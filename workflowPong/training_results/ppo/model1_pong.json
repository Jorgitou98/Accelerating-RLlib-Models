["{\"n\": 1, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1212.5, \"learn_time_ms\": 14236.284, \"total_train_time_s\": 25.24282479286194}", "{\"n\": 2, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1244.4, \"learn_time_ms\": 13744.26, \"total_train_time_s\": 24.442487955093384}", "{\"n\": 3, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.555555555555557, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1195.4444444444443, \"learn_time_ms\": 13701.996, \"total_train_time_s\": 24.559679985046387}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.333333333333332, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1206.0833333333333, \"learn_time_ms\": 13771.078, \"total_train_time_s\": 24.892672538757324}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1175.75, \"learn_time_ms\": 13564.234, \"total_train_time_s\": 24.053393363952637}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.526315789473685, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1176.6315789473683, \"learn_time_ms\": 13429.875, \"total_train_time_s\": 23.71034836769104}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1187.2727272727273, \"learn_time_ms\": 13391.56, \"total_train_time_s\": 24.328373432159424}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46153846153846, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1186.1538461538462, \"learn_time_ms\": 13483.493, \"total_train_time_s\": 25.084429264068604}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.413793103448278, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1191.896551724138, \"learn_time_ms\": 13430.312, \"total_train_time_s\": 24.07832407951355}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.375, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1199.84375, \"learn_time_ms\": 13470.292, \"total_train_time_s\": 24.86454749107361}"]["{\"n\": 1, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1166.0, \"learn_time_ms\": 13399.485, \"total_train_time_s\": 24.761070013046265}", "{\"n\": 2, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1138.6, \"learn_time_ms\": 12757.907, \"total_train_time_s\": 23.18251872062683}", "{\"n\": 3, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.666666666666668, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1197.7777777777778, \"learn_time_ms\": 12105.369, \"total_train_time_s\": 22.07895803451538}"]