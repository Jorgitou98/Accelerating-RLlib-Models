["{\"n\": 1, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1060.0, \"learn_time_ms\": 15718.717, \"total_train_time_s\": 29.818838357925415}", "{\"n\": 2, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1034.6666666666667, \"learn_time_ms\": 15525.699, \"total_train_time_s\": 24.91517400741577}", "{\"n\": 3, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.9, \"learn_time_ms\": 15394.755, \"total_train_time_s\": 25.45125102996826}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.928571428571427, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.5714285714287, \"learn_time_ms\": 15417.255, \"total_train_time_s\": 26.16796040534973}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.944444444444443, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.611111111111, \"learn_time_ms\": 15399.591, \"total_train_time_s\": 24.936664581298828}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.954545454545453, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.7727272727273, \"learn_time_ms\": 15339.435, \"total_train_time_s\": 26.164987564086914}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.923076923076923, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.7692307692307, \"learn_time_ms\": 15355.166, \"total_train_time_s\": 25.96389603614807}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1045.1, \"learn_time_ms\": 15326.578, \"total_train_time_s\": 25.497974634170532}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87878787878788, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1049.0, \"learn_time_ms\": 15356.622, \"total_train_time_s\": 26.329797744750977}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89189189189189, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1054.4324324324325, \"learn_time_ms\": 15379.504, \"total_train_time_s\": 25.696462154388428}"]["{\"n\": 1, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1244.5, \"learn_time_ms\": 15514.837, \"total_train_time_s\": 26.977269411087036}", "{\"n\": 2, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1279.8, \"learn_time_ms\": 15376.065, \"total_train_time_s\": 31.254196643829346}"]