["{\"n\": 1, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -770.6, \"episode_reward_max\": -668.0, \"episode_len_mean\": 200.0, \"learn_time_ms\": 2571.318, \"total_train_time_s\": 6.463725328445435}", "{\"n\": 2, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -751.175, \"episode_reward_max\": -287.0, \"episode_len_mean\": 197.3, \"learn_time_ms\": 3514.633, \"total_train_time_s\": 8.330763816833496}", "{\"n\": 3, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -729.8333333333334, \"episode_reward_max\": -287.0, \"episode_len_mean\": 196.68333333333334, \"learn_time_ms\": 3570.695, \"total_train_time_s\": 7.503092050552368}", "{\"n\": 4, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -717.525, \"episode_reward_max\": -287.0, \"episode_len_mean\": 197.5125, \"learn_time_ms\": 3542.547, \"total_train_time_s\": 7.416043043136597}", "{\"n\": 5, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -697.66, \"episode_reward_max\": -206.0, \"episode_len_mean\": 196.48, \"learn_time_ms\": 3879.625, \"total_train_time_s\": 9.112382650375366}", "{\"n\": 6, \"episode_reward_min\": -884.0, \"episode_reward_mean\": -663.46, \"episode_reward_max\": -206.0, \"episode_len_mean\": 196.48, \"learn_time_ms\": 4067.223, \"total_train_time_s\": 8.823630094528198}", "{\"n\": 7, \"episode_reward_min\": -884.0, \"episode_reward_mean\": -622.04, \"episode_reward_max\": -206.0, \"episode_len_mean\": 196.37, \"learn_time_ms\": 4027.406, \"total_train_time_s\": 7.619020462036133}", "{\"n\": 8, \"episode_reward_min\": -965.0, \"episode_reward_mean\": -590.86, \"episode_reward_max\": -206.0, \"episode_len_mean\": 197.23, \"learn_time_ms\": 4138.591, \"total_train_time_s\": 8.781495571136475}", "{\"n\": 9, \"episode_reward_min\": -965.0, \"episode_reward_mean\": -545.81, \"episode_reward_max\": -206.0, \"episode_len_mean\": 196.07, \"learn_time_ms\": 4149.898, \"total_train_time_s\": 8.232675313949585}", "{\"n\": 10, \"episode_reward_min\": -965.0, \"episode_reward_mean\": -496.33, \"episode_reward_max\": -114.0, \"episode_len_mean\": 196.0, \"learn_time_ms\": 3997.159, \"total_train_time_s\": 6.618338346481323}"]["{\"n\": 1, \"episode_reward_min\": -902.0, \"episode_reward_mean\": -800.3, \"episode_reward_max\": -713.0, \"episode_len_mean\": 200.0, \"learn_time_ms\": 5489.483, \"total_train_time_s\": 9.401346445083618}", "{\"n\": 2, \"episode_reward_min\": -902.0, \"episode_reward_mean\": -779.6, \"episode_reward_max\": -641.0, \"episode_len_mean\": 200.0, \"learn_time_ms\": 5183.103, \"total_train_time_s\": 8.767105102539062}", "{\"n\": 3, \"episode_reward_min\": -902.0, \"episode_reward_mean\": -756.05, \"episode_reward_max\": -569.0, \"episode_len_mean\": 200.0, \"learn_time_ms\": 4939.956, \"total_train_time_s\": 8.426772832870483}", "{\"n\": 4, \"episode_reward_min\": -902.0, \"episode_reward_mean\": -730.5625, \"episode_reward_max\": -542.0, \"episode_len_mean\": 199.9375, \"learn_time_ms\": 4662.919, \"total_train_time_s\": 7.800619602203369}", "{\"n\": 5, \"episode_reward_min\": -902.0, \"episode_reward_mean\": -700.86, \"episode_reward_max\": -461.0, \"episode_len_mean\": 199.95, \"learn_time_ms\": 4628.082, \"total_train_time_s\": 8.435993194580078}", "{\"n\": 6, \"episode_reward_min\": -866.0, \"episode_reward_mean\": -659.01, \"episode_reward_max\": -452.0, \"episode_len_mean\": 199.95, \"learn_time_ms\": 4735.463, \"total_train_time_s\": 9.532742977142334}", "{\"n\": 7, \"episode_reward_min\": -866.0, \"episode_reward_mean\": -623.9, \"episode_reward_max\": -190.0, \"episode_len_mean\": 198.62, \"learn_time_ms\": 4738.852, \"total_train_time_s\": 9.764745950698853}", "{\"n\": 8, \"episode_reward_min\": -839.0, \"episode_reward_mean\": -577.72, \"episode_reward_max\": -73.0, \"episode_len_mean\": 197.11, \"learn_time_ms\": 4624.351, \"total_train_time_s\": 7.843708515167236}", "{\"n\": 9, \"episode_reward_min\": -839.0, \"episode_reward_mean\": -545.39, \"episode_reward_max\": -73.0, \"episode_len_mean\": 196.46, \"learn_time_ms\": 4551.049, \"total_train_time_s\": 8.202889204025269}", "{\"n\": 10, \"episode_reward_min\": -839.0, \"episode_reward_mean\": -518.81, \"episode_reward_max\": -73.0, \"episode_len_mean\": 196.19, \"learn_time_ms\": 4490.21, \"total_train_time_s\": 7.878126621246338}"]["{\"n\": 1, \"episode_reward_min\": -920.0, \"episode_reward_mean\": -747.7, \"episode_reward_max\": -291.0, \"episode_len_mean\": 194.35, \"learn_time_ms\": 3596.032, \"total_train_time_s\": 7.474529027938843}", "{\"n\": 2, \"episode_reward_min\": -920.0, \"episode_reward_mean\": -716.9, \"episode_reward_max\": -291.0, \"episode_len_mean\": 195.725, \"learn_time_ms\": 4240.591, \"total_train_time_s\": 8.659173488616943}", "{\"n\": 3, \"episode_reward_min\": -920.0, \"episode_reward_mean\": -701.05, \"episode_reward_max\": -291.0, \"episode_len_mean\": 197.15, \"learn_time_ms\": 3830.577, \"total_train_time_s\": 7.293977975845337}", "{\"n\": 4, \"episode_reward_min\": -920.0, \"episode_reward_mean\": -674.0853658536586, \"episode_reward_max\": -125.0, \"episode_len_mean\": 194.6341463414634, \"learn_time_ms\": 3707.125, \"total_train_time_s\": 7.778702974319458}", "{\"n\": 5, \"episode_reward_min\": -920.0, \"episode_reward_mean\": -654.67, \"episode_reward_max\": -125.0, \"episode_len_mean\": 195.4, \"learn_time_ms\": 3866.375, \"total_train_time_s\": 8.35298752784729}", "{\"n\": 6, \"episode_reward_min\": -830.0, \"episode_reward_mean\": -606.22, \"episode_reward_max\": -125.0, \"episode_len_mean\": 193.54, \"learn_time_ms\": 3962.815, \"total_train_time_s\": 9.566411256790161}", "{\"n\": 7, \"episode_reward_min\": -785.0, \"episode_reward_mean\": -564.68, \"episode_reward_max\": -125.0, \"episode_len_mean\": 193.52, \"learn_time_ms\": 3843.105, \"total_train_time_s\": 7.220056533813477}", "{\"n\": 8, \"episode_reward_min\": -776.0, \"episode_reward_mean\": -499.36, \"episode_reward_max\": -61.0, \"episode_len_mean\": 187.81, \"learn_time_ms\": 3768.15, \"total_train_time_s\": 7.574686765670776}", "{\"n\": 9, \"episode_reward_min\": -677.0, \"episode_reward_mean\": -463.16, \"episode_reward_max\": -61.0, \"episode_len_mean\": 187.43, \"learn_time_ms\": 3952.272, \"total_train_time_s\": 9.289734125137329}", "{\"n\": 10, \"episode_reward_min\": -668.0, \"episode_reward_mean\": -412.75, \"episode_reward_max\": -26.0, \"episode_len_mean\": 180.64, \"learn_time_ms\": 4059.365, \"total_train_time_s\": 8.826020956039429}", "{\"n\": 11, \"episode_reward_min\": -632.0, \"episode_reward_mean\": -376.07, \"episode_reward_max\": -26.0, \"episode_len_mean\": 177.11, \"learn_time_ms\": 4071.991, \"total_train_time_s\": 7.495086431503296}", "{\"n\": 12, \"episode_reward_min\": -632.0, \"episode_reward_mean\": -347.86, \"episode_reward_max\": -16.0, \"episode_len_mean\": 171.79, \"learn_time_ms\": 3887.305, \"total_train_time_s\": 6.821305751800537}", "{\"n\": 13, \"episode_reward_min\": -632.0, \"episode_reward_mean\": -315.17, \"episode_reward_max\": -16.0, \"episode_len_mean\": 169.97, \"learn_time_ms\": 4008.874, \"total_train_time_s\": 8.100349426269531}", "{\"n\": 14, \"episode_reward_min\": -596.0, \"episode_reward_mean\": -280.53, \"episode_reward_max\": -7.0, \"episode_len_mean\": 162.48, \"learn_time_ms\": 3911.286, \"total_train_time_s\": 6.284930944442749}", "{\"n\": 15, \"episode_reward_min\": -596.0, \"episode_reward_mean\": -254.17, \"episode_reward_max\": -7.0, \"episode_len_mean\": 157.72, \"learn_time_ms\": 3809.228, \"total_train_time_s\": 7.863272666931152}", "{\"n\": 16, \"episode_reward_min\": -497.0, \"episode_reward_mean\": -234.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 154.93, \"learn_time_ms\": 3814.395, \"total_train_time_s\": 8.315915822982788}", "{\"n\": 17, \"episode_reward_min\": -524.0, \"episode_reward_mean\": -200.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 135.47, \"learn_time_ms\": 3842.252, \"total_train_time_s\": 7.918500661849976}", "{\"n\": 18, \"episode_reward_min\": -524.0, \"episode_reward_mean\": -199.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 139.07, \"learn_time_ms\": 3856.663, \"total_train_time_s\": 7.483479976654053}", "{\"n\": 19, \"episode_reward_min\": -524.0, \"episode_reward_mean\": -170.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 126.06, \"learn_time_ms\": 3804.323, \"total_train_time_s\": 8.777126789093018}", "{\"n\": 20, \"episode_reward_min\": -407.0, \"episode_reward_mean\": -159.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 126.58, \"learn_time_ms\": 3772.27, \"total_train_time_s\": 8.441848278045654}", "{\"n\": 21, \"episode_reward_min\": -407.0, \"episode_reward_mean\": -152.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 125.01, \"learn_time_ms\": 3894.469, \"total_train_time_s\": 8.728464365005493}", "{\"n\": 22, \"episode_reward_min\": -407.0, \"episode_reward_mean\": -153.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 130.13, \"learn_time_ms\": 4136.648, \"total_train_time_s\": 9.997196912765503}", "{\"n\": 23, \"episode_reward_min\": -344.0, \"episode_reward_mean\": -141.04, \"episode_reward_max\": 7.0, \"episode_len_mean\": 122.32, \"learn_time_ms\": 4237.022, \"total_train_time_s\": 9.289427042007446}", "{\"n\": 24, \"episode_reward_min\": -326.0, \"episode_reward_mean\": -110.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 102.39, \"learn_time_ms\": 4205.614, \"total_train_time_s\": 5.885413646697998}", "{\"n\": 25, \"episode_reward_min\": -308.0, \"episode_reward_mean\": -100.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 96.26, \"learn_time_ms\": 4367.197, \"total_train_time_s\": 9.783565282821655}", "{\"n\": 26, \"episode_reward_min\": -308.0, \"episode_reward_mean\": -98.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 96.69, \"learn_time_ms\": 4101.293, \"total_train_time_s\": 5.701527833938599}", "{\"n\": 27, \"episode_reward_min\": -308.0, \"episode_reward_mean\": -103.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 102.98, \"learn_time_ms\": 4125.049, \"total_train_time_s\": 7.476345539093018}", "{\"n\": 28, \"episode_reward_min\": -272.0, \"episode_reward_mean\": -110.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 109.96, \"learn_time_ms\": 4131.735, \"total_train_time_s\": 7.554596662521362}", "{\"n\": 29, \"episode_reward_min\": -263.0, \"episode_reward_mean\": -84.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 89.5, \"learn_time_ms\": 3988.474, \"total_train_time_s\": 7.417399644851685}", "{\"n\": 30, \"episode_reward_min\": -254.0, \"episode_reward_mean\": -64.0, \"episode_reward_max\": 14.0, \"episode_len_mean\": 73.63, \"learn_time_ms\": 3922.524, \"total_train_time_s\": 8.68003249168396}", "{\"n\": 31, \"episode_reward_min\": -254.0, \"episode_reward_mean\": -63.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 74.52, \"learn_time_ms\": 3869.752, \"total_train_time_s\": 8.418171167373657}", "{\"n\": 32, \"episode_reward_min\": -254.0, \"episode_reward_mean\": -70.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 80.93, \"learn_time_ms\": 3722.243, \"total_train_time_s\": 7.803366422653198}", "{\"n\": 33, \"episode_reward_min\": -254.0, \"episode_reward_mean\": -83.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 90.63, \"learn_time_ms\": 3555.567, \"total_train_time_s\": 7.344155311584473}", "{\"n\": 34, \"episode_reward_min\": -254.0, \"episode_reward_mean\": -97.0, \"episode_reward_max\": 15.0, \"episode_len_mean\": 101.83, \"learn_time_ms\": 3883.294, \"total_train_time_s\": 9.464335918426514}", "{\"n\": 35, \"episode_reward_min\": -254.0, \"episode_reward_mean\": -104.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 108.38, \"learn_time_ms\": 3862.913, \"total_train_time_s\": 9.326492547988892}", "{\"n\": 36, \"episode_reward_min\": -245.0, \"episode_reward_mean\": -97.7, \"episode_reward_max\": 14.0, \"episode_len_mean\": 103.58, \"learn_time_ms\": 4186.071, \"total_train_time_s\": 9.596236944198608}", "{\"n\": 37, \"episode_reward_min\": -236.0, \"episode_reward_mean\": -82.66, \"episode_reward_max\": 14.0, \"episode_len_mean\": 91.63, \"learn_time_ms\": 4389.597, \"total_train_time_s\": 9.455227375030518}", "{\"n\": 38, \"episode_reward_min\": -281.0, \"episode_reward_mean\": -72.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 82.31, \"learn_time_ms\": 4489.575, \"total_train_time_s\": 8.770145177841187}", "{\"n\": 39, \"episode_reward_min\": -281.0, \"episode_reward_mean\": -71.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 81.11, \"learn_time_ms\": 4683.434, \"total_train_time_s\": 9.234663248062134}", "{\"n\": 40, \"episode_reward_min\": -281.0, \"episode_reward_mean\": -81.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 91.49, \"learn_time_ms\": 4747.282, \"total_train_time_s\": 9.169251203536987}", "{\"n\": 41, \"episode_reward_min\": -245.0, \"episode_reward_mean\": -71.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 84.23, \"learn_time_ms\": 4644.811, \"total_train_time_s\": 7.962663173675537}", "{\"n\": 42, \"episode_reward_min\": -245.0, \"episode_reward_mean\": -55.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 68.75, \"learn_time_ms\": 4735.556, \"total_train_time_s\": 8.70341420173645}", "{\"n\": 43, \"episode_reward_min\": -254.0, \"episode_reward_mean\": -54.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 67.27, \"learn_time_ms\": 4722.848, \"total_train_time_s\": 7.17958402633667}", "{\"n\": 44, \"episode_reward_min\": -254.0, \"episode_reward_mean\": -62.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 73.8, \"learn_time_ms\": 4450.32, \"total_train_time_s\": 6.39035177230835}", "{\"n\": 45, \"episode_reward_min\": -299.0, \"episode_reward_mean\": -72.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 82.07, \"learn_time_ms\": 4498.787, \"total_train_time_s\": 9.598202466964722}", "{\"n\": 46, \"episode_reward_min\": -299.0, \"episode_reward_mean\": -70.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 81.31, \"learn_time_ms\": 4381.636, \"total_train_time_s\": 7.955387353897095}", "{\"n\": 47, \"episode_reward_min\": -227.0, \"episode_reward_mean\": -59.34, \"episode_reward_max\": 14.0, \"episode_len_mean\": 72.96, \"learn_time_ms\": 4184.311, \"total_train_time_s\": 7.808483839035034}", "{\"n\": 48, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -56.92, \"episode_reward_max\": 14.0, \"episode_len_mean\": 70.69, \"learn_time_ms\": 4287.753, \"total_train_time_s\": 9.25984811782837}", "{\"n\": 49, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -66.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 79.07, \"learn_time_ms\": 4092.713, \"total_train_time_s\": 7.374577760696411}", "{\"n\": 50, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -66.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 79.41, \"learn_time_ms\": 3988.303, \"total_train_time_s\": 7.527630090713501}", "{\"n\": 51, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -59.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 73.5, \"learn_time_ms\": 4106.731, \"total_train_time_s\": 8.795652389526367}", "{\"n\": 52, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -64.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 78.37, \"learn_time_ms\": 3949.367, \"total_train_time_s\": 7.392401933670044}", "{\"n\": 53, \"episode_reward_min\": -335.0, \"episode_reward_mean\": -66.48, \"episode_reward_max\": 15.0, \"episode_len_mean\": 78.84, \"learn_time_ms\": 3950.849, \"total_train_time_s\": 7.2085113525390625}", "{\"n\": 54, \"episode_reward_min\": -398.0, \"episode_reward_mean\": -75.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 84.26, \"learn_time_ms\": 4063.894, \"total_train_time_s\": 7.960203647613525}", "{\"n\": 55, \"episode_reward_min\": -398.0, \"episode_reward_mean\": -77.73, \"episode_reward_max\": 15.0, \"episode_len_mean\": 86.37, \"learn_time_ms\": 3755.348, \"total_train_time_s\": 6.1812522411346436}", "{\"n\": 56, \"episode_reward_min\": -236.0, \"episode_reward_mean\": -64.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 77.57, \"learn_time_ms\": 3793.632, \"total_train_time_s\": 8.01600980758667}", "{\"n\": 57, \"episode_reward_min\": -272.0, \"episode_reward_mean\": -68.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 80.63, \"learn_time_ms\": 3966.039, \"total_train_time_s\": 9.327914237976074}", "{\"n\": 58, \"episode_reward_min\": -272.0, \"episode_reward_mean\": -55.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 68.77, \"learn_time_ms\": 3717.749, \"total_train_time_s\": 6.8257598876953125}", "{\"n\": 59, \"episode_reward_min\": -263.0, \"episode_reward_mean\": -53.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 67.92, \"learn_time_ms\": 3751.478, \"total_train_time_s\": 7.660545587539673}", "{\"n\": 60, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -59.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 73.38, \"learn_time_ms\": 3813.508, \"total_train_time_s\": 8.106534719467163}", "{\"n\": 61, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -60.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 73.83, \"learn_time_ms\": 3640.766, \"total_train_time_s\": 6.830529451370239}", "{\"n\": 62, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -55.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 69.75, \"learn_time_ms\": 3686.408, \"total_train_time_s\": 7.731589078903198}", "{\"n\": 63, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -69.75, \"episode_reward_max\": 14.0, \"episode_len_mean\": 82.56, \"learn_time_ms\": 3818.303, \"total_train_time_s\": 8.564268827438354}", "{\"n\": 64, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -73.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 85.85, \"learn_time_ms\": 4000.573, \"total_train_time_s\": 10.090790271759033}", "{\"n\": 65, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -43.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 59.56, \"learn_time_ms\": 4056.144, \"total_train_time_s\": 6.827287673950195}", "{\"n\": 66, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -56.4, \"episode_reward_max\": 14.0, \"episode_len_mean\": 70.98, \"learn_time_ms\": 4032.979, \"total_train_time_s\": 7.813515901565552}", "{\"n\": 67, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -63.73, \"episode_reward_max\": 14.0, \"episode_len_mean\": 77.74, \"learn_time_ms\": 3780.48, \"total_train_time_s\": 6.7213075160980225}", "{\"n\": 68, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -72.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 85.24, \"learn_time_ms\": 3912.798, \"total_train_time_s\": 8.177189111709595}", "{\"n\": 69, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -67.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 80.49, \"learn_time_ms\": 4101.132, \"total_train_time_s\": 9.577738523483276}", "{\"n\": 70, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -51.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 66.03, \"learn_time_ms\": 4309.007, \"total_train_time_s\": 10.585601806640625}", "{\"n\": 71, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -62.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 76.58, \"learn_time_ms\": 4610.939, \"total_train_time_s\": 10.15756344795227}", "{\"n\": 72, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -75.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 87.75, \"learn_time_ms\": 4724.771, \"total_train_time_s\": 8.96408224105835}", "{\"n\": 73, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -51.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 66.82, \"learn_time_ms\": 4619.539, \"total_train_time_s\": 7.570673704147339}", "{\"n\": 74, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -48.89, \"episode_reward_max\": 14.0, \"episode_len_mean\": 64.64, \"learn_time_ms\": 4503.062, \"total_train_time_s\": 8.439242601394653}", "{\"n\": 75, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -60.89, \"episode_reward_max\": 12.0, \"episode_len_mean\": 75.2, \"learn_time_ms\": 4628.529, \"total_train_time_s\": 7.9032886028289795}", "{\"n\": 76, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -63.51, \"episode_reward_max\": 15.0, \"episode_len_mean\": 77.4, \"learn_time_ms\": 4489.242, \"total_train_time_s\": 6.853801488876343}", "{\"n\": 77, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -60.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 75.16, \"learn_time_ms\": 4563.908, \"total_train_time_s\": 7.695039510726929}", "{\"n\": 78, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -41.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 57.75, \"learn_time_ms\": 4399.451, \"total_train_time_s\": 7.216443300247192}", "{\"n\": 79, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -53.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 67.92, \"learn_time_ms\": 4398.996, \"total_train_time_s\": 9.502144813537598}", "{\"n\": 80, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -49.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 65.13, \"learn_time_ms\": 4219.079, \"total_train_time_s\": 8.381021976470947}", "{\"n\": 81, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -49.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 65.08, \"learn_time_ms\": 4102.676, \"total_train_time_s\": 8.688272714614868}", "{\"n\": 82, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -59.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 73.52, \"learn_time_ms\": 4042.837, \"total_train_time_s\": 8.49165415763855}", "{\"n\": 83, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -52.6, \"episode_reward_max\": 14.0, \"episode_len_mean\": 67.45, \"learn_time_ms\": 4094.852, \"total_train_time_s\": 7.952418565750122}", "{\"n\": 84, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -44.16, \"episode_reward_max\": 14.0, \"episode_len_mean\": 60.24, \"learn_time_ms\": 4026.866, \"total_train_time_s\": 8.37319302558899}", "{\"n\": 85, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -41.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 57.74, \"learn_time_ms\": 3969.908, \"total_train_time_s\": 8.144410610198975}", "{\"n\": 86, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -42.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 58.25, \"learn_time_ms\": 4135.579, \"total_train_time_s\": 9.992529392242432}", "{\"n\": 87, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -56.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 71.03, \"learn_time_ms\": 4226.289, \"total_train_time_s\": 8.41215991973877}", "{\"n\": 88, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -67.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 81.09, \"learn_time_ms\": 4468.097, \"total_train_time_s\": 9.031285285949707}", "{\"n\": 89, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -58.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 73.57, \"learn_time_ms\": 4298.246, \"total_train_time_s\": 8.212612628936768}", "{\"n\": 90, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -41.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 58.08, \"learn_time_ms\": 4241.344, \"total_train_time_s\": 7.903102397918701}", "{\"n\": 91, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -59.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 73.99, \"learn_time_ms\": 4177.723, \"total_train_time_s\": 7.884031772613525}", "{\"n\": 92, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -73.13, \"episode_reward_max\": 15.0, \"episode_len_mean\": 85.91, \"learn_time_ms\": 4067.295, \"total_train_time_s\": 7.007686138153076}", "{\"n\": 93, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -65.33, \"episode_reward_max\": 15.0, \"episode_len_mean\": 79.1, \"learn_time_ms\": 4072.332, \"total_train_time_s\": 8.048357009887695}", "{\"n\": 94, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -64.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 78.9, \"learn_time_ms\": 4198.346, \"total_train_time_s\": 8.812813520431519}", "{\"n\": 95, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -75.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 88.15, \"learn_time_ms\": 4310.123, \"total_train_time_s\": 8.492565393447876}", "{\"n\": 96, \"episode_reward_min\": -218.0, \"episode_reward_mean\": -84.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 95.95, \"learn_time_ms\": 4318.254, \"total_train_time_s\": 8.38731050491333}", "{\"n\": 97, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -71.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 84.52, \"learn_time_ms\": 4286.951, \"total_train_time_s\": 8.131815195083618}", "{\"n\": 98, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -56.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 70.76, \"learn_time_ms\": 4161.403, \"total_train_time_s\": 7.9239184856414795}", "{\"n\": 99, \"episode_reward_min\": -200.0, \"episode_reward_mean\": -65.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 79.62, \"learn_time_ms\": 4195.325, \"total_train_time_s\": 8.183425188064575}", "{\"n\": 100, \"episode_reward_min\": -209.0, \"episode_reward_mean\": -65.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 79.28, \"learn_time_ms\": 4384.191, \"total_train_time_s\": 9.879571437835693}"]["{\"n\": 1, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -780.95, \"episode_reward_max\": -506.0, \"episode_len_mean\": 196.55, \"learn_time_ms\": 4287.705, \"total_train_time_s\": 8.24838662147522}", "{\"n\": 2, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -754.375, \"episode_reward_max\": -226.0, \"episode_len_mean\": 195.175, \"learn_time_ms\": 4821.493, \"total_train_time_s\": 9.118996858596802}", "{\"n\": 3, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -749.4333333333333, \"episode_reward_max\": -226.0, \"episode_len_mean\": 196.78333333333333, \"learn_time_ms\": 4798.505, \"total_train_time_s\": 8.661937713623047}", "{\"n\": 4, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -724.5975609756098, \"episode_reward_max\": -138.0, \"episode_len_mean\": 194.1829268292683, \"learn_time_ms\": 4747.526, \"total_train_time_s\": 9.181194543838501}", "{\"n\": 5, \"episode_reward_min\": -884.0, \"episode_reward_mean\": -709.73, \"episode_reward_max\": -138.0, \"episode_len_mean\": 195.23, \"learn_time_ms\": 4896.379, \"total_train_time_s\": 9.683757066726685}", "{\"n\": 6, \"episode_reward_min\": -866.0, \"episode_reward_mean\": -668.6, \"episode_reward_max\": -138.0, \"episode_len_mean\": 195.92, \"learn_time_ms\": 4914.757, \"total_train_time_s\": 9.304538488388062}", "{\"n\": 7, \"episode_reward_min\": -866.0, \"episode_reward_mean\": -627.75, \"episode_reward_max\": -138.0, \"episode_len_mean\": 197.16, \"learn_time_ms\": 4975.316, \"total_train_time_s\": 9.321289777755737}", "{\"n\": 8, \"episode_reward_min\": -830.0, \"episode_reward_mean\": -573.93, \"episode_reward_max\": -138.0, \"episode_len_mean\": 197.16, \"learn_time_ms\": 4990.135, \"total_train_time_s\": 9.769370079040527}", "{\"n\": 9, \"episode_reward_min\": -830.0, \"episode_reward_mean\": -522.24, \"episode_reward_max\": -153.0, \"episode_len_mean\": 197.76, \"learn_time_ms\": 4644.267, \"total_train_time_s\": 6.013020038604736}", "{\"n\": 10, \"episode_reward_min\": -749.0, \"episode_reward_mean\": -474.0, \"episode_reward_max\": -153.0, \"episode_len_mean\": 197.76, \"learn_time_ms\": 4375.956, \"total_train_time_s\": 5.991300106048584}"]["{\"n\": 1, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -765.35, \"episode_reward_max\": -329.0, \"episode_len_mean\": 194.9, \"learn_time_ms\": 3673.711, \"total_train_time_s\": 8.122333526611328}", "{\"n\": 2, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -741.4634146341464, \"episode_reward_max\": -329.0, \"episode_len_mean\": 195.02439024390245, \"learn_time_ms\": 3805.093, \"total_train_time_s\": 7.713823556900024}", "{\"n\": 3, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -725.5081967213115, \"episode_reward_max\": -309.0, \"episode_len_mean\": 195.24590163934425, \"learn_time_ms\": 3771.511, \"total_train_time_s\": 7.5652923583984375}", "{\"n\": 4, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -694.1927710843373, \"episode_reward_max\": -73.0, \"episode_len_mean\": 192.46987951807228, \"learn_time_ms\": 3878.897, \"total_train_time_s\": 8.390843629837036}", "{\"n\": 5, \"episode_reward_min\": -893.0, \"episode_reward_mean\": -670.75, \"episode_reward_max\": -73.0, \"episode_len_mean\": 193.18, \"learn_time_ms\": 4025.891, \"total_train_time_s\": 8.444833040237427}", "{\"n\": 6, \"episode_reward_min\": -875.0, \"episode_reward_mean\": -624.05, \"episode_reward_max\": -73.0, \"episode_len_mean\": 190.64, \"learn_time_ms\": 3962.678, \"total_train_time_s\": 7.916005849838257}", "{\"n\": 7, \"episode_reward_min\": -875.0, \"episode_reward_mean\": -601.02, \"episode_reward_max\": -73.0, \"episode_len_mean\": 190.08, \"learn_time_ms\": 3947.594, \"total_train_time_s\": 7.750525236129761}", "{\"n\": 8, \"episode_reward_min\": -812.0, \"episode_reward_mean\": -567.66, \"episode_reward_max\": -137.0, \"episode_len_mean\": 189.69, \"learn_time_ms\": 4060.315, \"total_train_time_s\": 9.717350959777832}", "{\"n\": 9, \"episode_reward_min\": -812.0, \"episode_reward_mean\": -525.81, \"episode_reward_max\": -88.0, \"episode_len_mean\": 186.09, \"learn_time_ms\": 4075.874, \"total_train_time_s\": 8.028571367263794}", "{\"n\": 10, \"episode_reward_min\": -857.0, \"episode_reward_mean\": -483.58, \"episode_reward_max\": -58.0, \"episode_len_mean\": 178.6, \"learn_time_ms\": 3924.955, \"total_train_time_s\": 6.3250532150268555}"]["{\"n\": 1, \"episode_reward_min\": -884.0, \"episode_reward_mean\": -759.85, \"episode_reward_max\": -395.0, \"episode_len_mean\": 191.5, \"learn_time_ms\": 2290.024, \"total_train_time_s\": 6.200985431671143}", "{\"n\": 2, \"episode_reward_min\": -884.0, \"episode_reward_mean\": -745.65, \"episode_reward_max\": -395.0, \"episode_len_mean\": 195.75, \"learn_time_ms\": 3476.657, \"total_train_time_s\": 8.654202699661255}", "{\"n\": 3, \"episode_reward_min\": -884.0, \"episode_reward_mean\": -726.1311475409836, \"episode_reward_max\": -395.0, \"episode_len_mean\": 196.50819672131146, \"learn_time_ms\": 3019.82, \"total_train_time_s\": 6.568488597869873}", "{\"n\": 4, \"episode_reward_min\": -884.0, \"episode_reward_mean\": -710.7777777777778, \"episode_reward_max\": -395.0, \"episode_len_mean\": 197.37037037037038, \"learn_time_ms\": 2963.648, \"total_train_time_s\": 6.743287086486816}", "{\"n\": 5, \"episode_reward_min\": -875.0, \"episode_reward_mean\": -667.67, \"episode_reward_max\": -53.0, \"episode_len_mean\": 193.52, \"learn_time_ms\": 3458.415, \"total_train_time_s\": 9.231478691101074}", "{\"n\": 6, \"episode_reward_min\": -821.0, \"episode_reward_mean\": -622.75, \"episode_reward_max\": -53.0, \"episode_len_mean\": 193.93, \"learn_time_ms\": 3472.46, \"total_train_time_s\": 7.398035049438477}", "{\"n\": 7, \"episode_reward_min\": -821.0, \"episode_reward_mean\": -578.11, \"episode_reward_max\": -53.0, \"episode_len_mean\": 192.1, \"learn_time_ms\": 3467.862, \"total_train_time_s\": 7.20008397102356}", "{\"n\": 8, \"episode_reward_min\": -785.0, \"episode_reward_mean\": -520.03, \"episode_reward_max\": -34.0, \"episode_len_mean\": 187.78, \"learn_time_ms\": 3362.707, \"total_train_time_s\": 6.871255159378052}", "{\"n\": 9, \"episode_reward_min\": -758.0, \"episode_reward_mean\": -487.68, \"episode_reward_max\": -34.0, \"episode_len_mean\": 188.61, \"learn_time_ms\": 3348.716, \"total_train_time_s\": 7.2170209884643555}", "{\"n\": 10, \"episode_reward_min\": -722.0, \"episode_reward_mean\": -449.43, \"episode_reward_max\": -34.0, \"episode_len_mean\": 189.96, \"learn_time_ms\": 3364.011, \"total_train_time_s\": 7.726320028305054}"]["{\"n\": 1, \"episode_reward_min\": -920.0, \"episode_reward_mean\": -717.4761904761905, \"episode_reward_max\": -183.0, \"episode_len_mean\": 186.9047619047619, \"learn_time_ms\": 4397.239, \"total_train_time_s\": 8.2499418258667}", "{\"n\": 2, \"episode_reward_min\": -920.0, \"episode_reward_mean\": -727.2926829268292, \"episode_reward_max\": -183.0, \"episode_len_mean\": 190.73170731707316, \"learn_time_ms\": 3697.001, \"total_train_time_s\": 6.867610216140747}", "{\"n\": 3, \"episode_reward_min\": -920.0, \"episode_reward_mean\": -711.5967741935484, \"episode_reward_max\": -183.0, \"episode_len_mean\": 192.6451612903226, \"learn_time_ms\": 3830.575, \"total_train_time_s\": 7.959760904312134}", "{\"n\": 4, \"episode_reward_min\": -920.0, \"episode_reward_mean\": -685.952380952381, \"episode_reward_max\": -85.0, \"episode_len_mean\": 190.0952380952381, \"learn_time_ms\": 3937.101, \"total_train_time_s\": 8.13756537437439}", "{\"n\": 5, \"episode_reward_min\": -920.0, \"episode_reward_mean\": -679.39, \"episode_reward_max\": -85.0, \"episode_len_mean\": 191.68, \"learn_time_ms\": 4210.544, \"total_train_time_s\": 11.81766963005066}", "{\"n\": 6, \"episode_reward_min\": -884.0, \"episode_reward_mean\": -660.38, \"episode_reward_max\": -85.0, \"episode_len_mean\": 194.21, \"learn_time_ms\": 4134.666, \"total_train_time_s\": 7.765719175338745}", "{\"n\": 7, \"episode_reward_min\": -866.0, \"episode_reward_mean\": -609.46, \"episode_reward_max\": -85.0, \"episode_len_mean\": 193.63, \"learn_time_ms\": 4199.965, \"total_train_time_s\": 8.40579342842102}", "{\"n\": 8, \"episode_reward_min\": -830.0, \"episode_reward_mean\": -569.01, \"episode_reward_max\": -32.0, \"episode_len_mean\": 192.54, \"learn_time_ms\": 4298.462, \"total_train_time_s\": 9.46550440788269}", "{\"n\": 9, \"episode_reward_min\": -803.0, \"episode_reward_mean\": -534.95, \"episode_reward_max\": -32.0, \"episode_len_mean\": 192.2, \"learn_time_ms\": 4157.061, \"total_train_time_s\": 6.842595100402832}", "{\"n\": 10, \"episode_reward_min\": -794.0, \"episode_reward_mean\": -478.65, \"episode_reward_max\": -9.0, \"episode_len_mean\": 186.24, \"learn_time_ms\": 4091.616, \"total_train_time_s\": 7.316408634185791}"]