["{\"n\": 1, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1248.0, \"learn_time_ms\": 12762.289, \"total_train_time_s\": 23.923706769943237}", "{\"n\": 2, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1244.0, \"learn_time_ms\": 12836.464, \"total_train_time_s\": 24.315317392349243}", "{\"n\": 3, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1246.25, \"learn_time_ms\": 12928.386, \"total_train_time_s\": 24.26589846611023}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.272727272727273, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1278.4545454545455, \"learn_time_ms\": 12647.074, \"total_train_time_s\": 22.938988208770752}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.214285714285715, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1273.142857142857, \"learn_time_ms\": 12501.058, \"total_train_time_s\": 22.91710114479065}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22222222222222, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1278.111111111111, \"learn_time_ms\": 12518.497, \"total_train_time_s\": 23.602263927459717}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.285714285714285, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1256.4285714285713, \"learn_time_ms\": 12648.789, \"total_train_time_s\": 24.325044631958008}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1255.75, \"learn_time_ms\": 12853.31, \"total_train_time_s\": 25.501240491867065}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22222222222222, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1267.4814814814815, \"learn_time_ms\": 12809.33, \"total_train_time_s\": 23.65334129333496}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.225806451612904, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1260.225806451613, \"learn_time_ms\": 12963.734, \"total_train_time_s\": 25.459941625595093}"]["{\"n\": 1, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1192.0, \"learn_time_ms\": 12946.303, \"total_train_time_s\": 22.279006004333496}", "{\"n\": 2, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1355.6, \"learn_time_ms\": 13324.014, \"total_train_time_s\": 22.77715539932251}", "{\"n\": 3, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.875, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1280.75, \"learn_time_ms\": 13175.507, \"total_train_time_s\": 22.038897275924683}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.083333333333332, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1228.1666666666667, \"learn_time_ms\": 13326.51, \"total_train_time_s\": 22.977306604385376}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.133333333333333, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1240.5333333333333, \"learn_time_ms\": 13357.503, \"total_train_time_s\": 22.64875555038452}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.166666666666668, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1237.3333333333333, \"learn_time_ms\": 13551.883, \"total_train_time_s\": 23.75745153427124}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.047619047619047, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1252.8095238095239, \"learn_time_ms\": 13292.629, \"total_train_time_s\": 20.90373134613037}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1258.625, \"learn_time_ms\": 13354.216, \"total_train_time_s\": 22.96247410774231}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.037037037037038, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1255.2592592592594, \"learn_time_ms\": 13305.965, \"total_train_time_s\": 22.056806087493896}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.032258064516128, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1267.4516129032259, \"learn_time_ms\": 13363.986, \"total_train_time_s\": 23.14988899230957}"]