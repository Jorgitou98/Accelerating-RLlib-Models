["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 40406.247}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 38806.142}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 38281.684}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1015.875, \"learn_time_ms\": 38042.168}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1015.75, \"learn_time_ms\": 37757.543}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.5625, \"learn_time_ms\": 37668.297}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.875, \"learn_time_ms\": 37605.489}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.875, \"learn_time_ms\": 37510.511}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.0, \"learn_time_ms\": 37477.826}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9444444444445, \"learn_time_ms\": 37451.824}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.575, \"learn_time_ms\": 37104.504}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.4791666666666, \"learn_time_ms\": 37105.76}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.4791666666666, \"learn_time_ms\": 37107.532}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9107142857143, \"learn_time_ms\": 37084.767}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.5967741935484, \"learn_time_ms\": 37131.944}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.65625, \"learn_time_ms\": 37130.542}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.7916666666666, \"learn_time_ms\": 37096.367}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.7916666666666, \"learn_time_ms\": 37136.835}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.85, \"learn_time_ms\": 37109.368}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.4941176470588, \"learn_time_ms\": 37086.438}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5227272727273, \"learn_time_ms\": 37082.948}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.4479166666666, \"learn_time_ms\": 37102.309}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.4479166666666, \"learn_time_ms\": 37074.258}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5, \"learn_time_ms\": 37061.607}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.42, \"learn_time_ms\": 37038.633}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.85, \"learn_time_ms\": 36999.43}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 36992.836}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 36919.659}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 36911.833}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 36909.868}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 36910.338}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 36827.204}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 36808.879}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.63, \"learn_time_ms\": 36750.191}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.37, \"learn_time_ms\": 36759.394}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.23, \"learn_time_ms\": 36776.115}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 36790.328}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 36836.365}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.57, \"learn_time_ms\": 36829.594}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.37, \"learn_time_ms\": 36783.105}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.16, \"learn_time_ms\": 36724.726}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.85, \"learn_time_ms\": 36748.49}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.85, \"learn_time_ms\": 36765.108}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.15, \"learn_time_ms\": 36759.983}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.05, \"learn_time_ms\": 36751.779}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 36754.885}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.62, \"learn_time_ms\": 36703.002}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.62, \"learn_time_ms\": 36668.602}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.73, \"learn_time_ms\": 36680.2}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.66, \"learn_time_ms\": 36718.754}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.15, \"learn_time_ms\": 36732.182}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.43, \"learn_time_ms\": 36680.085}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.43, \"learn_time_ms\": 36678.079}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.18, \"learn_time_ms\": 36734.596}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 36715.955}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 36669.488}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.51, \"learn_time_ms\": 36713.562}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.53, \"learn_time_ms\": 36714.653}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.63, \"learn_time_ms\": 36658.448}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.53, \"learn_time_ms\": 36636.635}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.51, \"learn_time_ms\": 36637.145}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 36689.461}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 36632.155}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.21, \"learn_time_ms\": 36570.813}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 36569.311}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 36590.546}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.32, \"learn_time_ms\": 36533.786}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.35, \"learn_time_ms\": 36514.704}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.67, \"learn_time_ms\": 36554.32}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.66, \"learn_time_ms\": 36551.016}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.68, \"learn_time_ms\": 36561.616}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.72, \"learn_time_ms\": 36580.175}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.62, \"learn_time_ms\": 36614.686}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.19, \"learn_time_ms\": 36634.14}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.06, \"learn_time_ms\": 36668.938}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.08, \"learn_time_ms\": 36659.282}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.79, \"learn_time_ms\": 36692.385}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.83, \"learn_time_ms\": 36689.514}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.9, \"learn_time_ms\": 36705.431}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.36, \"learn_time_ms\": 36742.38}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.33, \"learn_time_ms\": 36739.435}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.37, \"learn_time_ms\": 36724.962}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.39, \"learn_time_ms\": 36682.65}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.63, \"learn_time_ms\": 36723.663}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.5, \"learn_time_ms\": 36656.718}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.57, \"learn_time_ms\": 36609.633}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.34, \"learn_time_ms\": 36631.888}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.34, \"learn_time_ms\": 36656.287}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.49, \"learn_time_ms\": 36622.174}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.36, \"learn_time_ms\": 36612.708}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 36603.118}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 36605.946}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 36601.245}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 36612.114}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 36614.806}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.95, \"learn_time_ms\": 36622.17}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.85, \"learn_time_ms\": 36616.907}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.75, \"learn_time_ms\": 36609.91}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 36612.598}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.63, \"learn_time_ms\": 36611.31}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 36661.732}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 36644.431}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.33, \"learn_time_ms\": 36688.232}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.86, \"learn_time_ms\": 36697.548}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.84, \"learn_time_ms\": 36710.971}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.92, \"learn_time_ms\": 36766.169}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.53, \"learn_time_ms\": 36732.731}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.53, \"learn_time_ms\": 36749.078}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8, \"learn_time_ms\": 36748.005}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.17, \"learn_time_ms\": 36728.132}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 36686.08}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 36698.553}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 36683.315}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 36630.651}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 36670.424}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.43, \"learn_time_ms\": 36600.633}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 36576.976}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 36545.461}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.15, \"learn_time_ms\": 36561.768}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.23, \"learn_time_ms\": 36529.375}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.33, \"learn_time_ms\": 36523.84}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.65, \"learn_time_ms\": 36496.273}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.65, \"learn_time_ms\": 36512.62}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.91, \"learn_time_ms\": 36543.59}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 36545.853}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 36589.877}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 36626.805}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 36670.101}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.93, \"learn_time_ms\": 36634.039}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 36641.515}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 36631.953}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.76, \"learn_time_ms\": 36615.101}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 36607.803}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 36573.59}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.46, \"learn_time_ms\": 36566.78}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.44, \"learn_time_ms\": 36580.651}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 36558.458}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 36559.221}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 36590.853}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 36583.926}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 36632.059}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.88, \"learn_time_ms\": 36639.861}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.09, \"learn_time_ms\": 36638.427}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.62, \"learn_time_ms\": 36643.642}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.67, \"learn_time_ms\": 36604.011}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.71, \"learn_time_ms\": 36607.904}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.38, \"learn_time_ms\": 36601.002}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.07, \"learn_time_ms\": 36572.5}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.33, \"learn_time_ms\": 36584.242}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.15, \"learn_time_ms\": 36633.81}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.73, \"learn_time_ms\": 36620.626}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.56, \"learn_time_ms\": 36684.179}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.54, \"learn_time_ms\": 36655.777}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.99, \"learn_time_ms\": 36658.462}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.88, \"learn_time_ms\": 36653.051}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.09, \"learn_time_ms\": 36657.701}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.1, \"learn_time_ms\": 36706.353}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9, \"learn_time_ms\": 36715.693}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.96, \"learn_time_ms\": 36685.497}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.97, \"learn_time_ms\": 36686.279}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.3, \"learn_time_ms\": 36653.423}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.51, \"learn_time_ms\": 36633.753}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.64, \"learn_time_ms\": 36672.241}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.53, \"learn_time_ms\": 36652.872}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.65, \"learn_time_ms\": 36713.903}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.11, \"learn_time_ms\": 36679.882}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.98, \"learn_time_ms\": 36683.227}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.04, \"learn_time_ms\": 36709.086}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.98, \"learn_time_ms\": 36741.543}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 36715.359}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 36768.067}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 36766.957}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.81, \"learn_time_ms\": 36763.65}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 36806.435}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.68, \"learn_time_ms\": 36795.389}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 36784.332}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 36747.218}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 36753.203}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.73, \"learn_time_ms\": 36711.324}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.83, \"learn_time_ms\": 36733.519}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 36682.257}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.01, \"learn_time_ms\": 36638.329}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.96, \"learn_time_ms\": 36637.945}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.08, \"learn_time_ms\": 36605.294}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.3, \"learn_time_ms\": 36611.736}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.62, \"learn_time_ms\": 36665.027}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.97, \"learn_time_ms\": 36670.83}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.68, \"learn_time_ms\": 36663.684}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.24, \"learn_time_ms\": 36694.197}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.97, \"learn_time_ms\": 36663.491}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 36676.349}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 36718.574}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.22, \"learn_time_ms\": 36722.766}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.33, \"learn_time_ms\": 36720.301}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.43, \"learn_time_ms\": 36722.834}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.13, \"learn_time_ms\": 36682.96}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.15, \"learn_time_ms\": 36743.859}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.53, \"learn_time_ms\": 36705.462}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.28, \"learn_time_ms\": 36717.96}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.23, \"learn_time_ms\": 36706.193}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.19, \"learn_time_ms\": 36737.644}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.01, \"learn_time_ms\": 36739.744}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.18, \"learn_time_ms\": 36727.188}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.67, \"learn_time_ms\": 36734.942}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 36728.86}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.45, \"learn_time_ms\": 36736.626}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.15, \"learn_time_ms\": 36700.757}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.06, \"learn_time_ms\": 36724.758}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.36, \"learn_time_ms\": 36674.985}", "{\"n\": 210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.49, \"learn_time_ms\": 36727.274}", "{\"n\": 211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 36682.381}", "{\"n\": 212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.61, \"learn_time_ms\": 36663.601}", "{\"n\": 213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.53, \"learn_time_ms\": 36644.712}", "{\"n\": 214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 36673.763}", "{\"n\": 215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.15, \"learn_time_ms\": 36615.798}", "{\"n\": 216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 36644.031}", "{\"n\": 217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7, \"learn_time_ms\": 36659.173}", "{\"n\": 218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.31, \"learn_time_ms\": 36674.882}", "{\"n\": 219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 36676.598}", "{\"n\": 220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 36658.725}", "{\"n\": 221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 36691.724}", "{\"n\": 222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 36659.576}", "{\"n\": 223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.97, \"learn_time_ms\": 36674.137}", "{\"n\": 224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7, \"learn_time_ms\": 36684.849}", "{\"n\": 225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.62, \"learn_time_ms\": 36728.071}", "{\"n\": 226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.05, \"learn_time_ms\": 36699.119}", "{\"n\": 227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7, \"learn_time_ms\": 36699.093}", "{\"n\": 228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 36636.131}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.64, \"learn_time_ms\": 36662.713}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.89, \"learn_time_ms\": 36634.36}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 36600.624}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.96, \"learn_time_ms\": 36625.661}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.08, \"learn_time_ms\": 36628.699}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.94, \"learn_time_ms\": 36612.043}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.01, \"learn_time_ms\": 36605.953}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 36635.759}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 36588.931}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 36633.669}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 36623.997}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 36642.911}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.44, \"learn_time_ms\": 36681.453}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.57, \"learn_time_ms\": 36662.975}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.84, \"learn_time_ms\": 36694.356}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 36692.284}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.83, \"learn_time_ms\": 36664.298}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8, \"learn_time_ms\": 36648.553}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5, \"learn_time_ms\": 36681.55}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 36679.587}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 36680.695}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.82, \"learn_time_ms\": 36653.181}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 36657.123}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 36678.11}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34, \"learn_time_ms\": 36681.081}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.03, \"learn_time_ms\": 36648.721}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 36695.393}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 36674.802}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 36643.069}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.61, \"learn_time_ms\": 36644.152}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.37, \"learn_time_ms\": 36660.796}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.45, \"learn_time_ms\": 36692.527}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.21, \"learn_time_ms\": 36656.186}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.3, \"learn_time_ms\": 36652.189}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34, \"learn_time_ms\": 36660.451}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 36693.766}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.7, \"learn_time_ms\": 36659.172}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.71, \"learn_time_ms\": 36702.53}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.78, \"learn_time_ms\": 36751.501}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 36725.259}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.54, \"learn_time_ms\": 36738.379}", "{\"n\": 270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.43, \"learn_time_ms\": 36707.382}", "{\"n\": 271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.57, \"learn_time_ms\": 36742.454}", "{\"n\": 272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 36764.881}", "{\"n\": 273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.38, \"learn_time_ms\": 36752.406}", "{\"n\": 274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 36759.328}", "{\"n\": 275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.33, \"learn_time_ms\": 36751.526}", "{\"n\": 276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9, \"learn_time_ms\": 36748.697}", "{\"n\": 277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.79, \"learn_time_ms\": 36747.857}", "{\"n\": 278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.96, \"learn_time_ms\": 36751.098}", "{\"n\": 279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.8, \"learn_time_ms\": 36761.057}", "{\"n\": 280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.82, \"learn_time_ms\": 36765.914}", "{\"n\": 281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.68, \"learn_time_ms\": 36760.2}", "{\"n\": 282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.83, \"learn_time_ms\": 36748.988}", "{\"n\": 283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.67, \"learn_time_ms\": 36719.508}", "{\"n\": 284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.85, \"learn_time_ms\": 36696.335}", "{\"n\": 285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.16, \"learn_time_ms\": 36690.71}", "{\"n\": 286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.34, \"learn_time_ms\": 36683.044}", "{\"n\": 287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 36675.164}", "{\"n\": 288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.17, \"learn_time_ms\": 36677.795}", "{\"n\": 289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.33, \"learn_time_ms\": 36680.93}", "{\"n\": 290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.88, \"learn_time_ms\": 36692.168}", "{\"n\": 291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 36668.23}", "{\"n\": 292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.44, \"learn_time_ms\": 36684.852}", "{\"n\": 293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5, \"learn_time_ms\": 36719.176}", "{\"n\": 294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.44, \"learn_time_ms\": 36715.982}", "{\"n\": 295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.18, \"learn_time_ms\": 36757.25}", "{\"n\": 296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.47, \"learn_time_ms\": 36710.828}", "{\"n\": 297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8, \"learn_time_ms\": 36655.717}", "{\"n\": 298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 36661.007}", "{\"n\": 299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.57, \"learn_time_ms\": 36656.283}", "{\"n\": 300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.36, \"learn_time_ms\": 36686.543}", "{\"n\": 301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.95, \"learn_time_ms\": 36681.032}", "{\"n\": 302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.07, \"learn_time_ms\": 36634.554}", "{\"n\": 303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 36589.805}", "{\"n\": 304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.03, \"learn_time_ms\": 36627.969}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.13, \"learn_time_ms\": 36620.81}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.23, \"learn_time_ms\": 36675.637}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.42, \"learn_time_ms\": 36710.339}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.34, \"learn_time_ms\": 36690.779}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.22, \"learn_time_ms\": 36678.47}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.88, \"learn_time_ms\": 36660.127}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.88, \"learn_time_ms\": 36681.603}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.91, \"learn_time_ms\": 36695.563}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.21, \"learn_time_ms\": 36732.391}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.01, \"learn_time_ms\": 36725.066}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.96, \"learn_time_ms\": 36702.208}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.22, \"learn_time_ms\": 36658.707}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1, \"learn_time_ms\": 36659.967}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 36653.446}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 36643.728}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.12, \"learn_time_ms\": 36662.334}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 36617.261}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.46, \"learn_time_ms\": 36642.358}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 36588.43}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.54, \"learn_time_ms\": 36573.125}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 36565.541}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.74, \"learn_time_ms\": 36600.347}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.72, \"learn_time_ms\": 36620.82}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 36646.957}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 36672.698}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.42, \"learn_time_ms\": 36670.993}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 36689.33}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.21, \"learn_time_ms\": 36692.221}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34, \"learn_time_ms\": 36715.059}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 36714.645}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7, \"learn_time_ms\": 36758.883}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.17, \"learn_time_ms\": 36733.237}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.06, \"learn_time_ms\": 36696.809}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.83, \"learn_time_ms\": 36713.394}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.17, \"learn_time_ms\": 36673.915}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.94, \"learn_time_ms\": 36666.965}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.0, \"learn_time_ms\": 36690.718}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.9, \"learn_time_ms\": 36699.364}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.85, \"learn_time_ms\": 36683.888}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.67, \"learn_time_ms\": 36698.204}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.22, \"learn_time_ms\": 36643.41}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.63, \"learn_time_ms\": 36642.691}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.66, \"learn_time_ms\": 36644.275}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.12, \"learn_time_ms\": 36657.194}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.42, \"learn_time_ms\": 36660.585}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.36, \"learn_time_ms\": 36667.408}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.62, \"learn_time_ms\": 36660.451}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.86, \"learn_time_ms\": 36660.491}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.37, \"learn_time_ms\": 36665.607}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.38, \"learn_time_ms\": 36663.307}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.02, \"learn_time_ms\": 36720.995}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.59, \"learn_time_ms\": 36712.456}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.69, \"learn_time_ms\": 36692.167}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.78, \"learn_time_ms\": 36687.006}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.41, \"learn_time_ms\": 36672.502}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.01, \"learn_time_ms\": 36665.25}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.33, \"learn_time_ms\": 36664.739}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.42, \"learn_time_ms\": 36655.448}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.8, \"learn_time_ms\": 36687.927}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.0, \"learn_time_ms\": 36644.554}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.02, \"learn_time_ms\": 36620.231}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.73, \"learn_time_ms\": 36671.165}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.65, \"learn_time_ms\": 36677.184}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.18, \"learn_time_ms\": 36630.961}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.29, \"learn_time_ms\": 36684.484}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.42, \"learn_time_ms\": 36646.268}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.05, \"learn_time_ms\": 36684.859}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.12, \"learn_time_ms\": 36650.007}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.45, \"learn_time_ms\": 36679.317}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.34, \"learn_time_ms\": 36689.666}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.44, \"learn_time_ms\": 36711.125}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.42, \"learn_time_ms\": 36678.391}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.48, \"learn_time_ms\": 36701.082}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.47, \"learn_time_ms\": 36723.222}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.69, \"learn_time_ms\": 36664.575}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.37, \"learn_time_ms\": 36666.372}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.0, \"learn_time_ms\": 36663.324}", "{\"n\": 382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.07, \"learn_time_ms\": 36657.866}", "{\"n\": 383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.15, \"learn_time_ms\": 36620.142}", "{\"n\": 384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.07, \"learn_time_ms\": 36625.26}", "{\"n\": 385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.85, \"learn_time_ms\": 36588.548}", "{\"n\": 386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.7, \"learn_time_ms\": 36612.784}", "{\"n\": 387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1023.99, \"learn_time_ms\": 36594.399}", "{\"n\": 388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.14, \"learn_time_ms\": 36584.852}", "{\"n\": 389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.08, \"learn_time_ms\": 36619.597}", "{\"n\": 390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.17, \"learn_time_ms\": 36658.528}", "{\"n\": 391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1023.84, \"learn_time_ms\": 36619.231}", "{\"n\": 392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1023.66, \"learn_time_ms\": 36661.915}", "{\"n\": 393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1023.53, \"learn_time_ms\": 36678.198}", "{\"n\": 394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1022.99, \"learn_time_ms\": 36665.962}", "{\"n\": 395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1022.9, \"learn_time_ms\": 36686.885}", "{\"n\": 396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1022.29, \"learn_time_ms\": 36674.07}", "{\"n\": 397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1022.22, \"learn_time_ms\": 36679.295}", "{\"n\": 398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1021.09, \"learn_time_ms\": 36679.871}", "{\"n\": 399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1021.09, \"learn_time_ms\": 36683.196}", "{\"n\": 400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1020.8, \"learn_time_ms\": 36659.928}", "{\"n\": 401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1020.76, \"learn_time_ms\": 36693.281}", "{\"n\": 402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1020.8, \"learn_time_ms\": 36680.153}", "{\"n\": 403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1021.43, \"learn_time_ms\": 36662.247}", "{\"n\": 404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1021.29, \"learn_time_ms\": 36696.055}", "{\"n\": 405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1022.03, \"learn_time_ms\": 36704.145}", "{\"n\": 406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1022.0, \"learn_time_ms\": 36684.913}", "{\"n\": 407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1022.03, \"learn_time_ms\": 36679.484}", "{\"n\": 408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.63, \"learn_time_ms\": 36695.432}", "{\"n\": 409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 36666.181}", "{\"n\": 410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.53, \"learn_time_ms\": 36681.687}", "{\"n\": 411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 36694.898}", "{\"n\": 412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.71, \"learn_time_ms\": 36699.097}", "{\"n\": 413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 36678.512}", "{\"n\": 414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.67, \"learn_time_ms\": 36708.664}", "{\"n\": 415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 36678.257}", "{\"n\": 416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.89, \"learn_time_ms\": 36702.227}", "{\"n\": 417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.9, \"learn_time_ms\": 36736.174}", "{\"n\": 418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.6, \"learn_time_ms\": 36725.147}", "{\"n\": 419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.86, \"learn_time_ms\": 36723.525}", "{\"n\": 420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.39, \"learn_time_ms\": 36680.82}", "{\"n\": 421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.32, \"learn_time_ms\": 36675.609}", "{\"n\": 422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.29, \"learn_time_ms\": 36701.813}", "{\"n\": 423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.15, \"learn_time_ms\": 36707.863}", "{\"n\": 424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.25, \"learn_time_ms\": 36672.974}", "{\"n\": 425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.04, \"learn_time_ms\": 36674.191}", "{\"n\": 426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.12, \"learn_time_ms\": 36678.401}", "{\"n\": 427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.03, \"learn_time_ms\": 36711.253}", "{\"n\": 428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.0, \"learn_time_ms\": 36752.008}", "{\"n\": 429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.45, \"learn_time_ms\": 36751.069}", "{\"n\": 430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1032.91, \"learn_time_ms\": 36801.036}", "{\"n\": 431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.94, \"learn_time_ms\": 36763.952}", "{\"n\": 432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.37, \"learn_time_ms\": 36744.146}", "{\"n\": 433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.29, \"learn_time_ms\": 36781.231}", "{\"n\": 434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.88, \"learn_time_ms\": 36750.573}", "{\"n\": 435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.74, \"learn_time_ms\": 36772.372}", "{\"n\": 436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.64, \"learn_time_ms\": 36791.555}", "{\"n\": 437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.42, \"learn_time_ms\": 36745.646}", "{\"n\": 438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1036.42, \"learn_time_ms\": 36748.079}", "{\"n\": 439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1036.7, \"learn_time_ms\": 36758.945}", "{\"n\": 440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.56, \"learn_time_ms\": 36775.213}", "{\"n\": 441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1038.08, \"learn_time_ms\": 36768.706}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1038.64, \"learn_time_ms\": 36770.219}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1039.95, \"learn_time_ms\": 36763.098}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1038.9, \"learn_time_ms\": 36773.515}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1039.19, \"learn_time_ms\": 36743.731}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1039.2, \"learn_time_ms\": 36713.668}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1039.0, \"learn_time_ms\": 36699.598}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1039.13, \"learn_time_ms\": 36685.642}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1038.27, \"learn_time_ms\": 36672.944}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.0, \"learn_time_ms\": 36627.332}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.08, \"learn_time_ms\": 36662.549}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.32, \"learn_time_ms\": 36662.4}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.63, \"learn_time_ms\": 36641.37}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.71, \"learn_time_ms\": 36665.773}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.43, \"learn_time_ms\": 36677.216}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.58, \"learn_time_ms\": 36677.798}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.9, \"learn_time_ms\": 36667.353}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.28, \"learn_time_ms\": 36671.451}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.47, \"learn_time_ms\": 36680.058}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1038.13, \"learn_time_ms\": 36701.19}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1038.15, \"learn_time_ms\": 36702.866}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.94, \"learn_time_ms\": 36692.154}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.01, \"learn_time_ms\": 36691.428}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.76, \"learn_time_ms\": 36720.178}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.43, \"learn_time_ms\": 36749.997}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.35, \"learn_time_ms\": 36754.632}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.37, \"learn_time_ms\": 36770.326}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.87, \"learn_time_ms\": 36780.007}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.88, \"learn_time_ms\": 36803.452}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.59, \"learn_time_ms\": 36800.24}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.9, \"learn_time_ms\": 36794.486}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1038.09, \"learn_time_ms\": 36774.043}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.5, \"learn_time_ms\": 36805.309}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1038.51, \"learn_time_ms\": 36742.183}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1038.76, \"learn_time_ms\": 36744.341}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1037.71, \"learn_time_ms\": 36719.824}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1035.67, \"learn_time_ms\": 36744.731}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.26, \"learn_time_ms\": 36733.666}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1034.03, \"learn_time_ms\": 36710.866}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1033.73, \"learn_time_ms\": 36694.435}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.38, \"learn_time_ms\": 36696.384}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.89, \"learn_time_ms\": 36710.638}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.98, \"learn_time_ms\": 36671.165}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.38, \"learn_time_ms\": 36738.319}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.91, \"learn_time_ms\": 36705.519}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1029.59, \"learn_time_ms\": 36693.516}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.82, \"learn_time_ms\": 36655.983}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.36, \"learn_time_ms\": 36664.579}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.29, \"learn_time_ms\": 36654.658}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.38, \"learn_time_ms\": 36661.632}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.53, \"learn_time_ms\": 36658.434}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.73, \"learn_time_ms\": 36638.842}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.5, \"learn_time_ms\": 36670.942}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.23, \"learn_time_ms\": 36616.949}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.35, \"learn_time_ms\": 36645.488}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.85, \"learn_time_ms\": 36679.784}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1026.64, \"learn_time_ms\": 36685.966}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.3, \"learn_time_ms\": 36673.333}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.73, \"learn_time_ms\": 36709.137}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.21, \"learn_time_ms\": 36709.527}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.67, \"learn_time_ms\": 36723.637}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.71, \"learn_time_ms\": 36752.418}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.45, \"learn_time_ms\": 36736.537}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.62, \"learn_time_ms\": 36751.302}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.74, \"learn_time_ms\": 36715.216}", "{\"n\": 506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.85, \"learn_time_ms\": 36702.488}", "{\"n\": 507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1043.73, \"learn_time_ms\": 36745.857}", "{\"n\": 508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.88, \"learn_time_ms\": 36715.838}", "{\"n\": 509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.66, \"learn_time_ms\": 36740.647}", "{\"n\": 510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.23, \"learn_time_ms\": 36730.168}", "{\"n\": 511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.66, \"learn_time_ms\": 36732.467}", "{\"n\": 512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.85, \"learn_time_ms\": 36703.505}", "{\"n\": 513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.37, \"learn_time_ms\": 36689.072}", "{\"n\": 514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.74, \"learn_time_ms\": 36716.266}", "{\"n\": 515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.43, \"learn_time_ms\": 36775.651}", "{\"n\": 516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.82, \"learn_time_ms\": 36807.39}", "{\"n\": 517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1046.99, \"learn_time_ms\": 36800.185}", "{\"n\": 518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1047.6, \"learn_time_ms\": 36819.866}", "{\"n\": 519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1046.0, \"learn_time_ms\": 36767.016}", "{\"n\": 520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.69, \"learn_time_ms\": 36810.623}", "{\"n\": 521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.99, \"learn_time_ms\": 36782.723}", "{\"n\": 522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.93, \"learn_time_ms\": 36852.38}", "{\"n\": 523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.45, \"learn_time_ms\": 36895.652}", "{\"n\": 524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1044.3, \"learn_time_ms\": 36843.421}", "{\"n\": 525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1042.33, \"learn_time_ms\": 36785.482}", "{\"n\": 526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1043.22, \"learn_time_ms\": 36785.056}", "{\"n\": 527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1043.48, \"learn_time_ms\": 36744.235}", "{\"n\": 528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1040.66, \"learn_time_ms\": 36757.287}", "{\"n\": 529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1040.78, \"learn_time_ms\": 36764.679}", "{\"n\": 530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1044.86, \"learn_time_ms\": 36739.817}", "{\"n\": 531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1046.14, \"learn_time_ms\": 36772.637}", "{\"n\": 532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1045.06, \"learn_time_ms\": 36703.595}", "{\"n\": 533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1045.02, \"learn_time_ms\": 36701.045}", "{\"n\": 534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1045.07, \"learn_time_ms\": 36694.927}", "{\"n\": 535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1044.74, \"learn_time_ms\": 36712.912}", "{\"n\": 536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1045.68, \"learn_time_ms\": 36675.218}", "{\"n\": 537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1049.95, \"learn_time_ms\": 36670.866}", "{\"n\": 538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1049.96, \"learn_time_ms\": 36647.236}", "{\"n\": 539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1050.75, \"learn_time_ms\": 36641.176}", "{\"n\": 540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1049.67, \"learn_time_ms\": 36667.763}", "{\"n\": 541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1050.28, \"learn_time_ms\": 36622.921}", "{\"n\": 542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1050.04, \"learn_time_ms\": 36636.075}", "{\"n\": 543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1048.24, \"learn_time_ms\": 36621.759}", "{\"n\": 544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1051.31, \"learn_time_ms\": 36642.661}", "{\"n\": 545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1051.94, \"learn_time_ms\": 36662.087}", "{\"n\": 546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1046.45, \"learn_time_ms\": 36662.789}", "{\"n\": 547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.94, \"learn_time_ms\": 36705.95}", "{\"n\": 548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1044.86, \"learn_time_ms\": 36693.682}", "{\"n\": 549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1046.73, \"learn_time_ms\": 36725.131}", "{\"n\": 550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1049.26, \"learn_time_ms\": 36668.825}", "{\"n\": 551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1046.08, \"learn_time_ms\": 36684.71}", "{\"n\": 552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1047.0, \"learn_time_ms\": 36690.871}", "{\"n\": 553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.84, \"learn_time_ms\": 36698.881}", "{\"n\": 554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.35, \"learn_time_ms\": 36698.488}", "{\"n\": 555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1044.78, \"learn_time_ms\": 36690.901}", "{\"n\": 556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.04, \"learn_time_ms\": 36665.929}", "{\"n\": 557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.37, \"learn_time_ms\": 36647.734}", "{\"n\": 558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.42, \"learn_time_ms\": 36655.985}", "{\"n\": 559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1039.3, \"learn_time_ms\": 36618.987}", "{\"n\": 560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.01, \"learn_time_ms\": 36685.216}", "{\"n\": 561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.4, \"learn_time_ms\": 36643.977}", "{\"n\": 562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1043.8, \"learn_time_ms\": 36612.185}", "{\"n\": 563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1044.62, \"learn_time_ms\": 36591.437}", "{\"n\": 564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1046.77, \"learn_time_ms\": 36579.89}", "{\"n\": 565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.59, \"learn_time_ms\": 36530.497}", "{\"n\": 566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.35, \"learn_time_ms\": 36552.518}", "{\"n\": 567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.22, \"learn_time_ms\": 36544.327}", "{\"n\": 568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.15, \"learn_time_ms\": 36565.734}", "{\"n\": 569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.63, \"learn_time_ms\": 36572.339}", "{\"n\": 570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.7, \"learn_time_ms\": 36563.337}", "{\"n\": 571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.88, \"learn_time_ms\": 36589.874}", "{\"n\": 572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.1, \"learn_time_ms\": 36634.702}", "{\"n\": 573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1049.2, \"learn_time_ms\": 36622.049}", "{\"n\": 574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.85, \"learn_time_ms\": 36641.307}", "{\"n\": 575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1047.77, \"learn_time_ms\": 36654.649}", "{\"n\": 576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.57, \"learn_time_ms\": 36689.931}", "{\"n\": 577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.56, \"learn_time_ms\": 36677.615}", "{\"n\": 578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1051.62, \"learn_time_ms\": 36685.237}", "{\"n\": 579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.86, \"learn_time_ms\": 36665.84}", "{\"n\": 580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.76, \"learn_time_ms\": 36615.606}", "{\"n\": 581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1051.77, \"learn_time_ms\": 36643.338}", "{\"n\": 582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.52, \"learn_time_ms\": 36630.81}", "{\"n\": 583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.85, \"learn_time_ms\": 36645.601}", "{\"n\": 584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.6, \"learn_time_ms\": 36680.078}", "{\"n\": 585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.86, \"learn_time_ms\": 36701.639}", "{\"n\": 586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1051.88, \"learn_time_ms\": 36714.702}", "{\"n\": 587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1056.07, \"learn_time_ms\": 36725.669}", "{\"n\": 588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1058.16, \"learn_time_ms\": 36722.391}", "{\"n\": 589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1061.27, \"learn_time_ms\": 36728.742}", "{\"n\": 590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1062.7, \"learn_time_ms\": 36764.129}", "{\"n\": 591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1060.41, \"learn_time_ms\": 36760.749}", "{\"n\": 592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1062.18, \"learn_time_ms\": 36778.888}", "{\"n\": 593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1060.14, \"learn_time_ms\": 36761.372}", "{\"n\": 594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1060.86, \"learn_time_ms\": 36697.425}", "{\"n\": 595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.17, \"learn_time_ms\": 36702.881}", "{\"n\": 596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1053.56, \"learn_time_ms\": 36644.438}", "{\"n\": 597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1053.59, \"learn_time_ms\": 36633.287}", "{\"n\": 598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1051.32, \"learn_time_ms\": 36637.064}", "{\"n\": 599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1047.64, \"learn_time_ms\": 36689.209}", "{\"n\": 600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1047.1, \"learn_time_ms\": 36690.283}", "{\"n\": 601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1046.74, \"learn_time_ms\": 36703.012}", "{\"n\": 602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1053.98, \"learn_time_ms\": 36674.99}", "{\"n\": 603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1059.94, \"learn_time_ms\": 36713.925}", "{\"n\": 604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1059.86, \"learn_time_ms\": 36738.489}", "{\"n\": 605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1063.49, \"learn_time_ms\": 36717.328}", "{\"n\": 606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1063.17, \"learn_time_ms\": 36765.805}", "{\"n\": 607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1060.22, \"learn_time_ms\": 36796.861}", "{\"n\": 608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1060.9, \"learn_time_ms\": 36752.847}", "{\"n\": 609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1056.04, \"learn_time_ms\": 36735.702}", "{\"n\": 610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1055.37, \"learn_time_ms\": 36704.46}", "{\"n\": 611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1053.23, \"learn_time_ms\": 36672.034}", "{\"n\": 612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1054.03, \"learn_time_ms\": 36682.411}", "{\"n\": 613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1057.83, \"learn_time_ms\": 36683.878}", "{\"n\": 614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1062.21, \"learn_time_ms\": 36653.221}", "{\"n\": 615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1068.09, \"learn_time_ms\": 36706.536}", "{\"n\": 616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1070.0, \"learn_time_ms\": 36699.189}", "{\"n\": 617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1070.54, \"learn_time_ms\": 36646.988}", "{\"n\": 618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1071.37, \"learn_time_ms\": 36651.57}", "{\"n\": 619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1073.5, \"learn_time_ms\": 36658.94}", "{\"n\": 620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1073.02, \"learn_time_ms\": 36692.905}", "{\"n\": 621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1073.44, \"learn_time_ms\": 36676.739}", "{\"n\": 622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1075.43, \"learn_time_ms\": 36645.712}", "{\"n\": 623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1069.9, \"learn_time_ms\": 36596.019}", "{\"n\": 624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1067.79, \"learn_time_ms\": 36644.496}", "{\"n\": 625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.6, \"learn_time_ms\": 36639.269}", "{\"n\": 626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.26, \"learn_time_ms\": 36584.837}", "{\"n\": 627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.6, \"learn_time_ms\": 36646.939}", "{\"n\": 628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.89, \"learn_time_ms\": 36680.588}", "{\"n\": 629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1059.42, \"learn_time_ms\": 36646.54}", "{\"n\": 630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.19, \"learn_time_ms\": 36627.783}", "{\"n\": 631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.48, \"learn_time_ms\": 36633.047}", "{\"n\": 632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1063.64, \"learn_time_ms\": 36663.064}", "{\"n\": 633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.22, \"learn_time_ms\": 36711.983}", "{\"n\": 634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1059.96, \"learn_time_ms\": 36684.588}", "{\"n\": 635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.15, \"learn_time_ms\": 36648.484}", "{\"n\": 636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.8, \"learn_time_ms\": 36720.311}", "{\"n\": 637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.37, \"learn_time_ms\": 36684.776}", "{\"n\": 638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.54, \"learn_time_ms\": 36671.134}", "{\"n\": 639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1046.49, \"learn_time_ms\": 36682.016}", "{\"n\": 640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1046.09, \"learn_time_ms\": 36656.274}", "{\"n\": 641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1046.92, \"learn_time_ms\": 36686.213}", "{\"n\": 642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.47, \"learn_time_ms\": 36674.797}", "{\"n\": 643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1048.41, \"learn_time_ms\": 36675.614}", "{\"n\": 644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.24, \"learn_time_ms\": 36669.267}", "{\"n\": 645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1049.99, \"learn_time_ms\": 36694.183}", "{\"n\": 646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.39, \"learn_time_ms\": 36626.945}", "{\"n\": 647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1051.99, \"learn_time_ms\": 36627.798}", "{\"n\": 648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1053.6, \"learn_time_ms\": 36642.494}", "{\"n\": 649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1059.05, \"learn_time_ms\": 36612.013}", "{\"n\": 650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1061.7, \"learn_time_ms\": 36671.018}", "{\"n\": 651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1060.17, \"learn_time_ms\": 36627.178}", "{\"n\": 652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1060.27, \"learn_time_ms\": 36653.144}", "{\"n\": 653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1058.05, \"learn_time_ms\": 36607.783}", "{\"n\": 654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1057.23, \"learn_time_ms\": 36650.576}", "{\"n\": 655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1059.73, \"learn_time_ms\": 36614.938}", "{\"n\": 656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1059.74, \"learn_time_ms\": 36623.144}", "{\"n\": 657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1063.14, \"learn_time_ms\": 36660.664}", "{\"n\": 658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1066.71, \"learn_time_ms\": 36629.605}", "{\"n\": 659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1064.59, \"learn_time_ms\": 36673.2}", "{\"n\": 660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1061.81, \"learn_time_ms\": 36616.019}", "{\"n\": 661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1060.47, \"learn_time_ms\": 36619.925}", "{\"n\": 662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1057.28, \"learn_time_ms\": 36618.789}", "{\"n\": 663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1057.02, \"learn_time_ms\": 36620.931}", "{\"n\": 664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1055.74, \"learn_time_ms\": 36597.533}", "{\"n\": 665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.55, \"learn_time_ms\": 36613.255}", "{\"n\": 666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.59, \"learn_time_ms\": 36616.186}", "{\"n\": 667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.75, \"learn_time_ms\": 36625.425}", "{\"n\": 668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1051.7, \"learn_time_ms\": 36620.605}", "{\"n\": 669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1055.21, \"learn_time_ms\": 36618.853}", "{\"n\": 670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1051.36, \"learn_time_ms\": 36623.391}", "{\"n\": 671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.11, \"learn_time_ms\": 36618.538}", "{\"n\": 672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.6, \"learn_time_ms\": 36604.084}", "{\"n\": 673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1053.67, \"learn_time_ms\": 36639.458}", "{\"n\": 674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1059.64, \"learn_time_ms\": 36641.766}", "{\"n\": 675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1059.86, \"learn_time_ms\": 36667.359}", "{\"n\": 676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1057.05, \"learn_time_ms\": 36665.02}", "{\"n\": 677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1058.58, \"learn_time_ms\": 36600.45}", "{\"n\": 678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1061.74, \"learn_time_ms\": 36634.891}", "{\"n\": 679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1062.27, \"learn_time_ms\": 36613.196}", "{\"n\": 680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1062.18, \"learn_time_ms\": 36642.735}", "{\"n\": 681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1061.95, \"learn_time_ms\": 36662.229}", "{\"n\": 682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1059.7, \"learn_time_ms\": 36627.151}", "{\"n\": 683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1061.41, \"learn_time_ms\": 36612.112}", "{\"n\": 684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1062.0, \"learn_time_ms\": 36585.752}", "{\"n\": 685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1062.96, \"learn_time_ms\": 36568.717}", "{\"n\": 686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1062.79, \"learn_time_ms\": 36563.797}", "{\"n\": 687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1064.46, \"learn_time_ms\": 36580.659}", "{\"n\": 688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1064.48, \"learn_time_ms\": 36570.402}", "{\"n\": 689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1063.76, \"learn_time_ms\": 36618.231}", "{\"n\": 690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1061.38, \"learn_time_ms\": 36579.782}", "{\"n\": 691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1064.27, \"learn_time_ms\": 36581.528}", "{\"n\": 692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1060.95, \"learn_time_ms\": 36580.206}", "{\"n\": 693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1060.46, \"learn_time_ms\": 36597.202}", "{\"n\": 694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1059.84, \"learn_time_ms\": 36588.747}", "{\"n\": 695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1057.12, \"learn_time_ms\": 36581.882}", "{\"n\": 696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1053.19, \"learn_time_ms\": 36583.974}", "{\"n\": 697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1056.45, \"learn_time_ms\": 36626.737}", "{\"n\": 698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1055.02, \"learn_time_ms\": 36591.063}", "{\"n\": 699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.18, \"learn_time_ms\": 36541.083}", "{\"n\": 700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.44, \"learn_time_ms\": 36597.753}", "{\"n\": 701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.58, \"learn_time_ms\": 36605.9}", "{\"n\": 702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.32, \"learn_time_ms\": 36614.697}", "{\"n\": 703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.86, \"learn_time_ms\": 36580.639}", "{\"n\": 704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1053.98, \"learn_time_ms\": 36595.741}", "{\"n\": 705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1053.39, \"learn_time_ms\": 36567.258}", "{\"n\": 706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1054.22, \"learn_time_ms\": 36565.894}", "{\"n\": 707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1054.36, \"learn_time_ms\": 36566.156}", "{\"n\": 708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1066.57, \"learn_time_ms\": 36587.981}", "{\"n\": 709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1066.51, \"learn_time_ms\": 36602.785}", "{\"n\": 710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1069.04, \"learn_time_ms\": 36596.237}", "{\"n\": 711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1070.04, \"learn_time_ms\": 36576.943}", "{\"n\": 712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1071.35, \"learn_time_ms\": 36618.51}", "{\"n\": 713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1070.21, \"learn_time_ms\": 36619.322}", "{\"n\": 714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1073.15, \"learn_time_ms\": 36628.771}", "{\"n\": 715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1073.1, \"learn_time_ms\": 36625.185}", "{\"n\": 716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1074.81, \"learn_time_ms\": 36676.104}", "{\"n\": 717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1077.45, \"learn_time_ms\": 36654.122}", "{\"n\": 718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1078.32, \"learn_time_ms\": 36653.788}", "{\"n\": 719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1081.51, \"learn_time_ms\": 36619.676}", "{\"n\": 720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1084.29, \"learn_time_ms\": 36615.387}", "{\"n\": 721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1082.55, \"learn_time_ms\": 36650.788}", "{\"n\": 722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1085.57, \"learn_time_ms\": 36635.475}", "{\"n\": 723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1091.52, \"learn_time_ms\": 36601.086}", "{\"n\": 724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1092.04, \"learn_time_ms\": 36588.361}", "{\"n\": 725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1094.6, \"learn_time_ms\": 36584.644}", "{\"n\": 726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1095.85, \"learn_time_ms\": 36530.771}", "{\"n\": 727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1095.16, \"learn_time_ms\": 36533.228}", "{\"n\": 728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1091.64, \"learn_time_ms\": 36522.685}", "{\"n\": 729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1090.69, \"learn_time_ms\": 36543.178}", "{\"n\": 730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1085.97, \"learn_time_ms\": 36554.462}", "{\"n\": 731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1082.97, \"learn_time_ms\": 36512.516}", "{\"n\": 732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1078.78, \"learn_time_ms\": 36530.35}", "{\"n\": 733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1080.13, \"learn_time_ms\": 36549.453}", "{\"n\": 734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1077.76, \"learn_time_ms\": 36593.809}", "{\"n\": 735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1076.13, \"learn_time_ms\": 36600.459}", "{\"n\": 736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1072.27, \"learn_time_ms\": 36607.45}", "{\"n\": 737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1071.42, \"learn_time_ms\": 36615.683}", "{\"n\": 738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1068.71, \"learn_time_ms\": 36627.438}", "{\"n\": 739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1067.89, \"learn_time_ms\": 36607.571}", "{\"n\": 740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1071.35, \"learn_time_ms\": 36604.377}", "{\"n\": 741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1065.75, \"learn_time_ms\": 36620.496}", "{\"n\": 742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1062.57, \"learn_time_ms\": 36592.355}", "{\"n\": 743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1063.27, \"learn_time_ms\": 36589.515}", "{\"n\": 744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1063.5, \"learn_time_ms\": 36537.201}", "{\"n\": 745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1058.26, \"learn_time_ms\": 36574.994}", "{\"n\": 746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1053.83, \"learn_time_ms\": 36612.072}", "{\"n\": 747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1049.9, \"learn_time_ms\": 36563.939}", "{\"n\": 748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1049.09, \"learn_time_ms\": 36541.937}", "{\"n\": 749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.69, \"learn_time_ms\": 36591.266}", "{\"n\": 750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.47, \"learn_time_ms\": 36536.204}", "{\"n\": 751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.58, \"learn_time_ms\": 36566.373}", "{\"n\": 752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.5, \"learn_time_ms\": 36589.565}", "{\"n\": 753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.91, \"learn_time_ms\": 36612.758}", "{\"n\": 754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.06, \"learn_time_ms\": 36648.964}", "{\"n\": 755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.43, \"learn_time_ms\": 36619.71}", "{\"n\": 756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.14, \"learn_time_ms\": 36577.238}", "{\"n\": 757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.53, \"learn_time_ms\": 36633.022}", "{\"n\": 758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.64, \"learn_time_ms\": 36632.221}", "{\"n\": 759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.21, \"learn_time_ms\": 36628.352}", "{\"n\": 760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.82, \"learn_time_ms\": 36630.295}", "{\"n\": 761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.76, \"learn_time_ms\": 36607.602}", "{\"n\": 762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.34, \"learn_time_ms\": 36624.166}", "{\"n\": 763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1058.69, \"learn_time_ms\": 36658.544}", "{\"n\": 764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.57, \"learn_time_ms\": 36656.38}", "{\"n\": 765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1064.34, \"learn_time_ms\": 36702.61}", "{\"n\": 766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1064.25, \"learn_time_ms\": 36704.725}", "{\"n\": 767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1065.64, \"learn_time_ms\": 36704.354}", "{\"n\": 768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1068.44, \"learn_time_ms\": 36711.474}", "{\"n\": 769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1067.4, \"learn_time_ms\": 36721.344}", "{\"n\": 770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1071.72, \"learn_time_ms\": 36740.645}", "{\"n\": 771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1069.33, \"learn_time_ms\": 36729.182}", "{\"n\": 772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1067.42, \"learn_time_ms\": 36729.02}", "{\"n\": 773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1071.07, \"learn_time_ms\": 36741.034}", "{\"n\": 774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1069.03, \"learn_time_ms\": 36701.862}", "{\"n\": 775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1066.65, \"learn_time_ms\": 36648.856}", "{\"n\": 776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.67, \"learn_time_ms\": 36662.427}", "{\"n\": 777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1064.33, \"learn_time_ms\": 36662.801}", "{\"n\": 778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.95, \"learn_time_ms\": 36688.521}", "{\"n\": 779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.23, \"learn_time_ms\": 36659.922}", "{\"n\": 780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1065.53, \"learn_time_ms\": 36680.239}", "{\"n\": 781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1065.56, \"learn_time_ms\": 36679.325}", "{\"n\": 782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1063.82, \"learn_time_ms\": 36675.079}", "{\"n\": 783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1064.35, \"learn_time_ms\": 36610.213}", "{\"n\": 784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.84, \"learn_time_ms\": 36613.101}", "{\"n\": 785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1064.07, \"learn_time_ms\": 36650.913}", "{\"n\": 786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1061.95, \"learn_time_ms\": 36618.165}", "{\"n\": 787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1061.32, \"learn_time_ms\": 36575.339}", "{\"n\": 788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1065.8, \"learn_time_ms\": 36579.201}", "{\"n\": 789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1065.38, \"learn_time_ms\": 36557.119}", "{\"n\": 790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1066.21, \"learn_time_ms\": 36558.233}", "{\"n\": 791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1070.66, \"learn_time_ms\": 36536.168}", "{\"n\": 792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1069.99, \"learn_time_ms\": 36545.301}", "{\"n\": 793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1074.48, \"learn_time_ms\": 36547.579}", "{\"n\": 794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1074.95, \"learn_time_ms\": 36574.696}", "{\"n\": 795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1083.84, \"learn_time_ms\": 36566.607}", "{\"n\": 796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1080.04, \"learn_time_ms\": 36611.573}", "{\"n\": 797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1082.09, \"learn_time_ms\": 36672.526}", "{\"n\": 798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1086.39, \"learn_time_ms\": 36668.203}", "{\"n\": 799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1090.44, \"learn_time_ms\": 36729.453}", "{\"n\": 800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1089.03, \"learn_time_ms\": 36747.276}", "{\"n\": 801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1090.37, \"learn_time_ms\": 36752.776}", "{\"n\": 802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1093.48, \"learn_time_ms\": 36718.616}", "{\"n\": 803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1093.87, \"learn_time_ms\": 36765.986}", "{\"n\": 804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1098.93, \"learn_time_ms\": 36742.358}", "{\"n\": 805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1105.75, \"learn_time_ms\": 36767.458}", "{\"n\": 806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1107.61, \"learn_time_ms\": 36731.562}", "{\"n\": 807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1109.54, \"learn_time_ms\": 36668.143}", "{\"n\": 808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1111.12, \"learn_time_ms\": 36644.655}", "{\"n\": 809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1105.06, \"learn_time_ms\": 36629.477}", "{\"n\": 810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1105.21, \"learn_time_ms\": 36577.603}", "{\"n\": 811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1105.15, \"learn_time_ms\": 36635.088}", "{\"n\": 812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1105.0, \"learn_time_ms\": 36656.652}", "{\"n\": 813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1101.47, \"learn_time_ms\": 36616.149}", "{\"n\": 814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1100.72, \"learn_time_ms\": 36615.059}", "{\"n\": 815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1101.22, \"learn_time_ms\": 36606.142}", "{\"n\": 816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1104.12, \"learn_time_ms\": 36637.979}", "{\"n\": 817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1101.8, \"learn_time_ms\": 36629.284}", "{\"n\": 818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1100.54, \"learn_time_ms\": 36633.89}", "{\"n\": 819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1099.13, \"learn_time_ms\": 36617.288}", "{\"n\": 820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1104.39, \"learn_time_ms\": 36662.197}", "{\"n\": 821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1103.78, \"learn_time_ms\": 36660.438}", "{\"n\": 822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1104.02, \"learn_time_ms\": 36617.367}", "{\"n\": 823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1104.68, \"learn_time_ms\": 36615.431}", "{\"n\": 824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1105.19, \"learn_time_ms\": 36662.933}", "{\"n\": 825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1103.41, \"learn_time_ms\": 36620.528}", "{\"n\": 826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1109.45, \"learn_time_ms\": 36600.394}", "{\"n\": 827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1104.55, \"learn_time_ms\": 36658.413}", "{\"n\": 828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1107.3, \"learn_time_ms\": 36656.792}", "{\"n\": 829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1107.2, \"learn_time_ms\": 36687.018}", "{\"n\": 830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1107.49, \"learn_time_ms\": 36667.18}", "{\"n\": 831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1109.91, \"learn_time_ms\": 36630.376}", "{\"n\": 832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1109.72, \"learn_time_ms\": 36617.905}", "{\"n\": 833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1111.18, \"learn_time_ms\": 36673.503}", "{\"n\": 834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1116.32, \"learn_time_ms\": 36660.262}", "{\"n\": 835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1117.64, \"learn_time_ms\": 36704.338}", "{\"n\": 836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1115.51, \"learn_time_ms\": 36709.92}", "{\"n\": 837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1118.7, \"learn_time_ms\": 36656.484}", "{\"n\": 838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1118.7, \"learn_time_ms\": 36688.827}", "{\"n\": 839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1114.43, \"learn_time_ms\": 36684.844}", "{\"n\": 840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1114.69, \"learn_time_ms\": 36671.054}", "{\"n\": 841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1109.83, \"learn_time_ms\": 36702.582}", "{\"n\": 842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1105.68, \"learn_time_ms\": 36705.644}", "{\"n\": 843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1104.48, \"learn_time_ms\": 36678.088}", "{\"n\": 844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1106.92, \"learn_time_ms\": 36636.85}", "{\"n\": 845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1110.15, \"learn_time_ms\": 36600.811}", "{\"n\": 846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1116.44, \"learn_time_ms\": 36643.693}", "{\"n\": 847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1115.89, \"learn_time_ms\": 36629.631}", "{\"n\": 848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1113.45, \"learn_time_ms\": 36610.923}", "{\"n\": 849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1108.95, \"learn_time_ms\": 36589.61}", "{\"n\": 850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1114.26, \"learn_time_ms\": 36608.372}", "{\"n\": 851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1108.84, \"learn_time_ms\": 36564.612}", "{\"n\": 852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1108.12, \"learn_time_ms\": 36561.03}", "{\"n\": 853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1108.86, \"learn_time_ms\": 36571.259}", "{\"n\": 854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1109.07, \"learn_time_ms\": 36601.848}", "{\"n\": 855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1113.7, \"learn_time_ms\": 36626.838}", "{\"n\": 856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1110.8, \"learn_time_ms\": 36571.87}", "{\"n\": 857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1109.54, \"learn_time_ms\": 36605.96}", "{\"n\": 858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1111.89, \"learn_time_ms\": 36615.042}", "{\"n\": 859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1113.05, \"learn_time_ms\": 36638.692}", "{\"n\": 860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1118.12, \"learn_time_ms\": 36606.36}", "{\"n\": 861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1114.18, \"learn_time_ms\": 36655.02}", "{\"n\": 862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1113.55, \"learn_time_ms\": 36683.464}", "{\"n\": 863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1115.57, \"learn_time_ms\": 36674.503}", "{\"n\": 864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1115.0, \"learn_time_ms\": 36674.189}", "{\"n\": 865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1114.33, \"learn_time_ms\": 36666.323}", "{\"n\": 866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1121.99, \"learn_time_ms\": 36727.43}", "{\"n\": 867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1121.06, \"learn_time_ms\": 36721.569}", "{\"n\": 868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1120.32, \"learn_time_ms\": 36746.048}", "{\"n\": 869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1121.19, \"learn_time_ms\": 36700.949}", "{\"n\": 870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1122.51, \"learn_time_ms\": 36756.477}", "{\"n\": 871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1122.4, \"learn_time_ms\": 36721.478}", "{\"n\": 872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1120.37, \"learn_time_ms\": 36723.07}", "{\"n\": 873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1115.08, \"learn_time_ms\": 36740.098}", "{\"n\": 874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1119.13, \"learn_time_ms\": 36732.84}", "{\"n\": 875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1119.19, \"learn_time_ms\": 36744.419}", "{\"n\": 876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1119.31, \"learn_time_ms\": 36696.226}", "{\"n\": 877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1117.44, \"learn_time_ms\": 36686.814}", "{\"n\": 878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1114.48, \"learn_time_ms\": 36632.988}", "{\"n\": 879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1113.73, \"learn_time_ms\": 36679.84}", "{\"n\": 880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1116.29, \"learn_time_ms\": 36634.917}", "{\"n\": 881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1122.41, \"learn_time_ms\": 36609.26}", "{\"n\": 882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1123.49, \"learn_time_ms\": 36626.265}", "{\"n\": 883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1121.62, \"learn_time_ms\": 36580.442}", "{\"n\": 884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1121.62, \"learn_time_ms\": 36588.021}", "{\"n\": 885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1131.62, \"learn_time_ms\": 36553.213}", "{\"n\": 886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1127.87, \"learn_time_ms\": 36591.848}", "{\"n\": 887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1137.23, \"learn_time_ms\": 36614.505}", "{\"n\": 888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1144.08, \"learn_time_ms\": 36617.862}", "{\"n\": 889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1132.87, \"learn_time_ms\": 36627.051}", "{\"n\": 890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1136.58, \"learn_time_ms\": 36627.476}", "{\"n\": 891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1139.85, \"learn_time_ms\": 36626.683}", "{\"n\": 892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1138.85, \"learn_time_ms\": 36603.849}", "{\"n\": 893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1137.72, \"learn_time_ms\": 36637.711}", "{\"n\": 894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1141.18, \"learn_time_ms\": 36634.497}", "{\"n\": 895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1144.57, \"learn_time_ms\": 36673.489}", "{\"n\": 896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1145.24, \"learn_time_ms\": 36643.738}", "{\"n\": 897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1155.98, \"learn_time_ms\": 36619.206}", "{\"n\": 898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1155.65, \"learn_time_ms\": 36650.405}", "{\"n\": 899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1157.82, \"learn_time_ms\": 36571.625}", "{\"n\": 900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1162.04, \"learn_time_ms\": 36551.308}", "{\"n\": 901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1167.5, \"learn_time_ms\": 36613.317}", "{\"n\": 902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1181.03, \"learn_time_ms\": 36607.478}", "{\"n\": 903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1184.45, \"learn_time_ms\": 36552.121}", "{\"n\": 904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1180.19, \"learn_time_ms\": 36569.184}", "{\"n\": 905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1183.59, \"learn_time_ms\": 36538.45}", "{\"n\": 906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1181.42, \"learn_time_ms\": 36581.834}", "{\"n\": 907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1181.47, \"learn_time_ms\": 36590.16}", "{\"n\": 908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1187.04, \"learn_time_ms\": 36554.972}", "{\"n\": 909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1185.84, \"learn_time_ms\": 36615.97}", "{\"n\": 910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1188.86, \"learn_time_ms\": 36689.336}", "{\"n\": 911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1182.54, \"learn_time_ms\": 36642.62}", "{\"n\": 912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1182.31, \"learn_time_ms\": 36648.773}", "{\"n\": 913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1184.57, \"learn_time_ms\": 36723.071}", "{\"n\": 914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1185.82, \"learn_time_ms\": 36679.35}", "{\"n\": 915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.38, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1185.09, \"learn_time_ms\": 36714.158}", "{\"n\": 916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1189.64, \"learn_time_ms\": 36648.674}", "{\"n\": 917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1183.98, \"learn_time_ms\": 36647.899}", "{\"n\": 918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.35, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1194.42, \"learn_time_ms\": 36656.341}", "{\"n\": 919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1199.17, \"learn_time_ms\": 36639.671}", "{\"n\": 920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1200.7, \"learn_time_ms\": 36594.367}", "{\"n\": 921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1202.4, \"learn_time_ms\": 36596.199}", "{\"n\": 922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1201.17, \"learn_time_ms\": 36614.906}", "{\"n\": 923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1203.86, \"learn_time_ms\": 36565.43}", "{\"n\": 924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.38, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1209.41, \"learn_time_ms\": 36581.243}", "{\"n\": 925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1213.39, \"learn_time_ms\": 36582.725}", "{\"n\": 926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1210.1, \"learn_time_ms\": 36593.833}", "{\"n\": 927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1200.4, \"learn_time_ms\": 36586.825}", "{\"n\": 928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1202.08, \"learn_time_ms\": 36614.46}", "{\"n\": 929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1214.58, \"learn_time_ms\": 36597.577}", "{\"n\": 930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1210.47, \"learn_time_ms\": 36601.37}", "{\"n\": 931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.32, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1224.25, \"learn_time_ms\": 36598.313}", "{\"n\": 932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.32, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1220.6, \"learn_time_ms\": 36607.93}", "{\"n\": 933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.31, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1224.25, \"learn_time_ms\": 36601.3}", "{\"n\": 934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.29, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1230.61, \"learn_time_ms\": 36596.805}", "{\"n\": 935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.32, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1228.57, \"learn_time_ms\": 36566.177}", "{\"n\": 936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1239.32, \"learn_time_ms\": 36620.865}", "{\"n\": 937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1246.52, \"learn_time_ms\": 36632.221}", "{\"n\": 938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1250.77, \"learn_time_ms\": 36604.989}", "{\"n\": 939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1253.45, \"learn_time_ms\": 36643.799}", "{\"n\": 940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1264.35, \"learn_time_ms\": 36645.105}", "{\"n\": 941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1264.35, \"learn_time_ms\": 36671.445}", "{\"n\": 942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1266.88, \"learn_time_ms\": 36648.22}", "{\"n\": 943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1269.11, \"learn_time_ms\": 36658.261}", "{\"n\": 944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.08, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1277.76, \"learn_time_ms\": 36698.704}", "{\"n\": 945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.06, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1282.1, \"learn_time_ms\": 36668.385}", "{\"n\": 946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.07, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1280.2, \"learn_time_ms\": 36619.035}", "{\"n\": 947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.04, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1283.22, \"learn_time_ms\": 36638.716}", "{\"n\": 948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1287.28, \"learn_time_ms\": 36676.034}", "{\"n\": 949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.99, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1290.49, \"learn_time_ms\": 36655.533}", "{\"n\": 950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.97, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1289.61, \"learn_time_ms\": 36643.431}", "{\"n\": 951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1293.65, \"learn_time_ms\": 36626.131}", "{\"n\": 952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1293.26, \"learn_time_ms\": 36667.833}", "{\"n\": 953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1297.07, \"learn_time_ms\": 36673.519}", "{\"n\": 954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1308.72, \"learn_time_ms\": 36656.699}", "{\"n\": 955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1309.79, \"learn_time_ms\": 36680.389}", "{\"n\": 956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1307.49, \"learn_time_ms\": 36724.33}", "{\"n\": 957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1301.73, \"learn_time_ms\": 36698.004}", "{\"n\": 958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.92, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1300.44, \"learn_time_ms\": 36641.745}", "{\"n\": 959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1298.82, \"learn_time_ms\": 36652.646}", "{\"n\": 960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1295.41, \"learn_time_ms\": 36654.705}", "{\"n\": 961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1300.12, \"learn_time_ms\": 36666.085}", "{\"n\": 962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.85, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1302.2, \"learn_time_ms\": 36607.083}", "{\"n\": 963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.83, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1304.67, \"learn_time_ms\": 36645.505}", "{\"n\": 964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1306.97, \"learn_time_ms\": 36616.303}", "{\"n\": 965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1307.09, \"learn_time_ms\": 36677.187}", "{\"n\": 966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.83, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1314.33, \"learn_time_ms\": 36639.421}", "{\"n\": 967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1314.29, \"learn_time_ms\": 36641.576}", "{\"n\": 968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1316.94, \"learn_time_ms\": 36676.488}", "{\"n\": 969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1314.46, \"learn_time_ms\": 36657.601}", "{\"n\": 970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1318.56, \"learn_time_ms\": 36663.994}", "{\"n\": 971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1312.22, \"learn_time_ms\": 36695.75}", "{\"n\": 972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1311.61, \"learn_time_ms\": 36736.399}", "{\"n\": 973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.9, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1313.2, \"learn_time_ms\": 36681.087}", "{\"n\": 974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.9, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1313.85, \"learn_time_ms\": 36725.745}", "{\"n\": 975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1313.24, \"learn_time_ms\": 36669.415}", "{\"n\": 976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.94, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1309.71, \"learn_time_ms\": 36655.453}", "{\"n\": 977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1316.77, \"learn_time_ms\": 36706.006}", "{\"n\": 978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1317.11, \"learn_time_ms\": 36689.356}", "{\"n\": 979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1316.52, \"learn_time_ms\": 36684.626}", "{\"n\": 980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1321.97, \"learn_time_ms\": 36677.309}", "{\"n\": 981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1319.28, \"learn_time_ms\": 36637.344}", "{\"n\": 982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1316.74, \"learn_time_ms\": 36659.457}", "{\"n\": 983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1326.82, \"learn_time_ms\": 36667.645}", "{\"n\": 984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.83, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1327.51, \"learn_time_ms\": 36636.438}", "{\"n\": 985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1339.53, \"learn_time_ms\": 36669.334}", "{\"n\": 986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1336.99, \"learn_time_ms\": 36680.414}", "{\"n\": 987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1348.38, \"learn_time_ms\": 36626.052}", "{\"n\": 988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1348.99, \"learn_time_ms\": 36660.124}", "{\"n\": 989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.82, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1341.87, \"learn_time_ms\": 36630.852}", "{\"n\": 990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1339.57, \"learn_time_ms\": 36626.09}", "{\"n\": 991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1336.18, \"learn_time_ms\": 36621.107}", "{\"n\": 992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1343.72, \"learn_time_ms\": 36602.022}", "{\"n\": 993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1340.86, \"learn_time_ms\": 36622.93}", "{\"n\": 994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.79, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1347.29, \"learn_time_ms\": 36635.12}", "{\"n\": 995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1345.59, \"learn_time_ms\": 36587.832}", "{\"n\": 996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1354.54, \"learn_time_ms\": 36614.899}", "{\"n\": 997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.79, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1355.43, \"learn_time_ms\": 36623.705}", "{\"n\": 998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.81, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1354.26, \"learn_time_ms\": 36627.303}", "{\"n\": 999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1357.35, \"learn_time_ms\": 36655.978}", "{\"n\": 1000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1360.56, \"learn_time_ms\": 36708.131}"]["{\"n\": 1001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 39195.478}", "{\"n\": 1002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 37985.613}", "{\"n\": 1003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 37351.617}", "{\"n\": 1004, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1251.0, \"learn_time_ms\": 37102.563}", "{\"n\": 1005, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1334.0, \"learn_time_ms\": 36867.822}", "{\"n\": 1006, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11111111111111, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1328.5555555555557, \"learn_time_ms\": 36755.318}", "{\"n\": 1007, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1351.0, \"learn_time_ms\": 36670.185}", "{\"n\": 1008, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.75, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1387.5625, \"learn_time_ms\": 36586.159}", "{\"n\": 1009, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.833333333333332, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1385.4444444444443, \"learn_time_ms\": 36501.855}", "{\"n\": 1010, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91304347826087, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1392.7391304347825, \"learn_time_ms\": 36456.26}", "{\"n\": 1011, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.846153846153847, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1397.1153846153845, \"learn_time_ms\": 36156.727}", "{\"n\": 1012, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1420.5666666666666, \"learn_time_ms\": 36044.781}", "{\"n\": 1013, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78787878787879, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1422.3030303030303, \"learn_time_ms\": 36047.533}", "{\"n\": 1014, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.82857142857143, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1409.1714285714286, \"learn_time_ms\": 35994.063}", "{\"n\": 1015, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.804878048780488, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1410.341463414634, \"learn_time_ms\": 36004.012}", "{\"n\": 1016, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.790697674418606, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1409.3255813953488, \"learn_time_ms\": 35957.144}", "{\"n\": 1017, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.82608695652174, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1402.8478260869565, \"learn_time_ms\": 35904.089}", "{\"n\": 1018, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1399.34, \"learn_time_ms\": 35862.322}", "{\"n\": 1019, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.90566037735849, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1395.5849056603774, \"learn_time_ms\": 35857.584}", "{\"n\": 1020, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.912280701754387, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1404.859649122807, \"learn_time_ms\": 35835.163}", "{\"n\": 1021, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89830508474576, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1409.593220338983, \"learn_time_ms\": 35802.36}", "{\"n\": 1022, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.90625, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1406.640625, \"learn_time_ms\": 35820.629}", "{\"n\": 1023, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.865671641791046, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1409.5820895522388, \"learn_time_ms\": 35804.122}", "{\"n\": 1024, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84285714285714, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1410.857142857143, \"learn_time_ms\": 35795.707}", "{\"n\": 1025, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.80821917808219, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1415.9041095890411, \"learn_time_ms\": 35757.455}", "{\"n\": 1026, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.805194805194805, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1417.9610389610389, \"learn_time_ms\": 35763.423}", "{\"n\": 1027, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.775, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1424.3875, \"learn_time_ms\": 35762.384}", "{\"n\": 1028, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.771084337349397, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1427.3734939759036, \"learn_time_ms\": 35764.278}", "{\"n\": 1029, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.79310344827586, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1426.4022988505747, \"learn_time_ms\": 35756.622}", "{\"n\": 1030, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.808988764044944, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1421.3595505617977, \"learn_time_ms\": 35768.258}", "{\"n\": 1031, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.763440860215052, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1429.505376344086, \"learn_time_ms\": 35761.639}", "{\"n\": 1032, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.729166666666668, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1433.78125, \"learn_time_ms\": 35769.447}", "{\"n\": 1033, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.73469387755102, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1433.438775510204, \"learn_time_ms\": 35754.359}", "{\"n\": 1034, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.65, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1447.11, \"learn_time_ms\": 35760.43}", "{\"n\": 1035, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.66, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1446.56, \"learn_time_ms\": 35787.473}", "{\"n\": 1036, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.63, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1452.73, \"learn_time_ms\": 35802.767}", "{\"n\": 1037, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.59, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1467.14, \"learn_time_ms\": 35812.792}", "{\"n\": 1038, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.57, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1474.28, \"learn_time_ms\": 35841.906}", "{\"n\": 1039, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.57, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1479.28, \"learn_time_ms\": 35855.539}", "{\"n\": 1040, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.53, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1483.28, \"learn_time_ms\": 35855.448}", "{\"n\": 1041, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.56, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1479.44, \"learn_time_ms\": 35916.572}", "{\"n\": 1042, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1484.17, \"learn_time_ms\": 35922.969}", "{\"n\": 1043, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1477.33, \"learn_time_ms\": 35931.643}", "{\"n\": 1044, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1485.06, \"learn_time_ms\": 35918.11}", "{\"n\": 1045, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1478.93, \"learn_time_ms\": 35920.841}", "{\"n\": 1046, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1476.12, \"learn_time_ms\": 35904.191}", "{\"n\": 1047, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1484.01, \"learn_time_ms\": 35914.189}", "{\"n\": 1048, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1486.15, \"learn_time_ms\": 35883.055}", "{\"n\": 1049, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1484.03, \"learn_time_ms\": 35887.652}", "{\"n\": 1050, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.41, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1493.47, \"learn_time_ms\": 35865.34}", "{\"n\": 1051, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.38, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1493.24, \"learn_time_ms\": 35821.646}", "{\"n\": 1052, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.36, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1498.18, \"learn_time_ms\": 35831.592}", "{\"n\": 1053, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.29, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1509.16, \"learn_time_ms\": 35818.376}", "{\"n\": 1054, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1519.57, \"learn_time_ms\": 35831.767}", "{\"n\": 1055, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1523.3, \"learn_time_ms\": 35845.493}", "{\"n\": 1056, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.26, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1522.16, \"learn_time_ms\": 35863.454}", "{\"n\": 1057, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1520.95, \"learn_time_ms\": 35877.969}", "{\"n\": 1058, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1516.74, \"learn_time_ms\": 35930.03}", "{\"n\": 1059, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1512.2, \"learn_time_ms\": 35923.49}", "{\"n\": 1060, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.29, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1514.97, \"learn_time_ms\": 35915.797}", "{\"n\": 1061, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1517.98, \"learn_time_ms\": 35931.746}", "{\"n\": 1062, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1522.4, \"learn_time_ms\": 35905.081}", "{\"n\": 1063, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1526.88, \"learn_time_ms\": 35908.046}", "{\"n\": 1064, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.2, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1531.58, \"learn_time_ms\": 35897.532}", "{\"n\": 1065, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.2, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1533.14, \"learn_time_ms\": 35899.725}", "{\"n\": 1066, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.24, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1528.09, \"learn_time_ms\": 35909.697}", "{\"n\": 1067, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1526.05, \"learn_time_ms\": 35935.636}", "{\"n\": 1068, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.29, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1521.04, \"learn_time_ms\": 35902.866}", "{\"n\": 1069, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1534.04, \"learn_time_ms\": 35860.041}", "{\"n\": 1070, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1530.02, \"learn_time_ms\": 35883.58}", "{\"n\": 1071, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1530.65, \"learn_time_ms\": 35904.893}", "{\"n\": 1072, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1531.18, \"learn_time_ms\": 35923.354}", "{\"n\": 1073, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1536.99, \"learn_time_ms\": 35952.172}", "{\"n\": 1074, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1538.88, \"learn_time_ms\": 35985.18}", "{\"n\": 1075, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1545.12, \"learn_time_ms\": 36001.514}", "{\"n\": 1076, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1550.83, \"learn_time_ms\": 35964.752}", "{\"n\": 1077, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1555.75, \"learn_time_ms\": 35963.667}", "{\"n\": 1078, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1568.91, \"learn_time_ms\": 35965.596}", "{\"n\": 1079, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.15, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1562.75, \"learn_time_ms\": 36025.239}", "{\"n\": 1080, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1563.87, \"learn_time_ms\": 36056.183}", "{\"n\": 1081, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1561.73, \"learn_time_ms\": 36009.451}", "{\"n\": 1082, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1569.14, \"learn_time_ms\": 35975.263}", "{\"n\": 1083, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1569.14, \"learn_time_ms\": 35963.45}", "{\"n\": 1084, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1573.61, \"learn_time_ms\": 35942.342}", "{\"n\": 1085, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1569.65, \"learn_time_ms\": 35888.83}", "{\"n\": 1086, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.15, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1568.74, \"learn_time_ms\": 35924.481}", "{\"n\": 1087, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1568.06, \"learn_time_ms\": 35891.412}", "{\"n\": 1088, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1567.04, \"learn_time_ms\": 35894.384}", "{\"n\": 1089, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1571.56, \"learn_time_ms\": 35888.754}", "{\"n\": 1090, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1575.9, \"learn_time_ms\": 35883.391}", "{\"n\": 1091, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1575.77, \"learn_time_ms\": 35861.548}", "{\"n\": 1092, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.09, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1580.15, \"learn_time_ms\": 35902.762}", "{\"n\": 1093, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.1, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1580.03, \"learn_time_ms\": 35901.519}", "{\"n\": 1094, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1582.83, \"learn_time_ms\": 35858.207}", "{\"n\": 1095, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1573.21, \"learn_time_ms\": 35901.909}", "{\"n\": 1096, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1575.92, \"learn_time_ms\": 35865.836}", "{\"n\": 1097, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1573.71, \"learn_time_ms\": 35851.328}", "{\"n\": 1098, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1576.06, \"learn_time_ms\": 35875.374}", "{\"n\": 1099, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1578.55, \"learn_time_ms\": 35863.22}", "{\"n\": 1100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1582.84, \"learn_time_ms\": 35776.873}", "{\"n\": 1101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1581.3, \"learn_time_ms\": 35804.955}", "{\"n\": 1102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1570.76, \"learn_time_ms\": 35806.516}", "{\"n\": 1103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1568.04, \"learn_time_ms\": 35813.27}", "{\"n\": 1104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.15, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1577.66, \"learn_time_ms\": 35834.719}", "{\"n\": 1105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1580.15, \"learn_time_ms\": 35816.91}", "{\"n\": 1106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1588.81, \"learn_time_ms\": 35848.983}", "{\"n\": 1107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.1, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1595.56, \"learn_time_ms\": 35873.237}", "{\"n\": 1108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1589.65, \"learn_time_ms\": 35834.556}", "{\"n\": 1109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1594.56, \"learn_time_ms\": 35831.825}", "{\"n\": 1110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1590.44, \"learn_time_ms\": 35904.04}", "{\"n\": 1111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.1, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1595.07, \"learn_time_ms\": 35933.436}", "{\"n\": 1112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1593.02, \"learn_time_ms\": 35884.167}", "{\"n\": 1113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.1, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1594.26, \"learn_time_ms\": 35850.669}", "{\"n\": 1114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.06, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1603.72, \"learn_time_ms\": 35893.477}", "{\"n\": 1115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1604.74, \"learn_time_ms\": 35888.031}", "{\"n\": 1116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1602.57, \"learn_time_ms\": 35875.985}", "{\"n\": 1117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1600.34, \"learn_time_ms\": 35858.511}", "{\"n\": 1118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1598.95, \"learn_time_ms\": 35876.076}", "{\"n\": 1119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1598.95, \"learn_time_ms\": 35860.907}", "{\"n\": 1120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1611.74, \"learn_time_ms\": 35793.701}", "{\"n\": 1121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1612.71, \"learn_time_ms\": 35755.285}", "{\"n\": 1122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1614.98, \"learn_time_ms\": 35813.979}", "{\"n\": 1123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1617.27, \"learn_time_ms\": 35827.295}", "{\"n\": 1124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1617.27, \"learn_time_ms\": 35804.508}", "{\"n\": 1125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1619.46, \"learn_time_ms\": 35814.911}", "{\"n\": 1126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1620.49, \"learn_time_ms\": 35831.967}", "{\"n\": 1127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1620.08, \"learn_time_ms\": 35836.441}", "{\"n\": 1128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1628.98, \"learn_time_ms\": 35870.974}", "{\"n\": 1129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1633.66, \"learn_time_ms\": 35887.262}", "{\"n\": 1130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1631.56, \"learn_time_ms\": 35915.633}", "{\"n\": 1131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1630.23, \"learn_time_ms\": 35907.271}", "{\"n\": 1132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1634.62, \"learn_time_ms\": 35863.486}", "{\"n\": 1133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1635.87, \"learn_time_ms\": 35862.663}", "{\"n\": 1134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1642.04, \"learn_time_ms\": 35856.799}", "{\"n\": 1135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1647.18, \"learn_time_ms\": 35825.473}", "{\"n\": 1136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1648.15, \"learn_time_ms\": 35815.318}", "{\"n\": 1137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1658.9, \"learn_time_ms\": 35823.772}", "{\"n\": 1138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1661.26, \"learn_time_ms\": 35805.091}", "{\"n\": 1139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1666.66, \"learn_time_ms\": 35816.166}", "{\"n\": 1140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1669.44, \"learn_time_ms\": 35856.553}", "{\"n\": 1141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1669.03, \"learn_time_ms\": 35847.376}", "{\"n\": 1142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1665.7, \"learn_time_ms\": 35855.353}", "{\"n\": 1143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.64, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1672.41, \"learn_time_ms\": 35827.716}", "{\"n\": 1144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1680.63, \"learn_time_ms\": 35854.327}", "{\"n\": 1145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.53, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1687.91, \"learn_time_ms\": 35852.191}", "{\"n\": 1146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.53, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1687.91, \"learn_time_ms\": 35874.997}", "{\"n\": 1147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.52, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1694.43, \"learn_time_ms\": 35889.995}", "{\"n\": 1148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.52, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1697.81, \"learn_time_ms\": 35839.163}", "{\"n\": 1149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.54, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1701.75, \"learn_time_ms\": 35821.269}", "{\"n\": 1150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.53, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1703.94, \"learn_time_ms\": 35842.832}", "{\"n\": 1151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1715.26, \"learn_time_ms\": 35847.891}", "{\"n\": 1152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1731.45, \"learn_time_ms\": 35892.309}", "{\"n\": 1153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.4, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1736.9, \"learn_time_ms\": 35928.028}", "{\"n\": 1154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1737.34, \"learn_time_ms\": 35951.367}", "{\"n\": 1155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1739.07, \"learn_time_ms\": 36001.184}", "{\"n\": 1156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.35, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1743.6, \"learn_time_ms\": 35982.414}", "{\"n\": 1157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1741.39, \"learn_time_ms\": 36015.726}", "{\"n\": 1158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.32, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1751.53, \"learn_time_ms\": 36070.491}", "{\"n\": 1159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.35, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1745.64, \"learn_time_ms\": 36089.136}", "{\"n\": 1160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1759.66, \"learn_time_ms\": 36029.458}", "{\"n\": 1161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1777.92, \"learn_time_ms\": 36015.494}", "{\"n\": 1162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1777.58, \"learn_time_ms\": 35975.425}", "{\"n\": 1163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1789.6, \"learn_time_ms\": 36007.225}", "{\"n\": 1164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1805.93, \"learn_time_ms\": 35992.12}", "{\"n\": 1165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1812.09, \"learn_time_ms\": 35963.232}", "{\"n\": 1166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1807.06, \"learn_time_ms\": 35967.397}", "{\"n\": 1167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1808.78, \"learn_time_ms\": 35937.227}", "{\"n\": 1168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1810.33, \"learn_time_ms\": 35900.393}", "{\"n\": 1169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1815.88, \"learn_time_ms\": 35935.03}", "{\"n\": 1170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1828.06, \"learn_time_ms\": 35964.383}", "{\"n\": 1171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1832.77, \"learn_time_ms\": 36013.306}", "{\"n\": 1172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1839.17, \"learn_time_ms\": 36033.001}", "{\"n\": 1173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.77, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1858.23, \"learn_time_ms\": 36013.553}", "{\"n\": 1174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.77, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1858.23, \"learn_time_ms\": 36002.66}", "{\"n\": 1175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.71, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1863.42, \"learn_time_ms\": 36012.253}", "{\"n\": 1176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.76, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1855.63, \"learn_time_ms\": 35971.647}", "{\"n\": 1177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1850.73, \"learn_time_ms\": 35980.077}", "{\"n\": 1178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.82, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1847.74, \"learn_time_ms\": 36029.829}", "{\"n\": 1179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1842.93, \"learn_time_ms\": 36001.82}", "{\"n\": 1180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1843.57, \"learn_time_ms\": 36020.424}", "{\"n\": 1181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.88, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1852.83, \"learn_time_ms\": 36002.062}", "{\"n\": 1182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1847.31, \"learn_time_ms\": 35997.974}", "{\"n\": 1183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1854.14, \"learn_time_ms\": 36009.264}", "{\"n\": 1184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.92, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1855.38, \"learn_time_ms\": 36004.195}", "{\"n\": 1185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1860.59, \"learn_time_ms\": 36017.018}", "{\"n\": 1186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1860.59, \"learn_time_ms\": 36010.526}", "{\"n\": 1187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.82, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1865.37, \"learn_time_ms\": 35994.653}", "{\"n\": 1188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1873.8, \"learn_time_ms\": 36016.158}", "{\"n\": 1189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.77, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1881.12, \"learn_time_ms\": 36053.394}", "{\"n\": 1190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1884.11, \"learn_time_ms\": 36038.039}", "{\"n\": 1191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.73, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1884.9, \"learn_time_ms\": 36047.674}", "{\"n\": 1192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1883.61, \"learn_time_ms\": 36019.783}", "{\"n\": 1193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1888.01, \"learn_time_ms\": 36002.559}", "{\"n\": 1194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1894.89, \"learn_time_ms\": 36059.786}", "{\"n\": 1195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1897.24, \"learn_time_ms\": 36049.385}", "{\"n\": 1196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1902.43, \"learn_time_ms\": 36081.477}", "{\"n\": 1197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1904.21, \"learn_time_ms\": 36077.188}", "{\"n\": 1198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1905.72, \"learn_time_ms\": 36070.286}", "{\"n\": 1199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1905.72, \"learn_time_ms\": 36016.638}", "{\"n\": 1200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.81, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1901.1, \"learn_time_ms\": 35994.458}", "{\"n\": 1201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.78, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1906.65, \"learn_time_ms\": 36032.714}", "{\"n\": 1202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1907.6, \"learn_time_ms\": 36038.171}", "{\"n\": 1203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1910.8, \"learn_time_ms\": 36053.623}", "{\"n\": 1204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1908.71, \"learn_time_ms\": 35974.68}", "{\"n\": 1205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1908.89, \"learn_time_ms\": 35949.186}", "{\"n\": 1206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1911.22, \"learn_time_ms\": 35964.354}", "{\"n\": 1207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1911.35, \"learn_time_ms\": 35961.829}", "{\"n\": 1208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.65, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1920.22, \"learn_time_ms\": 35943.651}", "{\"n\": 1209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1915.06, \"learn_time_ms\": 35989.602}", "{\"n\": 1210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1915.27, \"learn_time_ms\": 36036.128}", "{\"n\": 1211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1913.41, \"learn_time_ms\": 35980.326}", "{\"n\": 1212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1914.28, \"learn_time_ms\": 35987.908}", "{\"n\": 1213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1911.17, \"learn_time_ms\": 36009.181}", "{\"n\": 1214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1914.5, \"learn_time_ms\": 36043.248}", "{\"n\": 1215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.72, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1914.0, \"learn_time_ms\": 36069.721}", "{\"n\": 1216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.72, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1914.0, \"learn_time_ms\": 36052.851}", "{\"n\": 1217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1921.19, \"learn_time_ms\": 36036.348}", "{\"n\": 1218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1930.89, \"learn_time_ms\": 36008.0}", "{\"n\": 1219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.65, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1930.69, \"learn_time_ms\": 35956.425}", "{\"n\": 1220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1939.56, \"learn_time_ms\": 35907.576}", "{\"n\": 1221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1943.21, \"learn_time_ms\": 35909.768}", "{\"n\": 1222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1943.21, \"learn_time_ms\": 35902.318}", "{\"n\": 1223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.52, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1955.55, \"learn_time_ms\": 35856.691}", "{\"n\": 1224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1962.0, \"learn_time_ms\": 35865.701}", "{\"n\": 1225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1962.0, \"learn_time_ms\": 35841.203}", "{\"n\": 1226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1963.6, \"learn_time_ms\": 35877.416}", "{\"n\": 1227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1969.72, \"learn_time_ms\": 35861.757}", "{\"n\": 1228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1966.82, \"learn_time_ms\": 35858.431}", "{\"n\": 1229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1969.45, \"learn_time_ms\": 35907.844}", "{\"n\": 1230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1979.54, \"learn_time_ms\": 35956.775}", "{\"n\": 1231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1980.11, \"learn_time_ms\": 35926.385}", "{\"n\": 1232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1980.11, \"learn_time_ms\": 35946.021}", "{\"n\": 1233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1986.6, \"learn_time_ms\": 35912.855}", "{\"n\": 1234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1988.52, \"learn_time_ms\": 35913.736}", "{\"n\": 1235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1988.58, \"learn_time_ms\": 35921.602}", "{\"n\": 1236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.22, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1992.84, \"learn_time_ms\": 35911.319}", "{\"n\": 1237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1991.4, \"learn_time_ms\": 35991.818}", "{\"n\": 1238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1995.2, \"learn_time_ms\": 35994.262}", "{\"n\": 1239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1995.2, \"learn_time_ms\": 35960.074}", "{\"n\": 1240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.12, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2007.31, \"learn_time_ms\": 35953.475}", "{\"n\": 1241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2016.37, \"learn_time_ms\": 35965.558}", "{\"n\": 1242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2014.91, \"learn_time_ms\": 35948.283}", "{\"n\": 1243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2027.68, \"learn_time_ms\": 36037.931}", "{\"n\": 1244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2029.75, \"learn_time_ms\": 36004.758}", "{\"n\": 1245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2031.3, \"learn_time_ms\": 36038.473}", "{\"n\": 1246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2027.34, \"learn_time_ms\": 35987.039}", "{\"n\": 1247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2039.3, \"learn_time_ms\": 35949.516}", "{\"n\": 1248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2053.09, \"learn_time_ms\": 35996.329}", "{\"n\": 1249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2054.74, \"learn_time_ms\": 36019.135}", "{\"n\": 1250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2056.87, \"learn_time_ms\": 36019.247}", "{\"n\": 1251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2059.67, \"learn_time_ms\": 36061.099}", "{\"n\": 1252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2061.66, \"learn_time_ms\": 36032.698}", "{\"n\": 1253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2064.52, \"learn_time_ms\": 35965.573}", "{\"n\": 1254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2070.29, \"learn_time_ms\": 35971.714}", "{\"n\": 1255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2071.73, \"learn_time_ms\": 35936.703}", "{\"n\": 1256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2083.05, \"learn_time_ms\": 36006.693}", "{\"n\": 1257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2085.87, \"learn_time_ms\": 35993.629}", "{\"n\": 1258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2089.22, \"learn_time_ms\": 35969.24}", "{\"n\": 1259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2092.52, \"learn_time_ms\": 35915.627}", "{\"n\": 1260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2087.85, \"learn_time_ms\": 35933.98}", "{\"n\": 1261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2091.03, \"learn_time_ms\": 35935.905}", "{\"n\": 1262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2099.32, \"learn_time_ms\": 35968.595}", "{\"n\": 1263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2111.5, \"learn_time_ms\": 35978.834}", "{\"n\": 1264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2107.7, \"learn_time_ms\": 35993.391}", "{\"n\": 1265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2108.01, \"learn_time_ms\": 35991.058}", "{\"n\": 1266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.52, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2110.64, \"learn_time_ms\": 35989.423}", "{\"n\": 1267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2112.09, \"learn_time_ms\": 35970.284}", "{\"n\": 1268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2108.79, \"learn_time_ms\": 35940.641}", "{\"n\": 1269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2110.33, \"learn_time_ms\": 36014.598}", "{\"n\": 1270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2105.55, \"learn_time_ms\": 35985.466}", "{\"n\": 1271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2114.89, \"learn_time_ms\": 35914.222}", "{\"n\": 1272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2120.76, \"learn_time_ms\": 35927.242}", "{\"n\": 1273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2120.76, \"learn_time_ms\": 35932.673}", "{\"n\": 1274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2127.34, \"learn_time_ms\": 35965.641}", "{\"n\": 1275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2128.07, \"learn_time_ms\": 35956.637}", "{\"n\": 1276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2126.95, \"learn_time_ms\": 35905.563}", "{\"n\": 1277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2129.86, \"learn_time_ms\": 35967.344}", "{\"n\": 1278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2125.15, \"learn_time_ms\": 35973.024}", "{\"n\": 1279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2125.0, \"learn_time_ms\": 35958.247}", "{\"n\": 1280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2125.0, \"learn_time_ms\": 35978.234}", "{\"n\": 1281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2133.15, \"learn_time_ms\": 36013.492}", "{\"n\": 1282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2132.12, \"learn_time_ms\": 36000.815}", "{\"n\": 1283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2132.12, \"learn_time_ms\": 36038.583}", "{\"n\": 1284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.4, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2130.38, \"learn_time_ms\": 35985.527}", "{\"n\": 1285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2124.92, \"learn_time_ms\": 36010.527}", "{\"n\": 1286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.46, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2127.61, \"learn_time_ms\": 36056.338}", "{\"n\": 1287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2119.82, \"learn_time_ms\": 36001.328}", "{\"n\": 1288, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2125.19, \"learn_time_ms\": 36017.737}", "{\"n\": 1289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2128.79, \"learn_time_ms\": 36005.561}", "{\"n\": 1290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2128.79, \"learn_time_ms\": 35968.177}", "{\"n\": 1291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2124.74, \"learn_time_ms\": 35996.918}", "{\"n\": 1292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2113.11, \"learn_time_ms\": 36031.894}", "{\"n\": 1293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2113.11, \"learn_time_ms\": 35955.159}", "{\"n\": 1294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2103.39, \"learn_time_ms\": 35963.103}", "{\"n\": 1295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.68, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2104.71, \"learn_time_ms\": 35982.71}", "{\"n\": 1296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2117.87, \"learn_time_ms\": 35960.485}", "{\"n\": 1297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2117.87, \"learn_time_ms\": 35978.255}", "{\"n\": 1298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2109.97, \"learn_time_ms\": 35982.118}", "{\"n\": 1299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2113.19, \"learn_time_ms\": 35973.046}", "{\"n\": 1300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2114.36, \"learn_time_ms\": 36003.022}", "{\"n\": 1301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2114.93, \"learn_time_ms\": 36033.172}", "{\"n\": 1302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2114.27, \"learn_time_ms\": 36019.685}", "{\"n\": 1303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.72, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2120.25, \"learn_time_ms\": 36059.122}", "{\"n\": 1304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2128.17, \"learn_time_ms\": 36054.925}", "{\"n\": 1305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2124.8, \"learn_time_ms\": 36054.229}", "{\"n\": 1306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2113.39, \"learn_time_ms\": 36022.761}", "{\"n\": 1307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2118.84, \"learn_time_ms\": 35952.973}", "{\"n\": 1308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2115.52, \"learn_time_ms\": 35948.525}", "{\"n\": 1309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2112.67, \"learn_time_ms\": 35955.002}", "{\"n\": 1310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2120.89, \"learn_time_ms\": 35946.591}", "{\"n\": 1311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2119.33, \"learn_time_ms\": 35927.185}", "{\"n\": 1312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.62, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2120.91, \"learn_time_ms\": 35904.424}", "{\"n\": 1313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2121.08, \"learn_time_ms\": 35906.686}", "{\"n\": 1314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2124.43, \"learn_time_ms\": 35949.111}", "{\"n\": 1315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2130.31, \"learn_time_ms\": 35916.267}", "{\"n\": 1316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2128.79, \"learn_time_ms\": 35947.994}", "{\"n\": 1317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2124.7, \"learn_time_ms\": 36036.594}", "{\"n\": 1318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2113.36, \"learn_time_ms\": 36012.102}", "{\"n\": 1319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2120.02, \"learn_time_ms\": 35974.262}", "{\"n\": 1320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.59, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2122.22, \"learn_time_ms\": 35947.392}", "{\"n\": 1321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2127.9, \"learn_time_ms\": 35956.643}", "{\"n\": 1322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.55, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2122.3, \"learn_time_ms\": 35974.823}", "{\"n\": 1323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2123.1, \"learn_time_ms\": 35958.186}", "{\"n\": 1324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2122.06, \"learn_time_ms\": 35894.256}", "{\"n\": 1325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2118.19, \"learn_time_ms\": 35913.183}", "{\"n\": 1326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2121.37, \"learn_time_ms\": 35891.891}", "{\"n\": 1327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2133.47, \"learn_time_ms\": 35849.83}", "{\"n\": 1328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.52, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2137.01, \"learn_time_ms\": 35873.988}", "{\"n\": 1329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2140.58, \"learn_time_ms\": 35921.653}", "{\"n\": 1330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2145.3, \"learn_time_ms\": 35948.901}", "{\"n\": 1331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2147.44, \"learn_time_ms\": 35914.471}", "{\"n\": 1332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2145.73, \"learn_time_ms\": 35923.556}", "{\"n\": 1333, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2137.98, \"learn_time_ms\": 35928.907}", "{\"n\": 1334, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2137.99, \"learn_time_ms\": 35934.83}", "{\"n\": 1335, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2145.54, \"learn_time_ms\": 35922.625}", "{\"n\": 1336, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2148.11, \"learn_time_ms\": 35934.209}", "{\"n\": 1337, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2148.11, \"learn_time_ms\": 35955.949}", "{\"n\": 1338, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2150.76, \"learn_time_ms\": 35953.118}", "{\"n\": 1339, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2161.21, \"learn_time_ms\": 35945.072}", "{\"n\": 1340, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2156.76, \"learn_time_ms\": 35946.456}", "{\"n\": 1341, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2156.76, \"learn_time_ms\": 35959.934}", "{\"n\": 1342, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2154.85, \"learn_time_ms\": 35954.347}", "{\"n\": 1343, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2162.82, \"learn_time_ms\": 35961.679}", "{\"n\": 1344, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2162.82, \"learn_time_ms\": 35988.507}", "{\"n\": 1345, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2166.99, \"learn_time_ms\": 35986.783}", "{\"n\": 1346, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2163.91, \"learn_time_ms\": 35984.529}", "{\"n\": 1347, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2163.91, \"learn_time_ms\": 35970.917}", "{\"n\": 1348, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2175.93, \"learn_time_ms\": 35989.334}", "{\"n\": 1349, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2176.27, \"learn_time_ms\": 35972.874}", "{\"n\": 1350, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2183.66, \"learn_time_ms\": 35992.745}", "{\"n\": 1351, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.98, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2189.03, \"learn_time_ms\": 35977.005}", "{\"n\": 1352, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.01, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2187.21, \"learn_time_ms\": 35956.412}", "{\"n\": 1353, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2179.7, \"learn_time_ms\": 35956.468}", "{\"n\": 1354, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2187.93, \"learn_time_ms\": 35958.749}", "{\"n\": 1355, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2190.63, \"learn_time_ms\": 35993.692}", "{\"n\": 1356, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2194.19, \"learn_time_ms\": 35966.892}", "{\"n\": 1357, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2196.87, \"learn_time_ms\": 35982.439}", "{\"n\": 1358, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.98, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2195.7, \"learn_time_ms\": 35981.633}", "{\"n\": 1359, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.92, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2207.92, \"learn_time_ms\": 35959.207}", "{\"n\": 1360, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.99, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2201.33, \"learn_time_ms\": 35939.677}", "{\"n\": 1361, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.01, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2198.05, \"learn_time_ms\": 35961.272}", "{\"n\": 1362, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2196.18, \"learn_time_ms\": 35958.797}", "{\"n\": 1363, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2200.3, \"learn_time_ms\": 35978.042}", "{\"n\": 1364, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2198.43, \"learn_time_ms\": 35973.0}", "{\"n\": 1365, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2195.4, \"learn_time_ms\": 35938.662}", "{\"n\": 1366, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2202.54, \"learn_time_ms\": 35984.385}", "{\"n\": 1367, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2206.61, \"learn_time_ms\": 35988.639}", "{\"n\": 1368, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2209.11, \"learn_time_ms\": 35992.13}", "{\"n\": 1369, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2216.61, \"learn_time_ms\": 36054.044}", "{\"n\": 1370, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2224.29, \"learn_time_ms\": 36016.646}", "{\"n\": 1371, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2219.94, \"learn_time_ms\": 36011.948}", "{\"n\": 1372, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2222.78, \"learn_time_ms\": 36009.908}", "{\"n\": 1373, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2226.17, \"learn_time_ms\": 35957.977}", "{\"n\": 1374, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.8, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2217.64, \"learn_time_ms\": 35935.093}", "{\"n\": 1375, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2213.54, \"learn_time_ms\": 35944.727}", "{\"n\": 1376, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2213.29, \"learn_time_ms\": 35937.6}", "{\"n\": 1377, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2206.68, \"learn_time_ms\": 35955.558}", "{\"n\": 1378, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2218.35, \"learn_time_ms\": 35930.336}", "{\"n\": 1379, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2218.35, \"learn_time_ms\": 35871.923}", "{\"n\": 1380, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2218.35, \"learn_time_ms\": 35870.695}", "{\"n\": 1381, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2228.6, \"learn_time_ms\": 35853.774}", "{\"n\": 1382, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.63, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2229.35, \"learn_time_ms\": 35851.31}", "{\"n\": 1383, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.57, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2234.21, \"learn_time_ms\": 35903.93}", "{\"n\": 1384, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.57, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2236.48, \"learn_time_ms\": 35947.725}", "{\"n\": 1385, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.48, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2248.61, \"learn_time_ms\": 35953.412}", "{\"n\": 1386, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2254.13, \"learn_time_ms\": 35949.981}", "{\"n\": 1387, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2254.13, \"learn_time_ms\": 35949.602}", "{\"n\": 1388, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2256.76, \"learn_time_ms\": 35968.43}", "{\"n\": 1389, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2256.61, \"learn_time_ms\": 36009.406}", "{\"n\": 1390, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2253.48, \"learn_time_ms\": 36042.162}", "{\"n\": 1391, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2253.48, \"learn_time_ms\": 36078.357}", "{\"n\": 1392, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2252.08, \"learn_time_ms\": 36099.055}", "{\"n\": 1393, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2247.12, \"learn_time_ms\": 36095.239}", "{\"n\": 1394, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2248.95, \"learn_time_ms\": 36067.872}", "{\"n\": 1395, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2247.33, \"learn_time_ms\": 36096.42}", "{\"n\": 1396, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2246.44, \"learn_time_ms\": 36093.301}", "{\"n\": 1397, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2243.45, \"learn_time_ms\": 36074.75}", "{\"n\": 1398, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2258.21, \"learn_time_ms\": 36047.667}", "{\"n\": 1399, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2258.21, \"learn_time_ms\": 36032.758}", "{\"n\": 1400, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2282.78, \"learn_time_ms\": 36028.579}", "{\"n\": 1401, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2290.6, \"learn_time_ms\": 35969.556}", "{\"n\": 1402, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2289.6, \"learn_time_ms\": 35956.789}", "{\"n\": 1403, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2285.99, \"learn_time_ms\": 35979.864}", "{\"n\": 1404, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2279.51, \"learn_time_ms\": 35987.332}", "{\"n\": 1405, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2281.1, \"learn_time_ms\": 35972.599}", "{\"n\": 1406, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2279.69, \"learn_time_ms\": 35973.396}", "{\"n\": 1407, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2279.53, \"learn_time_ms\": 35949.936}", "{\"n\": 1408, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2290.09, \"learn_time_ms\": 35968.397}", "{\"n\": 1409, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2293.74, \"learn_time_ms\": 35974.762}", "{\"n\": 1410, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2289.99, \"learn_time_ms\": 35954.91}", "{\"n\": 1411, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2284.35, \"learn_time_ms\": 35979.099}", "{\"n\": 1412, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2284.97, \"learn_time_ms\": 36000.168}", "{\"n\": 1413, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2287.27, \"learn_time_ms\": 35986.234}", "{\"n\": 1414, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2290.45, \"learn_time_ms\": 35991.717}", "{\"n\": 1415, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2291.05, \"learn_time_ms\": 35994.474}", "{\"n\": 1416, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2281.83, \"learn_time_ms\": 35985.894}", "{\"n\": 1417, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2283.16, \"learn_time_ms\": 36042.149}", "{\"n\": 1418, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2279.02, \"learn_time_ms\": 36043.709}", "{\"n\": 1419, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2279.11, \"learn_time_ms\": 36030.748}", "{\"n\": 1420, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2273.57, \"learn_time_ms\": 36062.217}", "{\"n\": 1421, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2272.07, \"learn_time_ms\": 36078.118}", "{\"n\": 1422, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2289.29, \"learn_time_ms\": 36080.014}", "{\"n\": 1423, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2289.79, \"learn_time_ms\": 36039.863}", "{\"n\": 1424, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2291.48, \"learn_time_ms\": 36018.465}", "{\"n\": 1425, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2292.4, \"learn_time_ms\": 35979.293}", "{\"n\": 1426, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2302.18, \"learn_time_ms\": 36021.033}", "{\"n\": 1427, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2302.19, \"learn_time_ms\": 35973.093}", "{\"n\": 1428, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2300.32, \"learn_time_ms\": 35980.098}", "{\"n\": 1429, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2300.58, \"learn_time_ms\": 35982.176}", "{\"n\": 1430, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2308.53, \"learn_time_ms\": 35975.164}", "{\"n\": 1431, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2311.19, \"learn_time_ms\": 35973.942}", "{\"n\": 1432, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2308.55, \"learn_time_ms\": 35969.683}", "{\"n\": 1433, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2309.4, \"learn_time_ms\": 35951.379}", "{\"n\": 1434, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2307.43, \"learn_time_ms\": 35986.665}", "{\"n\": 1435, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2303.44, \"learn_time_ms\": 35988.433}", "{\"n\": 1436, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2303.44, \"learn_time_ms\": 35903.726}", "{\"n\": 1437, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2314.18, \"learn_time_ms\": 35899.367}", "{\"n\": 1438, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2306.36, \"learn_time_ms\": 35852.636}", "{\"n\": 1439, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2320.56, \"learn_time_ms\": 35845.039}", "{\"n\": 1440, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2318.32, \"learn_time_ms\": 35865.865}", "{\"n\": 1441, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2327.01, \"learn_time_ms\": 35820.008}", "{\"n\": 1442, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2327.12, \"learn_time_ms\": 35794.16}", "{\"n\": 1443, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2341.19, \"learn_time_ms\": 35838.265}", "{\"n\": 1444, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2330.96, \"learn_time_ms\": 35861.894}", "{\"n\": 1445, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2328.29, \"learn_time_ms\": 35883.031}", "{\"n\": 1446, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2322.87, \"learn_time_ms\": 35943.396}", "{\"n\": 1447, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2319.38, \"learn_time_ms\": 35956.779}", "{\"n\": 1448, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2313.89, \"learn_time_ms\": 35987.757}", "{\"n\": 1449, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.55, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2298.87, \"learn_time_ms\": 36000.244}", "{\"n\": 1450, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.54, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2302.62, \"learn_time_ms\": 35987.873}", "{\"n\": 1451, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.51, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2303.78, \"learn_time_ms\": 36045.324}", "{\"n\": 1452, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.47, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2310.27, \"learn_time_ms\": 36075.902}", "{\"n\": 1453, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2309.7, \"learn_time_ms\": 36030.979}", "{\"n\": 1454, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2320.19, \"learn_time_ms\": 36004.422}", "{\"n\": 1455, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2320.19, \"learn_time_ms\": 35982.689}", "{\"n\": 1456, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.53, \"learn_time_ms\": 35974.896}", "{\"n\": 1457, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2332.05, \"learn_time_ms\": 36002.387}", "{\"n\": 1458, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2333.55, \"learn_time_ms\": 35975.653}", "{\"n\": 1459, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2339.75, \"learn_time_ms\": 35977.522}", "{\"n\": 1460, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2339.75, \"learn_time_ms\": 35919.557}", "{\"n\": 1461, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2348.4, \"learn_time_ms\": 35941.209}", "{\"n\": 1462, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2344.44, \"learn_time_ms\": 35911.311}", "{\"n\": 1463, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.13, \"learn_time_ms\": 35981.208}", "{\"n\": 1464, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.31, \"learn_time_ms\": 35943.997}", "{\"n\": 1465, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2338.16, \"learn_time_ms\": 35951.649}", "{\"n\": 1466, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2344.63, \"learn_time_ms\": 35964.892}", "{\"n\": 1467, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2345.26, \"learn_time_ms\": 35926.084}", "{\"n\": 1468, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2337.29, \"learn_time_ms\": 35948.28}", "{\"n\": 1469, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2354.3, \"learn_time_ms\": 35947.297}", "{\"n\": 1470, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2339.12, \"learn_time_ms\": 35963.198}", "{\"n\": 1471, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2344.4, \"learn_time_ms\": 35917.323}", "{\"n\": 1472, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2344.66, \"learn_time_ms\": 35946.835}", "{\"n\": 1473, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.38, \"learn_time_ms\": 35892.952}", "{\"n\": 1474, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2342.13, \"learn_time_ms\": 35935.091}", "{\"n\": 1475, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2334.04, \"learn_time_ms\": 35936.496}", "{\"n\": 1476, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2325.76, \"learn_time_ms\": 35954.757}", "{\"n\": 1477, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2323.86, \"learn_time_ms\": 35933.34}", "{\"n\": 1478, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2329.76, \"learn_time_ms\": 35914.578}", "{\"n\": 1479, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2329.76, \"learn_time_ms\": 35947.026}", "{\"n\": 1480, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.52, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2326.26, \"learn_time_ms\": 35973.43}", "{\"n\": 1481, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2320.91, \"learn_time_ms\": 35972.503}", "{\"n\": 1482, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.47, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2332.23, \"learn_time_ms\": 35988.643}", "{\"n\": 1483, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.48, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2332.03, \"learn_time_ms\": 36032.162}", "{\"n\": 1484, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2348.86, \"learn_time_ms\": 35989.172}", "{\"n\": 1485, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.2, \"learn_time_ms\": 36023.332}", "{\"n\": 1486, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.19, \"learn_time_ms\": 35975.42}", "{\"n\": 1487, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2351.05, \"learn_time_ms\": 36014.679}", "{\"n\": 1488, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2347.53, \"learn_time_ms\": 36048.252}", "{\"n\": 1489, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2347.21, \"learn_time_ms\": 36018.14}", "{\"n\": 1490, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2340.98, \"learn_time_ms\": 36013.829}", "{\"n\": 1491, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2338.03, \"learn_time_ms\": 36026.612}", "{\"n\": 1492, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2331.14, \"learn_time_ms\": 36017.204}", "{\"n\": 1493, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2339.54, \"learn_time_ms\": 36003.149}", "{\"n\": 1494, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2348.36, \"learn_time_ms\": 36043.306}", "{\"n\": 1495, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2347.62, \"learn_time_ms\": 36048.473}", "{\"n\": 1496, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2342.12, \"learn_time_ms\": 36075.079}", "{\"n\": 1497, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.57, \"learn_time_ms\": 36062.054}", "{\"n\": 1498, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2360.57, \"learn_time_ms\": 36096.135}", "{\"n\": 1499, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2360.57, \"learn_time_ms\": 36070.595}", "{\"n\": 1500, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2373.57, \"learn_time_ms\": 36025.697}", "{\"n\": 1501, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2372.42, \"learn_time_ms\": 36033.892}", "{\"n\": 1502, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2369.33, \"learn_time_ms\": 36006.632}", "{\"n\": 1503, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2365.03, \"learn_time_ms\": 36023.819}", "{\"n\": 1504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2340.29, \"learn_time_ms\": 36044.508}", "{\"n\": 1505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2338.47, \"learn_time_ms\": 36013.978}", "{\"n\": 1506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2340.22, \"learn_time_ms\": 35999.724}", "{\"n\": 1507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2339.75, \"learn_time_ms\": 36009.606}", "{\"n\": 1508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.71, \"learn_time_ms\": 35922.961}", "{\"n\": 1509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2339.48, \"learn_time_ms\": 35936.7}", "{\"n\": 1510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2335.28, \"learn_time_ms\": 35991.9}", "{\"n\": 1511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2338.87, \"learn_time_ms\": 35981.445}", "{\"n\": 1512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2348.53, \"learn_time_ms\": 36006.66}", "{\"n\": 1513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2346.73, \"learn_time_ms\": 35975.412}", "{\"n\": 1514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2351.19, \"learn_time_ms\": 35937.331}", "{\"n\": 1515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2352.66, \"learn_time_ms\": 35937.538}", "{\"n\": 1516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2356.11, \"learn_time_ms\": 35953.851}", "{\"n\": 1517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2360.25, \"learn_time_ms\": 35933.041}", "{\"n\": 1518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2362.25, \"learn_time_ms\": 35961.345}", "{\"n\": 1519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2361.49, \"learn_time_ms\": 35975.127}", "{\"n\": 1520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2363.08, \"learn_time_ms\": 35978.23}", "{\"n\": 1521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2370.79, \"learn_time_ms\": 35982.678}", "{\"n\": 1522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2370.79, \"learn_time_ms\": 35959.282}", "{\"n\": 1523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2367.87, \"learn_time_ms\": 35972.791}", "{\"n\": 1524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2367.87, \"learn_time_ms\": 35984.411}", "{\"n\": 1525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2376.86, \"learn_time_ms\": 36015.37}", "{\"n\": 1526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2376.86, \"learn_time_ms\": 35980.297}", "{\"n\": 1527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2380.23, \"learn_time_ms\": 35980.467}", "{\"n\": 1528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2381.63, \"learn_time_ms\": 35987.005}", "{\"n\": 1529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2376.05, \"learn_time_ms\": 35947.382}", "{\"n\": 1530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2383.53, \"learn_time_ms\": 35911.285}", "{\"n\": 1531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2378.89, \"learn_time_ms\": 35896.03}", "{\"n\": 1532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2365.51, \"learn_time_ms\": 35925.233}", "{\"n\": 1533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2361.0, \"learn_time_ms\": 35934.6}", "{\"n\": 1534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2357.39, \"learn_time_ms\": 35897.068}", "{\"n\": 1535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2356.13, \"learn_time_ms\": 35857.459}", "{\"n\": 1536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2367.83, \"learn_time_ms\": 35870.809}", "{\"n\": 1537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2368.06, \"learn_time_ms\": 35888.776}", "{\"n\": 1538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2368.06, \"learn_time_ms\": 35926.233}", "{\"n\": 1539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2373.67, \"learn_time_ms\": 35953.801}", "{\"n\": 1540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2386.25, \"learn_time_ms\": 35984.632}", "{\"n\": 1541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2387.93, \"learn_time_ms\": 35980.894}", "{\"n\": 1542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2393.68, \"learn_time_ms\": 35969.269}", "{\"n\": 1543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2385.75, \"learn_time_ms\": 35981.57}", "{\"n\": 1544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2379.1, \"learn_time_ms\": 35990.098}", "{\"n\": 1545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2384.63, \"learn_time_ms\": 35981.141}", "{\"n\": 1546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2388.42, \"learn_time_ms\": 36005.408}", "{\"n\": 1547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2383.29, \"learn_time_ms\": 36003.962}", "{\"n\": 1548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2378.56, \"learn_time_ms\": 35974.967}", "{\"n\": 1549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2379.37, \"learn_time_ms\": 35953.073}", "{\"n\": 1550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2379.37, \"learn_time_ms\": 35979.467}", "{\"n\": 1551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2376.07, \"learn_time_ms\": 35986.399}", "{\"n\": 1552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2388.6, \"learn_time_ms\": 35982.169}", "{\"n\": 1553, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2391.46, \"learn_time_ms\": 35952.12}", "{\"n\": 1554, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2391.46, \"learn_time_ms\": 35972.033}", "{\"n\": 1555, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2389.96, \"learn_time_ms\": 35994.759}", "{\"n\": 1556, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2396.71, \"learn_time_ms\": 35945.545}", "{\"n\": 1557, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2405.06, \"learn_time_ms\": 35927.708}", "{\"n\": 1558, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2400.54, \"learn_time_ms\": 35938.614}", "{\"n\": 1559, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2394.85, \"learn_time_ms\": 35978.768}", "{\"n\": 1560, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2404.03, \"learn_time_ms\": 35954.155}", "{\"n\": 1561, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2418.15, \"learn_time_ms\": 35954.404}", "{\"n\": 1562, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2413.44, \"learn_time_ms\": 35932.36}", "{\"n\": 1563, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2416.38, \"learn_time_ms\": 35959.037}", "{\"n\": 1564, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2408.9, \"learn_time_ms\": 35988.002}", "{\"n\": 1565, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2408.9, \"learn_time_ms\": 35981.643}", "{\"n\": 1566, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2411.14, \"learn_time_ms\": 36044.572}", "{\"n\": 1567, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2397.18, \"learn_time_ms\": 36051.448}", "{\"n\": 1568, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2387.62, \"learn_time_ms\": 36024.887}", "{\"n\": 1569, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2387.62, \"learn_time_ms\": 36011.813}", "{\"n\": 1570, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2389.52, \"learn_time_ms\": 36003.445}", "{\"n\": 1571, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2389.52, \"learn_time_ms\": 36010.697}", "{\"n\": 1572, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2386.72, \"learn_time_ms\": 36018.53}", "{\"n\": 1573, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2389.43, \"learn_time_ms\": 36015.262}", "{\"n\": 1574, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2389.43, \"learn_time_ms\": 35965.868}", "{\"n\": 1575, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2392.11, \"learn_time_ms\": 35957.644}", "{\"n\": 1576, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2403.38, \"learn_time_ms\": 35934.017}", "{\"n\": 1577, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2403.38, \"learn_time_ms\": 35970.019}", "{\"n\": 1578, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.03, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2403.43, \"learn_time_ms\": 35979.899}", "{\"n\": 1579, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.03, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2403.43, \"learn_time_ms\": 35984.626}", "{\"n\": 1580, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2403.19, \"learn_time_ms\": 35971.888}", "{\"n\": 1581, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2403.19, \"learn_time_ms\": 35959.287}", "{\"n\": 1582, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2397.38, \"learn_time_ms\": 35994.192}", "{\"n\": 1583, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2396.66, \"learn_time_ms\": 35973.877}", "{\"n\": 1584, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2404.99, \"learn_time_ms\": 35990.508}", "{\"n\": 1585, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2393.52, \"learn_time_ms\": 35983.117}", "{\"n\": 1586, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2390.56, \"learn_time_ms\": 35960.045}", "{\"n\": 1587, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2386.26, \"learn_time_ms\": 35956.964}", "{\"n\": 1588, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2382.51, \"learn_time_ms\": 35951.169}", "{\"n\": 1589, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2378.43, \"learn_time_ms\": 35944.061}", "{\"n\": 1590, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2377.51, \"learn_time_ms\": 35951.603}", "{\"n\": 1591, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2377.51, \"learn_time_ms\": 35954.481}", "{\"n\": 1592, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2377.44, \"learn_time_ms\": 35941.112}", "{\"n\": 1593, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2375.65, \"learn_time_ms\": 35937.009}", "{\"n\": 1594, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.2, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2388.67, \"learn_time_ms\": 35926.842}", "{\"n\": 1595, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2386.18, \"learn_time_ms\": 35971.602}", "{\"n\": 1596, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2380.56, \"learn_time_ms\": 35972.8}", "{\"n\": 1597, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2382.92, \"learn_time_ms\": 35934.11}", "{\"n\": 1598, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2388.6, \"learn_time_ms\": 35973.608}", "{\"n\": 1599, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2395.2, \"learn_time_ms\": 35950.114}", "{\"n\": 1600, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2405.62, \"learn_time_ms\": 35952.827}", "{\"n\": 1601, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2405.53, \"learn_time_ms\": 35977.306}", "{\"n\": 1602, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2410.06, \"learn_time_ms\": 35963.477}", "{\"n\": 1603, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2404.75, \"learn_time_ms\": 35982.138}", "{\"n\": 1604, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2409.48, \"learn_time_ms\": 36027.192}", "{\"n\": 1605, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2408.95, \"learn_time_ms\": 35988.684}", "{\"n\": 1606, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2408.95, \"learn_time_ms\": 35990.207}", "{\"n\": 1607, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2419.61, \"learn_time_ms\": 36019.499}", "{\"n\": 1608, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2425.41, \"learn_time_ms\": 35977.237}", "{\"n\": 1609, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2430.94, \"learn_time_ms\": 36019.881}", "{\"n\": 1610, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2439.69, \"learn_time_ms\": 36032.391}", "{\"n\": 1611, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2433.81, \"learn_time_ms\": 36008.076}", "{\"n\": 1612, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2425.21, \"learn_time_ms\": 35981.511}", "{\"n\": 1613, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2425.21, \"learn_time_ms\": 35990.237}", "{\"n\": 1614, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2424.8, \"learn_time_ms\": 35945.235}", "{\"n\": 1615, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2425.66, \"learn_time_ms\": 35943.71}", "{\"n\": 1616, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2438.19, \"learn_time_ms\": 35988.153}", "{\"n\": 1617, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2441.24, \"learn_time_ms\": 35978.069}", "{\"n\": 1618, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2467.91, \"learn_time_ms\": 35988.023}", "{\"n\": 1619, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2467.91, \"learn_time_ms\": 35959.101}", "{\"n\": 1620, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2479.35, \"learn_time_ms\": 35930.677}", "{\"n\": 1621, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2480.48, \"learn_time_ms\": 35971.307}", "{\"n\": 1622, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2482.21, \"learn_time_ms\": 35981.172}", "{\"n\": 1623, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2482.21, \"learn_time_ms\": 35958.001}", "{\"n\": 1624, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.48, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2488.17, \"learn_time_ms\": 35952.479}", "{\"n\": 1625, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2494.06, \"learn_time_ms\": 35953.305}", "{\"n\": 1626, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2500.02, \"learn_time_ms\": 35868.107}", "{\"n\": 1627, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2500.02, \"learn_time_ms\": 35888.308}", "{\"n\": 1628, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2498.12, \"learn_time_ms\": 35904.455}", "{\"n\": 1629, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2492.92, \"learn_time_ms\": 35942.433}", "{\"n\": 1630, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.48, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2495.12, \"learn_time_ms\": 35960.546}", "{\"n\": 1631, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2502.27, \"learn_time_ms\": 35939.42}", "{\"n\": 1632, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2502.27, \"learn_time_ms\": 35984.561}", "{\"n\": 1633, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2510.7, \"learn_time_ms\": 35972.993}", "{\"n\": 1634, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.21, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2526.08, \"learn_time_ms\": 35991.133}", "{\"n\": 1635, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2540.81, \"learn_time_ms\": 36028.72}", "{\"n\": 1636, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2540.81, \"learn_time_ms\": 36052.97}", "{\"n\": 1637, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2542.75, \"learn_time_ms\": 36070.09}", "{\"n\": 1638, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.13, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2539.23, \"learn_time_ms\": 36068.865}", "{\"n\": 1639, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2548.93, \"learn_time_ms\": 36042.829}", "{\"n\": 1640, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2553.13, \"learn_time_ms\": 36084.679}", "{\"n\": 1641, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2553.13, \"learn_time_ms\": 36067.212}", "{\"n\": 1642, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2553.35, \"learn_time_ms\": 36076.566}", "{\"n\": 1643, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2558.77, \"learn_time_ms\": 36099.23}", "{\"n\": 1644, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2559.34, \"learn_time_ms\": 36098.165}", "{\"n\": 1645, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2559.34, \"learn_time_ms\": 36068.709}", "{\"n\": 1646, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.16, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2547.4, \"learn_time_ms\": 36111.633}", "{\"n\": 1647, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.15, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2551.25, \"learn_time_ms\": 36115.918}", "{\"n\": 1648, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2557.86, \"learn_time_ms\": 36125.734}", "{\"n\": 1649, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.15, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2557.26, \"learn_time_ms\": 36109.161}", "{\"n\": 1650, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2547.8, \"learn_time_ms\": 36030.752}", "{\"n\": 1651, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2541.61, \"learn_time_ms\": 36044.391}", "{\"n\": 1652, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2541.61, \"learn_time_ms\": 36003.14}", "{\"n\": 1653, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2539.46, \"learn_time_ms\": 35989.226}", "{\"n\": 1654, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2529.34, \"learn_time_ms\": 36009.854}", "{\"n\": 1655, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2531.78, \"learn_time_ms\": 36015.705}", "{\"n\": 1656, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.37, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2532.44, \"learn_time_ms\": 36010.486}", "{\"n\": 1657, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2544.53, \"learn_time_ms\": 35970.701}", "{\"n\": 1658, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.31, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2540.16, \"learn_time_ms\": 35945.84}", "{\"n\": 1659, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2535.72, \"learn_time_ms\": 35977.504}", "{\"n\": 1660, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2525.63, \"learn_time_ms\": 36069.666}", "{\"n\": 1661, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2524.04, \"learn_time_ms\": 36078.398}", "{\"n\": 1662, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2522.8, \"learn_time_ms\": 36083.792}", "{\"n\": 1663, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2519.42, \"learn_time_ms\": 36102.101}", "{\"n\": 1664, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2525.26, \"learn_time_ms\": 36090.549}", "{\"n\": 1665, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2525.26, \"learn_time_ms\": 36073.511}", "{\"n\": 1666, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2525.22, \"learn_time_ms\": 36052.993}", "{\"n\": 1667, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2517.08, \"learn_time_ms\": 36053.63}", "{\"n\": 1668, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2513.85, \"learn_time_ms\": 36046.684}", "{\"n\": 1669, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2513.31, \"learn_time_ms\": 36066.961}", "{\"n\": 1670, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2513.31, \"learn_time_ms\": 36059.645}", "{\"n\": 1671, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2497.44, \"learn_time_ms\": 36042.002}", "{\"n\": 1672, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2500.67, \"learn_time_ms\": 36043.394}", "{\"n\": 1673, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2499.31, \"learn_time_ms\": 36054.591}", "{\"n\": 1674, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2502.39, \"learn_time_ms\": 36044.685}", "{\"n\": 1675, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2500.73, \"learn_time_ms\": 36074.29}", "{\"n\": 1676, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2517.49, \"learn_time_ms\": 36125.026}", "{\"n\": 1677, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2522.67, \"learn_time_ms\": 36090.136}", "{\"n\": 1678, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2521.88, \"learn_time_ms\": 36110.552}", "{\"n\": 1679, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.21, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2523.95, \"learn_time_ms\": 36127.251}", "{\"n\": 1680, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.11, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2536.97, \"learn_time_ms\": 36080.522}", "{\"n\": 1681, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.06, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2541.84, \"learn_time_ms\": 36092.422}", "{\"n\": 1682, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.06, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2541.84, \"learn_time_ms\": 36087.681}", "{\"n\": 1683, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.13, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2528.18, \"learn_time_ms\": 36080.376}", "{\"n\": 1684, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2519.25, \"learn_time_ms\": 36068.949}", "{\"n\": 1685, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2511.93, \"learn_time_ms\": 36052.528}", "{\"n\": 1686, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2505.81, \"learn_time_ms\": 36049.019}", "{\"n\": 1687, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2514.75, \"learn_time_ms\": 36070.976}", "{\"n\": 1688, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2513.91, \"learn_time_ms\": 36058.135}", "{\"n\": 1689, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2517.87, \"learn_time_ms\": 36008.879}", "{\"n\": 1690, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2519.9, \"learn_time_ms\": 36038.443}", "{\"n\": 1691, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2529.5, \"learn_time_ms\": 35979.471}", "{\"n\": 1692, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2539.09, \"learn_time_ms\": 35998.011}", "{\"n\": 1693, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2540.73, \"learn_time_ms\": 35941.335}", "{\"n\": 1694, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2540.42, \"learn_time_ms\": 35948.253}", "{\"n\": 1695, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2562.51, \"learn_time_ms\": 35934.983}", "{\"n\": 1696, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.83, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2564.68, \"learn_time_ms\": 35917.112}", "{\"n\": 1697, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2556.83, \"learn_time_ms\": 35892.871}", "{\"n\": 1698, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2565.27, \"learn_time_ms\": 35903.159}", "{\"n\": 1699, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2573.56, \"learn_time_ms\": 35910.38}", "{\"n\": 1700, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2575.53, \"learn_time_ms\": 35842.322}", "{\"n\": 1701, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2566.56, \"learn_time_ms\": 35875.319}", "{\"n\": 1702, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2566.56, \"learn_time_ms\": 35889.27}", "{\"n\": 1703, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2569.56, \"learn_time_ms\": 35951.105}", "{\"n\": 1704, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2574.58, \"learn_time_ms\": 35956.179}", "{\"n\": 1705, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2586.82, \"learn_time_ms\": 35971.581}", "{\"n\": 1706, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2586.82, \"learn_time_ms\": 35970.967}", "{\"n\": 1707, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2598.08, \"learn_time_ms\": 36009.422}", "{\"n\": 1708, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.47, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2582.09, \"learn_time_ms\": 35982.406}", "{\"n\": 1709, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2589.56, \"learn_time_ms\": 35971.575}", "{\"n\": 1710, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2587.27, \"learn_time_ms\": 35989.76}", "{\"n\": 1711, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2581.17, \"learn_time_ms\": 36028.471}", "{\"n\": 1712, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2588.75, \"learn_time_ms\": 35996.911}", "{\"n\": 1713, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2583.55, \"learn_time_ms\": 35960.994}", "{\"n\": 1714, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2582.15, \"learn_time_ms\": 35966.201}", "{\"n\": 1715, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2589.66, \"learn_time_ms\": 35950.41}", "{\"n\": 1716, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2599.62, \"learn_time_ms\": 35979.38}", "{\"n\": 1717, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2607.59, \"learn_time_ms\": 35959.295}", "{\"n\": 1718, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2604.98, \"learn_time_ms\": 35958.256}", "{\"n\": 1719, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2604.98, \"learn_time_ms\": 35991.592}", "{\"n\": 1720, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2609.89, \"learn_time_ms\": 35989.087}", "{\"n\": 1721, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2623.0, \"learn_time_ms\": 35944.0}", "{\"n\": 1722, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.24, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2626.91, \"learn_time_ms\": 35948.698}", "{\"n\": 1723, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2626.77, \"learn_time_ms\": 35951.598}", "{\"n\": 1724, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2627.61, \"learn_time_ms\": 35956.218}", "{\"n\": 1725, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2627.85, \"learn_time_ms\": 35947.427}", "{\"n\": 1726, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2633.97, \"learn_time_ms\": 35879.779}", "{\"n\": 1727, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2643.08, \"learn_time_ms\": 35898.797}", "{\"n\": 1728, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2645.24, \"learn_time_ms\": 35907.275}", "{\"n\": 1729, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2637.89, \"learn_time_ms\": 35850.945}", "{\"n\": 1730, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2639.47, \"learn_time_ms\": 35861.603}", "{\"n\": 1731, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2644.09, \"learn_time_ms\": 35859.817}", "{\"n\": 1732, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2645.79, \"learn_time_ms\": 35887.214}", "{\"n\": 1733, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.38, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2632.69, \"learn_time_ms\": 35881.905}", "{\"n\": 1734, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.38, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2632.69, \"learn_time_ms\": 35831.983}", "{\"n\": 1735, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.48, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2616.12, \"learn_time_ms\": 35794.402}", "{\"n\": 1736, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2607.9, \"learn_time_ms\": 35831.471}", "{\"n\": 1737, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2621.95, \"learn_time_ms\": 35821.83}", "{\"n\": 1738, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.47, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2627.38, \"learn_time_ms\": 35847.678}", "{\"n\": 1739, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2630.37, \"learn_time_ms\": 35861.941}", "{\"n\": 1740, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2628.59, \"learn_time_ms\": 35876.62}", "{\"n\": 1741, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2634.1, \"learn_time_ms\": 35899.916}", "{\"n\": 1742, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2628.54, \"learn_time_ms\": 35864.542}", "{\"n\": 1743, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.48, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2617.83, \"learn_time_ms\": 35905.116}", "{\"n\": 1744, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2624.66, \"learn_time_ms\": 35899.609}", "{\"n\": 1745, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2620.94, \"learn_time_ms\": 35953.823}", "{\"n\": 1746, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2624.09, \"learn_time_ms\": 35928.196}", "{\"n\": 1747, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.53, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2619.89, \"learn_time_ms\": 35916.809}", "{\"n\": 1748, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.57, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2611.83, \"learn_time_ms\": 35944.813}", "{\"n\": 1749, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.64, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2605.14, \"learn_time_ms\": 35913.388}", "{\"n\": 1750, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.66, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2605.67, \"learn_time_ms\": 35901.573}", "{\"n\": 1751, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2608.86, \"learn_time_ms\": 35927.976}", "{\"n\": 1752, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.66, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2608.18, \"learn_time_ms\": 35905.176}", "{\"n\": 1753, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2615.59, \"learn_time_ms\": 35896.28}", "{\"n\": 1754, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2620.61, \"learn_time_ms\": 35966.814}", "{\"n\": 1755, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.74, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2616.79, \"learn_time_ms\": 35937.118}", "{\"n\": 1756, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.68, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2627.82, \"learn_time_ms\": 35954.102}", "{\"n\": 1757, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2636.76, \"learn_time_ms\": 35992.701}", "{\"n\": 1758, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.64, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2634.77, \"learn_time_ms\": 35970.578}", "{\"n\": 1759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2633.83, \"learn_time_ms\": 35957.409}", "{\"n\": 1760, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2636.68, \"learn_time_ms\": 35990.479}", "{\"n\": 1761, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.66, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2630.91, \"learn_time_ms\": 36074.658}", "{\"n\": 1762, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2629.66, \"learn_time_ms\": 36093.769}", "{\"n\": 1763, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2639.0, \"learn_time_ms\": 36087.023}", "{\"n\": 1764, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2639.0, \"learn_time_ms\": 36077.996}", "{\"n\": 1765, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.63, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2638.98, \"learn_time_ms\": 36091.577}", "{\"n\": 1766, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2640.07, \"learn_time_ms\": 36080.09}", "{\"n\": 1767, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.62, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2636.84, \"learn_time_ms\": 36032.859}", "{\"n\": 1768, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2639.0, \"learn_time_ms\": 36014.472}", "{\"n\": 1769, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.57, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2647.26, \"learn_time_ms\": 36077.832}", "{\"n\": 1770, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2634.33, \"learn_time_ms\": 36041.221}", "{\"n\": 1771, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2626.59, \"learn_time_ms\": 35910.388}", "{\"n\": 1772, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.74, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2621.69, \"learn_time_ms\": 35914.967}", "{\"n\": 1773, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.64, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2632.24, \"learn_time_ms\": 35892.183}", "{\"n\": 1774, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.62, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2634.59, \"learn_time_ms\": 35856.61}", "{\"n\": 1775, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2632.74, \"learn_time_ms\": 35883.925}", "{\"n\": 1776, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.71, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2624.38, \"learn_time_ms\": 35872.631}", "{\"n\": 1777, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2619.17, \"learn_time_ms\": 35874.267}", "{\"n\": 1778, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2625.49, \"learn_time_ms\": 35903.187}", "{\"n\": 1779, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2626.13, \"learn_time_ms\": 35872.636}", "{\"n\": 1780, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.78, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2624.2, \"learn_time_ms\": 35900.107}", "{\"n\": 1781, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.68, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2627.07, \"learn_time_ms\": 35903.844}", "{\"n\": 1782, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2629.36, \"learn_time_ms\": 35846.791}", "{\"n\": 1783, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.59, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2637.06, \"learn_time_ms\": 35872.789}", "{\"n\": 1784, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.54, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2642.9, \"learn_time_ms\": 35887.509}", "{\"n\": 1785, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2650.67, \"learn_time_ms\": 35853.784}", "{\"n\": 1786, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.39, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2653.72, \"learn_time_ms\": 35874.119}", "{\"n\": 1787, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.33, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2659.52, \"learn_time_ms\": 35860.87}", "{\"n\": 1788, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.31, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2667.09, \"learn_time_ms\": 35822.956}", "{\"n\": 1789, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2662.33, \"learn_time_ms\": 35872.398}", "{\"n\": 1790, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.29, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2668.37, \"learn_time_ms\": 35814.813}", "{\"n\": 1791, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2672.12, \"learn_time_ms\": 35826.124}", "{\"n\": 1792, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2672.12, \"learn_time_ms\": 35847.693}", "{\"n\": 1793, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.19, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2674.07, \"learn_time_ms\": 35833.187}", "{\"n\": 1794, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.18, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2674.69, \"learn_time_ms\": 35829.307}", "{\"n\": 1795, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.19, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2671.81, \"learn_time_ms\": 35844.264}", "{\"n\": 1796, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.19, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2671.81, \"learn_time_ms\": 35846.128}", "{\"n\": 1797, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2672.65, \"learn_time_ms\": 35877.802}", "{\"n\": 1798, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2672.34, \"learn_time_ms\": 35861.439}", "{\"n\": 1799, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2672.34, \"learn_time_ms\": 35786.132}", "{\"n\": 1800, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2673.11, \"learn_time_ms\": 35841.86}", "{\"n\": 1801, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2666.5, \"learn_time_ms\": 35827.525}", "{\"n\": 1802, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.3, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2664.42, \"learn_time_ms\": 35862.313}", "{\"n\": 1803, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2667.87, \"learn_time_ms\": 35865.812}", "{\"n\": 1804, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2677.0, \"learn_time_ms\": 35848.767}", "{\"n\": 1805, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.24, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2673.88, \"learn_time_ms\": 35840.772}", "{\"n\": 1806, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.19, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2677.1, \"learn_time_ms\": 35847.925}", "{\"n\": 1807, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2672.67, \"learn_time_ms\": 35874.633}", "{\"n\": 1808, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2677.37, \"learn_time_ms\": 35870.013}", "{\"n\": 1809, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2677.37, \"learn_time_ms\": 35899.656}", "{\"n\": 1810, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2682.55, \"learn_time_ms\": 35918.606}", "{\"n\": 1811, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2690.6, \"learn_time_ms\": 35934.197}", "{\"n\": 1812, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2692.76, \"learn_time_ms\": 35888.545}", "{\"n\": 1813, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2696.45, \"learn_time_ms\": 35937.68}", "{\"n\": 1814, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2688.27, \"learn_time_ms\": 35938.763}", "{\"n\": 1815, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2688.27, \"learn_time_ms\": 35937.389}", "{\"n\": 1816, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2685.19, \"learn_time_ms\": 35976.554}", "{\"n\": 1817, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2689.43, \"learn_time_ms\": 35900.029}", "{\"n\": 1818, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2685.49, \"learn_time_ms\": 35907.952}", "{\"n\": 1819, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2685.49, \"learn_time_ms\": 35968.116}", "{\"n\": 1820, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2687.89, \"learn_time_ms\": 35905.664}", "{\"n\": 1821, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2687.54, \"learn_time_ms\": 35890.528}", "{\"n\": 1822, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2688.6, \"learn_time_ms\": 35945.293}", "{\"n\": 1823, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2691.12, \"learn_time_ms\": 35901.446}", "{\"n\": 1824, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.95, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2683.96, \"learn_time_ms\": 35928.99}", "{\"n\": 1825, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2689.39, \"learn_time_ms\": 35973.979}", "{\"n\": 1826, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2702.6, \"learn_time_ms\": 35919.724}", "{\"n\": 1827, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2706.14, \"learn_time_ms\": 35955.618}", "{\"n\": 1828, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2707.06, \"learn_time_ms\": 35991.969}", "{\"n\": 1829, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2697.5, \"learn_time_ms\": 35965.662}", "{\"n\": 1830, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2704.9, \"learn_time_ms\": 35959.851}", "{\"n\": 1831, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.83, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2705.93, \"learn_time_ms\": 36014.93}", "{\"n\": 1832, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2712.42, \"learn_time_ms\": 35999.887}", "{\"n\": 1833, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2713.02, \"learn_time_ms\": 35982.376}", "{\"n\": 1834, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2704.88, \"learn_time_ms\": 35984.809}", "{\"n\": 1835, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2711.59, \"learn_time_ms\": 35978.683}", "{\"n\": 1836, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2709.77, \"learn_time_ms\": 35947.769}", "{\"n\": 1837, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2703.85, \"learn_time_ms\": 35948.577}", "{\"n\": 1838, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2701.8, \"learn_time_ms\": 35963.66}", "{\"n\": 1839, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2689.45, \"learn_time_ms\": 35939.846}", "{\"n\": 1840, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2683.38, \"learn_time_ms\": 35974.152}", "{\"n\": 1841, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.04, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2672.66, \"learn_time_ms\": 35954.656}", "{\"n\": 1842, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2673.76, \"learn_time_ms\": 35990.785}", "{\"n\": 1843, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2673.83, \"learn_time_ms\": 36001.365}", "{\"n\": 1844, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2675.09, \"learn_time_ms\": 35979.893}", "{\"n\": 1845, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2675.09, \"learn_time_ms\": 35965.028}", "{\"n\": 1846, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2686.23, \"learn_time_ms\": 36010.12}", "{\"n\": 1847, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2694.1, \"learn_time_ms\": 36032.247}", "{\"n\": 1848, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2690.58, \"learn_time_ms\": 35987.807}", "{\"n\": 1849, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2689.7, \"learn_time_ms\": 35975.341}", "{\"n\": 1850, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2689.7, \"learn_time_ms\": 35970.091}", "{\"n\": 1851, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2692.29, \"learn_time_ms\": 35946.782}", "{\"n\": 1852, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2688.22, \"learn_time_ms\": 35906.597}", "{\"n\": 1853, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2692.33, \"learn_time_ms\": 35887.805}", "{\"n\": 1854, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2687.77, \"learn_time_ms\": 35909.732}", "{\"n\": 1855, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2681.74, \"learn_time_ms\": 35898.138}", "{\"n\": 1856, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2681.74, \"learn_time_ms\": 35888.704}", "{\"n\": 1857, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2696.21, \"learn_time_ms\": 35887.065}", "{\"n\": 1858, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2687.9, \"learn_time_ms\": 35916.72}", "{\"n\": 1859, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2687.9, \"learn_time_ms\": 35917.562}", "{\"n\": 1860, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2687.9, \"learn_time_ms\": 35963.542}", "{\"n\": 1861, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2687.9, \"learn_time_ms\": 35928.027}", "{\"n\": 1862, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2673.16, \"learn_time_ms\": 35936.683}", "{\"n\": 1863, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2660.46, \"learn_time_ms\": 35969.62}", "{\"n\": 1864, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2660.46, \"learn_time_ms\": 35955.914}", "{\"n\": 1865, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2660.46, \"learn_time_ms\": 35946.71}", "{\"n\": 1866, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2654.15, \"learn_time_ms\": 35957.753}", "{\"n\": 1867, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2675.48, \"learn_time_ms\": 35937.613}", "{\"n\": 1868, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2678.17, \"learn_time_ms\": 35933.798}", "{\"n\": 1869, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2678.17, \"learn_time_ms\": 35983.872}", "{\"n\": 1870, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2674.16, \"learn_time_ms\": 35930.954}", "{\"n\": 1871, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2666.13, \"learn_time_ms\": 35976.932}", "{\"n\": 1872, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2666.06, \"learn_time_ms\": 35966.058}", "{\"n\": 1873, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2666.06, \"learn_time_ms\": 35918.164}", "{\"n\": 1874, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2673.2, \"learn_time_ms\": 35940.947}", "{\"n\": 1875, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2673.3, \"learn_time_ms\": 35960.494}", "{\"n\": 1876, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.06, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2674.65, \"learn_time_ms\": 35909.087}", "{\"n\": 1877, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.04, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2678.76, \"learn_time_ms\": 35958.704}", "{\"n\": 1878, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2682.66, \"learn_time_ms\": 35919.245}", "{\"n\": 1879, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2670.42, \"learn_time_ms\": 35903.182}", "{\"n\": 1880, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2666.21, \"learn_time_ms\": 35924.191}", "{\"n\": 1881, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2673.31, \"learn_time_ms\": 35878.859}", "{\"n\": 1882, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.15, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2672.54, \"learn_time_ms\": 35914.672}", "{\"n\": 1883, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.13, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2671.22, \"learn_time_ms\": 35889.783}", "{\"n\": 1884, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.06, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2682.79, \"learn_time_ms\": 35865.011}", "{\"n\": 1885, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2678.05, \"learn_time_ms\": 35839.639}", "{\"n\": 1886, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2678.05, \"learn_time_ms\": 35852.075}", "{\"n\": 1887, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2695.4, \"learn_time_ms\": 35828.057}", "{\"n\": 1888, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2694.21, \"learn_time_ms\": 35842.688}", "{\"n\": 1889, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2694.41, \"learn_time_ms\": 35800.294}", "{\"n\": 1890, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2701.07, \"learn_time_ms\": 35789.878}", "{\"n\": 1891, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2694.51, \"learn_time_ms\": 35838.153}", "{\"n\": 1892, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2690.25, \"learn_time_ms\": 35765.073}", "{\"n\": 1893, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2687.16, \"learn_time_ms\": 35813.134}", "{\"n\": 1894, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2693.43, \"learn_time_ms\": 35814.71}", "{\"n\": 1895, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2681.78, \"learn_time_ms\": 35841.732}", "{\"n\": 1896, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2681.78, \"learn_time_ms\": 35824.531}", "{\"n\": 1897, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2684.12, \"learn_time_ms\": 35851.998}", "{\"n\": 1898, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2679.1, \"learn_time_ms\": 35854.016}", "{\"n\": 1899, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2671.68, \"learn_time_ms\": 35832.272}", "{\"n\": 1900, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2669.64, \"learn_time_ms\": 35849.823}", "{\"n\": 1901, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2665.21, \"learn_time_ms\": 35819.102}", "{\"n\": 1902, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2665.21, \"learn_time_ms\": 35837.808}", "{\"n\": 1903, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2668.6, \"learn_time_ms\": 35832.935}", "{\"n\": 1904, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2672.2, \"learn_time_ms\": 35788.984}", "{\"n\": 1905, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2674.13, \"learn_time_ms\": 35766.394}", "{\"n\": 1906, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2674.13, \"learn_time_ms\": 35814.284}", "{\"n\": 1907, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.04, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2671.73, \"learn_time_ms\": 35714.578}", "{\"n\": 1908, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.13, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2669.9, \"learn_time_ms\": 35700.05}", "{\"n\": 1909, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2677.4, \"learn_time_ms\": 35743.339}", "{\"n\": 1910, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2677.4, \"learn_time_ms\": 35736.65}", "{\"n\": 1911, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2670.74, \"learn_time_ms\": 35782.567}", "{\"n\": 1912, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2665.79, \"learn_time_ms\": 35779.638}", "{\"n\": 1913, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.08, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2682.02, \"learn_time_ms\": 35759.086}", "{\"n\": 1914, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.08, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2682.02, \"learn_time_ms\": 35812.464}", "{\"n\": 1915, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.08, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2682.02, \"learn_time_ms\": 35807.898}", "{\"n\": 1916, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.04, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2690.63, \"learn_time_ms\": 35790.024}", "{\"n\": 1917, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.06, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2688.16, \"learn_time_ms\": 35887.344}", "{\"n\": 1918, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.08, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2698.82, \"learn_time_ms\": 35873.975}", "{\"n\": 1919, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.04, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2706.99, \"learn_time_ms\": 35867.436}", "{\"n\": 1920, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.04, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2706.99, \"learn_time_ms\": 35862.391}", "{\"n\": 1921, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.06, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2705.34, \"learn_time_ms\": 35832.56}", "{\"n\": 1922, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2685.64, \"learn_time_ms\": 35846.141}", "{\"n\": 1923, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2685.64, \"learn_time_ms\": 35844.039}", "{\"n\": 1924, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2671.91, \"learn_time_ms\": 35798.242}", "{\"n\": 1925, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2675.14, \"learn_time_ms\": 35829.125}", "{\"n\": 1926, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2672.05, \"learn_time_ms\": 35834.413}", "{\"n\": 1927, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.24, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2685.45, \"learn_time_ms\": 35780.155}", "{\"n\": 1928, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.24, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2685.45, \"learn_time_ms\": 35837.526}", "{\"n\": 1929, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2681.81, \"learn_time_ms\": 35802.661}", "{\"n\": 1930, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.24, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2677.08, \"learn_time_ms\": 35799.582}", "{\"n\": 1931, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2681.36, \"learn_time_ms\": 35769.223}", "{\"n\": 1932, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2681.36, \"learn_time_ms\": 35790.324}", "{\"n\": 1933, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2689.38, \"learn_time_ms\": 35815.851}", "{\"n\": 1934, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2689.38, \"learn_time_ms\": 35842.043}", "{\"n\": 1935, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2692.51, \"learn_time_ms\": 35861.864}", "{\"n\": 1936, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2696.88, \"learn_time_ms\": 35874.186}", "{\"n\": 1937, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2700.89, \"learn_time_ms\": 35899.059}", "{\"n\": 1938, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.39, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2674.51, \"learn_time_ms\": 35824.031}", "{\"n\": 1939, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.39, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2674.51, \"learn_time_ms\": 35852.119}", "{\"n\": 1940, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2671.04, \"learn_time_ms\": 35834.714}", "{\"n\": 1941, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.54, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2664.71, \"learn_time_ms\": 35829.175}", "{\"n\": 1942, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.59, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2663.19, \"learn_time_ms\": 35836.599}", "{\"n\": 1943, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2659.75, \"learn_time_ms\": 35830.437}", "{\"n\": 1944, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2659.75, \"learn_time_ms\": 35821.518}", "{\"n\": 1945, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.62, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2657.66, \"learn_time_ms\": 35719.333}", "{\"n\": 1946, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.63, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2660.52, \"learn_time_ms\": 35698.201}", "{\"n\": 1947, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.63, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2659.61, \"learn_time_ms\": 35673.757}", "{\"n\": 1948, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2657.08, \"learn_time_ms\": 35724.461}", "{\"n\": 1949, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.68, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2655.66, \"learn_time_ms\": 35730.101}", "{\"n\": 1950, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.66, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2661.11, \"learn_time_ms\": 35723.747}", "{\"n\": 1951, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2663.16, \"learn_time_ms\": 35745.67}", "{\"n\": 1952, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.59, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2680.46, \"learn_time_ms\": 35725.956}", "{\"n\": 1953, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.59, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2680.46, \"learn_time_ms\": 35733.266}", "{\"n\": 1954, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.54, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2678.04, \"learn_time_ms\": 35760.194}", "{\"n\": 1955, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.52, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2675.23, \"learn_time_ms\": 35840.528}", "{\"n\": 1956, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.54, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2679.54, \"learn_time_ms\": 35820.081}", "{\"n\": 1957, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.59, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2674.28, \"learn_time_ms\": 35787.145}", "{\"n\": 1958, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.59, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2679.21, \"learn_time_ms\": 35777.055}", "{\"n\": 1959, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.58, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2684.85, \"learn_time_ms\": 35777.119}", "{\"n\": 1960, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.58, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2683.26, \"learn_time_ms\": 35797.505}", "{\"n\": 1961, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.58, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2685.83, \"learn_time_ms\": 35841.019}", "{\"n\": 1962, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.59, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2689.31, \"learn_time_ms\": 35792.904}", "{\"n\": 1963, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2692.93, \"learn_time_ms\": 35791.941}", "{\"n\": 1964, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2692.93, \"learn_time_ms\": 35745.127}", "{\"n\": 1965, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2713.29, \"learn_time_ms\": 35748.834}", "{\"n\": 1966, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.38, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2727.63, \"learn_time_ms\": 35789.455}", "{\"n\": 1967, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2730.9, \"learn_time_ms\": 35832.036}", "{\"n\": 1968, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2726.41, \"learn_time_ms\": 35799.05}", "{\"n\": 1969, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2726.41, \"learn_time_ms\": 35783.155}", "{\"n\": 1970, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2717.11, \"learn_time_ms\": 35766.713}", "{\"n\": 1971, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2724.81, \"learn_time_ms\": 35761.543}", "{\"n\": 1972, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2716.4, \"learn_time_ms\": 35811.072}", "{\"n\": 1973, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2716.49, \"learn_time_ms\": 35810.395}", "{\"n\": 1974, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2720.78, \"learn_time_ms\": 35865.8}", "{\"n\": 1975, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2718.88, \"learn_time_ms\": 35803.455}", "{\"n\": 1976, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2726.81, \"learn_time_ms\": 35788.637}", "{\"n\": 1977, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2726.94, \"learn_time_ms\": 35736.368}", "{\"n\": 1978, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2733.22, \"learn_time_ms\": 35767.054}", "{\"n\": 1979, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2734.94, \"learn_time_ms\": 35767.157}", "{\"n\": 1980, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2739.57, \"learn_time_ms\": 35776.133}", "{\"n\": 1981, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2739.18, \"learn_time_ms\": 35686.712}", "{\"n\": 1982, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2737.05, \"learn_time_ms\": 35679.487}", "{\"n\": 1983, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2740.23, \"learn_time_ms\": 35701.56}", "{\"n\": 1984, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2741.99, \"learn_time_ms\": 35679.76}", "{\"n\": 1985, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2733.03, \"learn_time_ms\": 35728.297}", "{\"n\": 1986, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2742.52, \"learn_time_ms\": 35741.602}", "{\"n\": 1987, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2751.46, \"learn_time_ms\": 35780.427}", "{\"n\": 1988, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2743.4, \"learn_time_ms\": 35765.798}", "{\"n\": 1989, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2749.79, \"learn_time_ms\": 35791.828}", "{\"n\": 1990, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2752.35, \"learn_time_ms\": 35792.789}", "{\"n\": 1991, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2751.06, \"learn_time_ms\": 35828.138}", "{\"n\": 1992, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2740.19, \"learn_time_ms\": 35802.225}", "{\"n\": 1993, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2740.19, \"learn_time_ms\": 35768.115}", "{\"n\": 1994, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2740.45, \"learn_time_ms\": 35783.951}", "{\"n\": 1995, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2744.22, \"learn_time_ms\": 35763.559}", "{\"n\": 1996, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2754.55, \"learn_time_ms\": 35758.639}", "{\"n\": 1997, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2745.61, \"learn_time_ms\": 35747.784}", "{\"n\": 1998, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2745.61, \"learn_time_ms\": 35806.329}", "{\"n\": 1999, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.95, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2736.19, \"learn_time_ms\": 35779.171}", "{\"n\": 2000, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2732.97, \"learn_time_ms\": 35788.99}"]["{\"n\": 2001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28058.766}", "{\"n\": 2002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27476.736}", "{\"n\": 2003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27320.916}", "{\"n\": 2004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27210.443}", "{\"n\": 2005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27145.951}", "{\"n\": 2006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27129.978}", "{\"n\": 2007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27141.945}", "{\"n\": 2008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27124.895}", "{\"n\": 2009, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -16.0, \"episode_len_mean\": 2359.0, \"learn_time_ms\": 27108.916}", "{\"n\": 2010, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.833333333333334, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2638.1666666666665, \"learn_time_ms\": 27134.039}", "{\"n\": 2011, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2799.75, \"learn_time_ms\": 27041.028}", "{\"n\": 2012, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2799.75, \"learn_time_ms\": 27071.795}", "{\"n\": 2013, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2789.9, \"learn_time_ms\": 27080.236}", "{\"n\": 2014, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.090909090909092, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2843.3636363636365, \"learn_time_ms\": 27112.285}", "{\"n\": 2015, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.571428571428571, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2816.1428571428573, \"learn_time_ms\": 27136.3}", "{\"n\": 2016, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.3125, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2833.0, \"learn_time_ms\": 27137.678}", "{\"n\": 2017, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.470588235294118, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2798.235294117647, \"learn_time_ms\": 27150.096}", "{\"n\": 2018, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.666666666666666, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2788.222222222222, \"learn_time_ms\": 27152.498}", "{\"n\": 2019, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.571428571428571, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2826.8571428571427, \"learn_time_ms\": 27179.817}", "{\"n\": 2020, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.833333333333334, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2813.3333333333335, \"learn_time_ms\": 27179.105}", "{\"n\": 2021, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.833333333333334, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2813.3333333333335, \"learn_time_ms\": 27161.695}", "{\"n\": 2022, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.923076923076923, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2795.153846153846, \"learn_time_ms\": 27150.485}", "{\"n\": 2023, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.11111111111111, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2767.5555555555557, \"learn_time_ms\": 27147.92}", "{\"n\": 2024, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2751.464285714286, \"learn_time_ms\": 27123.202}", "{\"n\": 2025, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9375, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2783.34375, \"learn_time_ms\": 27108.492}", "{\"n\": 2026, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.030303030303031, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2791.7272727272725, \"learn_time_ms\": 27128.794}", "{\"n\": 2027, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.17142857142857, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2785.4, \"learn_time_ms\": 27117.999}", "{\"n\": 2028, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.222222222222221, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2781.0, \"learn_time_ms\": 27160.798}", "{\"n\": 2029, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.216216216216216, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2785.4054054054054, \"learn_time_ms\": 27158.445}", "{\"n\": 2030, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.102564102564102, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2797.0, \"learn_time_ms\": 27164.958}", "{\"n\": 2031, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.951219512195122, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2801.512195121951, \"learn_time_ms\": 27203.988}", "{\"n\": 2032, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.953488372093023, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2795.9767441860463, \"learn_time_ms\": 27230.797}", "{\"n\": 2033, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.955555555555556, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2789.2444444444445, \"learn_time_ms\": 27245.746}", "{\"n\": 2034, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.934782608695652, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2793.1521739130435, \"learn_time_ms\": 27278.506}", "{\"n\": 2035, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2819.3541666666665, \"learn_time_ms\": 27293.031}", "{\"n\": 2036, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.705882352941176, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2824.0588235294117, \"learn_time_ms\": 27299.365}", "{\"n\": 2037, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.705882352941176, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2824.0588235294117, \"learn_time_ms\": 27307.736}", "{\"n\": 2038, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.716981132075471, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2817.830188679245, \"learn_time_ms\": 27242.066}", "{\"n\": 2039, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.672727272727272, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2816.4, \"learn_time_ms\": 27221.265}", "{\"n\": 2040, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.672413793103448, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2810.9137931034484, \"learn_time_ms\": 27215.479}", "{\"n\": 2041, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.672413793103448, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2810.9137931034484, \"learn_time_ms\": 27204.432}", "{\"n\": 2042, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.694915254237289, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2810.677966101695, \"learn_time_ms\": 27174.656}", "{\"n\": 2043, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.672131147540984, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2815.377049180328, \"learn_time_ms\": 27173.532}", "{\"n\": 2044, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65625, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2817.578125, \"learn_time_ms\": 27157.718}", "{\"n\": 2045, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.681818181818182, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2822.1666666666665, \"learn_time_ms\": 27169.087}", "{\"n\": 2046, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.671641791044776, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2829.5373134328356, \"learn_time_ms\": 27172.872}", "{\"n\": 2047, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.691176470588236, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2826.735294117647, \"learn_time_ms\": 27163.148}", "{\"n\": 2048, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.732394366197184, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2821.1408450704225, \"learn_time_ms\": 27204.979}", "{\"n\": 2049, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2822.0138888888887, \"learn_time_ms\": 27198.457}", "{\"n\": 2050, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.797297297297296, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2816.837837837838, \"learn_time_ms\": 27190.073}", "{\"n\": 2051, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.786666666666667, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2820.0, \"learn_time_ms\": 27189.462}", "{\"n\": 2052, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.85897435897436, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2807.897435897436, \"learn_time_ms\": 27204.33}", "{\"n\": 2053, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.835443037974683, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2809.481012658228, \"learn_time_ms\": 27247.678}", "{\"n\": 2054, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.829268292682928, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2806.939024390244, \"learn_time_ms\": 27232.889}", "{\"n\": 2055, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.829268292682928, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2806.939024390244, \"learn_time_ms\": 27269.522}", "{\"n\": 2056, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.869047619047619, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2805.0, \"learn_time_ms\": 27264.607}", "{\"n\": 2057, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.839080459770114, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2804.885057471264, \"learn_time_ms\": 27246.047}", "{\"n\": 2058, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.863636363636363, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2802.0, \"learn_time_ms\": 27266.228}", "{\"n\": 2059, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.842696629213483, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2805.8426966292136, \"learn_time_ms\": 27303.967}", "{\"n\": 2060, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.87912087912088, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2797.956043956044, \"learn_time_ms\": 27281.418}", "{\"n\": 2061, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.880434782608695, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2796.2608695652175, \"learn_time_ms\": 27224.6}", "{\"n\": 2062, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.904255319148936, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2792.31914893617, \"learn_time_ms\": 27255.196}", "{\"n\": 2063, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.84375, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2803.2604166666665, \"learn_time_ms\": 27227.78}", "{\"n\": 2064, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.84375, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2803.2604166666665, \"learn_time_ms\": 27285.502}", "{\"n\": 2065, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2810.22, \"learn_time_ms\": 27207.899}", "{\"n\": 2066, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2821.51, \"learn_time_ms\": 27193.775}", "{\"n\": 2067, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2839.72, \"learn_time_ms\": 27213.334}", "{\"n\": 2068, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.64, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2842.57, \"learn_time_ms\": 27204.042}", "{\"n\": 2069, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2838.82, \"learn_time_ms\": 27209.087}", "{\"n\": 2070, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2825.85, \"learn_time_ms\": 27205.107}", "{\"n\": 2071, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2823.01, \"learn_time_ms\": 27279.429}", "{\"n\": 2072, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2823.59, \"learn_time_ms\": 27252.999}", "{\"n\": 2073, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2817.72, \"learn_time_ms\": 27239.992}", "{\"n\": 2074, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2812.36, \"learn_time_ms\": 27179.217}", "{\"n\": 2075, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2812.36, \"learn_time_ms\": 27213.01}", "{\"n\": 2076, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2810.41, \"learn_time_ms\": 27220.635}", "{\"n\": 2077, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2810.41, \"learn_time_ms\": 27246.443}", "{\"n\": 2078, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2796.05, \"learn_time_ms\": 27230.752}", "{\"n\": 2079, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2798.01, \"learn_time_ms\": 27197.132}", "{\"n\": 2080, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2798.01, \"learn_time_ms\": 27245.077}", "{\"n\": 2081, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2812.17, \"learn_time_ms\": 27216.915}", "{\"n\": 2082, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2820.61, \"learn_time_ms\": 27229.884}", "{\"n\": 2083, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2807.0, \"learn_time_ms\": 27232.71}", "{\"n\": 2084, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2808.47, \"learn_time_ms\": 27208.226}", "{\"n\": 2085, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2809.57, \"learn_time_ms\": 27223.103}", "{\"n\": 2086, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2809.57, \"learn_time_ms\": 27212.481}", "{\"n\": 2087, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2808.05, \"learn_time_ms\": 27187.547}", "{\"n\": 2088, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2808.32, \"learn_time_ms\": 27203.824}", "{\"n\": 2089, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2808.32, \"learn_time_ms\": 27199.526}", "{\"n\": 2090, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2801.68, \"learn_time_ms\": 27177.632}", "{\"n\": 2091, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2801.04, \"learn_time_ms\": 27170.224}", "{\"n\": 2092, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2781.78, \"learn_time_ms\": 27108.862}", "{\"n\": 2093, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2780.28, \"learn_time_ms\": 27084.893}", "{\"n\": 2094, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2781.19, \"learn_time_ms\": 27127.23}", "{\"n\": 2095, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2778.33, \"learn_time_ms\": 27123.955}", "{\"n\": 2096, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2768.4, \"learn_time_ms\": 27128.099}", "{\"n\": 2097, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2768.4, \"learn_time_ms\": 27109.384}", "{\"n\": 2098, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2779.3, \"learn_time_ms\": 27171.751}", "{\"n\": 2099, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2779.3, \"learn_time_ms\": 27212.554}", "{\"n\": 2100, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2758.48, \"learn_time_ms\": 27181.632}", "{\"n\": 2101, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2760.09, \"learn_time_ms\": 27176.651}", "{\"n\": 2102, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2757.84, \"learn_time_ms\": 27225.4}", "{\"n\": 2103, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2746.21, \"learn_time_ms\": 27231.041}", "{\"n\": 2104, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2746.21, \"learn_time_ms\": 27242.831}", "{\"n\": 2105, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2751.42, \"learn_time_ms\": 27250.518}", "{\"n\": 2106, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2751.13, \"learn_time_ms\": 27268.381}", "{\"n\": 2107, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2751.7, \"learn_time_ms\": 27296.134}", "{\"n\": 2108, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2751.09, \"learn_time_ms\": 27212.336}", "{\"n\": 2109, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2753.02, \"learn_time_ms\": 27167.91}", "{\"n\": 2110, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2748.71, \"learn_time_ms\": 27181.622}", "{\"n\": 2111, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2743.13, \"learn_time_ms\": 27181.056}", "{\"n\": 2112, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2739.88, \"learn_time_ms\": 27147.867}", "{\"n\": 2113, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2741.22, \"learn_time_ms\": 27175.894}", "{\"n\": 2114, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2741.46, \"learn_time_ms\": 27232.968}", "{\"n\": 2115, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2744.03, \"learn_time_ms\": 27268.038}", "{\"n\": 2116, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2747.59, \"learn_time_ms\": 27285.148}", "{\"n\": 2117, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2744.92, \"learn_time_ms\": 27312.644}", "{\"n\": 2118, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2748.48, \"learn_time_ms\": 27327.812}", "{\"n\": 2119, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2751.33, \"learn_time_ms\": 27365.954}", "{\"n\": 2120, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2742.2, \"learn_time_ms\": 27378.172}", "{\"n\": 2121, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2733.47, \"learn_time_ms\": 27403.712}", "{\"n\": 2122, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2738.95, \"learn_time_ms\": 27410.093}", "{\"n\": 2123, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2732.87, \"learn_time_ms\": 27390.616}", "{\"n\": 2124, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2734.14, \"learn_time_ms\": 27324.645}", "{\"n\": 2125, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2731.11, \"learn_time_ms\": 27305.166}", "{\"n\": 2126, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2728.34, \"learn_time_ms\": 27299.468}", "{\"n\": 2127, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2725.14, \"learn_time_ms\": 27258.825}", "{\"n\": 2128, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2752.71, \"learn_time_ms\": 27279.737}", "{\"n\": 2129, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2746.53, \"learn_time_ms\": 27261.612}", "{\"n\": 2130, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2754.87, \"learn_time_ms\": 27244.338}", "{\"n\": 2131, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2765.82, \"learn_time_ms\": 27229.111}", "{\"n\": 2132, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2765.82, \"learn_time_ms\": 27243.621}", "{\"n\": 2133, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2770.09, \"learn_time_ms\": 27269.346}", "{\"n\": 2134, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2772.92, \"learn_time_ms\": 27309.371}", "{\"n\": 2135, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2775.66, \"learn_time_ms\": 27237.364}", "{\"n\": 2136, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2784.57, \"learn_time_ms\": 27204.286}", "{\"n\": 2137, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2784.57, \"learn_time_ms\": 27245.986}", "{\"n\": 2138, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2794.79, \"learn_time_ms\": 27221.406}", "{\"n\": 2139, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2798.16, \"learn_time_ms\": 27182.442}", "{\"n\": 2140, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2797.51, \"learn_time_ms\": 27208.852}", "{\"n\": 2141, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2806.86, \"learn_time_ms\": 27189.062}", "{\"n\": 2142, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2810.47, \"learn_time_ms\": 27220.794}", "{\"n\": 2143, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2809.23, \"learn_time_ms\": 27192.995}", "{\"n\": 2144, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2805.31, \"learn_time_ms\": 27160.795}", "{\"n\": 2145, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2796.45, \"learn_time_ms\": 27209.115}", "{\"n\": 2146, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2800.12, \"learn_time_ms\": 27194.83}", "{\"n\": 2147, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2800.12, \"learn_time_ms\": 27128.572}", "{\"n\": 2148, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2804.06, \"learn_time_ms\": 27109.205}", "{\"n\": 2149, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2809.84, \"learn_time_ms\": 27167.418}", "{\"n\": 2150, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2808.91, \"learn_time_ms\": 27162.534}", "{\"n\": 2151, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2808.91, \"learn_time_ms\": 27165.552}", "{\"n\": 2152, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2818.02, \"learn_time_ms\": 27163.458}", "{\"n\": 2153, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2828.32, \"learn_time_ms\": 27187.412}", "{\"n\": 2154, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2829.58, \"learn_time_ms\": 27211.077}", "{\"n\": 2155, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.09, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2838.13, \"learn_time_ms\": 27178.959}", "{\"n\": 2156, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.09, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2838.13, \"learn_time_ms\": 27181.328}", "{\"n\": 2157, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2813.22, \"learn_time_ms\": 27237.864}", "{\"n\": 2158, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2813.77, \"learn_time_ms\": 27272.228}", "{\"n\": 2159, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2813.77, \"learn_time_ms\": 27227.528}", "{\"n\": 2160, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2828.98, \"learn_time_ms\": 27238.359}", "{\"n\": 2161, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2828.98, \"learn_time_ms\": 27283.462}", "{\"n\": 2162, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.16, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2831.82, \"learn_time_ms\": 27303.049}", "{\"n\": 2163, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2839.48, \"learn_time_ms\": 27280.536}", "{\"n\": 2164, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.09, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2843.87, \"learn_time_ms\": 27216.324}", "{\"n\": 2165, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2837.13, \"learn_time_ms\": 27260.639}", "{\"n\": 2166, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2837.13, \"learn_time_ms\": 27298.463}", "{\"n\": 2167, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.06, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2845.2, \"learn_time_ms\": 27310.131}", "{\"n\": 2168, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2851.86, \"learn_time_ms\": 27331.794}", "{\"n\": 2169, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2855.46, \"learn_time_ms\": 27382.236}", "{\"n\": 2170, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2861.77, \"learn_time_ms\": 27330.566}", "{\"n\": 2171, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2866.75, \"learn_time_ms\": 27289.569}", "{\"n\": 2172, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2866.75, \"learn_time_ms\": 27247.688}", "{\"n\": 2173, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2871.07, \"learn_time_ms\": 27264.976}", "{\"n\": 2174, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2871.07, \"learn_time_ms\": 27339.417}", "{\"n\": 2175, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2850.53, \"learn_time_ms\": 27365.77}", "{\"n\": 2176, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.09, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2846.2, \"learn_time_ms\": 27354.113}", "{\"n\": 2177, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.09, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2851.32, \"learn_time_ms\": 27288.128}", "{\"n\": 2178, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2854.63, \"learn_time_ms\": 27262.507}", "{\"n\": 2179, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2854.63, \"learn_time_ms\": 27269.64}", "{\"n\": 2180, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2862.65, \"learn_time_ms\": 27334.699}", "{\"n\": 2181, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.1, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2866.51, \"learn_time_ms\": 27395.648}", "{\"n\": 2182, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.16, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2855.39, \"learn_time_ms\": 27384.677}", "{\"n\": 2183, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.16, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2855.39, \"learn_time_ms\": 27379.992}", "{\"n\": 2184, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2860.11, \"learn_time_ms\": 27353.58}", "{\"n\": 2185, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2863.44, \"learn_time_ms\": 27242.21}", "{\"n\": 2186, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2869.16, \"learn_time_ms\": 27204.928}", "{\"n\": 2187, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2848.6, \"learn_time_ms\": 27216.806}", "{\"n\": 2188, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2843.39, \"learn_time_ms\": 27214.265}", "{\"n\": 2189, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2843.39, \"learn_time_ms\": 27222.442}", "{\"n\": 2190, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2837.9, \"learn_time_ms\": 27196.098}", "{\"n\": 2191, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2834.86, \"learn_time_ms\": 27159.392}", "{\"n\": 2192, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2841.66, \"learn_time_ms\": 27123.993}", "{\"n\": 2193, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2846.24, \"learn_time_ms\": 27120.46}", "{\"n\": 2194, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2847.62, \"learn_time_ms\": 27125.901}", "{\"n\": 2195, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2838.88, \"learn_time_ms\": 27222.415}", "{\"n\": 2196, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2836.94, \"learn_time_ms\": 27281.541}", "{\"n\": 2197, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2836.94, \"learn_time_ms\": 27286.82}", "{\"n\": 2198, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2830.87, \"learn_time_ms\": 27245.269}", "{\"n\": 2199, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2830.87, \"learn_time_ms\": 27208.092}", "{\"n\": 2200, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2822.74, \"learn_time_ms\": 27213.987}", "{\"n\": 2201, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2815.04, \"learn_time_ms\": 27220.55}", "{\"n\": 2202, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2822.68, \"learn_time_ms\": 27278.285}", "{\"n\": 2203, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2824.23, \"learn_time_ms\": 27318.377}", "{\"n\": 2204, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2837.65, \"learn_time_ms\": 27338.313}", "{\"n\": 2205, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2840.44, \"learn_time_ms\": 27330.996}", "{\"n\": 2206, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2841.22, \"learn_time_ms\": 27299.181}", "{\"n\": 2207, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2841.22, \"learn_time_ms\": 27362.715}", "{\"n\": 2208, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2838.49, \"learn_time_ms\": 27379.571}", "{\"n\": 2209, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2838.49, \"learn_time_ms\": 27388.314}", "{\"n\": 2210, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2837.0, \"learn_time_ms\": 27430.658}", "{\"n\": 2211, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2826.91, \"learn_time_ms\": 27465.276}", "{\"n\": 2212, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2836.41, \"learn_time_ms\": 27464.674}", "{\"n\": 2213, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2836.46, \"learn_time_ms\": 27421.801}", "{\"n\": 2214, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2843.83, \"learn_time_ms\": 27383.007}", "{\"n\": 2215, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2833.04, \"learn_time_ms\": 27371.04}", "{\"n\": 2216, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2856.41, \"learn_time_ms\": 27383.84}", "{\"n\": 2217, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2862.13, \"learn_time_ms\": 27298.788}", "{\"n\": 2218, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2862.13, \"learn_time_ms\": 27291.151}", "{\"n\": 2219, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2876.51, \"learn_time_ms\": 27237.22}", "{\"n\": 2220, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2869.16, \"learn_time_ms\": 27216.26}", "{\"n\": 2221, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2860.25, \"learn_time_ms\": 27180.512}", "{\"n\": 2222, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2862.86, \"learn_time_ms\": 27147.289}", "{\"n\": 2223, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2857.49, \"learn_time_ms\": 27158.959}", "{\"n\": 2224, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2857.49, \"learn_time_ms\": 27172.099}", "{\"n\": 2225, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2853.78, \"learn_time_ms\": 27184.329}", "{\"n\": 2226, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2855.15, \"learn_time_ms\": 27158.893}", "{\"n\": 2227, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2856.69, \"learn_time_ms\": 27226.575}", "{\"n\": 2228, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2845.91, \"learn_time_ms\": 27255.877}", "{\"n\": 2229, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2845.91, \"learn_time_ms\": 27318.515}", "{\"n\": 2230, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2857.45, \"learn_time_ms\": 27298.578}", "{\"n\": 2231, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2868.88, \"learn_time_ms\": 27286.176}", "{\"n\": 2232, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2867.63, \"learn_time_ms\": 27372.759}", "{\"n\": 2233, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2867.33, \"learn_time_ms\": 27365.525}", "{\"n\": 2234, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2874.79, \"learn_time_ms\": 27386.0}", "{\"n\": 2235, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2889.22, \"learn_time_ms\": 27357.957}", "{\"n\": 2236, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2902.11, \"learn_time_ms\": 27363.164}", "{\"n\": 2237, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2911.86, \"learn_time_ms\": 27314.815}", "{\"n\": 2238, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2911.86, \"learn_time_ms\": 27313.68}", "{\"n\": 2239, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2900.17, \"learn_time_ms\": 27317.158}", "{\"n\": 2240, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2894.79, \"learn_time_ms\": 27291.195}", "{\"n\": 2241, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2894.79, \"learn_time_ms\": 27285.897}", "{\"n\": 2242, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2888.26, \"learn_time_ms\": 27193.897}", "{\"n\": 2243, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2867.93, \"learn_time_ms\": 27169.073}", "{\"n\": 2244, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2873.07, \"learn_time_ms\": 27134.504}", "{\"n\": 2245, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2873.07, \"learn_time_ms\": 27206.394}", "{\"n\": 2246, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2885.59, \"learn_time_ms\": 27195.167}", "{\"n\": 2247, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2885.15, \"learn_time_ms\": 27181.914}", "{\"n\": 2248, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.15, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2889.86, \"learn_time_ms\": 27169.658}", "{\"n\": 2249, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2881.71, \"learn_time_ms\": 27147.079}", "{\"n\": 2250, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2881.71, \"learn_time_ms\": 27159.472}", "{\"n\": 2251, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2884.42, \"learn_time_ms\": 27171.689}", "{\"n\": 2252, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2883.18, \"learn_time_ms\": 27161.587}", "{\"n\": 2253, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2881.87, \"learn_time_ms\": 27182.805}", "{\"n\": 2254, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2881.87, \"learn_time_ms\": 27215.304}", "{\"n\": 2255, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2881.87, \"learn_time_ms\": 27134.78}", "{\"n\": 2256, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.19, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2892.75, \"learn_time_ms\": 27164.405}", "{\"n\": 2257, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2893.66, \"learn_time_ms\": 27180.758}", "{\"n\": 2258, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2893.72, \"learn_time_ms\": 27194.054}", "{\"n\": 2259, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2893.72, \"learn_time_ms\": 27229.047}", "{\"n\": 2260, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.15, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2886.56, \"learn_time_ms\": 27232.606}", "{\"n\": 2261, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2884.2, \"learn_time_ms\": 27214.124}", "{\"n\": 2262, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2903.06, \"learn_time_ms\": 27277.462}", "{\"n\": 2263, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2895.3, \"learn_time_ms\": 27283.176}", "{\"n\": 2264, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2895.3, \"learn_time_ms\": 27270.53}", "{\"n\": 2265, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2894.39, \"learn_time_ms\": 27326.145}", "{\"n\": 2266, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2894.39, \"learn_time_ms\": 27314.965}", "{\"n\": 2267, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2883.22, \"learn_time_ms\": 27340.797}", "{\"n\": 2268, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2897.6, \"learn_time_ms\": 27349.415}", "{\"n\": 2269, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2909.23, \"learn_time_ms\": 27330.963}", "{\"n\": 2270, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2908.46, \"learn_time_ms\": 27368.61}", "{\"n\": 2271, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2906.17, \"learn_time_ms\": 27412.485}", "{\"n\": 2272, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2905.29, \"learn_time_ms\": 27405.257}", "{\"n\": 2273, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2896.22, \"learn_time_ms\": 27408.888}", "{\"n\": 2274, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2913.93, \"learn_time_ms\": 27391.334}", "{\"n\": 2275, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2913.93, \"learn_time_ms\": 27336.254}", "{\"n\": 2276, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2898.99, \"learn_time_ms\": 27330.589}", "{\"n\": 2277, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2898.53, \"learn_time_ms\": 27291.719}", "{\"n\": 2278, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2893.76, \"learn_time_ms\": 27254.245}", "{\"n\": 2279, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2880.23, \"learn_time_ms\": 27272.648}", "{\"n\": 2280, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2880.23, \"learn_time_ms\": 27269.969}", "{\"n\": 2281, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2883.18, \"learn_time_ms\": 27246.053}", "{\"n\": 2282, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2899.3, \"learn_time_ms\": 27240.115}", "{\"n\": 2283, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2911.44, \"learn_time_ms\": 27209.338}", "{\"n\": 2284, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2911.44, \"learn_time_ms\": 27283.592}", "{\"n\": 2285, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2911.44, \"learn_time_ms\": 27332.507}", "{\"n\": 2286, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2919.31, \"learn_time_ms\": 27352.757}", "{\"n\": 2287, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2915.25, \"learn_time_ms\": 27399.168}", "{\"n\": 2288, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2917.39, \"learn_time_ms\": 27400.529}", "{\"n\": 2289, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2915.92, \"learn_time_ms\": 27404.602}", "{\"n\": 2290, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2915.92, \"learn_time_ms\": 27388.391}", "{\"n\": 2291, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2906.12, \"learn_time_ms\": 27418.978}", "{\"n\": 2292, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2904.04, \"learn_time_ms\": 27443.636}", "{\"n\": 2293, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2906.49, \"learn_time_ms\": 27451.621}", "{\"n\": 2294, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2901.53, \"learn_time_ms\": 27408.572}", "{\"n\": 2295, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2907.72, \"learn_time_ms\": 27381.276}", "{\"n\": 2296, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2887.9, \"learn_time_ms\": 27374.766}", "{\"n\": 2297, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2890.29, \"learn_time_ms\": 27355.812}", "{\"n\": 2298, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2894.69, \"learn_time_ms\": 27339.973}", "{\"n\": 2299, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2894.69, \"learn_time_ms\": 27332.199}", "{\"n\": 2300, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2896.44, \"learn_time_ms\": 27296.36}", "{\"n\": 2301, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2920.15, \"learn_time_ms\": 27240.974}", "{\"n\": 2302, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2920.15, \"learn_time_ms\": 27204.026}", "{\"n\": 2303, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2923.07, \"learn_time_ms\": 27230.343}", "{\"n\": 2304, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2923.07, \"learn_time_ms\": 27235.025}", "{\"n\": 2305, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2930.58, \"learn_time_ms\": 27259.381}", "{\"n\": 2306, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2926.84, \"learn_time_ms\": 27248.8}", "{\"n\": 2307, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2926.84, \"learn_time_ms\": 27257.275}", "{\"n\": 2308, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2926.84, \"learn_time_ms\": 27308.701}", "{\"n\": 2309, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2919.32, \"learn_time_ms\": 27286.808}", "{\"n\": 2310, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2927.95, \"learn_time_ms\": 27343.217}", "{\"n\": 2311, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2932.49, \"learn_time_ms\": 27381.623}", "{\"n\": 2312, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2932.49, \"learn_time_ms\": 27389.852}", "{\"n\": 2313, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2933.98, \"learn_time_ms\": 27357.674}", "{\"n\": 2314, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2925.62, \"learn_time_ms\": 27319.07}", "{\"n\": 2315, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2917.28, \"learn_time_ms\": 27303.305}", "{\"n\": 2316, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2915.88, \"learn_time_ms\": 27300.236}", "{\"n\": 2317, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2915.88, \"learn_time_ms\": 27299.73}", "{\"n\": 2318, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2902.36, \"learn_time_ms\": 27307.818}", "{\"n\": 2319, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2903.55, \"learn_time_ms\": 27286.026}", "{\"n\": 2320, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2908.03, \"learn_time_ms\": 27249.672}", "{\"n\": 2321, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2906.97, \"learn_time_ms\": 27257.423}", "{\"n\": 2322, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2891.66, \"learn_time_ms\": 27274.186}", "{\"n\": 2323, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2901.47, \"learn_time_ms\": 27270.801}", "{\"n\": 2324, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2901.75, \"learn_time_ms\": 27300.27}", "{\"n\": 2325, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2905.01, \"learn_time_ms\": 27235.722}", "{\"n\": 2326, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2911.39, \"learn_time_ms\": 27242.699}", "{\"n\": 2327, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2911.39, \"learn_time_ms\": 27191.997}", "{\"n\": 2328, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2893.86, \"learn_time_ms\": 27163.405}", "{\"n\": 2329, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2894.13, \"learn_time_ms\": 27165.01}", "{\"n\": 2330, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2889.64, \"learn_time_ms\": 27182.845}", "{\"n\": 2331, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2889.5, \"learn_time_ms\": 27181.72}", "{\"n\": 2332, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2896.36, \"learn_time_ms\": 27189.034}", "{\"n\": 2333, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2901.15, \"learn_time_ms\": 27247.701}", "{\"n\": 2334, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2889.7, \"learn_time_ms\": 27225.485}", "{\"n\": 2335, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2889.7, \"learn_time_ms\": 27229.741}", "{\"n\": 2336, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2888.57, \"learn_time_ms\": 27230.213}", "{\"n\": 2337, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2876.75, \"learn_time_ms\": 27283.824}", "{\"n\": 2338, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2866.6, \"learn_time_ms\": 27281.61}", "{\"n\": 2339, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2877.09, \"learn_time_ms\": 27306.074}", "{\"n\": 2340, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2877.09, \"learn_time_ms\": 27288.15}", "{\"n\": 2341, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2873.5, \"learn_time_ms\": 27297.355}", "{\"n\": 2342, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2868.04, \"learn_time_ms\": 27292.525}", "{\"n\": 2343, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2864.96, \"learn_time_ms\": 27290.168}", "{\"n\": 2344, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2863.75, \"learn_time_ms\": 27352.496}", "{\"n\": 2345, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2859.77, \"learn_time_ms\": 27415.196}", "{\"n\": 2346, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2857.84, \"learn_time_ms\": 27408.848}", "{\"n\": 2347, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2857.31, \"learn_time_ms\": 27359.609}", "{\"n\": 2348, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2863.87, \"learn_time_ms\": 27364.596}", "{\"n\": 2349, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2859.99, \"learn_time_ms\": 27357.031}", "{\"n\": 2350, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2859.99, \"learn_time_ms\": 27333.901}", "{\"n\": 2351, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2860.93, \"learn_time_ms\": 27293.679}", "{\"n\": 2352, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2858.84, \"learn_time_ms\": 27277.234}", "{\"n\": 2353, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2854.27, \"learn_time_ms\": 27251.645}", "{\"n\": 2354, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2847.98, \"learn_time_ms\": 27190.984}", "{\"n\": 2355, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2847.98, \"learn_time_ms\": 27189.37}", "{\"n\": 2356, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2847.87, \"learn_time_ms\": 27214.113}", "{\"n\": 2357, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2847.2, \"learn_time_ms\": 27236.108}", "{\"n\": 2358, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.25, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2847.56, \"learn_time_ms\": 27191.109}", "{\"n\": 2359, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2838.91, \"learn_time_ms\": 27252.021}", "{\"n\": 2360, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2838.91, \"learn_time_ms\": 27231.407}", "{\"n\": 2361, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2838.91, \"learn_time_ms\": 27234.613}", "{\"n\": 2362, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2839.61, \"learn_time_ms\": 27229.409}", "{\"n\": 2363, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2839.25, \"learn_time_ms\": 27226.337}", "{\"n\": 2364, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2843.13, \"learn_time_ms\": 27189.734}", "{\"n\": 2365, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2843.13, \"learn_time_ms\": 27199.307}", "{\"n\": 2366, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2838.72, \"learn_time_ms\": 27248.961}", "{\"n\": 2367, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2837.44, \"learn_time_ms\": 27298.978}", "{\"n\": 2368, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2834.09, \"learn_time_ms\": 27360.896}", "{\"n\": 2369, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2835.42, \"learn_time_ms\": 27332.368}", "{\"n\": 2370, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2835.42, \"learn_time_ms\": 27334.094}", "{\"n\": 2371, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2834.8, \"learn_time_ms\": 27380.395}", "{\"n\": 2372, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2825.1, \"learn_time_ms\": 27353.761}", "{\"n\": 2373, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2834.04, \"learn_time_ms\": 27390.38}", "{\"n\": 2374, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2835.14, \"learn_time_ms\": 27441.544}", "{\"n\": 2375, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2837.57, \"learn_time_ms\": 27506.623}", "{\"n\": 2376, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2840.28, \"learn_time_ms\": 27422.496}", "{\"n\": 2377, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2835.06, \"learn_time_ms\": 27377.373}", "{\"n\": 2378, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2860.52, \"learn_time_ms\": 27386.229}", "{\"n\": 2379, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2855.13, \"learn_time_ms\": 27322.636}", "{\"n\": 2380, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2840.02, \"learn_time_ms\": 27329.045}", "{\"n\": 2381, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2840.02, \"learn_time_ms\": 27333.125}", "{\"n\": 2382, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2859.95, \"learn_time_ms\": 27352.019}", "{\"n\": 2383, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.39, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2853.75, \"learn_time_ms\": 27307.911}", "{\"n\": 2384, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2853.49, \"learn_time_ms\": 27316.922}", "{\"n\": 2385, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2855.36, \"learn_time_ms\": 27225.08}", "{\"n\": 2386, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2862.21, \"learn_time_ms\": 27265.638}", "{\"n\": 2387, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2862.21, \"learn_time_ms\": 27285.788}", "{\"n\": 2388, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2861.62, \"learn_time_ms\": 27273.437}", "{\"n\": 2389, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2865.86, \"learn_time_ms\": 27274.763}", "{\"n\": 2390, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.23, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2870.9, \"learn_time_ms\": 27304.888}", "{\"n\": 2391, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2872.31, \"learn_time_ms\": 27266.22}", "{\"n\": 2392, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.23, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2860.68, \"learn_time_ms\": 27298.289}", "{\"n\": 2393, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2852.13, \"learn_time_ms\": 27271.618}", "{\"n\": 2394, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.12, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2874.5, \"learn_time_ms\": 27224.247}", "{\"n\": 2395, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.12, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2875.84, \"learn_time_ms\": 27233.701}", "{\"n\": 2396, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2881.87, \"learn_time_ms\": 27257.837}", "{\"n\": 2397, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2881.51, \"learn_time_ms\": 27187.7}", "{\"n\": 2398, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2897.38, \"learn_time_ms\": 27194.011}", "{\"n\": 2399, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2909.51, \"learn_time_ms\": 27190.897}", "{\"n\": 2400, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2909.31, \"learn_time_ms\": 27189.129}", "{\"n\": 2401, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2914.49, \"learn_time_ms\": 27145.785}", "{\"n\": 2402, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2909.96, \"learn_time_ms\": 27174.272}", "{\"n\": 2403, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2909.96, \"learn_time_ms\": 27203.631}", "{\"n\": 2404, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2924.15, \"learn_time_ms\": 27221.093}", "{\"n\": 2405, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2931.65, \"learn_time_ms\": 27213.277}", "{\"n\": 2406, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2933.98, \"learn_time_ms\": 27169.355}", "{\"n\": 2407, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2943.98, \"learn_time_ms\": 27247.807}", "{\"n\": 2408, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2951.45, \"learn_time_ms\": 27298.276}", "{\"n\": 2409, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2960.11, \"learn_time_ms\": 27346.437}", "{\"n\": 2410, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2948.7, \"learn_time_ms\": 27401.581}", "{\"n\": 2411, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2962.89, \"learn_time_ms\": 27517.598}", "{\"n\": 2412, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2966.45, \"learn_time_ms\": 27510.396}", "{\"n\": 2413, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2966.45, \"learn_time_ms\": 27577.181}", "{\"n\": 2414, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2957.62, \"learn_time_ms\": 27602.773}", "{\"n\": 2415, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2974.73, \"learn_time_ms\": 27651.117}", "{\"n\": 2416, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2986.2, \"learn_time_ms\": 27706.338}", "{\"n\": 2417, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2970.86, \"learn_time_ms\": 27663.281}", "{\"n\": 2418, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2963.0, \"learn_time_ms\": 27621.972}", "{\"n\": 2419, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2962.41, \"learn_time_ms\": 27645.93}", "{\"n\": 2420, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2955.82, \"learn_time_ms\": 27619.694}", "{\"n\": 2421, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2957.48, \"learn_time_ms\": 27644.804}", "{\"n\": 2422, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2957.48, \"learn_time_ms\": 27625.093}", "{\"n\": 2423, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2950.56, \"learn_time_ms\": 27554.416}", "{\"n\": 2424, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2947.01, \"learn_time_ms\": 27539.638}", "{\"n\": 2425, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2943.5, \"learn_time_ms\": 27523.509}", "{\"n\": 2426, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2944.18, \"learn_time_ms\": 27434.305}", "{\"n\": 2427, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2947.55, \"learn_time_ms\": 27479.573}", "{\"n\": 2428, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2947.55, \"learn_time_ms\": 27482.881}", "{\"n\": 2429, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2970.87, \"learn_time_ms\": 27467.859}", "{\"n\": 2430, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2971.7, \"learn_time_ms\": 27446.94}", "{\"n\": 2431, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2971.66, \"learn_time_ms\": 27353.306}", "{\"n\": 2432, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2972.01, \"learn_time_ms\": 27345.744}", "{\"n\": 2433, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2974.05, \"learn_time_ms\": 27396.542}", "{\"n\": 2434, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2984.91, \"learn_time_ms\": 27390.079}", "{\"n\": 2435, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2979.06, \"learn_time_ms\": 27325.623}", "{\"n\": 2436, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2992.74, \"learn_time_ms\": 27382.749}", "{\"n\": 2437, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2995.87, \"learn_time_ms\": 27315.317}", "{\"n\": 2438, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2990.4, \"learn_time_ms\": 27341.178}", "{\"n\": 2439, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3011.3, \"learn_time_ms\": 27359.095}", "{\"n\": 2440, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3001.08, \"learn_time_ms\": 27350.524}", "{\"n\": 2441, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3002.73, \"learn_time_ms\": 27331.831}", "{\"n\": 2442, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3009.5, \"learn_time_ms\": 27302.623}", "{\"n\": 2443, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3009.5, \"learn_time_ms\": 27228.972}", "{\"n\": 2444, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3016.89, \"learn_time_ms\": 27247.752}", "{\"n\": 2445, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3012.3, \"learn_time_ms\": 27263.887}", "{\"n\": 2446, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3014.64, \"learn_time_ms\": 27301.359}", "{\"n\": 2447, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3020.79, \"learn_time_ms\": 27355.484}", "{\"n\": 2448, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3020.79, \"learn_time_ms\": 27321.055}", "{\"n\": 2449, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3025.84, \"learn_time_ms\": 27255.238}", "{\"n\": 2450, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3019.82, \"learn_time_ms\": 27262.451}", "{\"n\": 2451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3029.99, \"learn_time_ms\": 27313.543}", "{\"n\": 2452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3042.8, \"learn_time_ms\": 27306.701}", "{\"n\": 2453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3042.8, \"learn_time_ms\": 27348.909}", "{\"n\": 2454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3049.99, \"learn_time_ms\": 27377.875}", "{\"n\": 2455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3049.99, \"learn_time_ms\": 27412.192}", "{\"n\": 2456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3057.71, \"learn_time_ms\": 27341.103}", "{\"n\": 2457, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3052.07, \"learn_time_ms\": 27370.699}", "{\"n\": 2458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3052.07, \"learn_time_ms\": 27331.303}", "{\"n\": 2459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3046.63, \"learn_time_ms\": 27323.142}", "{\"n\": 2460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3043.96, \"learn_time_ms\": 27292.436}", "{\"n\": 2461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3044.34, \"learn_time_ms\": 27316.402}", "{\"n\": 2462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3049.87, \"learn_time_ms\": 27331.209}", "{\"n\": 2463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3043.89, \"learn_time_ms\": 27309.903}", "{\"n\": 2464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3045.95, \"learn_time_ms\": 27264.302}", "{\"n\": 2465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3033.67, \"learn_time_ms\": 27233.009}", "{\"n\": 2466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3030.14, \"learn_time_ms\": 27230.343}", "{\"n\": 2467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3025.14, \"learn_time_ms\": 27223.131}", "{\"n\": 2468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3010.47, \"learn_time_ms\": 27261.712}", "{\"n\": 2469, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3008.91, \"learn_time_ms\": 27310.722}", "{\"n\": 2470, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2992.11, \"learn_time_ms\": 27380.406}", "{\"n\": 2471, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2993.84, \"learn_time_ms\": 27325.151}", "{\"n\": 2472, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3004.42, \"learn_time_ms\": 27348.785}", "{\"n\": 2473, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3001.14, \"learn_time_ms\": 27331.558}", "{\"n\": 2474, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2996.38, \"learn_time_ms\": 27366.089}", "{\"n\": 2475, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2996.88, \"learn_time_ms\": 27377.79}", "{\"n\": 2476, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2994.27, \"learn_time_ms\": 27372.003}", "{\"n\": 2477, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2994.27, \"learn_time_ms\": 27335.178}", "{\"n\": 2478, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2985.25, \"learn_time_ms\": 27335.123}", "{\"n\": 2479, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.68, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2982.07, \"learn_time_ms\": 27337.818}", "{\"n\": 2480, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2982.34, \"learn_time_ms\": 27327.132}", "{\"n\": 2481, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2994.63, \"learn_time_ms\": 27354.225}", "{\"n\": 2482, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3009.61, \"learn_time_ms\": 27323.962}", "{\"n\": 2483, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3016.14, \"learn_time_ms\": 27379.442}", "{\"n\": 2484, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3025.59, \"learn_time_ms\": 27374.093}", "{\"n\": 2485, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.33, \"learn_time_ms\": 27406.202}", "{\"n\": 2486, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.33, \"learn_time_ms\": 27401.912}", "{\"n\": 2487, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3022.45, \"learn_time_ms\": 27437.779}", "{\"n\": 2488, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3032.15, \"learn_time_ms\": 27461.613}", "{\"n\": 2489, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3026.39, \"learn_time_ms\": 27477.863}", "{\"n\": 2490, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3021.81, \"learn_time_ms\": 27412.444}", "{\"n\": 2491, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3014.01, \"learn_time_ms\": 27400.549}", "{\"n\": 2492, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3006.74, \"learn_time_ms\": 27431.832}", "{\"n\": 2493, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3005.22, \"learn_time_ms\": 27398.647}", "{\"n\": 2494, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3005.22, \"learn_time_ms\": 27401.736}", "{\"n\": 2495, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3002.65, \"learn_time_ms\": 27350.087}", "{\"n\": 2496, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2991.15, \"learn_time_ms\": 27329.882}", "{\"n\": 2497, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2994.86, \"learn_time_ms\": 27288.494}", "{\"n\": 2498, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2996.11, \"learn_time_ms\": 27234.867}", "{\"n\": 2499, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2988.16, \"learn_time_ms\": 27159.562}", "{\"n\": 2500, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2988.16, \"learn_time_ms\": 27207.116}", "{\"n\": 2501, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2993.04, \"learn_time_ms\": 27224.25}", "{\"n\": 2502, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2999.43, \"learn_time_ms\": 27216.287}", "{\"n\": 2503, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2994.85, \"learn_time_ms\": 27269.128}", "{\"n\": 2504, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2998.07, \"learn_time_ms\": 27238.945}", "{\"n\": 2505, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3011.29, \"learn_time_ms\": 27282.447}", "{\"n\": 2506, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3011.29, \"learn_time_ms\": 27329.747}", "{\"n\": 2507, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3011.29, \"learn_time_ms\": 27334.343}", "{\"n\": 2508, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3010.47, \"learn_time_ms\": 27377.024}", "{\"n\": 2509, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3010.01, \"learn_time_ms\": 27405.086}", "{\"n\": 2510, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3000.0, \"learn_time_ms\": 27363.725}", "{\"n\": 2511, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3004.53, \"learn_time_ms\": 27358.363}", "{\"n\": 2512, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3004.53, \"learn_time_ms\": 27366.921}", "{\"n\": 2513, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2987.85, \"learn_time_ms\": 27288.78}", "{\"n\": 2514, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2987.85, \"learn_time_ms\": 27323.215}", "{\"n\": 2515, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2971.38, \"learn_time_ms\": 27310.038}", "{\"n\": 2516, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2980.05, \"learn_time_ms\": 27311.573}", "{\"n\": 2517, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2980.2, \"learn_time_ms\": 27314.66}", "{\"n\": 2518, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2979.1, \"learn_time_ms\": 27291.068}", "{\"n\": 2519, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2971.23, \"learn_time_ms\": 27331.663}", "{\"n\": 2520, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2980.78, \"learn_time_ms\": 27356.55}", "{\"n\": 2521, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2980.05, \"learn_time_ms\": 27354.075}", "{\"n\": 2522, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2980.05, \"learn_time_ms\": 27315.619}", "{\"n\": 2523, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2983.49, \"learn_time_ms\": 27408.515}", "{\"n\": 2524, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2973.14, \"learn_time_ms\": 27404.549}", "{\"n\": 2525, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2976.95, \"learn_time_ms\": 27369.425}", "{\"n\": 2526, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2976.99, \"learn_time_ms\": 27350.036}", "{\"n\": 2527, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2978.91, \"learn_time_ms\": 27417.209}", "{\"n\": 2528, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2986.26, \"learn_time_ms\": 27382.313}", "{\"n\": 2529, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2994.98, \"learn_time_ms\": 27365.132}", "{\"n\": 2530, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3015.58, \"learn_time_ms\": 27365.331}", "{\"n\": 2531, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3034.43, \"learn_time_ms\": 27361.304}", "{\"n\": 2532, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3041.65, \"learn_time_ms\": 27365.457}", "{\"n\": 2533, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3044.31, \"learn_time_ms\": 27299.401}", "{\"n\": 2534, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3049.21, \"learn_time_ms\": 27262.359}", "{\"n\": 2535, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3045.75, \"learn_time_ms\": 27315.113}", "{\"n\": 2536, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3045.75, \"learn_time_ms\": 27319.365}", "{\"n\": 2537, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3046.35, \"learn_time_ms\": 27262.137}", "{\"n\": 2538, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3039.85, \"learn_time_ms\": 27381.332}", "{\"n\": 2539, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3045.0, \"learn_time_ms\": 27335.447}", "{\"n\": 2540, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3051.62, \"learn_time_ms\": 27345.534}", "{\"n\": 2541, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3053.76, \"learn_time_ms\": 27302.192}", "{\"n\": 2542, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3052.23, \"learn_time_ms\": 27314.503}", "{\"n\": 2543, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3067.02, \"learn_time_ms\": 27359.257}", "{\"n\": 2544, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3063.74, \"learn_time_ms\": 27343.36}", "{\"n\": 2545, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3054.72, \"learn_time_ms\": 27303.329}", "{\"n\": 2546, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3054.72, \"learn_time_ms\": 27312.637}", "{\"n\": 2547, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3044.19, \"learn_time_ms\": 27329.472}", "{\"n\": 2548, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3049.98, \"learn_time_ms\": 27233.125}", "{\"n\": 2549, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3048.1, \"learn_time_ms\": 27242.254}", "{\"n\": 2550, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3052.25, \"learn_time_ms\": 27252.161}", "{\"n\": 2551, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3063.16, \"learn_time_ms\": 27317.841}", "{\"n\": 2552, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3055.35, \"learn_time_ms\": 27331.783}", "{\"n\": 2553, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3055.35, \"learn_time_ms\": 27267.489}", "{\"n\": 2554, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3057.97, \"learn_time_ms\": 27347.644}", "{\"n\": 2555, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3072.11, \"learn_time_ms\": 27403.55}", "{\"n\": 2556, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3078.12, \"learn_time_ms\": 27426.424}", "{\"n\": 2557, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3074.17, \"learn_time_ms\": 27400.872}", "{\"n\": 2558, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3074.17, \"learn_time_ms\": 27441.893}", "{\"n\": 2559, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3081.42, \"learn_time_ms\": 27489.573}", "{\"n\": 2560, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3097.8, \"learn_time_ms\": 27501.022}", "{\"n\": 2561, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3094.59, \"learn_time_ms\": 27524.482}", "{\"n\": 2562, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3098.02, \"learn_time_ms\": 27498.738}", "{\"n\": 2563, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3098.02, \"learn_time_ms\": 27521.952}", "{\"n\": 2564, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3095.43, \"learn_time_ms\": 27428.917}", "{\"n\": 2565, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3085.49, \"learn_time_ms\": 27367.717}", "{\"n\": 2566, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3090.31, \"learn_time_ms\": 27327.456}", "{\"n\": 2567, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3091.79, \"learn_time_ms\": 27318.405}", "{\"n\": 2568, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3098.72, \"learn_time_ms\": 27231.1}", "{\"n\": 2569, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3086.46, \"learn_time_ms\": 27191.168}", "{\"n\": 2570, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3077.89, \"learn_time_ms\": 27176.24}", "{\"n\": 2571, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3085.25, \"learn_time_ms\": 27109.611}", "{\"n\": 2572, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3083.27, \"learn_time_ms\": 27120.911}", "{\"n\": 2573, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3087.24, \"learn_time_ms\": 27088.443}", "{\"n\": 2574, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3083.14, \"learn_time_ms\": 27113.797}", "{\"n\": 2575, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3098.97, \"learn_time_ms\": 27137.985}", "{\"n\": 2576, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3109.18, \"learn_time_ms\": 27172.55}", "{\"n\": 2577, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3103.62, \"learn_time_ms\": 27216.83}", "{\"n\": 2578, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3107.26, \"learn_time_ms\": 27312.345}", "{\"n\": 2579, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3100.9, \"learn_time_ms\": 27343.294}", "{\"n\": 2580, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3106.12, \"learn_time_ms\": 27335.228}", "{\"n\": 2581, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3105.92, \"learn_time_ms\": 27314.428}", "{\"n\": 2582, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3115.51, \"learn_time_ms\": 27323.405}", "{\"n\": 2583, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3111.64, \"learn_time_ms\": 27376.98}", "{\"n\": 2584, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3108.05, \"learn_time_ms\": 27436.879}", "{\"n\": 2585, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3109.38, \"learn_time_ms\": 27425.509}", "{\"n\": 2586, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3109.38, \"learn_time_ms\": 27399.143}", "{\"n\": 2587, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3111.58, \"learn_time_ms\": 27349.534}", "{\"n\": 2588, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3106.21, \"learn_time_ms\": 27318.244}", "{\"n\": 2589, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3111.03, \"learn_time_ms\": 27314.848}", "{\"n\": 2590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3100.38, \"learn_time_ms\": 27290.114}", "{\"n\": 2591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3095.83, \"learn_time_ms\": 27289.386}", "{\"n\": 2592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3095.83, \"learn_time_ms\": 27321.714}", "{\"n\": 2593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3095.21, \"learn_time_ms\": 27299.041}", "{\"n\": 2594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3077.01, \"learn_time_ms\": 27232.335}", "{\"n\": 2595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3094.86, \"learn_time_ms\": 27275.383}", "{\"n\": 2596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3085.74, \"learn_time_ms\": 27255.42}", "{\"n\": 2597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3085.74, \"learn_time_ms\": 27259.928}", "{\"n\": 2598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3095.74, \"learn_time_ms\": 27249.349}", "{\"n\": 2599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3092.37, \"learn_time_ms\": 27272.066}", "{\"n\": 2600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3089.96, \"learn_time_ms\": 27296.7}", "{\"n\": 2601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3100.14, \"learn_time_ms\": 27279.854}", "{\"n\": 2602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3100.14, \"learn_time_ms\": 27227.439}", "{\"n\": 2603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3109.3, \"learn_time_ms\": 27192.024}", "{\"n\": 2604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3109.3, \"learn_time_ms\": 27217.656}", "{\"n\": 2605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3116.72, \"learn_time_ms\": 27163.836}", "{\"n\": 2606, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3122.86, \"learn_time_ms\": 27175.775}", "{\"n\": 2607, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3124.61, \"learn_time_ms\": 27223.406}", "{\"n\": 2608, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3109.74, \"learn_time_ms\": 27242.058}", "{\"n\": 2609, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3110.61, \"learn_time_ms\": 27207.977}", "{\"n\": 2610, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3107.01, \"learn_time_ms\": 27196.154}", "{\"n\": 2611, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3111.82, \"learn_time_ms\": 27246.547}", "{\"n\": 2612, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3119.88, \"learn_time_ms\": 27256.422}", "{\"n\": 2613, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3118.26, \"learn_time_ms\": 27269.985}", "{\"n\": 2614, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3118.0, \"learn_time_ms\": 27281.52}", "{\"n\": 2615, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3131.78, \"learn_time_ms\": 27275.781}", "{\"n\": 2616, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3133.62, \"learn_time_ms\": 27288.379}", "{\"n\": 2617, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3128.95, \"learn_time_ms\": 27273.214}", "{\"n\": 2618, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3136.02, \"learn_time_ms\": 27282.053}", "{\"n\": 2619, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3131.27, \"learn_time_ms\": 27260.489}", "{\"n\": 2620, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3136.31, \"learn_time_ms\": 27239.807}", "{\"n\": 2621, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3136.31, \"learn_time_ms\": 27259.168}", "{\"n\": 2622, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3132.65, \"learn_time_ms\": 27264.555}", "{\"n\": 2623, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3135.48, \"learn_time_ms\": 27321.502}", "{\"n\": 2624, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3135.48, \"learn_time_ms\": 27310.685}", "{\"n\": 2625, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3129.7, \"learn_time_ms\": 27352.733}", "{\"n\": 2626, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3124.63, \"learn_time_ms\": 27349.368}", "{\"n\": 2627, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3119.61, \"learn_time_ms\": 27394.911}", "{\"n\": 2628, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3106.77, \"learn_time_ms\": 27344.059}", "{\"n\": 2629, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3110.18, \"learn_time_ms\": 27379.699}", "{\"n\": 2630, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3103.98, \"learn_time_ms\": 27378.554}", "{\"n\": 2631, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3105.56, \"learn_time_ms\": 27347.983}", "{\"n\": 2632, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3105.56, \"learn_time_ms\": 27336.221}", "{\"n\": 2633, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3105.43, \"learn_time_ms\": 27293.978}", "{\"n\": 2634, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3123.91, \"learn_time_ms\": 27318.223}", "{\"n\": 2635, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3121.03, \"learn_time_ms\": 27282.5}", "{\"n\": 2636, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3121.23, \"learn_time_ms\": 27288.455}", "{\"n\": 2637, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3121.23, \"learn_time_ms\": 27219.717}", "{\"n\": 2638, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3116.41, \"learn_time_ms\": 27316.327}", "{\"n\": 2639, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3100.91, \"learn_time_ms\": 27285.95}", "{\"n\": 2640, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3103.34, \"learn_time_ms\": 27315.271}", "{\"n\": 2641, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3100.01, \"learn_time_ms\": 27338.628}", "{\"n\": 2642, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3097.14, \"learn_time_ms\": 27367.044}", "{\"n\": 2643, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3098.46, \"learn_time_ms\": 27348.839}", "{\"n\": 2644, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3092.15, \"learn_time_ms\": 27332.226}", "{\"n\": 2645, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3083.96, \"learn_time_ms\": 27351.114}", "{\"n\": 2646, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3085.48, \"learn_time_ms\": 27333.35}", "{\"n\": 2647, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3085.99, \"learn_time_ms\": 27339.112}", "{\"n\": 2648, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3087.92, \"learn_time_ms\": 27248.462}", "{\"n\": 2649, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3087.92, \"learn_time_ms\": 27336.179}", "{\"n\": 2650, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3087.92, \"learn_time_ms\": 27317.261}", "{\"n\": 2651, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3087.71, \"learn_time_ms\": 27260.997}", "{\"n\": 2652, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3096.24, \"learn_time_ms\": 27226.926}", "{\"n\": 2653, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3083.78, \"learn_time_ms\": 27219.896}", "{\"n\": 2654, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3079.26, \"learn_time_ms\": 27174.3}", "{\"n\": 2655, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3079.26, \"learn_time_ms\": 27161.728}", "{\"n\": 2656, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3080.01, \"learn_time_ms\": 27207.332}", "{\"n\": 2657, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3074.02, \"learn_time_ms\": 27218.417}", "{\"n\": 2658, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3057.04, \"learn_time_ms\": 27266.307}", "{\"n\": 2659, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3065.38, \"learn_time_ms\": 27194.761}", "{\"n\": 2660, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3065.38, \"learn_time_ms\": 27194.266}", "{\"n\": 2661, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3060.92, \"learn_time_ms\": 27215.238}", "{\"n\": 2662, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3056.56, \"learn_time_ms\": 27244.602}", "{\"n\": 2663, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3052.04, \"learn_time_ms\": 27350.304}", "{\"n\": 2664, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3054.57, \"learn_time_ms\": 27377.856}", "{\"n\": 2665, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3054.57, \"learn_time_ms\": 27397.778}", "{\"n\": 2666, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3048.88, \"learn_time_ms\": 27395.098}", "{\"n\": 2667, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3050.86, \"learn_time_ms\": 27360.83}", "{\"n\": 2668, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3032.89, \"learn_time_ms\": 27278.518}", "{\"n\": 2669, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3030.46, \"learn_time_ms\": 27249.649}", "{\"n\": 2670, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.13, \"learn_time_ms\": 27258.972}", "{\"n\": 2671, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3025.9, \"learn_time_ms\": 27245.985}", "{\"n\": 2672, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.18, \"learn_time_ms\": 27245.848}", "{\"n\": 2673, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.53, \"learn_time_ms\": 27202.693}", "{\"n\": 2674, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3040.79, \"learn_time_ms\": 27219.747}", "{\"n\": 2675, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.58, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3045.55, \"learn_time_ms\": 27227.97}", "{\"n\": 2676, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3046.4, \"learn_time_ms\": 27194.716}", "{\"n\": 2677, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3046.55, \"learn_time_ms\": 27239.939}", "{\"n\": 2678, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3037.69, \"learn_time_ms\": 27291.564}", "{\"n\": 2679, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3037.69, \"learn_time_ms\": 27331.147}", "{\"n\": 2680, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3045.13, \"learn_time_ms\": 27315.569}", "{\"n\": 2681, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3038.33, \"learn_time_ms\": 27329.125}", "{\"n\": 2682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3045.68, \"learn_time_ms\": 27314.565}", "{\"n\": 2683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3047.16, \"learn_time_ms\": 27294.315}", "{\"n\": 2684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3043.29, \"learn_time_ms\": 27285.976}", "{\"n\": 2685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3052.46, \"learn_time_ms\": 27292.129}", "{\"n\": 2686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3044.76, \"learn_time_ms\": 27292.072}", "{\"n\": 2687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3051.86, \"learn_time_ms\": 27342.114}", "{\"n\": 2688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3051.75, \"learn_time_ms\": 27315.467}", "{\"n\": 2689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3046.23, \"learn_time_ms\": 27297.299}", "{\"n\": 2690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3053.26, \"learn_time_ms\": 27299.282}", "{\"n\": 2691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3069.35, \"learn_time_ms\": 27273.044}", "{\"n\": 2692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3071.6, \"learn_time_ms\": 27246.605}", "{\"n\": 2693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3082.46, \"learn_time_ms\": 27236.719}", "{\"n\": 2694, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3070.03, \"learn_time_ms\": 27180.989}", "{\"n\": 2695, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3070.74, \"learn_time_ms\": 27196.654}", "{\"n\": 2696, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3070.6, \"learn_time_ms\": 27260.69}", "{\"n\": 2697, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3063.61, \"learn_time_ms\": 27147.085}", "{\"n\": 2698, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3059.18, \"learn_time_ms\": 27210.864}", "{\"n\": 2699, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3058.91, \"learn_time_ms\": 27243.601}", "{\"n\": 2700, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3052.39, \"learn_time_ms\": 27240.238}", "{\"n\": 2701, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3050.06, \"learn_time_ms\": 27300.38}", "{\"n\": 2702, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3050.01, \"learn_time_ms\": 27326.426}", "{\"n\": 2703, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3058.72, \"learn_time_ms\": 27328.95}", "{\"n\": 2704, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3052.41, \"learn_time_ms\": 27384.79}", "{\"n\": 2705, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3066.94, \"learn_time_ms\": 27356.289}", "{\"n\": 2706, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3067.34, \"learn_time_ms\": 27279.261}", "{\"n\": 2707, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3076.56, \"learn_time_ms\": 27332.878}", "{\"n\": 2708, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3077.39, \"learn_time_ms\": 27310.821}", "{\"n\": 2709, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3073.9, \"learn_time_ms\": 27282.666}", "{\"n\": 2710, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3069.59, \"learn_time_ms\": 27328.561}", "{\"n\": 2711, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3079.82, \"learn_time_ms\": 27287.696}", "{\"n\": 2712, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3077.62, \"learn_time_ms\": 27330.449}", "{\"n\": 2713, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3085.79, \"learn_time_ms\": 27357.939}", "{\"n\": 2714, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3085.79, \"learn_time_ms\": 27384.924}", "{\"n\": 2715, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3072.93, \"learn_time_ms\": 27413.934}", "{\"n\": 2716, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3072.93, \"learn_time_ms\": 27450.889}", "{\"n\": 2717, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3077.53, \"learn_time_ms\": 27439.078}", "{\"n\": 2718, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3098.97, \"learn_time_ms\": 27442.364}", "{\"n\": 2719, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3098.97, \"learn_time_ms\": 27424.592}", "{\"n\": 2720, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3102.96, \"learn_time_ms\": 27358.259}", "{\"n\": 2721, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3102.96, \"learn_time_ms\": 27385.905}", "{\"n\": 2722, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3113.76, \"learn_time_ms\": 27390.422}", "{\"n\": 2723, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3105.34, \"learn_time_ms\": 27341.016}", "{\"n\": 2724, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3103.79, \"learn_time_ms\": 27318.063}", "{\"n\": 2725, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3102.25, \"learn_time_ms\": 27267.304}", "{\"n\": 2726, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3101.07, \"learn_time_ms\": 27238.635}", "{\"n\": 2727, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3101.07, \"learn_time_ms\": 27189.251}", "{\"n\": 2728, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3134.48, \"learn_time_ms\": 27220.047}", "{\"n\": 2729, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3135.93, \"learn_time_ms\": 27239.511}", "{\"n\": 2730, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.93, \"learn_time_ms\": 27302.13}", "{\"n\": 2731, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.93, \"learn_time_ms\": 27330.648}", "{\"n\": 2732, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3127.7, \"learn_time_ms\": 27265.04}", "{\"n\": 2733, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3124.51, \"learn_time_ms\": 27325.309}", "{\"n\": 2734, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.53, \"learn_time_ms\": 27291.162}", "{\"n\": 2735, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.53, \"learn_time_ms\": 27260.647}", "{\"n\": 2736, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.99, \"learn_time_ms\": 27264.321}", "{\"n\": 2737, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.84, \"learn_time_ms\": 27319.821}", "{\"n\": 2738, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.05, \"learn_time_ms\": 27286.156}", "{\"n\": 2739, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3146.3, \"learn_time_ms\": 27286.05}", "{\"n\": 2740, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.38, \"learn_time_ms\": 27258.913}", "{\"n\": 2741, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.38, \"learn_time_ms\": 27236.411}", "{\"n\": 2742, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.39, \"learn_time_ms\": 27262.269}", "{\"n\": 2743, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.58, \"learn_time_ms\": 27238.333}", "{\"n\": 2744, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3142.0, \"learn_time_ms\": 27226.622}", "{\"n\": 2745, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3140.85, \"learn_time_ms\": 27267.728}", "{\"n\": 2746, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.65, \"learn_time_ms\": 27255.789}", "{\"n\": 2747, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3139.38, \"learn_time_ms\": 27250.217}", "{\"n\": 2748, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.85, \"learn_time_ms\": 27228.682}", "{\"n\": 2749, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.85, \"learn_time_ms\": 27231.48}", "{\"n\": 2750, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.5, \"learn_time_ms\": 27222.16}", "{\"n\": 2751, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3139.64, \"learn_time_ms\": 27190.345}", "{\"n\": 2752, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3142.94, \"learn_time_ms\": 27183.241}", "{\"n\": 2753, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.54, \"learn_time_ms\": 27161.163}", "{\"n\": 2754, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.54, \"learn_time_ms\": 27212.677}", "{\"n\": 2755, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.54, \"learn_time_ms\": 27229.764}", "{\"n\": 2756, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.41, \"learn_time_ms\": 27268.317}", "{\"n\": 2757, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.12, \"learn_time_ms\": 27291.16}", "{\"n\": 2758, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.12, \"learn_time_ms\": 27313.508}", "{\"n\": 2759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.93, \"learn_time_ms\": 27318.861}", "{\"n\": 2760, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3162.01, \"learn_time_ms\": 27350.578}", "{\"n\": 2761, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.11, \"learn_time_ms\": 27362.597}", "{\"n\": 2762, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.08, \"learn_time_ms\": 27355.377}", "{\"n\": 2763, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.08, \"learn_time_ms\": 27355.639}", "{\"n\": 2764, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.08, \"learn_time_ms\": 27352.263}", "{\"n\": 2765, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3163.08, \"learn_time_ms\": 27321.326}", "{\"n\": 2766, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.49, \"learn_time_ms\": 27297.545}", "{\"n\": 2767, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.76, \"learn_time_ms\": 27263.99}", "{\"n\": 2768, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.83, \"learn_time_ms\": 27246.448}", "{\"n\": 2769, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.83, \"learn_time_ms\": 27234.601}", "{\"n\": 2770, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3164.83, \"learn_time_ms\": 27230.776}", "{\"n\": 2771, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3165.4, \"learn_time_ms\": 27222.589}", "{\"n\": 2772, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.11, \"learn_time_ms\": 27213.541}", "{\"n\": 2773, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.14, \"learn_time_ms\": 27205.323}", "{\"n\": 2774, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.14, \"learn_time_ms\": 27183.92}", "{\"n\": 2775, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.14, \"learn_time_ms\": 27213.561}", "{\"n\": 2776, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.04, \"learn_time_ms\": 27156.617}", "{\"n\": 2777, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.18, \"learn_time_ms\": 27189.208}", "{\"n\": 2778, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.9, \"learn_time_ms\": 27207.467}", "{\"n\": 2779, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.9, \"learn_time_ms\": 27201.332}", "{\"n\": 2780, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.37, \"learn_time_ms\": 27142.925}", "{\"n\": 2781, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.91, \"learn_time_ms\": 27174.738}", "{\"n\": 2782, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.19, \"learn_time_ms\": 27147.611}", "{\"n\": 2783, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.43, \"learn_time_ms\": 27164.855}", "{\"n\": 2784, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.27, \"learn_time_ms\": 27165.395}", "{\"n\": 2785, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.27, \"learn_time_ms\": 27132.934}", "{\"n\": 2786, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.2, \"learn_time_ms\": 27224.212}", "{\"n\": 2787, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.2, \"learn_time_ms\": 27182.063}", "{\"n\": 2788, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.2, \"learn_time_ms\": 27246.118}", "{\"n\": 2789, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.77, \"learn_time_ms\": 27249.146}", "{\"n\": 2790, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.77, \"learn_time_ms\": 27282.259}", "{\"n\": 2791, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.98, \"learn_time_ms\": 27184.462}", "{\"n\": 2792, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.05, \"learn_time_ms\": 27184.785}", "{\"n\": 2793, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.16, \"learn_time_ms\": 27177.207}", "{\"n\": 2794, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3205.46, \"learn_time_ms\": 27164.325}", "{\"n\": 2795, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.45, \"learn_time_ms\": 27203.241}", "{\"n\": 2796, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.69, \"learn_time_ms\": 27148.898}", "{\"n\": 2797, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.69, \"learn_time_ms\": 27127.487}", "{\"n\": 2798, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.41, \"learn_time_ms\": 27019.332}", "{\"n\": 2799, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.32, \"learn_time_ms\": 27004.863}", "{\"n\": 2800, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.82, \"learn_time_ms\": 26997.848}", "{\"n\": 2801, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.57, \"learn_time_ms\": 27079.838}", "{\"n\": 2802, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.95, \"learn_time_ms\": 27128.411}", "{\"n\": 2803, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.69, \"learn_time_ms\": 27152.042}", "{\"n\": 2804, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.41, \"learn_time_ms\": 27169.982}", "{\"n\": 2805, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.77, \"learn_time_ms\": 27103.167}", "{\"n\": 2806, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.68, \"learn_time_ms\": 27188.815}", "{\"n\": 2807, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.48, \"learn_time_ms\": 27218.121}", "{\"n\": 2808, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.08, \"learn_time_ms\": 27224.193}", "{\"n\": 2809, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.08, \"learn_time_ms\": 27236.848}", "{\"n\": 2810, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3202.38, \"learn_time_ms\": 27297.464}", "{\"n\": 2811, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.67, \"learn_time_ms\": 27285.477}", "{\"n\": 2812, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.84, \"learn_time_ms\": 27227.816}", "{\"n\": 2813, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.81, \"learn_time_ms\": 27184.706}", "{\"n\": 2814, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.18, \"learn_time_ms\": 27174.08}", "{\"n\": 2815, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.18, \"learn_time_ms\": 27212.434}", "{\"n\": 2816, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.56, \"learn_time_ms\": 27176.39}", "{\"n\": 2817, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.56, \"learn_time_ms\": 27156.572}", "{\"n\": 2818, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.59, \"learn_time_ms\": 27151.764}", "{\"n\": 2819, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.49, \"learn_time_ms\": 27126.906}", "{\"n\": 2820, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.6, \"learn_time_ms\": 27114.646}", "{\"n\": 2821, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3220.74, \"learn_time_ms\": 27118.799}", "{\"n\": 2822, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.7, \"learn_time_ms\": 27169.229}", "{\"n\": 2823, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.1, \"learn_time_ms\": 27201.746}", "{\"n\": 2824, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.75, \"learn_time_ms\": 27225.412}", "{\"n\": 2825, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.46, \"learn_time_ms\": 27287.101}", "{\"n\": 2826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3203.95, \"learn_time_ms\": 27231.738}", "{\"n\": 2827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.86, \"learn_time_ms\": 27270.287}", "{\"n\": 2828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.23, \"learn_time_ms\": 27264.205}", "{\"n\": 2829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.35, \"learn_time_ms\": 27331.724}", "{\"n\": 2830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.1, \"learn_time_ms\": 27403.318}", "{\"n\": 2831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3184.64, \"learn_time_ms\": 27422.95}", "{\"n\": 2832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.46, \"learn_time_ms\": 27414.197}", "{\"n\": 2833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.91, \"learn_time_ms\": 27426.357}", "{\"n\": 2834, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.4, \"learn_time_ms\": 27422.527}", "{\"n\": 2835, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.44, \"learn_time_ms\": 27371.349}", "{\"n\": 2836, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.05, \"learn_time_ms\": 27412.921}", "{\"n\": 2837, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.52, \"learn_time_ms\": 27373.998}", "{\"n\": 2838, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3165.92, \"learn_time_ms\": 27366.671}", "{\"n\": 2839, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.91, \"learn_time_ms\": 27283.432}", "{\"n\": 2840, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3147.4, \"learn_time_ms\": 27199.253}", "{\"n\": 2841, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3147.4, \"learn_time_ms\": 27169.072}", "{\"n\": 2842, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3136.4, \"learn_time_ms\": 27179.808}", "{\"n\": 2843, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3134.91, \"learn_time_ms\": 27184.671}", "{\"n\": 2844, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3134.91, \"learn_time_ms\": 27223.642}", "{\"n\": 2845, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3144.77, \"learn_time_ms\": 27264.119}", "{\"n\": 2846, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3144.77, \"learn_time_ms\": 27297.03}", "{\"n\": 2847, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3147.74, \"learn_time_ms\": 27283.742}", "{\"n\": 2848, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3147.65, \"learn_time_ms\": 27298.4}", "{\"n\": 2849, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3161.92, \"learn_time_ms\": 27353.364}", "{\"n\": 2850, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3167.12, \"learn_time_ms\": 27303.387}", "{\"n\": 2851, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3166.71, \"learn_time_ms\": 27298.252}", "{\"n\": 2852, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3177.93, \"learn_time_ms\": 27248.421}", "{\"n\": 2853, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3176.07, \"learn_time_ms\": 27203.018}", "{\"n\": 2854, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3174.55, \"learn_time_ms\": 27199.266}", "{\"n\": 2855, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3179.38, \"learn_time_ms\": 27166.133}", "{\"n\": 2856, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3190.14, \"learn_time_ms\": 27132.401}", "{\"n\": 2857, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3190.14, \"learn_time_ms\": 27169.657}", "{\"n\": 2858, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3191.2, \"learn_time_ms\": 27187.477}", "{\"n\": 2859, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3197.63, \"learn_time_ms\": 27141.174}", "{\"n\": 2860, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3186.05, \"learn_time_ms\": 27184.729}", "{\"n\": 2861, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3199.19, \"learn_time_ms\": 27191.986}", "{\"n\": 2862, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3199.19, \"learn_time_ms\": 27261.227}", "{\"n\": 2863, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3200.41, \"learn_time_ms\": 27328.549}", "{\"n\": 2864, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3200.41, \"learn_time_ms\": 27264.95}", "{\"n\": 2865, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3197.74, \"learn_time_ms\": 27219.347}", "{\"n\": 2866, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3192.83, \"learn_time_ms\": 27233.245}", "{\"n\": 2867, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3192.83, \"learn_time_ms\": 27229.004}", "{\"n\": 2868, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3193.79, \"learn_time_ms\": 27215.604}", "{\"n\": 2869, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3194.55, \"learn_time_ms\": 27249.178}", "{\"n\": 2870, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3206.15, \"learn_time_ms\": 27249.494}", "{\"n\": 2871, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3207.49, \"learn_time_ms\": 27215.522}", "{\"n\": 2872, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3207.49, \"learn_time_ms\": 27196.261}", "{\"n\": 2873, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3212.51, \"learn_time_ms\": 27102.715}", "{\"n\": 2874, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3201.96, \"learn_time_ms\": 27104.662}", "{\"n\": 2875, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3202.81, \"learn_time_ms\": 27114.511}", "{\"n\": 2876, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3198.8, \"learn_time_ms\": 27115.304}", "{\"n\": 2877, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3201.18, \"learn_time_ms\": 27100.568}", "{\"n\": 2878, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3206.31, \"learn_time_ms\": 27113.401}", "{\"n\": 2879, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3192.83, \"learn_time_ms\": 27095.406}", "{\"n\": 2880, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3193.03, \"learn_time_ms\": 27098.081}", "{\"n\": 2881, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3186.33, \"learn_time_ms\": 27127.564}", "{\"n\": 2882, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3191.71, \"learn_time_ms\": 27100.793}", "{\"n\": 2883, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3191.71, \"learn_time_ms\": 27148.111}", "{\"n\": 2884, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3171.65, \"learn_time_ms\": 27115.736}", "{\"n\": 2885, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3169.56, \"learn_time_ms\": 27132.45}", "{\"n\": 2886, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3169.56, \"learn_time_ms\": 27149.113}", "{\"n\": 2887, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3168.82, \"learn_time_ms\": 27156.867}", "{\"n\": 2888, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3168.97, \"learn_time_ms\": 27151.78}", "{\"n\": 2889, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3170.18, \"learn_time_ms\": 27152.562}", "{\"n\": 2890, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3162.72, \"learn_time_ms\": 27122.285}", "{\"n\": 2891, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3169.89, \"learn_time_ms\": 27121.306}", "{\"n\": 2892, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3167.92, \"learn_time_ms\": 27182.832}", "{\"n\": 2893, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3166.59, \"learn_time_ms\": 27154.364}", "{\"n\": 2894, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3157.64, \"learn_time_ms\": 27163.531}", "{\"n\": 2895, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3173.47, \"learn_time_ms\": 27184.384}", "{\"n\": 2896, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3179.93, \"learn_time_ms\": 27124.002}", "{\"n\": 2897, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3183.7, \"learn_time_ms\": 27133.818}", "{\"n\": 2898, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3187.4, \"learn_time_ms\": 27126.091}", "{\"n\": 2899, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3198.33, \"learn_time_ms\": 27135.17}", "{\"n\": 2900, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3190.86, \"learn_time_ms\": 27150.434}", "{\"n\": 2901, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3189.73, \"learn_time_ms\": 27138.461}", "{\"n\": 2902, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3183.57, \"learn_time_ms\": 27113.039}", "{\"n\": 2903, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3201.58, \"learn_time_ms\": 27146.405}", "{\"n\": 2904, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.44, \"learn_time_ms\": 27225.418}", "{\"n\": 2905, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.54, \"learn_time_ms\": 27210.228}", "{\"n\": 2906, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.9, \"learn_time_ms\": 27247.56}", "{\"n\": 2907, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.96, \"learn_time_ms\": 27251.786}", "{\"n\": 2908, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.64, \"learn_time_ms\": 27224.708}", "{\"n\": 2909, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.64, \"learn_time_ms\": 27243.089}", "{\"n\": 2910, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.64, \"learn_time_ms\": 27255.296}", "{\"n\": 2911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.12, \"learn_time_ms\": 27253.731}", "{\"n\": 2912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.68, \"learn_time_ms\": 27243.727}", "{\"n\": 2913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.74, \"learn_time_ms\": 27266.058}", "{\"n\": 2914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3238.74, \"learn_time_ms\": 27229.436}", "{\"n\": 2915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.34, \"learn_time_ms\": 27240.757}", "{\"n\": 2916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.81, \"learn_time_ms\": 27219.729}", "{\"n\": 2917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.73, \"learn_time_ms\": 27255.235}", "{\"n\": 2918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.0, \"learn_time_ms\": 27277.673}", "{\"n\": 2919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.0, \"learn_time_ms\": 27271.898}", "{\"n\": 2920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.0, \"learn_time_ms\": 27245.643}", "{\"n\": 2921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.61, \"learn_time_ms\": 27252.075}", "{\"n\": 2922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.99, \"learn_time_ms\": 27238.067}", "{\"n\": 2923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.7, \"learn_time_ms\": 27206.341}", "{\"n\": 2924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.19, \"learn_time_ms\": 27199.781}", "{\"n\": 2925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3210.07, \"learn_time_ms\": 27257.976}", "{\"n\": 2926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.6, \"learn_time_ms\": 27243.569}", "{\"n\": 2927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.88, \"learn_time_ms\": 27208.812}", "{\"n\": 2928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3219.81, \"learn_time_ms\": 27278.476}", "{\"n\": 2929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3212.32, \"learn_time_ms\": 27278.715}", "{\"n\": 2930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.58, \"learn_time_ms\": 27305.91}", "{\"n\": 2931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3200.88, \"learn_time_ms\": 27378.163}", "{\"n\": 2932, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.41, \"learn_time_ms\": 27401.076}", "{\"n\": 2933, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.9, \"learn_time_ms\": 27434.972}", "{\"n\": 2934, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.92, \"learn_time_ms\": 27411.407}", "{\"n\": 2935, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.92, \"learn_time_ms\": 27368.344}", "{\"n\": 2936, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.77, \"learn_time_ms\": 27335.511}", "{\"n\": 2937, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.77, \"learn_time_ms\": 27368.25}", "{\"n\": 2938, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3216.48, \"learn_time_ms\": 27313.093}", "{\"n\": 2939, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.82, \"learn_time_ms\": 27275.298}", "{\"n\": 2940, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.14, \"learn_time_ms\": 27266.765}", "{\"n\": 2941, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.97, \"learn_time_ms\": 27197.782}", "{\"n\": 2942, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.97, \"learn_time_ms\": 27186.889}", "{\"n\": 2943, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.97, \"learn_time_ms\": 27148.5}", "{\"n\": 2944, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.85, \"learn_time_ms\": 27174.944}", "{\"n\": 2945, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.44, \"learn_time_ms\": 27127.51}", "{\"n\": 2946, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.44, \"learn_time_ms\": 27151.404}", "{\"n\": 2947, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3195.44, \"learn_time_ms\": 27111.558}", "{\"n\": 2948, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3192.79, \"learn_time_ms\": 27104.001}", "{\"n\": 2949, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.36, \"learn_time_ms\": 27108.794}", "{\"n\": 2950, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.46, \"learn_time_ms\": 27129.415}", "{\"n\": 2951, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.46, \"learn_time_ms\": 27096.36}", "{\"n\": 2952, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.46, \"learn_time_ms\": 27062.162}", "{\"n\": 2953, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3187.24, \"learn_time_ms\": 27060.105}", "{\"n\": 2954, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3186.87, \"learn_time_ms\": 27031.642}", "{\"n\": 2955, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.85, \"learn_time_ms\": 27108.829}", "{\"n\": 2956, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.85, \"learn_time_ms\": 27091.186}", "{\"n\": 2957, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.22, \"learn_time_ms\": 27089.486}", "{\"n\": 2958, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3224.22, \"learn_time_ms\": 27091.447}", "{\"n\": 2959, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.63, \"learn_time_ms\": 27143.161}", "{\"n\": 2960, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.52, \"learn_time_ms\": 27124.999}", "{\"n\": 2961, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.55, \"learn_time_ms\": 27192.141}", "{\"n\": 2962, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.43, \"learn_time_ms\": 27218.451}", "{\"n\": 2963, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.43, \"learn_time_ms\": 27228.361}", "{\"n\": 2964, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.04, \"learn_time_ms\": 27239.079}", "{\"n\": 2965, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3223.04, \"learn_time_ms\": 27172.636}", "{\"n\": 2966, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.01, \"learn_time_ms\": 27192.703}", "{\"n\": 2967, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.83, \"learn_time_ms\": 27164.36}", "{\"n\": 2968, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.87, \"learn_time_ms\": 27185.115}", "{\"n\": 2969, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.7, \"learn_time_ms\": 27163.441}", "{\"n\": 2970, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3222.84, \"learn_time_ms\": 27192.539}", "{\"n\": 2971, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3220.31, \"learn_time_ms\": 27174.115}", "{\"n\": 2972, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3212.84, \"learn_time_ms\": 27258.945}", "{\"n\": 2973, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.85, \"learn_time_ms\": 27247.888}", "{\"n\": 2974, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.93, \"learn_time_ms\": 27233.244}", "{\"n\": 2975, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.93, \"learn_time_ms\": 27244.836}", "{\"n\": 2976, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.37, \"learn_time_ms\": 27332.649}", "{\"n\": 2977, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.23, \"learn_time_ms\": 27403.067}", "{\"n\": 2978, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.66, \"learn_time_ms\": 27441.632}", "{\"n\": 2979, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.66, \"learn_time_ms\": 27432.602}", "{\"n\": 2980, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.67, \"learn_time_ms\": 27440.063}", "{\"n\": 2981, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.67, \"learn_time_ms\": 27430.382}", "{\"n\": 2982, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.89, \"learn_time_ms\": 27331.619}", "{\"n\": 2983, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.91, \"learn_time_ms\": 27366.593}", "{\"n\": 2984, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.03, \"learn_time_ms\": 27391.016}", "{\"n\": 2985, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.2, \"learn_time_ms\": 27385.645}", "{\"n\": 2986, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.01, \"learn_time_ms\": 27304.153}", "{\"n\": 2987, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.81, \"learn_time_ms\": 27262.018}", "{\"n\": 2988, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.19, \"learn_time_ms\": 27166.439}", "{\"n\": 2989, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.58, \"learn_time_ms\": 27152.974}", "{\"n\": 2990, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.58, \"learn_time_ms\": 27086.806}", "{\"n\": 2991, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.02, \"learn_time_ms\": 27095.003}", "{\"n\": 2992, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.89, \"learn_time_ms\": 27129.516}", "{\"n\": 2993, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.0, \"learn_time_ms\": 27077.56}", "{\"n\": 2994, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.0, \"learn_time_ms\": 27087.304}", "{\"n\": 2995, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.1, \"learn_time_ms\": 27075.274}", "{\"n\": 2996, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.63, \"learn_time_ms\": 27109.941}", "{\"n\": 2997, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.76, \"learn_time_ms\": 27077.735}", "{\"n\": 2998, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.18, \"learn_time_ms\": 27145.404}", "{\"n\": 2999, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.18, \"learn_time_ms\": 27156.159}", "{\"n\": 3000, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.18, \"learn_time_ms\": 27180.03}"]["{\"n\": 3001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29830.522}", "{\"n\": 3002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29189.04}", "{\"n\": 3003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29019.106}", "{\"n\": 3004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28924.339}", "{\"n\": 3005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28839.296}", "{\"n\": 3006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28812.069}", "{\"n\": 3007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28765.478}", "{\"n\": 3008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28705.571}", "{\"n\": 3009, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2153.0, \"learn_time_ms\": 28699.919}", "{\"n\": 3010, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2153.0, \"learn_time_ms\": 28678.135}", "{\"n\": 3011, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -13.666666666666666, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2579.0, \"learn_time_ms\": 28558.389}", "{\"n\": 3012, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3320.5, \"learn_time_ms\": 28533.965}", "{\"n\": 3013, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3374.1111111111113, \"learn_time_ms\": 28516.862}", "{\"n\": 3014, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3374.1111111111113, \"learn_time_ms\": 28494.334}", "{\"n\": 3015, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.454545454545455, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3258.5454545454545, \"learn_time_ms\": 28495.694}", "{\"n\": 3016, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.666666666666666, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3212.5833333333335, \"learn_time_ms\": 28483.351}", "{\"n\": 3017, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.066666666666666, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3281.266666666667, \"learn_time_ms\": 28483.574}", "{\"n\": 3018, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.411764705882353, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3212.5882352941176, \"learn_time_ms\": 28473.986}", "{\"n\": 3019, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.411764705882353, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3212.5882352941176, \"learn_time_ms\": 28450.605}", "{\"n\": 3020, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.722222222222221, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3147.0555555555557, \"learn_time_ms\": 28440.043}", "{\"n\": 3021, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3158.5, \"learn_time_ms\": 28417.353}", "{\"n\": 3022, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.863636363636363, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3109.7272727272725, \"learn_time_ms\": 28421.611}", "{\"n\": 3023, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.958333333333334, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3097.375, \"learn_time_ms\": 28398.908}", "{\"n\": 3024, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3097.92, \"learn_time_ms\": 28417.218}", "{\"n\": 3025, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.692307692307692, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3128.0, \"learn_time_ms\": 28391.037}", "{\"n\": 3026, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74074074074074, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3130.5925925925926, \"learn_time_ms\": 28373.804}", "{\"n\": 3027, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.67741935483871, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3146.967741935484, \"learn_time_ms\": 28375.031}", "{\"n\": 3028, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65625, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3144.59375, \"learn_time_ms\": 28380.029}", "{\"n\": 3029, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.794117647058824, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3117.294117647059, \"learn_time_ms\": 28374.783}", "{\"n\": 3030, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.794117647058824, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3117.294117647059, \"learn_time_ms\": 28338.858}", "{\"n\": 3031, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.794117647058824, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3117.294117647059, \"learn_time_ms\": 28319.223}", "{\"n\": 3032, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86111111111111, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3101.527777777778, \"learn_time_ms\": 28333.709}", "{\"n\": 3033, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.763157894736842, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3121.5526315789475, \"learn_time_ms\": 28339.849}", "{\"n\": 3034, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3139.575, \"learn_time_ms\": 28328.202}", "{\"n\": 3035, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.952380952380953, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3096.5238095238096, \"learn_time_ms\": 28324.128}", "{\"n\": 3036, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.906976744186046, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3104.6279069767443, \"learn_time_ms\": 28326.256}", "{\"n\": 3037, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.863636363636363, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3121.4772727272725, \"learn_time_ms\": 28279.438}", "{\"n\": 3038, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.73913043478261, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3141.4565217391305, \"learn_time_ms\": 28276.852}", "{\"n\": 3039, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.604166666666666, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3176.5416666666665, \"learn_time_ms\": 28276.083}", "{\"n\": 3040, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.673469387755102, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3171.1428571428573, \"learn_time_ms\": 28311.065}", "{\"n\": 3041, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3159.32, \"learn_time_ms\": 28333.585}", "{\"n\": 3042, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.679245283018869, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3160.5471698113206, \"learn_time_ms\": 28313.104}", "{\"n\": 3043, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.685185185185185, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3158.962962962963, \"learn_time_ms\": 28302.724}", "{\"n\": 3044, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.727272727272727, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3144.4363636363637, \"learn_time_ms\": 28292.477}", "{\"n\": 3045, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.666666666666666, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3152.2280701754385, \"learn_time_ms\": 28288.867}", "{\"n\": 3046, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.666666666666666, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3152.2280701754385, \"learn_time_ms\": 28243.839}", "{\"n\": 3047, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.724137931034482, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3140.5862068965516, \"learn_time_ms\": 28263.114}", "{\"n\": 3048, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.711864406779661, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3136.3898305084745, \"learn_time_ms\": 28262.892}", "{\"n\": 3049, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.661290322580646, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3147.451612903226, \"learn_time_ms\": 28223.759}", "{\"n\": 3050, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.609375, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3160.28125, \"learn_time_ms\": 28235.1}", "{\"n\": 3051, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.584615384615384, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3163.9538461538464, \"learn_time_ms\": 28218.651}", "{\"n\": 3052, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.636363636363637, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3162.6363636363635, \"learn_time_ms\": 28193.559}", "{\"n\": 3053, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.567164179104477, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3168.0298507462685, \"learn_time_ms\": 28213.966}", "{\"n\": 3054, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.485294117647058, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3180.794117647059, \"learn_time_ms\": 28194.682}", "{\"n\": 3055, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.366197183098592, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3193.957746478873, \"learn_time_ms\": 28192.498}", "{\"n\": 3056, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.375, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3195.6388888888887, \"learn_time_ms\": 28236.721}", "{\"n\": 3057, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.315068493150685, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3204.931506849315, \"learn_time_ms\": 28237.363}", "{\"n\": 3058, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.302631578947368, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3204.407894736842, \"learn_time_ms\": 28215.413}", "{\"n\": 3059, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.302631578947368, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3204.407894736842, \"learn_time_ms\": 28262.654}", "{\"n\": 3060, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.246753246753247, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3210.7662337662337, \"learn_time_ms\": 28251.8}", "{\"n\": 3061, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.240506329113924, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3213.784810126582, \"learn_time_ms\": 28272.704}", "{\"n\": 3062, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3218.925, \"learn_time_ms\": 28305.339}", "{\"n\": 3063, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.168674698795181, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3221.120481927711, \"learn_time_ms\": 28294.733}", "{\"n\": 3064, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.226190476190476, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.9761904761904, \"learn_time_ms\": 28266.793}", "{\"n\": 3065, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.226190476190476, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.9761904761904, \"learn_time_ms\": 28195.173}", "{\"n\": 3066, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.258823529411766, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3208.9176470588236, \"learn_time_ms\": 28146.027}", "{\"n\": 3067, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.241379310344827, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3213.32183908046, \"learn_time_ms\": 28123.091}", "{\"n\": 3068, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.155555555555555, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3227.9222222222224, \"learn_time_ms\": 28080.216}", "{\"n\": 3069, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.186813186813186, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3229.186813186813, \"learn_time_ms\": 28006.941}", "{\"n\": 3070, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.172043010752688, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3233.8064516129034, \"learn_time_ms\": 27979.748}", "{\"n\": 3071, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.172043010752688, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3233.8064516129034, \"learn_time_ms\": 27946.191}", "{\"n\": 3072, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16842105263158, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3244.5789473684213, \"learn_time_ms\": 27900.889}", "{\"n\": 3073, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.208333333333334, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3237.8645833333335, \"learn_time_ms\": 27901.583}", "{\"n\": 3074, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.244897959183673, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3234.765306122449, \"learn_time_ms\": 27960.055}", "{\"n\": 3075, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3230.54, \"learn_time_ms\": 28001.161}", "{\"n\": 3076, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3254.47, \"learn_time_ms\": 28034.716}", "{\"n\": 3077, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3243.5, \"learn_time_ms\": 28046.043}", "{\"n\": 3078, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3249.88, \"learn_time_ms\": 28108.932}", "{\"n\": 3079, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3243.63, \"learn_time_ms\": 28151.96}", "{\"n\": 3080, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3249.09, \"learn_time_ms\": 28178.173}", "{\"n\": 3081, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3235.99, \"learn_time_ms\": 28163.435}", "{\"n\": 3082, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3242.74, \"learn_time_ms\": 28200.004}", "{\"n\": 3083, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3241.4, \"learn_time_ms\": 28176.067}", "{\"n\": 3084, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3217.13, \"learn_time_ms\": 28126.593}", "{\"n\": 3085, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3217.13, \"learn_time_ms\": 28157.991}", "{\"n\": 3086, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3218.03, \"learn_time_ms\": 28147.199}", "{\"n\": 3087, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3241.96, \"learn_time_ms\": 28109.121}", "{\"n\": 3088, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3241.96, \"learn_time_ms\": 28120.764}", "{\"n\": 3089, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3251.07, \"learn_time_ms\": 28086.174}", "{\"n\": 3090, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.4, \"learn_time_ms\": 28019.403}", "{\"n\": 3091, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.4, \"learn_time_ms\": 28032.442}", "{\"n\": 3092, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3259.62, \"learn_time_ms\": 28000.76}", "{\"n\": 3093, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3267.19, \"learn_time_ms\": 28021.898}", "{\"n\": 3094, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3261.75, \"learn_time_ms\": 28056.626}", "{\"n\": 3095, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3278.72, \"learn_time_ms\": 28026.651}", "{\"n\": 3096, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3278.72, \"learn_time_ms\": 28025.858}", "{\"n\": 3097, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3278.72, \"learn_time_ms\": 28049.48}", "{\"n\": 3098, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3286.39, \"learn_time_ms\": 28044.724}", "{\"n\": 3099, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3300.18, \"learn_time_ms\": 28049.544}", "{\"n\": 3100, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3315.4, \"learn_time_ms\": 28122.718}", "{\"n\": 3101, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3326.45, \"learn_time_ms\": 28141.575}", "{\"n\": 3102, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3321.11, \"learn_time_ms\": 28171.922}", "{\"n\": 3103, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3321.11, \"learn_time_ms\": 28152.633}", "{\"n\": 3104, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3317.6, \"learn_time_ms\": 28116.319}", "{\"n\": 3105, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3334.85, \"learn_time_ms\": 28158.339}", "{\"n\": 3106, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3342.14, \"learn_time_ms\": 28155.732}", "{\"n\": 3107, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3342.14, \"learn_time_ms\": 28070.816}", "{\"n\": 3108, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3350.26, \"learn_time_ms\": 27995.631}", "{\"n\": 3109, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3350.26, \"learn_time_ms\": 27967.381}", "{\"n\": 3110, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3351.36, \"learn_time_ms\": 27845.167}", "{\"n\": 3111, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3359.8, \"learn_time_ms\": 27707.996}", "{\"n\": 3112, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3361.41, \"learn_time_ms\": 27593.047}", "{\"n\": 3113, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3364.49, \"learn_time_ms\": 27513.696}", "{\"n\": 3114, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3364.49, \"learn_time_ms\": 27433.195}", "{\"n\": 3115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3373.4, \"learn_time_ms\": 27317.047}", "{\"n\": 3116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3368.37, \"learn_time_ms\": 27234.605}", "{\"n\": 3117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3383.39, \"learn_time_ms\": 27240.007}", "{\"n\": 3118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3391.55, \"learn_time_ms\": 27223.664}", "{\"n\": 3119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3391.55, \"learn_time_ms\": 27204.924}", "{\"n\": 3120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3396.74, \"learn_time_ms\": 27211.27}", "{\"n\": 3121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3401.5, \"learn_time_ms\": 27250.948}", "{\"n\": 3122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3410.7, \"learn_time_ms\": 27264.75}", "{\"n\": 3123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3407.8, \"learn_time_ms\": 27264.822}", "{\"n\": 3124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3399.73, \"learn_time_ms\": 27300.101}", "{\"n\": 3125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3399.9, \"learn_time_ms\": 27407.345}", "{\"n\": 3126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3387.62, \"learn_time_ms\": 27512.932}", "{\"n\": 3127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3383.71, \"learn_time_ms\": 27598.245}", "{\"n\": 3128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3390.52, \"learn_time_ms\": 27694.815}", "{\"n\": 3129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3398.49, \"learn_time_ms\": 27745.261}", "{\"n\": 3130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3393.59, \"learn_time_ms\": 27812.816}", "{\"n\": 3131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3391.8, \"learn_time_ms\": 27925.294}", "{\"n\": 3132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3407.66, \"learn_time_ms\": 27985.638}", "{\"n\": 3133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3400.89, \"learn_time_ms\": 27989.41}", "{\"n\": 3134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3404.48, \"learn_time_ms\": 28001.247}", "{\"n\": 3135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3404.48, \"learn_time_ms\": 27981.004}", "{\"n\": 3136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3413.39, \"learn_time_ms\": 27936.603}", "{\"n\": 3137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3411.31, \"learn_time_ms\": 27960.041}", "{\"n\": 3138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3416.56, \"learn_time_ms\": 27866.889}", "{\"n\": 3139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3406.91, \"learn_time_ms\": 27874.267}", "{\"n\": 3140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3411.46, \"learn_time_ms\": 27903.373}", "{\"n\": 3141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3411.46, \"learn_time_ms\": 27839.379}", "{\"n\": 3142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3406.69, \"learn_time_ms\": 27907.986}", "{\"n\": 3143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3406.69, \"learn_time_ms\": 27981.165}", "{\"n\": 3144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.96, \"learn_time_ms\": 28009.325}", "{\"n\": 3145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.44, \"learn_time_ms\": 27915.597}", "{\"n\": 3146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.77, \"learn_time_ms\": 27829.103}", "{\"n\": 3147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.38, \"learn_time_ms\": 27749.536}", "{\"n\": 3148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.98, \"learn_time_ms\": 27711.183}", "{\"n\": 3149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.98, \"learn_time_ms\": 27642.884}", "{\"n\": 3150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3461.25, \"learn_time_ms\": 27555.311}", "{\"n\": 3151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.43, \"learn_time_ms\": 27478.646}", "{\"n\": 3152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3467.18, \"learn_time_ms\": 27355.937}", "{\"n\": 3153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3465.95, \"learn_time_ms\": 27272.169}", "{\"n\": 3154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3465.95, \"learn_time_ms\": 27218.8}", "{\"n\": 3155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3465.95, \"learn_time_ms\": 27235.961}", "{\"n\": 3156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3459.51, \"learn_time_ms\": 27263.731}", "{\"n\": 3157, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3506.29, \"learn_time_ms\": 27247.442}", "{\"n\": 3158, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3504.71, \"learn_time_ms\": 27285.788}", "{\"n\": 3159, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3510.83, \"learn_time_ms\": 27301.046}", "{\"n\": 3160, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3510.83, \"learn_time_ms\": 27238.529}", "{\"n\": 3161, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3510.83, \"learn_time_ms\": 27301.504}", "{\"n\": 3162, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3496.25, \"learn_time_ms\": 27311.093}", "{\"n\": 3163, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3496.25, \"learn_time_ms\": 27318.199}", "{\"n\": 3164, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3501.74, \"learn_time_ms\": 27295.142}", "{\"n\": 3165, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3512.98, \"learn_time_ms\": 27308.235}", "{\"n\": 3166, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3524.4, \"learn_time_ms\": 27319.831}", "{\"n\": 3167, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3522.63, \"learn_time_ms\": 27321.027}", "{\"n\": 3168, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3522.63, \"learn_time_ms\": 27366.23}", "{\"n\": 3169, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3525.14, \"learn_time_ms\": 27474.165}", "{\"n\": 3170, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3519.56, \"learn_time_ms\": 27520.162}", "{\"n\": 3171, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3548.04, \"learn_time_ms\": 27531.067}", "{\"n\": 3172, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3561.17, \"learn_time_ms\": 27509.177}", "{\"n\": 3173, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3553.57, \"learn_time_ms\": 27595.193}", "{\"n\": 3174, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3565.54, \"learn_time_ms\": 27596.179}", "{\"n\": 3175, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3565.8, \"learn_time_ms\": 27631.344}", "{\"n\": 3176, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3576.73, \"learn_time_ms\": 27705.032}", "{\"n\": 3177, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3581.97, \"learn_time_ms\": 27759.756}", "{\"n\": 3178, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3581.97, \"learn_time_ms\": 27705.167}", "{\"n\": 3179, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3568.27, \"learn_time_ms\": 27626.333}", "{\"n\": 3180, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3564.7, \"learn_time_ms\": 27723.461}", "{\"n\": 3181, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3555.84, \"learn_time_ms\": 27730.73}", "{\"n\": 3182, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3555.84, \"learn_time_ms\": 27821.669}", "{\"n\": 3183, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3563.76, \"learn_time_ms\": 27802.667}", "{\"n\": 3184, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3561.66, \"learn_time_ms\": 27915.914}", "{\"n\": 3185, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3562.33, \"learn_time_ms\": 27924.605}", "{\"n\": 3186, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3572.97, \"learn_time_ms\": 27925.913}", "{\"n\": 3187, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3567.23, \"learn_time_ms\": 27972.033}", "{\"n\": 3188, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3567.23, \"learn_time_ms\": 28066.739}", "{\"n\": 3189, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3575.2, \"learn_time_ms\": 28118.569}", "{\"n\": 3190, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3583.69, \"learn_time_ms\": 28112.412}", "{\"n\": 3191, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3599.76, \"learn_time_ms\": 28137.671}", "{\"n\": 3192, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3611.41, \"learn_time_ms\": 28148.187}", "{\"n\": 3193, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3605.8, \"learn_time_ms\": 28147.418}", "{\"n\": 3194, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3605.8, \"learn_time_ms\": 28125.943}", "{\"n\": 3195, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3613.38, \"learn_time_ms\": 28158.783}", "{\"n\": 3196, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3613.38, \"learn_time_ms\": 28198.09}", "{\"n\": 3197, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3619.36, \"learn_time_ms\": 28154.424}", "{\"n\": 3198, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3618.72, \"learn_time_ms\": 28163.705}", "{\"n\": 3199, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3629.07, \"learn_time_ms\": 28146.411}", "{\"n\": 3200, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3623.11, \"learn_time_ms\": 28143.448}", "{\"n\": 3201, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3623.11, \"learn_time_ms\": 28140.713}", "{\"n\": 3202, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3623.11, \"learn_time_ms\": 28123.378}", "{\"n\": 3203, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3629.36, \"learn_time_ms\": 28104.661}", "{\"n\": 3204, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3631.09, \"learn_time_ms\": 28073.897}", "{\"n\": 3205, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3631.09, \"learn_time_ms\": 28073.383}", "{\"n\": 3206, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3620.0, \"learn_time_ms\": 28026.89}", "{\"n\": 3207, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3620.0, \"learn_time_ms\": 28048.436}", "{\"n\": 3208, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3618.19, \"learn_time_ms\": 28058.977}", "{\"n\": 3209, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3622.71, \"learn_time_ms\": 28045.818}", "{\"n\": 3210, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3628.47, \"learn_time_ms\": 28048.343}", "{\"n\": 3211, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3642.72, \"learn_time_ms\": 28020.813}", "{\"n\": 3212, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3656.29, \"learn_time_ms\": 28025.692}", "{\"n\": 3213, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3653.4, \"learn_time_ms\": 28052.101}", "{\"n\": 3214, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3654.91, \"learn_time_ms\": 28088.241}", "{\"n\": 3215, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3660.18, \"learn_time_ms\": 28058.43}", "{\"n\": 3216, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3644.19, \"learn_time_ms\": 28062.875}", "{\"n\": 3217, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3644.19, \"learn_time_ms\": 28059.558}", "{\"n\": 3218, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3650.96, \"learn_time_ms\": 28034.356}", "{\"n\": 3219, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3652.64, \"learn_time_ms\": 28048.732}", "{\"n\": 3220, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3663.07, \"learn_time_ms\": 28046.302}", "{\"n\": 3221, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3654.41, \"learn_time_ms\": 28072.553}", "{\"n\": 3222, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3646.6, \"learn_time_ms\": 28077.88}", "{\"n\": 3223, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3621.41, \"learn_time_ms\": 28078.315}", "{\"n\": 3224, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3621.41, \"learn_time_ms\": 28089.094}", "{\"n\": 3225, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3616.8, \"learn_time_ms\": 28123.144}", "{\"n\": 3226, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3617.78, \"learn_time_ms\": 28115.855}", "{\"n\": 3227, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3603.66, \"learn_time_ms\": 28103.223}", "{\"n\": 3228, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3603.66, \"learn_time_ms\": 28090.776}", "{\"n\": 3229, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3613.87, \"learn_time_ms\": 28064.335}", "{\"n\": 3230, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3604.92, \"learn_time_ms\": 28050.351}", "{\"n\": 3231, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3606.64, \"learn_time_ms\": 28055.389}", "{\"n\": 3232, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3601.35, \"learn_time_ms\": 28034.217}", "{\"n\": 3233, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3608.33, \"learn_time_ms\": 28038.594}", "{\"n\": 3234, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3608.33, \"learn_time_ms\": 28021.298}", "{\"n\": 3235, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3609.73, \"learn_time_ms\": 27993.325}", "{\"n\": 3236, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3614.45, \"learn_time_ms\": 28018.54}", "{\"n\": 3237, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3614.45, \"learn_time_ms\": 28028.896}", "{\"n\": 3238, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3623.76, \"learn_time_ms\": 28037.572}", "{\"n\": 3239, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3623.76, \"learn_time_ms\": 28017.556}", "{\"n\": 3240, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3592.04, \"learn_time_ms\": 28024.549}", "{\"n\": 3241, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3592.04, \"learn_time_ms\": 27938.882}", "{\"n\": 3242, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3562.91, \"learn_time_ms\": 27952.916}", "{\"n\": 3243, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3557.92, \"learn_time_ms\": 27920.278}", "{\"n\": 3244, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3541.56, \"learn_time_ms\": 27904.004}", "{\"n\": 3245, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3541.56, \"learn_time_ms\": 27895.364}", "{\"n\": 3246, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3539.23, \"learn_time_ms\": 27789.202}", "{\"n\": 3247, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3536.76, \"learn_time_ms\": 27726.163}", "{\"n\": 3248, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3533.94, \"learn_time_ms\": 27644.942}", "{\"n\": 3249, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3525.09, \"learn_time_ms\": 27601.597}", "{\"n\": 3250, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3525.09, \"learn_time_ms\": 27536.41}", "{\"n\": 3251, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3521.49, \"learn_time_ms\": 27523.046}", "{\"n\": 3252, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3535.77, \"learn_time_ms\": 27463.87}", "{\"n\": 3253, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3544.15, \"learn_time_ms\": 27409.585}", "{\"n\": 3254, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3540.82, \"learn_time_ms\": 27367.897}", "{\"n\": 3255, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3530.47, \"learn_time_ms\": 27383.451}", "{\"n\": 3256, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3521.62, \"learn_time_ms\": 27452.294}", "{\"n\": 3257, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3516.6, \"learn_time_ms\": 27524.384}", "{\"n\": 3258, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3529.96, \"learn_time_ms\": 27559.537}", "{\"n\": 3259, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3519.67, \"learn_time_ms\": 27614.894}", "{\"n\": 3260, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3519.67, \"learn_time_ms\": 27706.349}", "{\"n\": 3261, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3522.43, \"learn_time_ms\": 27818.554}", "{\"n\": 3262, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3513.3, \"learn_time_ms\": 27852.47}", "{\"n\": 3263, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3492.08, \"learn_time_ms\": 27955.972}", "{\"n\": 3264, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3484.93, \"learn_time_ms\": 28025.835}", "{\"n\": 3265, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3490.51, \"learn_time_ms\": 28033.585}", "{\"n\": 3266, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3472.53, \"learn_time_ms\": 28031.485}", "{\"n\": 3267, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3472.53, \"learn_time_ms\": 27997.815}", "{\"n\": 3268, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3472.53, \"learn_time_ms\": 27946.283}", "{\"n\": 3269, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3473.84, \"learn_time_ms\": 27902.187}", "{\"n\": 3270, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3463.44, \"learn_time_ms\": 27815.893}", "{\"n\": 3271, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3467.25, \"learn_time_ms\": 27714.533}", "{\"n\": 3272, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3474.02, \"learn_time_ms\": 27660.181}", "{\"n\": 3273, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3473.76, \"learn_time_ms\": 27569.158}", "{\"n\": 3274, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3471.16, \"learn_time_ms\": 27476.343}", "{\"n\": 3275, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3470.11, \"learn_time_ms\": 27416.062}", "{\"n\": 3276, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3462.97, \"learn_time_ms\": 27344.92}", "{\"n\": 3277, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3464.31, \"learn_time_ms\": 27296.088}", "{\"n\": 3278, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3489.14, \"learn_time_ms\": 27303.589}", "{\"n\": 3279, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.71, \"learn_time_ms\": 27307.525}", "{\"n\": 3280, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3477.57, \"learn_time_ms\": 27294.622}", "{\"n\": 3281, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3475.53, \"learn_time_ms\": 27330.964}", "{\"n\": 3282, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3466.5, \"learn_time_ms\": 27346.321}", "{\"n\": 3283, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3466.5, \"learn_time_ms\": 27343.839}", "{\"n\": 3284, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3451.14, \"learn_time_ms\": 27289.629}", "{\"n\": 3285, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3451.14, \"learn_time_ms\": 27280.782}", "{\"n\": 3286, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3457.26, \"learn_time_ms\": 27278.954}", "{\"n\": 3287, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3454.98, \"learn_time_ms\": 27214.094}", "{\"n\": 3288, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3451.01, \"learn_time_ms\": 27199.323}", "{\"n\": 3289, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3451.01, \"learn_time_ms\": 27192.365}", "{\"n\": 3290, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3450.71, \"learn_time_ms\": 27187.546}", "{\"n\": 3291, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3451.7, \"learn_time_ms\": 27250.888}", "{\"n\": 3292, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3458.88, \"learn_time_ms\": 27281.009}", "{\"n\": 3293, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3463.15, \"learn_time_ms\": 27318.781}", "{\"n\": 3294, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3461.71, \"learn_time_ms\": 27452.299}", "{\"n\": 3295, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3465.31, \"learn_time_ms\": 27545.558}", "{\"n\": 3296, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3465.31, \"learn_time_ms\": 27629.473}", "{\"n\": 3297, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3465.31, \"learn_time_ms\": 27764.431}", "{\"n\": 3298, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3448.89, \"learn_time_ms\": 27868.172}", "{\"n\": 3299, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3448.89, \"learn_time_ms\": 27937.099}", "{\"n\": 3300, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3456.75, \"learn_time_ms\": 28001.178}", "{\"n\": 3301, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3469.86, \"learn_time_ms\": 28013.945}", "{\"n\": 3302, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3463.12, \"learn_time_ms\": 28025.981}", "{\"n\": 3303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3471.03, \"learn_time_ms\": 28043.672}", "{\"n\": 3304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3471.03, \"learn_time_ms\": 28027.351}", "{\"n\": 3305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3481.66, \"learn_time_ms\": 28035.527}", "{\"n\": 3306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3481.63, \"learn_time_ms\": 28057.805}", "{\"n\": 3307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.25, \"learn_time_ms\": 28090.59}", "{\"n\": 3308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3476.71, \"learn_time_ms\": 28117.035}", "{\"n\": 3309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3486.85, \"learn_time_ms\": 28148.648}", "{\"n\": 3310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3460.24, \"learn_time_ms\": 28185.505}", "{\"n\": 3311, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3460.24, \"learn_time_ms\": 28181.045}", "{\"n\": 3312, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3478.37, \"learn_time_ms\": 28215.262}", "{\"n\": 3313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3484.04, \"learn_time_ms\": 28268.467}", "{\"n\": 3314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3499.02, \"learn_time_ms\": 28300.949}", "{\"n\": 3315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3493.08, \"learn_time_ms\": 28287.981}", "{\"n\": 3316, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3501.61, \"learn_time_ms\": 28277.936}", "{\"n\": 3317, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3505.88, \"learn_time_ms\": 28217.786}", "{\"n\": 3318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3493.4, \"learn_time_ms\": 28114.585}", "{\"n\": 3319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3493.4, \"learn_time_ms\": 28010.427}", "{\"n\": 3320, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3474.67, \"learn_time_ms\": 27938.277}", "{\"n\": 3321, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3483.74, \"learn_time_ms\": 27835.877}", "{\"n\": 3322, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3483.74, \"learn_time_ms\": 27765.018}", "{\"n\": 3323, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3483.74, \"learn_time_ms\": 27658.076}", "{\"n\": 3324, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3501.29, \"learn_time_ms\": 27577.216}", "{\"n\": 3325, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3514.92, \"learn_time_ms\": 27472.92}", "{\"n\": 3326, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3499.79, \"learn_time_ms\": 27400.563}", "{\"n\": 3327, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3512.25, \"learn_time_ms\": 27313.535}", "{\"n\": 3328, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3512.25, \"learn_time_ms\": 27314.641}", "{\"n\": 3329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3529.56, \"learn_time_ms\": 27408.969}", "{\"n\": 3330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3553.12, \"learn_time_ms\": 27466.891}", "{\"n\": 3331, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3537.16, \"learn_time_ms\": 27493.04}", "{\"n\": 3332, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3544.29, \"learn_time_ms\": 27526.253}", "{\"n\": 3333, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3554.34, \"learn_time_ms\": 27585.6}", "{\"n\": 3334, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3554.34, \"learn_time_ms\": 27678.121}", "{\"n\": 3335, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3557.51, \"learn_time_ms\": 27773.705}", "{\"n\": 3336, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3557.16, \"learn_time_ms\": 27821.305}", "{\"n\": 3337, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3561.78, \"learn_time_ms\": 27954.428}", "{\"n\": 3338, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3561.78, \"learn_time_ms\": 28009.57}", "{\"n\": 3339, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3550.8, \"learn_time_ms\": 28025.116}", "{\"n\": 3340, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3545.24, \"learn_time_ms\": 27995.782}", "{\"n\": 3341, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3550.05, \"learn_time_ms\": 28026.231}", "{\"n\": 3342, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3561.64, \"learn_time_ms\": 28058.33}", "{\"n\": 3343, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3561.64, \"learn_time_ms\": 28054.425}", "{\"n\": 3344, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3561.64, \"learn_time_ms\": 27988.301}", "{\"n\": 3345, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3565.84, \"learn_time_ms\": 27981.453}", "{\"n\": 3346, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3544.84, \"learn_time_ms\": 28014.793}", "{\"n\": 3347, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3567.32, \"learn_time_ms\": 27992.683}", "{\"n\": 3348, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3567.32, \"learn_time_ms\": 28008.248}", "{\"n\": 3349, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3566.83, \"learn_time_ms\": 27981.757}", "{\"n\": 3350, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3566.83, \"learn_time_ms\": 27997.572}", "{\"n\": 3351, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3564.65, \"learn_time_ms\": 28029.271}", "{\"n\": 3352, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3571.96, \"learn_time_ms\": 28005.466}", "{\"n\": 3353, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3560.88, \"learn_time_ms\": 28036.524}", "{\"n\": 3354, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3572.76, \"learn_time_ms\": 28096.138}", "{\"n\": 3355, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3579.82, \"learn_time_ms\": 28095.69}", "{\"n\": 3356, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3579.82, \"learn_time_ms\": 28048.629}", "{\"n\": 3357, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3579.82, \"learn_time_ms\": 28092.028}", "{\"n\": 3358, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3578.23, \"learn_time_ms\": 28084.079}", "{\"n\": 3359, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3574.41, \"learn_time_ms\": 28072.885}", "{\"n\": 3360, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3574.41, \"learn_time_ms\": 28094.557}", "{\"n\": 3361, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3584.14, \"learn_time_ms\": 28089.981}", "{\"n\": 3362, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3584.14, \"learn_time_ms\": 28101.927}", "{\"n\": 3363, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3608.08, \"learn_time_ms\": 28092.486}", "{\"n\": 3364, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3611.11, \"learn_time_ms\": 28095.91}", "{\"n\": 3365, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3611.11, \"learn_time_ms\": 28112.961}", "{\"n\": 3366, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3617.44, \"learn_time_ms\": 28128.232}", "{\"n\": 3367, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3616.45, \"learn_time_ms\": 28073.376}", "{\"n\": 3368, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3606.07, \"learn_time_ms\": 28041.748}", "{\"n\": 3369, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3608.15, \"learn_time_ms\": 28083.133}", "{\"n\": 3370, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3607.04, \"learn_time_ms\": 28110.719}", "{\"n\": 3371, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3607.04, \"learn_time_ms\": 28093.817}", "{\"n\": 3372, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3609.35, \"learn_time_ms\": 28084.759}", "{\"n\": 3373, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3643.85, \"learn_time_ms\": 28066.933}", "{\"n\": 3374, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3639.88, \"learn_time_ms\": 28047.181}", "{\"n\": 3375, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3635.85, \"learn_time_ms\": 28028.354}", "{\"n\": 3376, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3635.85, \"learn_time_ms\": 28026.968}", "{\"n\": 3377, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3622.56, \"learn_time_ms\": 28066.099}", "{\"n\": 3378, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3625.03, \"learn_time_ms\": 28112.146}", "{\"n\": 3379, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3625.3, \"learn_time_ms\": 28102.775}", "{\"n\": 3380, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.51, \"learn_time_ms\": 28047.14}", "{\"n\": 3381, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.51, \"learn_time_ms\": 28059.693}", "{\"n\": 3382, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3623.87, \"learn_time_ms\": 28061.83}", "{\"n\": 3383, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3623.87, \"learn_time_ms\": 28094.03}", "{\"n\": 3384, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.01, \"learn_time_ms\": 28092.867}", "{\"n\": 3385, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3618.63, \"learn_time_ms\": 28064.576}", "{\"n\": 3386, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3626.81, \"learn_time_ms\": 28084.0}", "{\"n\": 3387, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3626.81, \"learn_time_ms\": 28084.836}", "{\"n\": 3388, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3608.59, \"learn_time_ms\": 28088.86}", "{\"n\": 3389, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3596.59, \"learn_time_ms\": 28075.573}", "{\"n\": 3390, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3590.53, \"learn_time_ms\": 28121.229}", "{\"n\": 3391, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3597.7, \"learn_time_ms\": 28134.374}", "{\"n\": 3392, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.22, \"learn_time_ms\": 28153.312}", "{\"n\": 3393, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.22, \"learn_time_ms\": 28143.112}", "{\"n\": 3394, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3652.04, \"learn_time_ms\": 28140.294}", "{\"n\": 3395, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3652.04, \"learn_time_ms\": 28172.098}", "{\"n\": 3396, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3652.8, \"learn_time_ms\": 28159.861}", "{\"n\": 3397, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3655.66, \"learn_time_ms\": 28114.209}", "{\"n\": 3398, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3646.71, \"learn_time_ms\": 28134.962}", "{\"n\": 3399, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3630.57, \"learn_time_ms\": 28118.72}", "{\"n\": 3400, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3631.76, \"learn_time_ms\": 28094.596}", "{\"n\": 3401, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3631.76, \"learn_time_ms\": 28105.782}", "{\"n\": 3402, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3601.35, \"learn_time_ms\": 28107.999}", "{\"n\": 3403, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3609.17, \"learn_time_ms\": 28053.046}", "{\"n\": 3404, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3609.17, \"learn_time_ms\": 28074.491}", "{\"n\": 3405, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.92, \"learn_time_ms\": 28074.817}", "{\"n\": 3406, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3595.1, \"learn_time_ms\": 28052.676}", "{\"n\": 3407, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3592.18, \"learn_time_ms\": 28097.643}", "{\"n\": 3408, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3580.38, \"learn_time_ms\": 28040.95}", "{\"n\": 3409, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3578.62, \"learn_time_ms\": 28023.435}", "{\"n\": 3410, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3584.92, \"learn_time_ms\": 28038.031}", "{\"n\": 3411, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3590.62, \"learn_time_ms\": 27992.42}", "{\"n\": 3412, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3608.37, \"learn_time_ms\": 27985.131}", "{\"n\": 3413, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3615.11, \"learn_time_ms\": 28038.907}", "{\"n\": 3414, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3612.15, \"learn_time_ms\": 28029.751}", "{\"n\": 3415, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3622.75, \"learn_time_ms\": 28010.668}", "{\"n\": 3416, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3622.48, \"learn_time_ms\": 28065.47}", "{\"n\": 3417, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.67, \"learn_time_ms\": 28052.115}", "{\"n\": 3418, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.48, \"learn_time_ms\": 28083.325}", "{\"n\": 3419, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3622.93, \"learn_time_ms\": 28120.345}", "{\"n\": 3420, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3631.11, \"learn_time_ms\": 28093.869}", "{\"n\": 3421, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3636.79, \"learn_time_ms\": 28123.253}", "{\"n\": 3422, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3651.26, \"learn_time_ms\": 28104.385}", "{\"n\": 3423, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3650.4, \"learn_time_ms\": 28058.646}", "{\"n\": 3424, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3647.16, \"learn_time_ms\": 28052.434}", "{\"n\": 3425, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3659.55, \"learn_time_ms\": 28075.723}", "{\"n\": 3426, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3646.55, \"learn_time_ms\": 28062.605}", "{\"n\": 3427, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3651.79, \"learn_time_ms\": 28094.771}", "{\"n\": 3428, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3649.42, \"learn_time_ms\": 28132.462}", "{\"n\": 3429, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3644.39, \"learn_time_ms\": 28123.572}", "{\"n\": 3430, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3646.16, \"learn_time_ms\": 28128.243}", "{\"n\": 3431, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3644.12, \"learn_time_ms\": 28129.093}", "{\"n\": 3432, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3639.15, \"learn_time_ms\": 28151.845}", "{\"n\": 3433, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3631.55, \"learn_time_ms\": 28202.756}", "{\"n\": 3434, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3635.14, \"learn_time_ms\": 28222.487}", "{\"n\": 3435, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3616.69, \"learn_time_ms\": 28240.763}", "{\"n\": 3436, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3603.83, \"learn_time_ms\": 28238.554}", "{\"n\": 3437, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3583.1, \"learn_time_ms\": 28201.696}", "{\"n\": 3438, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.07, \"learn_time_ms\": 28187.628}", "{\"n\": 3439, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3558.93, \"learn_time_ms\": 28161.603}", "{\"n\": 3440, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3558.93, \"learn_time_ms\": 28158.909}", "{\"n\": 3441, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3558.93, \"learn_time_ms\": 28156.747}", "{\"n\": 3442, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3554.07, \"learn_time_ms\": 28174.931}", "{\"n\": 3443, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.58, \"learn_time_ms\": 28188.638}", "{\"n\": 3444, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3556.65, \"learn_time_ms\": 28179.016}", "{\"n\": 3445, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3556.65, \"learn_time_ms\": 28148.174}", "{\"n\": 3446, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3556.65, \"learn_time_ms\": 28165.591}", "{\"n\": 3447, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3565.97, \"learn_time_ms\": 28148.338}", "{\"n\": 3448, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.44, \"learn_time_ms\": 28097.349}", "{\"n\": 3449, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.44, \"learn_time_ms\": 28117.422}", "{\"n\": 3450, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3562.77, \"learn_time_ms\": 28119.919}", "{\"n\": 3451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3573.07, \"learn_time_ms\": 28111.82}", "{\"n\": 3452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.14, \"learn_time_ms\": 28104.308}", "{\"n\": 3453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3548.13, \"learn_time_ms\": 28092.079}", "{\"n\": 3454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3563.82, \"learn_time_ms\": 28066.809}", "{\"n\": 3455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3563.98, \"learn_time_ms\": 28079.9}", "{\"n\": 3456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3539.28, \"learn_time_ms\": 28058.971}", "{\"n\": 3457, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3539.28, \"learn_time_ms\": 28071.794}", "{\"n\": 3458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3539.28, \"learn_time_ms\": 28076.439}", "{\"n\": 3459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3555.37, \"learn_time_ms\": 28112.093}", "{\"n\": 3460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3554.23, \"learn_time_ms\": 28151.906}", "{\"n\": 3461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3553.71, \"learn_time_ms\": 28185.6}", "{\"n\": 3462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3554.19, \"learn_time_ms\": 28186.808}", "{\"n\": 3463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3554.19, \"learn_time_ms\": 28199.639}", "{\"n\": 3464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3540.44, \"learn_time_ms\": 28214.458}", "{\"n\": 3465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3517.99, \"learn_time_ms\": 28228.731}", "{\"n\": 3466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3493.42, \"learn_time_ms\": 28262.445}", "{\"n\": 3467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3485.27, \"learn_time_ms\": 28257.597}", "{\"n\": 3468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3480.06, \"learn_time_ms\": 28288.964}", "{\"n\": 3469, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3487.3, \"learn_time_ms\": 28286.185}", "{\"n\": 3470, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3473.71, \"learn_time_ms\": 28229.251}", "{\"n\": 3471, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3481.62, \"learn_time_ms\": 28229.243}", "{\"n\": 3472, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3481.88, \"learn_time_ms\": 28194.133}", "{\"n\": 3473, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3489.36, \"learn_time_ms\": 28185.552}", "{\"n\": 3474, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3502.16, \"learn_time_ms\": 28188.997}", "{\"n\": 3475, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3486.74, \"learn_time_ms\": 28178.908}", "{\"n\": 3476, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3499.65, \"learn_time_ms\": 28176.433}", "{\"n\": 3477, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3497.58, \"learn_time_ms\": 28168.245}", "{\"n\": 3478, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3492.28, \"learn_time_ms\": 28166.545}", "{\"n\": 3479, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3467.77, \"learn_time_ms\": 28148.77}", "{\"n\": 3480, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3467.77, \"learn_time_ms\": 28147.838}", "{\"n\": 3481, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3489.79, \"learn_time_ms\": 28109.222}", "{\"n\": 3482, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3485.37, \"learn_time_ms\": 28165.678}", "{\"n\": 3483, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3459.34, \"learn_time_ms\": 28140.536}", "{\"n\": 3484, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3459.34, \"learn_time_ms\": 28115.988}", "{\"n\": 3485, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3455.49, \"learn_time_ms\": 28096.317}", "{\"n\": 3486, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3450.87, \"learn_time_ms\": 28071.185}", "{\"n\": 3487, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3448.92, \"learn_time_ms\": 28108.756}", "{\"n\": 3488, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3440.61, \"learn_time_ms\": 28115.53}", "{\"n\": 3489, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3448.42, \"learn_time_ms\": 28090.146}", "{\"n\": 3490, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3424.96, \"learn_time_ms\": 28125.641}", "{\"n\": 3491, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3424.96, \"learn_time_ms\": 28152.66}", "{\"n\": 3492, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.7, \"learn_time_ms\": 28143.876}", "{\"n\": 3493, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3371.9, \"learn_time_ms\": 28193.751}", "{\"n\": 3494, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3375.17, \"learn_time_ms\": 28202.11}", "{\"n\": 3495, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3382.95, \"learn_time_ms\": 28237.582}", "{\"n\": 3496, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3391.29, \"learn_time_ms\": 28229.016}", "{\"n\": 3497, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.12, \"learn_time_ms\": 28198.818}", "{\"n\": 3498, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3398.24, \"learn_time_ms\": 28188.81}", "{\"n\": 3499, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3378.32, \"learn_time_ms\": 28237.2}", "{\"n\": 3500, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3349.83, \"learn_time_ms\": 28219.906}", "{\"n\": 3501, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3349.83, \"learn_time_ms\": 28181.118}", "{\"n\": 3502, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3349.83, \"learn_time_ms\": 28178.998}", "{\"n\": 3503, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3355.32, \"learn_time_ms\": 28155.251}", "{\"n\": 3504, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3363.02, \"learn_time_ms\": 28157.47}", "{\"n\": 3505, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.38, \"learn_time_ms\": 28157.82}", "{\"n\": 3506, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3363.15, \"learn_time_ms\": 28198.175}", "{\"n\": 3507, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3364.49, \"learn_time_ms\": 28232.679}", "{\"n\": 3508, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3367.47, \"learn_time_ms\": 28195.502}", "{\"n\": 3509, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3367.47, \"learn_time_ms\": 28161.057}", "{\"n\": 3510, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3399.47, \"learn_time_ms\": 28208.637}", "{\"n\": 3511, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3391.91, \"learn_time_ms\": 28237.442}", "{\"n\": 3512, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3391.91, \"learn_time_ms\": 28238.493}", "{\"n\": 3513, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.16, \"learn_time_ms\": 28217.22}", "{\"n\": 3514, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.16, \"learn_time_ms\": 28227.147}", "{\"n\": 3515, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3381.03, \"learn_time_ms\": 28226.501}", "{\"n\": 3516, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3381.03, \"learn_time_ms\": 28201.815}", "{\"n\": 3517, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.34, \"learn_time_ms\": 28197.641}", "{\"n\": 3518, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.34, \"learn_time_ms\": 28228.285}", "{\"n\": 3519, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3364.61, \"learn_time_ms\": 28232.185}", "{\"n\": 3520, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3362.23, \"learn_time_ms\": 28176.942}", "{\"n\": 3521, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3362.23, \"learn_time_ms\": 28158.009}", "{\"n\": 3522, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3367.1, \"learn_time_ms\": 28141.237}", "{\"n\": 3523, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.62, \"learn_time_ms\": 28171.476}", "{\"n\": 3524, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.38, \"learn_time_ms\": 28171.876}", "{\"n\": 3525, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.38, \"learn_time_ms\": 28141.083}", "{\"n\": 3526, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.38, \"learn_time_ms\": 28158.252}", "{\"n\": 3527, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.19, \"learn_time_ms\": 28156.794}", "{\"n\": 3528, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.71, \"learn_time_ms\": 28146.439}", "{\"n\": 3529, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.71, \"learn_time_ms\": 28183.295}", "{\"n\": 3530, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3392.25, \"learn_time_ms\": 28196.523}", "{\"n\": 3531, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3392.25, \"learn_time_ms\": 28184.556}", "{\"n\": 3532, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3411.39, \"learn_time_ms\": 28170.819}", "{\"n\": 3533, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3415.1, \"learn_time_ms\": 28165.624}", "{\"n\": 3534, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3409.1, \"learn_time_ms\": 28153.121}", "{\"n\": 3535, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.75, \"learn_time_ms\": 28147.966}", "{\"n\": 3536, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.75, \"learn_time_ms\": 28062.458}", "{\"n\": 3537, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3440.89, \"learn_time_ms\": 28058.421}", "{\"n\": 3538, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3440.89, \"learn_time_ms\": 28091.557}", "{\"n\": 3539, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.99, \"learn_time_ms\": 28064.416}", "{\"n\": 3540, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.99, \"learn_time_ms\": 28067.991}", "{\"n\": 3541, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3454.32, \"learn_time_ms\": 28089.719}", "{\"n\": 3542, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3455.83, \"learn_time_ms\": 28119.782}", "{\"n\": 3543, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3460.85, \"learn_time_ms\": 28098.585}", "{\"n\": 3544, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3472.37, \"learn_time_ms\": 28134.048}", "{\"n\": 3545, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3441.5, \"learn_time_ms\": 28125.724}", "{\"n\": 3546, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3454.26, \"learn_time_ms\": 28146.613}", "{\"n\": 3547, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3462.3, \"learn_time_ms\": 28140.384}", "{\"n\": 3548, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3458.14, \"learn_time_ms\": 28149.996}", "{\"n\": 3549, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3458.14, \"learn_time_ms\": 28153.242}", "{\"n\": 3550, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3479.18, \"learn_time_ms\": 28176.383}", "{\"n\": 3551, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3436.46, \"learn_time_ms\": 28176.317}", "{\"n\": 3552, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3436.46, \"learn_time_ms\": 28179.033}", "{\"n\": 3553, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3436.46, \"learn_time_ms\": 28191.332}", "{\"n\": 3554, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3436.46, \"learn_time_ms\": 28210.703}", "{\"n\": 3555, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3443.91, \"learn_time_ms\": 28236.623}", "{\"n\": 3556, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.26, \"learn_time_ms\": 28263.731}", "{\"n\": 3557, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3448.93, \"learn_time_ms\": 28286.246}", "{\"n\": 3558, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3444.48, \"learn_time_ms\": 28244.245}", "{\"n\": 3559, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3458.55, \"learn_time_ms\": 28214.376}", "{\"n\": 3560, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3453.72, \"learn_time_ms\": 28143.833}", "{\"n\": 3561, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3453.72, \"learn_time_ms\": 28152.692}", "{\"n\": 3562, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3464.53, \"learn_time_ms\": 28148.29}", "{\"n\": 3563, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3473.02, \"learn_time_ms\": 28145.331}", "{\"n\": 3564, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3495.42, \"learn_time_ms\": 28119.175}", "{\"n\": 3565, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3501.68, \"learn_time_ms\": 28108.19}", "{\"n\": 3566, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3490.04, \"learn_time_ms\": 28128.726}", "{\"n\": 3567, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3483.74, \"learn_time_ms\": 28095.161}", "{\"n\": 3568, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3483.74, \"learn_time_ms\": 28099.024}", "{\"n\": 3569, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3499.29, \"learn_time_ms\": 28122.201}", "{\"n\": 3570, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3481.43, \"learn_time_ms\": 28157.286}", "{\"n\": 3571, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3486.11, \"learn_time_ms\": 28170.954}", "{\"n\": 3572, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3489.79, \"learn_time_ms\": 28167.516}", "{\"n\": 3573, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3495.77, \"learn_time_ms\": 28185.299}", "{\"n\": 3574, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.24, \"learn_time_ms\": 28202.719}", "{\"n\": 3575, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3506.07, \"learn_time_ms\": 28220.311}", "{\"n\": 3576, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3501.72, \"learn_time_ms\": 28193.18}", "{\"n\": 3577, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3495.97, \"learn_time_ms\": 28178.462}", "{\"n\": 3578, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.34, \"learn_time_ms\": 28202.627}", "{\"n\": 3579, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.34, \"learn_time_ms\": 28212.422}", "{\"n\": 3580, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3506.4, \"learn_time_ms\": 28215.548}", "{\"n\": 3581, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3494.71, \"learn_time_ms\": 28192.474}", "{\"n\": 3582, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3494.71, \"learn_time_ms\": 28184.865}", "{\"n\": 3583, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3502.83, \"learn_time_ms\": 28152.35}", "{\"n\": 3584, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3500.76, \"learn_time_ms\": 28129.591}", "{\"n\": 3585, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3500.76, \"learn_time_ms\": 28137.221}", "{\"n\": 3586, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3500.1, \"learn_time_ms\": 28158.007}", "{\"n\": 3587, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3485.35, \"learn_time_ms\": 28172.246}", "{\"n\": 3588, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3485.35, \"learn_time_ms\": 28137.242}", "{\"n\": 3589, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.07, \"learn_time_ms\": 28151.895}", "{\"n\": 3590, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3493.85, \"learn_time_ms\": 28164.698}", "{\"n\": 3591, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3478.6, \"learn_time_ms\": 28164.252}", "{\"n\": 3592, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3478.7, \"learn_time_ms\": 28129.639}", "{\"n\": 3593, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3478.1, \"learn_time_ms\": 28128.078}", "{\"n\": 3594, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.92, \"learn_time_ms\": 28105.071}", "{\"n\": 3595, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.92, \"learn_time_ms\": 28108.251}", "{\"n\": 3596, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3474.24, \"learn_time_ms\": 28123.312}", "{\"n\": 3597, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.26, \"learn_time_ms\": 28158.608}", "{\"n\": 3598, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.59, \"learn_time_ms\": 28205.738}", "{\"n\": 3599, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3443.91, \"learn_time_ms\": 28189.423}", "{\"n\": 3600, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3443.91, \"learn_time_ms\": 28180.294}", "{\"n\": 3601, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3436.46, \"learn_time_ms\": 28120.418}", "{\"n\": 3602, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3436.46, \"learn_time_ms\": 28165.069}", "{\"n\": 3603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.56, \"learn_time_ms\": 28168.292}", "{\"n\": 3604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.61, \"learn_time_ms\": 28169.302}", "{\"n\": 3605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.84, \"learn_time_ms\": 28167.386}", "{\"n\": 3606, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.84, \"learn_time_ms\": 28193.457}", "{\"n\": 3607, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.54, \"learn_time_ms\": 28149.624}", "{\"n\": 3608, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.54, \"learn_time_ms\": 28138.571}", "{\"n\": 3609, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.58, \"learn_time_ms\": 28108.016}", "{\"n\": 3610, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.61, \"learn_time_ms\": 28123.465}", "{\"n\": 3611, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.61, \"learn_time_ms\": 28197.156}", "{\"n\": 3612, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3388.97, \"learn_time_ms\": 28165.211}", "{\"n\": 3613, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3383.51, \"learn_time_ms\": 28147.232}", "{\"n\": 3614, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.11, \"learn_time_ms\": 28161.908}", "{\"n\": 3615, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3382.47, \"learn_time_ms\": 28124.995}", "{\"n\": 3616, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.61, \"learn_time_ms\": 28081.395}", "{\"n\": 3617, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.22, \"learn_time_ms\": 28092.039}", "{\"n\": 3618, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.49, \"learn_time_ms\": 28095.579}", "{\"n\": 3619, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.49, \"learn_time_ms\": 28131.103}", "{\"n\": 3620, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3374.56, \"learn_time_ms\": 28125.281}", "{\"n\": 3621, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.84, \"learn_time_ms\": 28092.497}", "{\"n\": 3622, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.59, \"learn_time_ms\": 28048.4}", "{\"n\": 3623, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3421.93, \"learn_time_ms\": 28077.318}", "{\"n\": 3624, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3421.93, \"learn_time_ms\": 28095.471}", "{\"n\": 3625, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3408.23, \"learn_time_ms\": 28124.264}", "{\"n\": 3626, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3437.03, \"learn_time_ms\": 28092.668}", "{\"n\": 3627, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3403.04, \"learn_time_ms\": 28079.153}", "{\"n\": 3628, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3402.96, \"learn_time_ms\": 28081.171}", "{\"n\": 3629, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3396.39, \"learn_time_ms\": 28088.831}", "{\"n\": 3630, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3396.39, \"learn_time_ms\": 28068.885}", "{\"n\": 3631, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3390.96, \"learn_time_ms\": 28047.012}", "{\"n\": 3632, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.0, \"learn_time_ms\": 28097.207}", "{\"n\": 3633, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.0, \"learn_time_ms\": 28117.476}", "{\"n\": 3634, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3376.09, \"learn_time_ms\": 28052.802}", "{\"n\": 3635, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.56, \"learn_time_ms\": 28020.571}", "{\"n\": 3636, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3387.6, \"learn_time_ms\": 28053.69}", "{\"n\": 3637, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3387.6, \"learn_time_ms\": 28033.76}", "{\"n\": 3638, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3397.75, \"learn_time_ms\": 27968.395}", "{\"n\": 3639, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3397.75, \"learn_time_ms\": 27887.456}", "{\"n\": 3640, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3395.94, \"learn_time_ms\": 27911.899}", "{\"n\": 3641, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3395.94, \"learn_time_ms\": 27962.695}", "{\"n\": 3642, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3378.68, \"learn_time_ms\": 27954.054}", "{\"n\": 3643, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3391.24, \"learn_time_ms\": 27899.259}", "{\"n\": 3644, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.14, \"learn_time_ms\": 27942.082}", "{\"n\": 3645, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3403.68, \"learn_time_ms\": 27976.437}", "{\"n\": 3646, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3403.68, \"learn_time_ms\": 27955.728}", "{\"n\": 3647, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3402.97, \"learn_time_ms\": 28001.012}", "{\"n\": 3648, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3404.88, \"learn_time_ms\": 28061.094}", "{\"n\": 3649, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3405.5, \"learn_time_ms\": 28131.308}", "{\"n\": 3650, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3400.1, \"learn_time_ms\": 28096.712}", "{\"n\": 3651, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3395.22, \"learn_time_ms\": 28085.91}", "{\"n\": 3652, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3406.69, \"learn_time_ms\": 28088.214}", "{\"n\": 3653, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3406.69, \"learn_time_ms\": 28115.591}", "{\"n\": 3654, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3394.81, \"learn_time_ms\": 28126.645}", "{\"n\": 3655, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3394.81, \"learn_time_ms\": 28104.771}", "{\"n\": 3656, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3423.18, \"learn_time_ms\": 28147.313}", "{\"n\": 3657, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3418.61, \"learn_time_ms\": 28151.579}", "{\"n\": 3658, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3418.61, \"learn_time_ms\": 28115.908}", "{\"n\": 3659, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3435.57, \"learn_time_ms\": 28106.672}", "{\"n\": 3660, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3439.19, \"learn_time_ms\": 28113.309}", "{\"n\": 3661, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3438.9, \"learn_time_ms\": 28102.385}", "{\"n\": 3662, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3436.52, \"learn_time_ms\": 28116.945}", "{\"n\": 3663, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3452.0, \"learn_time_ms\": 28147.38}", "{\"n\": 3664, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3452.0, \"learn_time_ms\": 28129.211}", "{\"n\": 3665, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3452.0, \"learn_time_ms\": 28106.571}", "{\"n\": 3666, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3457.37, \"learn_time_ms\": 28053.741}", "{\"n\": 3667, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3462.56, \"learn_time_ms\": 28030.315}", "{\"n\": 3668, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3438.58, \"learn_time_ms\": 28046.892}", "{\"n\": 3669, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3438.58, \"learn_time_ms\": 27994.042}", "{\"n\": 3670, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3448.22, \"learn_time_ms\": 27987.548}", "{\"n\": 3671, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3448.22, \"learn_time_ms\": 27992.872}", "{\"n\": 3672, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3448.22, \"learn_time_ms\": 27969.863}", "{\"n\": 3673, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3479.12, \"learn_time_ms\": 27954.392}", "{\"n\": 3674, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3492.77, \"learn_time_ms\": 27971.026}", "{\"n\": 3675, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3493.08, \"learn_time_ms\": 28011.729}", "{\"n\": 3676, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3493.08, \"learn_time_ms\": 28045.014}", "{\"n\": 3677, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3493.08, \"learn_time_ms\": 28085.398}", "{\"n\": 3678, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3499.98, \"learn_time_ms\": 28079.985}", "{\"n\": 3679, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3493.43, \"learn_time_ms\": 28106.135}", "{\"n\": 3680, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3520.45, \"learn_time_ms\": 28100.249}", "{\"n\": 3681, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3517.57, \"learn_time_ms\": 28080.308}", "{\"n\": 3682, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3517.57, \"learn_time_ms\": 28109.274}", "{\"n\": 3683, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3517.57, \"learn_time_ms\": 28072.137}", "{\"n\": 3684, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3531.05, \"learn_time_ms\": 28078.832}", "{\"n\": 3685, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3531.93, \"learn_time_ms\": 28055.159}", "{\"n\": 3686, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3535.57, \"learn_time_ms\": 28074.389}", "{\"n\": 3687, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3548.89, \"learn_time_ms\": 28064.225}", "{\"n\": 3688, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3542.74, \"learn_time_ms\": 28063.861}", "{\"n\": 3689, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3542.96, \"learn_time_ms\": 28070.196}", "{\"n\": 3690, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3538.02, \"learn_time_ms\": 28096.932}", "{\"n\": 3691, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3537.35, \"learn_time_ms\": 28120.245}", "{\"n\": 3692, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.03, \"learn_time_ms\": 28121.529}", "{\"n\": 3693, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3550.65, \"learn_time_ms\": 28146.698}", "{\"n\": 3694, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3550.65, \"learn_time_ms\": 28134.402}", "{\"n\": 3695, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.95, \"learn_time_ms\": 28151.211}", "{\"n\": 3696, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3545.23, \"learn_time_ms\": 28103.6}", "{\"n\": 3697, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3552.35, \"learn_time_ms\": 28074.827}", "{\"n\": 3698, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3552.35, \"learn_time_ms\": 28055.065}", "{\"n\": 3699, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3527.57, \"learn_time_ms\": 28115.786}", "{\"n\": 3700, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3529.38, \"learn_time_ms\": 28118.535}", "{\"n\": 3701, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3537.4, \"learn_time_ms\": 28121.344}", "{\"n\": 3702, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3545.63, \"learn_time_ms\": 28088.005}", "{\"n\": 3703, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3548.55, \"learn_time_ms\": 28101.173}", "{\"n\": 3704, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3548.55, \"learn_time_ms\": 28091.85}", "{\"n\": 3705, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.49, \"learn_time_ms\": 28092.568}", "{\"n\": 3706, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3580.54, \"learn_time_ms\": 28097.378}", "{\"n\": 3707, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3572.43, \"learn_time_ms\": 28085.685}", "{\"n\": 3708, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3572.43, \"learn_time_ms\": 28128.742}", "{\"n\": 3709, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3566.72, \"learn_time_ms\": 28105.081}", "{\"n\": 3710, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3565.51, \"learn_time_ms\": 28124.332}", "{\"n\": 3711, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3578.36, \"learn_time_ms\": 28121.343}", "{\"n\": 3712, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3576.91, \"learn_time_ms\": 28132.793}", "{\"n\": 3713, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3576.91, \"learn_time_ms\": 28140.439}", "{\"n\": 3714, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3570.25, \"learn_time_ms\": 28166.304}", "{\"n\": 3715, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3592.59, \"learn_time_ms\": 28177.79}", "{\"n\": 3716, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3591.71, \"learn_time_ms\": 28199.139}", "{\"n\": 3717, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3576.4, \"learn_time_ms\": 28183.077}", "{\"n\": 3718, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3560.36, \"learn_time_ms\": 28151.741}", "{\"n\": 3719, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3568.22, \"learn_time_ms\": 28133.885}", "{\"n\": 3720, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.92, \"learn_time_ms\": 28112.5}", "{\"n\": 3721, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.92, \"learn_time_ms\": 28131.185}", "{\"n\": 3722, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.46, \"learn_time_ms\": 28119.871}", "{\"n\": 3723, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3571.5, \"learn_time_ms\": 28112.263}", "{\"n\": 3724, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3567.43, \"learn_time_ms\": 28091.004}", "{\"n\": 3725, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.61, \"learn_time_ms\": 28084.578}", "{\"n\": 3726, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.74, \"learn_time_ms\": 28066.349}", "{\"n\": 3727, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.74, \"learn_time_ms\": 28066.137}", "{\"n\": 3728, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3568.86, \"learn_time_ms\": 28070.733}", "{\"n\": 3729, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3564.55, \"learn_time_ms\": 28067.495}", "{\"n\": 3730, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3579.85, \"learn_time_ms\": 28055.278}", "{\"n\": 3731, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3576.21, \"learn_time_ms\": 28043.37}", "{\"n\": 3732, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3582.53, \"learn_time_ms\": 28054.887}", "{\"n\": 3733, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3585.48, \"learn_time_ms\": 28027.57}", "{\"n\": 3734, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3585.44, \"learn_time_ms\": 28063.817}", "{\"n\": 3735, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3576.11, \"learn_time_ms\": 28066.64}", "{\"n\": 3736, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3577.46, \"learn_time_ms\": 28060.814}", "{\"n\": 3737, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3590.12, \"learn_time_ms\": 28107.45}", "{\"n\": 3738, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3590.12, \"learn_time_ms\": 28115.416}", "{\"n\": 3739, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3573.86, \"learn_time_ms\": 28108.214}", "{\"n\": 3740, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3584.45, \"learn_time_ms\": 28137.456}", "{\"n\": 3741, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3593.7, \"learn_time_ms\": 28159.13}", "{\"n\": 3742, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3605.9, \"learn_time_ms\": 28180.199}", "{\"n\": 3743, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3606.98, \"learn_time_ms\": 28178.513}", "{\"n\": 3744, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3606.98, \"learn_time_ms\": 28170.487}", "{\"n\": 3745, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3571.93, \"learn_time_ms\": 28167.36}", "{\"n\": 3746, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3581.31, \"learn_time_ms\": 28166.213}", "{\"n\": 3747, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3581.31, \"learn_time_ms\": 28154.845}", "{\"n\": 3748, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3584.2, \"learn_time_ms\": 28145.338}", "{\"n\": 3749, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3584.2, \"learn_time_ms\": 28136.871}", "{\"n\": 3750, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3586.32, \"learn_time_ms\": 28138.425}", "{\"n\": 3751, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3564.5, \"learn_time_ms\": 28104.686}", "{\"n\": 3752, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3564.5, \"learn_time_ms\": 28107.967}", "{\"n\": 3753, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3566.2, \"learn_time_ms\": 28120.537}", "{\"n\": 3754, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3566.2, \"learn_time_ms\": 28110.672}", "{\"n\": 3755, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3552.47, \"learn_time_ms\": 28112.736}", "{\"n\": 3756, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3558.64, \"learn_time_ms\": 28130.118}", "{\"n\": 3757, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3558.64, \"learn_time_ms\": 28120.402}", "{\"n\": 3758, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3558.64, \"learn_time_ms\": 28081.067}", "{\"n\": 3759, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3564.86, \"learn_time_ms\": 28105.245}", "{\"n\": 3760, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3571.79, \"learn_time_ms\": 28140.52}", "{\"n\": 3761, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3593.35, \"learn_time_ms\": 28127.273}", "{\"n\": 3762, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3582.7, \"learn_time_ms\": 28095.756}", "{\"n\": 3763, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3582.7, \"learn_time_ms\": 28056.439}", "{\"n\": 3764, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3597.32, \"learn_time_ms\": 28033.558}", "{\"n\": 3765, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3597.32, \"learn_time_ms\": 28047.337}", "{\"n\": 3766, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3592.86, \"learn_time_ms\": 28072.576}", "{\"n\": 3767, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.58, \"learn_time_ms\": 28056.642}", "{\"n\": 3768, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.58, \"learn_time_ms\": 28078.8}", "{\"n\": 3769, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3588.54, \"learn_time_ms\": 28108.88}", "{\"n\": 3770, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3590.75, \"learn_time_ms\": 28062.73}", "{\"n\": 3771, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3590.75, \"learn_time_ms\": 28111.898}", "{\"n\": 3772, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3602.32, \"learn_time_ms\": 28132.799}", "{\"n\": 3773, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3604.69, \"learn_time_ms\": 28123.618}", "{\"n\": 3774, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3599.66, \"learn_time_ms\": 28140.696}", "{\"n\": 3775, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3599.66, \"learn_time_ms\": 28101.843}", "{\"n\": 3776, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.9, \"learn_time_ms\": 28056.79}", "{\"n\": 3777, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3594.2, \"learn_time_ms\": 28109.692}", "{\"n\": 3778, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3596.63, \"learn_time_ms\": 28126.43}", "{\"n\": 3779, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.2, \"learn_time_ms\": 28089.871}", "{\"n\": 3780, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3595.37, \"learn_time_ms\": 28087.512}", "{\"n\": 3781, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3578.16, \"learn_time_ms\": 28037.614}", "{\"n\": 3782, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3578.16, \"learn_time_ms\": 28060.346}", "{\"n\": 3783, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3577.87, \"learn_time_ms\": 28073.437}", "{\"n\": 3784, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3572.15, \"learn_time_ms\": 28056.763}", "{\"n\": 3785, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3574.41, \"learn_time_ms\": 28108.38}", "{\"n\": 3786, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3580.17, \"learn_time_ms\": 28111.21}", "{\"n\": 3787, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3595.06, \"learn_time_ms\": 28072.291}", "{\"n\": 3788, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3595.06, \"learn_time_ms\": 28090.158}", "{\"n\": 3789, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3595.06, \"learn_time_ms\": 28074.11}", "{\"n\": 3790, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3604.3, \"learn_time_ms\": 28071.283}", "{\"n\": 3791, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3607.73, \"learn_time_ms\": 28072.601}", "{\"n\": 3792, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3607.73, \"learn_time_ms\": 28043.054}", "{\"n\": 3793, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3615.87, \"learn_time_ms\": 28096.523}", "{\"n\": 3794, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3615.87, \"learn_time_ms\": 28089.544}", "{\"n\": 3795, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3615.87, \"learn_time_ms\": 28020.998}", "{\"n\": 3796, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3633.25, \"learn_time_ms\": 28037.982}", "{\"n\": 3797, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3651.28, \"learn_time_ms\": 28030.604}", "{\"n\": 3798, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3651.28, \"learn_time_ms\": 28039.5}", "{\"n\": 3799, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3658.34, \"learn_time_ms\": 28063.836}", "{\"n\": 3800, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3658.34, \"learn_time_ms\": 28049.271}", "{\"n\": 3801, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3652.67, \"learn_time_ms\": 28066.043}", "{\"n\": 3802, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3680.18, \"learn_time_ms\": 28097.931}", "{\"n\": 3803, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3689.96, \"learn_time_ms\": 28023.554}", "{\"n\": 3804, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3689.96, \"learn_time_ms\": 28026.83}", "{\"n\": 3805, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3679.0, \"learn_time_ms\": 28044.334}", "{\"n\": 3806, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3649.66, \"learn_time_ms\": 28024.392}", "{\"n\": 3807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3644.19, \"learn_time_ms\": 28039.511}", "{\"n\": 3808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3642.06, \"learn_time_ms\": 28022.584}", "{\"n\": 3809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3641.24, \"learn_time_ms\": 28000.123}", "{\"n\": 3810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3646.5, \"learn_time_ms\": 27992.838}", "{\"n\": 3811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3646.5, \"learn_time_ms\": 27978.475}", "{\"n\": 3812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3653.11, \"learn_time_ms\": 27912.105}", "{\"n\": 3813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3645.0, \"learn_time_ms\": 27989.937}", "{\"n\": 3814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3639.46, \"learn_time_ms\": 27995.18}", "{\"n\": 3815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3648.92, \"learn_time_ms\": 27980.434}", "{\"n\": 3816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3643.33, \"learn_time_ms\": 27971.969}", "{\"n\": 3817, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3638.7, \"learn_time_ms\": 27979.71}", "{\"n\": 3818, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3633.17, \"learn_time_ms\": 27983.564}", "{\"n\": 3819, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3657.86, \"learn_time_ms\": 28023.001}", "{\"n\": 3820, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3657.86, \"learn_time_ms\": 28065.39}", "{\"n\": 3821, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3683.27, \"learn_time_ms\": 28085.781}", "{\"n\": 3822, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3683.27, \"learn_time_ms\": 28132.927}", "{\"n\": 3823, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3689.74, \"learn_time_ms\": 28117.229}", "{\"n\": 3824, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3706.81, \"learn_time_ms\": 28082.759}", "{\"n\": 3825, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3714.89, \"learn_time_ms\": 28102.663}", "{\"n\": 3826, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3712.16, \"learn_time_ms\": 28182.851}", "{\"n\": 3827, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3719.39, \"learn_time_ms\": 28172.636}", "{\"n\": 3828, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3719.39, \"learn_time_ms\": 28154.353}", "{\"n\": 3829, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3716.11, \"learn_time_ms\": 28104.178}", "{\"n\": 3830, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3737.41, \"learn_time_ms\": 28107.844}", "{\"n\": 3831, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3737.41, \"learn_time_ms\": 28129.454}", "{\"n\": 3832, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3730.88, \"learn_time_ms\": 28124.586}", "{\"n\": 3833, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3732.12, \"learn_time_ms\": 28131.341}", "{\"n\": 3834, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3723.16, \"learn_time_ms\": 28179.699}", "{\"n\": 3835, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3723.09, \"learn_time_ms\": 28209.643}", "{\"n\": 3836, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3723.09, \"learn_time_ms\": 28123.66}", "{\"n\": 3837, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3722.97, \"learn_time_ms\": 28133.821}", "{\"n\": 3838, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3721.37, \"learn_time_ms\": 28128.679}", "{\"n\": 3839, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3726.55, \"learn_time_ms\": 28176.536}", "{\"n\": 3840, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3750.75, \"learn_time_ms\": 28150.997}", "{\"n\": 3841, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3744.93, \"learn_time_ms\": 28117.452}", "{\"n\": 3842, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3744.93, \"learn_time_ms\": 28072.556}", "{\"n\": 3843, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3744.24, \"learn_time_ms\": 28034.657}", "{\"n\": 3844, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3744.24, \"learn_time_ms\": 28054.421}", "{\"n\": 3845, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3756.45, \"learn_time_ms\": 28019.952}", "{\"n\": 3846, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3770.09, \"learn_time_ms\": 28055.012}", "{\"n\": 3847, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3765.43, \"learn_time_ms\": 28073.916}", "{\"n\": 3848, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3782.41, \"learn_time_ms\": 28106.945}", "{\"n\": 3849, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3787.22, \"learn_time_ms\": 28094.034}", "{\"n\": 3850, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3787.22, \"learn_time_ms\": 28072.726}", "{\"n\": 3851, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3786.67, \"learn_time_ms\": 28108.61}", "{\"n\": 3852, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3799.6, \"learn_time_ms\": 28175.699}", "{\"n\": 3853, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3812.13, \"learn_time_ms\": 28165.124}", "{\"n\": 3854, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3824.47, \"learn_time_ms\": 28137.401}", "{\"n\": 3855, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3814.94, \"learn_time_ms\": 28157.681}", "{\"n\": 3856, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3824.09, \"learn_time_ms\": 28114.019}", "{\"n\": 3857, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3824.09, \"learn_time_ms\": 28078.939}", "{\"n\": 3858, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3815.65, \"learn_time_ms\": 28080.681}", "{\"n\": 3859, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3828.7, \"learn_time_ms\": 28054.405}", "{\"n\": 3860, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3830.69, \"learn_time_ms\": 28026.885}", "{\"n\": 3861, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3830.91, \"learn_time_ms\": 27958.225}", "{\"n\": 3862, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3830.91, \"learn_time_ms\": 27921.697}", "{\"n\": 3863, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3834.48, \"learn_time_ms\": 27921.281}", "{\"n\": 3864, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3832.79, \"learn_time_ms\": 27890.787}", "{\"n\": 3865, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3821.38, \"learn_time_ms\": 27889.149}", "{\"n\": 3866, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3792.28, \"learn_time_ms\": 27926.369}", "{\"n\": 3867, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3793.41, \"learn_time_ms\": 27935.429}", "{\"n\": 3868, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3791.71, \"learn_time_ms\": 27916.45}", "{\"n\": 3869, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3786.32, \"learn_time_ms\": 27897.999}", "{\"n\": 3870, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3783.32, \"learn_time_ms\": 27966.717}", "{\"n\": 3871, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3775.28, \"learn_time_ms\": 28015.418}", "{\"n\": 3872, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3780.05, \"learn_time_ms\": 28029.65}", "{\"n\": 3873, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3780.05, \"learn_time_ms\": 28082.674}", "{\"n\": 3874, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3768.12, \"learn_time_ms\": 28122.365}", "{\"n\": 3875, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3764.76, \"learn_time_ms\": 28104.739}", "{\"n\": 3876, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3753.28, \"learn_time_ms\": 28106.233}", "{\"n\": 3877, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3751.82, \"learn_time_ms\": 28117.099}", "{\"n\": 3878, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3765.01, \"learn_time_ms\": 28088.181}", "{\"n\": 3879, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3765.01, \"learn_time_ms\": 28142.889}", "{\"n\": 3880, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3771.61, \"learn_time_ms\": 28096.033}", "{\"n\": 3881, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3778.69, \"learn_time_ms\": 28064.285}", "{\"n\": 3882, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3750.97, \"learn_time_ms\": 28092.615}", "{\"n\": 3883, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3749.19, \"learn_time_ms\": 28065.331}", "{\"n\": 3884, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3767.87, \"learn_time_ms\": 28007.526}", "{\"n\": 3885, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3767.87, \"learn_time_ms\": 28006.461}", "{\"n\": 3886, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3769.98, \"learn_time_ms\": 28013.559}", "{\"n\": 3887, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3765.84, \"learn_time_ms\": 28020.269}", "{\"n\": 3888, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3765.45, \"learn_time_ms\": 28067.905}", "{\"n\": 3889, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3769.75, \"learn_time_ms\": 28061.036}", "{\"n\": 3890, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3769.75, \"learn_time_ms\": 28064.001}", "{\"n\": 3891, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3765.55, \"learn_time_ms\": 28054.6}", "{\"n\": 3892, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3750.93, \"learn_time_ms\": 28003.994}", "{\"n\": 3893, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3735.52, \"learn_time_ms\": 28039.73}", "{\"n\": 3894, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3727.58, \"learn_time_ms\": 28087.258}", "{\"n\": 3895, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3727.58, \"learn_time_ms\": 28110.403}", "{\"n\": 3896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3717.12, \"learn_time_ms\": 28096.154}", "{\"n\": 3897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3717.12, \"learn_time_ms\": 28087.119}", "{\"n\": 3898, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3693.96, \"learn_time_ms\": 28050.182}", "{\"n\": 3899, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3665.7, \"learn_time_ms\": 28043.139}", "{\"n\": 3900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3650.11, \"learn_time_ms\": 28082.953}", "{\"n\": 3901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3636.89, \"learn_time_ms\": 28108.132}", "{\"n\": 3902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3634.97, \"learn_time_ms\": 28143.933}", "{\"n\": 3903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3633.84, \"learn_time_ms\": 28127.134}", "{\"n\": 3904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3620.25, \"learn_time_ms\": 28122.858}", "{\"n\": 3905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3622.31, \"learn_time_ms\": 28146.124}", "{\"n\": 3906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3633.01, \"learn_time_ms\": 28111.388}", "{\"n\": 3907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3633.01, \"learn_time_ms\": 28093.383}", "{\"n\": 3908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3633.01, \"learn_time_ms\": 28121.034}", "{\"n\": 3909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3626.36, \"learn_time_ms\": 28136.849}", "{\"n\": 3910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3626.36, \"learn_time_ms\": 28164.539}", "{\"n\": 3911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3607.1, \"learn_time_ms\": 28207.296}", "{\"n\": 3912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3604.77, \"learn_time_ms\": 28194.663}", "{\"n\": 3913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3597.74, \"learn_time_ms\": 28176.846}", "{\"n\": 3914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3597.74, \"learn_time_ms\": 28153.166}", "{\"n\": 3915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3558.82, \"learn_time_ms\": 28160.482}", "{\"n\": 3916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3570.12, \"learn_time_ms\": 28228.905}", "{\"n\": 3917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3570.12, \"learn_time_ms\": 28213.049}", "{\"n\": 3918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3563.17, \"learn_time_ms\": 28226.435}", "{\"n\": 3919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3564.66, \"learn_time_ms\": 28161.642}", "{\"n\": 3920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3557.16, \"learn_time_ms\": 28137.461}", "{\"n\": 3921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3553.4, \"learn_time_ms\": 28137.062}", "{\"n\": 3922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3543.97, \"learn_time_ms\": 28144.077}", "{\"n\": 3923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3543.97, \"learn_time_ms\": 28142.362}", "{\"n\": 3924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3552.38, \"learn_time_ms\": 28126.511}", "{\"n\": 3925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3541.42, \"learn_time_ms\": 28090.93}", "{\"n\": 3926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.2, \"learn_time_ms\": 28073.255}", "{\"n\": 3927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3525.37, \"learn_time_ms\": 28080.552}", "{\"n\": 3928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3525.37, \"learn_time_ms\": 28024.491}", "{\"n\": 3929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3525.37, \"learn_time_ms\": 28068.3}", "{\"n\": 3930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3521.98, \"learn_time_ms\": 28036.071}", "{\"n\": 3931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3520.12, \"learn_time_ms\": 27982.556}", "{\"n\": 3932, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3520.93, \"learn_time_ms\": 27941.014}", "{\"n\": 3933, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.07, \"learn_time_ms\": 27945.366}", "{\"n\": 3934, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.07, \"learn_time_ms\": 27988.566}", "{\"n\": 3935, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.07, \"learn_time_ms\": 27998.372}", "{\"n\": 3936, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3514.46, \"learn_time_ms\": 27960.32}", "{\"n\": 3937, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3521.78, \"learn_time_ms\": 27996.604}", "{\"n\": 3938, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3517.97, \"learn_time_ms\": 28034.031}", "{\"n\": 3939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3528.37, \"learn_time_ms\": 28049.717}", "{\"n\": 3940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3528.37, \"learn_time_ms\": 28046.314}", "{\"n\": 3941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3511.86, \"learn_time_ms\": 28101.455}", "{\"n\": 3942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3517.39, \"learn_time_ms\": 28137.962}", "{\"n\": 3943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3518.76, \"learn_time_ms\": 28132.483}", "{\"n\": 3944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3518.76, \"learn_time_ms\": 28130.448}", "{\"n\": 3945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3527.04, \"learn_time_ms\": 28095.322}", "{\"n\": 3946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3527.04, \"learn_time_ms\": 28091.211}", "{\"n\": 3947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3529.26, \"learn_time_ms\": 28092.625}", "{\"n\": 3948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3523.04, \"learn_time_ms\": 28099.35}", "{\"n\": 3949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3523.46, \"learn_time_ms\": 28113.315}", "{\"n\": 3950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3541.04, \"learn_time_ms\": 28082.353}", "{\"n\": 3951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3546.09, \"learn_time_ms\": 28063.841}", "{\"n\": 3952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3546.09, \"learn_time_ms\": 28029.538}", "{\"n\": 3953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3534.31, \"learn_time_ms\": 28051.026}", "{\"n\": 3954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3523.94, \"learn_time_ms\": 28085.859}", "{\"n\": 3955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3523.87, \"learn_time_ms\": 28069.025}", "{\"n\": 3956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3527.96, \"learn_time_ms\": 28110.449}", "{\"n\": 3957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3527.96, \"learn_time_ms\": 28090.239}", "{\"n\": 3958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3535.27, \"learn_time_ms\": 28093.808}", "{\"n\": 3959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3543.63, \"learn_time_ms\": 28058.759}", "{\"n\": 3960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.55, \"learn_time_ms\": 28091.811}", "{\"n\": 3961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.64, \"learn_time_ms\": 28047.471}", "{\"n\": 3962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.64, \"learn_time_ms\": 28064.949}", "{\"n\": 3963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3545.24, \"learn_time_ms\": 28023.797}", "{\"n\": 3964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3550.48, \"learn_time_ms\": 27975.56}", "{\"n\": 3965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3544.5, \"learn_time_ms\": 28044.422}", "{\"n\": 3966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3544.5, \"learn_time_ms\": 28025.736}", "{\"n\": 3967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3549.48, \"learn_time_ms\": 28028.249}", "{\"n\": 3968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3531.11, \"learn_time_ms\": 28010.999}", "{\"n\": 3969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3535.39, \"learn_time_ms\": 28017.639}", "{\"n\": 3970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3529.13, \"learn_time_ms\": 28062.908}", "{\"n\": 3971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3537.89, \"learn_time_ms\": 28078.492}", "{\"n\": 3972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3545.85, \"learn_time_ms\": 28061.359}", "{\"n\": 3973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.0, \"learn_time_ms\": 28117.255}", "{\"n\": 3974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3579.14, \"learn_time_ms\": 28096.807}", "{\"n\": 3975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3588.66, \"learn_time_ms\": 28092.299}", "{\"n\": 3976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3596.21, \"learn_time_ms\": 28074.87}", "{\"n\": 3977, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3582.72, \"learn_time_ms\": 28069.462}", "{\"n\": 3978, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3588.87, \"learn_time_ms\": 28031.806}", "{\"n\": 3979, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3588.87, \"learn_time_ms\": 28025.25}", "{\"n\": 3980, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3587.06, \"learn_time_ms\": 28018.42}", "{\"n\": 3981, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3580.25, \"learn_time_ms\": 28007.787}", "{\"n\": 3982, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.84, \"learn_time_ms\": 28024.048}", "{\"n\": 3983, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3584.68, \"learn_time_ms\": 27995.303}", "{\"n\": 3984, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3589.22, \"learn_time_ms\": 28035.066}", "{\"n\": 3985, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3593.56, \"learn_time_ms\": 27997.553}", "{\"n\": 3986, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3590.55, \"learn_time_ms\": 28045.257}", "{\"n\": 3987, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3601.37, \"learn_time_ms\": 28020.475}", "{\"n\": 3988, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3606.06, \"learn_time_ms\": 28043.199}", "{\"n\": 3989, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3607.0, \"learn_time_ms\": 28033.956}", "{\"n\": 3990, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3601.11, \"learn_time_ms\": 28012.181}", "{\"n\": 3991, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3585.06, \"learn_time_ms\": 28056.037}", "{\"n\": 3992, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.76, \"learn_time_ms\": 28091.662}", "{\"n\": 3993, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.76, \"learn_time_ms\": 28067.443}", "{\"n\": 3994, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3568.99, \"learn_time_ms\": 28059.75}", "{\"n\": 3995, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3568.99, \"learn_time_ms\": 28084.314}", "{\"n\": 3996, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.07, \"learn_time_ms\": 28075.635}", "{\"n\": 3997, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3540.07, \"learn_time_ms\": 28078.401}", "{\"n\": 3998, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3540.19, \"learn_time_ms\": 28086.633}", "{\"n\": 3999, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3540.19, \"learn_time_ms\": 28151.635}", "{\"n\": 4000, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3543.48, \"learn_time_ms\": 28144.712}"]["{\"n\": 4001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29554.334}", "{\"n\": 4002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29118.021}", "{\"n\": 4003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28969.493}", "{\"n\": 4004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28863.032}", "{\"n\": 4005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28860.161}", "{\"n\": 4006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28767.294}", "{\"n\": 4007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28729.447}", "{\"n\": 4008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28705.001}", "{\"n\": 4009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28666.23}", "{\"n\": 4010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28611.719}", "{\"n\": 4011, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2749.0, \"learn_time_ms\": 28522.672}", "{\"n\": 4012, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2755.3333333333335, \"learn_time_ms\": 28490.896}", "{\"n\": 4013, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3213.0, \"learn_time_ms\": 28455.228}", "{\"n\": 4014, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.428571428571429, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3250.1428571428573, \"learn_time_ms\": 28454.063}", "{\"n\": 4015, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.125, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3331.75, \"learn_time_ms\": 28420.959}", "{\"n\": 4016, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.125, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3331.75, \"learn_time_ms\": 28432.521}", "{\"n\": 4017, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.125, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3331.75, \"learn_time_ms\": 28378.77}", "{\"n\": 4018, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3475.1666666666665, \"learn_time_ms\": 28298.344}", "{\"n\": 4019, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3605.4, \"learn_time_ms\": 28285.7}", "{\"n\": 4020, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3605.4, \"learn_time_ms\": 28257.457}", "{\"n\": 4021, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.8125, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3686.125, \"learn_time_ms\": 28209.215}", "{\"n\": 4022, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.8125, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3686.125, \"learn_time_ms\": 28157.221}", "{\"n\": 4023, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.882352941176471, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3660.235294117647, \"learn_time_ms\": 28125.306}", "{\"n\": 4024, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.142857142857142, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3583.6190476190477, \"learn_time_ms\": 28091.438}", "{\"n\": 4025, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.045454545454545, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3609.5454545454545, \"learn_time_ms\": 28020.699}", "{\"n\": 4026, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.875, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3647.25, \"learn_time_ms\": 27986.503}", "{\"n\": 4027, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.875, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3647.25, \"learn_time_ms\": 28005.718}", "{\"n\": 4028, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.875, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3647.25, \"learn_time_ms\": 28039.199}", "{\"n\": 4029, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3620.423076923077, \"learn_time_ms\": 28049.3}", "{\"n\": 4030, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.724137931034482, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3655.448275862069, \"learn_time_ms\": 28099.271}", "{\"n\": 4031, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.741935483870968, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3649.6129032258063, \"learn_time_ms\": 28083.77}", "{\"n\": 4032, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.741935483870968, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3649.6129032258063, \"learn_time_ms\": 28101.114}", "{\"n\": 4033, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71875, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3630.625, \"learn_time_ms\": 28091.722}", "{\"n\": 4034, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.705882352941176, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3612.8823529411766, \"learn_time_ms\": 28061.998}", "{\"n\": 4035, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3591.4, \"learn_time_ms\": 28093.033}", "{\"n\": 4036, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.833333333333334, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3585.1666666666665, \"learn_time_ms\": 28103.147}", "{\"n\": 4037, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.054054054054054, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3551.945945945946, \"learn_time_ms\": 28096.746}", "{\"n\": 4038, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.871794871794872, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3583.051282051282, \"learn_time_ms\": 28056.211}", "{\"n\": 4039, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.871794871794872, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3583.051282051282, \"learn_time_ms\": 28046.473}", "{\"n\": 4040, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3580.75, \"learn_time_ms\": 28044.363}", "{\"n\": 4041, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.166666666666666, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3535.690476190476, \"learn_time_ms\": 28024.079}", "{\"n\": 4042, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.069767441860465, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3557.232558139535, \"learn_time_ms\": 28021.568}", "{\"n\": 4043, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3578.681818181818, \"learn_time_ms\": 28029.705}", "{\"n\": 4044, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.911111111111111, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3599.5777777777776, \"learn_time_ms\": 28047.808}", "{\"n\": 4045, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.936170212765957, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3613.340425531915, \"learn_time_ms\": 28007.427}", "{\"n\": 4046, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.936170212765957, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3613.340425531915, \"learn_time_ms\": 27992.626}", "{\"n\": 4047, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3630.08, \"learn_time_ms\": 27976.936}", "{\"n\": 4048, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.705882352941176, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3656.5882352941176, \"learn_time_ms\": 28044.843}", "{\"n\": 4049, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.705882352941176, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3656.5882352941176, \"learn_time_ms\": 28015.212}", "{\"n\": 4050, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.574074074074074, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3689.6481481481483, \"learn_time_ms\": 27975.719}", "{\"n\": 4051, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.563636363636364, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3688.3636363636365, \"learn_time_ms\": 28003.344}", "{\"n\": 4052, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.563636363636364, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3688.3636363636365, \"learn_time_ms\": 27978.946}", "{\"n\": 4053, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.517857142857142, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3694.25, \"learn_time_ms\": 27995.509}", "{\"n\": 4054, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.578947368421053, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3688.035087719298, \"learn_time_ms\": 27997.882}", "{\"n\": 4055, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.516666666666667, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3687.85, \"learn_time_ms\": 28037.585}", "{\"n\": 4056, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.596774193548388, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3677.983870967742, \"learn_time_ms\": 28034.839}", "{\"n\": 4057, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.571428571428571, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3678.9523809523807, \"learn_time_ms\": 28017.237}", "{\"n\": 4058, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5625, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3688.53125, \"learn_time_ms\": 27973.281}", "{\"n\": 4059, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5625, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3688.53125, \"learn_time_ms\": 27962.748}", "{\"n\": 4060, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5625, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3688.53125, \"learn_time_ms\": 27968.306}", "{\"n\": 4061, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.313432835820896, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3727.208955223881, \"learn_time_ms\": 27973.93}", "{\"n\": 4062, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.382352941176471, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3715.573529411765, \"learn_time_ms\": 27981.749}", "{\"n\": 4063, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.492957746478874, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3690.507042253521, \"learn_time_ms\": 27916.489}", "{\"n\": 4064, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.492957746478874, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3690.507042253521, \"learn_time_ms\": 27903.473}", "{\"n\": 4065, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.416666666666666, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3699.8888888888887, \"learn_time_ms\": 27872.215}", "{\"n\": 4066, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.416666666666666, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3699.8888888888887, \"learn_time_ms\": 27855.192}", "{\"n\": 4067, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.378378378378379, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3701.054054054054, \"learn_time_ms\": 27931.214}", "{\"n\": 4068, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.376623376623376, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3711.5584415584417, \"learn_time_ms\": 27955.044}", "{\"n\": 4069, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41025641025641, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3704.474358974359, \"learn_time_ms\": 28000.518}", "{\"n\": 4070, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.367088607594937, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3714.9240506329115, \"learn_time_ms\": 28000.33}", "{\"n\": 4071, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.367088607594937, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3714.9240506329115, \"learn_time_ms\": 27975.791}", "{\"n\": 4072, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3715.0, \"learn_time_ms\": 27994.227}", "{\"n\": 4073, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.25609756097561, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3714.060975609756, \"learn_time_ms\": 28007.548}", "{\"n\": 4074, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3713.7261904761904, \"learn_time_ms\": 28015.485}", "{\"n\": 4075, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.183908045977011, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3727.022988505747, \"learn_time_ms\": 28051.647}", "{\"n\": 4076, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.183908045977011, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3727.022988505747, \"learn_time_ms\": 28057.223}", "{\"n\": 4077, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.272727272727273, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3715.4886363636365, \"learn_time_ms\": 27968.915}", "{\"n\": 4078, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.272727272727273, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3715.4886363636365, \"learn_time_ms\": 27958.945}", "{\"n\": 4079, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.269662921348315, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3712.876404494382, \"learn_time_ms\": 27941.844}", "{\"n\": 4080, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.16304347826087, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3729.391304347826, \"learn_time_ms\": 27976.918}", "{\"n\": 4081, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.16842105263158, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3729.2105263157896, \"learn_time_ms\": 27965.118}", "{\"n\": 4082, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.16842105263158, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3729.2105263157896, \"learn_time_ms\": 27934.952}", "{\"n\": 4083, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.16842105263158, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3729.2105263157896, \"learn_time_ms\": 27999.731}", "{\"n\": 4084, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.21875, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3718.3229166666665, \"learn_time_ms\": 27970.662}", "{\"n\": 4085, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.21875, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3718.3229166666665, \"learn_time_ms\": 27942.219}", "{\"n\": 4086, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3716.61, \"learn_time_ms\": 27936.049}", "{\"n\": 4087, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3733.03, \"learn_time_ms\": 27998.991}", "{\"n\": 4088, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3745.46, \"learn_time_ms\": 27979.178}", "{\"n\": 4089, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3745.46, \"learn_time_ms\": 27912.339}", "{\"n\": 4090, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3751.91, \"learn_time_ms\": 27894.665}", "{\"n\": 4091, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3754.29, \"learn_time_ms\": 27905.995}", "{\"n\": 4092, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3746.75, \"learn_time_ms\": 27932.042}", "{\"n\": 4093, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3750.97, \"learn_time_ms\": 27897.965}", "{\"n\": 4094, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3749.58, \"learn_time_ms\": 27931.823}", "{\"n\": 4095, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3747.77, \"learn_time_ms\": 27976.735}", "{\"n\": 4096, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3747.77, \"learn_time_ms\": 27995.25}", "{\"n\": 4097, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3735.89, \"learn_time_ms\": 27983.365}", "{\"n\": 4098, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3735.89, \"learn_time_ms\": 28006.981}", "{\"n\": 4099, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3732.46, \"learn_time_ms\": 28022.821}", "{\"n\": 4100, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3733.25, \"learn_time_ms\": 27985.475}", "{\"n\": 4101, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3756.67, \"learn_time_ms\": 27995.433}", "{\"n\": 4102, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3763.17, \"learn_time_ms\": 28008.26}", "{\"n\": 4103, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3757.03, \"learn_time_ms\": 27976.501}", "{\"n\": 4104, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3757.03, \"learn_time_ms\": 27971.875}", "{\"n\": 4105, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3757.03, \"learn_time_ms\": 27866.439}", "{\"n\": 4106, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3764.9, \"learn_time_ms\": 27860.841}", "{\"n\": 4107, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3770.78, \"learn_time_ms\": 27854.795}", "{\"n\": 4108, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3760.34, \"learn_time_ms\": 27881.513}", "{\"n\": 4109, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3763.45, \"learn_time_ms\": 27937.115}", "{\"n\": 4110, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3763.45, \"learn_time_ms\": 27950.131}", "{\"n\": 4111, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3763.45, \"learn_time_ms\": 27947.639}", "{\"n\": 4112, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3767.34, \"learn_time_ms\": 27974.074}", "{\"n\": 4113, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3775.04, \"learn_time_ms\": 28034.507}", "{\"n\": 4114, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3775.04, \"learn_time_ms\": 28005.946}", "{\"n\": 4115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3776.34, \"learn_time_ms\": 28037.006}", "{\"n\": 4116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3776.34, \"learn_time_ms\": 28044.831}", "{\"n\": 4117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3776.34, \"learn_time_ms\": 28033.515}", "{\"n\": 4118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3773.83, \"learn_time_ms\": 27979.481}", "{\"n\": 4119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3780.53, \"learn_time_ms\": 27975.777}", "{\"n\": 4120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3771.24, \"learn_time_ms\": 28000.336}", "{\"n\": 4121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3771.24, \"learn_time_ms\": 28006.836}", "{\"n\": 4122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3771.94, \"learn_time_ms\": 27976.234}", "{\"n\": 4123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3771.94, \"learn_time_ms\": 27988.91}", "{\"n\": 4124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3772.21, \"learn_time_ms\": 28012.841}", "{\"n\": 4125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3772.21, \"learn_time_ms\": 28051.954}", "{\"n\": 4126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3776.66, \"learn_time_ms\": 28057.897}", "{\"n\": 4127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3760.44, \"learn_time_ms\": 28076.438}", "{\"n\": 4128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3762.83, \"learn_time_ms\": 28080.547}", "{\"n\": 4129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3762.83, \"learn_time_ms\": 28080.629}", "{\"n\": 4130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3762.83, \"learn_time_ms\": 28055.685}", "{\"n\": 4131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3761.53, \"learn_time_ms\": 28063.326}", "{\"n\": 4132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3763.6, \"learn_time_ms\": 28066.417}", "{\"n\": 4133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3772.5, \"learn_time_ms\": 28036.976}", "{\"n\": 4134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3780.11, \"learn_time_ms\": 28040.861}", "{\"n\": 4135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3780.11, \"learn_time_ms\": 28097.449}", "{\"n\": 4136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3779.66, \"learn_time_ms\": 28101.529}", "{\"n\": 4137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3786.97, \"learn_time_ms\": 28110.089}", "{\"n\": 4138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3775.4, \"learn_time_ms\": 28108.019}", "{\"n\": 4139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3756.4, \"learn_time_ms\": 28101.221}", "{\"n\": 4140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3771.08, \"learn_time_ms\": 28123.565}", "{\"n\": 4141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3807.82, \"learn_time_ms\": 28085.585}", "{\"n\": 4142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3807.82, \"learn_time_ms\": 28097.543}", "{\"n\": 4143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3807.82, \"learn_time_ms\": 28099.126}", "{\"n\": 4144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3804.81, \"learn_time_ms\": 28115.176}", "{\"n\": 4145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3804.62, \"learn_time_ms\": 28106.578}", "{\"n\": 4146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3801.96, \"learn_time_ms\": 28108.817}", "{\"n\": 4147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3795.59, \"learn_time_ms\": 28072.799}", "{\"n\": 4148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3806.82, \"learn_time_ms\": 28117.829}", "{\"n\": 4149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3806.82, \"learn_time_ms\": 28119.481}", "{\"n\": 4150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3815.83, \"learn_time_ms\": 28062.187}", "{\"n\": 4151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3809.44, \"learn_time_ms\": 28094.959}", "{\"n\": 4152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3812.14, \"learn_time_ms\": 28081.064}", "{\"n\": 4153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3812.14, \"learn_time_ms\": 28069.842}", "{\"n\": 4154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3812.14, \"learn_time_ms\": 28098.867}", "{\"n\": 4155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3816.27, \"learn_time_ms\": 28088.464}", "{\"n\": 4156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3798.16, \"learn_time_ms\": 28079.798}", "{\"n\": 4157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3792.11, \"learn_time_ms\": 28090.49}", "{\"n\": 4158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3791.89, \"learn_time_ms\": 28063.333}", "{\"n\": 4159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3784.32, \"learn_time_ms\": 28115.079}", "{\"n\": 4160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3785.87, \"learn_time_ms\": 28180.559}", "{\"n\": 4161, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3795.11, \"learn_time_ms\": 28169.151}", "{\"n\": 4162, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3808.7, \"learn_time_ms\": 28142.55}", "{\"n\": 4163, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3824.62, \"learn_time_ms\": 28131.911}", "{\"n\": 4164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3837.85, \"learn_time_ms\": 28088.582}", "{\"n\": 4165, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3826.64, \"learn_time_ms\": 28060.543}", "{\"n\": 4166, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3826.64, \"learn_time_ms\": 28038.698}", "{\"n\": 4167, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3826.64, \"learn_time_ms\": 28019.703}", "{\"n\": 4168, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3828.75, \"learn_time_ms\": 28064.423}", "{\"n\": 4169, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3821.91, \"learn_time_ms\": 28012.252}", "{\"n\": 4170, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3810.69, \"learn_time_ms\": 28001.076}", "{\"n\": 4171, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3803.89, \"learn_time_ms\": 28001.727}", "{\"n\": 4172, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3803.89, \"learn_time_ms\": 28035.314}", "{\"n\": 4173, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3792.69, \"learn_time_ms\": 28055.186}", "{\"n\": 4174, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3783.9, \"learn_time_ms\": 28030.851}", "{\"n\": 4175, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3768.17, \"learn_time_ms\": 28009.816}", "{\"n\": 4176, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.69, \"learn_time_ms\": 28037.412}", "{\"n\": 4177, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3768.53, \"learn_time_ms\": 28048.652}", "{\"n\": 4178, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3755.94, \"learn_time_ms\": 28018.777}", "{\"n\": 4179, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3746.87, \"learn_time_ms\": 28015.797}", "{\"n\": 4180, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3750.63, \"learn_time_ms\": 27944.37}", "{\"n\": 4181, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3736.78, \"learn_time_ms\": 27940.042}", "{\"n\": 4182, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3756.14, \"learn_time_ms\": 27913.893}", "{\"n\": 4183, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3750.09, \"learn_time_ms\": 27901.83}", "{\"n\": 4184, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3750.09, \"learn_time_ms\": 27900.499}", "{\"n\": 4185, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3744.23, \"learn_time_ms\": 27915.19}", "{\"n\": 4186, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3744.23, \"learn_time_ms\": 27898.286}", "{\"n\": 4187, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3760.86, \"learn_time_ms\": 27849.065}", "{\"n\": 4188, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3760.86, \"learn_time_ms\": 27833.572}", "{\"n\": 4189, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3758.88, \"learn_time_ms\": 27867.157}", "{\"n\": 4190, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3766.77, \"learn_time_ms\": 27922.456}", "{\"n\": 4191, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3766.77, \"learn_time_ms\": 27931.836}", "{\"n\": 4192, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3773.03, \"learn_time_ms\": 27922.421}", "{\"n\": 4193, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3777.17, \"learn_time_ms\": 27928.742}", "{\"n\": 4194, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3783.08, \"learn_time_ms\": 27962.445}", "{\"n\": 4195, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3781.72, \"learn_time_ms\": 27964.679}", "{\"n\": 4196, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3781.72, \"learn_time_ms\": 28013.883}", "{\"n\": 4197, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3781.72, \"learn_time_ms\": 28082.826}", "{\"n\": 4198, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3779.05, \"learn_time_ms\": 28089.961}", "{\"n\": 4199, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3774.76, \"learn_time_ms\": 27995.779}", "{\"n\": 4200, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3767.15, \"learn_time_ms\": 27970.753}", "{\"n\": 4201, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3745.81, \"learn_time_ms\": 28021.79}", "{\"n\": 4202, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3745.81, \"learn_time_ms\": 28059.054}", "{\"n\": 4203, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3733.32, \"learn_time_ms\": 28072.513}", "{\"n\": 4204, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3722.21, \"learn_time_ms\": 28088.756}", "{\"n\": 4205, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3726.55, \"learn_time_ms\": 28097.186}", "{\"n\": 4206, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3720.16, \"learn_time_ms\": 28042.913}", "{\"n\": 4207, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3704.15, \"learn_time_ms\": 28017.762}", "{\"n\": 4208, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3704.15, \"learn_time_ms\": 28006.316}", "{\"n\": 4209, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3718.8, \"learn_time_ms\": 28069.425}", "{\"n\": 4210, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3718.8, \"learn_time_ms\": 28101.359}", "{\"n\": 4211, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3721.31, \"learn_time_ms\": 28055.828}", "{\"n\": 4212, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3713.46, \"learn_time_ms\": 28056.797}", "{\"n\": 4213, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3720.25, \"learn_time_ms\": 28019.729}", "{\"n\": 4214, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3710.47, \"learn_time_ms\": 27997.784}", "{\"n\": 4215, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3710.47, \"learn_time_ms\": 28013.108}", "{\"n\": 4216, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3670.84, \"learn_time_ms\": 28046.179}", "{\"n\": 4217, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3650.77, \"learn_time_ms\": 28052.057}", "{\"n\": 4218, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3641.11, \"learn_time_ms\": 28052.897}", "{\"n\": 4219, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3636.06, \"learn_time_ms\": 28038.416}", "{\"n\": 4220, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3636.06, \"learn_time_ms\": 28090.573}", "{\"n\": 4221, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3630.76, \"learn_time_ms\": 28106.022}", "{\"n\": 4222, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3636.02, \"learn_time_ms\": 28102.265}", "{\"n\": 4223, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3632.05, \"learn_time_ms\": 28172.566}", "{\"n\": 4224, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3657.9, \"learn_time_ms\": 28181.068}", "{\"n\": 4225, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3658.51, \"learn_time_ms\": 28174.841}", "{\"n\": 4226, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3648.36, \"learn_time_ms\": 28137.793}", "{\"n\": 4227, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3638.82, \"learn_time_ms\": 28138.398}", "{\"n\": 4228, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3636.24, \"learn_time_ms\": 28166.061}", "{\"n\": 4229, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3636.24, \"learn_time_ms\": 28143.607}", "{\"n\": 4230, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3636.35, \"learn_time_ms\": 28056.615}", "{\"n\": 4231, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3627.62, \"learn_time_ms\": 28044.289}", "{\"n\": 4232, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3632.34, \"learn_time_ms\": 28021.576}", "{\"n\": 4233, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3632.27, \"learn_time_ms\": 27990.627}", "{\"n\": 4234, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3603.99, \"learn_time_ms\": 28023.692}", "{\"n\": 4235, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3583.86, \"learn_time_ms\": 28006.966}", "{\"n\": 4236, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3583.58, \"learn_time_ms\": 28046.78}", "{\"n\": 4237, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3585.14, \"learn_time_ms\": 28040.448}", "{\"n\": 4238, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3549.06, \"learn_time_ms\": 28028.874}", "{\"n\": 4239, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3549.95, \"learn_time_ms\": 28035.04}", "{\"n\": 4240, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3563.29, \"learn_time_ms\": 28072.954}", "{\"n\": 4241, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3563.29, \"learn_time_ms\": 28057.558}", "{\"n\": 4242, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3562.14, \"learn_time_ms\": 28061.022}", "{\"n\": 4243, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3555.36, \"learn_time_ms\": 28043.473}", "{\"n\": 4244, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3568.01, \"learn_time_ms\": 28024.211}", "{\"n\": 4245, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3568.73, \"learn_time_ms\": 28023.109}", "{\"n\": 4246, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3568.57, \"learn_time_ms\": 27972.482}", "{\"n\": 4247, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3578.19, \"learn_time_ms\": 27928.053}", "{\"n\": 4248, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3596.19, \"learn_time_ms\": 27904.214}", "{\"n\": 4249, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3613.95, \"learn_time_ms\": 27913.012}", "{\"n\": 4250, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3615.6, \"learn_time_ms\": 27917.229}", "{\"n\": 4251, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3615.6, \"learn_time_ms\": 27910.675}", "{\"n\": 4252, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3601.05, \"learn_time_ms\": 27885.034}", "{\"n\": 4253, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3613.04, \"learn_time_ms\": 27876.06}", "{\"n\": 4254, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3612.74, \"learn_time_ms\": 27865.664}", "{\"n\": 4255, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3617.54, \"learn_time_ms\": 27843.965}", "{\"n\": 4256, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3617.54, \"learn_time_ms\": 27913.458}", "{\"n\": 4257, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3627.18, \"learn_time_ms\": 27962.149}", "{\"n\": 4258, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3622.73, \"learn_time_ms\": 27997.427}", "{\"n\": 4259, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3612.88, \"learn_time_ms\": 27998.926}", "{\"n\": 4260, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3595.18, \"learn_time_ms\": 28015.124}", "{\"n\": 4261, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3590.03, \"learn_time_ms\": 28022.461}", "{\"n\": 4262, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3599.88, \"learn_time_ms\": 28066.445}", "{\"n\": 4263, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.76, \"learn_time_ms\": 28043.596}", "{\"n\": 4264, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3576.93, \"learn_time_ms\": 28036.487}", "{\"n\": 4265, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3576.28, \"learn_time_ms\": 28056.846}", "{\"n\": 4266, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3564.19, \"learn_time_ms\": 27989.187}", "{\"n\": 4267, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3560.6, \"learn_time_ms\": 27978.836}", "{\"n\": 4268, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3560.6, \"learn_time_ms\": 27966.186}", "{\"n\": 4269, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3549.02, \"learn_time_ms\": 27972.338}", "{\"n\": 4270, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3560.35, \"learn_time_ms\": 27979.517}", "{\"n\": 4271, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3556.86, \"learn_time_ms\": 27997.551}", "{\"n\": 4272, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3562.99, \"learn_time_ms\": 27977.308}", "{\"n\": 4273, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3578.95, \"learn_time_ms\": 28018.902}", "{\"n\": 4274, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3579.82, \"learn_time_ms\": 28021.586}", "{\"n\": 4275, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3587.66, \"learn_time_ms\": 27990.315}", "{\"n\": 4276, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3585.22, \"learn_time_ms\": 27994.889}", "{\"n\": 4277, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3595.08, \"learn_time_ms\": 27991.594}", "{\"n\": 4278, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3590.59, \"learn_time_ms\": 27961.584}", "{\"n\": 4279, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3587.0, \"learn_time_ms\": 27992.558}", "{\"n\": 4280, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.62, \"learn_time_ms\": 27965.107}", "{\"n\": 4281, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3572.08, \"learn_time_ms\": 27965.499}", "{\"n\": 4282, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3579.72, \"learn_time_ms\": 27970.737}", "{\"n\": 4283, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3597.35, \"learn_time_ms\": 27961.801}", "{\"n\": 4284, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3588.55, \"learn_time_ms\": 27973.438}", "{\"n\": 4285, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3586.68, \"learn_time_ms\": 27977.348}", "{\"n\": 4286, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3598.19, \"learn_time_ms\": 28003.323}", "{\"n\": 4287, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3597.02, \"learn_time_ms\": 28002.011}", "{\"n\": 4288, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3590.82, \"learn_time_ms\": 27959.612}", "{\"n\": 4289, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3601.14, \"learn_time_ms\": 27892.873}", "{\"n\": 4290, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3634.53, \"learn_time_ms\": 27922.997}", "{\"n\": 4291, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3654.57, \"learn_time_ms\": 27892.598}", "{\"n\": 4292, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3646.37, \"learn_time_ms\": 27905.107}", "{\"n\": 4293, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3640.44, \"learn_time_ms\": 27907.785}", "{\"n\": 4294, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3640.44, \"learn_time_ms\": 27852.597}", "{\"n\": 4295, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3648.99, \"learn_time_ms\": 27882.065}", "{\"n\": 4296, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3679.32, \"learn_time_ms\": 27893.136}", "{\"n\": 4297, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3678.43, \"learn_time_ms\": 27924.763}", "{\"n\": 4298, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3683.96, \"learn_time_ms\": 27990.82}", "{\"n\": 4299, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3683.96, \"learn_time_ms\": 28030.452}", "{\"n\": 4300, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3675.97, \"learn_time_ms\": 27966.721}", "{\"n\": 4301, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3675.97, \"learn_time_ms\": 27977.419}", "{\"n\": 4302, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3652.59, \"learn_time_ms\": 27978.719}", "{\"n\": 4303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3650.83, \"learn_time_ms\": 27972.631}", "{\"n\": 4304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3650.83, \"learn_time_ms\": 27977.189}", "{\"n\": 4305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3653.16, \"learn_time_ms\": 27999.178}", "{\"n\": 4306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3676.64, \"learn_time_ms\": 27969.636}", "{\"n\": 4307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3699.59, \"learn_time_ms\": 27917.104}", "{\"n\": 4308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3677.96, \"learn_time_ms\": 27949.106}", "{\"n\": 4309, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3677.96, \"learn_time_ms\": 27969.39}", "{\"n\": 4310, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3674.44, \"learn_time_ms\": 27971.497}", "{\"n\": 4311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3692.75, \"learn_time_ms\": 27988.868}", "{\"n\": 4312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3685.63, \"learn_time_ms\": 27964.49}", "{\"n\": 4313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3677.89, \"learn_time_ms\": 28011.713}", "{\"n\": 4314, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3675.31, \"learn_time_ms\": 28041.15}", "{\"n\": 4315, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3669.59, \"learn_time_ms\": 28025.731}", "{\"n\": 4316, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3667.74, \"learn_time_ms\": 28026.769}", "{\"n\": 4317, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3667.74, \"learn_time_ms\": 28090.915}", "{\"n\": 4318, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3667.74, \"learn_time_ms\": 28042.431}", "{\"n\": 4319, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3672.55, \"learn_time_ms\": 28024.034}", "{\"n\": 4320, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3668.85, \"learn_time_ms\": 28069.413}", "{\"n\": 4321, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3659.25, \"learn_time_ms\": 28065.651}", "{\"n\": 4322, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3659.25, \"learn_time_ms\": 28056.939}", "{\"n\": 4323, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3664.87, \"learn_time_ms\": 27988.681}", "{\"n\": 4324, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3651.93, \"learn_time_ms\": 27995.098}", "{\"n\": 4325, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3652.0, \"learn_time_ms\": 27979.792}", "{\"n\": 4326, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3637.71, \"learn_time_ms\": 27973.895}", "{\"n\": 4327, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3648.51, \"learn_time_ms\": 27955.715}", "{\"n\": 4328, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3643.98, \"learn_time_ms\": 28000.839}", "{\"n\": 4329, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3643.98, \"learn_time_ms\": 27986.094}", "{\"n\": 4330, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3638.45, \"learn_time_ms\": 27950.666}", "{\"n\": 4331, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3632.31, \"learn_time_ms\": 27957.445}", "{\"n\": 4332, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3640.61, \"learn_time_ms\": 28005.366}", "{\"n\": 4333, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3643.43, \"learn_time_ms\": 28020.362}", "{\"n\": 4334, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3651.83, \"learn_time_ms\": 28035.877}", "{\"n\": 4335, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3650.1, \"learn_time_ms\": 28037.54}", "{\"n\": 4336, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3648.75, \"learn_time_ms\": 28062.477}", "{\"n\": 4337, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3663.13, \"learn_time_ms\": 28037.935}", "{\"n\": 4338, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3670.45, \"learn_time_ms\": 28005.566}", "{\"n\": 4339, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3660.83, \"learn_time_ms\": 27987.254}", "{\"n\": 4340, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3652.82, \"learn_time_ms\": 27975.73}", "{\"n\": 4341, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3652.82, \"learn_time_ms\": 27933.187}", "{\"n\": 4342, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3644.01, \"learn_time_ms\": 27915.894}", "{\"n\": 4343, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3634.52, \"learn_time_ms\": 27889.326}", "{\"n\": 4344, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3617.5, \"learn_time_ms\": 27827.413}", "{\"n\": 4345, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3623.2, \"learn_time_ms\": 27817.934}", "{\"n\": 4346, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3616.98, \"learn_time_ms\": 27820.208}", "{\"n\": 4347, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3605.05, \"learn_time_ms\": 27859.288}", "{\"n\": 4348, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3605.05, \"learn_time_ms\": 27831.219}", "{\"n\": 4349, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3605.05, \"learn_time_ms\": 27851.507}", "{\"n\": 4350, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3600.82, \"learn_time_ms\": 27895.967}", "{\"n\": 4351, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3605.35, \"learn_time_ms\": 27895.996}", "{\"n\": 4352, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3605.65, \"learn_time_ms\": 27896.15}", "{\"n\": 4353, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3613.73, \"learn_time_ms\": 27948.641}", "{\"n\": 4354, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3618.4, \"learn_time_ms\": 27988.051}", "{\"n\": 4355, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3629.36, \"learn_time_ms\": 27965.105}", "{\"n\": 4356, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3629.36, \"learn_time_ms\": 27972.334}", "{\"n\": 4357, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3623.72, \"learn_time_ms\": 27940.868}", "{\"n\": 4358, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3633.66, \"learn_time_ms\": 28006.203}", "{\"n\": 4359, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3631.89, \"learn_time_ms\": 28029.178}", "{\"n\": 4360, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3631.18, \"learn_time_ms\": 28030.361}", "{\"n\": 4361, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3631.18, \"learn_time_ms\": 28038.826}", "{\"n\": 4362, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3633.86, \"learn_time_ms\": 28002.683}", "{\"n\": 4363, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3621.21, \"learn_time_ms\": 27985.258}", "{\"n\": 4364, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3617.86, \"learn_time_ms\": 28014.449}", "{\"n\": 4365, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3601.52, \"learn_time_ms\": 28063.227}", "{\"n\": 4366, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3601.02, \"learn_time_ms\": 28024.634}", "{\"n\": 4367, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3594.77, \"learn_time_ms\": 28032.388}", "{\"n\": 4368, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3608.84, \"learn_time_ms\": 28017.799}", "{\"n\": 4369, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3606.42, \"learn_time_ms\": 28019.79}", "{\"n\": 4370, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.71, \"learn_time_ms\": 28020.7}", "{\"n\": 4371, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3573.74, \"learn_time_ms\": 28032.997}", "{\"n\": 4372, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3573.74, \"learn_time_ms\": 28062.8}", "{\"n\": 4373, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3573.74, \"learn_time_ms\": 28062.993}", "{\"n\": 4374, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3572.56, \"learn_time_ms\": 28013.134}", "{\"n\": 4375, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3576.88, \"learn_time_ms\": 27991.622}", "{\"n\": 4376, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3578.33, \"learn_time_ms\": 27993.931}", "{\"n\": 4377, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3582.04, \"learn_time_ms\": 28000.285}", "{\"n\": 4378, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3574.24, \"learn_time_ms\": 27960.9}", "{\"n\": 4379, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3574.24, \"learn_time_ms\": 27996.471}", "{\"n\": 4380, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3552.71, \"learn_time_ms\": 27959.175}", "{\"n\": 4381, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3542.95, \"learn_time_ms\": 27972.827}", "{\"n\": 4382, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3547.67, \"learn_time_ms\": 27948.916}", "{\"n\": 4383, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3547.67, \"learn_time_ms\": 27981.658}", "{\"n\": 4384, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.41, \"learn_time_ms\": 28020.749}", "{\"n\": 4385, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3574.96, \"learn_time_ms\": 28034.035}", "{\"n\": 4386, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3566.51, \"learn_time_ms\": 28037.722}", "{\"n\": 4387, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3566.51, \"learn_time_ms\": 28074.599}", "{\"n\": 4388, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3576.74, \"learn_time_ms\": 28048.915}", "{\"n\": 4389, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3571.1, \"learn_time_ms\": 28004.265}", "{\"n\": 4390, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3606.36, \"learn_time_ms\": 27989.706}", "{\"n\": 4391, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3606.36, \"learn_time_ms\": 27983.07}", "{\"n\": 4392, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3589.82, \"learn_time_ms\": 28008.928}", "{\"n\": 4393, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3589.82, \"learn_time_ms\": 27987.658}", "{\"n\": 4394, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3608.79, \"learn_time_ms\": 27912.602}", "{\"n\": 4395, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3612.03, \"learn_time_ms\": 27888.463}", "{\"n\": 4396, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3620.43, \"learn_time_ms\": 27897.458}", "{\"n\": 4397, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3620.43, \"learn_time_ms\": 27874.634}", "{\"n\": 4398, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3620.43, \"learn_time_ms\": 27922.724}", "{\"n\": 4399, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3621.71, \"learn_time_ms\": 27930.269}", "{\"n\": 4400, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3609.1, \"learn_time_ms\": 27977.017}", "{\"n\": 4401, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3611.31, \"learn_time_ms\": 27976.596}", "{\"n\": 4402, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3632.29, \"learn_time_ms\": 27957.006}", "{\"n\": 4403, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.14, \"learn_time_ms\": 27926.082}", "{\"n\": 4404, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3637.11, \"learn_time_ms\": 27959.172}", "{\"n\": 4405, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3644.48, \"learn_time_ms\": 27984.322}", "{\"n\": 4406, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3644.48, \"learn_time_ms\": 28013.414}", "{\"n\": 4407, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.74, \"learn_time_ms\": 28025.323}", "{\"n\": 4408, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.74, \"learn_time_ms\": 28022.811}", "{\"n\": 4409, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3636.23, \"learn_time_ms\": 28009.122}", "{\"n\": 4410, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3631.36, \"learn_time_ms\": 28036.79}", "{\"n\": 4411, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3627.89, \"learn_time_ms\": 28017.42}", "{\"n\": 4412, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3630.87, \"learn_time_ms\": 28026.13}", "{\"n\": 4413, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3629.71, \"learn_time_ms\": 28039.612}", "{\"n\": 4414, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3626.26, \"learn_time_ms\": 28091.67}", "{\"n\": 4415, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3645.64, \"learn_time_ms\": 28076.172}", "{\"n\": 4416, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3658.17, \"learn_time_ms\": 28056.918}", "{\"n\": 4417, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3649.84, \"learn_time_ms\": 28064.613}", "{\"n\": 4418, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3649.84, \"learn_time_ms\": 28059.829}", "{\"n\": 4419, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3649.84, \"learn_time_ms\": 28059.469}", "{\"n\": 4420, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3649.84, \"learn_time_ms\": 27981.428}", "{\"n\": 4421, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3668.84, \"learn_time_ms\": 28026.97}", "{\"n\": 4422, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3669.62, \"learn_time_ms\": 28011.302}", "{\"n\": 4423, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3673.0, \"learn_time_ms\": 28041.458}", "{\"n\": 4424, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3651.93, \"learn_time_ms\": 28012.829}", "{\"n\": 4425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3651.93, \"learn_time_ms\": 28013.828}", "{\"n\": 4426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.07, \"learn_time_ms\": 27984.582}", "{\"n\": 4427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3647.58, \"learn_time_ms\": 27944.485}", "{\"n\": 4428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.36, \"learn_time_ms\": 27961.332}", "{\"n\": 4429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.84, \"learn_time_ms\": 27970.689}", "{\"n\": 4430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3663.11, \"learn_time_ms\": 28013.63}", "{\"n\": 4431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3663.11, \"learn_time_ms\": 27962.431}", "{\"n\": 4432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3661.06, \"learn_time_ms\": 27968.789}", "{\"n\": 4433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3649.18, \"learn_time_ms\": 27921.287}", "{\"n\": 4434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3649.18, \"learn_time_ms\": 27856.657}", "{\"n\": 4435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.65, \"learn_time_ms\": 27836.852}", "{\"n\": 4436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3631.07, \"learn_time_ms\": 27862.179}", "{\"n\": 4437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3631.07, \"learn_time_ms\": 27874.801}", "{\"n\": 4438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3633.91, \"learn_time_ms\": 27841.458}", "{\"n\": 4439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3630.1, \"learn_time_ms\": 27879.613}", "{\"n\": 4440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3638.96, \"learn_time_ms\": 27850.779}", "{\"n\": 4441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3636.04, \"learn_time_ms\": 27868.899}", "{\"n\": 4442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3638.7, \"learn_time_ms\": 27872.058}", "{\"n\": 4443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3638.7, \"learn_time_ms\": 27915.666}", "{\"n\": 4444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3632.79, \"learn_time_ms\": 28001.352}", "{\"n\": 4445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3620.68, \"learn_time_ms\": 28006.406}", "{\"n\": 4446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.46, \"learn_time_ms\": 28022.696}", "{\"n\": 4447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3629.09, \"learn_time_ms\": 28022.215}", "{\"n\": 4448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3629.09, \"learn_time_ms\": 28056.066}", "{\"n\": 4449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3644.45, \"learn_time_ms\": 27933.235}", "{\"n\": 4450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3644.45, \"learn_time_ms\": 27922.215}", "{\"n\": 4451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3631.34, \"learn_time_ms\": 27949.192}", "{\"n\": 4452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3632.89, \"learn_time_ms\": 28028.62}", "{\"n\": 4453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3632.89, \"learn_time_ms\": 28046.288}", "{\"n\": 4454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3637.75, \"learn_time_ms\": 28015.049}", "{\"n\": 4455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3637.75, \"learn_time_ms\": 28024.914}", "{\"n\": 4456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.75, \"learn_time_ms\": 28081.61}", "{\"n\": 4457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.18, \"learn_time_ms\": 28066.513}", "{\"n\": 4458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.76, \"learn_time_ms\": 28066.968}", "{\"n\": 4459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3613.16, \"learn_time_ms\": 28165.324}", "{\"n\": 4460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3613.16, \"learn_time_ms\": 28176.365}", "{\"n\": 4461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3617.36, \"learn_time_ms\": 28175.401}", "{\"n\": 4462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3622.62, \"learn_time_ms\": 28129.11}", "{\"n\": 4463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.47, \"learn_time_ms\": 28094.721}", "{\"n\": 4464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3636.39, \"learn_time_ms\": 28058.332}", "{\"n\": 4465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3627.54, \"learn_time_ms\": 28094.1}", "{\"n\": 4466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3618.77, \"learn_time_ms\": 28025.205}", "{\"n\": 4467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3616.99, \"learn_time_ms\": 28050.597}", "{\"n\": 4468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3616.99, \"learn_time_ms\": 28052.612}", "{\"n\": 4469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3616.99, \"learn_time_ms\": 28015.87}", "{\"n\": 4470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.08, \"learn_time_ms\": 28011.315}", "{\"n\": 4471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.13, \"learn_time_ms\": 27968.208}", "{\"n\": 4472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.13, \"learn_time_ms\": 27966.193}", "{\"n\": 4473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3638.11, \"learn_time_ms\": 27969.883}", "{\"n\": 4474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3638.11, \"learn_time_ms\": 28016.239}", "{\"n\": 4475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3638.11, \"learn_time_ms\": 28032.067}", "{\"n\": 4476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3622.06, \"learn_time_ms\": 28026.95}", "{\"n\": 4477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3622.06, \"learn_time_ms\": 28014.031}", "{\"n\": 4478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3622.06, \"learn_time_ms\": 27967.873}", "{\"n\": 4479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3594.02, \"learn_time_ms\": 28001.371}", "{\"n\": 4480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3583.67, \"learn_time_ms\": 28006.05}", "{\"n\": 4481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3584.66, \"learn_time_ms\": 28050.472}", "{\"n\": 4482, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3579.26, \"learn_time_ms\": 28072.308}", "{\"n\": 4483, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3579.26, \"learn_time_ms\": 28065.878}", "{\"n\": 4484, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3568.4, \"learn_time_ms\": 28057.747}", "{\"n\": 4485, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3596.43, \"learn_time_ms\": 28041.449}", "{\"n\": 4486, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3596.43, \"learn_time_ms\": 28047.41}", "{\"n\": 4487, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3595.71, \"learn_time_ms\": 28031.96}", "{\"n\": 4488, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3585.38, \"learn_time_ms\": 28086.165}", "{\"n\": 4489, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3584.69, \"learn_time_ms\": 28104.006}", "{\"n\": 4490, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3584.69, \"learn_time_ms\": 28129.583}", "{\"n\": 4491, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3588.36, \"learn_time_ms\": 28118.045}", "{\"n\": 4492, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3585.31, \"learn_time_ms\": 28101.396}", "{\"n\": 4493, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3585.31, \"learn_time_ms\": 28132.816}", "{\"n\": 4494, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3575.29, \"learn_time_ms\": 28137.873}", "{\"n\": 4495, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3576.72, \"learn_time_ms\": 28092.881}", "{\"n\": 4496, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3580.26, \"learn_time_ms\": 28118.773}", "{\"n\": 4497, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3588.3, \"learn_time_ms\": 28144.948}", "{\"n\": 4498, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3604.56, \"learn_time_ms\": 28122.528}", "{\"n\": 4499, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3604.56, \"learn_time_ms\": 28060.176}", "{\"n\": 4500, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3606.14, \"learn_time_ms\": 28039.533}", "{\"n\": 4501, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3606.14, \"learn_time_ms\": 28035.876}", "{\"n\": 4502, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3615.25, \"learn_time_ms\": 27989.775}", "{\"n\": 4503, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3607.17, \"learn_time_ms\": 27969.701}", "{\"n\": 4504, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3592.59, \"learn_time_ms\": 27992.349}", "{\"n\": 4505, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3565.99, \"learn_time_ms\": 28068.455}", "{\"n\": 4506, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3572.78, \"learn_time_ms\": 28061.686}", "{\"n\": 4507, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3572.11, \"learn_time_ms\": 28072.906}", "{\"n\": 4508, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3586.8, \"learn_time_ms\": 28096.671}", "{\"n\": 4509, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3586.8, \"learn_time_ms\": 28133.101}", "{\"n\": 4510, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3590.61, \"learn_time_ms\": 28204.657}", "{\"n\": 4511, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3590.61, \"learn_time_ms\": 28220.946}", "{\"n\": 4512, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3591.02, \"learn_time_ms\": 28217.775}", "{\"n\": 4513, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3588.33, \"learn_time_ms\": 28192.713}", "{\"n\": 4514, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3599.74, \"learn_time_ms\": 28165.281}", "{\"n\": 4515, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.6, \"learn_time_ms\": 28118.653}", "{\"n\": 4516, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3591.08, \"learn_time_ms\": 28110.496}", "{\"n\": 4517, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3593.46, \"learn_time_ms\": 28079.362}", "{\"n\": 4518, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.46, \"learn_time_ms\": 28084.385}", "{\"n\": 4519, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3615.87, \"learn_time_ms\": 28095.752}", "{\"n\": 4520, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3615.87, \"learn_time_ms\": 28062.909}", "{\"n\": 4521, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3618.26, \"learn_time_ms\": 28046.553}", "{\"n\": 4522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3639.96, \"learn_time_ms\": 28061.092}", "{\"n\": 4523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3639.96, \"learn_time_ms\": 28105.433}", "{\"n\": 4524, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3618.35, \"learn_time_ms\": 28142.223}", "{\"n\": 4525, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3612.73, \"learn_time_ms\": 28142.999}", "{\"n\": 4526, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3612.73, \"learn_time_ms\": 28137.425}", "{\"n\": 4527, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3622.28, \"learn_time_ms\": 28143.775}", "{\"n\": 4528, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3625.66, \"learn_time_ms\": 28110.743}", "{\"n\": 4529, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3625.66, \"learn_time_ms\": 28117.9}", "{\"n\": 4530, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3626.82, \"learn_time_ms\": 28106.053}", "{\"n\": 4531, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3632.68, \"learn_time_ms\": 28080.63}", "{\"n\": 4532, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3638.0, \"learn_time_ms\": 28106.785}", "{\"n\": 4533, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3650.5, \"learn_time_ms\": 28079.684}", "{\"n\": 4534, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3650.5, \"learn_time_ms\": 28089.02}", "{\"n\": 4535, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3653.89, \"learn_time_ms\": 28085.129}", "{\"n\": 4536, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3647.88, \"learn_time_ms\": 28064.22}", "{\"n\": 4537, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3639.81, \"learn_time_ms\": 28094.321}", "{\"n\": 4538, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3630.96, \"learn_time_ms\": 28107.57}", "{\"n\": 4539, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3606.26, \"learn_time_ms\": 28121.483}", "{\"n\": 4540, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3606.26, \"learn_time_ms\": 28137.832}", "{\"n\": 4541, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3575.41, \"learn_time_ms\": 28172.288}", "{\"n\": 4542, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3575.41, \"learn_time_ms\": 28189.833}", "{\"n\": 4543, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3571.85, \"learn_time_ms\": 28212.937}", "{\"n\": 4544, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3565.08, \"learn_time_ms\": 28202.82}", "{\"n\": 4545, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3565.08, \"learn_time_ms\": 28208.984}", "{\"n\": 4546, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3569.87, \"learn_time_ms\": 28240.195}", "{\"n\": 4547, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3569.87, \"learn_time_ms\": 28220.067}", "{\"n\": 4548, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3556.95, \"learn_time_ms\": 28238.421}", "{\"n\": 4549, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3553.29, \"learn_time_ms\": 28211.866}", "{\"n\": 4550, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3566.48, \"learn_time_ms\": 28179.01}", "{\"n\": 4551, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3549.8, \"learn_time_ms\": 28171.5}", "{\"n\": 4552, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3567.72, \"learn_time_ms\": 28158.463}", "{\"n\": 4553, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3572.42, \"learn_time_ms\": 28176.775}", "{\"n\": 4554, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3564.26, \"learn_time_ms\": 28163.123}", "{\"n\": 4555, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3564.26, \"learn_time_ms\": 28161.089}", "{\"n\": 4556, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3548.73, \"learn_time_ms\": 28124.273}", "{\"n\": 4557, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3551.82, \"learn_time_ms\": 28111.03}", "{\"n\": 4558, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3551.82, \"learn_time_ms\": 28113.537}", "{\"n\": 4559, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3544.24, \"learn_time_ms\": 28070.073}", "{\"n\": 4560, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3544.79, \"learn_time_ms\": 28098.173}", "{\"n\": 4561, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3555.63, \"learn_time_ms\": 28127.685}", "{\"n\": 4562, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3555.63, \"learn_time_ms\": 28133.682}", "{\"n\": 4563, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3545.87, \"learn_time_ms\": 28125.668}", "{\"n\": 4564, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3564.33, \"learn_time_ms\": 28153.348}", "{\"n\": 4565, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.39, \"learn_time_ms\": 28188.289}", "{\"n\": 4566, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.59, \"learn_time_ms\": 28162.127}", "{\"n\": 4567, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.59, \"learn_time_ms\": 28165.936}", "{\"n\": 4568, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3568.49, \"learn_time_ms\": 28177.52}", "{\"n\": 4569, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3566.15, \"learn_time_ms\": 28270.235}", "{\"n\": 4570, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3564.45, \"learn_time_ms\": 28273.154}", "{\"n\": 4571, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.14, \"learn_time_ms\": 28271.853}", "{\"n\": 4572, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.14, \"learn_time_ms\": 28265.312}", "{\"n\": 4573, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3557.48, \"learn_time_ms\": 28259.833}", "{\"n\": 4574, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3557.48, \"learn_time_ms\": 28234.005}", "{\"n\": 4575, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3558.95, \"learn_time_ms\": 28225.779}", "{\"n\": 4576, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.1, \"learn_time_ms\": 28304.257}", "{\"n\": 4577, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.33, \"learn_time_ms\": 28301.714}", "{\"n\": 4578, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3564.13, \"learn_time_ms\": 28276.219}", "{\"n\": 4579, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3568.91, \"learn_time_ms\": 28240.068}", "{\"n\": 4580, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3568.91, \"learn_time_ms\": 28243.803}", "{\"n\": 4581, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3571.46, \"learn_time_ms\": 28240.169}", "{\"n\": 4582, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3567.36, \"learn_time_ms\": 28236.967}", "{\"n\": 4583, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3548.86, \"learn_time_ms\": 28172.801}", "{\"n\": 4584, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3548.86, \"learn_time_ms\": 28131.613}", "{\"n\": 4585, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3548.86, \"learn_time_ms\": 28114.752}", "{\"n\": 4586, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3549.9, \"learn_time_ms\": 28069.129}", "{\"n\": 4587, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3564.2, \"learn_time_ms\": 28094.736}", "{\"n\": 4588, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3567.5, \"learn_time_ms\": 28085.535}", "{\"n\": 4589, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3569.43, \"learn_time_ms\": 28109.695}", "{\"n\": 4590, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3577.51, \"learn_time_ms\": 28117.671}", "{\"n\": 4591, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3577.51, \"learn_time_ms\": 28097.319}", "{\"n\": 4592, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3581.62, \"learn_time_ms\": 28090.634}", "{\"n\": 4593, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3577.66, \"learn_time_ms\": 28148.042}", "{\"n\": 4594, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3567.91, \"learn_time_ms\": 28150.987}", "{\"n\": 4595, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3556.02, \"learn_time_ms\": 28144.256}", "{\"n\": 4596, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3566.87, \"learn_time_ms\": 28159.179}", "{\"n\": 4597, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3545.31, \"learn_time_ms\": 28153.015}", "{\"n\": 4598, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3547.43, \"learn_time_ms\": 28132.825}", "{\"n\": 4599, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.73, \"learn_time_ms\": 28079.783}", "{\"n\": 4600, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3566.49, \"learn_time_ms\": 28057.966}", "{\"n\": 4601, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.77, \"learn_time_ms\": 28054.226}", "{\"n\": 4602, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.77, \"learn_time_ms\": 28048.017}", "{\"n\": 4603, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3551.26, \"learn_time_ms\": 28054.163}", "{\"n\": 4604, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.61, \"learn_time_ms\": 28085.136}", "{\"n\": 4605, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.61, \"learn_time_ms\": 28083.882}", "{\"n\": 4606, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3524.91, \"learn_time_ms\": 28124.58}", "{\"n\": 4607, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3505.95, \"learn_time_ms\": 28114.038}", "{\"n\": 4608, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3505.95, \"learn_time_ms\": 28165.96}", "{\"n\": 4609, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3512.59, \"learn_time_ms\": 28140.642}", "{\"n\": 4610, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3512.59, \"learn_time_ms\": 28153.614}", "{\"n\": 4611, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3512.59, \"learn_time_ms\": 28141.242}", "{\"n\": 4612, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.73, \"learn_time_ms\": 28171.627}", "{\"n\": 4613, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3538.0, \"learn_time_ms\": 28153.388}", "{\"n\": 4614, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3548.74, \"learn_time_ms\": 28131.393}", "{\"n\": 4615, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3548.74, \"learn_time_ms\": 28126.388}", "{\"n\": 4616, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3557.88, \"learn_time_ms\": 28124.676}", "{\"n\": 4617, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3583.9, \"learn_time_ms\": 28153.874}", "{\"n\": 4618, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.44, \"learn_time_ms\": 28142.141}", "{\"n\": 4619, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3578.46, \"learn_time_ms\": 28164.385}", "{\"n\": 4620, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3560.05, \"learn_time_ms\": 28121.595}", "{\"n\": 4621, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3560.05, \"learn_time_ms\": 28183.382}", "{\"n\": 4622, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3566.76, \"learn_time_ms\": 28137.421}", "{\"n\": 4623, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.81, \"learn_time_ms\": 28157.707}", "{\"n\": 4624, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3557.51, \"learn_time_ms\": 28166.736}", "{\"n\": 4625, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.15, \"learn_time_ms\": 28166.577}", "{\"n\": 4626, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3565.64, \"learn_time_ms\": 28177.076}", "{\"n\": 4627, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3582.53, \"learn_time_ms\": 28144.135}", "{\"n\": 4628, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3582.53, \"learn_time_ms\": 28120.307}", "{\"n\": 4629, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3596.33, \"learn_time_ms\": 28152.476}", "{\"n\": 4630, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.42, \"learn_time_ms\": 28221.242}", "{\"n\": 4631, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.42, \"learn_time_ms\": 28181.309}", "{\"n\": 4632, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3604.87, \"learn_time_ms\": 28150.194}", "{\"n\": 4633, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.02, \"learn_time_ms\": 28131.387}", "{\"n\": 4634, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.91, \"learn_time_ms\": 28157.408}", "{\"n\": 4635, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3603.44, \"learn_time_ms\": 28139.636}", "{\"n\": 4636, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3589.11, \"learn_time_ms\": 28113.07}", "{\"n\": 4637, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.48, \"learn_time_ms\": 28108.808}", "{\"n\": 4638, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.82, \"learn_time_ms\": 28099.94}", "{\"n\": 4639, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.82, \"learn_time_ms\": 28069.689}", "{\"n\": 4640, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.27, \"learn_time_ms\": 28055.109}", "{\"n\": 4641, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3571.88, \"learn_time_ms\": 28072.049}", "{\"n\": 4642, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3575.04, \"learn_time_ms\": 28128.566}", "{\"n\": 4643, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3560.07, \"learn_time_ms\": 28160.656}", "{\"n\": 4644, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3560.07, \"learn_time_ms\": 28145.842}", "{\"n\": 4645, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3554.28, \"learn_time_ms\": 28197.463}", "{\"n\": 4646, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3554.28, \"learn_time_ms\": 28181.26}", "{\"n\": 4647, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.84, \"learn_time_ms\": 28191.887}", "{\"n\": 4648, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.97, \"learn_time_ms\": 28245.241}", "{\"n\": 4649, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3572.71, \"learn_time_ms\": 28241.463}", "{\"n\": 4650, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3572.71, \"learn_time_ms\": 28209.354}", "{\"n\": 4651, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.04, \"learn_time_ms\": 28168.552}", "{\"n\": 4652, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3589.84, \"learn_time_ms\": 28194.821}", "{\"n\": 4653, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3589.84, \"learn_time_ms\": 28151.058}", "{\"n\": 4654, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3595.08, \"learn_time_ms\": 28183.073}", "{\"n\": 4655, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3599.4, \"learn_time_ms\": 28179.393}", "{\"n\": 4656, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3599.4, \"learn_time_ms\": 28186.261}", "{\"n\": 4657, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3595.96, \"learn_time_ms\": 28182.013}", "{\"n\": 4658, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3598.55, \"learn_time_ms\": 28175.242}", "{\"n\": 4659, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3598.55, \"learn_time_ms\": 28223.694}", "{\"n\": 4660, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3594.89, \"learn_time_ms\": 28217.692}", "{\"n\": 4661, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3576.44, \"learn_time_ms\": 28239.289}", "{\"n\": 4662, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3593.33, \"learn_time_ms\": 28134.031}", "{\"n\": 4663, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3593.33, \"learn_time_ms\": 28132.085}", "{\"n\": 4664, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3587.14, \"learn_time_ms\": 28105.859}", "{\"n\": 4665, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.72, \"learn_time_ms\": 28092.776}", "{\"n\": 4666, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.82, \"learn_time_ms\": 28115.767}", "{\"n\": 4667, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.82, \"learn_time_ms\": 28145.293}", "{\"n\": 4668, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3562.59, \"learn_time_ms\": 28110.312}", "{\"n\": 4669, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3548.65, \"learn_time_ms\": 28050.811}", "{\"n\": 4670, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3548.65, \"learn_time_ms\": 28082.046}", "{\"n\": 4671, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3550.21, \"learn_time_ms\": 28094.75}", "{\"n\": 4672, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3532.02, \"learn_time_ms\": 28180.8}", "{\"n\": 4673, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3532.02, \"learn_time_ms\": 28207.711}", "{\"n\": 4674, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3540.85, \"learn_time_ms\": 28219.684}", "{\"n\": 4675, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3541.14, \"learn_time_ms\": 28210.807}", "{\"n\": 4676, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3560.9, \"learn_time_ms\": 28210.683}", "{\"n\": 4677, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.42, \"learn_time_ms\": 28176.491}", "{\"n\": 4678, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3575.16, \"learn_time_ms\": 28196.678}", "{\"n\": 4679, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3571.46, \"learn_time_ms\": 28261.495}", "{\"n\": 4680, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3574.91, \"learn_time_ms\": 28258.319}", "{\"n\": 4681, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.42, \"learn_time_ms\": 28226.406}", "{\"n\": 4682, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3573.32, \"learn_time_ms\": 28207.496}", "{\"n\": 4683, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.65, \"learn_time_ms\": 28220.655}", "{\"n\": 4684, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.65, \"learn_time_ms\": 28222.659}", "{\"n\": 4685, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3554.13, \"learn_time_ms\": 28197.064}", "{\"n\": 4686, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.08, \"learn_time_ms\": 28162.851}", "{\"n\": 4687, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.08, \"learn_time_ms\": 28168.162}", "{\"n\": 4688, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3571.82, \"learn_time_ms\": 28162.766}", "{\"n\": 4689, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3571.82, \"learn_time_ms\": 28089.293}", "{\"n\": 4690, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.87, \"learn_time_ms\": 28054.416}", "{\"n\": 4691, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.87, \"learn_time_ms\": 28036.27}", "{\"n\": 4692, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3541.62, \"learn_time_ms\": 28017.403}", "{\"n\": 4693, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3537.71, \"learn_time_ms\": 28003.955}", "{\"n\": 4694, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3529.67, \"learn_time_ms\": 28004.589}", "{\"n\": 4695, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3529.67, \"learn_time_ms\": 28033.585}", "{\"n\": 4696, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3538.85, \"learn_time_ms\": 28008.921}", "{\"n\": 4697, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3535.06, \"learn_time_ms\": 27979.777}", "{\"n\": 4698, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3535.06, \"learn_time_ms\": 27942.718}", "{\"n\": 4699, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3541.62, \"learn_time_ms\": 27960.926}", "{\"n\": 4700, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3512.92, \"learn_time_ms\": 27967.748}", "{\"n\": 4701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3500.33, \"learn_time_ms\": 27999.233}", "{\"n\": 4702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3500.33, \"learn_time_ms\": 28027.622}", "{\"n\": 4703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3497.7, \"learn_time_ms\": 28009.426}", "{\"n\": 4704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3496.8, \"learn_time_ms\": 28038.695}", "{\"n\": 4705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3496.8, \"learn_time_ms\": 28035.595}", "{\"n\": 4706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3502.01, \"learn_time_ms\": 28060.849}", "{\"n\": 4707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3504.0, \"learn_time_ms\": 28071.76}", "{\"n\": 4708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3513.06, \"learn_time_ms\": 28120.061}", "{\"n\": 4709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3516.31, \"learn_time_ms\": 28189.99}", "{\"n\": 4710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3538.9, \"learn_time_ms\": 28222.632}", "{\"n\": 4711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3534.87, \"learn_time_ms\": 28245.741}", "{\"n\": 4712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3542.61, \"learn_time_ms\": 28268.238}", "{\"n\": 4713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3542.61, \"learn_time_ms\": 28245.735}", "{\"n\": 4714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3538.79, \"learn_time_ms\": 28213.233}", "{\"n\": 4715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3560.94, \"learn_time_ms\": 28222.373}", "{\"n\": 4716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3560.94, \"learn_time_ms\": 28210.568}", "{\"n\": 4717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.94, \"learn_time_ms\": 28246.126}", "{\"n\": 4718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3581.31, \"learn_time_ms\": 28238.711}", "{\"n\": 4719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3581.31, \"learn_time_ms\": 28202.377}", "{\"n\": 4720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3570.07, \"learn_time_ms\": 28186.107}", "{\"n\": 4721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3578.55, \"learn_time_ms\": 28145.466}", "{\"n\": 4722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3581.59, \"learn_time_ms\": 28141.57}", "{\"n\": 4723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3578.41, \"learn_time_ms\": 28204.111}", "{\"n\": 4724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3565.02, \"learn_time_ms\": 28175.086}", "{\"n\": 4725, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3565.02, \"learn_time_ms\": 28161.138}", "{\"n\": 4726, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3565.02, \"learn_time_ms\": 28153.218}", "{\"n\": 4727, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3566.37, \"learn_time_ms\": 28122.439}", "{\"n\": 4728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3554.31, \"learn_time_ms\": 28128.072}", "{\"n\": 4729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3548.05, \"learn_time_ms\": 28149.878}", "{\"n\": 4730, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3550.27, \"learn_time_ms\": 28147.855}", "{\"n\": 4731, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3550.27, \"learn_time_ms\": 28186.747}", "{\"n\": 4732, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3565.51, \"learn_time_ms\": 28167.37}", "{\"n\": 4733, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3549.53, \"learn_time_ms\": 28158.529}", "{\"n\": 4734, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3552.11, \"learn_time_ms\": 28153.556}", "{\"n\": 4735, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3533.94, \"learn_time_ms\": 28128.493}", "{\"n\": 4736, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3533.94, \"learn_time_ms\": 28166.016}", "{\"n\": 4737, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3530.45, \"learn_time_ms\": 28206.406}", "{\"n\": 4738, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3530.45, \"learn_time_ms\": 28210.517}", "{\"n\": 4739, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3551.14, \"learn_time_ms\": 28211.659}", "{\"n\": 4740, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3547.23, \"learn_time_ms\": 28236.196}", "{\"n\": 4741, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3547.23, \"learn_time_ms\": 28248.962}", "{\"n\": 4742, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3561.09, \"learn_time_ms\": 28223.823}", "{\"n\": 4743, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3561.09, \"learn_time_ms\": 28196.232}", "{\"n\": 4744, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3566.64, \"learn_time_ms\": 28228.863}", "{\"n\": 4745, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3571.05, \"learn_time_ms\": 28255.369}", "{\"n\": 4746, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3605.86, \"learn_time_ms\": 28260.974}", "{\"n\": 4747, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3597.69, \"learn_time_ms\": 28253.174}", "{\"n\": 4748, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3597.69, \"learn_time_ms\": 28239.136}", "{\"n\": 4749, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3598.2, \"learn_time_ms\": 28199.199}", "{\"n\": 4750, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3598.36, \"learn_time_ms\": 28151.04}", "{\"n\": 4751, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3591.17, \"learn_time_ms\": 28101.588}", "{\"n\": 4752, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3582.11, \"learn_time_ms\": 28137.295}", "{\"n\": 4753, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3585.98, \"learn_time_ms\": 28151.664}", "{\"n\": 4754, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3582.86, \"learn_time_ms\": 28135.893}", "{\"n\": 4755, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3582.86, \"learn_time_ms\": 28136.09}", "{\"n\": 4756, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3582.86, \"learn_time_ms\": 28110.919}", "{\"n\": 4757, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3605.49, \"learn_time_ms\": 28105.107}", "{\"n\": 4758, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3609.74, \"learn_time_ms\": 28067.696}", "{\"n\": 4759, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3628.21, \"learn_time_ms\": 28090.084}", "{\"n\": 4760, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3645.59, \"learn_time_ms\": 28109.752}", "{\"n\": 4761, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3644.03, \"learn_time_ms\": 28137.592}", "{\"n\": 4762, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3644.03, \"learn_time_ms\": 28174.493}", "{\"n\": 4763, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3650.98, \"learn_time_ms\": 28159.235}", "{\"n\": 4764, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3662.55, \"learn_time_ms\": 28142.091}", "{\"n\": 4765, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3662.2, \"learn_time_ms\": 28126.627}", "{\"n\": 4766, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3663.63, \"learn_time_ms\": 28171.644}", "{\"n\": 4767, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3663.63, \"learn_time_ms\": 28205.802}", "{\"n\": 4768, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3672.81, \"learn_time_ms\": 28256.345}", "{\"n\": 4769, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3672.81, \"learn_time_ms\": 28228.542}", "{\"n\": 4770, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3672.81, \"learn_time_ms\": 28247.89}", "{\"n\": 4771, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3672.81, \"learn_time_ms\": 28255.792}", "{\"n\": 4772, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3694.43, \"learn_time_ms\": 28186.045}", "{\"n\": 4773, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3707.96, \"learn_time_ms\": 28193.59}", "{\"n\": 4774, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3707.96, \"learn_time_ms\": 28222.046}", "{\"n\": 4775, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3706.01, \"learn_time_ms\": 28256.32}", "{\"n\": 4776, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3706.01, \"learn_time_ms\": 28237.354}", "{\"n\": 4777, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3702.54, \"learn_time_ms\": 28217.032}", "{\"n\": 4778, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3721.19, \"learn_time_ms\": 28192.984}", "{\"n\": 4779, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3768.03, \"learn_time_ms\": 28220.329}", "{\"n\": 4780, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3768.03, \"learn_time_ms\": 28194.887}", "{\"n\": 4781, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3768.03, \"learn_time_ms\": 28212.116}", "{\"n\": 4782, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3768.03, \"learn_time_ms\": 28251.753}", "{\"n\": 4783, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3775.93, \"learn_time_ms\": 28217.481}", "{\"n\": 4784, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3776.99, \"learn_time_ms\": 28224.431}", "{\"n\": 4785, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3794.34, \"learn_time_ms\": 28218.687}", "{\"n\": 4786, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3788.06, \"learn_time_ms\": 28215.205}", "{\"n\": 4787, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3780.73, \"learn_time_ms\": 28250.192}", "{\"n\": 4788, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3780.73, \"learn_time_ms\": 28241.493}", "{\"n\": 4789, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3780.73, \"learn_time_ms\": 28241.874}", "{\"n\": 4790, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3780.73, \"learn_time_ms\": 28282.307}", "{\"n\": 4791, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3788.91, \"learn_time_ms\": 28249.541}", "{\"n\": 4792, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3809.05, \"learn_time_ms\": 28230.949}", "{\"n\": 4793, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3822.26, \"learn_time_ms\": 28249.588}", "{\"n\": 4794, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3825.59, \"learn_time_ms\": 28222.106}", "{\"n\": 4795, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3825.59, \"learn_time_ms\": 28219.77}", "{\"n\": 4796, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3825.59, \"learn_time_ms\": 28233.401}", "{\"n\": 4797, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3825.58, \"learn_time_ms\": 28179.512}", "{\"n\": 4798, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3850.28, \"learn_time_ms\": 28212.682}", "{\"n\": 4799, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3861.06, \"learn_time_ms\": 28186.504}", "{\"n\": 4800, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3861.06, \"learn_time_ms\": 28181.792}", "{\"n\": 4801, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3865.35, \"learn_time_ms\": 28188.079}", "{\"n\": 4802, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3865.35, \"learn_time_ms\": 28209.003}", "{\"n\": 4803, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3865.35, \"learn_time_ms\": 28254.498}", "{\"n\": 4804, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3869.52, \"learn_time_ms\": 28277.556}", "{\"n\": 4805, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3861.57, \"learn_time_ms\": 28315.497}", "{\"n\": 4806, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3878.04, \"learn_time_ms\": 28247.894}", "{\"n\": 4807, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3887.02, \"learn_time_ms\": 28238.796}", "{\"n\": 4808, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3887.02, \"learn_time_ms\": 28195.55}", "{\"n\": 4809, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3887.02, \"learn_time_ms\": 28211.741}", "{\"n\": 4810, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3885.83, \"learn_time_ms\": 28141.327}", "{\"n\": 4811, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3900.34, \"learn_time_ms\": 28175.719}", "{\"n\": 4812, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3917.46, \"learn_time_ms\": 28161.325}", "{\"n\": 4813, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3930.9, \"learn_time_ms\": 28123.92}", "{\"n\": 4814, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3930.9, \"learn_time_ms\": 28091.292}", "{\"n\": 4815, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3930.9, \"learn_time_ms\": 28032.019}", "{\"n\": 4816, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3935.93, \"learn_time_ms\": 28087.385}", "{\"n\": 4817, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3929.03, \"learn_time_ms\": 28118.877}", "{\"n\": 4818, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3952.96, \"learn_time_ms\": 28163.2}", "{\"n\": 4819, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3952.96, \"learn_time_ms\": 28150.617}", "{\"n\": 4820, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3957.71, \"learn_time_ms\": 28189.927}", "{\"n\": 4821, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3957.71, \"learn_time_ms\": 28121.412}", "{\"n\": 4822, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3957.71, \"learn_time_ms\": 28142.657}", "{\"n\": 4823, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3958.1, \"learn_time_ms\": 28153.908}", "{\"n\": 4824, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3949.43, \"learn_time_ms\": 28169.509}", "{\"n\": 4825, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3957.62, \"learn_time_ms\": 28210.875}", "{\"n\": 4826, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3957.62, \"learn_time_ms\": 28152.982}", "{\"n\": 4827, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3962.21, \"learn_time_ms\": 28120.433}", "{\"n\": 4828, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3977.61, \"learn_time_ms\": 28080.332}", "{\"n\": 4829, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3977.61, \"learn_time_ms\": 28116.883}", "{\"n\": 4830, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3983.28, \"learn_time_ms\": 28150.424}", "{\"n\": 4831, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3987.28, \"learn_time_ms\": 28187.51}", "{\"n\": 4832, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4010.26, \"learn_time_ms\": 28168.475}", "{\"n\": 4833, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4016.76, \"learn_time_ms\": 28169.925}", "{\"n\": 4834, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4016.76, \"learn_time_ms\": 28178.305}", "{\"n\": 4835, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4022.69, \"learn_time_ms\": 28159.372}", "{\"n\": 4836, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4016.3, \"learn_time_ms\": 28193.247}", "{\"n\": 4837, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4038.3, \"learn_time_ms\": 28196.549}", "{\"n\": 4838, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4038.3, \"learn_time_ms\": 28234.263}", "{\"n\": 4839, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4046.31, \"learn_time_ms\": 28177.799}", "{\"n\": 4840, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4047.67, \"learn_time_ms\": 28136.085}", "{\"n\": 4841, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4047.67, \"learn_time_ms\": 28118.008}", "{\"n\": 4842, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4049.14, \"learn_time_ms\": 28056.787}", "{\"n\": 4843, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4049.14, \"learn_time_ms\": 28046.965}", "{\"n\": 4844, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4033.11, \"learn_time_ms\": 28014.699}", "{\"n\": 4845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4029.75, \"learn_time_ms\": 27976.108}", "{\"n\": 4846, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4016.92, \"learn_time_ms\": 27968.893}", "{\"n\": 4847, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4016.92, \"learn_time_ms\": 27981.504}", "{\"n\": 4848, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4024.06, \"learn_time_ms\": 27957.939}", "{\"n\": 4849, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4024.06, \"learn_time_ms\": 28004.563}", "{\"n\": 4850, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4036.75, \"learn_time_ms\": 28017.155}", "{\"n\": 4851, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4036.75, \"learn_time_ms\": 28036.803}", "{\"n\": 4852, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4058.03, \"learn_time_ms\": 28074.158}", "{\"n\": 4853, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4046.21, \"learn_time_ms\": 28104.539}", "{\"n\": 4854, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4043.97, \"learn_time_ms\": 28134.603}", "{\"n\": 4855, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4037.74, \"learn_time_ms\": 28138.178}", "{\"n\": 4856, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4045.06, \"learn_time_ms\": 28167.373}", "{\"n\": 4857, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4020.07, \"learn_time_ms\": 28163.931}", "{\"n\": 4858, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4020.07, \"learn_time_ms\": 28207.494}", "{\"n\": 4859, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4054.05, \"learn_time_ms\": 28186.274}", "{\"n\": 4860, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4031.99, \"learn_time_ms\": 28169.86}", "{\"n\": 4861, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4027.13, \"learn_time_ms\": 28168.486}", "{\"n\": 4862, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4011.44, \"learn_time_ms\": 28214.961}", "{\"n\": 4863, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4012.61, \"learn_time_ms\": 28201.49}", "{\"n\": 4864, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4012.61, \"learn_time_ms\": 28158.95}", "{\"n\": 4865, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4006.67, \"learn_time_ms\": 28189.482}", "{\"n\": 4866, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4006.67, \"learn_time_ms\": 28193.449}", "{\"n\": 4867, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4006.67, \"learn_time_ms\": 28150.321}", "{\"n\": 4868, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4004.78, \"learn_time_ms\": 28127.006}", "{\"n\": 4869, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4003.99, \"learn_time_ms\": 28146.904}", "{\"n\": 4870, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4003.05, \"learn_time_ms\": 28152.219}", "{\"n\": 4871, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3990.67, \"learn_time_ms\": 28155.7}", "{\"n\": 4872, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3990.67, \"learn_time_ms\": 28092.499}", "{\"n\": 4873, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3992.73, \"learn_time_ms\": 28105.379}", "{\"n\": 4874, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3984.88, \"learn_time_ms\": 28127.403}", "{\"n\": 4875, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3983.41, \"learn_time_ms\": 28143.348}", "{\"n\": 4876, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3984.75, \"learn_time_ms\": 28109.331}", "{\"n\": 4877, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3969.91, \"learn_time_ms\": 28146.211}", "{\"n\": 4878, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3977.54, \"learn_time_ms\": 28135.97}", "{\"n\": 4879, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3977.54, \"learn_time_ms\": 28106.161}", "{\"n\": 4880, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3983.6, \"learn_time_ms\": 28113.614}", "{\"n\": 4881, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 4000.64, \"learn_time_ms\": 28059.377}", "{\"n\": 4882, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3990.47, \"learn_time_ms\": 28110.298}", "{\"n\": 4883, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3990.47, \"learn_time_ms\": 28076.52}", "{\"n\": 4884, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3998.49, \"learn_time_ms\": 28145.642}", "{\"n\": 4885, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3990.74, \"learn_time_ms\": 28123.117}", "{\"n\": 4886, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3997.99, \"learn_time_ms\": 28170.416}", "{\"n\": 4887, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3997.99, \"learn_time_ms\": 28178.769}", "{\"n\": 4888, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3981.58, \"learn_time_ms\": 28202.697}", "{\"n\": 4889, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3973.87, \"learn_time_ms\": 28243.118}", "{\"n\": 4890, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3961.81, \"learn_time_ms\": 28247.065}", "{\"n\": 4891, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3970.18, \"learn_time_ms\": 28313.651}", "{\"n\": 4892, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3951.96, \"learn_time_ms\": 28339.898}", "{\"n\": 4893, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3952.33, \"learn_time_ms\": 28330.504}", "{\"n\": 4894, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3943.44, \"learn_time_ms\": 28292.552}", "{\"n\": 4895, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3943.44, \"learn_time_ms\": 28285.329}", "{\"n\": 4896, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3941.29, \"learn_time_ms\": 28261.113}", "{\"n\": 4897, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3904.49, \"learn_time_ms\": 28263.63}", "{\"n\": 4898, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3904.49, \"learn_time_ms\": 28247.742}", "{\"n\": 4899, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3904.49, \"learn_time_ms\": 28217.44}", "{\"n\": 4900, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3882.88, \"learn_time_ms\": 28253.484}", "{\"n\": 4901, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3855.21, \"learn_time_ms\": 28221.084}", "{\"n\": 4902, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3848.44, \"learn_time_ms\": 28154.619}", "{\"n\": 4903, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3824.07, \"learn_time_ms\": 28193.63}", "{\"n\": 4904, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3822.47, \"learn_time_ms\": 28178.297}", "{\"n\": 4905, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3819.2, \"learn_time_ms\": 28208.109}", "{\"n\": 4906, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3800.22, \"learn_time_ms\": 28185.712}", "{\"n\": 4907, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3810.85, \"learn_time_ms\": 28177.515}", "{\"n\": 4908, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3810.85, \"learn_time_ms\": 28130.45}", "{\"n\": 4909, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3806.03, \"learn_time_ms\": 28129.311}", "{\"n\": 4910, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3796.07, \"learn_time_ms\": 28123.713}", "{\"n\": 4911, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3766.45, \"learn_time_ms\": 28125.884}", "{\"n\": 4912, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3754.02, \"learn_time_ms\": 28162.329}", "{\"n\": 4913, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3762.65, \"learn_time_ms\": 28135.839}", "{\"n\": 4914, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3748.62, \"learn_time_ms\": 28127.423}", "{\"n\": 4915, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3748.62, \"learn_time_ms\": 28075.796}", "{\"n\": 4916, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3748.62, \"learn_time_ms\": 28127.635}", "{\"n\": 4917, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3758.29, \"learn_time_ms\": 28142.986}", "{\"n\": 4918, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3755.75, \"learn_time_ms\": 28187.223}", "{\"n\": 4919, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3746.46, \"learn_time_ms\": 28208.265}", "{\"n\": 4920, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3746.46, \"learn_time_ms\": 28182.28}", "{\"n\": 4921, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3753.05, \"learn_time_ms\": 28124.69}", "{\"n\": 4922, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3753.05, \"learn_time_ms\": 28110.526}", "{\"n\": 4923, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.85, \"learn_time_ms\": 28131.75}", "{\"n\": 4924, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.07, \"learn_time_ms\": 28146.342}", "{\"n\": 4925, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.47, \"learn_time_ms\": 28205.954}", "{\"n\": 4926, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3765.54, \"learn_time_ms\": 28136.79}", "{\"n\": 4927, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.81, \"learn_time_ms\": 28082.126}", "{\"n\": 4928, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.78, \"learn_time_ms\": 28085.928}", "{\"n\": 4929, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3739.66, \"learn_time_ms\": 28105.048}", "{\"n\": 4930, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3740.88, \"learn_time_ms\": 28128.968}", "{\"n\": 4931, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3740.88, \"learn_time_ms\": 28220.558}", "{\"n\": 4932, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3739.09, \"learn_time_ms\": 28225.673}", "{\"n\": 4933, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3738.57, \"learn_time_ms\": 28212.348}", "{\"n\": 4934, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3738.57, \"learn_time_ms\": 28228.655}", "{\"n\": 4935, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3738.3, \"learn_time_ms\": 28208.664}", "{\"n\": 4936, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3738.3, \"learn_time_ms\": 28256.722}", "{\"n\": 4937, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3738.3, \"learn_time_ms\": 28289.761}", "{\"n\": 4938, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3740.96, \"learn_time_ms\": 28259.723}", "{\"n\": 4939, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3742.43, \"learn_time_ms\": 28233.649}", "{\"n\": 4940, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3724.94, \"learn_time_ms\": 28187.779}", "{\"n\": 4941, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3724.94, \"learn_time_ms\": 28188.747}", "{\"n\": 4942, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3710.19, \"learn_time_ms\": 28192.435}", "{\"n\": 4943, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3710.19, \"learn_time_ms\": 28228.623}", "{\"n\": 4944, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3710.19, \"learn_time_ms\": 28182.275}", "{\"n\": 4945, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3692.63, \"learn_time_ms\": 28158.11}", "{\"n\": 4946, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3687.97, \"learn_time_ms\": 28129.81}", "{\"n\": 4947, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3679.3, \"learn_time_ms\": 28155.775}", "{\"n\": 4948, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3680.25, \"learn_time_ms\": 28200.414}", "{\"n\": 4949, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3680.53, \"learn_time_ms\": 28163.719}", "{\"n\": 4950, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3692.64, \"learn_time_ms\": 28185.756}", "{\"n\": 4951, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3706.21, \"learn_time_ms\": 28169.106}", "{\"n\": 4952, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3706.21, \"learn_time_ms\": 28187.717}", "{\"n\": 4953, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3706.21, \"learn_time_ms\": 28141.216}", "{\"n\": 4954, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3710.93, \"learn_time_ms\": 28132.021}", "{\"n\": 4955, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3698.16, \"learn_time_ms\": 28187.237}", "{\"n\": 4956, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3668.99, \"learn_time_ms\": 28227.833}", "{\"n\": 4957, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3664.52, \"learn_time_ms\": 28206.448}", "{\"n\": 4958, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3664.52, \"learn_time_ms\": 28185.648}", "{\"n\": 4959, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3629.68, \"learn_time_ms\": 28176.481}", "{\"n\": 4960, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3646.56, \"learn_time_ms\": 28173.744}", "{\"n\": 4961, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3634.33, \"learn_time_ms\": 28152.618}", "{\"n\": 4962, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3629.0, \"learn_time_ms\": 28167.004}", "{\"n\": 4963, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3633.18, \"learn_time_ms\": 28172.689}", "{\"n\": 4964, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3630.18, \"learn_time_ms\": 28212.97}", "{\"n\": 4965, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3626.37, \"learn_time_ms\": 28162.99}", "{\"n\": 4966, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3626.37, \"learn_time_ms\": 28155.619}", "{\"n\": 4967, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3623.37, \"learn_time_ms\": 28144.003}", "{\"n\": 4968, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3627.1, \"learn_time_ms\": 28155.637}", "{\"n\": 4969, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3593.95, \"learn_time_ms\": 28183.433}", "{\"n\": 4970, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3615.59, \"learn_time_ms\": 28182.56}", "{\"n\": 4971, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3615.59, \"learn_time_ms\": 28200.784}", "{\"n\": 4972, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.33, \"learn_time_ms\": 28180.564}", "{\"n\": 4973, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3631.35, \"learn_time_ms\": 28200.585}", "{\"n\": 4974, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3635.98, \"learn_time_ms\": 28179.743}", "{\"n\": 4975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3636.22, \"learn_time_ms\": 28193.781}", "{\"n\": 4976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3654.32, \"learn_time_ms\": 28163.164}", "{\"n\": 4977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3659.51, \"learn_time_ms\": 28200.22}", "{\"n\": 4978, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3659.51, \"learn_time_ms\": 28136.029}", "{\"n\": 4979, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3659.51, \"learn_time_ms\": 28166.268}", "{\"n\": 4980, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3669.91, \"learn_time_ms\": 28198.511}", "{\"n\": 4981, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3673.07, \"learn_time_ms\": 28180.713}", "{\"n\": 4982, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3684.87, \"learn_time_ms\": 28173.334}", "{\"n\": 4983, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3674.31, \"learn_time_ms\": 28172.8}", "{\"n\": 4984, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3686.73, \"learn_time_ms\": 28239.761}", "{\"n\": 4985, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3686.73, \"learn_time_ms\": 28232.52}", "{\"n\": 4986, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3686.35, \"learn_time_ms\": 28240.265}", "{\"n\": 4987, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3686.42, \"learn_time_ms\": 28249.76}", "{\"n\": 4988, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3711.95, \"learn_time_ms\": 28273.213}", "{\"n\": 4989, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3719.42, \"learn_time_ms\": 28229.494}", "{\"n\": 4990, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3719.42, \"learn_time_ms\": 28174.264}", "{\"n\": 4991, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3719.42, \"learn_time_ms\": 28223.357}", "{\"n\": 4992, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3719.42, \"learn_time_ms\": 28212.854}", "{\"n\": 4993, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3718.68, \"learn_time_ms\": 28206.04}", "{\"n\": 4994, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3698.35, \"learn_time_ms\": 28168.534}", "{\"n\": 4995, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3692.63, \"learn_time_ms\": 28171.479}", "{\"n\": 4996, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3692.63, \"learn_time_ms\": 28220.85}", "{\"n\": 4997, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3690.37, \"learn_time_ms\": 28209.394}", "{\"n\": 4998, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3700.39, \"learn_time_ms\": 28193.239}", "{\"n\": 4999, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3700.39, \"learn_time_ms\": 28188.618}", "{\"n\": 5000, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3679.8, \"learn_time_ms\": 28225.147}"]["{\"n\": 5001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28300.594}", "{\"n\": 5002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27620.633}", "{\"n\": 5003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27470.442}", "{\"n\": 5004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27342.783}", "{\"n\": 5005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27298.046}", "{\"n\": 5006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27247.43}", "{\"n\": 5007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27211.092}", "{\"n\": 5008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27182.107}", "{\"n\": 5009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27170.237}", "{\"n\": 5010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27132.824}", "{\"n\": 5011, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 26998.548}", "{\"n\": 5012, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 26982.617}", "{\"n\": 5013, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3505.0, \"learn_time_ms\": 26972.877}", "{\"n\": 5014, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3855.8, \"learn_time_ms\": 26944.967}", "{\"n\": 5015, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.166666666666667, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3885.5, \"learn_time_ms\": 26926.038}", "{\"n\": 5016, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.857142857142857, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3975.8571428571427, \"learn_time_ms\": 26914.965}", "{\"n\": 5017, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.625, \"episode_reward_max\": -4.0, \"episode_len_mean\": 4005.75, \"learn_time_ms\": 26900.068}", "{\"n\": 5018, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.625, \"episode_reward_max\": -4.0, \"episode_len_mean\": 4005.75, \"learn_time_ms\": 26881.152}", "{\"n\": 5019, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.888888888888889, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3983.777777777778, \"learn_time_ms\": 26870.281}", "{\"n\": 5020, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.888888888888889, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3983.777777777778, \"learn_time_ms\": 26878.242}", "{\"n\": 5021, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 4009.2727272727275, \"learn_time_ms\": 26849.361}", "{\"n\": 5022, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.928571428571429, \"episode_reward_max\": -4.0, \"episode_len_mean\": 4094.6428571428573, \"learn_time_ms\": 26845.227}", "{\"n\": 5023, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.4375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4230.5, \"learn_time_ms\": 26856.208}", "{\"n\": 5024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.9411764705882355, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4169.058823529412, \"learn_time_ms\": 26859.711}", "{\"n\": 5025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.9411764705882355, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4169.058823529412, \"learn_time_ms\": 26860.312}", "{\"n\": 5026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.9411764705882355, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4169.058823529412, \"learn_time_ms\": 26828.984}", "{\"n\": 5027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4188.1578947368425, \"learn_time_ms\": 26856.277}", "{\"n\": 5028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.095238095238095, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4227.380952380952, \"learn_time_ms\": 26846.316}", "{\"n\": 5029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.181818181818182, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4213.318181818182, \"learn_time_ms\": 26847.915}", "{\"n\": 5030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.166666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4228.083333333333, \"learn_time_ms\": 26879.543}", "{\"n\": 5031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4184.8, \"learn_time_ms\": 26908.167}", "{\"n\": 5032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4184.8, \"learn_time_ms\": 26951.378}", "{\"n\": 5033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4184.8, \"learn_time_ms\": 26933.812}", "{\"n\": 5034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.481481481481482, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4129.962962962963, \"learn_time_ms\": 26994.022}", "{\"n\": 5035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.344827586206897, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4166.862068965517, \"learn_time_ms\": 27007.869}", "{\"n\": 5036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.483870967741935, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4130.774193548387, \"learn_time_ms\": 27069.418}", "{\"n\": 5037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.483870967741935, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4130.774193548387, \"learn_time_ms\": 27112.444}", "{\"n\": 5038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4144.90625, \"learn_time_ms\": 27102.679}", "{\"n\": 5039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.454545454545454, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4136.939393939394, \"learn_time_ms\": 27109.476}", "{\"n\": 5040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.588235294117647, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4112.088235294118, \"learn_time_ms\": 27136.407}", "{\"n\": 5041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4116.942857142857, \"learn_time_ms\": 27173.02}", "{\"n\": 5042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7105263157894735, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4131.5526315789475, \"learn_time_ms\": 27188.043}", "{\"n\": 5043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6923076923076925, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4126.692307692308, \"learn_time_ms\": 27173.096}", "{\"n\": 5044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4150.575, \"learn_time_ms\": 27168.652}", "{\"n\": 5045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.571428571428571, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4152.5952380952385, \"learn_time_ms\": 27166.376}", "{\"n\": 5046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.558139534883721, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4153.860465116279, \"learn_time_ms\": 27174.317}", "{\"n\": 5047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.613636363636363, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4142.227272727273, \"learn_time_ms\": 27117.833}", "{\"n\": 5048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.613636363636363, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4142.227272727273, \"learn_time_ms\": 27155.371}", "{\"n\": 5049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.613636363636363, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4142.227272727273, \"learn_time_ms\": 27137.197}", "{\"n\": 5050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.608695652173913, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4120.086956521739, \"learn_time_ms\": 27104.56}", "{\"n\": 5051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4127.875, \"learn_time_ms\": 27096.361}", "{\"n\": 5052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4097.98, \"learn_time_ms\": 27085.283}", "{\"n\": 5053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96078431372549, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4077.4313725490197, \"learn_time_ms\": 27110.776}", "{\"n\": 5054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.019230769230769, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4062.5, \"learn_time_ms\": 27080.617}", "{\"n\": 5055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.019230769230769, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4062.5, \"learn_time_ms\": 27104.591}", "{\"n\": 5056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.019230769230769, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4062.5, \"learn_time_ms\": 27111.405}", "{\"n\": 5057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9245283018867925, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4086.9056603773583, \"learn_time_ms\": 27134.347}", "{\"n\": 5058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.890909090909091, \"episode_reward_max\": -1.0, \"episode_len_mean\": 4087.836363636364, \"learn_time_ms\": 27168.078}", "{\"n\": 5059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7368421052631575, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4096.070175438596, \"learn_time_ms\": 27209.824}", "{\"n\": 5060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.661016949152542, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4117.881355932203, \"learn_time_ms\": 27204.006}", "{\"n\": 5061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.666666666666667, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4119.783333333334, \"learn_time_ms\": 27181.425}", "{\"n\": 5062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.666666666666667, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4119.783333333334, \"learn_time_ms\": 27167.946}", "{\"n\": 5063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.721311475409836, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4111.770491803279, \"learn_time_ms\": 27195.648}", "{\"n\": 5064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.721311475409836, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4111.770491803279, \"learn_time_ms\": 27196.362}", "{\"n\": 5065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.682539682539683, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4125.285714285715, \"learn_time_ms\": 27176.519}", "{\"n\": 5066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.590909090909091, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4155.863636363636, \"learn_time_ms\": 27158.095}", "{\"n\": 5067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.617647058823529, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4155.661764705882, \"learn_time_ms\": 27112.685}", "{\"n\": 5068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.617647058823529, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4155.661764705882, \"learn_time_ms\": 27099.105}", "{\"n\": 5069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.617647058823529, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4155.661764705882, \"learn_time_ms\": 27064.586}", "{\"n\": 5070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.728571428571429, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4136.442857142857, \"learn_time_ms\": 27056.93}", "{\"n\": 5071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4126.138888888889, \"learn_time_ms\": 27059.577}", "{\"n\": 5072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.780821917808219, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4119.3835616438355, \"learn_time_ms\": 27075.913}", "{\"n\": 5073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72972972972973, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4120.445945945946, \"learn_time_ms\": 27030.318}", "{\"n\": 5074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72972972972973, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4120.445945945946, \"learn_time_ms\": 27031.905}", "{\"n\": 5075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.671052631578948, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4135.5, \"learn_time_ms\": 27017.776}", "{\"n\": 5076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64935064935065, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4134.532467532467, \"learn_time_ms\": 27010.575}", "{\"n\": 5077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.705128205128205, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4117.884615384615, \"learn_time_ms\": 27046.498}", "{\"n\": 5078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.825, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4092.575, \"learn_time_ms\": 27046.086}", "{\"n\": 5079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.814814814814815, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4094.901234567901, \"learn_time_ms\": 27040.104}", "{\"n\": 5080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.783132530120482, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4101.144578313253, \"learn_time_ms\": 27073.359}", "{\"n\": 5081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.752941176470588, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4105.729411764706, \"learn_time_ms\": 27087.129}", "{\"n\": 5082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72093023255814, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4104.581395348837, \"learn_time_ms\": 27065.196}", "{\"n\": 5083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7701149425287355, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4092.574712643678, \"learn_time_ms\": 27069.773}", "{\"n\": 5084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7701149425287355, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4092.574712643678, \"learn_time_ms\": 27074.025}", "{\"n\": 5085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4105.545454545455, \"learn_time_ms\": 27092.602}", "{\"n\": 5086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.786516853932584, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4100.528089887641, \"learn_time_ms\": 27080.661}", "{\"n\": 5087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.771739130434782, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4099.760869565217, \"learn_time_ms\": 27086.776}", "{\"n\": 5088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.771739130434782, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4099.760869565217, \"learn_time_ms\": 27073.867}", "{\"n\": 5089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8936170212765955, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4072.5851063829787, \"learn_time_ms\": 27083.303}", "{\"n\": 5090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8936170212765955, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4072.5851063829787, \"learn_time_ms\": 27026.312}", "{\"n\": 5091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.926315789473684, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4067.5157894736844, \"learn_time_ms\": 27030.043}", "{\"n\": 5092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.918367346938775, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4056.9795918367345, \"learn_time_ms\": 27082.249}", "{\"n\": 5093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4061.06, \"learn_time_ms\": 27070.63}", "{\"n\": 5094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4061.06, \"learn_time_ms\": 27037.752}", "{\"n\": 5095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4070.1, \"learn_time_ms\": 27018.654}", "{\"n\": 5096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4071.69, \"learn_time_ms\": 27039.013}", "{\"n\": 5097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4086.14, \"learn_time_ms\": 27010.561}", "{\"n\": 5098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4076.89, \"learn_time_ms\": 27050.044}", "{\"n\": 5099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4073.22, \"learn_time_ms\": 27055.865}", "{\"n\": 5100, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4062.42, \"learn_time_ms\": 27093.703}", "{\"n\": 5101, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4060.66, \"learn_time_ms\": 27084.07}", "{\"n\": 5102, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4057.32, \"learn_time_ms\": 27043.736}", "{\"n\": 5103, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4057.32, \"learn_time_ms\": 27063.692}", "{\"n\": 5104, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4057.32, \"learn_time_ms\": 27063.856}", "{\"n\": 5105, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4057.32, \"learn_time_ms\": 27080.066}", "{\"n\": 5106, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4016.46, \"learn_time_ms\": 27050.476}", "{\"n\": 5107, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4010.79, \"learn_time_ms\": 27063.839}", "{\"n\": 5108, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4002.86, \"learn_time_ms\": 27002.665}", "{\"n\": 5109, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4012.61, \"learn_time_ms\": 26986.322}", "{\"n\": 5110, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4012.61, \"learn_time_ms\": 26973.011}", "{\"n\": 5111, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4009.78, \"learn_time_ms\": 26972.49}", "{\"n\": 5112, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3995.68, \"learn_time_ms\": 26940.785}", "{\"n\": 5113, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3984.75, \"learn_time_ms\": 26964.863}", "{\"n\": 5114, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4000.96, \"learn_time_ms\": 26999.254}", "{\"n\": 5115, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4000.96, \"learn_time_ms\": 26991.394}", "{\"n\": 5116, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 4000.96, \"learn_time_ms\": 26980.032}", "{\"n\": 5117, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3991.74, \"learn_time_ms\": 26943.621}", "{\"n\": 5118, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3987.54, \"learn_time_ms\": 26965.444}", "{\"n\": 5119, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3987.54, \"learn_time_ms\": 26960.244}", "{\"n\": 5120, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3971.32, \"learn_time_ms\": 26968.114}", "{\"n\": 5121, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3978.01, \"learn_time_ms\": 26933.945}", "{\"n\": 5122, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3969.57, \"learn_time_ms\": 26962.78}", "{\"n\": 5123, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3952.06, \"learn_time_ms\": 26927.448}", "{\"n\": 5124, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3941.04, \"learn_time_ms\": 26945.766}", "{\"n\": 5125, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3925.21, \"learn_time_ms\": 26968.637}", "{\"n\": 5126, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3925.21, \"learn_time_ms\": 26986.798}", "{\"n\": 5127, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3908.11, \"learn_time_ms\": 27021.428}", "{\"n\": 5128, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3931.63, \"learn_time_ms\": 26970.199}", "{\"n\": 5129, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3918.14, \"learn_time_ms\": 26973.772}", "{\"n\": 5130, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3910.97, \"learn_time_ms\": 26980.698}", "{\"n\": 5131, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3910.97, \"learn_time_ms\": 27012.922}", "{\"n\": 5132, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3910.97, \"learn_time_ms\": 26994.092}", "{\"n\": 5133, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3914.82, \"learn_time_ms\": 26993.371}", "{\"n\": 5134, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3914.31, \"learn_time_ms\": 26970.713}", "{\"n\": 5135, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3902.33, \"learn_time_ms\": 26985.392}", "{\"n\": 5136, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3898.03, \"learn_time_ms\": 26986.595}", "{\"n\": 5137, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3898.03, \"learn_time_ms\": 27030.163}", "{\"n\": 5138, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3898.03, \"learn_time_ms\": 27090.475}", "{\"n\": 5139, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3898.03, \"learn_time_ms\": 27116.384}", "{\"n\": 5140, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3874.4, \"learn_time_ms\": 27109.111}", "{\"n\": 5141, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3872.35, \"learn_time_ms\": 27115.879}", "{\"n\": 5142, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3865.46, \"learn_time_ms\": 27092.541}", "{\"n\": 5143, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3866.72, \"learn_time_ms\": 27136.237}", "{\"n\": 5144, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3866.72, \"learn_time_ms\": 27120.847}", "{\"n\": 5145, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3844.4, \"learn_time_ms\": 27096.9}", "{\"n\": 5146, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3833.53, \"learn_time_ms\": 27079.979}", "{\"n\": 5147, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3824.67, \"learn_time_ms\": 27057.47}", "{\"n\": 5148, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3824.67, \"learn_time_ms\": 27075.593}", "{\"n\": 5149, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3846.18, \"learn_time_ms\": 27051.83}", "{\"n\": 5150, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3855.35, \"learn_time_ms\": 27039.67}", "{\"n\": 5151, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3853.98, \"learn_time_ms\": 27027.114}", "{\"n\": 5152, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3853.98, \"learn_time_ms\": 27055.629}", "{\"n\": 5153, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3849.0, \"learn_time_ms\": 27045.699}", "{\"n\": 5154, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3843.7, \"learn_time_ms\": 27073.118}", "{\"n\": 5155, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3835.21, \"learn_time_ms\": 27036.098}", "{\"n\": 5156, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3835.21, \"learn_time_ms\": 27056.037}", "{\"n\": 5157, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3852.63, \"learn_time_ms\": 27051.002}", "{\"n\": 5158, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3860.04, \"learn_time_ms\": 27011.016}", "{\"n\": 5159, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3871.5, \"learn_time_ms\": 27034.729}", "{\"n\": 5160, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3864.02, \"learn_time_ms\": 27007.865}", "{\"n\": 5161, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3864.02, \"learn_time_ms\": 26993.301}", "{\"n\": 5162, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3875.53, \"learn_time_ms\": 26976.008}", "{\"n\": 5163, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3891.52, \"learn_time_ms\": 26945.044}", "{\"n\": 5164, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3905.72, \"learn_time_ms\": 26938.349}", "{\"n\": 5165, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3889.15, \"learn_time_ms\": 26931.02}", "{\"n\": 5166, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3889.15, \"learn_time_ms\": 26916.9}", "{\"n\": 5167, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3901.6, \"learn_time_ms\": 26900.326}", "{\"n\": 5168, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3900.43, \"learn_time_ms\": 26927.344}", "{\"n\": 5169, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3907.09, \"learn_time_ms\": 26926.061}", "{\"n\": 5170, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3912.57, \"learn_time_ms\": 26968.904}", "{\"n\": 5171, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3912.57, \"learn_time_ms\": 26953.964}", "{\"n\": 5172, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3912.57, \"learn_time_ms\": 26999.108}", "{\"n\": 5173, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3916.99, \"learn_time_ms\": 26988.952}", "{\"n\": 5174, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3902.8, \"learn_time_ms\": 26990.724}", "{\"n\": 5175, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3891.75, \"learn_time_ms\": 27042.277}", "{\"n\": 5176, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3872.42, \"learn_time_ms\": 27059.846}", "{\"n\": 5177, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3872.42, \"learn_time_ms\": 27070.228}", "{\"n\": 5178, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3856.66, \"learn_time_ms\": 27033.691}", "{\"n\": 5179, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3830.92, \"learn_time_ms\": 27016.034}", "{\"n\": 5180, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3818.08, \"learn_time_ms\": 27015.283}", "{\"n\": 5181, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3844.94, \"learn_time_ms\": 27038.374}", "{\"n\": 5182, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3844.94, \"learn_time_ms\": 27016.091}", "{\"n\": 5183, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3859.08, \"learn_time_ms\": 27024.699}", "{\"n\": 5184, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3869.05, \"learn_time_ms\": 27047.148}", "{\"n\": 5185, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3832.98, \"learn_time_ms\": 27005.742}", "{\"n\": 5186, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3829.0, \"learn_time_ms\": 27004.841}", "{\"n\": 5187, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3810.94, \"learn_time_ms\": 27008.982}", "{\"n\": 5188, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3792.52, \"learn_time_ms\": 27020.439}", "{\"n\": 5189, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3781.27, \"learn_time_ms\": 27043.031}", "{\"n\": 5190, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3785.56, \"learn_time_ms\": 27022.815}", "{\"n\": 5191, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3769.45, \"learn_time_ms\": 27015.071}", "{\"n\": 5192, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3768.39, \"learn_time_ms\": 26992.691}", "{\"n\": 5193, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3768.39, \"learn_time_ms\": 26987.771}", "{\"n\": 5194, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3778.74, \"learn_time_ms\": 26949.74}", "{\"n\": 5195, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3791.93, \"learn_time_ms\": 26946.652}", "{\"n\": 5196, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3767.58, \"learn_time_ms\": 26947.857}", "{\"n\": 5197, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3784.67, \"learn_time_ms\": 26927.992}", "{\"n\": 5198, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3786.68, \"learn_time_ms\": 26951.202}", "{\"n\": 5199, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3782.38, \"learn_time_ms\": 26972.1}", "{\"n\": 5200, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3782.38, \"learn_time_ms\": 26985.968}", "{\"n\": 5201, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3800.34, \"learn_time_ms\": 26969.528}", "{\"n\": 5202, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3792.3, \"learn_time_ms\": 27033.493}", "{\"n\": 5203, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3792.3, \"learn_time_ms\": 27043.565}", "{\"n\": 5204, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3792.3, \"learn_time_ms\": 27031.214}", "{\"n\": 5205, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3825.17, \"learn_time_ms\": 27051.685}", "{\"n\": 5206, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3839.17, \"learn_time_ms\": 27059.67}", "{\"n\": 5207, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3818.2, \"learn_time_ms\": 27044.22}", "{\"n\": 5208, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3818.41, \"learn_time_ms\": 27041.591}", "{\"n\": 5209, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3818.41, \"learn_time_ms\": 26988.691}", "{\"n\": 5210, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3827.51, \"learn_time_ms\": 26972.965}", "{\"n\": 5211, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3842.43, \"learn_time_ms\": 26979.37}", "{\"n\": 5212, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3842.68, \"learn_time_ms\": 26917.671}", "{\"n\": 5213, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3864.66, \"learn_time_ms\": 26929.745}", "{\"n\": 5214, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3869.96, \"learn_time_ms\": 26971.057}", "{\"n\": 5215, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3869.96, \"learn_time_ms\": 26992.498}", "{\"n\": 5216, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3844.5, \"learn_time_ms\": 26986.113}", "{\"n\": 5217, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3841.97, \"learn_time_ms\": 27001.73}", "{\"n\": 5218, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3841.97, \"learn_time_ms\": 26949.161}", "{\"n\": 5219, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3831.44, \"learn_time_ms\": 26930.376}", "{\"n\": 5220, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3845.77, \"learn_time_ms\": 26950.849}", "{\"n\": 5221, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3830.79, \"learn_time_ms\": 26983.737}", "{\"n\": 5222, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3830.79, \"learn_time_ms\": 27008.638}", "{\"n\": 5223, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3835.28, \"learn_time_ms\": 26989.753}", "{\"n\": 5224, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3844.6, \"learn_time_ms\": 26952.308}", "{\"n\": 5225, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3842.44, \"learn_time_ms\": 26930.749}", "{\"n\": 5226, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3849.41, \"learn_time_ms\": 26904.062}", "{\"n\": 5227, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3849.41, \"learn_time_ms\": 26923.318}", "{\"n\": 5228, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3853.0, \"learn_time_ms\": 26957.713}", "{\"n\": 5229, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3853.0, \"learn_time_ms\": 26970.11}", "{\"n\": 5230, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3819.25, \"learn_time_ms\": 26975.844}", "{\"n\": 5231, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3819.25, \"learn_time_ms\": 26954.473}", "{\"n\": 5232, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3855.09, \"learn_time_ms\": 26919.791}", "{\"n\": 5233, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3855.09, \"learn_time_ms\": 26930.822}", "{\"n\": 5234, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3845.64, \"learn_time_ms\": 26918.547}", "{\"n\": 5235, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3845.64, \"learn_time_ms\": 26938.299}", "{\"n\": 5236, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3839.13, \"learn_time_ms\": 26934.718}", "{\"n\": 5237, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3844.22, \"learn_time_ms\": 26936.507}", "{\"n\": 5238, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3850.24, \"learn_time_ms\": 26937.4}", "{\"n\": 5239, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3853.17, \"learn_time_ms\": 26967.19}", "{\"n\": 5240, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3853.17, \"learn_time_ms\": 26931.417}", "{\"n\": 5241, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.04, \"learn_time_ms\": 26930.818}", "{\"n\": 5242, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3832.75, \"learn_time_ms\": 26940.745}", "{\"n\": 5243, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3806.27, \"learn_time_ms\": 26939.812}", "{\"n\": 5244, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3800.15, \"learn_time_ms\": 26988.9}", "{\"n\": 5245, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3791.15, \"learn_time_ms\": 26968.404}", "{\"n\": 5246, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3801.14, \"learn_time_ms\": 27016.026}", "{\"n\": 5247, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3795.16, \"learn_time_ms\": 26973.69}", "{\"n\": 5248, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3785.05, \"learn_time_ms\": 26971.266}", "{\"n\": 5249, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3820.83, \"learn_time_ms\": 27017.459}", "{\"n\": 5250, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3821.32, \"learn_time_ms\": 27031.423}", "{\"n\": 5251, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3801.79, \"learn_time_ms\": 27014.334}", "{\"n\": 5252, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3799.81, \"learn_time_ms\": 27002.839}", "{\"n\": 5253, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3799.81, \"learn_time_ms\": 27015.423}", "{\"n\": 5254, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3802.33, \"learn_time_ms\": 26992.728}", "{\"n\": 5255, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3820.41, \"learn_time_ms\": 27013.735}", "{\"n\": 5256, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3820.41, \"learn_time_ms\": 26989.609}", "{\"n\": 5257, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3824.24, \"learn_time_ms\": 27021.206}", "{\"n\": 5258, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3825.78, \"learn_time_ms\": 27029.141}", "{\"n\": 5259, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3829.29, \"learn_time_ms\": 26969.54}", "{\"n\": 5260, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3844.41, \"learn_time_ms\": 26994.692}", "{\"n\": 5261, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3846.24, \"learn_time_ms\": 27017.94}", "{\"n\": 5262, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3833.66, \"learn_time_ms\": 27013.737}", "{\"n\": 5263, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3834.67, \"learn_time_ms\": 26986.849}", "{\"n\": 5264, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3834.67, \"learn_time_ms\": 26993.064}", "{\"n\": 5265, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3836.52, \"learn_time_ms\": 26957.593}", "{\"n\": 5266, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3859.1, \"learn_time_ms\": 26968.843}", "{\"n\": 5267, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3859.1, \"learn_time_ms\": 26968.182}", "{\"n\": 5268, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3859.1, \"learn_time_ms\": 26957.733}", "{\"n\": 5269, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3878.77, \"learn_time_ms\": 26955.185}", "{\"n\": 5270, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3911.09, \"learn_time_ms\": 26958.167}", "{\"n\": 5271, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3912.65, \"learn_time_ms\": 26953.506}", "{\"n\": 5272, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3927.29, \"learn_time_ms\": 26991.089}", "{\"n\": 5273, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3927.29, \"learn_time_ms\": 26993.118}", "{\"n\": 5274, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3904.46, \"learn_time_ms\": 26969.486}", "{\"n\": 5275, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3899.49, \"learn_time_ms\": 27009.601}", "{\"n\": 5276, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3899.11, \"learn_time_ms\": 26998.612}", "{\"n\": 5277, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3899.11, \"learn_time_ms\": 26981.401}", "{\"n\": 5278, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3891.43, \"learn_time_ms\": 26981.212}", "{\"n\": 5279, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3878.2, \"learn_time_ms\": 26986.385}", "{\"n\": 5280, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3888.95, \"learn_time_ms\": 26986.258}", "{\"n\": 5281, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3871.13, \"learn_time_ms\": 26941.775}", "{\"n\": 5282, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3866.11, \"learn_time_ms\": 26919.22}", "{\"n\": 5283, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.0, \"learn_time_ms\": 26938.253}", "{\"n\": 5284, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.0, \"learn_time_ms\": 26951.485}", "{\"n\": 5285, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.24, \"learn_time_ms\": 26924.228}", "{\"n\": 5286, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3862.69, \"learn_time_ms\": 26916.599}", "{\"n\": 5287, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3862.69, \"learn_time_ms\": 26953.736}", "{\"n\": 5288, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3851.08, \"learn_time_ms\": 26967.753}", "{\"n\": 5289, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3873.0, \"learn_time_ms\": 26996.476}", "{\"n\": 5290, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3841.66, \"learn_time_ms\": 26926.896}", "{\"n\": 5291, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3836.29, \"learn_time_ms\": 26975.387}", "{\"n\": 5292, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3836.29, \"learn_time_ms\": 26989.532}", "{\"n\": 5293, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3836.29, \"learn_time_ms\": 27005.914}", "{\"n\": 5294, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3837.57, \"learn_time_ms\": 27015.108}", "{\"n\": 5295, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3835.93, \"learn_time_ms\": 27017.776}", "{\"n\": 5296, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3848.62, \"learn_time_ms\": 27023.323}", "{\"n\": 5297, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3855.04, \"learn_time_ms\": 26951.94}", "{\"n\": 5298, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3860.08, \"learn_time_ms\": 26969.832}", "{\"n\": 5299, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3854.05, \"learn_time_ms\": 26958.051}", "{\"n\": 5300, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3854.05, \"learn_time_ms\": 27000.761}", "{\"n\": 5301, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3853.48, \"learn_time_ms\": 27005.002}", "{\"n\": 5302, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3854.32, \"learn_time_ms\": 26983.099}", "{\"n\": 5303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3843.13, \"learn_time_ms\": 26976.51}", "{\"n\": 5304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3843.13, \"learn_time_ms\": 26969.257}", "{\"n\": 5305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3821.55, \"learn_time_ms\": 26946.122}", "{\"n\": 5306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3814.91, \"learn_time_ms\": 26954.43}", "{\"n\": 5307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3812.4, \"learn_time_ms\": 27032.533}", "{\"n\": 5308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3804.03, \"learn_time_ms\": 27013.287}", "{\"n\": 5309, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3811.87, \"learn_time_ms\": 26999.655}", "{\"n\": 5310, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3827.06, \"learn_time_ms\": 27034.918}", "{\"n\": 5311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3830.56, \"learn_time_ms\": 27020.445}", "{\"n\": 5312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3846.56, \"learn_time_ms\": 27040.922}", "{\"n\": 5313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3846.56, \"learn_time_ms\": 27022.499}", "{\"n\": 5314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3860.88, \"learn_time_ms\": 27024.865}", "{\"n\": 5315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3860.88, \"learn_time_ms\": 27040.808}", "{\"n\": 5316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3837.04, \"learn_time_ms\": 27018.685}", "{\"n\": 5317, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3831.33, \"learn_time_ms\": 26998.711}", "{\"n\": 5318, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3819.71, \"learn_time_ms\": 26972.426}", "{\"n\": 5319, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3807.08, \"learn_time_ms\": 26953.588}", "{\"n\": 5320, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3807.08, \"learn_time_ms\": 26912.188}", "{\"n\": 5321, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3811.61, \"learn_time_ms\": 26911.205}", "{\"n\": 5322, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3817.93, \"learn_time_ms\": 26919.784}", "{\"n\": 5323, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3811.45, \"learn_time_ms\": 26914.187}", "{\"n\": 5324, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3820.03, \"learn_time_ms\": 26901.957}", "{\"n\": 5325, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3820.03, \"learn_time_ms\": 26960.662}", "{\"n\": 5326, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3816.96, \"learn_time_ms\": 26985.494}", "{\"n\": 5327, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3849.07, \"learn_time_ms\": 26997.095}", "{\"n\": 5328, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3849.07, \"learn_time_ms\": 27022.835}", "{\"n\": 5329, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3849.07, \"learn_time_ms\": 27040.782}", "{\"n\": 5330, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3819.43, \"learn_time_ms\": 27048.668}", "{\"n\": 5331, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3825.0, \"learn_time_ms\": 27106.524}", "{\"n\": 5332, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3840.55, \"learn_time_ms\": 27138.793}", "{\"n\": 5333, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3840.55, \"learn_time_ms\": 27153.439}", "{\"n\": 5334, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3841.07, \"learn_time_ms\": 27158.518}", "{\"n\": 5335, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3841.07, \"learn_time_ms\": 27119.299}", "{\"n\": 5336, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3859.85, \"learn_time_ms\": 27106.581}", "{\"n\": 5337, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3867.6, \"learn_time_ms\": 27057.881}", "{\"n\": 5338, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3867.6, \"learn_time_ms\": 27040.362}", "{\"n\": 5339, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3865.94, \"learn_time_ms\": 27048.559}", "{\"n\": 5340, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3864.49, \"learn_time_ms\": 27050.33}", "{\"n\": 5341, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3877.75, \"learn_time_ms\": 26992.937}", "{\"n\": 5342, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3856.39, \"learn_time_ms\": 26970.867}", "{\"n\": 5343, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3854.67, \"learn_time_ms\": 26969.246}", "{\"n\": 5344, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3854.67, \"learn_time_ms\": 27002.751}", "{\"n\": 5345, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3857.66, \"learn_time_ms\": 26995.44}", "{\"n\": 5346, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3858.07, \"learn_time_ms\": 26978.551}", "{\"n\": 5347, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3842.45, \"learn_time_ms\": 27015.394}", "{\"n\": 5348, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3864.1, \"learn_time_ms\": 27005.485}", "{\"n\": 5349, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3850.35, \"learn_time_ms\": 27012.164}", "{\"n\": 5350, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3831.94, \"learn_time_ms\": 27019.097}", "{\"n\": 5351, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3834.93, \"learn_time_ms\": 27082.301}", "{\"n\": 5352, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3834.93, \"learn_time_ms\": 27081.961}", "{\"n\": 5353, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3812.47, \"learn_time_ms\": 27080.593}", "{\"n\": 5354, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3832.52, \"learn_time_ms\": 27064.847}", "{\"n\": 5355, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3839.49, \"learn_time_ms\": 27078.469}", "{\"n\": 5356, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3839.61, \"learn_time_ms\": 27118.34}", "{\"n\": 5357, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3839.61, \"learn_time_ms\": 27083.439}", "{\"n\": 5358, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3837.3, \"learn_time_ms\": 27115.992}", "{\"n\": 5359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3813.53, \"learn_time_ms\": 27123.633}", "{\"n\": 5360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3832.59, \"learn_time_ms\": 27094.472}", "{\"n\": 5361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3832.59, \"learn_time_ms\": 27008.48}", "{\"n\": 5362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3843.22, \"learn_time_ms\": 26967.548}", "{\"n\": 5363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3844.05, \"learn_time_ms\": 26937.544}", "{\"n\": 5364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3811.89, \"learn_time_ms\": 26901.934}", "{\"n\": 5365, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3823.66, \"learn_time_ms\": 26882.91}", "{\"n\": 5366, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3806.12, \"learn_time_ms\": 26878.285}", "{\"n\": 5367, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3813.75, \"learn_time_ms\": 26916.422}", "{\"n\": 5368, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3807.25, \"learn_time_ms\": 26920.645}", "{\"n\": 5369, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3805.97, \"learn_time_ms\": 26936.102}", "{\"n\": 5370, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3815.88, \"learn_time_ms\": 26950.394}", "{\"n\": 5371, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3823.37, \"learn_time_ms\": 26978.052}", "{\"n\": 5372, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3816.95, \"learn_time_ms\": 27038.595}", "{\"n\": 5373, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3816.95, \"learn_time_ms\": 27033.877}", "{\"n\": 5374, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3816.95, \"learn_time_ms\": 27063.561}", "{\"n\": 5375, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3801.99, \"learn_time_ms\": 27027.919}", "{\"n\": 5376, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3779.63, \"learn_time_ms\": 27019.213}", "{\"n\": 5377, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3786.68, \"learn_time_ms\": 26986.951}", "{\"n\": 5378, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3786.68, \"learn_time_ms\": 26985.531}", "{\"n\": 5379, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3794.15, \"learn_time_ms\": 26954.895}", "{\"n\": 5380, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3794.15, \"learn_time_ms\": 26955.734}", "{\"n\": 5381, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3815.5, \"learn_time_ms\": 26956.164}", "{\"n\": 5382, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3837.68, \"learn_time_ms\": 26940.153}", "{\"n\": 5383, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3839.46, \"learn_time_ms\": 26939.987}", "{\"n\": 5384, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3835.67, \"learn_time_ms\": 26927.451}", "{\"n\": 5385, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3827.81, \"learn_time_ms\": 26985.578}", "{\"n\": 5386, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3827.81, \"learn_time_ms\": 26995.435}", "{\"n\": 5387, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3819.13, \"learn_time_ms\": 27009.303}", "{\"n\": 5388, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3771.51, \"learn_time_ms\": 27049.996}", "{\"n\": 5389, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3762.42, \"learn_time_ms\": 27039.357}", "{\"n\": 5390, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3737.86, \"learn_time_ms\": 27040.32}", "{\"n\": 5391, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3737.86, \"learn_time_ms\": 27055.082}", "{\"n\": 5392, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3741.15, \"learn_time_ms\": 27042.722}", "{\"n\": 5393, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3755.03, \"learn_time_ms\": 27065.169}", "{\"n\": 5394, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3738.33, \"learn_time_ms\": 27089.837}", "{\"n\": 5395, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3738.33, \"learn_time_ms\": 27065.175}", "{\"n\": 5396, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3719.9, \"learn_time_ms\": 27095.758}", "{\"n\": 5397, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3719.9, \"learn_time_ms\": 27126.813}", "{\"n\": 5398, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3729.16, \"learn_time_ms\": 27091.719}", "{\"n\": 5399, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3729.16, \"learn_time_ms\": 27066.02}", "{\"n\": 5400, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3729.16, \"learn_time_ms\": 27083.297}", "{\"n\": 5401, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3727.63, \"learn_time_ms\": 27115.559}", "{\"n\": 5402, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3729.73, \"learn_time_ms\": 27142.571}", "{\"n\": 5403, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3720.72, \"learn_time_ms\": 27128.974}", "{\"n\": 5404, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3727.69, \"learn_time_ms\": 27133.29}", "{\"n\": 5405, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3714.06, \"learn_time_ms\": 27104.573}", "{\"n\": 5406, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3714.06, \"learn_time_ms\": 27039.387}", "{\"n\": 5407, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3732.28, \"learn_time_ms\": 26997.01}", "{\"n\": 5408, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3737.1, \"learn_time_ms\": 26955.835}", "{\"n\": 5409, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3728.81, \"learn_time_ms\": 26960.384}", "{\"n\": 5410, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3715.0, \"learn_time_ms\": 26943.777}", "{\"n\": 5411, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3707.38, \"learn_time_ms\": 26904.22}", "{\"n\": 5412, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3696.35, \"learn_time_ms\": 26869.425}", "{\"n\": 5413, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3696.35, \"learn_time_ms\": 26891.688}", "{\"n\": 5414, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3687.82, \"learn_time_ms\": 26870.567}", "{\"n\": 5415, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3687.82, \"learn_time_ms\": 26896.997}", "{\"n\": 5416, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3686.87, \"learn_time_ms\": 26980.586}", "{\"n\": 5417, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3673.39, \"learn_time_ms\": 26984.587}", "{\"n\": 5418, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3664.46, \"learn_time_ms\": 27026.207}", "{\"n\": 5419, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3673.06, \"learn_time_ms\": 27074.583}", "{\"n\": 5420, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3672.59, \"learn_time_ms\": 27088.411}", "{\"n\": 5421, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3672.02, \"learn_time_ms\": 27103.858}", "{\"n\": 5422, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3672.49, \"learn_time_ms\": 27126.473}", "{\"n\": 5423, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3674.54, \"learn_time_ms\": 27121.613}", "{\"n\": 5424, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3674.54, \"learn_time_ms\": 27154.687}", "{\"n\": 5425, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3673.03, \"learn_time_ms\": 27137.702}", "{\"n\": 5426, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3668.94, \"learn_time_ms\": 27075.948}", "{\"n\": 5427, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3672.13, \"learn_time_ms\": 27099.661}", "{\"n\": 5428, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3666.29, \"learn_time_ms\": 27065.502}", "{\"n\": 5429, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3670.14, \"learn_time_ms\": 27037.393}", "{\"n\": 5430, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3655.6, \"learn_time_ms\": 27023.064}", "{\"n\": 5431, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3641.38, \"learn_time_ms\": 27018.804}", "{\"n\": 5432, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3641.81, \"learn_time_ms\": 26988.273}", "{\"n\": 5433, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3663.69, \"learn_time_ms\": 27009.504}", "{\"n\": 5434, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3673.47, \"learn_time_ms\": 26993.015}", "{\"n\": 5435, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3650.36, \"learn_time_ms\": 26983.647}", "{\"n\": 5436, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3657.63, \"learn_time_ms\": 27014.055}", "{\"n\": 5437, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3641.09, \"learn_time_ms\": 27047.237}", "{\"n\": 5438, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3641.09, \"learn_time_ms\": 27054.817}", "{\"n\": 5439, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3649.91, \"learn_time_ms\": 27023.728}", "{\"n\": 5440, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3659.83, \"learn_time_ms\": 27020.373}", "{\"n\": 5441, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3659.83, \"learn_time_ms\": 27020.941}", "{\"n\": 5442, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3635.24, \"learn_time_ms\": 27004.35}", "{\"n\": 5443, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3635.24, \"learn_time_ms\": 26981.323}", "{\"n\": 5444, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3623.14, \"learn_time_ms\": 26927.026}", "{\"n\": 5445, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3612.28, \"learn_time_ms\": 26959.487}", "{\"n\": 5446, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3598.51, \"learn_time_ms\": 26900.66}", "{\"n\": 5447, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3598.51, \"learn_time_ms\": 26845.563}", "{\"n\": 5448, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3603.5, \"learn_time_ms\": 26850.806}", "{\"n\": 5449, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3605.1, \"learn_time_ms\": 26886.937}", "{\"n\": 5450, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3601.73, \"learn_time_ms\": 26924.919}", "{\"n\": 5451, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3610.76, \"learn_time_ms\": 26895.984}", "{\"n\": 5452, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3606.57, \"learn_time_ms\": 26932.368}", "{\"n\": 5453, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3597.71, \"learn_time_ms\": 26917.922}", "{\"n\": 5454, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3602.1, \"learn_time_ms\": 26935.874}", "{\"n\": 5455, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3571.05, \"learn_time_ms\": 26945.624}", "{\"n\": 5456, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3571.05, \"learn_time_ms\": 26989.897}", "{\"n\": 5457, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.0, \"learn_time_ms\": 26989.72}", "{\"n\": 5458, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3567.33, \"learn_time_ms\": 27017.654}", "{\"n\": 5459, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3566.58, \"learn_time_ms\": 27039.2}", "{\"n\": 5460, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3558.18, \"learn_time_ms\": 27001.76}", "{\"n\": 5461, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3558.18, \"learn_time_ms\": 27030.588}", "{\"n\": 5462, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3556.52, \"learn_time_ms\": 27021.249}", "{\"n\": 5463, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3553.52, \"learn_time_ms\": 27058.859}", "{\"n\": 5464, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3539.29, \"learn_time_ms\": 27082.714}", "{\"n\": 5465, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3520.32, \"learn_time_ms\": 27111.882}", "{\"n\": 5466, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3526.91, \"learn_time_ms\": 27128.001}", "{\"n\": 5467, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3544.04, \"learn_time_ms\": 27148.121}", "{\"n\": 5468, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3544.39, \"learn_time_ms\": 27130.887}", "{\"n\": 5469, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3525.07, \"learn_time_ms\": 27121.998}", "{\"n\": 5470, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3528.67, \"learn_time_ms\": 27164.542}", "{\"n\": 5471, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3524.67, \"learn_time_ms\": 27163.077}", "{\"n\": 5472, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3511.36, \"learn_time_ms\": 27159.197}", "{\"n\": 5473, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.76, \"learn_time_ms\": 27149.456}", "{\"n\": 5474, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.85, \"learn_time_ms\": 27131.276}", "{\"n\": 5475, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3453.61, \"learn_time_ms\": 27102.5}", "{\"n\": 5476, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3443.41, \"learn_time_ms\": 27041.258}", "{\"n\": 5477, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3430.94, \"learn_time_ms\": 27008.462}", "{\"n\": 5478, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3417.97, \"learn_time_ms\": 27026.314}", "{\"n\": 5479, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.95, \"learn_time_ms\": 27072.007}", "{\"n\": 5480, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.98, \"learn_time_ms\": 27039.713}", "{\"n\": 5481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.18, \"learn_time_ms\": 27011.497}", "{\"n\": 5482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.61, \"learn_time_ms\": 27027.952}", "{\"n\": 5483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.66, \"learn_time_ms\": 27008.531}", "{\"n\": 5484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.41, \"learn_time_ms\": 26966.357}", "{\"n\": 5485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.24, \"learn_time_ms\": 26980.01}", "{\"n\": 5486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.24, \"learn_time_ms\": 26992.74}", "{\"n\": 5487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.19, \"learn_time_ms\": 26991.456}", "{\"n\": 5488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.36, \"learn_time_ms\": 26933.52}", "{\"n\": 5489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.77, \"learn_time_ms\": 26899.502}", "{\"n\": 5490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.77, \"learn_time_ms\": 26941.504}", "{\"n\": 5491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.79, \"learn_time_ms\": 26940.596}", "{\"n\": 5492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.53, \"learn_time_ms\": 26920.334}", "{\"n\": 5493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.96, \"learn_time_ms\": 26946.026}", "{\"n\": 5494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.92, \"learn_time_ms\": 27005.511}", "{\"n\": 5495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.64, \"learn_time_ms\": 26987.914}", "{\"n\": 5496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.66, \"learn_time_ms\": 27035.97}", "{\"n\": 5497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.25, \"learn_time_ms\": 27071.21}", "{\"n\": 5498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.05, \"learn_time_ms\": 27122.134}", "{\"n\": 5499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.77, \"learn_time_ms\": 27081.073}", "{\"n\": 5500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.67, \"learn_time_ms\": 27024.377}", "{\"n\": 5501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.52, \"learn_time_ms\": 27063.367}", "{\"n\": 5502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.2, \"learn_time_ms\": 27101.86}", "{\"n\": 5503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.45, \"learn_time_ms\": 27081.827}", "{\"n\": 5504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 27103.396}", "{\"n\": 5505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.15, \"learn_time_ms\": 27063.2}", "{\"n\": 5506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.15, \"learn_time_ms\": 27039.36}", "{\"n\": 5507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.66, \"learn_time_ms\": 27028.641}", "{\"n\": 5508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.82, \"learn_time_ms\": 27035.725}", "{\"n\": 5509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.36, \"learn_time_ms\": 27039.423}", "{\"n\": 5510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.44, \"learn_time_ms\": 26999.05}", "{\"n\": 5511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.44, \"learn_time_ms\": 26980.135}", "{\"n\": 5512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.17, \"learn_time_ms\": 26977.208}", "{\"n\": 5513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.68, \"learn_time_ms\": 26970.254}", "{\"n\": 5514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.47, \"learn_time_ms\": 26949.691}", "{\"n\": 5515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.35, \"learn_time_ms\": 26995.555}", "{\"n\": 5516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.44, \"learn_time_ms\": 26981.419}", "{\"n\": 5517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.44, \"learn_time_ms\": 26967.742}", "{\"n\": 5518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.81, \"learn_time_ms\": 26962.978}", "{\"n\": 5519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.48, \"learn_time_ms\": 26983.914}", "{\"n\": 5520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.97, \"learn_time_ms\": 27048.247}", "{\"n\": 5521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.99, \"learn_time_ms\": 27077.781}", "{\"n\": 5522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.15, \"learn_time_ms\": 27014.112}", "{\"n\": 5523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.61, \"learn_time_ms\": 27036.882}", "{\"n\": 5524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.61, \"learn_time_ms\": 27017.85}", "{\"n\": 5525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.15, \"learn_time_ms\": 27031.99}", "{\"n\": 5526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.03, \"learn_time_ms\": 27024.703}", "{\"n\": 5527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.29, \"learn_time_ms\": 27047.766}", "{\"n\": 5528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.29, \"learn_time_ms\": 27032.291}", "{\"n\": 5529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.29, \"learn_time_ms\": 27019.754}", "{\"n\": 5530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.48, \"learn_time_ms\": 27049.94}", "{\"n\": 5531, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.27, \"learn_time_ms\": 27030.944}", "{\"n\": 5532, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.05, \"learn_time_ms\": 27047.387}", "{\"n\": 5533, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3292.46, \"learn_time_ms\": 27021.992}", "{\"n\": 5534, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3292.46, \"learn_time_ms\": 27005.086}", "{\"n\": 5535, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3292.46, \"learn_time_ms\": 26956.004}", "{\"n\": 5536, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3275.99, \"learn_time_ms\": 26952.316}", "{\"n\": 5537, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3278.34, \"learn_time_ms\": 26962.221}", "{\"n\": 5538, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.84, \"learn_time_ms\": 26934.485}", "{\"n\": 5539, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.84, \"learn_time_ms\": 26907.089}", "{\"n\": 5540, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.84, \"learn_time_ms\": 26859.448}", "{\"n\": 5541, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3299.34, \"learn_time_ms\": 26833.643}", "{\"n\": 5542, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3301.44, \"learn_time_ms\": 26839.911}", "{\"n\": 5543, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.57, \"learn_time_ms\": 26836.922}", "{\"n\": 5544, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.57, \"learn_time_ms\": 26863.575}", "{\"n\": 5545, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.57, \"learn_time_ms\": 26917.062}", "{\"n\": 5546, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.19, \"learn_time_ms\": 26921.957}", "{\"n\": 5547, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3293.11, \"learn_time_ms\": 26885.458}", "{\"n\": 5548, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3290.27, \"learn_time_ms\": 26916.365}", "{\"n\": 5549, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3293.15, \"learn_time_ms\": 26939.081}", "{\"n\": 5550, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3293.15, \"learn_time_ms\": 26947.766}", "{\"n\": 5551, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.6, \"learn_time_ms\": 26953.001}", "{\"n\": 5552, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3286.55, \"learn_time_ms\": 26939.981}", "{\"n\": 5553, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.3, \"learn_time_ms\": 26978.281}", "{\"n\": 5554, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.3, \"learn_time_ms\": 26975.134}", "{\"n\": 5555, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.68, \"learn_time_ms\": 26962.427}", "{\"n\": 5556, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3289.29, \"learn_time_ms\": 26984.899}", "{\"n\": 5557, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3282.63, \"learn_time_ms\": 26975.601}", "{\"n\": 5558, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3282.24, \"learn_time_ms\": 26948.785}", "{\"n\": 5559, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3282.24, \"learn_time_ms\": 26959.077}", "{\"n\": 5560, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3279.82, \"learn_time_ms\": 26958.222}", "{\"n\": 5561, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3279.82, \"learn_time_ms\": 26977.584}", "{\"n\": 5562, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3280.24, \"learn_time_ms\": 26983.119}", "{\"n\": 5563, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3268.87, \"learn_time_ms\": 26948.393}", "{\"n\": 5564, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3267.35, \"learn_time_ms\": 26918.945}", "{\"n\": 5565, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3272.19, \"learn_time_ms\": 26927.988}", "{\"n\": 5566, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3272.19, \"learn_time_ms\": 26946.049}", "{\"n\": 5567, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3272.19, \"learn_time_ms\": 26944.859}", "{\"n\": 5568, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3271.95, \"learn_time_ms\": 26938.17}", "{\"n\": 5569, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3276.74, \"learn_time_ms\": 26900.467}", "{\"n\": 5570, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3276.74, \"learn_time_ms\": 26884.241}", "{\"n\": 5571, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3271.46, \"learn_time_ms\": 26895.031}", "{\"n\": 5572, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3271.46, \"learn_time_ms\": 26888.685}", "{\"n\": 5573, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3274.36, \"learn_time_ms\": 26893.958}", "{\"n\": 5574, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3272.91, \"learn_time_ms\": 26945.366}", "{\"n\": 5575, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3270.81, \"learn_time_ms\": 26933.852}", "{\"n\": 5576, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3268.94, \"learn_time_ms\": 26851.613}", "{\"n\": 5577, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3268.94, \"learn_time_ms\": 26876.029}", "{\"n\": 5578, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3265.12, \"learn_time_ms\": 26903.619}", "{\"n\": 5579, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3256.05, \"learn_time_ms\": 26936.287}", "{\"n\": 5580, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3245.55, \"learn_time_ms\": 26938.832}", "{\"n\": 5581, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3243.88, \"learn_time_ms\": 26940.428}", "{\"n\": 5582, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3243.88, \"learn_time_ms\": 26992.24}", "{\"n\": 5583, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3243.88, \"learn_time_ms\": 26992.096}", "{\"n\": 5584, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3236.67, \"learn_time_ms\": 26989.323}", "{\"n\": 5585, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3237.5, \"learn_time_ms\": 26954.757}", "{\"n\": 5586, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3249.2, \"learn_time_ms\": 27016.448}", "{\"n\": 5587, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3250.42, \"learn_time_ms\": 27007.127}", "{\"n\": 5588, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3250.42, \"learn_time_ms\": 26988.803}", "{\"n\": 5589, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3253.25, \"learn_time_ms\": 27020.652}", "{\"n\": 5590, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3264.75, \"learn_time_ms\": 27052.651}", "{\"n\": 5591, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.41, \"learn_time_ms\": 27063.265}", "{\"n\": 5592, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.41, \"learn_time_ms\": 26992.799}", "{\"n\": 5593, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3274.23, \"learn_time_ms\": 27018.764}", "{\"n\": 5594, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3274.46, \"learn_time_ms\": 26989.381}", "{\"n\": 5595, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3267.31, \"learn_time_ms\": 27028.086}", "{\"n\": 5596, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3264.48, \"learn_time_ms\": 27030.78}", "{\"n\": 5597, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3265.06, \"learn_time_ms\": 27042.549}", "{\"n\": 5598, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3271.09, \"learn_time_ms\": 27051.353}", "{\"n\": 5599, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3271.09, \"learn_time_ms\": 27015.037}", "{\"n\": 5600, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3272.39, \"learn_time_ms\": 27028.438}", "{\"n\": 5601, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.8, \"learn_time_ms\": 26968.738}", "{\"n\": 5602, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.15, \"learn_time_ms\": 27035.757}", "{\"n\": 5603, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.15, \"learn_time_ms\": 27024.2}", "{\"n\": 5604, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3268.9, \"learn_time_ms\": 27027.716}", "{\"n\": 5605, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3264.5, \"learn_time_ms\": 26992.098}", "{\"n\": 5606, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.72, \"learn_time_ms\": 27007.644}", "{\"n\": 5607, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.88, \"learn_time_ms\": 27006.429}", "{\"n\": 5608, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.64, \"learn_time_ms\": 27026.218}", "{\"n\": 5609, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.21, \"learn_time_ms\": 27022.452}", "{\"n\": 5610, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.77, \"learn_time_ms\": 27000.335}", "{\"n\": 5611, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.59, \"learn_time_ms\": 27033.641}", "{\"n\": 5612, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.24, \"learn_time_ms\": 26997.922}", "{\"n\": 5613, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.63, \"learn_time_ms\": 26994.567}", "{\"n\": 5614, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.73, \"learn_time_ms\": 27041.358}", "{\"n\": 5615, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.73, \"learn_time_ms\": 27073.313}", "{\"n\": 5616, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3282.96, \"learn_time_ms\": 27078.614}", "{\"n\": 5617, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3282.78, \"learn_time_ms\": 27065.549}", "{\"n\": 5618, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3282.59, \"learn_time_ms\": 27060.562}", "{\"n\": 5619, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3283.21, \"learn_time_ms\": 27074.464}", "{\"n\": 5620, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3283.21, \"learn_time_ms\": 27062.596}", "{\"n\": 5621, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.28, \"learn_time_ms\": 27073.762}", "{\"n\": 5622, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3270.31, \"learn_time_ms\": 27090.977}", "{\"n\": 5623, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3270.31, \"learn_time_ms\": 27088.779}", "{\"n\": 5624, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3272.85, \"learn_time_ms\": 27055.537}", "{\"n\": 5625, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.17, \"learn_time_ms\": 27041.138}", "{\"n\": 5626, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3285.78, \"learn_time_ms\": 26991.346}", "{\"n\": 5627, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3283.94, \"learn_time_ms\": 27003.783}", "{\"n\": 5628, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.97, \"learn_time_ms\": 27017.316}", "{\"n\": 5629, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3278.22, \"learn_time_ms\": 27041.413}", "{\"n\": 5630, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3277.41, \"learn_time_ms\": 27066.885}", "{\"n\": 5631, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3277.41, \"learn_time_ms\": 27074.798}", "{\"n\": 5632, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.24, \"learn_time_ms\": 27050.823}", "{\"n\": 5633, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3280.02, \"learn_time_ms\": 27045.364}", "{\"n\": 5634, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.96, \"learn_time_ms\": 27087.326}", "{\"n\": 5635, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3271.66, \"learn_time_ms\": 27072.167}", "{\"n\": 5636, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3274.22, \"learn_time_ms\": 27091.331}", "{\"n\": 5637, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3281.16, \"learn_time_ms\": 27097.509}", "{\"n\": 5638, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.43, \"learn_time_ms\": 27053.715}", "{\"n\": 5639, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3275.43, \"learn_time_ms\": 27058.652}", "{\"n\": 5640, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3285.95, \"learn_time_ms\": 27050.659}", "{\"n\": 5641, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3284.09, \"learn_time_ms\": 27004.888}", "{\"n\": 5642, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3283.3, \"learn_time_ms\": 27036.958}", "{\"n\": 5643, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.8, \"learn_time_ms\": 27039.135}", "{\"n\": 5644, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.8, \"learn_time_ms\": 26989.276}", "{\"n\": 5645, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.8, \"learn_time_ms\": 27047.98}", "{\"n\": 5646, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.9, \"learn_time_ms\": 27073.88}", "{\"n\": 5647, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.9, \"learn_time_ms\": 27100.695}", "{\"n\": 5648, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.69, \"learn_time_ms\": 27145.417}", "{\"n\": 5649, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.57, \"learn_time_ms\": 27099.456}", "{\"n\": 5650, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.02, \"learn_time_ms\": 27050.31}", "{\"n\": 5651, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.16, \"learn_time_ms\": 27063.402}", "{\"n\": 5652, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.51, \"learn_time_ms\": 27066.744}", "{\"n\": 5653, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.1, \"learn_time_ms\": 27077.043}", "{\"n\": 5654, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.66, \"learn_time_ms\": 27055.651}", "{\"n\": 5655, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.96, \"learn_time_ms\": 27024.111}", "{\"n\": 5656, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.96, \"learn_time_ms\": 27005.019}", "{\"n\": 5657, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.41, \"learn_time_ms\": 26991.269}", "{\"n\": 5658, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3303.9, \"learn_time_ms\": 26964.455}", "{\"n\": 5659, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3305.51, \"learn_time_ms\": 27009.26}", "{\"n\": 5660, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.17, \"learn_time_ms\": 27041.602}", "{\"n\": 5661, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.17, \"learn_time_ms\": 27050.194}", "{\"n\": 5662, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.45, \"learn_time_ms\": 27050.384}", "{\"n\": 5663, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.7, \"learn_time_ms\": 27034.468}", "{\"n\": 5664, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3302.98, \"learn_time_ms\": 27067.011}", "{\"n\": 5665, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.64, \"learn_time_ms\": 27089.768}", "{\"n\": 5666, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.26, \"learn_time_ms\": 27097.656}", "{\"n\": 5667, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.26, \"learn_time_ms\": 27073.151}", "{\"n\": 5668, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.95, \"learn_time_ms\": 27084.11}", "{\"n\": 5669, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.2, \"learn_time_ms\": 27109.176}", "{\"n\": 5670, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3297.72, \"learn_time_ms\": 27113.491}", "{\"n\": 5671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.78, \"learn_time_ms\": 27135.859}", "{\"n\": 5672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3296.78, \"learn_time_ms\": 27107.146}", "{\"n\": 5673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.61, \"learn_time_ms\": 27100.449}", "{\"n\": 5674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3294.61, \"learn_time_ms\": 27097.636}", "{\"n\": 5675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.28, \"learn_time_ms\": 27064.298}", "{\"n\": 5676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3283.05, \"learn_time_ms\": 27042.05}", "{\"n\": 5677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3286.22, \"learn_time_ms\": 27006.942}", "{\"n\": 5678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3286.23, \"learn_time_ms\": 26998.612}", "{\"n\": 5679, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3286.39, \"learn_time_ms\": 26920.076}", "{\"n\": 5680, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3288.61, \"learn_time_ms\": 26930.912}", "{\"n\": 5681, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3290.51, \"learn_time_ms\": 26916.313}", "{\"n\": 5682, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.88, \"learn_time_ms\": 26941.789}", "{\"n\": 5683, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.79, \"learn_time_ms\": 26961.149}", "{\"n\": 5684, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.56, \"learn_time_ms\": 26937.978}", "{\"n\": 5685, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.27, \"learn_time_ms\": 26937.092}", "{\"n\": 5686, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.66, \"learn_time_ms\": 26915.019}", "{\"n\": 5687, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.91, \"learn_time_ms\": 26997.643}", "{\"n\": 5688, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.81, \"learn_time_ms\": 26996.357}", "{\"n\": 5689, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.87, \"learn_time_ms\": 26994.472}", "{\"n\": 5690, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.33, \"learn_time_ms\": 26979.019}", "{\"n\": 5691, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3284.53, \"learn_time_ms\": 26980.595}", "{\"n\": 5692, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.22, \"learn_time_ms\": 26940.688}", "{\"n\": 5693, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.0, \"learn_time_ms\": 26908.116}", "{\"n\": 5694, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.0, \"learn_time_ms\": 26925.6}", "{\"n\": 5695, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.29, \"learn_time_ms\": 26896.557}", "{\"n\": 5696, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.35, \"learn_time_ms\": 26929.251}", "{\"n\": 5697, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.35, \"learn_time_ms\": 26919.029}", "{\"n\": 5698, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.03, \"learn_time_ms\": 26899.801}", "{\"n\": 5699, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.74, \"learn_time_ms\": 26943.325}", "{\"n\": 5700, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.69, \"learn_time_ms\": 26936.913}", "{\"n\": 5701, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.89, \"learn_time_ms\": 26954.067}", "{\"n\": 5702, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.89, \"learn_time_ms\": 26995.082}", "{\"n\": 5703, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.89, \"learn_time_ms\": 26997.115}", "{\"n\": 5704, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.92, \"learn_time_ms\": 27007.734}", "{\"n\": 5705, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.15, \"learn_time_ms\": 27014.517}", "{\"n\": 5706, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.14, \"learn_time_ms\": 26978.376}", "{\"n\": 5707, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.85, \"learn_time_ms\": 26940.765}", "{\"n\": 5708, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.85, \"learn_time_ms\": 26957.911}", "{\"n\": 5709, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.85, \"learn_time_ms\": 26947.55}", "{\"n\": 5710, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.69, \"learn_time_ms\": 26953.661}", "{\"n\": 5711, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.29, \"learn_time_ms\": 26915.225}", "{\"n\": 5712, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.69, \"learn_time_ms\": 26946.588}", "{\"n\": 5713, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.69, \"learn_time_ms\": 26993.957}", "{\"n\": 5714, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.44, \"learn_time_ms\": 26977.343}", "{\"n\": 5715, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.61, \"learn_time_ms\": 27003.113}", "{\"n\": 5716, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.51, \"learn_time_ms\": 27035.784}", "{\"n\": 5717, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.3, \"learn_time_ms\": 27027.852}", "{\"n\": 5718, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.0, \"learn_time_ms\": 27006.074}", "{\"n\": 5719, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.5, \"learn_time_ms\": 27006.124}", "{\"n\": 5720, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.5, \"learn_time_ms\": 26996.551}", "{\"n\": 5721, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.55, \"learn_time_ms\": 27015.872}", "{\"n\": 5722, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.85, \"learn_time_ms\": 26957.423}", "{\"n\": 5723, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.87, \"learn_time_ms\": 26949.05}", "{\"n\": 5724, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.87, \"learn_time_ms\": 26952.825}", "{\"n\": 5725, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.88, \"learn_time_ms\": 26952.993}", "{\"n\": 5726, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.77, \"learn_time_ms\": 26965.945}", "{\"n\": 5727, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.71, \"learn_time_ms\": 26949.794}", "{\"n\": 5728, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.22, \"learn_time_ms\": 26967.169}", "{\"n\": 5729, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.69, \"learn_time_ms\": 26951.114}", "{\"n\": 5730, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.95, \"learn_time_ms\": 26959.739}", "{\"n\": 5731, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.87, \"learn_time_ms\": 26926.955}", "{\"n\": 5732, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.77, \"learn_time_ms\": 26946.549}", "{\"n\": 5733, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.77, \"learn_time_ms\": 26903.452}", "{\"n\": 5734, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.72, \"learn_time_ms\": 26940.875}", "{\"n\": 5735, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.72, \"learn_time_ms\": 26963.036}", "{\"n\": 5736, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.72, \"learn_time_ms\": 26972.994}", "{\"n\": 5737, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.56, \"learn_time_ms\": 27017.212}", "{\"n\": 5738, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.94, \"learn_time_ms\": 27032.61}", "{\"n\": 5739, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.55, \"learn_time_ms\": 27018.694}", "{\"n\": 5740, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.77, \"learn_time_ms\": 26995.849}", "{\"n\": 5741, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.77, \"learn_time_ms\": 26992.181}", "{\"n\": 5742, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.77, \"learn_time_ms\": 26942.757}", "{\"n\": 5743, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.58, \"learn_time_ms\": 26995.058}", "{\"n\": 5744, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.35, \"learn_time_ms\": 26985.647}", "{\"n\": 5745, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.28, \"learn_time_ms\": 26958.545}", "{\"n\": 5746, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.02, \"learn_time_ms\": 26940.077}", "{\"n\": 5747, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.53, \"learn_time_ms\": 26920.847}", "{\"n\": 5748, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.07, \"learn_time_ms\": 26902.293}", "{\"n\": 5749, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.11, \"learn_time_ms\": 26893.027}", "{\"n\": 5750, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.75, \"learn_time_ms\": 26926.104}", "{\"n\": 5751, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.53, \"learn_time_ms\": 26921.683}", "{\"n\": 5752, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.53, \"learn_time_ms\": 26964.148}", "{\"n\": 5753, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.64, \"learn_time_ms\": 26937.911}", "{\"n\": 5754, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.64, \"learn_time_ms\": 26898.385}", "{\"n\": 5755, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.32, \"learn_time_ms\": 26900.389}", "{\"n\": 5756, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.36, \"learn_time_ms\": 26911.133}", "{\"n\": 5757, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.36, \"learn_time_ms\": 26932.431}", "{\"n\": 5758, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.89, \"learn_time_ms\": 26951.56}", "{\"n\": 5759, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3271.6, \"learn_time_ms\": 26943.422}", "{\"n\": 5760, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.89, \"learn_time_ms\": 26924.663}", "{\"n\": 5761, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.14, \"learn_time_ms\": 26942.205}", "{\"n\": 5762, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.49, \"learn_time_ms\": 26934.627}", "{\"n\": 5763, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.04, \"learn_time_ms\": 26929.248}", "{\"n\": 5764, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.04, \"learn_time_ms\": 26939.68}", "{\"n\": 5765, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.0, \"learn_time_ms\": 26970.326}", "{\"n\": 5766, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.02, \"learn_time_ms\": 26946.366}", "{\"n\": 5767, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.5, \"learn_time_ms\": 26921.877}", "{\"n\": 5768, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.63, \"learn_time_ms\": 26929.783}", "{\"n\": 5769, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.03, \"learn_time_ms\": 26962.164}", "{\"n\": 5770, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.55, \"learn_time_ms\": 26975.904}", "{\"n\": 5771, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.88, \"learn_time_ms\": 26972.092}", "{\"n\": 5772, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.63, \"learn_time_ms\": 26987.437}", "{\"n\": 5773, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.12, \"learn_time_ms\": 26978.678}", "{\"n\": 5774, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.75, \"learn_time_ms\": 26978.96}", "{\"n\": 5775, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.17, \"learn_time_ms\": 26967.027}", "{\"n\": 5776, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.89, \"learn_time_ms\": 26969.153}", "{\"n\": 5777, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.89, \"learn_time_ms\": 26966.047}", "{\"n\": 5778, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.66, \"learn_time_ms\": 26952.58}", "{\"n\": 5779, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.75, \"learn_time_ms\": 26940.909}", "{\"n\": 5780, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.77, \"learn_time_ms\": 26947.965}", "{\"n\": 5781, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.71, \"learn_time_ms\": 26969.463}", "{\"n\": 5782, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.62, \"learn_time_ms\": 26962.431}", "{\"n\": 5783, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.97, \"learn_time_ms\": 26973.531}", "{\"n\": 5784, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.05, \"learn_time_ms\": 26936.177}", "{\"n\": 5785, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.05, \"learn_time_ms\": 26911.841}", "{\"n\": 5786, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.14, \"learn_time_ms\": 26906.72}", "{\"n\": 5787, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.86, \"learn_time_ms\": 26880.523}", "{\"n\": 5788, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.34, \"learn_time_ms\": 26879.021}", "{\"n\": 5789, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.85, \"learn_time_ms\": 26876.1}", "{\"n\": 5790, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.85, \"learn_time_ms\": 26870.716}", "{\"n\": 5791, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.13, \"learn_time_ms\": 26843.837}", "{\"n\": 5792, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.13, \"learn_time_ms\": 26859.154}", "{\"n\": 5793, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.4, \"learn_time_ms\": 26877.867}", "{\"n\": 5794, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.18, \"learn_time_ms\": 26936.167}", "{\"n\": 5795, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.81, \"learn_time_ms\": 26956.87}", "{\"n\": 5796, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.09, \"learn_time_ms\": 26955.787}", "{\"n\": 5797, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.09, \"learn_time_ms\": 27023.561}", "{\"n\": 5798, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.07, \"learn_time_ms\": 27010.238}", "{\"n\": 5799, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.11, \"learn_time_ms\": 27016.201}", "{\"n\": 5800, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.02, \"learn_time_ms\": 27011.489}", "{\"n\": 5801, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.45, \"learn_time_ms\": 27030.527}", "{\"n\": 5802, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.86, \"learn_time_ms\": 27020.989}", "{\"n\": 5803, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.23, \"learn_time_ms\": 26990.333}", "{\"n\": 5804, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.46, \"learn_time_ms\": 26974.302}", "{\"n\": 5805, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.09, \"learn_time_ms\": 26929.287}", "{\"n\": 5806, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.09, \"learn_time_ms\": 26934.428}", "{\"n\": 5807, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.19, \"learn_time_ms\": 26901.235}", "{\"n\": 5808, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.96, \"learn_time_ms\": 26896.834}", "{\"n\": 5809, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.84, \"learn_time_ms\": 26932.793}", "{\"n\": 5810, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.49, \"learn_time_ms\": 26947.752}", "{\"n\": 5811, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.12, \"learn_time_ms\": 26971.02}", "{\"n\": 5812, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.77, \"learn_time_ms\": 26968.546}", "{\"n\": 5813, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.18, \"learn_time_ms\": 26973.96}", "{\"n\": 5814, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.18, \"learn_time_ms\": 26962.066}", "{\"n\": 5815, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.37, \"learn_time_ms\": 26982.079}", "{\"n\": 5816, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.77, \"learn_time_ms\": 26958.343}", "{\"n\": 5817, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.77, \"learn_time_ms\": 26938.423}", "{\"n\": 5818, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.34, \"learn_time_ms\": 26958.653}", "{\"n\": 5819, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.83, \"learn_time_ms\": 26907.852}", "{\"n\": 5820, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.09, \"learn_time_ms\": 26857.971}", "{\"n\": 5821, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.44, \"learn_time_ms\": 26828.745}", "{\"n\": 5822, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.65, \"learn_time_ms\": 26816.161}", "{\"n\": 5823, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.67, \"learn_time_ms\": 26789.991}", "{\"n\": 5824, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.1, \"learn_time_ms\": 26805.23}", "{\"n\": 5825, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.1, \"learn_time_ms\": 26811.291}", "{\"n\": 5826, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.85, \"learn_time_ms\": 26839.239}", "{\"n\": 5827, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.87, \"learn_time_ms\": 26834.485}", "{\"n\": 5828, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.53, \"learn_time_ms\": 26826.613}", "{\"n\": 5829, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.68, \"learn_time_ms\": 26843.561}", "{\"n\": 5830, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.58, \"learn_time_ms\": 26883.468}", "{\"n\": 5831, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.45, \"learn_time_ms\": 26881.738}", "{\"n\": 5832, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.23, \"learn_time_ms\": 26870.465}", "{\"n\": 5833, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.03, \"learn_time_ms\": 26890.823}", "{\"n\": 5834, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.03, \"learn_time_ms\": 26883.488}", "{\"n\": 5835, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.81, \"learn_time_ms\": 26903.012}", "{\"n\": 5836, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.0, \"learn_time_ms\": 26890.954}", "{\"n\": 5837, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.0, \"learn_time_ms\": 26892.062}", "{\"n\": 5838, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.44, \"learn_time_ms\": 26930.918}", "{\"n\": 5839, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.19, \"learn_time_ms\": 26921.084}", "{\"n\": 5840, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.19, \"learn_time_ms\": 26903.443}", "{\"n\": 5841, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.29, \"learn_time_ms\": 26898.234}", "{\"n\": 5842, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.29, \"learn_time_ms\": 26932.285}", "{\"n\": 5843, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.29, \"learn_time_ms\": 26956.32}", "{\"n\": 5844, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.02, \"learn_time_ms\": 26953.712}", "{\"n\": 5845, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.02, \"learn_time_ms\": 26912.743}", "{\"n\": 5846, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.2, \"learn_time_ms\": 26962.435}", "{\"n\": 5847, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.06, \"learn_time_ms\": 26977.316}", "{\"n\": 5848, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.06, \"learn_time_ms\": 26900.662}", "{\"n\": 5849, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.54, \"learn_time_ms\": 26921.298}", "{\"n\": 5850, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.86, \"learn_time_ms\": 26917.711}", "{\"n\": 5851, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.08, \"learn_time_ms\": 26917.493}", "{\"n\": 5852, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.67, \"learn_time_ms\": 26877.275}", "{\"n\": 5853, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.67, \"learn_time_ms\": 26842.376}", "{\"n\": 5854, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.27, \"learn_time_ms\": 26851.577}", "{\"n\": 5855, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.22, \"learn_time_ms\": 26875.181}", "{\"n\": 5856, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.34, \"learn_time_ms\": 26824.127}", "{\"n\": 5857, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.34, \"learn_time_ms\": 26825.148}", "{\"n\": 5858, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.83, \"learn_time_ms\": 26863.328}", "{\"n\": 5859, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.83, \"learn_time_ms\": 26829.374}", "{\"n\": 5860, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.94, \"learn_time_ms\": 26879.881}", "{\"n\": 5861, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.06, \"learn_time_ms\": 26891.862}", "{\"n\": 5862, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.11, \"learn_time_ms\": 26923.54}", "{\"n\": 5863, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.45, \"learn_time_ms\": 26916.541}", "{\"n\": 5864, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.45, \"learn_time_ms\": 26927.15}", "{\"n\": 5865, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.13, \"learn_time_ms\": 26886.106}", "{\"n\": 5866, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.41, \"learn_time_ms\": 26906.123}", "{\"n\": 5867, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.98, \"learn_time_ms\": 26923.28}", "{\"n\": 5868, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.1, \"learn_time_ms\": 26929.945}", "{\"n\": 5869, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.84, \"learn_time_ms\": 26943.793}", "{\"n\": 5870, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.84, \"learn_time_ms\": 26907.324}", "{\"n\": 5871, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.09, \"learn_time_ms\": 26885.866}", "{\"n\": 5872, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.15, \"learn_time_ms\": 26899.952}", "{\"n\": 5873, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.5, \"learn_time_ms\": 26909.622}", "{\"n\": 5874, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.37, \"learn_time_ms\": 26878.572}", "{\"n\": 5875, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.96, \"learn_time_ms\": 26928.434}", "{\"n\": 5876, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.74, \"learn_time_ms\": 26915.005}", "{\"n\": 5877, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.74, \"learn_time_ms\": 26949.522}", "{\"n\": 5878, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.2, \"learn_time_ms\": 26943.896}", "{\"n\": 5879, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.73, \"learn_time_ms\": 26976.178}", "{\"n\": 5880, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.1, \"learn_time_ms\": 26990.734}", "{\"n\": 5881, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.63, \"learn_time_ms\": 27004.532}", "{\"n\": 5882, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.74, \"learn_time_ms\": 26990.107}", "{\"n\": 5883, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.84, \"learn_time_ms\": 26980.394}", "{\"n\": 5884, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.49, \"learn_time_ms\": 26995.784}", "{\"n\": 5885, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.51, \"learn_time_ms\": 26966.392}", "{\"n\": 5886, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.25, \"learn_time_ms\": 26978.595}", "{\"n\": 5887, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.37, \"learn_time_ms\": 26884.677}", "{\"n\": 5888, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.37, \"learn_time_ms\": 26882.692}", "{\"n\": 5889, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.25, \"learn_time_ms\": 26840.875}", "{\"n\": 5890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.9, \"learn_time_ms\": 26793.1}", "{\"n\": 5891, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.17, \"learn_time_ms\": 26801.58}", "{\"n\": 5892, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.27, \"learn_time_ms\": 26784.142}", "{\"n\": 5893, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.44, \"learn_time_ms\": 26825.943}", "{\"n\": 5894, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.61, \"learn_time_ms\": 26835.747}", "{\"n\": 5895, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.57, \"learn_time_ms\": 26859.626}", "{\"n\": 5896, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.78, \"learn_time_ms\": 26818.16}", "{\"n\": 5897, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.03, \"learn_time_ms\": 26865.478}", "{\"n\": 5898, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.66, \"learn_time_ms\": 26880.417}", "{\"n\": 5899, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.66, \"learn_time_ms\": 26894.17}", "{\"n\": 5900, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.09, \"learn_time_ms\": 26930.27}", "{\"n\": 5901, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.09, \"learn_time_ms\": 26896.926}", "{\"n\": 5902, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.13, \"learn_time_ms\": 26909.117}", "{\"n\": 5903, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.4, \"learn_time_ms\": 26890.477}", "{\"n\": 5904, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.35, \"learn_time_ms\": 26883.989}", "{\"n\": 5905, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.98, \"learn_time_ms\": 26864.064}", "{\"n\": 5906, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.8, \"learn_time_ms\": 26869.902}", "{\"n\": 5907, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.96, \"learn_time_ms\": 26885.778}", "{\"n\": 5908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.96, \"learn_time_ms\": 26864.098}", "{\"n\": 5909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.04, \"learn_time_ms\": 26882.39}", "{\"n\": 5910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.81, \"learn_time_ms\": 26861.816}", "{\"n\": 5911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.81, \"learn_time_ms\": 26889.231}", "{\"n\": 5912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.81, \"learn_time_ms\": 26888.831}", "{\"n\": 5913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.02, \"learn_time_ms\": 26869.421}", "{\"n\": 5914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.02, \"learn_time_ms\": 26853.903}", "{\"n\": 5915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.95, \"learn_time_ms\": 26854.421}", "{\"n\": 5916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.28, \"learn_time_ms\": 26852.272}", "{\"n\": 5917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.54, \"learn_time_ms\": 26823.516}", "{\"n\": 5918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.22, \"learn_time_ms\": 26843.989}", "{\"n\": 5919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.01, \"learn_time_ms\": 26828.063}", "{\"n\": 5920, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.01, \"learn_time_ms\": 26863.165}", "{\"n\": 5921, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.17, \"learn_time_ms\": 26862.89}", "{\"n\": 5922, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.25, \"learn_time_ms\": 26905.515}", "{\"n\": 5923, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.49, \"learn_time_ms\": 26931.178}", "{\"n\": 5924, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.49, \"learn_time_ms\": 26924.666}", "{\"n\": 5925, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.75, \"learn_time_ms\": 26952.125}", "{\"n\": 5926, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.95, \"learn_time_ms\": 26955.967}", "{\"n\": 5927, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.85, \"learn_time_ms\": 26987.223}", "{\"n\": 5928, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.68, \"learn_time_ms\": 26992.757}", "{\"n\": 5929, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.25, \"learn_time_ms\": 26980.05}", "{\"n\": 5930, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.09, \"learn_time_ms\": 26958.299}", "{\"n\": 5931, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.12, \"learn_time_ms\": 26974.366}", "{\"n\": 5932, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.35, \"learn_time_ms\": 26939.502}", "{\"n\": 5933, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.35, \"learn_time_ms\": 26933.837}", "{\"n\": 5934, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.09, \"learn_time_ms\": 26936.494}", "{\"n\": 5935, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.72, \"learn_time_ms\": 26897.454}", "{\"n\": 5936, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.72, \"learn_time_ms\": 26912.121}", "{\"n\": 5937, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.01, \"learn_time_ms\": 26897.008}", "{\"n\": 5938, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.01, \"learn_time_ms\": 26864.088}", "{\"n\": 5939, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.1, \"learn_time_ms\": 26905.137}", "{\"n\": 5940, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.97, \"learn_time_ms\": 26908.292}", "{\"n\": 5941, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.69, \"learn_time_ms\": 26890.105}", "{\"n\": 5942, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.68, \"learn_time_ms\": 26867.089}", "{\"n\": 5943, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.43, \"learn_time_ms\": 26830.426}", "{\"n\": 5944, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.3, \"learn_time_ms\": 26853.907}", "{\"n\": 5945, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.99, \"learn_time_ms\": 26875.835}", "{\"n\": 5946, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.14, \"learn_time_ms\": 26864.201}", "{\"n\": 5947, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.28, \"learn_time_ms\": 26888.429}", "{\"n\": 5948, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.06, \"learn_time_ms\": 26856.925}", "{\"n\": 5949, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.06, \"learn_time_ms\": 26822.358}", "{\"n\": 5950, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.07, \"learn_time_ms\": 26796.792}", "{\"n\": 5951, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.34, \"learn_time_ms\": 26812.931}", "{\"n\": 5952, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.69, \"learn_time_ms\": 26818.787}", "{\"n\": 5953, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.83, \"learn_time_ms\": 26869.701}", "{\"n\": 5954, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.76, \"learn_time_ms\": 26843.152}", "{\"n\": 5955, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.76, \"learn_time_ms\": 26817.467}", "{\"n\": 5956, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.46, \"learn_time_ms\": 26852.794}", "{\"n\": 5957, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.46, \"learn_time_ms\": 26824.197}", "{\"n\": 5958, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.46, \"learn_time_ms\": 26876.146}", "{\"n\": 5959, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.84, \"learn_time_ms\": 26888.922}", "{\"n\": 5960, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.21, \"learn_time_ms\": 26880.748}", "{\"n\": 5961, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.21, \"learn_time_ms\": 26904.694}", "{\"n\": 5962, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.21, \"learn_time_ms\": 26924.139}", "{\"n\": 5963, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.33, \"learn_time_ms\": 26911.364}", "{\"n\": 5964, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.33, \"learn_time_ms\": 26938.804}", "{\"n\": 5965, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.06, \"learn_time_ms\": 26971.719}", "{\"n\": 5966, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.44, \"learn_time_ms\": 26962.757}", "{\"n\": 5967, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.39, \"learn_time_ms\": 26948.727}", "{\"n\": 5968, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.83, \"learn_time_ms\": 26922.165}", "{\"n\": 5969, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.03, \"learn_time_ms\": 26938.662}", "{\"n\": 5970, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.03, \"learn_time_ms\": 26972.662}", "{\"n\": 5971, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.23, \"learn_time_ms\": 26938.173}", "{\"n\": 5972, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.99, \"learn_time_ms\": 26953.207}", "{\"n\": 5973, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.18, \"learn_time_ms\": 26946.762}", "{\"n\": 5974, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.74, \"learn_time_ms\": 26918.147}", "{\"n\": 5975, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.78, \"learn_time_ms\": 26904.1}", "{\"n\": 5976, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.78, \"learn_time_ms\": 26907.548}", "{\"n\": 5977, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.08, \"learn_time_ms\": 26944.036}", "{\"n\": 5978, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.43, \"learn_time_ms\": 26972.507}", "{\"n\": 5979, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.95, \"learn_time_ms\": 26973.218}", "{\"n\": 5980, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.39, \"learn_time_ms\": 27003.262}", "{\"n\": 5981, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.39, \"learn_time_ms\": 27038.032}", "{\"n\": 5982, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.48, \"learn_time_ms\": 27014.468}", "{\"n\": 5983, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.25, \"learn_time_ms\": 27004.866}", "{\"n\": 5984, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.6, \"learn_time_ms\": 27056.859}", "{\"n\": 5985, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.51, \"learn_time_ms\": 27049.17}", "{\"n\": 5986, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.78, \"learn_time_ms\": 27049.89}", "{\"n\": 5987, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.86, \"learn_time_ms\": 26997.086}", "{\"n\": 5988, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.04, \"learn_time_ms\": 27021.364}", "{\"n\": 5989, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.57, \"learn_time_ms\": 26990.854}", "{\"n\": 5990, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.08, \"learn_time_ms\": 26961.814}", "{\"n\": 5991, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.74, \"learn_time_ms\": 26915.861}", "{\"n\": 5992, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.86, \"learn_time_ms\": 26912.22}", "{\"n\": 5993, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.46, \"learn_time_ms\": 26923.813}", "{\"n\": 5994, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.1, \"learn_time_ms\": 26908.503}", "{\"n\": 5995, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.17, \"learn_time_ms\": 26901.225}", "{\"n\": 5996, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.93, \"learn_time_ms\": 26895.958}", "{\"n\": 5997, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.19, \"learn_time_ms\": 26947.993}", "{\"n\": 5998, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.19, \"learn_time_ms\": 26912.281}", "{\"n\": 5999, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.88, \"learn_time_ms\": 26955.068}", "{\"n\": 6000, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.18, \"learn_time_ms\": 26991.473}"]["{\"n\": 6001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28516.219}", "{\"n\": 6002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27783.772}", "{\"n\": 6003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27455.838}", "{\"n\": 6004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27312.604}", "{\"n\": 6005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27221.26}", "{\"n\": 6006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27160.976}", "{\"n\": 6007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27082.618}", "{\"n\": 6008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27039.806}", "{\"n\": 6009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27029.139}", "{\"n\": 6010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 26997.843}", "{\"n\": 6011, \"episode_reward_min\": -6.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3305.0, \"learn_time_ms\": 26833.44}", "{\"n\": 6012, \"episode_reward_min\": -6.0, \"episode_reward_mean\": -4.857142857142857, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3408.285714285714, \"learn_time_ms\": 26805.547}", "{\"n\": 6013, \"episode_reward_min\": -6.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3430.875, \"learn_time_ms\": 26825.563}", "{\"n\": 6014, \"episode_reward_min\": -6.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3430.875, \"learn_time_ms\": 26815.194}", "{\"n\": 6015, \"episode_reward_min\": -6.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3430.875, \"learn_time_ms\": 26779.023}", "{\"n\": 6016, \"episode_reward_min\": -6.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3430.875, \"learn_time_ms\": 26774.161}", "{\"n\": 6017, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.846153846153846, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3418.3846153846152, \"learn_time_ms\": 26780.579}", "{\"n\": 6018, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.875, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3440.875, \"learn_time_ms\": 26780.735}", "{\"n\": 6019, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.875, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3440.875, \"learn_time_ms\": 26758.478}", "{\"n\": 6020, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.875, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3440.875, \"learn_time_ms\": 26803.551}", "{\"n\": 6021, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.875, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3440.875, \"learn_time_ms\": 26784.843}", "{\"n\": 6022, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.764705882352941, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3451.176470588235, \"learn_time_ms\": 26804.31}", "{\"n\": 6023, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.7727272727272725, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3423.7272727272725, \"learn_time_ms\": 26791.268}", "{\"n\": 6024, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.739130434782608, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3432.608695652174, \"learn_time_ms\": 26803.797}", "{\"n\": 6025, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.833333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3431.2916666666665, \"learn_time_ms\": 26832.676}", "{\"n\": 6026, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.833333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3431.2916666666665, \"learn_time_ms\": 26830.416}", "{\"n\": 6027, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.833333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3431.2916666666665, \"learn_time_ms\": 26850.966}", "{\"n\": 6028, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.925925925925926, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3413.8518518518517, \"learn_time_ms\": 26839.479}", "{\"n\": 6029, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.1290322580644, \"learn_time_ms\": 26856.068}", "{\"n\": 6030, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3425.1290322580644, \"learn_time_ms\": 26833.952}", "{\"n\": 6031, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.90625, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3433.5, \"learn_time_ms\": 26855.6}", "{\"n\": 6032, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.90625, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3433.5, \"learn_time_ms\": 26831.479}", "{\"n\": 6033, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -4.90625, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3433.5, \"learn_time_ms\": 26849.96}", "{\"n\": 6034, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.157894736842105, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3403.1315789473683, \"learn_time_ms\": 26858.868}", "{\"n\": 6035, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.153846153846154, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3405.25641025641, \"learn_time_ms\": 26827.224}", "{\"n\": 6036, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3411.15, \"learn_time_ms\": 26829.871}", "{\"n\": 6037, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3411.15, \"learn_time_ms\": 26855.358}", "{\"n\": 6038, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3411.15, \"learn_time_ms\": 26876.023}", "{\"n\": 6039, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -4.976190476190476, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3419.8571428571427, \"learn_time_ms\": 26876.626}", "{\"n\": 6040, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -4.913043478260869, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3409.891304347826, \"learn_time_ms\": 26882.725}", "{\"n\": 6041, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -4.914893617021277, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3414.936170212766, \"learn_time_ms\": 26896.082}", "{\"n\": 6042, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -4.9375, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3415.3958333333335, \"learn_time_ms\": 26891.964}", "{\"n\": 6043, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -4.9375, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3415.3958333333335, \"learn_time_ms\": 26890.689}", "{\"n\": 6044, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.020408163265306, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.918367346939, \"learn_time_ms\": 26865.744}", "{\"n\": 6045, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.098039215686274, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.764705882353, \"learn_time_ms\": 26923.066}", "{\"n\": 6046, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.054545454545455, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.2727272727275, \"learn_time_ms\": 26893.389}", "{\"n\": 6047, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.053571428571429, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.125, \"learn_time_ms\": 26835.339}", "{\"n\": 6048, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.053571428571429, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.125, \"learn_time_ms\": 26866.363}", "{\"n\": 6049, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.052631578947368, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.6491228070176, \"learn_time_ms\": 26884.337}", "{\"n\": 6050, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.052631578947368, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.6491228070176, \"learn_time_ms\": 26912.101}", "{\"n\": 6051, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.032258064516129, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.3225806451615, \"learn_time_ms\": 26887.922}", "{\"n\": 6052, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.28125, \"learn_time_ms\": 26915.064}", "{\"n\": 6053, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.28125, \"learn_time_ms\": 26943.424}", "{\"n\": 6054, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.046153846153846, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.3076923076924, \"learn_time_ms\": 26929.333}", "{\"n\": 6055, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.046153846153846, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.3076923076924, \"learn_time_ms\": 26925.076}", "{\"n\": 6056, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.03030303030303, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.2727272727275, \"learn_time_ms\": 26964.822}", "{\"n\": 6057, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.069444444444445, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.6944444444443, \"learn_time_ms\": 27026.323}", "{\"n\": 6058, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.069444444444445, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.6944444444443, \"learn_time_ms\": 27018.506}", "{\"n\": 6059, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.095890410958904, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.123287671233, \"learn_time_ms\": 27030.319}", "{\"n\": 6060, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.095890410958904, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.123287671233, \"learn_time_ms\": 26976.419}", "{\"n\": 6061, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.095890410958904, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.123287671233, \"learn_time_ms\": 26989.343}", "{\"n\": 6062, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.090909090909091, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.3636363636365, \"learn_time_ms\": 26976.698}", "{\"n\": 6063, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.1125, \"learn_time_ms\": 26907.461}", "{\"n\": 6064, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.209876543209877, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.0493827160494, \"learn_time_ms\": 26902.226}", "{\"n\": 6065, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.209876543209877, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.0493827160494, \"learn_time_ms\": 26925.507}", "{\"n\": 6066, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.209876543209877, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.0493827160494, \"learn_time_ms\": 26906.126}", "{\"n\": 6067, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.204819277108434, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.2289156626507, \"learn_time_ms\": 26904.492}", "{\"n\": 6068, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.275862068965517, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.0344827586205, \"learn_time_ms\": 26880.038}", "{\"n\": 6069, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.3636363636365, \"learn_time_ms\": 26853.657}", "{\"n\": 6070, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.247191011235955, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.078651685393, \"learn_time_ms\": 26866.059}", "{\"n\": 6071, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.247191011235955, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.078651685393, \"learn_time_ms\": 26858.224}", "{\"n\": 6072, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.247191011235955, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.078651685393, \"learn_time_ms\": 26872.191}", "{\"n\": 6073, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.336956521739131, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.7391304347825, \"learn_time_ms\": 26902.139}", "{\"n\": 6074, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.336842105263158, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.2526315789473, \"learn_time_ms\": 26935.333}", "{\"n\": 6075, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.354166666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.5104166666665, \"learn_time_ms\": 26928.075}", "{\"n\": 6076, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.360824742268041, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.0309278350514, \"learn_time_ms\": 26963.595}", "{\"n\": 6077, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.360824742268041, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.0309278350514, \"learn_time_ms\": 26946.48}", "{\"n\": 6078, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36734693877551, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.9591836734694, \"learn_time_ms\": 26950.218}", "{\"n\": 6079, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.52, \"learn_time_ms\": 26954.292}", "{\"n\": 6080, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.28, \"learn_time_ms\": 26974.797}", "{\"n\": 6081, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.73, \"learn_time_ms\": 26989.974}", "{\"n\": 6082, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.73, \"learn_time_ms\": 27000.681}", "{\"n\": 6083, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.73, \"learn_time_ms\": 26984.057}", "{\"n\": 6084, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.65, \"learn_time_ms\": 26993.113}", "{\"n\": 6085, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.76, \"learn_time_ms\": 26938.265}", "{\"n\": 6086, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.76, \"learn_time_ms\": 26924.675}", "{\"n\": 6087, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.72, \"learn_time_ms\": 26941.708}", "{\"n\": 6088, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.72, \"learn_time_ms\": 26951.288}", "{\"n\": 6089, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.44, \"learn_time_ms\": 26920.378}", "{\"n\": 6090, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.5, \"learn_time_ms\": 26913.576}", "{\"n\": 6091, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.92, \"learn_time_ms\": 26893.448}", "{\"n\": 6092, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.93, \"learn_time_ms\": 26875.497}", "{\"n\": 6093, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.41, \"learn_time_ms\": 26881.242}", "{\"n\": 6094, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.24, \"learn_time_ms\": 26896.754}", "{\"n\": 6095, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.66, \"learn_time_ms\": 26907.218}", "{\"n\": 6096, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.95, \"learn_time_ms\": 26913.335}", "{\"n\": 6097, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.4, \"learn_time_ms\": 26898.35}", "{\"n\": 6098, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.4, \"learn_time_ms\": 26890.144}", "{\"n\": 6099, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.66, \"learn_time_ms\": 26897.311}", "{\"n\": 6100, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.62, \"learn_time_ms\": 26858.021}", "{\"n\": 6101, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.98, \"learn_time_ms\": 26856.233}", "{\"n\": 6102, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.98, \"learn_time_ms\": 26891.131}", "{\"n\": 6103, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.63, \"learn_time_ms\": 26896.356}", "{\"n\": 6104, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.86, \"learn_time_ms\": 26832.23}", "{\"n\": 6105, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.12, \"learn_time_ms\": 26861.448}", "{\"n\": 6106, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.87, \"learn_time_ms\": 26832.235}", "{\"n\": 6107, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.32, \"learn_time_ms\": 26791.357}", "{\"n\": 6108, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.25, \"learn_time_ms\": 26784.662}", "{\"n\": 6109, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.46, \"learn_time_ms\": 26815.343}", "{\"n\": 6110, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.47, \"learn_time_ms\": 26830.187}", "{\"n\": 6111, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.47, \"learn_time_ms\": 26872.177}", "{\"n\": 6112, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.01, \"learn_time_ms\": 26844.446}", "{\"n\": 6113, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.27, \"learn_time_ms\": 26836.346}", "{\"n\": 6114, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.43, \"learn_time_ms\": 26904.818}", "{\"n\": 6115, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.39, \"learn_time_ms\": 26891.75}", "{\"n\": 6116, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.25, \"learn_time_ms\": 26898.097}", "{\"n\": 6117, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.25, \"learn_time_ms\": 26931.98}", "{\"n\": 6118, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.0, \"learn_time_ms\": 26964.177}", "{\"n\": 6119, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.28, \"learn_time_ms\": 26939.791}", "{\"n\": 6120, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.7, \"learn_time_ms\": 26932.412}", "{\"n\": 6121, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.7, \"learn_time_ms\": 26925.641}", "{\"n\": 6122, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.31, \"learn_time_ms\": 26949.638}", "{\"n\": 6123, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.31, \"learn_time_ms\": 26977.912}", "{\"n\": 6124, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.75, \"learn_time_ms\": 26983.366}", "{\"n\": 6125, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.34, \"learn_time_ms\": 26987.72}", "{\"n\": 6126, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.73, \"learn_time_ms\": 27027.545}", "{\"n\": 6127, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.96, \"learn_time_ms\": 27021.995}", "{\"n\": 6128, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.96, \"learn_time_ms\": 27063.609}", "{\"n\": 6129, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.47, \"learn_time_ms\": 27061.071}", "{\"n\": 6130, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.21, \"learn_time_ms\": 27094.241}", "{\"n\": 6131, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.19, \"learn_time_ms\": 27085.675}", "{\"n\": 6132, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.95, \"learn_time_ms\": 27071.66}", "{\"n\": 6133, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.57, \"learn_time_ms\": 27042.796}", "{\"n\": 6134, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.47, \"learn_time_ms\": 26994.624}", "{\"n\": 6135, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.89, \"learn_time_ms\": 26991.041}", "{\"n\": 6136, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.92, \"learn_time_ms\": 26981.975}", "{\"n\": 6137, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.86, \"learn_time_ms\": 26938.379}", "{\"n\": 6138, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.86, \"learn_time_ms\": 26897.321}", "{\"n\": 6139, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.99, \"learn_time_ms\": 26931.837}", "{\"n\": 6140, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.68, \"learn_time_ms\": 26906.44}", "{\"n\": 6141, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.68, \"learn_time_ms\": 26881.491}", "{\"n\": 6142, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.75, \"learn_time_ms\": 26863.417}", "{\"n\": 6143, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.29, \"learn_time_ms\": 26857.114}", "{\"n\": 6144, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.29, \"learn_time_ms\": 26857.378}", "{\"n\": 6145, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.05, \"learn_time_ms\": 26847.1}", "{\"n\": 6146, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3373.44, \"learn_time_ms\": 26803.618}", "{\"n\": 6147, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3375.73, \"learn_time_ms\": 26863.8}", "{\"n\": 6148, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3374.95, \"learn_time_ms\": 26847.215}", "{\"n\": 6149, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3374.95, \"learn_time_ms\": 26796.461}", "{\"n\": 6150, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3368.17, \"learn_time_ms\": 26818.737}", "{\"n\": 6151, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.25, \"learn_time_ms\": 26829.93}", "{\"n\": 6152, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.99, \"learn_time_ms\": 26852.908}", "{\"n\": 6153, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.56, \"learn_time_ms\": 26851.699}", "{\"n\": 6154, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.94, \"learn_time_ms\": 26854.159}", "{\"n\": 6155, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.94, \"learn_time_ms\": 26851.108}", "{\"n\": 6156, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.22, \"learn_time_ms\": 26881.758}", "{\"n\": 6157, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3341.98, \"learn_time_ms\": 26875.223}", "{\"n\": 6158, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.83, \"learn_time_ms\": 26869.992}", "{\"n\": 6159, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3345.72, \"learn_time_ms\": 26889.529}", "{\"n\": 6160, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.08, \"learn_time_ms\": 26899.617}", "{\"n\": 6161, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3329.91, \"learn_time_ms\": 26890.015}", "{\"n\": 6162, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3329.91, \"learn_time_ms\": 26851.938}", "{\"n\": 6163, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.74, \"learn_time_ms\": 26836.301}", "{\"n\": 6164, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.32, \"learn_time_ms\": 26836.726}", "{\"n\": 6165, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.98, \"learn_time_ms\": 26860.192}", "{\"n\": 6166, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.35, \"learn_time_ms\": 26876.754}", "{\"n\": 6167, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3322.21, \"learn_time_ms\": 26865.701}", "{\"n\": 6168, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3322.21, \"learn_time_ms\": 26850.458}", "{\"n\": 6169, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3329.66, \"learn_time_ms\": 26871.026}", "{\"n\": 6170, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3335.5, \"learn_time_ms\": 26860.0}", "{\"n\": 6171, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.78, \"learn_time_ms\": 26863.816}", "{\"n\": 6172, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.53, \"learn_time_ms\": 26913.84}", "{\"n\": 6173, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.62, \"learn_time_ms\": 26950.852}", "{\"n\": 6174, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.91, \"learn_time_ms\": 26958.706}", "{\"n\": 6175, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.13, \"learn_time_ms\": 26958.717}", "{\"n\": 6176, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.81, \"learn_time_ms\": 26913.889}", "{\"n\": 6177, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.81, \"learn_time_ms\": 26912.216}", "{\"n\": 6178, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3339.73, \"learn_time_ms\": 26953.978}", "{\"n\": 6179, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.79, \"learn_time_ms\": 26935.094}", "{\"n\": 6180, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3338.07, \"learn_time_ms\": 26949.164}", "{\"n\": 6181, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3341.5, \"learn_time_ms\": 26991.685}", "{\"n\": 6182, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3344.21, \"learn_time_ms\": 26942.988}", "{\"n\": 6183, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.59, \"learn_time_ms\": 26921.471}", "{\"n\": 6184, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.59, \"learn_time_ms\": 26971.184}", "{\"n\": 6185, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.7, \"learn_time_ms\": 26988.722}", "{\"n\": 6186, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.24, \"learn_time_ms\": 27030.971}", "{\"n\": 6187, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.02, \"learn_time_ms\": 27010.584}", "{\"n\": 6188, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.65, \"learn_time_ms\": 26958.643}", "{\"n\": 6189, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.65, \"learn_time_ms\": 26950.854}", "{\"n\": 6190, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.65, \"learn_time_ms\": 26922.136}", "{\"n\": 6191, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.51, \"learn_time_ms\": 26874.756}", "{\"n\": 6192, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.96, \"learn_time_ms\": 26889.815}", "{\"n\": 6193, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.83, \"learn_time_ms\": 26881.592}", "{\"n\": 6194, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.84, \"learn_time_ms\": 26851.637}", "{\"n\": 6195, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.08, \"learn_time_ms\": 26831.604}", "{\"n\": 6196, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.21, \"learn_time_ms\": 26781.733}", "{\"n\": 6197, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.98, \"learn_time_ms\": 26822.947}", "{\"n\": 6198, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.68, \"learn_time_ms\": 26818.763}", "{\"n\": 6199, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.39, \"learn_time_ms\": 26852.218}", "{\"n\": 6200, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.39, \"learn_time_ms\": 26851.741}", "{\"n\": 6201, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.38, \"learn_time_ms\": 26846.592}", "{\"n\": 6202, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3345.45, \"learn_time_ms\": 26840.06}", "{\"n\": 6203, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.58, \"learn_time_ms\": 26875.577}", "{\"n\": 6204, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.19, \"learn_time_ms\": 26836.91}", "{\"n\": 6205, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3341.02, \"learn_time_ms\": 26839.625}", "{\"n\": 6206, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.68, \"learn_time_ms\": 26880.133}", "{\"n\": 6207, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.52, \"learn_time_ms\": 26878.112}", "{\"n\": 6208, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.93, \"learn_time_ms\": 26872.915}", "{\"n\": 6209, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.26, \"learn_time_ms\": 26872.779}", "{\"n\": 6210, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.85, \"learn_time_ms\": 26888.558}", "{\"n\": 6211, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.31, \"learn_time_ms\": 26884.618}", "{\"n\": 6212, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.12, \"learn_time_ms\": 26903.748}", "{\"n\": 6213, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.57, \"learn_time_ms\": 26875.096}", "{\"n\": 6214, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.57, \"learn_time_ms\": 26900.149}", "{\"n\": 6215, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.65, \"learn_time_ms\": 26899.623}", "{\"n\": 6216, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.78, \"learn_time_ms\": 26936.366}", "{\"n\": 6217, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.21, \"learn_time_ms\": 26922.064}", "{\"n\": 6218, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.62, \"learn_time_ms\": 26946.224}", "{\"n\": 6219, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.05, \"learn_time_ms\": 26928.121}", "{\"n\": 6220, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.17, \"learn_time_ms\": 26918.29}", "{\"n\": 6221, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.77, \"learn_time_ms\": 26917.882}", "{\"n\": 6222, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.42, \"learn_time_ms\": 26920.335}", "{\"n\": 6223, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.54, \"learn_time_ms\": 26940.233}", "{\"n\": 6224, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.32, \"learn_time_ms\": 26932.376}", "{\"n\": 6225, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.39, \"learn_time_ms\": 26947.519}", "{\"n\": 6226, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.51, \"learn_time_ms\": 26892.176}", "{\"n\": 6227, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.5, \"learn_time_ms\": 26907.427}", "{\"n\": 6228, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.14, \"learn_time_ms\": 26907.302}", "{\"n\": 6229, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.78, \"learn_time_ms\": 26901.597}", "{\"n\": 6230, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.78, \"learn_time_ms\": 26905.294}", "{\"n\": 6231, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.67, \"learn_time_ms\": 26928.948}", "{\"n\": 6232, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.04, \"learn_time_ms\": 26912.749}", "{\"n\": 6233, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.24, \"learn_time_ms\": 26896.466}", "{\"n\": 6234, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.1, \"learn_time_ms\": 26888.99}", "{\"n\": 6235, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.1, \"learn_time_ms\": 26859.883}", "{\"n\": 6236, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.44, \"learn_time_ms\": 26872.293}", "{\"n\": 6237, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.01, \"learn_time_ms\": 26837.992}", "{\"n\": 6238, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.75, \"learn_time_ms\": 26821.48}", "{\"n\": 6239, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.22, \"learn_time_ms\": 26809.163}", "{\"n\": 6240, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.16, \"learn_time_ms\": 26814.275}", "{\"n\": 6241, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.98, \"learn_time_ms\": 26813.227}", "{\"n\": 6242, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.77, \"learn_time_ms\": 26847.897}", "{\"n\": 6243, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.11, \"learn_time_ms\": 26853.489}", "{\"n\": 6244, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.65, \"learn_time_ms\": 26863.125}", "{\"n\": 6245, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.65, \"learn_time_ms\": 26875.805}", "{\"n\": 6246, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.42, \"learn_time_ms\": 26868.017}", "{\"n\": 6247, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.96, \"learn_time_ms\": 26866.974}", "{\"n\": 6248, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.29, \"learn_time_ms\": 26911.076}", "{\"n\": 6249, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.39, \"learn_time_ms\": 26946.419}", "{\"n\": 6250, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.72, \"learn_time_ms\": 26922.405}", "{\"n\": 6251, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.82, \"learn_time_ms\": 26917.235}", "{\"n\": 6252, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.34, \"learn_time_ms\": 26897.924}", "{\"n\": 6253, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.34, \"learn_time_ms\": 26910.17}", "{\"n\": 6254, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.24, \"learn_time_ms\": 26939.383}", "{\"n\": 6255, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.66, \"learn_time_ms\": 26921.331}", "{\"n\": 6256, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.47, \"learn_time_ms\": 26915.268}", "{\"n\": 6257, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.92, \"learn_time_ms\": 26932.179}", "{\"n\": 6258, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3336.45, \"learn_time_ms\": 26896.99}", "{\"n\": 6259, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3336.45, \"learn_time_ms\": 26872.132}", "{\"n\": 6260, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.5, \"learn_time_ms\": 26896.932}", "{\"n\": 6261, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.09, \"learn_time_ms\": 26893.745}", "{\"n\": 6262, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.28, \"learn_time_ms\": 26854.566}", "{\"n\": 6263, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3331.24, \"learn_time_ms\": 26869.414}", "{\"n\": 6264, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3331.24, \"learn_time_ms\": 26846.945}", "{\"n\": 6265, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.97, \"learn_time_ms\": 26859.286}", "{\"n\": 6266, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3335.67, \"learn_time_ms\": 26836.811}", "{\"n\": 6267, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.23, \"learn_time_ms\": 26844.408}", "{\"n\": 6268, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.84, \"learn_time_ms\": 26888.802}", "{\"n\": 6269, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.84, \"learn_time_ms\": 26865.241}", "{\"n\": 6270, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.84, \"learn_time_ms\": 26856.941}", "{\"n\": 6271, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3322.09, \"learn_time_ms\": 26871.05}", "{\"n\": 6272, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3322.02, \"learn_time_ms\": 26898.611}", "{\"n\": 6273, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.34, \"learn_time_ms\": 26846.603}", "{\"n\": 6274, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3331.78, \"learn_time_ms\": 26865.379}", "{\"n\": 6275, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3331.78, \"learn_time_ms\": 26875.764}", "{\"n\": 6276, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.97, \"learn_time_ms\": 26859.667}", "{\"n\": 6277, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3340.87, \"learn_time_ms\": 26873.644}", "{\"n\": 6278, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3336.33, \"learn_time_ms\": 26797.504}", "{\"n\": 6279, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3338.18, \"learn_time_ms\": 26819.279}", "{\"n\": 6280, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3339.61, \"learn_time_ms\": 26830.05}", "{\"n\": 6281, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.27, \"learn_time_ms\": 26827.24}", "{\"n\": 6282, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.06, \"learn_time_ms\": 26841.462}", "{\"n\": 6283, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.06, \"learn_time_ms\": 26907.957}", "{\"n\": 6284, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.1, \"learn_time_ms\": 26891.588}", "{\"n\": 6285, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.3, \"learn_time_ms\": 26905.549}", "{\"n\": 6286, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3338.6, \"learn_time_ms\": 26971.048}", "{\"n\": 6287, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3339.97, \"learn_time_ms\": 26944.442}", "{\"n\": 6288, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.91, \"learn_time_ms\": 27012.494}", "{\"n\": 6289, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3333.11, \"learn_time_ms\": 27010.512}", "{\"n\": 6290, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3341.07, \"learn_time_ms\": 27027.227}", "{\"n\": 6291, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3341.07, \"learn_time_ms\": 27007.095}", "{\"n\": 6292, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3334.28, \"learn_time_ms\": 26991.436}", "{\"n\": 6293, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3331.21, \"learn_time_ms\": 26978.453}", "{\"n\": 6294, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3331.21, \"learn_time_ms\": 26985.169}", "{\"n\": 6295, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3331.86, \"learn_time_ms\": 26980.773}", "{\"n\": 6296, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3319.46, \"learn_time_ms\": 26967.126}", "{\"n\": 6297, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3316.59, \"learn_time_ms\": 26979.567}", "{\"n\": 6298, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3319.23, \"learn_time_ms\": 26921.109}", "{\"n\": 6299, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3312.05, \"learn_time_ms\": 26952.611}", "{\"n\": 6300, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3307.88, \"learn_time_ms\": 26940.632}", "{\"n\": 6301, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3316.27, \"learn_time_ms\": 26975.363}", "{\"n\": 6302, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3314.59, \"learn_time_ms\": 26981.944}", "{\"n\": 6303, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3312.36, \"learn_time_ms\": 26960.05}", "{\"n\": 6304, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3317.75, \"learn_time_ms\": 26956.938}", "{\"n\": 6305, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3317.75, \"learn_time_ms\": 26944.699}", "{\"n\": 6306, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3319.68, \"learn_time_ms\": 26947.215}", "{\"n\": 6307, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3321.29, \"learn_time_ms\": 26968.011}", "{\"n\": 6308, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3320.07, \"learn_time_ms\": 27010.635}", "{\"n\": 6309, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3316.21, \"learn_time_ms\": 27012.749}", "{\"n\": 6310, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3315.69, \"learn_time_ms\": 26973.847}", "{\"n\": 6311, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3322.95, \"learn_time_ms\": 26973.461}", "{\"n\": 6312, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3328.34, \"learn_time_ms\": 26979.874}", "{\"n\": 6313, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3329.26, \"learn_time_ms\": 27009.255}", "{\"n\": 6314, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3329.26, \"learn_time_ms\": 27012.779}", "{\"n\": 6315, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3339.2, \"learn_time_ms\": 27015.25}", "{\"n\": 6316, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3337.66, \"learn_time_ms\": 26994.993}", "{\"n\": 6317, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3344.17, \"learn_time_ms\": 27002.756}", "{\"n\": 6318, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3346.07, \"learn_time_ms\": 27021.938}", "{\"n\": 6319, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3346.07, \"learn_time_ms\": 27012.371}", "{\"n\": 6320, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3351.59, \"learn_time_ms\": 27040.322}", "{\"n\": 6321, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3351.59, \"learn_time_ms\": 27027.848}", "{\"n\": 6322, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3355.02, \"learn_time_ms\": 26980.136}", "{\"n\": 6323, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3353.27, \"learn_time_ms\": 26966.243}", "{\"n\": 6324, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3351.98, \"learn_time_ms\": 26968.296}", "{\"n\": 6325, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3347.48, \"learn_time_ms\": 26966.159}", "{\"n\": 6326, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3347.19, \"learn_time_ms\": 26992.74}", "{\"n\": 6327, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3349.03, \"learn_time_ms\": 27009.718}", "{\"n\": 6328, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3343.83, \"learn_time_ms\": 26976.787}", "{\"n\": 6329, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3341.35, \"learn_time_ms\": 26988.512}", "{\"n\": 6330, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3341.35, \"learn_time_ms\": 26983.265}", "{\"n\": 6331, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3333.07, \"learn_time_ms\": 26989.773}", "{\"n\": 6332, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3333.07, \"learn_time_ms\": 27014.874}", "{\"n\": 6333, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3330.0, \"learn_time_ms\": 26970.991}", "{\"n\": 6334, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3329.7, \"learn_time_ms\": 26974.788}", "{\"n\": 6335, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3329.7, \"learn_time_ms\": 26981.887}", "{\"n\": 6336, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3329.7, \"learn_time_ms\": 26961.812}", "{\"n\": 6337, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3333.52, \"learn_time_ms\": 26890.334}", "{\"n\": 6338, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3335.46, \"learn_time_ms\": 26890.587}", "{\"n\": 6339, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3342.95, \"learn_time_ms\": 26885.833}", "{\"n\": 6340, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3339.75, \"learn_time_ms\": 26904.563}", "{\"n\": 6341, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3342.77, \"learn_time_ms\": 26942.502}", "{\"n\": 6342, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3339.28, \"learn_time_ms\": 26976.057}", "{\"n\": 6343, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3339.28, \"learn_time_ms\": 27040.796}", "{\"n\": 6344, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3340.14, \"learn_time_ms\": 27036.077}", "{\"n\": 6345, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3334.09, \"learn_time_ms\": 27040.615}", "{\"n\": 6346, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3333.58, \"learn_time_ms\": 27059.937}", "{\"n\": 6347, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3331.88, \"learn_time_ms\": 27084.892}", "{\"n\": 6348, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3331.88, \"learn_time_ms\": 27127.686}", "{\"n\": 6349, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3329.66, \"learn_time_ms\": 27105.735}", "{\"n\": 6350, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3332.34, \"learn_time_ms\": 27133.798}", "{\"n\": 6351, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3331.49, \"learn_time_ms\": 27084.059}", "{\"n\": 6352, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3328.66, \"learn_time_ms\": 27090.959}", "{\"n\": 6353, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3326.7, \"learn_time_ms\": 27061.907}", "{\"n\": 6354, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3326.7, \"learn_time_ms\": 27043.003}", "{\"n\": 6355, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3320.22, \"learn_time_ms\": 27011.137}", "{\"n\": 6356, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3331.32, \"learn_time_ms\": 27030.697}", "{\"n\": 6357, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3331.32, \"learn_time_ms\": 27041.759}", "{\"n\": 6358, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.03, \"learn_time_ms\": 27023.823}", "{\"n\": 6359, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.0, \"learn_time_ms\": 27030.161}", "{\"n\": 6360, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.9, \"learn_time_ms\": 26985.342}", "{\"n\": 6361, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.37, \"learn_time_ms\": 27019.756}", "{\"n\": 6362, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.37, \"learn_time_ms\": 27009.842}", "{\"n\": 6363, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.37, \"learn_time_ms\": 26999.539}", "{\"n\": 6364, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.52, \"learn_time_ms\": 26955.724}", "{\"n\": 6365, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.78, \"learn_time_ms\": 26981.688}", "{\"n\": 6366, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.98, \"learn_time_ms\": 26966.095}", "{\"n\": 6367, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.29, \"learn_time_ms\": 27016.265}", "{\"n\": 6368, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.29, \"learn_time_ms\": 26983.59}", "{\"n\": 6369, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.03, \"learn_time_ms\": 26996.446}", "{\"n\": 6370, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.13, \"learn_time_ms\": 26964.336}", "{\"n\": 6371, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.44, \"learn_time_ms\": 26956.581}", "{\"n\": 6372, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.11, \"learn_time_ms\": 26938.194}", "{\"n\": 6373, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.66, \"learn_time_ms\": 26949.057}", "{\"n\": 6374, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.66, \"learn_time_ms\": 27010.955}", "{\"n\": 6375, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.8, \"learn_time_ms\": 26989.683}", "{\"n\": 6376, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.41, \"learn_time_ms\": 26967.288}", "{\"n\": 6377, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.5, \"learn_time_ms\": 26898.366}", "{\"n\": 6378, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.5, \"learn_time_ms\": 26949.471}", "{\"n\": 6379, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.74, \"learn_time_ms\": 26940.81}", "{\"n\": 6380, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.74, \"learn_time_ms\": 26944.542}", "{\"n\": 6381, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.8, \"learn_time_ms\": 26972.755}", "{\"n\": 6382, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.24, \"learn_time_ms\": 26973.425}", "{\"n\": 6383, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.71, \"learn_time_ms\": 26996.228}", "{\"n\": 6384, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.12, \"learn_time_ms\": 26987.078}", "{\"n\": 6385, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.63, \"learn_time_ms\": 26986.724}", "{\"n\": 6386, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.63, \"learn_time_ms\": 27002.581}", "{\"n\": 6387, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.98, \"learn_time_ms\": 27001.052}", "{\"n\": 6388, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.76, \"learn_time_ms\": 26980.417}", "{\"n\": 6389, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.76, \"learn_time_ms\": 26986.667}", "{\"n\": 6390, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.8, \"learn_time_ms\": 27019.111}", "{\"n\": 6391, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.0, \"learn_time_ms\": 26969.752}", "{\"n\": 6392, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.0, \"learn_time_ms\": 26932.678}", "{\"n\": 6393, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.65, \"learn_time_ms\": 26926.47}", "{\"n\": 6394, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.87, \"learn_time_ms\": 26946.802}", "{\"n\": 6395, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.87, \"learn_time_ms\": 26932.381}", "{\"n\": 6396, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.26, \"learn_time_ms\": 26953.368}", "{\"n\": 6397, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.26, \"learn_time_ms\": 26965.833}", "{\"n\": 6398, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.89, \"learn_time_ms\": 26925.431}", "{\"n\": 6399, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.62, \"learn_time_ms\": 26894.74}", "{\"n\": 6400, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.62, \"learn_time_ms\": 26849.744}", "{\"n\": 6401, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.02, \"learn_time_ms\": 26830.415}", "{\"n\": 6402, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.12, \"learn_time_ms\": 26854.424}", "{\"n\": 6403, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.5, \"learn_time_ms\": 26853.157}", "{\"n\": 6404, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.96, \"learn_time_ms\": 26852.439}", "{\"n\": 6405, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.35, \"learn_time_ms\": 26882.487}", "{\"n\": 6406, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.17, \"learn_time_ms\": 26840.841}", "{\"n\": 6407, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.97, \"learn_time_ms\": 26834.844}", "{\"n\": 6408, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.97, \"learn_time_ms\": 26869.123}", "{\"n\": 6409, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.78, \"learn_time_ms\": 26888.93}", "{\"n\": 6410, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.82, \"learn_time_ms\": 26949.297}", "{\"n\": 6411, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.58, \"learn_time_ms\": 26932.544}", "{\"n\": 6412, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.87, \"learn_time_ms\": 26950.726}", "{\"n\": 6413, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.58, \"learn_time_ms\": 26936.129}", "{\"n\": 6414, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.65, \"learn_time_ms\": 26932.431}", "{\"n\": 6415, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.57, \"learn_time_ms\": 26924.383}", "{\"n\": 6416, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.57, \"learn_time_ms\": 26962.512}", "{\"n\": 6417, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.42, \"learn_time_ms\": 26968.114}", "{\"n\": 6418, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.5, \"learn_time_ms\": 26973.487}", "{\"n\": 6419, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.84, \"learn_time_ms\": 27037.926}", "{\"n\": 6420, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.43, \"learn_time_ms\": 27030.406}", "{\"n\": 6421, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.38, \"learn_time_ms\": 27047.546}", "{\"n\": 6422, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.91, \"learn_time_ms\": 27074.373}", "{\"n\": 6423, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.43, \"learn_time_ms\": 27082.866}", "{\"n\": 6424, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.68, \"learn_time_ms\": 27084.273}", "{\"n\": 6425, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.87, \"learn_time_ms\": 27067.545}", "{\"n\": 6426, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.98, \"learn_time_ms\": 27038.757}", "{\"n\": 6427, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.97, \"learn_time_ms\": 27060.903}", "{\"n\": 6428, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.16, \"learn_time_ms\": 27027.744}", "{\"n\": 6429, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.3, \"learn_time_ms\": 26966.266}", "{\"n\": 6430, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.08, \"learn_time_ms\": 26937.018}", "{\"n\": 6431, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.27, \"learn_time_ms\": 26946.733}", "{\"n\": 6432, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.85, \"learn_time_ms\": 26927.359}", "{\"n\": 6433, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.64, \"learn_time_ms\": 26948.994}", "{\"n\": 6434, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.59, \"learn_time_ms\": 26969.175}", "{\"n\": 6435, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.63, \"learn_time_ms\": 26982.374}", "{\"n\": 6436, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.59, \"learn_time_ms\": 27006.64}", "{\"n\": 6437, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.07, \"learn_time_ms\": 27029.301}", "{\"n\": 6438, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.03, \"learn_time_ms\": 27049.921}", "{\"n\": 6439, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.15, \"learn_time_ms\": 27047.692}", "{\"n\": 6440, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.15, \"learn_time_ms\": 27073.312}", "{\"n\": 6441, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.29, \"learn_time_ms\": 27078.94}", "{\"n\": 6442, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.12, \"learn_time_ms\": 27111.639}", "{\"n\": 6443, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.45, \"learn_time_ms\": 27086.205}", "{\"n\": 6444, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.85, \"learn_time_ms\": 27031.076}", "{\"n\": 6445, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.8, \"learn_time_ms\": 27047.266}", "{\"n\": 6446, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.13, \"learn_time_ms\": 27024.588}", "{\"n\": 6447, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.6, \"learn_time_ms\": 26972.066}", "{\"n\": 6448, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.06, \"learn_time_ms\": 26968.934}", "{\"n\": 6449, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.46, \"learn_time_ms\": 26986.299}", "{\"n\": 6450, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.96, \"learn_time_ms\": 27000.064}", "{\"n\": 6451, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.21, \"learn_time_ms\": 26974.219}", "{\"n\": 6452, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.66, \"learn_time_ms\": 26920.726}", "{\"n\": 6453, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.88, \"learn_time_ms\": 26895.769}", "{\"n\": 6454, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.21, \"learn_time_ms\": 26899.289}", "{\"n\": 6455, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.08, \"learn_time_ms\": 26870.949}", "{\"n\": 6456, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.08, \"learn_time_ms\": 26877.08}", "{\"n\": 6457, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.08, \"learn_time_ms\": 26883.299}", "{\"n\": 6458, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.49, \"learn_time_ms\": 26886.524}", "{\"n\": 6459, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.46, \"learn_time_ms\": 26905.539}", "{\"n\": 6460, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.89, \"learn_time_ms\": 26905.873}", "{\"n\": 6461, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.66, \"learn_time_ms\": 26952.992}", "{\"n\": 6462, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.66, \"learn_time_ms\": 26957.371}", "{\"n\": 6463, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.78, \"learn_time_ms\": 26977.704}", "{\"n\": 6464, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.46, \"learn_time_ms\": 26977.225}", "{\"n\": 6465, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.24, \"learn_time_ms\": 27011.124}", "{\"n\": 6466, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.88, \"learn_time_ms\": 27027.35}", "{\"n\": 6467, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.88, \"learn_time_ms\": 27041.161}", "{\"n\": 6468, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.88, \"learn_time_ms\": 27042.567}", "{\"n\": 6469, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.31, \"learn_time_ms\": 27020.396}", "{\"n\": 6470, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.44, \"learn_time_ms\": 26991.942}", "{\"n\": 6471, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.49, \"learn_time_ms\": 26931.87}", "{\"n\": 6472, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.4, \"learn_time_ms\": 26922.103}", "{\"n\": 6473, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.4, \"learn_time_ms\": 26952.988}", "{\"n\": 6474, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.94, \"learn_time_ms\": 26970.955}", "{\"n\": 6475, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.89, \"learn_time_ms\": 26965.217}", "{\"n\": 6476, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.6, \"learn_time_ms\": 26981.857}", "{\"n\": 6477, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.68, \"learn_time_ms\": 26960.365}", "{\"n\": 6478, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.4, \"learn_time_ms\": 26953.469}", "{\"n\": 6479, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.4, \"learn_time_ms\": 26961.73}", "{\"n\": 6480, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.3, \"learn_time_ms\": 26974.415}", "{\"n\": 6481, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.79, \"learn_time_ms\": 27016.227}", "{\"n\": 6482, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.69, \"learn_time_ms\": 27025.841}", "{\"n\": 6483, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.85, \"learn_time_ms\": 26992.209}", "{\"n\": 6484, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.85, \"learn_time_ms\": 26950.857}", "{\"n\": 6485, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.85, \"learn_time_ms\": 26953.367}", "{\"n\": 6486, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.47, \"learn_time_ms\": 26910.901}", "{\"n\": 6487, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.84, \"learn_time_ms\": 26923.949}", "{\"n\": 6488, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.43, \"learn_time_ms\": 26951.766}", "{\"n\": 6489, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.1, \"learn_time_ms\": 26968.416}", "{\"n\": 6490, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.1, \"learn_time_ms\": 26931.837}", "{\"n\": 6491, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.27, \"learn_time_ms\": 26903.979}", "{\"n\": 6492, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.3, \"learn_time_ms\": 26892.326}", "{\"n\": 6493, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.48, \"learn_time_ms\": 26895.418}", "{\"n\": 6494, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.72, \"learn_time_ms\": 26941.301}", "{\"n\": 6495, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.31, \"learn_time_ms\": 26951.711}", "{\"n\": 6496, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.66, \"learn_time_ms\": 27002.163}", "{\"n\": 6497, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.9, \"learn_time_ms\": 26989.721}", "{\"n\": 6498, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.43, \"learn_time_ms\": 26976.046}", "{\"n\": 6499, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.63, \"learn_time_ms\": 26919.952}", "{\"n\": 6500, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.48, \"learn_time_ms\": 26945.485}", "{\"n\": 6501, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.48, \"learn_time_ms\": 26985.283}", "{\"n\": 6502, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.31, \"learn_time_ms\": 27015.938}", "{\"n\": 6503, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.86, \"learn_time_ms\": 27009.851}", "{\"n\": 6504, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.89, \"learn_time_ms\": 27031.245}", "{\"n\": 6505, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.92, \"learn_time_ms\": 26993.851}", "{\"n\": 6506, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.33, \"learn_time_ms\": 26963.355}", "{\"n\": 6507, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.33, \"learn_time_ms\": 26963.862}", "{\"n\": 6508, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.66, \"learn_time_ms\": 26931.076}", "{\"n\": 6509, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.13, \"learn_time_ms\": 26986.124}", "{\"n\": 6510, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.92, \"learn_time_ms\": 26968.357}", "{\"n\": 6511, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.77, \"learn_time_ms\": 26967.366}", "{\"n\": 6512, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.81, \"learn_time_ms\": 26962.727}", "{\"n\": 6513, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.81, \"learn_time_ms\": 27010.527}", "{\"n\": 6514, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.29, \"learn_time_ms\": 26982.3}", "{\"n\": 6515, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.81, \"learn_time_ms\": 26995.294}", "{\"n\": 6516, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.81, \"learn_time_ms\": 26987.703}", "{\"n\": 6517, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.3, \"learn_time_ms\": 27001.934}", "{\"n\": 6518, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.3, \"learn_time_ms\": 27038.912}", "{\"n\": 6519, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.05, \"learn_time_ms\": 27018.065}", "{\"n\": 6520, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.17, \"learn_time_ms\": 27038.59}", "{\"n\": 6521, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.17, \"learn_time_ms\": 27008.503}", "{\"n\": 6522, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.48, \"learn_time_ms\": 27011.84}", "{\"n\": 6523, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.77, \"learn_time_ms\": 26995.227}", "{\"n\": 6524, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.08, \"learn_time_ms\": 27035.942}", "{\"n\": 6525, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.5, \"learn_time_ms\": 27012.53}", "{\"n\": 6526, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.5, \"learn_time_ms\": 26992.316}", "{\"n\": 6527, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.37, \"learn_time_ms\": 26987.354}", "{\"n\": 6528, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.37, \"learn_time_ms\": 26973.621}", "{\"n\": 6529, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.26, \"learn_time_ms\": 26934.756}", "{\"n\": 6530, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.57, \"learn_time_ms\": 26936.414}", "{\"n\": 6531, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.31, \"learn_time_ms\": 27004.281}", "{\"n\": 6532, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.94, \"learn_time_ms\": 27028.008}", "{\"n\": 6533, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.64, \"learn_time_ms\": 26998.193}", "{\"n\": 6534, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.97, \"learn_time_ms\": 26962.214}", "{\"n\": 6535, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.55, \"learn_time_ms\": 26976.25}", "{\"n\": 6536, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.26, \"learn_time_ms\": 27006.925}", "{\"n\": 6537, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.26, \"learn_time_ms\": 26991.06}", "{\"n\": 6538, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.67, \"learn_time_ms\": 26982.478}", "{\"n\": 6539, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.47, \"learn_time_ms\": 27014.447}", "{\"n\": 6540, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.06, \"learn_time_ms\": 27028.212}", "{\"n\": 6541, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.45, \"learn_time_ms\": 26962.941}", "{\"n\": 6542, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.48, \"learn_time_ms\": 26909.515}", "{\"n\": 6543, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.73, \"learn_time_ms\": 26938.689}", "{\"n\": 6544, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.18, \"learn_time_ms\": 26964.215}", "{\"n\": 6545, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.63, \"learn_time_ms\": 26983.909}", "{\"n\": 6546, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.03, \"learn_time_ms\": 26968.77}", "{\"n\": 6547, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.0, \"learn_time_ms\": 27003.095}", "{\"n\": 6548, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.0, \"learn_time_ms\": 27028.579}", "{\"n\": 6549, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.88, \"learn_time_ms\": 27035.284}", "{\"n\": 6550, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.67, \"learn_time_ms\": 27022.375}", "{\"n\": 6551, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.93, \"learn_time_ms\": 27055.769}", "{\"n\": 6552, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.33, \"learn_time_ms\": 27082.362}", "{\"n\": 6553, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.72, \"learn_time_ms\": 27033.677}", "{\"n\": 6554, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.95, \"learn_time_ms\": 26994.604}", "{\"n\": 6555, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.59, \"learn_time_ms\": 26990.114}", "{\"n\": 6556, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.67, \"learn_time_ms\": 26974.493}", "{\"n\": 6557, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.86, \"learn_time_ms\": 26977.369}", "{\"n\": 6558, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.86, \"learn_time_ms\": 26982.168}", "{\"n\": 6559, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.93, \"learn_time_ms\": 26947.647}", "{\"n\": 6560, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.61, \"learn_time_ms\": 26961.669}", "{\"n\": 6561, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.15, \"learn_time_ms\": 26921.127}", "{\"n\": 6562, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.03, \"learn_time_ms\": 26915.226}", "{\"n\": 6563, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.37, \"learn_time_ms\": 26926.078}", "{\"n\": 6564, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.37, \"learn_time_ms\": 26903.394}", "{\"n\": 6565, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.45, \"learn_time_ms\": 26876.507}", "{\"n\": 6566, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.45, \"learn_time_ms\": 26876.428}", "{\"n\": 6567, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.01, \"learn_time_ms\": 26878.874}", "{\"n\": 6568, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.86, \"learn_time_ms\": 26876.929}", "{\"n\": 6569, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.86, \"learn_time_ms\": 26925.599}", "{\"n\": 6570, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.04, \"learn_time_ms\": 26932.566}", "{\"n\": 6571, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.19, \"learn_time_ms\": 26941.777}", "{\"n\": 6572, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.38, \"learn_time_ms\": 26951.64}", "{\"n\": 6573, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.42, \"learn_time_ms\": 26974.957}", "{\"n\": 6574, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.42, \"learn_time_ms\": 26977.021}", "{\"n\": 6575, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.17, \"learn_time_ms\": 27012.134}", "{\"n\": 6576, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.87, \"learn_time_ms\": 27055.63}", "{\"n\": 6577, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.41, \"learn_time_ms\": 27028.052}", "{\"n\": 6578, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.29, \"learn_time_ms\": 27005.017}", "{\"n\": 6579, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.48, \"learn_time_ms\": 26979.276}", "{\"n\": 6580, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.83, \"learn_time_ms\": 26944.882}", "{\"n\": 6581, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.83, \"learn_time_ms\": 26967.83}", "{\"n\": 6582, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.45, \"learn_time_ms\": 26947.26}", "{\"n\": 6583, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.43, \"learn_time_ms\": 26958.524}", "{\"n\": 6584, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.05, \"learn_time_ms\": 27011.629}", "{\"n\": 6585, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.3, \"learn_time_ms\": 26976.325}", "{\"n\": 6586, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.3, \"learn_time_ms\": 26937.864}", "{\"n\": 6587, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.14, \"learn_time_ms\": 26917.417}", "{\"n\": 6588, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.77, \"learn_time_ms\": 26924.281}", "{\"n\": 6589, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.77, \"learn_time_ms\": 26862.858}", "{\"n\": 6590, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.4, \"learn_time_ms\": 26906.998}", "{\"n\": 6591, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.13, \"learn_time_ms\": 26899.291}", "{\"n\": 6592, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.43, \"learn_time_ms\": 26934.88}", "{\"n\": 6593, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.15, \"learn_time_ms\": 26898.079}", "{\"n\": 6594, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.89, \"learn_time_ms\": 26868.149}", "{\"n\": 6595, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.2, \"learn_time_ms\": 26890.0}", "{\"n\": 6596, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.79, \"learn_time_ms\": 26901.087}", "{\"n\": 6597, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.29, \"learn_time_ms\": 26909.069}", "{\"n\": 6598, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.04, \"learn_time_ms\": 26922.044}", "{\"n\": 6599, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.7, \"learn_time_ms\": 26989.086}", "{\"n\": 6600, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.81, \"learn_time_ms\": 26966.283}", "{\"n\": 6601, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.79, \"learn_time_ms\": 27003.368}", "{\"n\": 6602, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.47, \"learn_time_ms\": 26967.668}", "{\"n\": 6603, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.53, \"learn_time_ms\": 27032.926}", "{\"n\": 6604, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.53, \"learn_time_ms\": 27072.071}", "{\"n\": 6605, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.21, \"learn_time_ms\": 27139.084}", "{\"n\": 6606, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.21, \"learn_time_ms\": 27129.884}", "{\"n\": 6607, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.65, \"learn_time_ms\": 27141.342}", "{\"n\": 6608, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.05, \"learn_time_ms\": 27134.124}", "{\"n\": 6609, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.14, \"learn_time_ms\": 27135.011}", "{\"n\": 6610, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.56, \"learn_time_ms\": 27150.211}", "{\"n\": 6611, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.83, \"learn_time_ms\": 27095.948}", "{\"n\": 6612, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.83, \"learn_time_ms\": 27102.683}", "{\"n\": 6613, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.24, \"learn_time_ms\": 27076.271}", "{\"n\": 6614, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.26, \"learn_time_ms\": 27073.45}", "{\"n\": 6615, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.26, \"learn_time_ms\": 27046.607}", "{\"n\": 6616, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.8, \"learn_time_ms\": 27041.958}", "{\"n\": 6617, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.25, \"learn_time_ms\": 27062.122}", "{\"n\": 6618, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.58, \"learn_time_ms\": 27056.19}", "{\"n\": 6619, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.28, \"learn_time_ms\": 27043.313}", "{\"n\": 6620, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.0, \"learn_time_ms\": 26986.609}", "{\"n\": 6621, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.0, \"learn_time_ms\": 26998.273}", "{\"n\": 6622, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.6, \"learn_time_ms\": 27011.073}", "{\"n\": 6623, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.6, \"learn_time_ms\": 26998.24}", "{\"n\": 6624, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.3, \"learn_time_ms\": 26956.395}", "{\"n\": 6625, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.18, \"learn_time_ms\": 26931.533}", "{\"n\": 6626, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.08, \"learn_time_ms\": 26982.391}", "{\"n\": 6627, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.08, \"learn_time_ms\": 26981.625}", "{\"n\": 6628, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.99, \"learn_time_ms\": 26989.806}", "{\"n\": 6629, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.95, \"learn_time_ms\": 26979.825}", "{\"n\": 6630, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.29, \"learn_time_ms\": 27006.375}", "{\"n\": 6631, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.61, \"learn_time_ms\": 27014.55}", "{\"n\": 6632, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.65, \"learn_time_ms\": 27029.038}", "{\"n\": 6633, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.14, \"learn_time_ms\": 27046.974}", "{\"n\": 6634, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.14, \"learn_time_ms\": 27044.038}", "{\"n\": 6635, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.38, \"learn_time_ms\": 27062.526}", "{\"n\": 6636, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.07, \"learn_time_ms\": 27039.412}", "{\"n\": 6637, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.1, \"learn_time_ms\": 27045.504}", "{\"n\": 6638, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.07, \"learn_time_ms\": 27046.267}", "{\"n\": 6639, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.07, \"learn_time_ms\": 27085.373}", "{\"n\": 6640, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.07, \"learn_time_ms\": 27112.244}", "{\"n\": 6641, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.01, \"learn_time_ms\": 27138.744}", "{\"n\": 6642, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.09, \"learn_time_ms\": 27119.817}", "{\"n\": 6643, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.69, \"learn_time_ms\": 27098.639}", "{\"n\": 6644, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.71, \"learn_time_ms\": 27124.265}", "{\"n\": 6645, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.71, \"learn_time_ms\": 27088.777}", "{\"n\": 6646, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.71, \"learn_time_ms\": 27087.195}", "{\"n\": 6647, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.05, \"learn_time_ms\": 27047.347}", "{\"n\": 6648, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.79, \"learn_time_ms\": 27015.584}", "{\"n\": 6649, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.92, \"learn_time_ms\": 26986.157}", "{\"n\": 6650, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.08, \"learn_time_ms\": 26983.021}", "{\"n\": 6651, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.08, \"learn_time_ms\": 26972.165}", "{\"n\": 6652, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.96, \"learn_time_ms\": 26958.519}", "{\"n\": 6653, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.5, \"learn_time_ms\": 26992.704}", "{\"n\": 6654, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.96, \"learn_time_ms\": 26993.358}", "{\"n\": 6655, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.27, \"learn_time_ms\": 26975.702}", "{\"n\": 6656, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.18, \"learn_time_ms\": 26933.035}", "{\"n\": 6657, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.2, \"learn_time_ms\": 26942.4}", "{\"n\": 6658, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.25, \"learn_time_ms\": 26960.264}", "{\"n\": 6659, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.25, \"learn_time_ms\": 26952.82}", "{\"n\": 6660, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.87, \"learn_time_ms\": 26946.209}", "{\"n\": 6661, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.87, \"learn_time_ms\": 26910.619}", "{\"n\": 6662, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.44, \"learn_time_ms\": 26908.443}", "{\"n\": 6663, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.23, \"learn_time_ms\": 26857.469}", "{\"n\": 6664, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.73, \"learn_time_ms\": 26834.383}", "{\"n\": 6665, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.68, \"learn_time_ms\": 26882.825}", "{\"n\": 6666, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.85, \"learn_time_ms\": 26924.269}", "{\"n\": 6667, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.85, \"learn_time_ms\": 26959.274}", "{\"n\": 6668, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.67, \"learn_time_ms\": 26946.835}", "{\"n\": 6669, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.78, \"learn_time_ms\": 26934.327}", "{\"n\": 6670, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.15, \"learn_time_ms\": 26939.837}", "{\"n\": 6671, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.3, \"learn_time_ms\": 26991.322}", "{\"n\": 6672, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.3, \"learn_time_ms\": 27007.522}", "{\"n\": 6673, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.03, \"learn_time_ms\": 27041.82}", "{\"n\": 6674, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.74, \"learn_time_ms\": 27067.536}", "{\"n\": 6675, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.74, \"learn_time_ms\": 27023.354}", "{\"n\": 6676, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.97, \"learn_time_ms\": 27047.539}", "{\"n\": 6677, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.36, \"learn_time_ms\": 27046.96}", "{\"n\": 6678, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.07, \"learn_time_ms\": 27064.547}", "{\"n\": 6679, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.96, \"learn_time_ms\": 27102.94}", "{\"n\": 6680, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.96, \"learn_time_ms\": 27112.522}", "{\"n\": 6681, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.67, \"learn_time_ms\": 27058.414}", "{\"n\": 6682, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.43, \"learn_time_ms\": 27063.076}", "{\"n\": 6683, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.05, \"learn_time_ms\": 27060.358}", "{\"n\": 6684, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.99, \"learn_time_ms\": 27062.317}", "{\"n\": 6685, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.28, \"learn_time_ms\": 27065.268}", "{\"n\": 6686, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.09, \"learn_time_ms\": 27042.649}", "{\"n\": 6687, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.03, \"learn_time_ms\": 27030.978}", "{\"n\": 6688, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.53, \"learn_time_ms\": 27027.972}", "{\"n\": 6689, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.91, \"learn_time_ms\": 27031.152}", "{\"n\": 6690, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.9, \"learn_time_ms\": 26984.234}", "{\"n\": 6691, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.77, \"learn_time_ms\": 27001.876}", "{\"n\": 6692, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.27, \"learn_time_ms\": 26971.115}", "{\"n\": 6693, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.0, \"learn_time_ms\": 26966.875}", "{\"n\": 6694, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.5, \"learn_time_ms\": 26946.641}", "{\"n\": 6695, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.91, \"learn_time_ms\": 26931.868}", "{\"n\": 6696, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.27, \"learn_time_ms\": 26932.454}", "{\"n\": 6697, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.39, \"learn_time_ms\": 26918.827}", "{\"n\": 6698, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.88, \"learn_time_ms\": 26942.724}", "{\"n\": 6699, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.72, \"learn_time_ms\": 26944.542}", "{\"n\": 6700, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.27, \"learn_time_ms\": 26930.322}", "{\"n\": 6701, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.55, \"learn_time_ms\": 26937.938}", "{\"n\": 6702, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.44, \"learn_time_ms\": 26942.681}", "{\"n\": 6703, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.46, \"learn_time_ms\": 26898.287}", "{\"n\": 6704, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.86, \"learn_time_ms\": 26914.203}", "{\"n\": 6705, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.41, \"learn_time_ms\": 26972.09}", "{\"n\": 6706, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.5, \"learn_time_ms\": 26984.831}", "{\"n\": 6707, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.5, \"learn_time_ms\": 26974.641}", "{\"n\": 6708, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.64, \"learn_time_ms\": 26965.395}", "{\"n\": 6709, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.25, \"learn_time_ms\": 26956.762}", "{\"n\": 6710, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.72, \"learn_time_ms\": 26985.464}", "{\"n\": 6711, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.73, \"learn_time_ms\": 26958.37}", "{\"n\": 6712, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.68, \"learn_time_ms\": 27010.625}", "{\"n\": 6713, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.68, \"learn_time_ms\": 27046.104}", "{\"n\": 6714, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.96, \"learn_time_ms\": 27056.137}", "{\"n\": 6715, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.16, \"learn_time_ms\": 27083.473}", "{\"n\": 6716, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.87, \"learn_time_ms\": 27055.536}", "{\"n\": 6717, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.08, \"learn_time_ms\": 27057.383}", "{\"n\": 6718, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.08, \"learn_time_ms\": 27091.488}", "{\"n\": 6719, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.64, \"learn_time_ms\": 27115.617}", "{\"n\": 6720, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.12, \"learn_time_ms\": 27137.197}", "{\"n\": 6721, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.88, \"learn_time_ms\": 27168.177}", "{\"n\": 6722, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.14, \"learn_time_ms\": 27125.02}", "{\"n\": 6723, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.14, \"learn_time_ms\": 27133.319}", "{\"n\": 6724, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.53, \"learn_time_ms\": 27102.502}", "{\"n\": 6725, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.44, \"learn_time_ms\": 27066.573}", "{\"n\": 6726, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.23, \"learn_time_ms\": 27094.374}", "{\"n\": 6727, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.88, \"learn_time_ms\": 27124.063}", "{\"n\": 6728, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.73, \"learn_time_ms\": 27106.625}", "{\"n\": 6729, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.81, \"learn_time_ms\": 27090.203}", "{\"n\": 6730, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.38, \"learn_time_ms\": 27059.411}", "{\"n\": 6731, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.54, \"learn_time_ms\": 27034.927}", "{\"n\": 6732, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.91, \"learn_time_ms\": 27037.166}", "{\"n\": 6733, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.98, \"learn_time_ms\": 27031.072}", "{\"n\": 6734, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.67, \"learn_time_ms\": 27004.346}", "{\"n\": 6735, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.62, \"learn_time_ms\": 26953.935}", "{\"n\": 6736, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.14, \"learn_time_ms\": 26962.091}", "{\"n\": 6737, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.85, \"learn_time_ms\": 26946.627}", "{\"n\": 6738, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.51, \"learn_time_ms\": 26905.716}", "{\"n\": 6739, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.23, \"learn_time_ms\": 26848.351}", "{\"n\": 6740, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.23, \"learn_time_ms\": 26848.327}", "{\"n\": 6741, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.23, \"learn_time_ms\": 26846.517}", "{\"n\": 6742, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.12, \"learn_time_ms\": 26862.344}", "{\"n\": 6743, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.84, \"learn_time_ms\": 26849.408}", "{\"n\": 6744, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.04, \"learn_time_ms\": 26859.855}", "{\"n\": 6745, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.59, \"learn_time_ms\": 26903.372}", "{\"n\": 6746, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.6, \"learn_time_ms\": 26870.11}", "{\"n\": 6747, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.6, \"learn_time_ms\": 26867.471}", "{\"n\": 6748, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.22, \"learn_time_ms\": 26889.145}", "{\"n\": 6749, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.69, \"learn_time_ms\": 26927.238}", "{\"n\": 6750, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.69, \"learn_time_ms\": 26977.523}", "{\"n\": 6751, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.52, \"learn_time_ms\": 27013.58}", "{\"n\": 6752, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.44, \"learn_time_ms\": 27007.484}", "{\"n\": 6753, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.44, \"learn_time_ms\": 27033.825}", "{\"n\": 6754, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.23, \"learn_time_ms\": 27075.112}", "{\"n\": 6755, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.41, \"learn_time_ms\": 27080.242}", "{\"n\": 6756, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.84, \"learn_time_ms\": 27098.602}", "{\"n\": 6757, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.84, \"learn_time_ms\": 27061.187}", "{\"n\": 6758, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.41, \"learn_time_ms\": 27011.999}", "{\"n\": 6759, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.36, \"learn_time_ms\": 27028.396}", "{\"n\": 6760, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.61, \"learn_time_ms\": 26997.208}", "{\"n\": 6761, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.53, \"learn_time_ms\": 26970.657}", "{\"n\": 6762, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.94, \"learn_time_ms\": 26979.623}", "{\"n\": 6763, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.97, \"learn_time_ms\": 26967.255}", "{\"n\": 6764, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.35, \"learn_time_ms\": 26946.994}", "{\"n\": 6765, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.26, \"learn_time_ms\": 26955.272}", "{\"n\": 6766, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.78, \"learn_time_ms\": 26924.491}", "{\"n\": 6767, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.17, \"learn_time_ms\": 26969.782}", "{\"n\": 6768, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.54, \"learn_time_ms\": 27007.293}", "{\"n\": 6769, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.54, \"learn_time_ms\": 26999.247}", "{\"n\": 6770, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.17, \"learn_time_ms\": 27024.456}", "{\"n\": 6771, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.89, \"learn_time_ms\": 27037.99}", "{\"n\": 6772, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.69, \"learn_time_ms\": 27031.976}", "{\"n\": 6773, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.28, \"learn_time_ms\": 27021.786}", "{\"n\": 6774, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.82, \"learn_time_ms\": 27020.7}", "{\"n\": 6775, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.82, \"learn_time_ms\": 27001.53}", "{\"n\": 6776, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3380.32, \"learn_time_ms\": 27041.382}", "{\"n\": 6777, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3382.38, \"learn_time_ms\": 26997.548}", "{\"n\": 6778, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.53, \"learn_time_ms\": 27030.782}", "{\"n\": 6779, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3383.83, \"learn_time_ms\": 27040.685}", "{\"n\": 6780, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.62, \"learn_time_ms\": 26973.205}", "{\"n\": 6781, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.62, \"learn_time_ms\": 26990.511}", "{\"n\": 6782, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.52, \"learn_time_ms\": 26969.104}", "{\"n\": 6783, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.51, \"learn_time_ms\": 26935.535}", "{\"n\": 6784, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.61, \"learn_time_ms\": 26968.138}", "{\"n\": 6785, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3394.26, \"learn_time_ms\": 26957.616}", "{\"n\": 6786, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3394.26, \"learn_time_ms\": 26897.158}", "{\"n\": 6787, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3394.26, \"learn_time_ms\": 26917.87}", "{\"n\": 6788, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3407.26, \"learn_time_ms\": 26878.164}", "{\"n\": 6789, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3398.68, \"learn_time_ms\": 26859.918}", "{\"n\": 6790, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3396.72, \"learn_time_ms\": 26893.234}", "{\"n\": 6791, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3391.74, \"learn_time_ms\": 26885.73}", "{\"n\": 6792, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3391.74, \"learn_time_ms\": 26873.183}", "{\"n\": 6793, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3385.89, \"learn_time_ms\": 26899.978}", "{\"n\": 6794, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3382.58, \"learn_time_ms\": 26855.137}", "{\"n\": 6795, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3383.56, \"learn_time_ms\": 26857.437}", "{\"n\": 6796, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3383.56, \"learn_time_ms\": 26943.081}", "{\"n\": 6797, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3391.09, \"learn_time_ms\": 26983.05}", "{\"n\": 6798, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3390.14, \"learn_time_ms\": 26982.798}", "{\"n\": 6799, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3383.63, \"learn_time_ms\": 27000.711}", "{\"n\": 6800, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3382.46, \"learn_time_ms\": 27022.943}", "{\"n\": 6801, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3378.03, \"learn_time_ms\": 27007.93}", "{\"n\": 6802, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3378.35, \"learn_time_ms\": 27053.718}", "{\"n\": 6803, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3378.35, \"learn_time_ms\": 27046.398}", "{\"n\": 6804, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3373.58, \"learn_time_ms\": 27076.118}", "{\"n\": 6805, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3376.64, \"learn_time_ms\": 27049.912}", "{\"n\": 6806, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3382.51, \"learn_time_ms\": 26953.477}", "{\"n\": 6807, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3379.92, \"learn_time_ms\": 26926.261}", "{\"n\": 6808, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3379.92, \"learn_time_ms\": 26929.925}", "{\"n\": 6809, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3375.44, \"learn_time_ms\": 26932.122}", "{\"n\": 6810, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3377.47, \"learn_time_ms\": 26924.34}", "{\"n\": 6811, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3378.82, \"learn_time_ms\": 26912.737}", "{\"n\": 6812, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3381.39, \"learn_time_ms\": 26894.307}", "{\"n\": 6813, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3379.01, \"learn_time_ms\": 26876.249}", "{\"n\": 6814, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3379.01, \"learn_time_ms\": 26885.397}", "{\"n\": 6815, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3378.32, \"learn_time_ms\": 26929.737}", "{\"n\": 6816, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3381.71, \"learn_time_ms\": 27004.693}", "{\"n\": 6817, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3385.22, \"learn_time_ms\": 27025.946}", "{\"n\": 6818, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3387.04, \"learn_time_ms\": 27038.216}", "{\"n\": 6819, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3387.04, \"learn_time_ms\": 27036.861}", "{\"n\": 6820, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3387.04, \"learn_time_ms\": 27074.392}", "{\"n\": 6821, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3383.68, \"learn_time_ms\": 27083.455}", "{\"n\": 6822, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3382.43, \"learn_time_ms\": 27075.318}", "{\"n\": 6823, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3374.83, \"learn_time_ms\": 27141.198}", "{\"n\": 6824, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3374.83, \"learn_time_ms\": 27133.486}", "{\"n\": 6825, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3374.83, \"learn_time_ms\": 27108.258}", "{\"n\": 6826, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3374.83, \"learn_time_ms\": 27093.974}", "{\"n\": 6827, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3381.32, \"learn_time_ms\": 27084.166}", "{\"n\": 6828, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3380.3, \"learn_time_ms\": 27134.406}", "{\"n\": 6829, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3383.92, \"learn_time_ms\": 27145.017}", "{\"n\": 6830, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3383.92, \"learn_time_ms\": 27113.113}", "{\"n\": 6831, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3383.92, \"learn_time_ms\": 27104.548}", "{\"n\": 6832, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3382.95, \"learn_time_ms\": 27118.791}", "{\"n\": 6833, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3386.56, \"learn_time_ms\": 27109.304}", "{\"n\": 6834, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3391.61, \"learn_time_ms\": 27113.9}", "{\"n\": 6835, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3391.91, \"learn_time_ms\": 27140.51}", "{\"n\": 6836, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3395.73, \"learn_time_ms\": 27102.26}", "{\"n\": 6837, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3395.73, \"learn_time_ms\": 27104.975}", "{\"n\": 6838, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3395.57, \"learn_time_ms\": 27042.196}", "{\"n\": 6839, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3406.33, \"learn_time_ms\": 27002.222}", "{\"n\": 6840, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3413.79, \"learn_time_ms\": 27001.467}", "{\"n\": 6841, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3413.79, \"learn_time_ms\": 27024.224}", "{\"n\": 6842, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3418.48, \"learn_time_ms\": 26995.535}", "{\"n\": 6843, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3417.91, \"learn_time_ms\": 26981.104}", "{\"n\": 6844, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3411.03, \"learn_time_ms\": 26970.723}", "{\"n\": 6845, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3407.94, \"learn_time_ms\": 26961.789}", "{\"n\": 6846, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3400.29, \"learn_time_ms\": 26977.464}", "{\"n\": 6847, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3403.81, \"learn_time_ms\": 26986.585}", "{\"n\": 6848, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3400.31, \"learn_time_ms\": 27018.073}", "{\"n\": 6849, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3399.09, \"learn_time_ms\": 27023.97}", "{\"n\": 6850, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3401.57, \"learn_time_ms\": 26994.587}", "{\"n\": 6851, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3410.79, \"learn_time_ms\": 26973.848}", "{\"n\": 6852, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3416.01, \"learn_time_ms\": 26971.54}", "{\"n\": 6853, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3409.8, \"learn_time_ms\": 26976.994}", "{\"n\": 6854, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3403.87, \"learn_time_ms\": 26983.73}", "{\"n\": 6855, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3405.9, \"learn_time_ms\": 26996.31}", "{\"n\": 6856, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.51, \"learn_time_ms\": 27015.965}", "{\"n\": 6857, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.08, \"learn_time_ms\": 26976.522}", "{\"n\": 6858, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.76, \"learn_time_ms\": 26943.432}", "{\"n\": 6859, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.85, \"learn_time_ms\": 26932.64}", "{\"n\": 6860, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.89, \"learn_time_ms\": 26971.896}", "{\"n\": 6861, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.89, \"learn_time_ms\": 26979.954}", "{\"n\": 6862, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.74, \"learn_time_ms\": 27019.668}", "{\"n\": 6863, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.01, \"learn_time_ms\": 26973.033}", "{\"n\": 6864, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.32, \"learn_time_ms\": 26946.52}", "{\"n\": 6865, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.72, \"learn_time_ms\": 26941.791}", "{\"n\": 6866, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.52, \"learn_time_ms\": 26935.363}", "{\"n\": 6867, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.71, \"learn_time_ms\": 26929.061}", "{\"n\": 6868, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.63, \"learn_time_ms\": 26952.262}", "{\"n\": 6869, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.96, \"learn_time_ms\": 26974.851}", "{\"n\": 6870, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.05, \"learn_time_ms\": 26947.409}", "{\"n\": 6871, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.05, \"learn_time_ms\": 26958.529}", "{\"n\": 6872, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.48, \"learn_time_ms\": 26954.226}", "{\"n\": 6873, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.65, \"learn_time_ms\": 26992.645}", "{\"n\": 6874, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.09, \"learn_time_ms\": 27044.308}", "{\"n\": 6875, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.07, \"learn_time_ms\": 27043.523}", "{\"n\": 6876, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.07, \"learn_time_ms\": 27023.017}", "{\"n\": 6877, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.46, \"learn_time_ms\": 27051.288}", "{\"n\": 6878, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.5, \"learn_time_ms\": 27023.807}", "{\"n\": 6879, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.31, \"learn_time_ms\": 27023.269}", "{\"n\": 6880, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.82, \"learn_time_ms\": 27043.71}", "{\"n\": 6881, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.97, \"learn_time_ms\": 27022.989}", "{\"n\": 6882, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.97, \"learn_time_ms\": 27008.888}", "{\"n\": 6883, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.32, \"learn_time_ms\": 27032.854}", "{\"n\": 6884, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.4, \"learn_time_ms\": 27009.432}", "{\"n\": 6885, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.72, \"learn_time_ms\": 26986.732}", "{\"n\": 6886, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.45, \"learn_time_ms\": 26965.767}", "{\"n\": 6887, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.91, \"learn_time_ms\": 26980.161}", "{\"n\": 6888, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.91, \"learn_time_ms\": 26970.606}", "{\"n\": 6889, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.02, \"learn_time_ms\": 26957.25}", "{\"n\": 6890, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.05, \"learn_time_ms\": 26962.114}", "{\"n\": 6891, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.05, \"learn_time_ms\": 26986.351}", "{\"n\": 6892, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.17, \"learn_time_ms\": 26968.756}", "{\"n\": 6893, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.2, \"learn_time_ms\": 26920.515}", "{\"n\": 6894, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.22, \"learn_time_ms\": 26905.063}", "{\"n\": 6895, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.54, \"learn_time_ms\": 26916.739}", "{\"n\": 6896, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.54, \"learn_time_ms\": 26946.072}", "{\"n\": 6897, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.19, \"learn_time_ms\": 26909.586}", "{\"n\": 6898, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.88, \"learn_time_ms\": 26914.216}", "{\"n\": 6899, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.81, \"learn_time_ms\": 26906.518}", "{\"n\": 6900, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.81, \"learn_time_ms\": 26889.478}", "{\"n\": 6901, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.9, \"learn_time_ms\": 26863.932}", "{\"n\": 6902, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.9, \"learn_time_ms\": 26865.43}", "{\"n\": 6903, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.81, \"learn_time_ms\": 26873.71}", "{\"n\": 6904, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.22, \"learn_time_ms\": 26883.246}", "{\"n\": 6905, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.22, \"learn_time_ms\": 26856.494}", "{\"n\": 6906, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.46, \"learn_time_ms\": 26886.062}", "{\"n\": 6907, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.95, \"learn_time_ms\": 26899.373}", "{\"n\": 6908, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.59, \"learn_time_ms\": 26887.262}", "{\"n\": 6909, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.33, \"learn_time_ms\": 26921.044}", "{\"n\": 6910, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.01, \"learn_time_ms\": 26916.074}", "{\"n\": 6911, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.01, \"learn_time_ms\": 26907.054}", "{\"n\": 6912, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.79, \"learn_time_ms\": 26931.768}", "{\"n\": 6913, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.26, \"learn_time_ms\": 26932.04}", "{\"n\": 6914, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.23, \"learn_time_ms\": 26930.104}", "{\"n\": 6915, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.42, \"learn_time_ms\": 26953.84}", "{\"n\": 6916, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.42, \"learn_time_ms\": 26925.231}", "{\"n\": 6917, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.42, \"learn_time_ms\": 26942.526}", "{\"n\": 6918, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.47, \"learn_time_ms\": 26970.884}", "{\"n\": 6919, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.81, \"learn_time_ms\": 26951.276}", "{\"n\": 6920, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.28, \"learn_time_ms\": 26967.976}", "{\"n\": 6921, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.18, \"learn_time_ms\": 26969.072}", "{\"n\": 6922, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.18, \"learn_time_ms\": 26964.61}", "{\"n\": 6923, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.18, \"learn_time_ms\": 26933.689}", "{\"n\": 6924, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.95, \"learn_time_ms\": 26947.904}", "{\"n\": 6925, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.1, \"learn_time_ms\": 26928.562}", "{\"n\": 6926, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.88, \"learn_time_ms\": 26939.872}", "{\"n\": 6927, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.6, \"learn_time_ms\": 26941.363}", "{\"n\": 6928, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.6, \"learn_time_ms\": 26937.319}", "{\"n\": 6929, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.38, \"learn_time_ms\": 26908.339}", "{\"n\": 6930, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.11, \"learn_time_ms\": 26926.895}", "{\"n\": 6931, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.06, \"learn_time_ms\": 26953.274}", "{\"n\": 6932, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.78, \"learn_time_ms\": 26961.789}", "{\"n\": 6933, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.78, \"learn_time_ms\": 27001.53}", "{\"n\": 6934, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.78, \"learn_time_ms\": 26998.822}", "{\"n\": 6935, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.43, \"learn_time_ms\": 27016.613}", "{\"n\": 6936, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.43, \"learn_time_ms\": 27039.143}", "{\"n\": 6937, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.85, \"learn_time_ms\": 27014.966}", "{\"n\": 6938, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.21, \"learn_time_ms\": 27013.672}", "{\"n\": 6939, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.21, \"learn_time_ms\": 27063.755}", "{\"n\": 6940, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.21, \"learn_time_ms\": 27074.723}", "{\"n\": 6941, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.53, \"learn_time_ms\": 27047.741}", "{\"n\": 6942, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.21, \"learn_time_ms\": 27038.719}", "{\"n\": 6943, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.04, \"learn_time_ms\": 27056.722}", "{\"n\": 6944, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.56, \"learn_time_ms\": 27031.931}", "{\"n\": 6945, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.56, \"learn_time_ms\": 27064.087}", "{\"n\": 6946, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.4, \"learn_time_ms\": 27066.736}", "{\"n\": 6947, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.25, \"learn_time_ms\": 27090.645}", "{\"n\": 6948, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.25, \"learn_time_ms\": 27105.925}", "{\"n\": 6949, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.7, \"learn_time_ms\": 27103.693}", "{\"n\": 6950, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.95, \"learn_time_ms\": 27038.489}", "{\"n\": 6951, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.95, \"learn_time_ms\": 27078.323}", "{\"n\": 6952, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.97, \"learn_time_ms\": 27048.579}", "{\"n\": 6953, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.51, \"learn_time_ms\": 27029.709}", "{\"n\": 6954, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.51, \"learn_time_ms\": 27047.529}", "{\"n\": 6955, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.45, \"learn_time_ms\": 27022.882}", "{\"n\": 6956, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.03, \"learn_time_ms\": 26968.728}", "{\"n\": 6957, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.2, \"learn_time_ms\": 26994.283}", "{\"n\": 6958, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.01, \"learn_time_ms\": 27009.458}", "{\"n\": 6959, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.33, \"learn_time_ms\": 26977.79}", "{\"n\": 6960, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.62, \"learn_time_ms\": 26987.688}", "{\"n\": 6961, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.85, \"learn_time_ms\": 26959.298}", "{\"n\": 6962, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.88, \"learn_time_ms\": 26993.483}", "{\"n\": 6963, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.41, \"learn_time_ms\": 27022.29}", "{\"n\": 6964, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.02, \"learn_time_ms\": 26991.258}", "{\"n\": 6965, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3436.03, \"learn_time_ms\": 26989.449}", "{\"n\": 6966, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.54, \"learn_time_ms\": 27036.935}", "{\"n\": 6967, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.87, \"learn_time_ms\": 27006.825}", "{\"n\": 6968, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.28, \"learn_time_ms\": 26999.58}", "{\"n\": 6969, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.37, \"learn_time_ms\": 26992.895}", "{\"n\": 6970, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3426.16, \"learn_time_ms\": 26989.083}", "{\"n\": 6971, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3434.41, \"learn_time_ms\": 26972.065}", "{\"n\": 6972, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.7, \"learn_time_ms\": 26972.209}", "{\"n\": 6973, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.7, \"learn_time_ms\": 26955.636}", "{\"n\": 6974, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3441.39, \"learn_time_ms\": 27007.119}", "{\"n\": 6975, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3441.39, \"learn_time_ms\": 27048.09}", "{\"n\": 6976, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3441.39, \"learn_time_ms\": 27024.794}", "{\"n\": 6977, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3447.65, \"learn_time_ms\": 27030.413}", "{\"n\": 6978, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3447.82, \"learn_time_ms\": 27026.99}", "{\"n\": 6979, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.43, \"learn_time_ms\": 27026.324}", "{\"n\": 6980, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.43, \"learn_time_ms\": 27052.762}", "{\"n\": 6981, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.14, \"learn_time_ms\": 27089.391}", "{\"n\": 6982, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3441.97, \"learn_time_ms\": 27070.148}", "{\"n\": 6983, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3448.67, \"learn_time_ms\": 27064.054}", "{\"n\": 6984, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3451.6, \"learn_time_ms\": 27044.442}", "{\"n\": 6985, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3456.0, \"learn_time_ms\": 27030.492}", "{\"n\": 6986, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3456.0, \"learn_time_ms\": 27041.126}", "{\"n\": 6987, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3461.09, \"learn_time_ms\": 27064.858}", "{\"n\": 6988, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3459.01, \"learn_time_ms\": 27060.351}", "{\"n\": 6989, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3455.41, \"learn_time_ms\": 27080.052}", "{\"n\": 6990, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3447.42, \"learn_time_ms\": 27065.55}", "{\"n\": 6991, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3449.3, \"learn_time_ms\": 27048.058}", "{\"n\": 6992, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3451.49, \"learn_time_ms\": 27071.861}", "{\"n\": 6993, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3449.79, \"learn_time_ms\": 27065.902}", "{\"n\": 6994, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.86, \"learn_time_ms\": 27043.145}", "{\"n\": 6995, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3447.76, \"learn_time_ms\": 26992.304}", "{\"n\": 6996, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3451.82, \"learn_time_ms\": 26956.018}", "{\"n\": 6997, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3454.29, \"learn_time_ms\": 26882.135}", "{\"n\": 6998, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3447.01, \"learn_time_ms\": 26855.851}", "{\"n\": 6999, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3443.77, \"learn_time_ms\": 26822.795}", "{\"n\": 7000, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3440.61, \"learn_time_ms\": 26835.072}"]["{\"n\": 7001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27712.807}", "{\"n\": 7002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27154.714}", "{\"n\": 7003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27164.851}", "{\"n\": 7004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27108.957}", "{\"n\": 7005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27102.231}", "{\"n\": 7006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27073.918}", "{\"n\": 7007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27079.148}", "{\"n\": 7008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27080.672}", "{\"n\": 7009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27068.653}", "{\"n\": 7010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27072.997}", "{\"n\": 7011, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3371.0, \"learn_time_ms\": 27003.766}", "{\"n\": 7012, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.125, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3273.875, \"learn_time_ms\": 27025.9}", "{\"n\": 7013, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.125, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3273.875, \"learn_time_ms\": 27022.132}", "{\"n\": 7014, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.125, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3273.875, \"learn_time_ms\": 27045.174}", "{\"n\": 7015, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.125, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3273.875, \"learn_time_ms\": 27064.056}", "{\"n\": 7016, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.125, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3273.875, \"learn_time_ms\": 27073.992}", "{\"n\": 7017, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.928571428571429, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.214285714286, \"learn_time_ms\": 27080.556}", "{\"n\": 7018, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.625, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.75, \"learn_time_ms\": 27061.949}", "{\"n\": 7019, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.625, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.75, \"learn_time_ms\": 27066.538}", "{\"n\": 7020, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.625, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.75, \"learn_time_ms\": 27055.56}", "{\"n\": 7021, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.625, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.75, \"learn_time_ms\": 27033.855}", "{\"n\": 7022, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.529411764705882, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.235294117647, \"learn_time_ms\": 27071.278}", "{\"n\": 7023, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.478260869565218, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.521739130435, \"learn_time_ms\": 27077.084}", "{\"n\": 7024, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.333333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.0, \"learn_time_ms\": 27070.904}", "{\"n\": 7025, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.333333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.0, \"learn_time_ms\": 27075.219}", "{\"n\": 7026, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.333333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.0, \"learn_time_ms\": 27081.309}", "{\"n\": 7027, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.333333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.0, \"learn_time_ms\": 27100.483}", "{\"n\": 7028, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.222222222222222, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.4444444444443, \"learn_time_ms\": 27129.463}", "{\"n\": 7029, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.064516129032258, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.6774193548385, \"learn_time_ms\": 27147.347}", "{\"n\": 7030, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.03125, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.8125, \"learn_time_ms\": 27130.301}", "{\"n\": 7031, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.03125, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.8125, \"learn_time_ms\": 27150.793}", "{\"n\": 7032, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.03125, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.8125, \"learn_time_ms\": 27146.464}", "{\"n\": 7033, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.818181818181818, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.242424242424, \"learn_time_ms\": 27115.779}", "{\"n\": 7034, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.916666666666667, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3390.3055555555557, \"learn_time_ms\": 27139.354}", "{\"n\": 7035, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.725, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3413.875, \"learn_time_ms\": 27137.777}", "{\"n\": 7036, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.725, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3413.875, \"learn_time_ms\": 27099.918}", "{\"n\": 7037, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.725, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3413.875, \"learn_time_ms\": 27074.513}", "{\"n\": 7038, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.725, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3413.875, \"learn_time_ms\": 27070.181}", "{\"n\": 7039, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.767441860465116, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.906976744186, \"learn_time_ms\": 27056.004}", "{\"n\": 7040, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.723404255319149, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.021276595745, \"learn_time_ms\": 27087.164}", "{\"n\": 7041, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3404.875, \"learn_time_ms\": 27079.304}", "{\"n\": 7042, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3404.875, \"learn_time_ms\": 27050.522}", "{\"n\": 7043, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3404.875, \"learn_time_ms\": 27078.654}", "{\"n\": 7044, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3404.875, \"learn_time_ms\": 27056.728}", "{\"n\": 7045, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.962264150943396, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.396226415094, \"learn_time_ms\": 27036.354}", "{\"n\": 7046, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.964285714285714, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3374.1071428571427, \"learn_time_ms\": 27082.56}", "{\"n\": 7047, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.964285714285714, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3374.1071428571427, \"learn_time_ms\": 27064.736}", "{\"n\": 7048, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.964285714285714, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3374.1071428571427, \"learn_time_ms\": 27068.005}", "{\"n\": 7049, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.964285714285714, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3374.1071428571427, \"learn_time_ms\": 27064.172}", "{\"n\": 7050, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.066666666666666, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.7, \"learn_time_ms\": 27082.596}", "{\"n\": 7051, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.967741935483871, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.0, \"learn_time_ms\": 27060.853}", "{\"n\": 7052, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.953125, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.828125, \"learn_time_ms\": 27072.336}", "{\"n\": 7053, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.953125, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.828125, \"learn_time_ms\": 27070.289}", "{\"n\": 7054, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.953125, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.828125, \"learn_time_ms\": 27063.431}", "{\"n\": 7055, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.014925373134329, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3369.0597014925374, \"learn_time_ms\": 27051.342}", "{\"n\": 7056, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.072463768115942, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3366.521739130435, \"learn_time_ms\": 27040.701}", "{\"n\": 7057, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.138888888888889, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.4444444444443, \"learn_time_ms\": 27060.274}", "{\"n\": 7058, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.138888888888889, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.4444444444443, \"learn_time_ms\": 27033.126}", "{\"n\": 7059, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.138888888888889, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.4444444444443, \"learn_time_ms\": 27031.459}", "{\"n\": 7060, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.138888888888889, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.4444444444443, \"learn_time_ms\": 27039.427}", "{\"n\": 7061, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.171052631578948, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3350.8552631578946, \"learn_time_ms\": 27089.346}", "{\"n\": 7062, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.1923076923076925, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.474358974359, \"learn_time_ms\": 27091.197}", "{\"n\": 7063, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2375, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.025, \"learn_time_ms\": 27100.081}", "{\"n\": 7064, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2375, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.025, \"learn_time_ms\": 27081.32}", "{\"n\": 7065, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2375, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.025, \"learn_time_ms\": 27118.673}", "{\"n\": 7066, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2560975609756095, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.4634146341464, \"learn_time_ms\": 27106.695}", "{\"n\": 7067, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22093023255814, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.8488372093025, \"learn_time_ms\": 27089.84}", "{\"n\": 7068, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.193181818181818, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.3522727272725, \"learn_time_ms\": 27100.106}", "{\"n\": 7069, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.193181818181818, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.3522727272725, \"learn_time_ms\": 27083.495}", "{\"n\": 7070, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.193181818181818, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.3522727272725, \"learn_time_ms\": 27044.508}", "{\"n\": 7071, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.202247191011236, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3356.7078651685392, \"learn_time_ms\": 27033.887}", "{\"n\": 7072, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.197802197802198, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.3846153846152, \"learn_time_ms\": 27060.119}", "{\"n\": 7073, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28421052631579, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.0526315789475, \"learn_time_ms\": 27016.314}", "{\"n\": 7074, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.270833333333333, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.9895833333335, \"learn_time_ms\": 27054.236}", "{\"n\": 7075, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.270833333333333, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.9895833333335, \"learn_time_ms\": 27023.255}", "{\"n\": 7076, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.270833333333333, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.9895833333335, \"learn_time_ms\": 27043.696}", "{\"n\": 7077, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.278350515463917, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.5257731958764, \"learn_time_ms\": 27033.092}", "{\"n\": 7078, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.69, \"learn_time_ms\": 27013.971}", "{\"n\": 7079, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.33, \"learn_time_ms\": 27034.512}", "{\"n\": 7080, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.33, \"learn_time_ms\": 27089.206}", "{\"n\": 7081, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.33, \"learn_time_ms\": 27085.439}", "{\"n\": 7082, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.89, \"learn_time_ms\": 27113.748}", "{\"n\": 7083, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.89, \"learn_time_ms\": 27132.955}", "{\"n\": 7084, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.57, \"learn_time_ms\": 27122.783}", "{\"n\": 7085, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.75, \"learn_time_ms\": 27167.874}", "{\"n\": 7086, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.75, \"learn_time_ms\": 27150.907}", "{\"n\": 7087, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.75, \"learn_time_ms\": 27182.661}", "{\"n\": 7088, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.86, \"learn_time_ms\": 27214.506}", "{\"n\": 7089, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.86, \"learn_time_ms\": 27225.861}", "{\"n\": 7090, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.42, \"learn_time_ms\": 27216.699}", "{\"n\": 7091, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.71, \"learn_time_ms\": 27212.401}", "{\"n\": 7092, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.71, \"learn_time_ms\": 27132.662}", "{\"n\": 7093, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.71, \"learn_time_ms\": 27148.989}", "{\"n\": 7094, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3366.3, \"learn_time_ms\": 27105.085}", "{\"n\": 7095, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.68, \"learn_time_ms\": 27091.007}", "{\"n\": 7096, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.62, \"learn_time_ms\": 27091.858}", "{\"n\": 7097, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.36, \"learn_time_ms\": 27099.479}", "{\"n\": 7098, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.36, \"learn_time_ms\": 27103.073}", "{\"n\": 7099, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.36, \"learn_time_ms\": 27099.778}", "{\"n\": 7100, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.27, \"learn_time_ms\": 27080.142}", "{\"n\": 7101, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.75, \"learn_time_ms\": 27084.027}", "{\"n\": 7102, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.5, \"learn_time_ms\": 27110.211}", "{\"n\": 7103, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.5, \"learn_time_ms\": 27099.357}", "{\"n\": 7104, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.5, \"learn_time_ms\": 27154.298}", "{\"n\": 7105, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.92, \"learn_time_ms\": 27137.592}", "{\"n\": 7106, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.58, \"learn_time_ms\": 27128.307}", "{\"n\": 7107, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.59, \"learn_time_ms\": 27093.645}", "{\"n\": 7108, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.59, \"learn_time_ms\": 27136.912}", "{\"n\": 7109, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.44, \"learn_time_ms\": 27147.763}", "{\"n\": 7110, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.6, \"learn_time_ms\": 27107.955}", "{\"n\": 7111, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.6, \"learn_time_ms\": 27118.119}", "{\"n\": 7112, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.56, \"learn_time_ms\": 27115.513}", "{\"n\": 7113, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.32, \"learn_time_ms\": 27126.19}", "{\"n\": 7114, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.81, \"learn_time_ms\": 27097.82}", "{\"n\": 7115, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.81, \"learn_time_ms\": 27078.015}", "{\"n\": 7116, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.29, \"learn_time_ms\": 27121.165}", "{\"n\": 7117, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.01, \"learn_time_ms\": 27142.511}", "{\"n\": 7118, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.64, \"learn_time_ms\": 27097.37}", "{\"n\": 7119, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.81, \"learn_time_ms\": 27094.757}", "{\"n\": 7120, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.66, \"learn_time_ms\": 27132.618}", "{\"n\": 7121, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.84, \"learn_time_ms\": 27135.639}", "{\"n\": 7122, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.84, \"learn_time_ms\": 27139.052}", "{\"n\": 7123, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.42, \"learn_time_ms\": 27137.427}", "{\"n\": 7124, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.21, \"learn_time_ms\": 27147.128}", "{\"n\": 7125, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.43, \"learn_time_ms\": 27156.036}", "{\"n\": 7126, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.43, \"learn_time_ms\": 27151.138}", "{\"n\": 7127, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.99, \"learn_time_ms\": 27146.321}", "{\"n\": 7128, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.99, \"learn_time_ms\": 27140.263}", "{\"n\": 7129, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.78, \"learn_time_ms\": 27130.98}", "{\"n\": 7130, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.84, \"learn_time_ms\": 27132.204}", "{\"n\": 7131, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.05, \"learn_time_ms\": 27096.155}", "{\"n\": 7132, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.05, \"learn_time_ms\": 27108.711}", "{\"n\": 7133, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.22, \"learn_time_ms\": 27110.759}", "{\"n\": 7134, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.78, \"learn_time_ms\": 27104.216}", "{\"n\": 7135, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.97, \"learn_time_ms\": 27088.02}", "{\"n\": 7136, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.56, \"learn_time_ms\": 27109.629}", "{\"n\": 7137, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.47, \"learn_time_ms\": 27126.826}", "{\"n\": 7138, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.47, \"learn_time_ms\": 27109.85}", "{\"n\": 7139, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.47, \"learn_time_ms\": 27095.473}", "{\"n\": 7140, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.37, \"learn_time_ms\": 27048.244}", "{\"n\": 7141, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.37, \"learn_time_ms\": 27054.907}", "{\"n\": 7142, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.94, \"learn_time_ms\": 27044.859}", "{\"n\": 7143, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.68, \"learn_time_ms\": 27056.125}", "{\"n\": 7144, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.68, \"learn_time_ms\": 27034.316}", "{\"n\": 7145, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.63, \"learn_time_ms\": 27042.375}", "{\"n\": 7146, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.54, \"learn_time_ms\": 27003.047}", "{\"n\": 7147, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.85, \"learn_time_ms\": 26978.537}", "{\"n\": 7148, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.26, \"learn_time_ms\": 27015.046}", "{\"n\": 7149, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.38, \"learn_time_ms\": 27051.574}", "{\"n\": 7150, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.38, \"learn_time_ms\": 27093.065}", "{\"n\": 7151, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.69, \"learn_time_ms\": 27116.175}", "{\"n\": 7152, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.39, \"learn_time_ms\": 27127.426}", "{\"n\": 7153, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.37, \"learn_time_ms\": 27111.355}", "{\"n\": 7154, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.1, \"learn_time_ms\": 27149.978}", "{\"n\": 7155, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.94, \"learn_time_ms\": 27170.87}", "{\"n\": 7156, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.94, \"learn_time_ms\": 27164.089}", "{\"n\": 7157, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.9, \"learn_time_ms\": 27174.654}", "{\"n\": 7158, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.47, \"learn_time_ms\": 27204.137}", "{\"n\": 7159, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.54, \"learn_time_ms\": 27170.146}", "{\"n\": 7160, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3412.07, \"learn_time_ms\": 27166.949}", "{\"n\": 7161, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3412.07, \"learn_time_ms\": 27158.805}", "{\"n\": 7162, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.09, \"learn_time_ms\": 27169.104}", "{\"n\": 7163, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.99, \"learn_time_ms\": 27183.369}", "{\"n\": 7164, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.49, \"learn_time_ms\": 27222.319}", "{\"n\": 7165, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.49, \"learn_time_ms\": 27213.525}", "{\"n\": 7166, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.03, \"learn_time_ms\": 27269.056}", "{\"n\": 7167, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.03, \"learn_time_ms\": 27292.16}", "{\"n\": 7168, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.46, \"learn_time_ms\": 27244.542}", "{\"n\": 7169, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.62, \"learn_time_ms\": 27294.309}", "{\"n\": 7170, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.7, \"learn_time_ms\": 27290.751}", "{\"n\": 7171, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.34, \"learn_time_ms\": 27324.278}", "{\"n\": 7172, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.02, \"learn_time_ms\": 27347.607}", "{\"n\": 7173, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.18, \"learn_time_ms\": 27320.814}", "{\"n\": 7174, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.61, \"learn_time_ms\": 27267.078}", "{\"n\": 7175, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.29, \"learn_time_ms\": 27261.432}", "{\"n\": 7176, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.43, \"learn_time_ms\": 27197.924}", "{\"n\": 7177, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.43, \"learn_time_ms\": 27201.018}", "{\"n\": 7178, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.4, \"learn_time_ms\": 27212.285}", "{\"n\": 7179, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.17, \"learn_time_ms\": 27163.169}", "{\"n\": 7180, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.86, \"learn_time_ms\": 27177.708}", "{\"n\": 7181, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.64, \"learn_time_ms\": 27163.864}", "{\"n\": 7182, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.2, \"learn_time_ms\": 27155.379}", "{\"n\": 7183, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.2, \"learn_time_ms\": 27156.422}", "{\"n\": 7184, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.03, \"learn_time_ms\": 27174.809}", "{\"n\": 7185, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.4, \"learn_time_ms\": 27164.189}", "{\"n\": 7186, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.02, \"learn_time_ms\": 27181.679}", "{\"n\": 7187, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.8, \"learn_time_ms\": 27184.649}", "{\"n\": 7188, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.8, \"learn_time_ms\": 27194.064}", "{\"n\": 7189, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.24, \"learn_time_ms\": 27204.4}", "{\"n\": 7190, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.69, \"learn_time_ms\": 27208.017}", "{\"n\": 7191, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.04, \"learn_time_ms\": 27202.066}", "{\"n\": 7192, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.84, \"learn_time_ms\": 27181.754}", "{\"n\": 7193, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.85, \"learn_time_ms\": 27230.106}", "{\"n\": 7194, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.85, \"learn_time_ms\": 27235.494}", "{\"n\": 7195, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.33, \"learn_time_ms\": 27265.109}", "{\"n\": 7196, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.5, \"learn_time_ms\": 27270.586}", "{\"n\": 7197, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.94, \"learn_time_ms\": 27221.567}", "{\"n\": 7198, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.22, \"learn_time_ms\": 27165.621}", "{\"n\": 7199, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.79, \"learn_time_ms\": 27176.962}", "{\"n\": 7200, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.3, \"learn_time_ms\": 27175.677}", "{\"n\": 7201, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.6, \"learn_time_ms\": 27201.926}", "{\"n\": 7202, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.06, \"learn_time_ms\": 27222.494}", "{\"n\": 7203, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.29, \"learn_time_ms\": 27181.12}", "{\"n\": 7204, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.22, \"learn_time_ms\": 27154.213}", "{\"n\": 7205, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.27, \"learn_time_ms\": 27181.562}", "{\"n\": 7206, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.91, \"learn_time_ms\": 27147.392}", "{\"n\": 7207, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.16, \"learn_time_ms\": 27120.56}", "{\"n\": 7208, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.83, \"learn_time_ms\": 27170.547}", "{\"n\": 7209, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.45, \"learn_time_ms\": 27191.436}", "{\"n\": 7210, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.45, \"learn_time_ms\": 27162.767}", "{\"n\": 7211, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.95, \"learn_time_ms\": 27145.361}", "{\"n\": 7212, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.27, \"learn_time_ms\": 27125.676}", "{\"n\": 7213, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.8, \"learn_time_ms\": 27115.063}", "{\"n\": 7214, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.21, \"learn_time_ms\": 27132.31}", "{\"n\": 7215, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.03, \"learn_time_ms\": 27099.925}", "{\"n\": 7216, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.03, \"learn_time_ms\": 27163.878}", "{\"n\": 7217, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.21, \"learn_time_ms\": 27226.52}", "{\"n\": 7218, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.18, \"learn_time_ms\": 27241.822}", "{\"n\": 7219, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.62, \"learn_time_ms\": 27209.721}", "{\"n\": 7220, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.95, \"learn_time_ms\": 27224.87}", "{\"n\": 7221, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.58, \"learn_time_ms\": 27169.179}", "{\"n\": 7222, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.58, \"learn_time_ms\": 27171.271}", "{\"n\": 7223, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.82, \"learn_time_ms\": 27159.472}", "{\"n\": 7224, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.6, \"learn_time_ms\": 27203.549}", "{\"n\": 7225, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.16, \"learn_time_ms\": 27199.464}", "{\"n\": 7226, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.16, \"learn_time_ms\": 27179.379}", "{\"n\": 7227, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.52, \"learn_time_ms\": 27190.393}", "{\"n\": 7228, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.82, \"learn_time_ms\": 27181.713}", "{\"n\": 7229, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.9, \"learn_time_ms\": 27180.677}", "{\"n\": 7230, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.82, \"learn_time_ms\": 27154.666}", "{\"n\": 7231, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.76, \"learn_time_ms\": 27184.651}", "{\"n\": 7232, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.29, \"learn_time_ms\": 27148.459}", "{\"n\": 7233, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.79, \"learn_time_ms\": 27184.426}", "{\"n\": 7234, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.79, \"learn_time_ms\": 27119.696}", "{\"n\": 7235, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.61, \"learn_time_ms\": 27114.514}", "{\"n\": 7236, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.53, \"learn_time_ms\": 27104.832}", "{\"n\": 7237, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.98, \"learn_time_ms\": 27066.844}", "{\"n\": 7238, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.72, \"learn_time_ms\": 27087.453}", "{\"n\": 7239, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.5, \"learn_time_ms\": 27080.849}", "{\"n\": 7240, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.5, \"learn_time_ms\": 27127.833}", "{\"n\": 7241, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.4, \"learn_time_ms\": 27142.252}", "{\"n\": 7242, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.12, \"learn_time_ms\": 27147.296}", "{\"n\": 7243, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.26, \"learn_time_ms\": 27141.713}", "{\"n\": 7244, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.71, \"learn_time_ms\": 27191.659}", "{\"n\": 7245, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.21, \"learn_time_ms\": 27203.676}", "{\"n\": 7246, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.21, \"learn_time_ms\": 27220.456}", "{\"n\": 7247, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.62, \"learn_time_ms\": 27270.195}", "{\"n\": 7248, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.62, \"learn_time_ms\": 27254.613}", "{\"n\": 7249, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.22, \"learn_time_ms\": 27242.509}", "{\"n\": 7250, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.22, \"learn_time_ms\": 27209.066}", "{\"n\": 7251, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.62, \"learn_time_ms\": 27195.067}", "{\"n\": 7252, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.42, \"learn_time_ms\": 27222.519}", "{\"n\": 7253, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.15, \"learn_time_ms\": 27192.007}", "{\"n\": 7254, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.15, \"learn_time_ms\": 27199.159}", "{\"n\": 7255, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.62, \"learn_time_ms\": 27185.665}", "{\"n\": 7256, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.95, \"learn_time_ms\": 27157.713}", "{\"n\": 7257, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.58, \"learn_time_ms\": 27113.606}", "{\"n\": 7258, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.08, \"learn_time_ms\": 27079.732}", "{\"n\": 7259, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.08, \"learn_time_ms\": 27070.988}", "{\"n\": 7260, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.18, \"learn_time_ms\": 27096.737}", "{\"n\": 7261, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.14, \"learn_time_ms\": 27132.179}", "{\"n\": 7262, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.31, \"learn_time_ms\": 27140.258}", "{\"n\": 7263, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.82, \"learn_time_ms\": 27183.712}", "{\"n\": 7264, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.93, \"learn_time_ms\": 27145.877}", "{\"n\": 7265, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.93, \"learn_time_ms\": 27146.454}", "{\"n\": 7266, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.12, \"learn_time_ms\": 27103.002}", "{\"n\": 7267, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.83, \"learn_time_ms\": 27099.891}", "{\"n\": 7268, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.05, \"learn_time_ms\": 27081.249}", "{\"n\": 7269, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.19, \"learn_time_ms\": 27118.7}", "{\"n\": 7270, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.65, \"learn_time_ms\": 27094.178}", "{\"n\": 7271, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.0, \"learn_time_ms\": 27067.365}", "{\"n\": 7272, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.86, \"learn_time_ms\": 27061.012}", "{\"n\": 7273, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.86, \"learn_time_ms\": 27060.402}", "{\"n\": 7274, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.38, \"learn_time_ms\": 27085.93}", "{\"n\": 7275, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.9, \"learn_time_ms\": 27098.232}", "{\"n\": 7276, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.65, \"learn_time_ms\": 27151.034}", "{\"n\": 7277, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.13, \"learn_time_ms\": 27138.114}", "{\"n\": 7278, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.9, \"learn_time_ms\": 27147.584}", "{\"n\": 7279, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.16, \"learn_time_ms\": 27142.093}", "{\"n\": 7280, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.9, \"learn_time_ms\": 27141.952}", "{\"n\": 7281, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.87, \"learn_time_ms\": 27101.451}", "{\"n\": 7282, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.87, \"learn_time_ms\": 27108.25}", "{\"n\": 7283, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.36, \"learn_time_ms\": 27088.009}", "{\"n\": 7284, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.59, \"learn_time_ms\": 27032.317}", "{\"n\": 7285, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.72, \"learn_time_ms\": 27039.059}", "{\"n\": 7286, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.72, \"learn_time_ms\": 27014.888}", "{\"n\": 7287, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.01, \"learn_time_ms\": 27065.075}", "{\"n\": 7288, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.01, \"learn_time_ms\": 27096.378}", "{\"n\": 7289, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.08, \"learn_time_ms\": 27093.568}", "{\"n\": 7290, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.08, \"learn_time_ms\": 27103.663}", "{\"n\": 7291, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.72, \"learn_time_ms\": 27129.175}", "{\"n\": 7292, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.89, \"learn_time_ms\": 27112.862}", "{\"n\": 7293, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.96, \"learn_time_ms\": 27091.503}", "{\"n\": 7294, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.96, \"learn_time_ms\": 27097.716}", "{\"n\": 7295, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.94, \"learn_time_ms\": 27092.588}", "{\"n\": 7296, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3422.46, \"learn_time_ms\": 27092.565}", "{\"n\": 7297, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.92, \"learn_time_ms\": 27075.756}", "{\"n\": 7298, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.24, \"learn_time_ms\": 27076.678}", "{\"n\": 7299, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.24, \"learn_time_ms\": 27079.94}", "{\"n\": 7300, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.02, \"learn_time_ms\": 27054.119}", "{\"n\": 7301, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.64, \"learn_time_ms\": 27059.888}", "{\"n\": 7302, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.21, \"learn_time_ms\": 27030.078}", "{\"n\": 7303, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.47, \"learn_time_ms\": 27071.551}", "{\"n\": 7304, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.35, \"learn_time_ms\": 27074.212}", "{\"n\": 7305, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.56, \"learn_time_ms\": 27035.493}", "{\"n\": 7306, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.56, \"learn_time_ms\": 27028.714}", "{\"n\": 7307, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.32, \"learn_time_ms\": 26988.923}", "{\"n\": 7308, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.99, \"learn_time_ms\": 26993.213}", "{\"n\": 7309, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.71, \"learn_time_ms\": 26996.659}", "{\"n\": 7310, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.38, \"learn_time_ms\": 27034.204}", "{\"n\": 7311, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.56, \"learn_time_ms\": 27034.623}", "{\"n\": 7312, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.27, \"learn_time_ms\": 27046.035}", "{\"n\": 7313, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.81, \"learn_time_ms\": 27002.477}", "{\"n\": 7314, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.21, \"learn_time_ms\": 27009.232}", "{\"n\": 7315, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.71, \"learn_time_ms\": 27060.682}", "{\"n\": 7316, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.71, \"learn_time_ms\": 27103.317}", "{\"n\": 7317, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.91, \"learn_time_ms\": 27094.315}", "{\"n\": 7318, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.87, \"learn_time_ms\": 27078.123}", "{\"n\": 7319, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.28, \"learn_time_ms\": 27081.859}", "{\"n\": 7320, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.81, \"learn_time_ms\": 27067.371}", "{\"n\": 7321, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.81, \"learn_time_ms\": 27053.449}", "{\"n\": 7322, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.81, \"learn_time_ms\": 27050.291}", "{\"n\": 7323, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.92, \"learn_time_ms\": 27069.217}", "{\"n\": 7324, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.4, \"learn_time_ms\": 27083.866}", "{\"n\": 7325, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.93, \"learn_time_ms\": 27051.168}", "{\"n\": 7326, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.44, \"learn_time_ms\": 27026.954}", "{\"n\": 7327, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.44, \"learn_time_ms\": 27025.54}", "{\"n\": 7328, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.44, \"learn_time_ms\": 27007.156}", "{\"n\": 7329, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.55, \"learn_time_ms\": 27027.29}", "{\"n\": 7330, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.77, \"learn_time_ms\": 26998.054}", "{\"n\": 7331, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.77, \"learn_time_ms\": 26988.106}", "{\"n\": 7332, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.69, \"learn_time_ms\": 27012.521}", "{\"n\": 7333, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.69, \"learn_time_ms\": 26967.667}", "{\"n\": 7334, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.77, \"learn_time_ms\": 26968.159}", "{\"n\": 7335, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.09, \"learn_time_ms\": 26984.087}", "{\"n\": 7336, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.57, \"learn_time_ms\": 26990.529}", "{\"n\": 7337, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.58, \"learn_time_ms\": 27014.456}", "{\"n\": 7338, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.63, \"learn_time_ms\": 27020.533}", "{\"n\": 7339, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.91, \"learn_time_ms\": 27003.922}", "{\"n\": 7340, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.89, \"learn_time_ms\": 27039.409}", "{\"n\": 7341, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.84, \"learn_time_ms\": 27084.272}", "{\"n\": 7342, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.84, \"learn_time_ms\": 27081.913}", "{\"n\": 7343, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.32, \"learn_time_ms\": 27139.873}", "{\"n\": 7344, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.45, \"learn_time_ms\": 27153.371}", "{\"n\": 7345, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.45, \"learn_time_ms\": 27134.792}", "{\"n\": 7346, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.83, \"learn_time_ms\": 27146.69}", "{\"n\": 7347, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.36, \"learn_time_ms\": 27188.6}", "{\"n\": 7348, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.36, \"learn_time_ms\": 27196.44}", "{\"n\": 7349, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.5, \"learn_time_ms\": 27160.661}", "{\"n\": 7350, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.91, \"learn_time_ms\": 27134.88}", "{\"n\": 7351, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.15, \"learn_time_ms\": 27143.004}", "{\"n\": 7352, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.09, \"learn_time_ms\": 27135.04}", "{\"n\": 7353, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.81, \"learn_time_ms\": 27106.235}", "{\"n\": 7354, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.85, \"learn_time_ms\": 27076.904}", "{\"n\": 7355, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.38, \"learn_time_ms\": 27084.653}", "{\"n\": 7356, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.89, \"learn_time_ms\": 27073.061}", "{\"n\": 7357, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.61, \"learn_time_ms\": 27020.331}", "{\"n\": 7358, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.11, \"learn_time_ms\": 27019.527}", "{\"n\": 7359, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.11, \"learn_time_ms\": 27066.139}", "{\"n\": 7360, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.96, \"learn_time_ms\": 27021.53}", "{\"n\": 7361, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.84, \"learn_time_ms\": 26992.397}", "{\"n\": 7362, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.71, \"learn_time_ms\": 27000.949}", "{\"n\": 7363, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.42, \"learn_time_ms\": 27018.144}", "{\"n\": 7364, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.54, \"learn_time_ms\": 26979.425}", "{\"n\": 7365, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.06, \"learn_time_ms\": 27005.122}", "{\"n\": 7366, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.4, \"learn_time_ms\": 27011.225}", "{\"n\": 7367, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.47, \"learn_time_ms\": 27026.337}", "{\"n\": 7368, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.35, \"learn_time_ms\": 27007.833}", "{\"n\": 7369, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.56, \"learn_time_ms\": 26976.797}", "{\"n\": 7370, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.56, \"learn_time_ms\": 27039.374}", "{\"n\": 7371, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.51, \"learn_time_ms\": 27050.746}", "{\"n\": 7372, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.04, \"learn_time_ms\": 27015.192}", "{\"n\": 7373, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.54, \"learn_time_ms\": 27057.121}", "{\"n\": 7374, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.26, \"learn_time_ms\": 27068.689}", "{\"n\": 7375, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.46, \"learn_time_ms\": 27031.207}", "{\"n\": 7376, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.13, \"learn_time_ms\": 27025.111}", "{\"n\": 7377, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.13, \"learn_time_ms\": 27041.834}", "{\"n\": 7378, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.1, \"learn_time_ms\": 27068.232}", "{\"n\": 7379, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.1, \"learn_time_ms\": 27051.55}", "{\"n\": 7380, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.77, \"learn_time_ms\": 27061.39}", "{\"n\": 7381, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.11, \"learn_time_ms\": 27038.072}", "{\"n\": 7382, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.4, \"learn_time_ms\": 27044.607}", "{\"n\": 7383, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.23, \"learn_time_ms\": 26989.462}", "{\"n\": 7384, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.8, \"learn_time_ms\": 27046.479}", "{\"n\": 7385, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.65, \"learn_time_ms\": 27066.253}", "{\"n\": 7386, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.95, \"learn_time_ms\": 27017.866}", "{\"n\": 7387, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.34, \"learn_time_ms\": 27015.625}", "{\"n\": 7388, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.37, \"learn_time_ms\": 26964.106}", "{\"n\": 7389, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.89, \"learn_time_ms\": 26967.289}", "{\"n\": 7390, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.82, \"learn_time_ms\": 26965.406}", "{\"n\": 7391, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.39, \"learn_time_ms\": 26974.832}", "{\"n\": 7392, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.49, \"learn_time_ms\": 27032.43}", "{\"n\": 7393, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.3, \"learn_time_ms\": 27019.797}", "{\"n\": 7394, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.3, \"learn_time_ms\": 26974.778}", "{\"n\": 7395, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.02, \"learn_time_ms\": 26978.145}", "{\"n\": 7396, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.15, \"learn_time_ms\": 27032.688}", "{\"n\": 7397, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.51, \"learn_time_ms\": 27016.042}", "{\"n\": 7398, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.91, \"learn_time_ms\": 27095.826}", "{\"n\": 7399, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.99, \"learn_time_ms\": 27141.714}", "{\"n\": 7400, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.67, \"learn_time_ms\": 27111.166}", "{\"n\": 7401, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.67, \"learn_time_ms\": 27130.23}", "{\"n\": 7402, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.79, \"learn_time_ms\": 27056.175}", "{\"n\": 7403, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.71, \"learn_time_ms\": 27046.996}", "{\"n\": 7404, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.36, \"learn_time_ms\": 27068.198}", "{\"n\": 7405, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.02, \"learn_time_ms\": 27101.794}", "{\"n\": 7406, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.43, \"learn_time_ms\": 27064.731}", "{\"n\": 7407, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.13, \"learn_time_ms\": 27086.022}", "{\"n\": 7408, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.47, \"learn_time_ms\": 27073.774}", "{\"n\": 7409, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.14, \"learn_time_ms\": 27091.386}", "{\"n\": 7410, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.28, \"learn_time_ms\": 27102.757}", "{\"n\": 7411, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.55, \"learn_time_ms\": 27077.198}", "{\"n\": 7412, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.63, \"learn_time_ms\": 27133.436}", "{\"n\": 7413, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.36, \"learn_time_ms\": 27183.764}", "{\"n\": 7414, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.85, \"learn_time_ms\": 27148.908}", "{\"n\": 7415, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.54, \"learn_time_ms\": 27098.811}", "{\"n\": 7416, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.37, \"learn_time_ms\": 27144.198}", "{\"n\": 7417, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.16, \"learn_time_ms\": 27145.492}", "{\"n\": 7418, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.8, \"learn_time_ms\": 27085.755}", "{\"n\": 7419, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.69, \"learn_time_ms\": 27048.768}", "{\"n\": 7420, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.63, \"learn_time_ms\": 27045.199}", "{\"n\": 7421, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.31, \"learn_time_ms\": 27078.662}", "{\"n\": 7422, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.31, \"learn_time_ms\": 27059.695}", "{\"n\": 7423, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.06, \"learn_time_ms\": 27064.307}", "{\"n\": 7424, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.03, \"learn_time_ms\": 27114.853}", "{\"n\": 7425, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.17, \"learn_time_ms\": 27139.976}", "{\"n\": 7426, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.17, \"learn_time_ms\": 27138.408}", "{\"n\": 7427, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.96, \"learn_time_ms\": 27108.568}", "{\"n\": 7428, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.29, \"learn_time_ms\": 27151.557}", "{\"n\": 7429, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.29, \"learn_time_ms\": 27153.008}", "{\"n\": 7430, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.67, \"learn_time_ms\": 27197.702}", "{\"n\": 7431, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.54, \"learn_time_ms\": 27180.217}", "{\"n\": 7432, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.54, \"learn_time_ms\": 27187.198}", "{\"n\": 7433, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.47, \"learn_time_ms\": 27143.234}", "{\"n\": 7434, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.42, \"learn_time_ms\": 27122.31}", "{\"n\": 7435, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.53, \"learn_time_ms\": 27112.816}", "{\"n\": 7436, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.41, \"learn_time_ms\": 27129.233}", "{\"n\": 7437, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.66, \"learn_time_ms\": 27157.963}", "{\"n\": 7438, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.66, \"learn_time_ms\": 27147.116}", "{\"n\": 7439, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.0, \"learn_time_ms\": 27149.941}", "{\"n\": 7440, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.98, \"learn_time_ms\": 27099.005}", "{\"n\": 7441, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.32, \"learn_time_ms\": 27088.341}", "{\"n\": 7442, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.44, \"learn_time_ms\": 27077.461}", "{\"n\": 7443, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.3, \"learn_time_ms\": 27103.434}", "{\"n\": 7444, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.99, \"learn_time_ms\": 27098.721}", "{\"n\": 7445, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.77, \"learn_time_ms\": 27113.349}", "{\"n\": 7446, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.77, \"learn_time_ms\": 27082.225}", "{\"n\": 7447, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.36, \"learn_time_ms\": 27026.671}", "{\"n\": 7448, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.36, \"learn_time_ms\": 27014.29}", "{\"n\": 7449, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.63, \"learn_time_ms\": 27023.846}", "{\"n\": 7450, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.79, \"learn_time_ms\": 27071.345}", "{\"n\": 7451, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.3, \"learn_time_ms\": 27070.784}", "{\"n\": 7452, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.08, \"learn_time_ms\": 27074.302}", "{\"n\": 7453, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.53, \"learn_time_ms\": 27081.968}", "{\"n\": 7454, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.53, \"learn_time_ms\": 27090.191}", "{\"n\": 7455, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.95, \"learn_time_ms\": 27076.462}", "{\"n\": 7456, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.03, \"learn_time_ms\": 27039.561}", "{\"n\": 7457, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.03, \"learn_time_ms\": 27071.807}", "{\"n\": 7458, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.42, \"learn_time_ms\": 27092.091}", "{\"n\": 7459, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.42, \"learn_time_ms\": 27094.344}", "{\"n\": 7460, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.42, \"learn_time_ms\": 27078.687}", "{\"n\": 7461, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.29, \"learn_time_ms\": 27096.715}", "{\"n\": 7462, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.29, \"learn_time_ms\": 27105.418}", "{\"n\": 7463, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.05, \"learn_time_ms\": 27114.63}", "{\"n\": 7464, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.17, \"learn_time_ms\": 27125.752}", "{\"n\": 7465, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.17, \"learn_time_ms\": 27108.517}", "{\"n\": 7466, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.46, \"learn_time_ms\": 27143.104}", "{\"n\": 7467, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.7, \"learn_time_ms\": 27141.879}", "{\"n\": 7468, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.7, \"learn_time_ms\": 27130.877}", "{\"n\": 7469, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.09, \"learn_time_ms\": 27083.272}", "{\"n\": 7470, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.65, \"learn_time_ms\": 27026.497}", "{\"n\": 7471, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.65, \"learn_time_ms\": 27073.133}", "{\"n\": 7472, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.71, \"learn_time_ms\": 27066.66}", "{\"n\": 7473, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.97, \"learn_time_ms\": 27011.855}", "{\"n\": 7474, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.97, \"learn_time_ms\": 27012.874}", "{\"n\": 7475, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.35, \"learn_time_ms\": 27021.99}", "{\"n\": 7476, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.52, \"learn_time_ms\": 27028.892}", "{\"n\": 7477, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.27, \"learn_time_ms\": 27048.693}", "{\"n\": 7478, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.55, \"learn_time_ms\": 27060.014}", "{\"n\": 7479, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.55, \"learn_time_ms\": 27054.575}", "{\"n\": 7480, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.16, \"learn_time_ms\": 27124.008}", "{\"n\": 7481, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.31, \"learn_time_ms\": 27064.696}", "{\"n\": 7482, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.5, \"learn_time_ms\": 27040.343}", "{\"n\": 7483, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.26, \"learn_time_ms\": 27062.417}", "{\"n\": 7484, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.09, \"learn_time_ms\": 27067.818}", "{\"n\": 7485, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.47, \"learn_time_ms\": 27074.529}", "{\"n\": 7486, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.77, \"learn_time_ms\": 27062.727}", "{\"n\": 7487, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.59, \"learn_time_ms\": 27074.511}", "{\"n\": 7488, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.96, \"learn_time_ms\": 27084.746}", "{\"n\": 7489, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.07, \"learn_time_ms\": 27124.027}", "{\"n\": 7490, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.8, \"learn_time_ms\": 27076.948}", "{\"n\": 7491, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.52, \"learn_time_ms\": 27062.72}", "{\"n\": 7492, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.8, \"learn_time_ms\": 27097.997}", "{\"n\": 7493, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.72, \"learn_time_ms\": 27140.208}", "{\"n\": 7494, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.26, \"learn_time_ms\": 27119.298}", "{\"n\": 7495, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.84, \"learn_time_ms\": 27077.655}", "{\"n\": 7496, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.22, \"learn_time_ms\": 27058.13}", "{\"n\": 7497, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.22, \"learn_time_ms\": 27041.879}", "{\"n\": 7498, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.78, \"learn_time_ms\": 26990.402}", "{\"n\": 7499, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.2, \"learn_time_ms\": 26934.614}", "{\"n\": 7500, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.45, \"learn_time_ms\": 26937.984}", "{\"n\": 7501, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.87, \"learn_time_ms\": 26960.936}", "{\"n\": 7502, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.87, \"learn_time_ms\": 26945.521}", "{\"n\": 7503, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.05, \"learn_time_ms\": 26920.732}", "{\"n\": 7504, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.71, \"learn_time_ms\": 26925.586}", "{\"n\": 7505, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.93, \"learn_time_ms\": 26944.042}", "{\"n\": 7506, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.8, \"learn_time_ms\": 26943.159}", "{\"n\": 7507, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.2, \"learn_time_ms\": 26933.606}", "{\"n\": 7508, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.2, \"learn_time_ms\": 26963.484}", "{\"n\": 7509, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.72, \"learn_time_ms\": 26994.003}", "{\"n\": 7510, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.29, \"learn_time_ms\": 26985.414}", "{\"n\": 7511, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.19, \"learn_time_ms\": 26963.52}", "{\"n\": 7512, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.3, \"learn_time_ms\": 26939.29}", "{\"n\": 7513, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.8, \"learn_time_ms\": 26924.2}", "{\"n\": 7514, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.04, \"learn_time_ms\": 26923.754}", "{\"n\": 7515, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.54, \"learn_time_ms\": 26958.446}", "{\"n\": 7516, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.0, \"learn_time_ms\": 26980.366}", "{\"n\": 7517, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.77, \"learn_time_ms\": 27004.54}", "{\"n\": 7518, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.74, \"learn_time_ms\": 26996.186}", "{\"n\": 7519, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.88, \"learn_time_ms\": 27007.465}", "{\"n\": 7520, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.88, \"learn_time_ms\": 27010.956}", "{\"n\": 7521, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.57, \"learn_time_ms\": 27053.486}", "{\"n\": 7522, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.48, \"learn_time_ms\": 27094.323}", "{\"n\": 7523, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.4, \"learn_time_ms\": 27125.137}", "{\"n\": 7524, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.78, \"learn_time_ms\": 27136.608}", "{\"n\": 7525, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.12, \"learn_time_ms\": 27142.645}", "{\"n\": 7526, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.96, \"learn_time_ms\": 27111.7}", "{\"n\": 7527, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.16, \"learn_time_ms\": 27099.558}", "{\"n\": 7528, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.16, \"learn_time_ms\": 27056.749}", "{\"n\": 7529, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.78, \"learn_time_ms\": 27055.178}", "{\"n\": 7530, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.11, \"learn_time_ms\": 27094.244}", "{\"n\": 7531, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.86, \"learn_time_ms\": 27074.571}", "{\"n\": 7532, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.74, \"learn_time_ms\": 27069.505}", "{\"n\": 7533, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.52, \"learn_time_ms\": 27040.475}", "{\"n\": 7534, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.45, \"learn_time_ms\": 27037.555}", "{\"n\": 7535, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.33, \"learn_time_ms\": 27025.414}", "{\"n\": 7536, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.47, \"learn_time_ms\": 27053.122}", "{\"n\": 7537, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.28, \"learn_time_ms\": 27047.653}", "{\"n\": 7538, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.28, \"learn_time_ms\": 27112.175}", "{\"n\": 7539, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.64, \"learn_time_ms\": 27126.086}", "{\"n\": 7540, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.16, \"learn_time_ms\": 27149.866}", "{\"n\": 7541, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.49, \"learn_time_ms\": 27118.324}", "{\"n\": 7542, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.31, \"learn_time_ms\": 27102.861}", "{\"n\": 7543, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.86, \"learn_time_ms\": 27116.744}", "{\"n\": 7544, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.86, \"learn_time_ms\": 27114.06}", "{\"n\": 7545, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.41, \"learn_time_ms\": 27090.297}", "{\"n\": 7546, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.78, \"learn_time_ms\": 27097.647}", "{\"n\": 7547, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.16, \"learn_time_ms\": 27109.415}", "{\"n\": 7548, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.77, \"learn_time_ms\": 27048.602}", "{\"n\": 7549, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.62, \"learn_time_ms\": 27039.008}", "{\"n\": 7550, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.62, \"learn_time_ms\": 27031.236}", "{\"n\": 7551, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.69, \"learn_time_ms\": 27012.347}", "{\"n\": 7552, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.46, \"learn_time_ms\": 26994.929}", "{\"n\": 7553, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.0, \"learn_time_ms\": 26971.464}", "{\"n\": 7554, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.94, \"learn_time_ms\": 26940.703}", "{\"n\": 7555, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.94, \"learn_time_ms\": 26964.071}", "{\"n\": 7556, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.94, \"learn_time_ms\": 26953.878}", "{\"n\": 7557, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.84, \"learn_time_ms\": 26938.757}", "{\"n\": 7558, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.77, \"learn_time_ms\": 26983.412}", "{\"n\": 7559, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.22, \"learn_time_ms\": 26965.091}", "{\"n\": 7560, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.22, \"learn_time_ms\": 26877.229}", "{\"n\": 7561, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.22, \"learn_time_ms\": 26927.546}", "{\"n\": 7562, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.59, \"learn_time_ms\": 26967.674}", "{\"n\": 7563, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.66, \"learn_time_ms\": 27014.43}", "{\"n\": 7564, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.21, \"learn_time_ms\": 27084.952}", "{\"n\": 7565, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.21, \"learn_time_ms\": 27091.35}", "{\"n\": 7566, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.21, \"learn_time_ms\": 27085.429}", "{\"n\": 7567, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.21, \"learn_time_ms\": 27054.24}", "{\"n\": 7568, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.17, \"learn_time_ms\": 27058.636}", "{\"n\": 7569, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.73, \"learn_time_ms\": 27059.63}", "{\"n\": 7570, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.95, \"learn_time_ms\": 27055.674}", "{\"n\": 7571, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.95, \"learn_time_ms\": 27034.792}", "{\"n\": 7572, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.95, \"learn_time_ms\": 27040.257}", "{\"n\": 7573, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.02, \"learn_time_ms\": 26979.455}", "{\"n\": 7574, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.9, \"learn_time_ms\": 26890.439}", "{\"n\": 7575, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.95, \"learn_time_ms\": 26871.075}", "{\"n\": 7576, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.78, \"learn_time_ms\": 26882.796}", "{\"n\": 7577, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.78, \"learn_time_ms\": 26891.738}", "{\"n\": 7578, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.49, \"learn_time_ms\": 26887.509}", "{\"n\": 7579, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.93, \"learn_time_ms\": 26906.222}", "{\"n\": 7580, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.28, \"learn_time_ms\": 26980.022}", "{\"n\": 7581, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.69, \"learn_time_ms\": 26979.779}", "{\"n\": 7582, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.56, \"learn_time_ms\": 26960.101}", "{\"n\": 7583, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.56, \"learn_time_ms\": 26964.194}", "{\"n\": 7584, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.96, \"learn_time_ms\": 26993.983}", "{\"n\": 7585, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.77, \"learn_time_ms\": 26994.232}", "{\"n\": 7586, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.38, \"learn_time_ms\": 26993.658}", "{\"n\": 7587, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.12, \"learn_time_ms\": 27011.605}", "{\"n\": 7588, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.12, \"learn_time_ms\": 27035.116}", "{\"n\": 7589, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.12, \"learn_time_ms\": 27006.13}", "{\"n\": 7590, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.06, \"learn_time_ms\": 27008.785}", "{\"n\": 7591, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.18, \"learn_time_ms\": 27024.718}", "{\"n\": 7592, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.68, \"learn_time_ms\": 27042.04}", "{\"n\": 7593, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.74, \"learn_time_ms\": 27064.479}", "{\"n\": 7594, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.59, \"learn_time_ms\": 27071.504}", "{\"n\": 7595, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.59, \"learn_time_ms\": 27088.36}", "{\"n\": 7596, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.07, \"learn_time_ms\": 27064.512}", "{\"n\": 7597, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.62, \"learn_time_ms\": 27107.75}", "{\"n\": 7598, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.47, \"learn_time_ms\": 27112.253}", "{\"n\": 7599, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.47, \"learn_time_ms\": 27152.364}", "{\"n\": 7600, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.47, \"learn_time_ms\": 27133.504}", "{\"n\": 7601, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.07, \"learn_time_ms\": 27172.981}", "{\"n\": 7602, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.11, \"learn_time_ms\": 27159.708}", "{\"n\": 7603, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.48, \"learn_time_ms\": 27143.622}", "{\"n\": 7604, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.21, \"learn_time_ms\": 27148.509}", "{\"n\": 7605, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.21, \"learn_time_ms\": 27105.846}", "{\"n\": 7606, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.17, \"learn_time_ms\": 27121.647}", "{\"n\": 7607, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.8, \"learn_time_ms\": 27071.468}", "{\"n\": 7608, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.45, \"learn_time_ms\": 27033.645}", "{\"n\": 7609, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.5, \"learn_time_ms\": 27045.267}", "{\"n\": 7610, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.86, \"learn_time_ms\": 27049.433}", "{\"n\": 7611, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.86, \"learn_time_ms\": 27007.975}", "{\"n\": 7612, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.17, \"learn_time_ms\": 27000.025}", "{\"n\": 7613, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.64, \"learn_time_ms\": 27003.587}", "{\"n\": 7614, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.77, \"learn_time_ms\": 27022.978}", "{\"n\": 7615, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.87, \"learn_time_ms\": 27034.421}", "{\"n\": 7616, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.87, \"learn_time_ms\": 27075.137}", "{\"n\": 7617, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.74, \"learn_time_ms\": 27056.107}", "{\"n\": 7618, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.74, \"learn_time_ms\": 27070.007}", "{\"n\": 7619, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.36, \"learn_time_ms\": 27069.279}", "{\"n\": 7620, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.8, \"learn_time_ms\": 27077.629}", "{\"n\": 7621, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.11, \"learn_time_ms\": 27087.417}", "{\"n\": 7622, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.11, \"learn_time_ms\": 27091.103}", "{\"n\": 7623, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.75, \"learn_time_ms\": 27134.425}", "{\"n\": 7624, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.13, \"learn_time_ms\": 27096.812}", "{\"n\": 7625, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.87, \"learn_time_ms\": 27097.788}", "{\"n\": 7626, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.21, \"learn_time_ms\": 27076.118}", "{\"n\": 7627, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.12, \"learn_time_ms\": 27121.105}", "{\"n\": 7628, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.2, \"learn_time_ms\": 27117.839}", "{\"n\": 7629, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.96, \"learn_time_ms\": 27094.998}", "{\"n\": 7630, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.91, \"learn_time_ms\": 27096.538}", "{\"n\": 7631, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.02, \"learn_time_ms\": 27106.317}", "{\"n\": 7632, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.46, \"learn_time_ms\": 27097.901}", "{\"n\": 7633, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.46, \"learn_time_ms\": 27078.931}", "{\"n\": 7634, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.8, \"learn_time_ms\": 27106.779}", "{\"n\": 7635, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.29, \"learn_time_ms\": 27124.783}", "{\"n\": 7636, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.26, \"learn_time_ms\": 27087.642}", "{\"n\": 7637, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.99, \"learn_time_ms\": 27077.69}", "{\"n\": 7638, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.46, \"learn_time_ms\": 27056.128}", "{\"n\": 7639, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.01, \"learn_time_ms\": 27066.913}", "{\"n\": 7640, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.53, \"learn_time_ms\": 27053.192}", "{\"n\": 7641, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.6, \"learn_time_ms\": 27010.354}", "{\"n\": 7642, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.66, \"learn_time_ms\": 27038.152}", "{\"n\": 7643, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.66, \"learn_time_ms\": 27040.691}", "{\"n\": 7644, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.14, \"learn_time_ms\": 27034.063}", "{\"n\": 7645, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.76, \"learn_time_ms\": 27038.146}", "{\"n\": 7646, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.42, \"learn_time_ms\": 27052.717}", "{\"n\": 7647, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.71, \"learn_time_ms\": 27069.265}", "{\"n\": 7648, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.41, \"learn_time_ms\": 27089.655}", "{\"n\": 7649, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.65, \"learn_time_ms\": 27078.071}", "{\"n\": 7650, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.84, \"learn_time_ms\": 27116.056}", "{\"n\": 7651, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.84, \"learn_time_ms\": 27130.35}", "{\"n\": 7652, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.34, \"learn_time_ms\": 27102.235}", "{\"n\": 7653, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.13, \"learn_time_ms\": 27134.793}", "{\"n\": 7654, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.01, \"learn_time_ms\": 27101.512}", "{\"n\": 7655, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.01, \"learn_time_ms\": 27077.089}", "{\"n\": 7656, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.81, \"learn_time_ms\": 27107.61}", "{\"n\": 7657, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.41, \"learn_time_ms\": 27067.943}", "{\"n\": 7658, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.71, \"learn_time_ms\": 27090.854}", "{\"n\": 7659, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.37, \"learn_time_ms\": 27055.563}", "{\"n\": 7660, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.42, \"learn_time_ms\": 27020.473}", "{\"n\": 7661, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.42, \"learn_time_ms\": 27036.592}", "{\"n\": 7662, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.81, \"learn_time_ms\": 27017.58}", "{\"n\": 7663, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.53, \"learn_time_ms\": 27008.075}", "{\"n\": 7664, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.53, \"learn_time_ms\": 27055.75}", "{\"n\": 7665, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.53, \"learn_time_ms\": 27089.269}", "{\"n\": 7666, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.79, \"learn_time_ms\": 27081.897}", "{\"n\": 7667, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.79, \"learn_time_ms\": 27057.912}", "{\"n\": 7668, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.02, \"learn_time_ms\": 27061.908}", "{\"n\": 7669, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.09, \"learn_time_ms\": 27074.477}", "{\"n\": 7670, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.09, \"learn_time_ms\": 27068.946}", "{\"n\": 7671, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.09, \"learn_time_ms\": 27051.07}", "{\"n\": 7672, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.51, \"learn_time_ms\": 27087.78}", "{\"n\": 7673, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.14, \"learn_time_ms\": 27094.851}", "{\"n\": 7674, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.11, \"learn_time_ms\": 27080.817}", "{\"n\": 7675, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.88, \"learn_time_ms\": 27042.342}", "{\"n\": 7676, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.88, \"learn_time_ms\": 27026.084}", "{\"n\": 7677, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.46, \"learn_time_ms\": 27085.627}", "{\"n\": 7678, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.46, \"learn_time_ms\": 27086.903}", "{\"n\": 7679, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.12, \"learn_time_ms\": 27117.059}", "{\"n\": 7680, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.61, \"learn_time_ms\": 27136.867}", "{\"n\": 7681, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.61, \"learn_time_ms\": 27148.673}", "{\"n\": 7682, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.21, \"learn_time_ms\": 27130.824}", "{\"n\": 7683, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.21, \"learn_time_ms\": 27086.598}", "{\"n\": 7684, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.26, \"learn_time_ms\": 27084.038}", "{\"n\": 7685, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.8, \"learn_time_ms\": 27105.256}", "{\"n\": 7686, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.56, \"learn_time_ms\": 27109.767}", "{\"n\": 7687, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.23, \"learn_time_ms\": 27057.115}", "{\"n\": 7688, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.23, \"learn_time_ms\": 27022.888}", "{\"n\": 7689, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.23, \"learn_time_ms\": 26994.649}", "{\"n\": 7690, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.0, \"learn_time_ms\": 26967.627}", "{\"n\": 7691, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.01, \"learn_time_ms\": 26960.763}", "{\"n\": 7692, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.32, \"learn_time_ms\": 26976.937}", "{\"n\": 7693, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.32, \"learn_time_ms\": 26990.67}", "{\"n\": 7694, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.32, \"learn_time_ms\": 26990.587}", "{\"n\": 7695, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.06, \"learn_time_ms\": 26982.614}", "{\"n\": 7696, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.88, \"learn_time_ms\": 26982.928}", "{\"n\": 7697, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.06, \"learn_time_ms\": 27019.038}", "{\"n\": 7698, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.98, \"learn_time_ms\": 27035.593}", "{\"n\": 7699, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.98, \"learn_time_ms\": 27062.504}", "{\"n\": 7700, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.98, \"learn_time_ms\": 27087.262}", "{\"n\": 7701, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.17, \"learn_time_ms\": 27092.012}", "{\"n\": 7702, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.52, \"learn_time_ms\": 27070.763}", "{\"n\": 7703, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.08, \"learn_time_ms\": 27039.144}", "{\"n\": 7704, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.08, \"learn_time_ms\": 27037.064}", "{\"n\": 7705, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.08, \"learn_time_ms\": 27039.696}", "{\"n\": 7706, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.92, \"learn_time_ms\": 27059.659}", "{\"n\": 7707, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.53, \"learn_time_ms\": 27104.967}", "{\"n\": 7708, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.45, \"learn_time_ms\": 27110.56}", "{\"n\": 7709, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.14, \"learn_time_ms\": 27103.989}", "{\"n\": 7710, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.14, \"learn_time_ms\": 27062.303}", "{\"n\": 7711, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.99, \"learn_time_ms\": 27103.038}", "{\"n\": 7712, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.32, \"learn_time_ms\": 27094.846}", "{\"n\": 7713, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.32, \"learn_time_ms\": 27088.785}", "{\"n\": 7714, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.72, \"learn_time_ms\": 27095.642}", "{\"n\": 7715, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.1, \"learn_time_ms\": 27108.207}", "{\"n\": 7716, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.24, \"learn_time_ms\": 27080.905}", "{\"n\": 7717, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.74, \"learn_time_ms\": 27023.364}", "{\"n\": 7718, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.61, \"learn_time_ms\": 27027.333}", "{\"n\": 7719, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3320.78, \"learn_time_ms\": 27035.698}", "{\"n\": 7720, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.08, \"learn_time_ms\": 27030.431}", "{\"n\": 7721, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.17, \"learn_time_ms\": 26996.342}", "{\"n\": 7722, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.17, \"learn_time_ms\": 26984.484}", "{\"n\": 7723, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.84, \"learn_time_ms\": 27006.185}", "{\"n\": 7724, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.82, \"learn_time_ms\": 27020.673}", "{\"n\": 7725, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.94, \"learn_time_ms\": 26998.688}", "{\"n\": 7726, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.03, \"learn_time_ms\": 26965.464}", "{\"n\": 7727, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.03, \"learn_time_ms\": 27017.162}", "{\"n\": 7728, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.84, \"learn_time_ms\": 27007.765}", "{\"n\": 7729, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.94, \"learn_time_ms\": 26967.674}", "{\"n\": 7730, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.55, \"learn_time_ms\": 26983.998}", "{\"n\": 7731, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.57, \"learn_time_ms\": 26998.054}", "{\"n\": 7732, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.27, \"learn_time_ms\": 27017.288}", "{\"n\": 7733, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.27, \"learn_time_ms\": 27026.014}", "{\"n\": 7734, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.68, \"learn_time_ms\": 27004.267}", "{\"n\": 7735, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.92, \"learn_time_ms\": 27047.636}", "{\"n\": 7736, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.25, \"learn_time_ms\": 27108.577}", "{\"n\": 7737, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.3, \"learn_time_ms\": 27079.866}", "{\"n\": 7738, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.3, \"learn_time_ms\": 27076.392}", "{\"n\": 7739, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.11, \"learn_time_ms\": 27082.913}", "{\"n\": 7740, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.11, \"learn_time_ms\": 27115.748}", "{\"n\": 7741, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.91, \"learn_time_ms\": 27134.724}", "{\"n\": 7742, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.85, \"learn_time_ms\": 27157.679}", "{\"n\": 7743, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.85, \"learn_time_ms\": 27179.773}", "{\"n\": 7744, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.57, \"learn_time_ms\": 27182.424}", "{\"n\": 7745, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.17, \"learn_time_ms\": 27141.22}", "{\"n\": 7746, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3298.79, \"learn_time_ms\": 27124.487}", "{\"n\": 7747, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.3, \"learn_time_ms\": 27138.543}", "{\"n\": 7748, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.3, \"learn_time_ms\": 27166.7}", "{\"n\": 7749, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.3, \"learn_time_ms\": 27195.114}", "{\"n\": 7750, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.92, \"learn_time_ms\": 27173.059}", "{\"n\": 7751, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.49, \"learn_time_ms\": 27137.89}", "{\"n\": 7752, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3295.19, \"learn_time_ms\": 27136.099}", "{\"n\": 7753, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.74, \"learn_time_ms\": 27131.242}", "{\"n\": 7754, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.74, \"learn_time_ms\": 27132.412}", "{\"n\": 7755, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3300.74, \"learn_time_ms\": 27138.188}", "{\"n\": 7756, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3299.82, \"learn_time_ms\": 27129.982}", "{\"n\": 7757, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.06, \"learn_time_ms\": 27110.636}", "{\"n\": 7758, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3304.32, \"learn_time_ms\": 27084.876}", "{\"n\": 7759, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.68, \"learn_time_ms\": 27080.542}", "{\"n\": 7760, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3306.68, \"learn_time_ms\": 27062.062}", "{\"n\": 7761, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.69, \"learn_time_ms\": 27063.585}", "{\"n\": 7762, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3307.69, \"learn_time_ms\": 27058.566}", "{\"n\": 7763, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.55, \"learn_time_ms\": 27018.378}", "{\"n\": 7764, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.86, \"learn_time_ms\": 27052.342}", "{\"n\": 7765, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.86, \"learn_time_ms\": 27056.775}", "{\"n\": 7766, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.86, \"learn_time_ms\": 27058.73}", "{\"n\": 7767, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.59, \"learn_time_ms\": 27086.359}", "{\"n\": 7768, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.59, \"learn_time_ms\": 27070.287}", "{\"n\": 7769, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.66, \"learn_time_ms\": 27084.757}", "{\"n\": 7770, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.03, \"learn_time_ms\": 27111.345}", "{\"n\": 7771, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.03, \"learn_time_ms\": 27089.571}", "{\"n\": 7772, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.03, \"learn_time_ms\": 27059.114}", "{\"n\": 7773, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.93, \"learn_time_ms\": 27068.988}", "{\"n\": 7774, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.88, \"learn_time_ms\": 27035.409}", "{\"n\": 7775, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.11, \"learn_time_ms\": 27027.37}", "{\"n\": 7776, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.07, \"learn_time_ms\": 27054.71}", "{\"n\": 7777, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.07, \"learn_time_ms\": 27039.691}", "{\"n\": 7778, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.29, \"learn_time_ms\": 27043.056}", "{\"n\": 7779, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.18, \"learn_time_ms\": 27015.697}", "{\"n\": 7780, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.36, \"learn_time_ms\": 27032.054}", "{\"n\": 7781, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.02, \"learn_time_ms\": 27040.44}", "{\"n\": 7782, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.37, \"learn_time_ms\": 27026.242}", "{\"n\": 7783, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.37, \"learn_time_ms\": 27062.997}", "{\"n\": 7784, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.27, \"learn_time_ms\": 27048.539}", "{\"n\": 7785, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.65, \"learn_time_ms\": 27056.64}", "{\"n\": 7786, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.34, \"learn_time_ms\": 27032.936}", "{\"n\": 7787, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.73, \"learn_time_ms\": 27009.948}", "{\"n\": 7788, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.73, \"learn_time_ms\": 26996.492}", "{\"n\": 7789, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.48, \"learn_time_ms\": 27036.707}", "{\"n\": 7790, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.27, \"learn_time_ms\": 27005.358}", "{\"n\": 7791, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.6, \"learn_time_ms\": 27052.91}", "{\"n\": 7792, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.0, \"learn_time_ms\": 27124.823}", "{\"n\": 7793, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.8, \"learn_time_ms\": 27121.902}", "{\"n\": 7794, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.42, \"learn_time_ms\": 27159.694}", "{\"n\": 7795, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.19, \"learn_time_ms\": 27188.387}", "{\"n\": 7796, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.19, \"learn_time_ms\": 27256.948}", "{\"n\": 7797, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.62, \"learn_time_ms\": 27243.208}", "{\"n\": 7798, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.62, \"learn_time_ms\": 27240.592}", "{\"n\": 7799, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.62, \"learn_time_ms\": 27221.297}", "{\"n\": 7800, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.89, \"learn_time_ms\": 27249.141}", "{\"n\": 7801, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.69, \"learn_time_ms\": 27218.964}", "{\"n\": 7802, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.58, \"learn_time_ms\": 27205.272}", "{\"n\": 7803, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.58, \"learn_time_ms\": 27200.234}", "{\"n\": 7804, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.07, \"learn_time_ms\": 27186.913}", "{\"n\": 7805, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.57, \"learn_time_ms\": 27138.174}", "{\"n\": 7806, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.57, \"learn_time_ms\": 27102.716}", "{\"n\": 7807, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.24, \"learn_time_ms\": 27135.699}", "{\"n\": 7808, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.35, \"learn_time_ms\": 27181.828}", "{\"n\": 7809, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.09, \"learn_time_ms\": 27145.249}", "{\"n\": 7810, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.67, \"learn_time_ms\": 27122.995}", "{\"n\": 7811, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.08, \"learn_time_ms\": 27086.423}", "{\"n\": 7812, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.76, \"learn_time_ms\": 27122.699}", "{\"n\": 7813, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.09, \"learn_time_ms\": 27096.194}", "{\"n\": 7814, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.8, \"learn_time_ms\": 27087.951}", "{\"n\": 7815, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.8, \"learn_time_ms\": 27118.754}", "{\"n\": 7816, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.49, \"learn_time_ms\": 27082.345}", "{\"n\": 7817, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.82, \"learn_time_ms\": 27043.026}", "{\"n\": 7818, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.16, \"learn_time_ms\": 26987.914}", "{\"n\": 7819, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.16, \"learn_time_ms\": 26967.782}", "{\"n\": 7820, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.15, \"learn_time_ms\": 26947.202}", "{\"n\": 7821, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.15, \"learn_time_ms\": 26934.304}", "{\"n\": 7822, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.47, \"learn_time_ms\": 26839.316}", "{\"n\": 7823, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.87, \"learn_time_ms\": 26857.326}", "{\"n\": 7824, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.11, \"learn_time_ms\": 26867.25}", "{\"n\": 7825, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.78, \"learn_time_ms\": 26877.076}", "{\"n\": 7826, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.91, \"learn_time_ms\": 26856.546}", "{\"n\": 7827, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.75, \"learn_time_ms\": 26881.642}", "{\"n\": 7828, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.81, \"learn_time_ms\": 26940.062}", "{\"n\": 7829, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.97, \"learn_time_ms\": 26946.459}", "{\"n\": 7830, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.74, \"learn_time_ms\": 26990.113}", "{\"n\": 7831, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.36, \"learn_time_ms\": 27030.116}", "{\"n\": 7832, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.19, \"learn_time_ms\": 27059.936}", "{\"n\": 7833, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.83, \"learn_time_ms\": 27057.199}", "{\"n\": 7834, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.0, \"learn_time_ms\": 27040.687}", "{\"n\": 7835, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.97, \"learn_time_ms\": 27006.862}", "{\"n\": 7836, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.98, \"learn_time_ms\": 27057.78}", "{\"n\": 7837, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.83, \"learn_time_ms\": 27056.852}", "{\"n\": 7838, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.14, \"learn_time_ms\": 27017.926}", "{\"n\": 7839, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.14, \"learn_time_ms\": 27035.332}", "{\"n\": 7840, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.59, \"learn_time_ms\": 27010.536}", "{\"n\": 7841, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.05, \"learn_time_ms\": 26983.309}", "{\"n\": 7842, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.32, \"learn_time_ms\": 27010.966}", "{\"n\": 7843, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.02, \"learn_time_ms\": 26995.855}", "{\"n\": 7844, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.05, \"learn_time_ms\": 27003.206}", "{\"n\": 7845, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.05, \"learn_time_ms\": 27040.349}", "{\"n\": 7846, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.29, \"learn_time_ms\": 27015.71}", "{\"n\": 7847, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.84, \"learn_time_ms\": 27020.947}", "{\"n\": 7848, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.84, \"learn_time_ms\": 27013.858}", "{\"n\": 7849, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.17, \"learn_time_ms\": 27023.117}", "{\"n\": 7850, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.17, \"learn_time_ms\": 27019.794}", "{\"n\": 7851, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.17, \"learn_time_ms\": 27018.604}", "{\"n\": 7852, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.44, \"learn_time_ms\": 26986.261}", "{\"n\": 7853, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.75, \"learn_time_ms\": 27017.226}", "{\"n\": 7854, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.29, \"learn_time_ms\": 27030.109}", "{\"n\": 7855, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.94, \"learn_time_ms\": 27028.754}", "{\"n\": 7856, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.94, \"learn_time_ms\": 27038.296}", "{\"n\": 7857, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.04, \"learn_time_ms\": 27019.258}", "{\"n\": 7858, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.86, \"learn_time_ms\": 27032.357}", "{\"n\": 7859, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.63, \"learn_time_ms\": 27048.526}", "{\"n\": 7860, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.63, \"learn_time_ms\": 27031.283}", "{\"n\": 7861, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.63, \"learn_time_ms\": 27073.408}", "{\"n\": 7862, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.63, \"learn_time_ms\": 27108.412}", "{\"n\": 7863, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.17, \"learn_time_ms\": 27107.379}", "{\"n\": 7864, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.81, \"learn_time_ms\": 27126.13}", "{\"n\": 7865, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3386.37, \"learn_time_ms\": 27115.159}", "{\"n\": 7866, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3388.65, \"learn_time_ms\": 27091.087}", "{\"n\": 7867, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3388.65, \"learn_time_ms\": 27095.826}", "{\"n\": 7868, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3389.09, \"learn_time_ms\": 27114.852}", "{\"n\": 7869, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.8, \"learn_time_ms\": 27131.192}", "{\"n\": 7870, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3389.3, \"learn_time_ms\": 27164.643}", "{\"n\": 7871, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.8, \"learn_time_ms\": 27162.375}", "{\"n\": 7872, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.8, \"learn_time_ms\": 27110.214}", "{\"n\": 7873, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.8, \"learn_time_ms\": 27090.92}", "{\"n\": 7874, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.17, \"learn_time_ms\": 27047.652}", "{\"n\": 7875, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3393.14, \"learn_time_ms\": 27006.769}", "{\"n\": 7876, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3388.97, \"learn_time_ms\": 27011.567}", "{\"n\": 7877, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.11, \"learn_time_ms\": 27042.433}", "{\"n\": 7878, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.11, \"learn_time_ms\": 27035.971}", "{\"n\": 7879, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.6, \"learn_time_ms\": 26999.522}", "{\"n\": 7880, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3383.12, \"learn_time_ms\": 26970.598}", "{\"n\": 7881, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3383.12, \"learn_time_ms\": 26966.391}", "{\"n\": 7882, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.03, \"learn_time_ms\": 26988.538}", "{\"n\": 7883, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.2, \"learn_time_ms\": 26978.976}", "{\"n\": 7884, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.54, \"learn_time_ms\": 26975.992}", "{\"n\": 7885, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.54, \"learn_time_ms\": 26979.7}", "{\"n\": 7886, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.17, \"learn_time_ms\": 26959.883}", "{\"n\": 7887, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.17, \"learn_time_ms\": 26898.524}", "{\"n\": 7888, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3418.56, \"learn_time_ms\": 26895.548}", "{\"n\": 7889, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3434.95, \"learn_time_ms\": 26917.105}", "{\"n\": 7890, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3439.9, \"learn_time_ms\": 26949.546}", "{\"n\": 7891, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.04, \"learn_time_ms\": 26923.967}", "{\"n\": 7892, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.04, \"learn_time_ms\": 26919.507}", "{\"n\": 7893, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3432.08, \"learn_time_ms\": 26931.47}", "{\"n\": 7894, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.77, \"learn_time_ms\": 26953.099}", "{\"n\": 7895, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.84, \"learn_time_ms\": 26969.901}", "{\"n\": 7896, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3431.08, \"learn_time_ms\": 26975.886}", "{\"n\": 7897, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.03, \"learn_time_ms\": 27004.26}", "{\"n\": 7898, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.03, \"learn_time_ms\": 26988.015}", "{\"n\": 7899, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.76, \"learn_time_ms\": 26961.399}", "{\"n\": 7900, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.76, \"learn_time_ms\": 26952.49}", "{\"n\": 7901, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.21, \"learn_time_ms\": 27000.058}", "{\"n\": 7902, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3418.13, \"learn_time_ms\": 27044.028}", "{\"n\": 7903, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3418.13, \"learn_time_ms\": 27038.86}", "{\"n\": 7904, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3427.49, \"learn_time_ms\": 27010.439}", "{\"n\": 7905, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3424.59, \"learn_time_ms\": 27003.909}", "{\"n\": 7906, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3424.59, \"learn_time_ms\": 27014.929}", "{\"n\": 7907, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.5, \"learn_time_ms\": 27027.229}", "{\"n\": 7908, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3417.79, \"learn_time_ms\": 27053.954}", "{\"n\": 7909, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3417.79, \"learn_time_ms\": 27087.595}", "{\"n\": 7910, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.95, \"learn_time_ms\": 27108.564}", "{\"n\": 7911, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.11, \"learn_time_ms\": 27047.657}", "{\"n\": 7912, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.07, \"learn_time_ms\": 27040.63}", "{\"n\": 7913, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.5, \"learn_time_ms\": 27017.803}", "{\"n\": 7914, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.5, \"learn_time_ms\": 27006.066}", "{\"n\": 7915, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.27, \"learn_time_ms\": 27010.717}", "{\"n\": 7916, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.93, \"learn_time_ms\": 27020.569}", "{\"n\": 7917, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.93, \"learn_time_ms\": 26997.896}", "{\"n\": 7918, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.74, \"learn_time_ms\": 27008.76}", "{\"n\": 7919, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.62, \"learn_time_ms\": 26962.215}", "{\"n\": 7920, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.62, \"learn_time_ms\": 26937.0}", "{\"n\": 7921, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.26, \"learn_time_ms\": 26989.892}", "{\"n\": 7922, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3396.9, \"learn_time_ms\": 26981.056}", "{\"n\": 7923, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3396.9, \"learn_time_ms\": 27005.406}", "{\"n\": 7924, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.34, \"learn_time_ms\": 27067.458}", "{\"n\": 7925, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.21, \"learn_time_ms\": 27092.358}", "{\"n\": 7926, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.21, \"learn_time_ms\": 27060.275}", "{\"n\": 7927, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.42, \"learn_time_ms\": 27100.75}", "{\"n\": 7928, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3412.67, \"learn_time_ms\": 27085.273}", "{\"n\": 7929, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3420.17, \"learn_time_ms\": 27137.151}", "{\"n\": 7930, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3422.85, \"learn_time_ms\": 27147.934}", "{\"n\": 7931, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3422.85, \"learn_time_ms\": 27097.953}", "{\"n\": 7932, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3422.69, \"learn_time_ms\": 27084.404}", "{\"n\": 7933, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3424.08, \"learn_time_ms\": 27107.375}", "{\"n\": 7934, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.5, \"learn_time_ms\": 27044.814}", "{\"n\": 7935, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.92, \"learn_time_ms\": 27018.559}", "{\"n\": 7936, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.17, \"learn_time_ms\": 27055.153}", "{\"n\": 7937, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.1, \"learn_time_ms\": 27017.559}", "{\"n\": 7938, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.68, \"learn_time_ms\": 27027.181}", "{\"n\": 7939, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.27, \"learn_time_ms\": 27013.408}", "{\"n\": 7940, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.11, \"learn_time_ms\": 27020.453}", "{\"n\": 7941, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.43, \"learn_time_ms\": 27056.943}", "{\"n\": 7942, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.43, \"learn_time_ms\": 27077.242}", "{\"n\": 7943, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.15, \"learn_time_ms\": 27064.027}", "{\"n\": 7944, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.59, \"learn_time_ms\": 27071.695}", "{\"n\": 7945, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.06, \"learn_time_ms\": 27087.078}", "{\"n\": 7946, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.04, \"learn_time_ms\": 27057.713}", "{\"n\": 7947, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.42, \"learn_time_ms\": 27084.435}", "{\"n\": 7948, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.42, \"learn_time_ms\": 27056.023}", "{\"n\": 7949, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.02, \"learn_time_ms\": 27073.113}", "{\"n\": 7950, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.0, \"learn_time_ms\": 27049.841}", "{\"n\": 7951, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.01, \"learn_time_ms\": 27044.033}", "{\"n\": 7952, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.88, \"learn_time_ms\": 27007.996}", "{\"n\": 7953, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.2, \"learn_time_ms\": 27011.788}", "{\"n\": 7954, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.3, \"learn_time_ms\": 27013.115}", "{\"n\": 7955, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.1, \"learn_time_ms\": 26997.243}", "{\"n\": 7956, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.72, \"learn_time_ms\": 27031.29}", "{\"n\": 7957, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.21, \"learn_time_ms\": 27036.105}", "{\"n\": 7958, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.62, \"learn_time_ms\": 27038.769}", "{\"n\": 7959, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.62, \"learn_time_ms\": 27001.915}", "{\"n\": 7960, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.01, \"learn_time_ms\": 26990.174}", "{\"n\": 7961, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.17, \"learn_time_ms\": 26975.663}", "{\"n\": 7962, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.55, \"learn_time_ms\": 26982.673}", "{\"n\": 7963, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.66, \"learn_time_ms\": 26956.238}", "{\"n\": 7964, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.1, \"learn_time_ms\": 26983.021}", "{\"n\": 7965, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.92, \"learn_time_ms\": 27002.29}", "{\"n\": 7966, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.92, \"learn_time_ms\": 27003.112}", "{\"n\": 7967, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.46, \"learn_time_ms\": 26957.054}", "{\"n\": 7968, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.46, \"learn_time_ms\": 26968.813}", "{\"n\": 7969, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.18, \"learn_time_ms\": 26986.837}", "{\"n\": 7970, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.18, \"learn_time_ms\": 27024.582}", "{\"n\": 7971, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.63, \"learn_time_ms\": 27062.091}", "{\"n\": 7972, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.63, \"learn_time_ms\": 27057.995}", "{\"n\": 7973, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.0, \"learn_time_ms\": 27066.798}", "{\"n\": 7974, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.0, \"learn_time_ms\": 27010.329}", "{\"n\": 7975, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.72, \"learn_time_ms\": 26964.595}", "{\"n\": 7976, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.2, \"learn_time_ms\": 26947.752}", "{\"n\": 7977, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.72, \"learn_time_ms\": 26995.81}", "{\"n\": 7978, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.01, \"learn_time_ms\": 26965.729}", "{\"n\": 7979, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.77, \"learn_time_ms\": 26984.83}", "{\"n\": 7980, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.5, \"learn_time_ms\": 27010.266}", "{\"n\": 7981, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.13, \"learn_time_ms\": 26967.823}", "{\"n\": 7982, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.24, \"learn_time_ms\": 26964.976}", "{\"n\": 7983, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.26, \"learn_time_ms\": 26992.148}", "{\"n\": 7984, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.86, \"learn_time_ms\": 27014.667}", "{\"n\": 7985, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.51, \"learn_time_ms\": 27043.798}", "{\"n\": 7986, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.51, \"learn_time_ms\": 27046.717}", "{\"n\": 7987, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.2, \"learn_time_ms\": 27039.955}", "{\"n\": 7988, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.15, \"learn_time_ms\": 27049.051}", "{\"n\": 7989, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.51, \"learn_time_ms\": 27028.743}", "{\"n\": 7990, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.51, \"learn_time_ms\": 26982.216}", "{\"n\": 7991, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.95, \"learn_time_ms\": 27014.977}", "{\"n\": 7992, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.71, \"learn_time_ms\": 27031.931}", "{\"n\": 7993, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.38, \"learn_time_ms\": 27040.019}", "{\"n\": 7994, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.65, \"learn_time_ms\": 27042.61}", "{\"n\": 7995, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.09, \"learn_time_ms\": 27053.187}", "{\"n\": 7996, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.92, \"learn_time_ms\": 27024.631}", "{\"n\": 7997, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.07, \"learn_time_ms\": 27040.135}", "{\"n\": 7998, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.19, \"learn_time_ms\": 27054.086}", "{\"n\": 7999, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.19, \"learn_time_ms\": 27077.391}", "{\"n\": 8000, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.52, \"learn_time_ms\": 27099.876}"]["{\"n\": 8001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27848.134}", "{\"n\": 8002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27368.785}", "{\"n\": 8003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27309.545}", "{\"n\": 8004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27230.716}", "{\"n\": 8005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27197.782}", "{\"n\": 8006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27171.186}", "{\"n\": 8007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27147.541}", "{\"n\": 8008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27134.142}", "{\"n\": 8009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27119.173}", "{\"n\": 8010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27113.741}", "{\"n\": 8011, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3118.5, \"learn_time_ms\": 27044.162}", "{\"n\": 8012, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.75, \"learn_time_ms\": 27024.655}", "{\"n\": 8013, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.75, \"learn_time_ms\": 26983.27}", "{\"n\": 8014, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.75, \"learn_time_ms\": 26989.552}", "{\"n\": 8015, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.75, \"learn_time_ms\": 26953.215}", "{\"n\": 8016, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.75, \"learn_time_ms\": 26932.02}", "{\"n\": 8017, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.846153846153846, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.5384615384614, \"learn_time_ms\": 26921.086}", "{\"n\": 8018, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5625, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.5, \"learn_time_ms\": 26904.895}", "{\"n\": 8019, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5625, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.5, \"learn_time_ms\": 26913.208}", "{\"n\": 8020, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5625, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.5, \"learn_time_ms\": 26934.094}", "{\"n\": 8021, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5625, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.5, \"learn_time_ms\": 26921.523}", "{\"n\": 8022, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.0, \"learn_time_ms\": 26957.727}", "{\"n\": 8023, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.636363636363637, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.5454545454545, \"learn_time_ms\": 26966.729}", "{\"n\": 8024, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.458333333333333, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.9166666666665, \"learn_time_ms\": 26939.851}", "{\"n\": 8025, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.458333333333333, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.9166666666665, \"learn_time_ms\": 26962.566}", "{\"n\": 8026, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.458333333333333, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.9166666666665, \"learn_time_ms\": 26975.438}", "{\"n\": 8027, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.0, \"learn_time_ms\": 26985.283}", "{\"n\": 8028, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.571428571428571, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.25, \"learn_time_ms\": 26998.597}", "{\"n\": 8029, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.483870967741935, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.8709677419356, \"learn_time_ms\": 27004.783}", "{\"n\": 8030, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53125, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.03125, \"learn_time_ms\": 26963.555}", "{\"n\": 8031, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53125, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.03125, \"learn_time_ms\": 26959.336}", "{\"n\": 8032, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53125, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.03125, \"learn_time_ms\": 26931.006}", "{\"n\": 8033, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.571428571428571, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.8, \"learn_time_ms\": 26956.463}", "{\"n\": 8034, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.555555555555555, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.0833333333335, \"learn_time_ms\": 26965.005}", "{\"n\": 8035, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.512820512820513, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.153846153846, \"learn_time_ms\": 26956.401}", "{\"n\": 8036, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3374.725, \"learn_time_ms\": 26936.103}", "{\"n\": 8037, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3374.725, \"learn_time_ms\": 26937.462}", "{\"n\": 8038, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.380952380952381, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3368.809523809524, \"learn_time_ms\": 26963.86}", "{\"n\": 8039, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.441860465116279, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3366.1162790697676, \"learn_time_ms\": 26957.813}", "{\"n\": 8040, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.431818181818182, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3375.318181818182, \"learn_time_ms\": 26966.811}", "{\"n\": 8041, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.416666666666667, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3387.3125, \"learn_time_ms\": 26999.831}", "{\"n\": 8042, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.416666666666667, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3387.3125, \"learn_time_ms\": 27016.264}", "{\"n\": 8043, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.428571428571429, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.061224489796, \"learn_time_ms\": 26992.601}", "{\"n\": 8044, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.66, \"learn_time_ms\": 26986.367}", "{\"n\": 8045, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.470588235294118, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.3137254901962, \"learn_time_ms\": 27019.965}", "{\"n\": 8046, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.4363636363636365, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.418181818182, \"learn_time_ms\": 27042.889}", "{\"n\": 8047, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.410714285714286, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.0535714285716, \"learn_time_ms\": 27037.931}", "{\"n\": 8048, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.410714285714286, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.0535714285716, \"learn_time_ms\": 27030.049}", "{\"n\": 8049, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.456140350877193, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.7894736842104, \"learn_time_ms\": 27005.554}", "{\"n\": 8050, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47457627118644, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3387.6101694915255, \"learn_time_ms\": 26997.124}", "{\"n\": 8051, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.475409836065574, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.5245901639346, \"learn_time_ms\": 26954.755}", "{\"n\": 8052, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.453125, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.53125, \"learn_time_ms\": 26963.575}", "{\"n\": 8053, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.453125, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.53125, \"learn_time_ms\": 26979.651}", "{\"n\": 8054, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.453125, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.53125, \"learn_time_ms\": 27008.468}", "{\"n\": 8055, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46969696969697, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.1363636363635, \"learn_time_ms\": 26994.376}", "{\"n\": 8056, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5588235294117645, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.470588235294, \"learn_time_ms\": 27005.957}", "{\"n\": 8057, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.542857142857143, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3376.7, \"learn_time_ms\": 27012.164}", "{\"n\": 8058, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.555555555555555, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.9583333333335, \"learn_time_ms\": 27016.392}", "{\"n\": 8059, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.555555555555555, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.9583333333335, \"learn_time_ms\": 27025.216}", "{\"n\": 8060, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.555555555555555, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.9583333333335, \"learn_time_ms\": 27084.5}", "{\"n\": 8061, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.573333333333333, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.5733333333333, \"learn_time_ms\": 27096.752}", "{\"n\": 8062, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.538461538461538, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3381.3846153846152, \"learn_time_ms\": 27122.847}", "{\"n\": 8063, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.538461538461538, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3381.3846153846152, \"learn_time_ms\": 27136.921}", "{\"n\": 8064, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.35, \"learn_time_ms\": 27125.036}", "{\"n\": 8065, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.35, \"learn_time_ms\": 27087.215}", "{\"n\": 8066, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.35, \"learn_time_ms\": 27058.998}", "{\"n\": 8067, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.530120481927711, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.4819277108436, \"learn_time_ms\": 27080.732}", "{\"n\": 8068, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.569767441860465, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3376.6279069767443, \"learn_time_ms\": 27070.547}", "{\"n\": 8069, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.545454545454546, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.443181818182, \"learn_time_ms\": 27099.178}", "{\"n\": 8070, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.545454545454546, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.443181818182, \"learn_time_ms\": 27065.925}", "{\"n\": 8071, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.545454545454546, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.443181818182, \"learn_time_ms\": 27045.767}", "{\"n\": 8072, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.545454545454546, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.443181818182, \"learn_time_ms\": 27020.102}", "{\"n\": 8073, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.462365591397849, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.0967741935483, \"learn_time_ms\": 26992.584}", "{\"n\": 8074, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4361702127659575, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.053191489362, \"learn_time_ms\": 26990.921}", "{\"n\": 8075, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.458333333333333, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.4583333333335, \"learn_time_ms\": 27033.481}", "{\"n\": 8076, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.458333333333333, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.4583333333335, \"learn_time_ms\": 27050.364}", "{\"n\": 8077, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.458333333333333, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.4583333333335, \"learn_time_ms\": 27035.848}", "{\"n\": 8078, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.494949494949495, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.777777777778, \"learn_time_ms\": 27019.434}", "{\"n\": 8079, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3395.16, \"learn_time_ms\": 26984.347}", "{\"n\": 8080, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3390.97, \"learn_time_ms\": 26952.25}", "{\"n\": 8081, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3390.46, \"learn_time_ms\": 26963.029}", "{\"n\": 8082, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3390.46, \"learn_time_ms\": 26894.372}", "{\"n\": 8083, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3390.46, \"learn_time_ms\": 26900.602}", "{\"n\": 8084, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.13, \"learn_time_ms\": 26897.218}", "{\"n\": 8085, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.46, \"learn_time_ms\": 26870.164}", "{\"n\": 8086, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.21, \"learn_time_ms\": 26865.618}", "{\"n\": 8087, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.21, \"learn_time_ms\": 26868.27}", "{\"n\": 8088, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.21, \"learn_time_ms\": 26843.893}", "{\"n\": 8089, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3382.59, \"learn_time_ms\": 26836.142}", "{\"n\": 8090, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3376.33, \"learn_time_ms\": 26856.934}", "{\"n\": 8091, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3371.99, \"learn_time_ms\": 26855.282}", "{\"n\": 8092, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.62, \"learn_time_ms\": 26925.485}", "{\"n\": 8093, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.62, \"learn_time_ms\": 26882.324}", "{\"n\": 8094, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.62, \"learn_time_ms\": 26887.242}", "{\"n\": 8095, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3366.12, \"learn_time_ms\": 26970.317}", "{\"n\": 8096, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.72, \"learn_time_ms\": 26982.216}", "{\"n\": 8097, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.43, \"learn_time_ms\": 27001.512}", "{\"n\": 8098, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.43, \"learn_time_ms\": 27057.954}", "{\"n\": 8099, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.43, \"learn_time_ms\": 27091.542}", "{\"n\": 8100, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.48, \"learn_time_ms\": 27106.523}", "{\"n\": 8101, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.79, \"learn_time_ms\": 27109.508}", "{\"n\": 8102, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.19, \"learn_time_ms\": 27123.352}", "{\"n\": 8103, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.19, \"learn_time_ms\": 27178.564}", "{\"n\": 8104, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.19, \"learn_time_ms\": 27173.459}", "{\"n\": 8105, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.09, \"learn_time_ms\": 27138.864}", "{\"n\": 8106, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3369.21, \"learn_time_ms\": 27155.46}", "{\"n\": 8107, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3374.75, \"learn_time_ms\": 27116.029}", "{\"n\": 8108, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.31, \"learn_time_ms\": 27125.265}", "{\"n\": 8109, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.31, \"learn_time_ms\": 27145.387}", "{\"n\": 8110, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.74, \"learn_time_ms\": 27106.837}", "{\"n\": 8111, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.53, \"learn_time_ms\": 27119.604}", "{\"n\": 8112, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.28, \"learn_time_ms\": 27107.702}", "{\"n\": 8113, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.22, \"learn_time_ms\": 27095.888}", "{\"n\": 8114, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.85, \"learn_time_ms\": 27097.418}", "{\"n\": 8115, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.85, \"learn_time_ms\": 27044.569}", "{\"n\": 8116, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.05, \"learn_time_ms\": 27043.352}", "{\"n\": 8117, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.05, \"learn_time_ms\": 27056.691}", "{\"n\": 8118, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.47, \"learn_time_ms\": 27039.659}", "{\"n\": 8119, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.77, \"learn_time_ms\": 27022.447}", "{\"n\": 8120, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.77, \"learn_time_ms\": 27016.303}", "{\"n\": 8121, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.32, \"learn_time_ms\": 27018.429}", "{\"n\": 8122, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.26, \"learn_time_ms\": 27006.042}", "{\"n\": 8123, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.86, \"learn_time_ms\": 27017.089}", "{\"n\": 8124, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.35, \"learn_time_ms\": 27009.534}", "{\"n\": 8125, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.09, \"learn_time_ms\": 27014.385}", "{\"n\": 8126, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.74, \"learn_time_ms\": 26994.546}", "{\"n\": 8127, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.37, \"learn_time_ms\": 27001.55}", "{\"n\": 8128, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.67, \"learn_time_ms\": 26954.993}", "{\"n\": 8129, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.85, \"learn_time_ms\": 26963.582}", "{\"n\": 8130, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.83, \"learn_time_ms\": 27024.086}", "{\"n\": 8131, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.03, \"learn_time_ms\": 27030.846}", "{\"n\": 8132, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.03, \"learn_time_ms\": 27040.704}", "{\"n\": 8133, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3358.05, \"learn_time_ms\": 27008.397}", "{\"n\": 8134, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.77, \"learn_time_ms\": 27006.391}", "{\"n\": 8135, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.97, \"learn_time_ms\": 27062.03}", "{\"n\": 8136, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.46, \"learn_time_ms\": 27101.49}", "{\"n\": 8137, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.35, \"learn_time_ms\": 27091.497}", "{\"n\": 8138, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.35, \"learn_time_ms\": 27138.146}", "{\"n\": 8139, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.16, \"learn_time_ms\": 27136.183}", "{\"n\": 8140, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.8, \"learn_time_ms\": 27092.298}", "{\"n\": 8141, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.43, \"learn_time_ms\": 27076.112}", "{\"n\": 8142, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.36, \"learn_time_ms\": 27096.945}", "{\"n\": 8143, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.34, \"learn_time_ms\": 27125.442}", "{\"n\": 8144, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.18, \"learn_time_ms\": 27147.648}", "{\"n\": 8145, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.18, \"learn_time_ms\": 27113.287}", "{\"n\": 8146, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.45, \"learn_time_ms\": 27085.792}", "{\"n\": 8147, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.65, \"learn_time_ms\": 27086.855}", "{\"n\": 8148, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.84, \"learn_time_ms\": 27084.249}", "{\"n\": 8149, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.8, \"learn_time_ms\": 27091.719}", "{\"n\": 8150, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.47, \"learn_time_ms\": 27112.589}", "{\"n\": 8151, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.06, \"learn_time_ms\": 27108.065}", "{\"n\": 8152, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.07, \"learn_time_ms\": 27097.496}", "{\"n\": 8153, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.52, \"learn_time_ms\": 27109.964}", "{\"n\": 8154, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.52, \"learn_time_ms\": 27150.986}", "{\"n\": 8155, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.61, \"learn_time_ms\": 27202.889}", "{\"n\": 8156, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.31, \"learn_time_ms\": 27192.054}", "{\"n\": 8157, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.54, \"learn_time_ms\": 27220.677}", "{\"n\": 8158, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3358.67, \"learn_time_ms\": 27230.399}", "{\"n\": 8159, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.5, \"learn_time_ms\": 27214.326}", "{\"n\": 8160, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.5, \"learn_time_ms\": 27222.41}", "{\"n\": 8161, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.22, \"learn_time_ms\": 27230.231}", "{\"n\": 8162, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.12, \"learn_time_ms\": 27210.101}", "{\"n\": 8163, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.83, \"learn_time_ms\": 27272.94}", "{\"n\": 8164, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.28, \"learn_time_ms\": 27260.303}", "{\"n\": 8165, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.27, \"learn_time_ms\": 27214.339}", "{\"n\": 8166, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.27, \"learn_time_ms\": 27225.48}", "{\"n\": 8167, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.73, \"learn_time_ms\": 27228.692}", "{\"n\": 8168, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.28, \"learn_time_ms\": 27208.079}", "{\"n\": 8169, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.57, \"learn_time_ms\": 27172.886}", "{\"n\": 8170, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.73, \"learn_time_ms\": 27167.758}", "{\"n\": 8171, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.29, \"learn_time_ms\": 27161.587}", "{\"n\": 8172, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.78, \"learn_time_ms\": 27149.808}", "{\"n\": 8173, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3358.19, \"learn_time_ms\": 27094.819}", "{\"n\": 8174, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.36, \"learn_time_ms\": 27081.151}", "{\"n\": 8175, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.36, \"learn_time_ms\": 27111.42}", "{\"n\": 8176, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.41, \"learn_time_ms\": 27122.875}", "{\"n\": 8177, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.82, \"learn_time_ms\": 27090.293}", "{\"n\": 8178, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.82, \"learn_time_ms\": 27107.753}", "{\"n\": 8179, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.14, \"learn_time_ms\": 27131.897}", "{\"n\": 8180, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.15, \"learn_time_ms\": 27120.323}", "{\"n\": 8181, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.78, \"learn_time_ms\": 27182.228}", "{\"n\": 8182, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.78, \"learn_time_ms\": 27211.192}", "{\"n\": 8183, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.91, \"learn_time_ms\": 27204.575}", "{\"n\": 8184, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.12, \"learn_time_ms\": 27206.203}", "{\"n\": 8185, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.86, \"learn_time_ms\": 27177.335}", "{\"n\": 8186, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.11, \"learn_time_ms\": 27127.745}", "{\"n\": 8187, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.25, \"learn_time_ms\": 27104.637}", "{\"n\": 8188, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.69, \"learn_time_ms\": 27122.873}", "{\"n\": 8189, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.69, \"learn_time_ms\": 27134.538}", "{\"n\": 8190, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.89, \"learn_time_ms\": 27149.074}", "{\"n\": 8191, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.58, \"learn_time_ms\": 27100.314}", "{\"n\": 8192, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.76, \"learn_time_ms\": 27122.375}", "{\"n\": 8193, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.99, \"learn_time_ms\": 27117.532}", "{\"n\": 8194, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.28, \"learn_time_ms\": 27098.881}", "{\"n\": 8195, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.45, \"learn_time_ms\": 27114.668}", "{\"n\": 8196, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.42, \"learn_time_ms\": 27146.102}", "{\"n\": 8197, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.92, \"learn_time_ms\": 27176.434}", "{\"n\": 8198, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.96, \"learn_time_ms\": 27155.413}", "{\"n\": 8199, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.4, \"learn_time_ms\": 27168.108}", "{\"n\": 8200, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.65, \"learn_time_ms\": 27149.2}", "{\"n\": 8201, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.65, \"learn_time_ms\": 27150.396}", "{\"n\": 8202, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.41, \"learn_time_ms\": 27149.536}", "{\"n\": 8203, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.83, \"learn_time_ms\": 27181.409}", "{\"n\": 8204, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.83, \"learn_time_ms\": 27222.024}", "{\"n\": 8205, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.1, \"learn_time_ms\": 27223.623}", "{\"n\": 8206, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.0, \"learn_time_ms\": 27254.79}", "{\"n\": 8207, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.81, \"learn_time_ms\": 27263.446}", "{\"n\": 8208, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.86, \"learn_time_ms\": 27293.481}", "{\"n\": 8209, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.27, \"learn_time_ms\": 27249.437}", "{\"n\": 8210, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.2, \"learn_time_ms\": 27267.191}", "{\"n\": 8211, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.59, \"learn_time_ms\": 27274.467}", "{\"n\": 8212, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.45, \"learn_time_ms\": 27287.766}", "{\"n\": 8213, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.09, \"learn_time_ms\": 27275.294}", "{\"n\": 8214, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.65, \"learn_time_ms\": 27231.272}", "{\"n\": 8215, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.38, \"learn_time_ms\": 27224.714}", "{\"n\": 8216, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.14, \"learn_time_ms\": 27213.739}", "{\"n\": 8217, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.14, \"learn_time_ms\": 27221.503}", "{\"n\": 8218, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.43, \"learn_time_ms\": 27206.665}", "{\"n\": 8219, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.32, \"learn_time_ms\": 27250.132}", "{\"n\": 8220, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.08, \"learn_time_ms\": 27253.567}", "{\"n\": 8221, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.42, \"learn_time_ms\": 27285.923}", "{\"n\": 8222, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.42, \"learn_time_ms\": 27277.834}", "{\"n\": 8223, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.42, \"learn_time_ms\": 27267.643}", "{\"n\": 8224, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.84, \"learn_time_ms\": 27293.146}", "{\"n\": 8225, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.4, \"learn_time_ms\": 27293.922}", "{\"n\": 8226, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.73, \"learn_time_ms\": 27257.553}", "{\"n\": 8227, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.97, \"learn_time_ms\": 27214.328}", "{\"n\": 8228, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.97, \"learn_time_ms\": 27207.855}", "{\"n\": 8229, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.4, \"learn_time_ms\": 27212.185}", "{\"n\": 8230, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.03, \"learn_time_ms\": 27204.827}", "{\"n\": 8231, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.98, \"learn_time_ms\": 27173.468}", "{\"n\": 8232, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.04, \"learn_time_ms\": 27135.466}", "{\"n\": 8233, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.04, \"learn_time_ms\": 27114.955}", "{\"n\": 8234, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.54, \"learn_time_ms\": 27105.741}", "{\"n\": 8235, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.9, \"learn_time_ms\": 27108.453}", "{\"n\": 8236, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.9, \"learn_time_ms\": 27147.53}", "{\"n\": 8237, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.12, \"learn_time_ms\": 27188.383}", "{\"n\": 8238, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.31, \"learn_time_ms\": 27190.449}", "{\"n\": 8239, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.44, \"learn_time_ms\": 27182.522}", "{\"n\": 8240, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.92, \"learn_time_ms\": 27207.339}", "{\"n\": 8241, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.92, \"learn_time_ms\": 27203.624}", "{\"n\": 8242, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.75, \"learn_time_ms\": 27210.883}", "{\"n\": 8243, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.75, \"learn_time_ms\": 27219.772}", "{\"n\": 8244, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.44, \"learn_time_ms\": 27228.369}", "{\"n\": 8245, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.72, \"learn_time_ms\": 27219.922}", "{\"n\": 8246, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.72, \"learn_time_ms\": 27197.198}", "{\"n\": 8247, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.72, \"learn_time_ms\": 27201.062}", "{\"n\": 8248, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.23, \"learn_time_ms\": 27161.276}", "{\"n\": 8249, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.52, \"learn_time_ms\": 27171.895}", "{\"n\": 8250, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.23, \"learn_time_ms\": 27150.85}", "{\"n\": 8251, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.3, \"learn_time_ms\": 27169.789}", "{\"n\": 8252, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.3, \"learn_time_ms\": 27177.963}", "{\"n\": 8253, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.3, \"learn_time_ms\": 27193.755}", "{\"n\": 8254, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.59, \"learn_time_ms\": 27159.481}", "{\"n\": 8255, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.9, \"learn_time_ms\": 27172.815}", "{\"n\": 8256, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.03, \"learn_time_ms\": 27234.771}", "{\"n\": 8257, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.03, \"learn_time_ms\": 27218.023}", "{\"n\": 8258, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.03, \"learn_time_ms\": 27230.316}", "{\"n\": 8259, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.66, \"learn_time_ms\": 27187.754}", "{\"n\": 8260, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.78, \"learn_time_ms\": 27198.272}", "{\"n\": 8261, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.27, \"learn_time_ms\": 27166.087}", "{\"n\": 8262, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.27, \"learn_time_ms\": 27174.852}", "{\"n\": 8263, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.27, \"learn_time_ms\": 27166.249}", "{\"n\": 8264, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.27, \"learn_time_ms\": 27188.794}", "{\"n\": 8265, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.26, \"learn_time_ms\": 27163.224}", "{\"n\": 8266, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.15, \"learn_time_ms\": 27089.675}", "{\"n\": 8267, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.21, \"learn_time_ms\": 27104.208}", "{\"n\": 8268, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.21, \"learn_time_ms\": 27126.48}", "{\"n\": 8269, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.21, \"learn_time_ms\": 27163.544}", "{\"n\": 8270, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.24, \"learn_time_ms\": 27196.269}", "{\"n\": 8271, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.24, \"learn_time_ms\": 27197.514}", "{\"n\": 8272, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.67, \"learn_time_ms\": 27204.569}", "{\"n\": 8273, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.67, \"learn_time_ms\": 27206.86}", "{\"n\": 8274, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.67, \"learn_time_ms\": 27186.497}", "{\"n\": 8275, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.26, \"learn_time_ms\": 27208.192}", "{\"n\": 8276, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.28, \"learn_time_ms\": 27239.334}", "{\"n\": 8277, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.39, \"learn_time_ms\": 27218.927}", "{\"n\": 8278, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.62, \"learn_time_ms\": 27247.645}", "{\"n\": 8279, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.62, \"learn_time_ms\": 27226.526}", "{\"n\": 8280, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.66, \"learn_time_ms\": 27196.098}", "{\"n\": 8281, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.76, \"learn_time_ms\": 27211.54}", "{\"n\": 8282, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.03, \"learn_time_ms\": 27196.886}", "{\"n\": 8283, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.13, \"learn_time_ms\": 27201.983}", "{\"n\": 8284, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.33, \"learn_time_ms\": 27231.37}", "{\"n\": 8285, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.33, \"learn_time_ms\": 27230.939}", "{\"n\": 8286, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.94, \"learn_time_ms\": 27215.125}", "{\"n\": 8287, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.57, \"learn_time_ms\": 27212.395}", "{\"n\": 8288, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.18, \"learn_time_ms\": 27137.793}", "{\"n\": 8289, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.19, \"learn_time_ms\": 27129.007}", "{\"n\": 8290, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.59, \"learn_time_ms\": 27107.855}", "{\"n\": 8291, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.04, \"learn_time_ms\": 27113.737}", "{\"n\": 8292, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.0, \"learn_time_ms\": 27123.576}", "{\"n\": 8293, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.61, \"learn_time_ms\": 27119.387}", "{\"n\": 8294, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.66, \"learn_time_ms\": 27114.396}", "{\"n\": 8295, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.66, \"learn_time_ms\": 27098.502}", "{\"n\": 8296, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.77, \"learn_time_ms\": 27107.475}", "{\"n\": 8297, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.84, \"learn_time_ms\": 27133.127}", "{\"n\": 8298, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.84, \"learn_time_ms\": 27174.294}", "{\"n\": 8299, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.47, \"learn_time_ms\": 27170.731}", "{\"n\": 8300, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.63, \"learn_time_ms\": 27206.848}", "{\"n\": 8301, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.06, \"learn_time_ms\": 27164.164}", "{\"n\": 8302, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.45, \"learn_time_ms\": 27136.154}", "{\"n\": 8303, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.19, \"learn_time_ms\": 27136.965}", "{\"n\": 8304, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.19, \"learn_time_ms\": 27137.048}", "{\"n\": 8305, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.78, \"learn_time_ms\": 27110.117}", "{\"n\": 8306, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.5, \"learn_time_ms\": 27107.657}", "{\"n\": 8307, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.7, \"learn_time_ms\": 27113.494}", "{\"n\": 8308, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.86, \"learn_time_ms\": 27086.421}", "{\"n\": 8309, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.86, \"learn_time_ms\": 27080.089}", "{\"n\": 8310, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.76, \"learn_time_ms\": 27075.83}", "{\"n\": 8311, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.2, \"learn_time_ms\": 27113.38}", "{\"n\": 8312, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.29, \"learn_time_ms\": 27144.447}", "{\"n\": 8313, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.72, \"learn_time_ms\": 27174.264}", "{\"n\": 8314, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.23, \"learn_time_ms\": 27137.082}", "{\"n\": 8315, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.45, \"learn_time_ms\": 27167.289}", "{\"n\": 8316, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.52, \"learn_time_ms\": 27223.008}", "{\"n\": 8317, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.0, \"learn_time_ms\": 27205.225}", "{\"n\": 8318, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.64, \"learn_time_ms\": 27230.402}", "{\"n\": 8319, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.72, \"learn_time_ms\": 27223.318}", "{\"n\": 8320, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.72, \"learn_time_ms\": 27210.221}", "{\"n\": 8321, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.41, \"learn_time_ms\": 27258.174}", "{\"n\": 8322, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.32, \"learn_time_ms\": 27229.32}", "{\"n\": 8323, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.12, \"learn_time_ms\": 27199.098}", "{\"n\": 8324, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.95, \"learn_time_ms\": 27243.051}", "{\"n\": 8325, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.91, \"learn_time_ms\": 27246.081}", "{\"n\": 8326, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.91, \"learn_time_ms\": 27198.231}", "{\"n\": 8327, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.09, \"learn_time_ms\": 27174.073}", "{\"n\": 8328, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.14, \"learn_time_ms\": 27180.97}", "{\"n\": 8329, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.14, \"learn_time_ms\": 27207.951}", "{\"n\": 8330, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.19, \"learn_time_ms\": 27236.614}", "{\"n\": 8331, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.19, \"learn_time_ms\": 27168.903}", "{\"n\": 8332, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.39, \"learn_time_ms\": 27184.578}", "{\"n\": 8333, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.03, \"learn_time_ms\": 27204.401}", "{\"n\": 8334, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.23, \"learn_time_ms\": 27204.83}", "{\"n\": 8335, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.31, \"learn_time_ms\": 27184.724}", "{\"n\": 8336, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.31, \"learn_time_ms\": 27180.355}", "{\"n\": 8337, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.66, \"learn_time_ms\": 27176.288}", "{\"n\": 8338, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.71, \"learn_time_ms\": 27169.486}", "{\"n\": 8339, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.75, \"learn_time_ms\": 27197.696}", "{\"n\": 8340, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.81, \"learn_time_ms\": 27132.01}", "{\"n\": 8341, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.0, \"learn_time_ms\": 27163.047}", "{\"n\": 8342, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.0, \"learn_time_ms\": 27149.623}", "{\"n\": 8343, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.91, \"learn_time_ms\": 27127.286}", "{\"n\": 8344, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.75, \"learn_time_ms\": 27142.47}", "{\"n\": 8345, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.94, \"learn_time_ms\": 27194.941}", "{\"n\": 8346, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.52, \"learn_time_ms\": 27169.666}", "{\"n\": 8347, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.52, \"learn_time_ms\": 27194.057}", "{\"n\": 8348, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.52, \"learn_time_ms\": 27190.047}", "{\"n\": 8349, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.86, \"learn_time_ms\": 27168.096}", "{\"n\": 8350, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.93, \"learn_time_ms\": 27188.077}", "{\"n\": 8351, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.23, \"learn_time_ms\": 27184.544}", "{\"n\": 8352, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.31, \"learn_time_ms\": 27195.994}", "{\"n\": 8353, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.31, \"learn_time_ms\": 27202.126}", "{\"n\": 8354, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.39, \"learn_time_ms\": 27168.758}", "{\"n\": 8355, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.9, \"learn_time_ms\": 27130.56}", "{\"n\": 8356, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.2, \"learn_time_ms\": 27155.22}", "{\"n\": 8357, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.33, \"learn_time_ms\": 27174.914}", "{\"n\": 8358, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.33, \"learn_time_ms\": 27183.366}", "{\"n\": 8359, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.33, \"learn_time_ms\": 27185.103}", "{\"n\": 8360, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.89, \"learn_time_ms\": 27184.088}", "{\"n\": 8361, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.21, \"learn_time_ms\": 27167.257}", "{\"n\": 8362, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.66, \"learn_time_ms\": 27159.795}", "{\"n\": 8363, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.04, \"learn_time_ms\": 27140.032}", "{\"n\": 8364, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.04, \"learn_time_ms\": 27180.869}", "{\"n\": 8365, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.02, \"learn_time_ms\": 27156.818}", "{\"n\": 8366, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.08, \"learn_time_ms\": 27160.4}", "{\"n\": 8367, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.16, \"learn_time_ms\": 27145.209}", "{\"n\": 8368, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.75, \"learn_time_ms\": 27126.584}", "{\"n\": 8369, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.75, \"learn_time_ms\": 27110.566}", "{\"n\": 8370, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.52, \"learn_time_ms\": 27150.301}", "{\"n\": 8371, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.85, \"learn_time_ms\": 27161.364}", "{\"n\": 8372, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.49, \"learn_time_ms\": 27163.05}", "{\"n\": 8373, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.33, \"learn_time_ms\": 27165.117}", "{\"n\": 8374, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.08, \"learn_time_ms\": 27102.306}", "{\"n\": 8375, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.91, \"learn_time_ms\": 27139.828}", "{\"n\": 8376, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.91, \"learn_time_ms\": 27159.227}", "{\"n\": 8377, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.8, \"learn_time_ms\": 27173.164}", "{\"n\": 8378, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.56, \"learn_time_ms\": 27204.269}", "{\"n\": 8379, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.02, \"learn_time_ms\": 27239.748}", "{\"n\": 8380, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.57, \"learn_time_ms\": 27206.158}", "{\"n\": 8381, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.01, \"learn_time_ms\": 27185.338}", "{\"n\": 8382, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.7, \"learn_time_ms\": 27217.628}", "{\"n\": 8383, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.66, \"learn_time_ms\": 27237.718}", "{\"n\": 8384, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.11, \"learn_time_ms\": 27247.404}", "{\"n\": 8385, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.53, \"learn_time_ms\": 27254.166}", "{\"n\": 8386, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.13, \"learn_time_ms\": 27210.068}", "{\"n\": 8387, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.9, \"learn_time_ms\": 27211.442}", "{\"n\": 8388, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.0, \"learn_time_ms\": 27220.597}", "{\"n\": 8389, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.97, \"learn_time_ms\": 27162.711}", "{\"n\": 8390, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.33, \"learn_time_ms\": 27166.042}", "{\"n\": 8391, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.94, \"learn_time_ms\": 27167.083}", "{\"n\": 8392, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.3, \"learn_time_ms\": 27150.505}", "{\"n\": 8393, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.3, \"learn_time_ms\": 27168.534}", "{\"n\": 8394, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.77, \"learn_time_ms\": 27237.412}", "{\"n\": 8395, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.92, \"learn_time_ms\": 27292.786}", "{\"n\": 8396, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.98, \"learn_time_ms\": 27293.01}", "{\"n\": 8397, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.98, \"learn_time_ms\": 27263.993}", "{\"n\": 8398, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.35, \"learn_time_ms\": 27247.76}", "{\"n\": 8399, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.35, \"learn_time_ms\": 27275.497}", "{\"n\": 8400, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.11, \"learn_time_ms\": 27295.334}", "{\"n\": 8401, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.92, \"learn_time_ms\": 27353.584}", "{\"n\": 8402, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.11, \"learn_time_ms\": 27336.977}", "{\"n\": 8403, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.09, \"learn_time_ms\": 27319.303}", "{\"n\": 8404, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.75, \"learn_time_ms\": 27317.968}", "{\"n\": 8405, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.04, \"learn_time_ms\": 27242.235}", "{\"n\": 8406, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.21, \"learn_time_ms\": 27278.475}", "{\"n\": 8407, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.53, \"learn_time_ms\": 27316.767}", "{\"n\": 8408, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.53, \"learn_time_ms\": 27267.091}", "{\"n\": 8409, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.2, \"learn_time_ms\": 27251.183}", "{\"n\": 8410, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.01, \"learn_time_ms\": 27233.228}", "{\"n\": 8411, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.73, \"learn_time_ms\": 27188.219}", "{\"n\": 8412, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.1, \"learn_time_ms\": 27181.981}", "{\"n\": 8413, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.1, \"learn_time_ms\": 27185.996}", "{\"n\": 8414, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.15, \"learn_time_ms\": 27146.75}", "{\"n\": 8415, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.18, \"learn_time_ms\": 27149.443}", "{\"n\": 8416, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.27, \"learn_time_ms\": 27108.923}", "{\"n\": 8417, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.66, \"learn_time_ms\": 27056.739}", "{\"n\": 8418, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.66, \"learn_time_ms\": 27136.564}", "{\"n\": 8419, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.66, \"learn_time_ms\": 27150.993}", "{\"n\": 8420, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.71, \"learn_time_ms\": 27157.459}", "{\"n\": 8421, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.55, \"learn_time_ms\": 27154.913}", "{\"n\": 8422, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.7, \"learn_time_ms\": 27189.177}", "{\"n\": 8423, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.2, \"learn_time_ms\": 27179.236}", "{\"n\": 8424, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.2, \"learn_time_ms\": 27178.275}", "{\"n\": 8425, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.2, \"learn_time_ms\": 27186.375}", "{\"n\": 8426, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.98, \"learn_time_ms\": 27204.572}", "{\"n\": 8427, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.97, \"learn_time_ms\": 27198.161}", "{\"n\": 8428, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.13, \"learn_time_ms\": 27150.035}", "{\"n\": 8429, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.13, \"learn_time_ms\": 27163.283}", "{\"n\": 8430, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.13, \"learn_time_ms\": 27167.488}", "{\"n\": 8431, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.67, \"learn_time_ms\": 27161.393}", "{\"n\": 8432, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.08, \"learn_time_ms\": 27145.384}", "{\"n\": 8433, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.89, \"learn_time_ms\": 27145.726}", "{\"n\": 8434, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.89, \"learn_time_ms\": 27174.826}", "{\"n\": 8435, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.89, \"learn_time_ms\": 27150.169}", "{\"n\": 8436, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.89, \"learn_time_ms\": 27157.623}", "{\"n\": 8437, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.62, \"learn_time_ms\": 27186.23}", "{\"n\": 8438, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.64, \"learn_time_ms\": 27166.736}", "{\"n\": 8439, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.88, \"learn_time_ms\": 27154.02}", "{\"n\": 8440, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.88, \"learn_time_ms\": 27161.479}", "{\"n\": 8441, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.88, \"learn_time_ms\": 27153.567}", "{\"n\": 8442, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.5, \"learn_time_ms\": 27118.07}", "{\"n\": 8443, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.96, \"learn_time_ms\": 27134.237}", "{\"n\": 8444, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.11, \"learn_time_ms\": 27109.634}", "{\"n\": 8445, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.23, \"learn_time_ms\": 27141.096}", "{\"n\": 8446, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.23, \"learn_time_ms\": 27129.937}", "{\"n\": 8447, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.81, \"learn_time_ms\": 27151.622}", "{\"n\": 8448, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.14, \"learn_time_ms\": 27159.227}", "{\"n\": 8449, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.66, \"learn_time_ms\": 27170.209}", "{\"n\": 8450, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.59, \"learn_time_ms\": 27176.613}", "{\"n\": 8451, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.59, \"learn_time_ms\": 27178.064}", "{\"n\": 8452, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.59, \"learn_time_ms\": 27216.712}", "{\"n\": 8453, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.1, \"learn_time_ms\": 27203.302}", "{\"n\": 8454, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.46, \"learn_time_ms\": 27217.541}", "{\"n\": 8455, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.76, \"learn_time_ms\": 27213.657}", "{\"n\": 8456, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.17, \"learn_time_ms\": 27220.28}", "{\"n\": 8457, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.17, \"learn_time_ms\": 27202.286}", "{\"n\": 8458, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.34, \"learn_time_ms\": 27209.267}", "{\"n\": 8459, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.8, \"learn_time_ms\": 27210.991}", "{\"n\": 8460, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.02, \"learn_time_ms\": 27182.52}", "{\"n\": 8461, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.66, \"learn_time_ms\": 27199.062}", "{\"n\": 8462, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.59, \"learn_time_ms\": 27183.831}", "{\"n\": 8463, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.88, \"learn_time_ms\": 27192.224}", "{\"n\": 8464, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.22, \"learn_time_ms\": 27166.477}", "{\"n\": 8465, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.46, \"learn_time_ms\": 27191.593}", "{\"n\": 8466, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.55, \"learn_time_ms\": 27143.529}", "{\"n\": 8467, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.4, \"learn_time_ms\": 27145.909}", "{\"n\": 8468, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.09, \"learn_time_ms\": 27175.391}", "{\"n\": 8469, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.01, \"learn_time_ms\": 27133.317}", "{\"n\": 8470, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.29, \"learn_time_ms\": 27170.041}", "{\"n\": 8471, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.77, \"learn_time_ms\": 27195.868}", "{\"n\": 8472, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.14, \"learn_time_ms\": 27157.601}", "{\"n\": 8473, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.96, \"learn_time_ms\": 27138.51}", "{\"n\": 8474, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.48, \"learn_time_ms\": 27132.772}", "{\"n\": 8475, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.66, \"learn_time_ms\": 27129.576}", "{\"n\": 8476, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.92, \"learn_time_ms\": 27184.414}", "{\"n\": 8477, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.87, \"learn_time_ms\": 27187.232}", "{\"n\": 8478, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.72, \"learn_time_ms\": 27171.043}", "{\"n\": 8479, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.27, \"learn_time_ms\": 27210.914}", "{\"n\": 8480, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.54, \"learn_time_ms\": 27171.687}", "{\"n\": 8481, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.61, \"learn_time_ms\": 27160.006}", "{\"n\": 8482, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.46, \"learn_time_ms\": 27160.888}", "{\"n\": 8483, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.45, \"learn_time_ms\": 27145.139}", "{\"n\": 8484, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.68, \"learn_time_ms\": 27131.698}", "{\"n\": 8485, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.47, \"learn_time_ms\": 27112.584}", "{\"n\": 8486, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.61, \"learn_time_ms\": 27147.444}", "{\"n\": 8487, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.26, \"learn_time_ms\": 27152.541}", "{\"n\": 8488, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.26, \"learn_time_ms\": 27135.843}", "{\"n\": 8489, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.51, \"learn_time_ms\": 27147.954}", "{\"n\": 8490, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.38, \"learn_time_ms\": 27141.771}", "{\"n\": 8491, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.03, \"learn_time_ms\": 27119.323}", "{\"n\": 8492, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.47, \"learn_time_ms\": 27187.945}", "{\"n\": 8493, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.47, \"learn_time_ms\": 27207.214}", "{\"n\": 8494, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.36, \"learn_time_ms\": 27291.806}", "{\"n\": 8495, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.36, \"learn_time_ms\": 27297.306}", "{\"n\": 8496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.76, \"learn_time_ms\": 27257.008}", "{\"n\": 8497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.11, \"learn_time_ms\": 27271.397}", "{\"n\": 8498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.43, \"learn_time_ms\": 27280.974}", "{\"n\": 8499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.61, \"learn_time_ms\": 27240.13}", "{\"n\": 8500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.61, \"learn_time_ms\": 27214.572}", "{\"n\": 8501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.52, \"learn_time_ms\": 27224.518}", "{\"n\": 8502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.23, \"learn_time_ms\": 27209.021}", "{\"n\": 8503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.38, \"learn_time_ms\": 27225.887}", "{\"n\": 8504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.95, \"learn_time_ms\": 27181.86}", "{\"n\": 8505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.62, \"learn_time_ms\": 27180.315}", "{\"n\": 8506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.69, \"learn_time_ms\": 27169.498}", "{\"n\": 8507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.69, \"learn_time_ms\": 27171.206}", "{\"n\": 8508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.35, \"learn_time_ms\": 27143.389}", "{\"n\": 8509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.18, \"learn_time_ms\": 27167.89}", "{\"n\": 8510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.04, \"learn_time_ms\": 27206.964}", "{\"n\": 8511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.04, \"learn_time_ms\": 27205.834}", "{\"n\": 8512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.16, \"learn_time_ms\": 27217.867}", "{\"n\": 8513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.14, \"learn_time_ms\": 27192.466}", "{\"n\": 8514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.87, \"learn_time_ms\": 27126.713}", "{\"n\": 8515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.87, \"learn_time_ms\": 27129.173}", "{\"n\": 8516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.71, \"learn_time_ms\": 27135.232}", "{\"n\": 8517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.71, \"learn_time_ms\": 27097.139}", "{\"n\": 8518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.17, \"learn_time_ms\": 27146.468}", "{\"n\": 8519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.81, \"learn_time_ms\": 27140.453}", "{\"n\": 8520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.0, \"learn_time_ms\": 27133.939}", "{\"n\": 8521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.89, \"learn_time_ms\": 27165.412}", "{\"n\": 8522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.89, \"learn_time_ms\": 27148.837}", "{\"n\": 8523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.48, \"learn_time_ms\": 27175.997}", "{\"n\": 8524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.63, \"learn_time_ms\": 27200.511}", "{\"n\": 8525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.43, \"learn_time_ms\": 27193.781}", "{\"n\": 8526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.91, \"learn_time_ms\": 27164.887}", "{\"n\": 8527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.91, \"learn_time_ms\": 27155.729}", "{\"n\": 8528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.91, \"learn_time_ms\": 27143.722}", "{\"n\": 8529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.38, \"learn_time_ms\": 27154.02}", "{\"n\": 8530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.68, \"learn_time_ms\": 27180.975}", "{\"n\": 8531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.93, \"learn_time_ms\": 27140.04}", "{\"n\": 8532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.4, \"learn_time_ms\": 27139.705}", "{\"n\": 8533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.4, \"learn_time_ms\": 27169.619}", "{\"n\": 8534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.4, \"learn_time_ms\": 27218.434}", "{\"n\": 8535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.85, \"learn_time_ms\": 27167.517}", "{\"n\": 8536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.68, \"learn_time_ms\": 27187.494}", "{\"n\": 8537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.04, \"learn_time_ms\": 27208.277}", "{\"n\": 8538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.9, \"learn_time_ms\": 27197.981}", "{\"n\": 8539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.9, \"learn_time_ms\": 27206.344}", "{\"n\": 8540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.9, \"learn_time_ms\": 27198.594}", "{\"n\": 8541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.52, \"learn_time_ms\": 27207.283}", "{\"n\": 8542, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.98, \"learn_time_ms\": 27192.541}", "{\"n\": 8543, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.5, \"learn_time_ms\": 27146.744}", "{\"n\": 8544, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.28, \"learn_time_ms\": 27126.569}", "{\"n\": 8545, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.28, \"learn_time_ms\": 27181.729}", "{\"n\": 8546, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.2, \"learn_time_ms\": 27196.91}", "{\"n\": 8547, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.08, \"learn_time_ms\": 27221.686}", "{\"n\": 8548, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.43, \"learn_time_ms\": 27222.632}", "{\"n\": 8549, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.38, \"learn_time_ms\": 27278.104}", "{\"n\": 8550, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.38, \"learn_time_ms\": 27258.61}", "{\"n\": 8551, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.38, \"learn_time_ms\": 27266.388}", "{\"n\": 8552, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.45, \"learn_time_ms\": 27270.213}", "{\"n\": 8553, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.58, \"learn_time_ms\": 27284.408}", "{\"n\": 8554, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.5, \"learn_time_ms\": 27302.375}", "{\"n\": 8555, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.41, \"learn_time_ms\": 27326.624}", "{\"n\": 8556, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.41, \"learn_time_ms\": 27359.358}", "{\"n\": 8557, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.93, \"learn_time_ms\": 27368.552}", "{\"n\": 8558, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.33, \"learn_time_ms\": 27356.688}", "{\"n\": 8559, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.13, \"learn_time_ms\": 27305.323}", "{\"n\": 8560, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.43, \"learn_time_ms\": 27314.578}", "{\"n\": 8561, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.43, \"learn_time_ms\": 27326.802}", "{\"n\": 8562, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.43, \"learn_time_ms\": 27339.618}", "{\"n\": 8563, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.46, \"learn_time_ms\": 27302.328}", "{\"n\": 8564, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.04, \"learn_time_ms\": 27287.13}", "{\"n\": 8565, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.04, \"learn_time_ms\": 27230.26}", "{\"n\": 8566, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.17, \"learn_time_ms\": 27228.657}", "{\"n\": 8567, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.9, \"learn_time_ms\": 27197.619}", "{\"n\": 8568, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.95, \"learn_time_ms\": 27257.848}", "{\"n\": 8569, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.33, \"learn_time_ms\": 27239.892}", "{\"n\": 8570, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.64, \"learn_time_ms\": 27253.378}", "{\"n\": 8571, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.33, \"learn_time_ms\": 27243.444}", "{\"n\": 8572, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.75, \"learn_time_ms\": 27242.54}", "{\"n\": 8573, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.75, \"learn_time_ms\": 27262.744}", "{\"n\": 8574, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.97, \"learn_time_ms\": 27236.474}", "{\"n\": 8575, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.99, \"learn_time_ms\": 27290.541}", "{\"n\": 8576, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.99, \"learn_time_ms\": 27235.437}", "{\"n\": 8577, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.89, \"learn_time_ms\": 27209.125}", "{\"n\": 8578, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.06, \"learn_time_ms\": 27182.42}", "{\"n\": 8579, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.06, \"learn_time_ms\": 27202.539}", "{\"n\": 8580, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.44, \"learn_time_ms\": 27182.384}", "{\"n\": 8581, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.85, \"learn_time_ms\": 27162.231}", "{\"n\": 8582, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.56, \"learn_time_ms\": 27166.64}", "{\"n\": 8583, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.82, \"learn_time_ms\": 27153.809}", "{\"n\": 8584, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.82, \"learn_time_ms\": 27173.646}", "{\"n\": 8585, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.76, \"learn_time_ms\": 27137.825}", "{\"n\": 8586, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.27, \"learn_time_ms\": 27173.976}", "{\"n\": 8587, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.44, \"learn_time_ms\": 27189.046}", "{\"n\": 8588, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.8, \"learn_time_ms\": 27160.005}", "{\"n\": 8589, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.41, \"learn_time_ms\": 27147.623}", "{\"n\": 8590, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.58, \"learn_time_ms\": 27152.268}", "{\"n\": 8591, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.07, \"learn_time_ms\": 27180.871}", "{\"n\": 8592, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.97, \"learn_time_ms\": 27184.329}", "{\"n\": 8593, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.47, \"learn_time_ms\": 27203.205}", "{\"n\": 8594, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.7, \"learn_time_ms\": 27197.018}", "{\"n\": 8595, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.7, \"learn_time_ms\": 27165.451}", "{\"n\": 8596, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.36, \"learn_time_ms\": 27143.468}", "{\"n\": 8597, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.07, \"learn_time_ms\": 27135.726}", "{\"n\": 8598, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.21, \"learn_time_ms\": 27137.083}", "{\"n\": 8599, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.27, \"learn_time_ms\": 27157.48}", "{\"n\": 8600, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.27, \"learn_time_ms\": 27157.238}", "{\"n\": 8601, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.28, \"learn_time_ms\": 27146.387}", "{\"n\": 8602, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.52, \"learn_time_ms\": 27187.278}", "{\"n\": 8603, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.75, \"learn_time_ms\": 27163.142}", "{\"n\": 8604, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.75, \"learn_time_ms\": 27136.785}", "{\"n\": 8605, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.75, \"learn_time_ms\": 27160.344}", "{\"n\": 8606, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.65, \"learn_time_ms\": 27193.068}", "{\"n\": 8607, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.65, \"learn_time_ms\": 27227.673}", "{\"n\": 8608, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.57, \"learn_time_ms\": 27220.376}", "{\"n\": 8609, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.83, \"learn_time_ms\": 27213.433}", "{\"n\": 8610, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.83, \"learn_time_ms\": 27189.291}", "{\"n\": 8611, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.39, \"learn_time_ms\": 27187.391}", "{\"n\": 8612, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.18, \"learn_time_ms\": 27131.662}", "{\"n\": 8613, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.42, \"learn_time_ms\": 27149.334}", "{\"n\": 8614, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.51, \"learn_time_ms\": 27174.871}", "{\"n\": 8615, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.51, \"learn_time_ms\": 27181.313}", "{\"n\": 8616, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.36, \"learn_time_ms\": 27160.699}", "{\"n\": 8617, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.15, \"learn_time_ms\": 27181.384}", "{\"n\": 8618, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.15, \"learn_time_ms\": 27216.943}", "{\"n\": 8619, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.3, \"learn_time_ms\": 27212.992}", "{\"n\": 8620, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.14, \"learn_time_ms\": 27235.435}", "{\"n\": 8621, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.14, \"learn_time_ms\": 27287.121}", "{\"n\": 8622, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.64, \"learn_time_ms\": 27302.549}", "{\"n\": 8623, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.61, \"learn_time_ms\": 27292.094}", "{\"n\": 8624, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.83, \"learn_time_ms\": 27272.94}", "{\"n\": 8625, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.34, \"learn_time_ms\": 27267.588}", "{\"n\": 8626, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.41, \"learn_time_ms\": 27241.999}", "{\"n\": 8627, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.41, \"learn_time_ms\": 27219.017}", "{\"n\": 8628, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.0, \"learn_time_ms\": 27201.847}", "{\"n\": 8629, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.13, \"learn_time_ms\": 27190.694}", "{\"n\": 8630, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.21, \"learn_time_ms\": 27181.774}", "{\"n\": 8631, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.72, \"learn_time_ms\": 27098.497}", "{\"n\": 8632, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.72, \"learn_time_ms\": 27097.693}", "{\"n\": 8633, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.57, \"learn_time_ms\": 27087.893}", "{\"n\": 8634, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.09, \"learn_time_ms\": 27090.223}", "{\"n\": 8635, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.96, \"learn_time_ms\": 27066.581}", "{\"n\": 8636, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.41, \"learn_time_ms\": 27098.699}", "{\"n\": 8637, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.69, \"learn_time_ms\": 27072.737}", "{\"n\": 8638, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.68, \"learn_time_ms\": 27080.241}", "{\"n\": 8639, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.83, \"learn_time_ms\": 27083.746}", "{\"n\": 8640, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.15, \"learn_time_ms\": 27095.989}", "{\"n\": 8641, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.4, \"learn_time_ms\": 27133.813}", "{\"n\": 8642, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.25, \"learn_time_ms\": 27107.354}", "{\"n\": 8643, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.35, \"learn_time_ms\": 27124.186}", "{\"n\": 8644, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.34, \"learn_time_ms\": 27148.487}", "{\"n\": 8645, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.95, \"learn_time_ms\": 27161.065}", "{\"n\": 8646, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.95, \"learn_time_ms\": 27114.07}", "{\"n\": 8647, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.89, \"learn_time_ms\": 27134.485}", "{\"n\": 8648, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.95, \"learn_time_ms\": 27161.164}", "{\"n\": 8649, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.75, \"learn_time_ms\": 27146.889}", "{\"n\": 8650, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.48, \"learn_time_ms\": 27149.779}", "{\"n\": 8651, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.08, \"learn_time_ms\": 27161.182}", "{\"n\": 8652, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.87, \"learn_time_ms\": 27164.401}", "{\"n\": 8653, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.88, \"learn_time_ms\": 27153.353}", "{\"n\": 8654, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.66, \"learn_time_ms\": 27154.69}", "{\"n\": 8655, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.53, \"learn_time_ms\": 27152.013}", "{\"n\": 8656, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.28, \"learn_time_ms\": 27182.207}", "{\"n\": 8657, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.14, \"learn_time_ms\": 27132.916}", "{\"n\": 8658, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.3, \"learn_time_ms\": 27130.135}", "{\"n\": 8659, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.75, \"learn_time_ms\": 27137.509}", "{\"n\": 8660, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.23, \"learn_time_ms\": 27141.839}", "{\"n\": 8661, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.34, \"learn_time_ms\": 27132.535}", "{\"n\": 8662, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.44, \"learn_time_ms\": 27138.484}", "{\"n\": 8663, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.91, \"learn_time_ms\": 27184.942}", "{\"n\": 8664, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.27, \"learn_time_ms\": 27176.659}", "{\"n\": 8665, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.82, \"learn_time_ms\": 27209.025}", "{\"n\": 8666, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.24, \"learn_time_ms\": 27200.973}", "{\"n\": 8667, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.03, \"learn_time_ms\": 27212.448}", "{\"n\": 8668, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.94, \"learn_time_ms\": 27166.774}", "{\"n\": 8669, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.94, \"learn_time_ms\": 27152.578}", "{\"n\": 8670, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.12, \"learn_time_ms\": 27235.083}", "{\"n\": 8671, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.65, \"learn_time_ms\": 27223.375}", "{\"n\": 8672, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.65, \"learn_time_ms\": 27220.756}", "{\"n\": 8673, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.72, \"learn_time_ms\": 27192.455}", "{\"n\": 8674, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.63, \"learn_time_ms\": 27176.465}", "{\"n\": 8675, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.63, \"learn_time_ms\": 27153.514}", "{\"n\": 8676, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.83, \"learn_time_ms\": 27177.041}", "{\"n\": 8677, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.83, \"learn_time_ms\": 27220.587}", "{\"n\": 8678, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.35, \"learn_time_ms\": 27214.676}", "{\"n\": 8679, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.87, \"learn_time_ms\": 27223.463}", "{\"n\": 8680, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.09, \"learn_time_ms\": 27170.164}", "{\"n\": 8681, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.26, \"learn_time_ms\": 27169.12}", "{\"n\": 8682, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.5, \"learn_time_ms\": 27177.997}", "{\"n\": 8683, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.5, \"learn_time_ms\": 27167.67}", "{\"n\": 8684, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.26, \"learn_time_ms\": 27177.036}", "{\"n\": 8685, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.67, \"learn_time_ms\": 27177.803}", "{\"n\": 8686, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.15, \"learn_time_ms\": 27140.883}", "{\"n\": 8687, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.15, \"learn_time_ms\": 27109.381}", "{\"n\": 8688, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.23, \"learn_time_ms\": 27150.847}", "{\"n\": 8689, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.44, \"learn_time_ms\": 27084.505}", "{\"n\": 8690, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.62, \"learn_time_ms\": 27040.952}", "{\"n\": 8691, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.03, \"learn_time_ms\": 27043.559}", "{\"n\": 8692, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.26, \"learn_time_ms\": 27070.844}", "{\"n\": 8693, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.52, \"learn_time_ms\": 27054.957}", "{\"n\": 8694, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.52, \"learn_time_ms\": 27075.12}", "{\"n\": 8695, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.34, \"learn_time_ms\": 27078.003}", "{\"n\": 8696, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.61, \"learn_time_ms\": 27112.365}", "{\"n\": 8697, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.84, \"learn_time_ms\": 27150.534}", "{\"n\": 8698, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.54, \"learn_time_ms\": 27121.673}", "{\"n\": 8699, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.71, \"learn_time_ms\": 27198.798}", "{\"n\": 8700, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.71, \"learn_time_ms\": 27195.677}", "{\"n\": 8701, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.72, \"learn_time_ms\": 27177.344}", "{\"n\": 8702, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.87, \"learn_time_ms\": 27148.173}", "{\"n\": 8703, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.39, \"learn_time_ms\": 27178.708}", "{\"n\": 8704, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.39, \"learn_time_ms\": 27193.698}", "{\"n\": 8705, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.48, \"learn_time_ms\": 27201.484}", "{\"n\": 8706, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.01, \"learn_time_ms\": 27193.655}", "{\"n\": 8707, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.74, \"learn_time_ms\": 27171.62}", "{\"n\": 8708, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.37, \"learn_time_ms\": 27121.151}", "{\"n\": 8709, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.37, \"learn_time_ms\": 27098.816}", "{\"n\": 8710, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.89, \"learn_time_ms\": 27082.772}", "{\"n\": 8711, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.77, \"learn_time_ms\": 27061.248}", "{\"n\": 8712, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.13, \"learn_time_ms\": 27078.683}", "{\"n\": 8713, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.86, \"learn_time_ms\": 27065.213}", "{\"n\": 8714, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.86, \"learn_time_ms\": 27021.949}", "{\"n\": 8715, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.43, \"learn_time_ms\": 27010.94}", "{\"n\": 8716, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.43, \"learn_time_ms\": 27049.917}", "{\"n\": 8717, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.81, \"learn_time_ms\": 27048.206}", "{\"n\": 8718, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.81, \"learn_time_ms\": 27075.911}", "{\"n\": 8719, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.85, \"learn_time_ms\": 27119.287}", "{\"n\": 8720, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.14, \"learn_time_ms\": 27135.117}", "{\"n\": 8721, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.14, \"learn_time_ms\": 27188.43}", "{\"n\": 8722, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.18, \"learn_time_ms\": 27162.515}", "{\"n\": 8723, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.91, \"learn_time_ms\": 27174.994}", "{\"n\": 8724, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.54, \"learn_time_ms\": 27163.036}", "{\"n\": 8725, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.07, \"learn_time_ms\": 27117.836}", "{\"n\": 8726, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.5, \"learn_time_ms\": 27063.3}", "{\"n\": 8727, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.5, \"learn_time_ms\": 27064.026}", "{\"n\": 8728, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.35, \"learn_time_ms\": 27062.123}", "{\"n\": 8729, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.39, \"learn_time_ms\": 27067.323}", "{\"n\": 8730, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.64, \"learn_time_ms\": 27086.583}", "{\"n\": 8731, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.98, \"learn_time_ms\": 27051.865}", "{\"n\": 8732, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.98, \"learn_time_ms\": 27068.314}", "{\"n\": 8733, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.69, \"learn_time_ms\": 26991.308}", "{\"n\": 8734, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.51, \"learn_time_ms\": 27024.957}", "{\"n\": 8735, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.78, \"learn_time_ms\": 27069.765}", "{\"n\": 8736, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.47, \"learn_time_ms\": 27028.838}", "{\"n\": 8737, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.47, \"learn_time_ms\": 27009.944}", "{\"n\": 8738, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.22, \"learn_time_ms\": 27015.725}", "{\"n\": 8739, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.06, \"learn_time_ms\": 26983.791}", "{\"n\": 8740, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.06, \"learn_time_ms\": 26951.44}", "{\"n\": 8741, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.37, \"learn_time_ms\": 26950.23}", "{\"n\": 8742, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.6, \"learn_time_ms\": 26906.749}", "{\"n\": 8743, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.6, \"learn_time_ms\": 26986.749}", "{\"n\": 8744, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.72, \"learn_time_ms\": 26989.302}", "{\"n\": 8745, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.46, \"learn_time_ms\": 26942.27}", "{\"n\": 8746, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.46, \"learn_time_ms\": 26969.97}", "{\"n\": 8747, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.04, \"learn_time_ms\": 26969.057}", "{\"n\": 8748, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.42, \"learn_time_ms\": 26978.979}", "{\"n\": 8749, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.42, \"learn_time_ms\": 26989.893}", "{\"n\": 8750, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.82, \"learn_time_ms\": 27006.96}", "{\"n\": 8751, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.75, \"learn_time_ms\": 26995.119}", "{\"n\": 8752, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.67, \"learn_time_ms\": 27018.875}", "{\"n\": 8753, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.92, \"learn_time_ms\": 27032.506}", "{\"n\": 8754, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.92, \"learn_time_ms\": 26977.256}", "{\"n\": 8755, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.72, \"learn_time_ms\": 27048.121}", "{\"n\": 8756, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.98, \"learn_time_ms\": 27041.847}", "{\"n\": 8757, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.84, \"learn_time_ms\": 27038.86}", "{\"n\": 8758, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.98, \"learn_time_ms\": 27036.573}", "{\"n\": 8759, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.86, \"learn_time_ms\": 27007.651}", "{\"n\": 8760, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.86, \"learn_time_ms\": 26997.586}", "{\"n\": 8761, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.39, \"learn_time_ms\": 27042.48}", "{\"n\": 8762, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.16, \"learn_time_ms\": 27056.893}", "{\"n\": 8763, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.33, \"learn_time_ms\": 27064.598}", "{\"n\": 8764, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.4, \"learn_time_ms\": 27118.459}", "{\"n\": 8765, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.4, \"learn_time_ms\": 27111.344}", "{\"n\": 8766, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.4, \"learn_time_ms\": 27137.992}", "{\"n\": 8767, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.91, \"learn_time_ms\": 27167.245}", "{\"n\": 8768, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.56, \"learn_time_ms\": 27151.666}", "{\"n\": 8769, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.07, \"learn_time_ms\": 27181.203}", "{\"n\": 8770, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.02, \"learn_time_ms\": 27174.524}", "{\"n\": 8771, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.02, \"learn_time_ms\": 27175.409}", "{\"n\": 8772, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.78, \"learn_time_ms\": 27183.732}", "{\"n\": 8773, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.54, \"learn_time_ms\": 27104.176}", "{\"n\": 8774, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.24, \"learn_time_ms\": 27086.1}", "{\"n\": 8775, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.05, \"learn_time_ms\": 27062.84}", "{\"n\": 8776, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.13, \"learn_time_ms\": 27076.415}", "{\"n\": 8777, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.13, \"learn_time_ms\": 27043.682}", "{\"n\": 8778, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.52, \"learn_time_ms\": 27050.087}", "{\"n\": 8779, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.09, \"learn_time_ms\": 27055.381}", "{\"n\": 8780, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.29, \"learn_time_ms\": 27031.515}", "{\"n\": 8781, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.52, \"learn_time_ms\": 26965.599}", "{\"n\": 8782, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.52, \"learn_time_ms\": 26923.728}", "{\"n\": 8783, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.52, \"learn_time_ms\": 26936.051}", "{\"n\": 8784, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.31, \"learn_time_ms\": 26940.98}", "{\"n\": 8785, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.73, \"learn_time_ms\": 26944.582}", "{\"n\": 8786, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.93, \"learn_time_ms\": 26950.39}", "{\"n\": 8787, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.93, \"learn_time_ms\": 26957.273}", "{\"n\": 8788, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.78, \"learn_time_ms\": 26948.989}", "{\"n\": 8789, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.78, \"learn_time_ms\": 26952.231}", "{\"n\": 8790, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.29, \"learn_time_ms\": 27003.323}", "{\"n\": 8791, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.98, \"learn_time_ms\": 27071.835}", "{\"n\": 8792, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.29, \"learn_time_ms\": 27097.59}", "{\"n\": 8793, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.29, \"learn_time_ms\": 27126.083}", "{\"n\": 8794, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.15, \"learn_time_ms\": 27099.229}", "{\"n\": 8795, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.48, \"learn_time_ms\": 27116.371}", "{\"n\": 8796, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.9, \"learn_time_ms\": 27102.123}", "{\"n\": 8797, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.22, \"learn_time_ms\": 27135.939}", "{\"n\": 8798, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.94, \"learn_time_ms\": 27152.593}", "{\"n\": 8799, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.63, \"learn_time_ms\": 27139.216}", "{\"n\": 8800, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.05, \"learn_time_ms\": 27117.861}", "{\"n\": 8801, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.05, \"learn_time_ms\": 27119.293}", "{\"n\": 8802, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.05, \"learn_time_ms\": 27138.315}", "{\"n\": 8803, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.89, \"learn_time_ms\": 27137.413}", "{\"n\": 8804, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.89, \"learn_time_ms\": 27157.178}", "{\"n\": 8805, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.78, \"learn_time_ms\": 27154.703}", "{\"n\": 8806, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.78, \"learn_time_ms\": 27128.72}", "{\"n\": 8807, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.78, \"learn_time_ms\": 27129.47}", "{\"n\": 8808, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.51, \"learn_time_ms\": 27157.116}", "{\"n\": 8809, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.74, \"learn_time_ms\": 27133.998}", "{\"n\": 8810, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.31, \"learn_time_ms\": 27153.667}", "{\"n\": 8811, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.8, \"learn_time_ms\": 27100.069}", "{\"n\": 8812, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.8, \"learn_time_ms\": 27078.982}", "{\"n\": 8813, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.26, \"learn_time_ms\": 27083.863}", "{\"n\": 8814, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.75, \"learn_time_ms\": 27076.874}", "{\"n\": 8815, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.29, \"learn_time_ms\": 27056.111}", "{\"n\": 8816, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.94, \"learn_time_ms\": 27098.638}", "{\"n\": 8817, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.94, \"learn_time_ms\": 27092.16}", "{\"n\": 8818, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.62, \"learn_time_ms\": 27107.401}", "{\"n\": 8819, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.71, \"learn_time_ms\": 27182.881}", "{\"n\": 8820, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.31, \"learn_time_ms\": 27167.737}", "{\"n\": 8821, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.19, \"learn_time_ms\": 27189.293}", "{\"n\": 8822, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.19, \"learn_time_ms\": 27182.399}", "{\"n\": 8823, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.61, \"learn_time_ms\": 27157.188}", "{\"n\": 8824, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.19, \"learn_time_ms\": 27173.506}", "{\"n\": 8825, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.65, \"learn_time_ms\": 27157.201}", "{\"n\": 8826, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.65, \"learn_time_ms\": 27090.867}", "{\"n\": 8827, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.85, \"learn_time_ms\": 27080.869}", "{\"n\": 8828, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.85, \"learn_time_ms\": 27043.218}", "{\"n\": 8829, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.85, \"learn_time_ms\": 26954.671}", "{\"n\": 8830, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.66, \"learn_time_ms\": 26954.555}", "{\"n\": 8831, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.66, \"learn_time_ms\": 26947.442}", "{\"n\": 8832, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.66, \"learn_time_ms\": 26938.903}", "{\"n\": 8833, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.66, \"learn_time_ms\": 26928.556}", "{\"n\": 8834, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3323.66, \"learn_time_ms\": 26917.218}", "{\"n\": 8835, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.3, \"learn_time_ms\": 26956.199}", "{\"n\": 8836, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.68, \"learn_time_ms\": 27001.407}", "{\"n\": 8837, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.29, \"learn_time_ms\": 27007.257}", "{\"n\": 8838, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.08, \"learn_time_ms\": 27017.694}", "{\"n\": 8839, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.08, \"learn_time_ms\": 27033.869}", "{\"n\": 8840, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.51, \"learn_time_ms\": 27025.088}", "{\"n\": 8841, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.27, \"learn_time_ms\": 27041.897}", "{\"n\": 8842, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.48, \"learn_time_ms\": 27067.184}", "{\"n\": 8843, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.51, \"learn_time_ms\": 27162.381}", "{\"n\": 8844, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.48, \"learn_time_ms\": 27151.954}", "{\"n\": 8845, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.48, \"learn_time_ms\": 27141.931}", "{\"n\": 8846, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.02, \"learn_time_ms\": 27138.369}", "{\"n\": 8847, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.96, \"learn_time_ms\": 27140.704}", "{\"n\": 8848, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3350.81, \"learn_time_ms\": 27143.154}", "{\"n\": 8849, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.97, \"learn_time_ms\": 27184.241}", "{\"n\": 8850, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.13, \"learn_time_ms\": 27209.751}", "{\"n\": 8851, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.22, \"learn_time_ms\": 27165.797}", "{\"n\": 8852, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.5, \"learn_time_ms\": 27118.451}", "{\"n\": 8853, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.84, \"learn_time_ms\": 27051.49}", "{\"n\": 8854, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.44, \"learn_time_ms\": 27083.038}", "{\"n\": 8855, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.68, \"learn_time_ms\": 27078.957}", "{\"n\": 8856, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.68, \"learn_time_ms\": 27098.249}", "{\"n\": 8857, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.75, \"learn_time_ms\": 27094.685}", "{\"n\": 8858, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.81, \"learn_time_ms\": 27066.666}", "{\"n\": 8859, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.95, \"learn_time_ms\": 27026.044}", "{\"n\": 8860, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.95, \"learn_time_ms\": 26993.793}", "{\"n\": 8861, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.45, \"learn_time_ms\": 27003.197}", "{\"n\": 8862, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.45, \"learn_time_ms\": 27067.076}", "{\"n\": 8863, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.41, \"learn_time_ms\": 27024.718}", "{\"n\": 8864, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.85, \"learn_time_ms\": 26961.707}", "{\"n\": 8865, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3347.37, \"learn_time_ms\": 26991.236}", "{\"n\": 8866, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3347.37, \"learn_time_ms\": 26968.035}", "{\"n\": 8867, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3347.26, \"learn_time_ms\": 26943.699}", "{\"n\": 8868, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.04, \"learn_time_ms\": 26979.568}", "{\"n\": 8869, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3347.94, \"learn_time_ms\": 26969.317}", "{\"n\": 8870, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.79, \"learn_time_ms\": 27005.697}", "{\"n\": 8871, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 27000.958}", "{\"n\": 8872, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 27031.934}", "{\"n\": 8873, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.22, \"learn_time_ms\": 27083.551}", "{\"n\": 8874, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.55, \"learn_time_ms\": 27107.73}", "{\"n\": 8875, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.55, \"learn_time_ms\": 27089.626}", "{\"n\": 8876, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.05, \"learn_time_ms\": 27120.179}", "{\"n\": 8877, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.33, \"learn_time_ms\": 27140.539}", "{\"n\": 8878, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.46, \"learn_time_ms\": 27124.163}", "{\"n\": 8879, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.82, \"learn_time_ms\": 27134.895}", "{\"n\": 8880, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.56, \"learn_time_ms\": 27112.709}", "{\"n\": 8881, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.86, \"learn_time_ms\": 27164.167}", "{\"n\": 8882, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.35, \"learn_time_ms\": 27121.769}", "{\"n\": 8883, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.12, \"learn_time_ms\": 27117.201}", "{\"n\": 8884, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.12, \"learn_time_ms\": 27134.72}", "{\"n\": 8885, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.46, \"learn_time_ms\": 27115.633}", "{\"n\": 8886, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.46, \"learn_time_ms\": 27080.632}", "{\"n\": 8887, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.72, \"learn_time_ms\": 27077.921}", "{\"n\": 8888, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.83, \"learn_time_ms\": 27046.345}", "{\"n\": 8889, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.35, \"learn_time_ms\": 27015.11}", "{\"n\": 8890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.35, \"learn_time_ms\": 27048.632}", "{\"n\": 8891, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.32, \"learn_time_ms\": 27041.035}", "{\"n\": 8892, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.64, \"learn_time_ms\": 27032.339}", "{\"n\": 8893, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.84, \"learn_time_ms\": 27016.513}", "{\"n\": 8894, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.04, \"learn_time_ms\": 27038.349}", "{\"n\": 8895, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.04, \"learn_time_ms\": 27058.342}", "{\"n\": 8896, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.79, \"learn_time_ms\": 27097.052}", "{\"n\": 8897, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.88, \"learn_time_ms\": 27084.098}", "{\"n\": 8898, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.46, \"learn_time_ms\": 27127.73}", "{\"n\": 8899, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.79, \"learn_time_ms\": 27148.974}", "{\"n\": 8900, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.85, \"learn_time_ms\": 27148.151}", "{\"n\": 8901, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.91, \"learn_time_ms\": 27140.389}", "{\"n\": 8902, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.91, \"learn_time_ms\": 27109.841}", "{\"n\": 8903, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.29, \"learn_time_ms\": 27102.404}", "{\"n\": 8904, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.44, \"learn_time_ms\": 27103.099}", "{\"n\": 8905, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.83, \"learn_time_ms\": 27101.167}", "{\"n\": 8906, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.27, \"learn_time_ms\": 27056.175}", "{\"n\": 8907, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.27, \"learn_time_ms\": 27068.821}", "{\"n\": 8908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.86, \"learn_time_ms\": 27048.189}", "{\"n\": 8909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.15, \"learn_time_ms\": 27077.511}", "{\"n\": 8910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.1, \"learn_time_ms\": 27059.647}", "{\"n\": 8911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.41, \"learn_time_ms\": 27088.13}", "{\"n\": 8912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.76, \"learn_time_ms\": 27129.342}", "{\"n\": 8913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.76, \"learn_time_ms\": 27171.085}", "{\"n\": 8914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.89, \"learn_time_ms\": 27128.194}", "{\"n\": 8915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.85, \"learn_time_ms\": 27134.528}", "{\"n\": 8916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.12, \"learn_time_ms\": 27193.848}", "{\"n\": 8917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.4, \"learn_time_ms\": 27198.438}", "{\"n\": 8918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.4, \"learn_time_ms\": 27202.94}", "{\"n\": 8919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.75, \"learn_time_ms\": 27219.273}", "{\"n\": 8920, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.81, \"learn_time_ms\": 27201.691}", "{\"n\": 8921, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.15, \"learn_time_ms\": 27160.849}", "{\"n\": 8922, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.49, \"learn_time_ms\": 27141.281}", "{\"n\": 8923, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.49, \"learn_time_ms\": 27153.818}", "{\"n\": 8924, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.49, \"learn_time_ms\": 27166.055}", "{\"n\": 8925, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.32, \"learn_time_ms\": 27156.527}", "{\"n\": 8926, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.64, \"learn_time_ms\": 27145.536}", "{\"n\": 8927, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.38, \"learn_time_ms\": 27157.19}", "{\"n\": 8928, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.38, \"learn_time_ms\": 27184.758}", "{\"n\": 8929, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.38, \"learn_time_ms\": 27141.415}", "{\"n\": 8930, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.09, \"learn_time_ms\": 27169.031}", "{\"n\": 8931, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.29, \"learn_time_ms\": 27189.282}", "{\"n\": 8932, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.22, \"learn_time_ms\": 27215.08}", "{\"n\": 8933, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.12, \"learn_time_ms\": 27221.921}", "{\"n\": 8934, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.12, \"learn_time_ms\": 27242.105}", "{\"n\": 8935, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3324.35, \"learn_time_ms\": 27230.996}", "{\"n\": 8936, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3324.94, \"learn_time_ms\": 27220.811}", "{\"n\": 8937, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3320.95, \"learn_time_ms\": 27185.206}", "{\"n\": 8938, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3314.52, \"learn_time_ms\": 27135.351}", "{\"n\": 8939, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3314.52, \"learn_time_ms\": 27162.673}", "{\"n\": 8940, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3314.52, \"learn_time_ms\": 27137.985}", "{\"n\": 8941, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.38, \"learn_time_ms\": 27165.108}", "{\"n\": 8942, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.47, \"learn_time_ms\": 27121.864}", "{\"n\": 8943, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.75, \"learn_time_ms\": 27061.772}", "{\"n\": 8944, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.58, \"learn_time_ms\": 27041.516}", "{\"n\": 8945, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.58, \"learn_time_ms\": 27061.456}", "{\"n\": 8946, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3298.11, \"learn_time_ms\": 27062.665}", "{\"n\": 8947, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3299.24, \"learn_time_ms\": 27069.727}", "{\"n\": 8948, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3294.06, \"learn_time_ms\": 27082.21}", "{\"n\": 8949, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3286.1, \"learn_time_ms\": 27084.614}", "{\"n\": 8950, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3286.58, \"learn_time_ms\": 27079.602}", "{\"n\": 8951, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3286.58, \"learn_time_ms\": 27089.214}", "{\"n\": 8952, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3281.69, \"learn_time_ms\": 27117.887}", "{\"n\": 8953, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3286.03, \"learn_time_ms\": 27101.515}", "{\"n\": 8954, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3281.33, \"learn_time_ms\": 27121.221}", "{\"n\": 8955, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3278.35, \"learn_time_ms\": 27134.104}", "{\"n\": 8956, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3283.6, \"learn_time_ms\": 27081.15}", "{\"n\": 8957, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3283.6, \"learn_time_ms\": 27093.843}", "{\"n\": 8958, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3282.95, \"learn_time_ms\": 27140.722}", "{\"n\": 8959, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3276.93, \"learn_time_ms\": 27111.092}", "{\"n\": 8960, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3281.95, \"learn_time_ms\": 27133.818}", "{\"n\": 8961, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3286.49, \"learn_time_ms\": 27057.356}", "{\"n\": 8962, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3287.58, \"learn_time_ms\": 27066.092}", "{\"n\": 8963, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3296.59, \"learn_time_ms\": 27071.484}", "{\"n\": 8964, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3302.7, \"learn_time_ms\": 27104.104}", "{\"n\": 8965, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3315.46, \"learn_time_ms\": 27086.612}", "{\"n\": 8966, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3318.47, \"learn_time_ms\": 27106.197}", "{\"n\": 8967, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.79, \"learn_time_ms\": 27115.698}", "{\"n\": 8968, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.79, \"learn_time_ms\": 27103.838}", "{\"n\": 8969, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.09, \"learn_time_ms\": 27094.756}", "{\"n\": 8970, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3320.91, \"learn_time_ms\": 27120.979}", "{\"n\": 8971, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.64, \"learn_time_ms\": 27158.049}", "{\"n\": 8972, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3324.78, \"learn_time_ms\": 27107.581}", "{\"n\": 8973, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.8, \"learn_time_ms\": 27144.445}", "{\"n\": 8974, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.8, \"learn_time_ms\": 27085.529}", "{\"n\": 8975, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.49, \"learn_time_ms\": 27124.892}", "{\"n\": 8976, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.32, \"learn_time_ms\": 27160.083}", "{\"n\": 8977, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.6, \"learn_time_ms\": 27170.303}", "{\"n\": 8978, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.05, \"learn_time_ms\": 27173.334}", "{\"n\": 8979, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.05, \"learn_time_ms\": 27219.313}", "{\"n\": 8980, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3335.57, \"learn_time_ms\": 27204.796}", "{\"n\": 8981, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.35, \"learn_time_ms\": 27184.958}", "{\"n\": 8982, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3336.64, \"learn_time_ms\": 27250.3}", "{\"n\": 8983, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3331.54, \"learn_time_ms\": 27232.271}", "{\"n\": 8984, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3335.12, \"learn_time_ms\": 27237.311}", "{\"n\": 8985, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.61, \"learn_time_ms\": 27185.684}", "{\"n\": 8986, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.39, \"learn_time_ms\": 27156.245}", "{\"n\": 8987, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.05, \"learn_time_ms\": 27150.418}", "{\"n\": 8988, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.51, \"learn_time_ms\": 27104.723}", "{\"n\": 8989, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.46, \"learn_time_ms\": 27078.93}", "{\"n\": 8990, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.46, \"learn_time_ms\": 27040.801}", "{\"n\": 8991, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.9, \"learn_time_ms\": 27069.968}", "{\"n\": 8992, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.47, \"learn_time_ms\": 27059.387}", "{\"n\": 8993, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.89, \"learn_time_ms\": 27074.25}", "{\"n\": 8994, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3330.14, \"learn_time_ms\": 27098.475}", "{\"n\": 8995, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3330.14, \"learn_time_ms\": 27136.963}", "{\"n\": 8996, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3330.71, \"learn_time_ms\": 27153.345}", "{\"n\": 8997, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3330.55, \"learn_time_ms\": 27159.625}", "{\"n\": 8998, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.24, \"learn_time_ms\": 27211.452}", "{\"n\": 8999, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.24, \"learn_time_ms\": 27217.088}", "{\"n\": 9000, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.67, \"learn_time_ms\": 27239.326}"]["{\"n\": 9001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29025.762}", "{\"n\": 9002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28893.578}", "{\"n\": 9003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28737.7}", "{\"n\": 9004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28666.173}", "{\"n\": 9005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28659.02}", "{\"n\": 9006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28656.122}", "{\"n\": 9007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28593.634}", "{\"n\": 9008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28568.613}", "{\"n\": 9009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28496.35}", "{\"n\": 9010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28413.718}", "{\"n\": 9011, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3237.3333333333335, \"learn_time_ms\": 28331.871}", "{\"n\": 9012, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3449.25, \"learn_time_ms\": 28313.433}", "{\"n\": 9013, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3449.25, \"learn_time_ms\": 28305.629}", "{\"n\": 9014, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3449.25, \"learn_time_ms\": 28224.085}", "{\"n\": 9015, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3449.25, \"learn_time_ms\": 28214.434}", "{\"n\": 9016, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.555555555555555, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3417.3333333333335, \"learn_time_ms\": 28145.992}", "{\"n\": 9017, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -6.071428571428571, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.0714285714284, \"learn_time_ms\": 28156.41}", "{\"n\": 9018, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -6.125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.0625, \"learn_time_ms\": 28132.843}", "{\"n\": 9019, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -6.125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.0625, \"learn_time_ms\": 28155.359}", "{\"n\": 9020, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -6.125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.0625, \"learn_time_ms\": 28230.707}", "{\"n\": 9021, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -6.125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.0625, \"learn_time_ms\": 28271.765}", "{\"n\": 9022, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.888888888888889, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.3888888888887, \"learn_time_ms\": 28264.662}", "{\"n\": 9023, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.863636363636363, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3370.681818181818, \"learn_time_ms\": 28289.69}", "{\"n\": 9024, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.791666666666667, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.875, \"learn_time_ms\": 28391.847}", "{\"n\": 9025, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.791666666666667, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.875, \"learn_time_ms\": 28379.61}", "{\"n\": 9026, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.791666666666667, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.875, \"learn_time_ms\": 28427.939}", "{\"n\": 9027, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.791666666666667, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.875, \"learn_time_ms\": 28407.605}", "{\"n\": 9028, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.928571428571429, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.8571428571427, \"learn_time_ms\": 28389.292}", "{\"n\": 9029, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6875, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3392.75, \"learn_time_ms\": 28423.41}", "{\"n\": 9030, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6875, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3392.75, \"learn_time_ms\": 28374.917}", "{\"n\": 9031, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6875, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3392.75, \"learn_time_ms\": 28346.033}", "{\"n\": 9032, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6875, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3392.75, \"learn_time_ms\": 28375.897}", "{\"n\": 9033, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.777777777777778, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.6666666666665, \"learn_time_ms\": 28332.565}", "{\"n\": 9034, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6923076923076925, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3377.4102564102564, \"learn_time_ms\": 28300.395}", "{\"n\": 9035, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.875, \"learn_time_ms\": 28291.91}", "{\"n\": 9036, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.875, \"learn_time_ms\": 28255.202}", "{\"n\": 9037, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.875, \"learn_time_ms\": 28246.086}", "{\"n\": 9038, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.875, \"learn_time_ms\": 28259.642}", "{\"n\": 9039, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.804347826086956, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.782608695652, \"learn_time_ms\": 28277.351}", "{\"n\": 9040, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.833333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.5208333333335, \"learn_time_ms\": 28267.934}", "{\"n\": 9041, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.833333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.5208333333335, \"learn_time_ms\": 28275.014}", "{\"n\": 9042, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.833333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.5208333333335, \"learn_time_ms\": 28190.086}", "{\"n\": 9043, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.833333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.5208333333335, \"learn_time_ms\": 28222.349}", "{\"n\": 9044, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.584905660377358, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.509433962264, \"learn_time_ms\": 28215.79}", "{\"n\": 9045, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.654545454545454, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.7454545454543, \"learn_time_ms\": 28220.535}", "{\"n\": 9046, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.678571428571429, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.3571428571427, \"learn_time_ms\": 28192.829}", "{\"n\": 9047, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.678571428571429, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.3571428571427, \"learn_time_ms\": 28183.351}", "{\"n\": 9048, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.678571428571429, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3352.3571428571427, \"learn_time_ms\": 28160.086}", "{\"n\": 9049, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7368421052631575, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.6315789473683, \"learn_time_ms\": 28079.803}", "{\"n\": 9050, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.55, \"learn_time_ms\": 28104.772}", "{\"n\": 9051, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.84375, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.390625, \"learn_time_ms\": 28064.183}", "{\"n\": 9052, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.84375, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.390625, \"learn_time_ms\": 28099.351}", "{\"n\": 9053, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.84375, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.390625, \"learn_time_ms\": 28052.677}", "{\"n\": 9054, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.84375, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.390625, \"learn_time_ms\": 28033.48}", "{\"n\": 9055, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.861538461538461, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.2923076923075, \"learn_time_ms\": 27982.947}", "{\"n\": 9056, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.785714285714286, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.9142857142856, \"learn_time_ms\": 28012.778}", "{\"n\": 9057, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.777777777777778, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.8333333333335, \"learn_time_ms\": 28022.981}", "{\"n\": 9058, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.777777777777778, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.8333333333335, \"learn_time_ms\": 27998.715}", "{\"n\": 9059, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.777777777777778, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.8333333333335, \"learn_time_ms\": 28045.309}", "{\"n\": 9060, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.777777777777778, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.8333333333335, \"learn_time_ms\": 28007.682}", "{\"n\": 9061, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.766233766233766, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3338.844155844156, \"learn_time_ms\": 27968.491}", "{\"n\": 9062, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 27965.916}", "{\"n\": 9063, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 27975.672}", "{\"n\": 9064, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 27999.395}", "{\"n\": 9065, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 27986.888}", "{\"n\": 9066, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.695121951219512, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3347.3048780487807, \"learn_time_ms\": 27961.49}", "{\"n\": 9067, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.747126436781609, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.0114942528735, \"learn_time_ms\": 27977.994}", "{\"n\": 9068, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.761363636363637, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.625, \"learn_time_ms\": 28010.902}", "{\"n\": 9069, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.761363636363637, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.625, \"learn_time_ms\": 27951.263}", "{\"n\": 9070, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.761363636363637, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3343.625, \"learn_time_ms\": 27974.622}", "{\"n\": 9071, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.775280898876405, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.0224719101125, \"learn_time_ms\": 27998.001}", "{\"n\": 9072, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.720430107526882, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.1505376344085, \"learn_time_ms\": 27958.44}", "{\"n\": 9073, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.760416666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.1145833333335, \"learn_time_ms\": 27975.546}", "{\"n\": 9074, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.760416666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.1145833333335, \"learn_time_ms\": 27967.785}", "{\"n\": 9075, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.760416666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.1145833333335, \"learn_time_ms\": 28020.567}", "{\"n\": 9076, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76530612244898, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.4489795918366, \"learn_time_ms\": 28031.769}", "{\"n\": 9077, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76530612244898, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.4489795918366, \"learn_time_ms\": 27999.328}", "{\"n\": 9078, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.43, \"learn_time_ms\": 28022.001}", "{\"n\": 9079, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.5, \"learn_time_ms\": 28024.443}", "{\"n\": 9080, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.5, \"learn_time_ms\": 28065.882}", "{\"n\": 9081, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.5, \"learn_time_ms\": 28109.948}", "{\"n\": 9082, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.98, \"learn_time_ms\": 28099.471}", "{\"n\": 9083, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.37, \"learn_time_ms\": 28080.593}", "{\"n\": 9084, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3318.19, \"learn_time_ms\": 28073.244}", "{\"n\": 9085, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3318.19, \"learn_time_ms\": 28047.302}", "{\"n\": 9086, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3318.19, \"learn_time_ms\": 28075.832}", "{\"n\": 9087, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3321.02, \"learn_time_ms\": 28136.91}", "{\"n\": 9088, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.21, \"learn_time_ms\": 28163.7}", "{\"n\": 9089, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.64, \"learn_time_ms\": 28194.812}", "{\"n\": 9090, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.15, \"learn_time_ms\": 28153.614}", "{\"n\": 9091, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.15, \"learn_time_ms\": 28136.054}", "{\"n\": 9092, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.15, \"learn_time_ms\": 28184.375}", "{\"n\": 9093, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3320.85, \"learn_time_ms\": 28150.375}", "{\"n\": 9094, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3320.85, \"learn_time_ms\": 28144.629}", "{\"n\": 9095, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.14, \"learn_time_ms\": 28156.2}", "{\"n\": 9096, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3322.45, \"learn_time_ms\": 28155.372}", "{\"n\": 9097, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3322.45, \"learn_time_ms\": 28130.888}", "{\"n\": 9098, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3322.45, \"learn_time_ms\": 28078.695}", "{\"n\": 9099, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3317.64, \"learn_time_ms\": 28062.542}", "{\"n\": 9100, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.35, \"learn_time_ms\": 28052.54}", "{\"n\": 9101, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.96, \"learn_time_ms\": 28052.45}", "{\"n\": 9102, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.55, \"learn_time_ms\": 28044.953}", "{\"n\": 9103, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.55, \"learn_time_ms\": 28051.122}", "{\"n\": 9104, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.44, \"learn_time_ms\": 28044.401}", "{\"n\": 9105, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.85, \"learn_time_ms\": 28063.948}", "{\"n\": 9106, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.81, \"learn_time_ms\": 28000.86}", "{\"n\": 9107, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.83, \"learn_time_ms\": 27967.895}", "{\"n\": 9108, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.83, \"learn_time_ms\": 27976.847}", "{\"n\": 9109, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.83, \"learn_time_ms\": 27990.724}", "{\"n\": 9110, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3334.8, \"learn_time_ms\": 27984.051}", "{\"n\": 9111, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3329.98, \"learn_time_ms\": 27992.255}", "{\"n\": 9112, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.94, \"learn_time_ms\": 27985.367}", "{\"n\": 9113, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.89, \"learn_time_ms\": 27966.137}", "{\"n\": 9114, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.89, \"learn_time_ms\": 27966.175}", "{\"n\": 9115, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.89, \"learn_time_ms\": 27932.97}", "{\"n\": 9116, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.48, \"learn_time_ms\": 27983.635}", "{\"n\": 9117, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.95, \"learn_time_ms\": 28005.237}", "{\"n\": 9118, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.21, \"learn_time_ms\": 28050.484}", "{\"n\": 9119, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.21, \"learn_time_ms\": 28067.478}", "{\"n\": 9120, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.21, \"learn_time_ms\": 28084.447}", "{\"n\": 9121, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.44, \"learn_time_ms\": 28068.794}", "{\"n\": 9122, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3341.85, \"learn_time_ms\": 28045.566}", "{\"n\": 9123, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3336.24, \"learn_time_ms\": 28092.12}", "{\"n\": 9124, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.08, \"learn_time_ms\": 28126.635}", "{\"n\": 9125, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.08, \"learn_time_ms\": 28116.942}", "{\"n\": 9126, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.08, \"learn_time_ms\": 28120.319}", "{\"n\": 9127, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.73, \"learn_time_ms\": 28140.893}", "{\"n\": 9128, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3330.34, \"learn_time_ms\": 28079.323}", "{\"n\": 9129, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.85, \"learn_time_ms\": 28076.155}", "{\"n\": 9130, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.96, \"learn_time_ms\": 28076.248}", "{\"n\": 9131, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.96, \"learn_time_ms\": 28064.996}", "{\"n\": 9132, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3339.76, \"learn_time_ms\": 28083.305}", "{\"n\": 9133, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3335.4, \"learn_time_ms\": 28084.765}", "{\"n\": 9134, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.31, \"learn_time_ms\": 28044.911}", "{\"n\": 9135, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.51, \"learn_time_ms\": 28066.823}", "{\"n\": 9136, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.44, \"learn_time_ms\": 28087.929}", "{\"n\": 9137, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.44, \"learn_time_ms\": 28091.644}", "{\"n\": 9138, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.08, \"learn_time_ms\": 28148.311}", "{\"n\": 9139, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3345.96, \"learn_time_ms\": 28161.908}", "{\"n\": 9140, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.19, \"learn_time_ms\": 28155.619}", "{\"n\": 9141, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.19, \"learn_time_ms\": 28165.456}", "{\"n\": 9142, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.71, \"learn_time_ms\": 28120.347}", "{\"n\": 9143, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.71, \"learn_time_ms\": 28160.506}", "{\"n\": 9144, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.33, \"learn_time_ms\": 28180.718}", "{\"n\": 9145, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.33, \"learn_time_ms\": 28157.796}", "{\"n\": 9146, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3351.47, \"learn_time_ms\": 28111.068}", "{\"n\": 9147, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.82, \"learn_time_ms\": 28096.862}", "{\"n\": 9148, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.82, \"learn_time_ms\": 27975.402}", "{\"n\": 9149, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.73, \"learn_time_ms\": 27898.505}", "{\"n\": 9150, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3367.67, \"learn_time_ms\": 27902.095}", "{\"n\": 9151, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.98, \"learn_time_ms\": 27898.5}", "{\"n\": 9152, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.66, \"learn_time_ms\": 27902.265}", "{\"n\": 9153, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.66, \"learn_time_ms\": 27825.599}", "{\"n\": 9154, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3386.18, \"learn_time_ms\": 27799.916}", "{\"n\": 9155, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3383.53, \"learn_time_ms\": 27796.73}", "{\"n\": 9156, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.07, \"learn_time_ms\": 27770.959}", "{\"n\": 9157, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.19, \"learn_time_ms\": 27712.435}", "{\"n\": 9158, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.41, \"learn_time_ms\": 27758.572}", "{\"n\": 9159, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.51, \"learn_time_ms\": 27761.012}", "{\"n\": 9160, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.78, \"learn_time_ms\": 27711.487}", "{\"n\": 9161, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.05, \"learn_time_ms\": 27755.704}", "{\"n\": 9162, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.44, \"learn_time_ms\": 27780.983}", "{\"n\": 9163, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.58, \"learn_time_ms\": 27773.038}", "{\"n\": 9164, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.79, \"learn_time_ms\": 27785.853}", "{\"n\": 9165, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.79, \"learn_time_ms\": 27817.399}", "{\"n\": 9166, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.93, \"learn_time_ms\": 27802.571}", "{\"n\": 9167, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.93, \"learn_time_ms\": 27818.625}", "{\"n\": 9168, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.77, \"learn_time_ms\": 27876.409}", "{\"n\": 9169, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.77, \"learn_time_ms\": 27965.044}", "{\"n\": 9170, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.27, \"learn_time_ms\": 28027.023}", "{\"n\": 9171, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.74, \"learn_time_ms\": 28008.695}", "{\"n\": 9172, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.22, \"learn_time_ms\": 27966.054}", "{\"n\": 9173, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.31, \"learn_time_ms\": 28007.728}", "{\"n\": 9174, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.31, \"learn_time_ms\": 27991.283}", "{\"n\": 9175, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.98, \"learn_time_ms\": 27952.606}", "{\"n\": 9176, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.18, \"learn_time_ms\": 28043.347}", "{\"n\": 9177, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.18, \"learn_time_ms\": 28068.923}", "{\"n\": 9178, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.49, \"learn_time_ms\": 28017.737}", "{\"n\": 9179, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.44, \"learn_time_ms\": 27981.776}", "{\"n\": 9180, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.01, \"learn_time_ms\": 27961.356}", "{\"n\": 9181, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.22, \"learn_time_ms\": 27915.609}", "{\"n\": 9182, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.01, \"learn_time_ms\": 27968.749}", "{\"n\": 9183, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.28, \"learn_time_ms\": 27955.253}", "{\"n\": 9184, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.16, \"learn_time_ms\": 27967.765}", "{\"n\": 9185, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.74, \"learn_time_ms\": 27971.325}", "{\"n\": 9186, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.74, \"learn_time_ms\": 27931.271}", "{\"n\": 9187, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.51, \"learn_time_ms\": 27901.622}", "{\"n\": 9188, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.51, \"learn_time_ms\": 27943.76}", "{\"n\": 9189, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.01, \"learn_time_ms\": 27939.273}", "{\"n\": 9190, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.09, \"learn_time_ms\": 27927.853}", "{\"n\": 9191, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.73, \"learn_time_ms\": 27929.751}", "{\"n\": 9192, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3422.97, \"learn_time_ms\": 27963.891}", "{\"n\": 9193, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3426.74, \"learn_time_ms\": 27960.012}", "{\"n\": 9194, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3430.61, \"learn_time_ms\": 27926.61}", "{\"n\": 9195, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3442.07, \"learn_time_ms\": 27932.336}", "{\"n\": 9196, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3438.68, \"learn_time_ms\": 27875.695}", "{\"n\": 9197, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3441.68, \"learn_time_ms\": 27873.028}", "{\"n\": 9198, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3444.66, \"learn_time_ms\": 27863.433}", "{\"n\": 9199, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.05, \"learn_time_ms\": 27859.419}", "{\"n\": 9200, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.06, \"learn_time_ms\": 27867.007}", "{\"n\": 9201, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.06, \"learn_time_ms\": 27890.293}", "{\"n\": 9202, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.17, \"learn_time_ms\": 27899.393}", "{\"n\": 9203, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3444.4, \"learn_time_ms\": 27890.44}", "{\"n\": 9204, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3448.01, \"learn_time_ms\": 27956.105}", "{\"n\": 9205, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3448.01, \"learn_time_ms\": 27972.605}", "{\"n\": 9206, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.51, \"learn_time_ms\": 28049.608}", "{\"n\": 9207, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.51, \"learn_time_ms\": 28073.472}", "{\"n\": 9208, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3436.34, \"learn_time_ms\": 28082.386}", "{\"n\": 9209, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.6, \"learn_time_ms\": 28140.423}", "{\"n\": 9210, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3440.68, \"learn_time_ms\": 28139.654}", "{\"n\": 9211, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3439.15, \"learn_time_ms\": 28177.061}", "{\"n\": 9212, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3438.62, \"learn_time_ms\": 28147.073}", "{\"n\": 9213, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3438.62, \"learn_time_ms\": 28146.855}", "{\"n\": 9214, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3440.88, \"learn_time_ms\": 28107.146}", "{\"n\": 9215, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3443.32, \"learn_time_ms\": 28117.702}", "{\"n\": 9216, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3443.32, \"learn_time_ms\": 28110.929}", "{\"n\": 9217, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3444.44, \"learn_time_ms\": 28151.364}", "{\"n\": 9218, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3448.86, \"learn_time_ms\": 28136.584}", "{\"n\": 9219, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3455.81, \"learn_time_ms\": 28080.14}", "{\"n\": 9220, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3452.23, \"learn_time_ms\": 28134.016}", "{\"n\": 9221, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3451.85, \"learn_time_ms\": 28077.151}", "{\"n\": 9222, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3457.02, \"learn_time_ms\": 28035.982}", "{\"n\": 9223, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3453.22, \"learn_time_ms\": 28070.413}", "{\"n\": 9224, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3453.22, \"learn_time_ms\": 28130.561}", "{\"n\": 9225, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3449.76, \"learn_time_ms\": 28096.341}", "{\"n\": 9226, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3449.76, \"learn_time_ms\": 28067.525}", "{\"n\": 9227, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3449.44, \"learn_time_ms\": 28069.584}", "{\"n\": 9228, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3446.42, \"learn_time_ms\": 28030.023}", "{\"n\": 9229, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3450.64, \"learn_time_ms\": 28005.107}", "{\"n\": 9230, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3451.32, \"learn_time_ms\": 27987.674}", "{\"n\": 9231, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3449.9, \"learn_time_ms\": 27990.412}", "{\"n\": 9232, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3449.9, \"learn_time_ms\": 28049.376}", "{\"n\": 9233, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3450.94, \"learn_time_ms\": 28034.526}", "{\"n\": 9234, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3449.88, \"learn_time_ms\": 27964.915}", "{\"n\": 9235, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3449.33, \"learn_time_ms\": 27971.879}", "{\"n\": 9236, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3443.77, \"learn_time_ms\": 27979.388}", "{\"n\": 9237, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3443.15, \"learn_time_ms\": 27953.916}", "{\"n\": 9238, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3443.15, \"learn_time_ms\": 27988.681}", "{\"n\": 9239, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.13, \"learn_time_ms\": 28025.338}", "{\"n\": 9240, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3434.08, \"learn_time_ms\": 27992.88}", "{\"n\": 9241, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3426.24, \"learn_time_ms\": 27988.349}", "{\"n\": 9242, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3431.59, \"learn_time_ms\": 27925.822}", "{\"n\": 9243, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3431.59, \"learn_time_ms\": 27960.291}", "{\"n\": 9244, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.77, \"learn_time_ms\": 27958.671}", "{\"n\": 9245, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.95, \"learn_time_ms\": 27940.356}", "{\"n\": 9246, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3436.65, \"learn_time_ms\": 27905.385}", "{\"n\": 9247, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.51, \"learn_time_ms\": 27898.125}", "{\"n\": 9248, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3434.43, \"learn_time_ms\": 27917.744}", "{\"n\": 9249, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.91, \"learn_time_ms\": 27935.321}", "{\"n\": 9250, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.91, \"learn_time_ms\": 27917.514}", "{\"n\": 9251, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3429.91, \"learn_time_ms\": 27918.118}", "{\"n\": 9252, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.31, \"learn_time_ms\": 27951.871}", "{\"n\": 9253, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.72, \"learn_time_ms\": 27906.908}", "{\"n\": 9254, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.72, \"learn_time_ms\": 27983.022}", "{\"n\": 9255, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.28, \"learn_time_ms\": 28031.138}", "{\"n\": 9256, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.23, \"learn_time_ms\": 28069.505}", "{\"n\": 9257, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.12, \"learn_time_ms\": 28068.654}", "{\"n\": 9258, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.6, \"learn_time_ms\": 28054.017}", "{\"n\": 9259, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.6, \"learn_time_ms\": 28022.018}", "{\"n\": 9260, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.6, \"learn_time_ms\": 28046.083}", "{\"n\": 9261, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.81, \"learn_time_ms\": 28051.401}", "{\"n\": 9262, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.71, \"learn_time_ms\": 28055.387}", "{\"n\": 9263, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.75, \"learn_time_ms\": 28049.117}", "{\"n\": 9264, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.32, \"learn_time_ms\": 28037.328}", "{\"n\": 9265, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.32, \"learn_time_ms\": 27996.566}", "{\"n\": 9266, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.74, \"learn_time_ms\": 27984.7}", "{\"n\": 9267, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.74, \"learn_time_ms\": 27990.997}", "{\"n\": 9268, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.98, \"learn_time_ms\": 27968.622}", "{\"n\": 9269, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.45, \"learn_time_ms\": 28024.159}", "{\"n\": 9270, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.45, \"learn_time_ms\": 28035.173}", "{\"n\": 9271, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.45, \"learn_time_ms\": 28053.437}", "{\"n\": 9272, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.16, \"learn_time_ms\": 28079.327}", "{\"n\": 9273, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.62, \"learn_time_ms\": 28073.995}", "{\"n\": 9274, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.97, \"learn_time_ms\": 28029.109}", "{\"n\": 9275, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.96, \"learn_time_ms\": 28045.105}", "{\"n\": 9276, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.96, \"learn_time_ms\": 28066.009}", "{\"n\": 9277, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.96, \"learn_time_ms\": 28074.876}", "{\"n\": 9278, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.44, \"learn_time_ms\": 28128.822}", "{\"n\": 9279, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.08, \"learn_time_ms\": 28083.803}", "{\"n\": 9280, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.54, \"learn_time_ms\": 28051.639}", "{\"n\": 9281, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.06, \"learn_time_ms\": 28059.247}", "{\"n\": 9282, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.06, \"learn_time_ms\": 28048.967}", "{\"n\": 9283, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.06, \"learn_time_ms\": 28036.614}", "{\"n\": 9284, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.02, \"learn_time_ms\": 28022.657}", "{\"n\": 9285, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.37, \"learn_time_ms\": 28017.749}", "{\"n\": 9286, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.41, \"learn_time_ms\": 28053.182}", "{\"n\": 9287, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.41, \"learn_time_ms\": 28022.328}", "{\"n\": 9288, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.41, \"learn_time_ms\": 27981.738}", "{\"n\": 9289, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.41, \"learn_time_ms\": 27985.438}", "{\"n\": 9290, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.53, \"learn_time_ms\": 27980.813}", "{\"n\": 9291, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.92, \"learn_time_ms\": 27963.866}", "{\"n\": 9292, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.3, \"learn_time_ms\": 27949.323}", "{\"n\": 9293, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.3, \"learn_time_ms\": 27985.992}", "{\"n\": 9294, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.3, \"learn_time_ms\": 27986.345}", "{\"n\": 9295, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.24, \"learn_time_ms\": 28001.049}", "{\"n\": 9296, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.86, \"learn_time_ms\": 27972.894}", "{\"n\": 9297, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.35, \"learn_time_ms\": 27966.97}", "{\"n\": 9298, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.99, \"learn_time_ms\": 27988.048}", "{\"n\": 9299, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.99, \"learn_time_ms\": 27956.333}", "{\"n\": 9300, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.47, \"learn_time_ms\": 27975.451}", "{\"n\": 9301, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.49, \"learn_time_ms\": 27998.524}", "{\"n\": 9302, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.75, \"learn_time_ms\": 27984.023}", "{\"n\": 9303, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.98, \"learn_time_ms\": 27999.304}", "{\"n\": 9304, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.98, \"learn_time_ms\": 28005.353}", "{\"n\": 9305, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.98, \"learn_time_ms\": 28032.669}", "{\"n\": 9306, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.5, \"learn_time_ms\": 28042.307}", "{\"n\": 9307, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.67, \"learn_time_ms\": 28056.504}", "{\"n\": 9308, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.74, \"learn_time_ms\": 28088.542}", "{\"n\": 9309, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.38, \"learn_time_ms\": 28136.269}", "{\"n\": 9310, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.38, \"learn_time_ms\": 28140.645}", "{\"n\": 9311, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.19, \"learn_time_ms\": 28108.543}", "{\"n\": 9312, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.66, \"learn_time_ms\": 28109.907}", "{\"n\": 9313, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.06, \"learn_time_ms\": 28086.693}", "{\"n\": 9314, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.47, \"learn_time_ms\": 28129.715}", "{\"n\": 9315, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.47, \"learn_time_ms\": 28086.327}", "{\"n\": 9316, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.73, \"learn_time_ms\": 28104.464}", "{\"n\": 9317, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.73, \"learn_time_ms\": 28107.009}", "{\"n\": 9318, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.11, \"learn_time_ms\": 28009.587}", "{\"n\": 9319, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.09, \"learn_time_ms\": 28050.012}", "{\"n\": 9320, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.25, \"learn_time_ms\": 28059.712}", "{\"n\": 9321, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.25, \"learn_time_ms\": 28076.25}", "{\"n\": 9322, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.48, \"learn_time_ms\": 28067.062}", "{\"n\": 9323, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.11, \"learn_time_ms\": 28069.99}", "{\"n\": 9324, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.54, \"learn_time_ms\": 28000.736}", "{\"n\": 9325, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.64, \"learn_time_ms\": 28024.182}", "{\"n\": 9326, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.64, \"learn_time_ms\": 27969.22}", "{\"n\": 9327, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.38, \"learn_time_ms\": 27963.953}", "{\"n\": 9328, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.69, \"learn_time_ms\": 28019.649}", "{\"n\": 9329, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.72, \"learn_time_ms\": 27930.37}", "{\"n\": 9330, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.64, \"learn_time_ms\": 27919.455}", "{\"n\": 9331, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.41, \"learn_time_ms\": 27927.543}", "{\"n\": 9332, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.41, \"learn_time_ms\": 27955.514}", "{\"n\": 9333, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.52, \"learn_time_ms\": 27943.253}", "{\"n\": 9334, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.23, \"learn_time_ms\": 27981.397}", "{\"n\": 9335, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.21, \"learn_time_ms\": 27957.039}", "{\"n\": 9336, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.16, \"learn_time_ms\": 27998.805}", "{\"n\": 9337, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.53, \"learn_time_ms\": 28020.029}", "{\"n\": 9338, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.53, \"learn_time_ms\": 28008.851}", "{\"n\": 9339, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.09, \"learn_time_ms\": 28046.463}", "{\"n\": 9340, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.52, \"learn_time_ms\": 28027.79}", "{\"n\": 9341, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.0, \"learn_time_ms\": 27985.176}", "{\"n\": 9342, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.0, \"learn_time_ms\": 27960.761}", "{\"n\": 9343, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.71, \"learn_time_ms\": 27988.327}", "{\"n\": 9344, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.51, \"learn_time_ms\": 27981.451}", "{\"n\": 9345, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.48, \"learn_time_ms\": 27991.438}", "{\"n\": 9346, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.67, \"learn_time_ms\": 27925.123}", "{\"n\": 9347, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.2, \"learn_time_ms\": 27906.17}", "{\"n\": 9348, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.62, \"learn_time_ms\": 27919.473}", "{\"n\": 9349, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.62, \"learn_time_ms\": 27849.116}", "{\"n\": 9350, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.9, \"learn_time_ms\": 27893.425}", "{\"n\": 9351, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.62, \"learn_time_ms\": 27905.663}", "{\"n\": 9352, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.23, \"learn_time_ms\": 27909.923}", "{\"n\": 9353, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.36, \"learn_time_ms\": 27870.921}", "{\"n\": 9354, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.75, \"learn_time_ms\": 27900.469}", "{\"n\": 9355, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.45, \"learn_time_ms\": 27947.13}", "{\"n\": 9356, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.45, \"learn_time_ms\": 27970.064}", "{\"n\": 9357, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.38, \"learn_time_ms\": 27939.977}", "{\"n\": 9358, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.44, \"learn_time_ms\": 27917.971}", "{\"n\": 9359, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.6, \"learn_time_ms\": 28021.439}", "{\"n\": 9360, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.28, \"learn_time_ms\": 28023.813}", "{\"n\": 9361, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.28, \"learn_time_ms\": 28026.734}", "{\"n\": 9362, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.22, \"learn_time_ms\": 28014.359}", "{\"n\": 9363, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.12, \"learn_time_ms\": 28079.412}", "{\"n\": 9364, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.0, \"learn_time_ms\": 28039.1}", "{\"n\": 9365, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.76, \"learn_time_ms\": 27978.718}", "{\"n\": 9366, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.35, \"learn_time_ms\": 28001.111}", "{\"n\": 9367, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.35, \"learn_time_ms\": 28059.965}", "{\"n\": 9368, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.96, \"learn_time_ms\": 28084.18}", "{\"n\": 9369, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.06, \"learn_time_ms\": 28010.846}", "{\"n\": 9370, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.19, \"learn_time_ms\": 27978.61}", "{\"n\": 9371, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.13, \"learn_time_ms\": 28013.912}", "{\"n\": 9372, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.0, \"learn_time_ms\": 27967.635}", "{\"n\": 9373, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.99, \"learn_time_ms\": 27947.539}", "{\"n\": 9374, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.54, \"learn_time_ms\": 27951.955}", "{\"n\": 9375, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.08, \"learn_time_ms\": 27941.594}", "{\"n\": 9376, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.36, \"learn_time_ms\": 27934.506}", "{\"n\": 9377, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.0, \"learn_time_ms\": 27941.169}", "{\"n\": 9378, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.0, \"learn_time_ms\": 27965.588}", "{\"n\": 9379, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.69, \"learn_time_ms\": 27990.268}", "{\"n\": 9380, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.39, \"learn_time_ms\": 28012.108}", "{\"n\": 9381, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.39, \"learn_time_ms\": 28037.281}", "{\"n\": 9382, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.82, \"learn_time_ms\": 28127.498}", "{\"n\": 9383, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.71, \"learn_time_ms\": 28125.401}", "{\"n\": 9384, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.71, \"learn_time_ms\": 28144.493}", "{\"n\": 9385, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.46, \"learn_time_ms\": 28180.282}", "{\"n\": 9386, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.35, \"learn_time_ms\": 28207.753}", "{\"n\": 9387, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.07, \"learn_time_ms\": 28155.144}", "{\"n\": 9388, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.28, \"learn_time_ms\": 28155.909}", "{\"n\": 9389, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.27, \"learn_time_ms\": 28157.031}", "{\"n\": 9390, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.32, \"learn_time_ms\": 28149.669}", "{\"n\": 9391, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.64, \"learn_time_ms\": 28104.392}", "{\"n\": 9392, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.64, \"learn_time_ms\": 28103.941}", "{\"n\": 9393, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.64, \"learn_time_ms\": 28089.036}", "{\"n\": 9394, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.85, \"learn_time_ms\": 28085.996}", "{\"n\": 9395, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.85, \"learn_time_ms\": 28117.262}", "{\"n\": 9396, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.56, \"learn_time_ms\": 28104.586}", "{\"n\": 9397, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.34, \"learn_time_ms\": 28134.535}", "{\"n\": 9398, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.34, \"learn_time_ms\": 28121.914}", "{\"n\": 9399, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.41, \"learn_time_ms\": 28124.221}", "{\"n\": 9400, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.08, \"learn_time_ms\": 28144.187}", "{\"n\": 9401, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.08, \"learn_time_ms\": 28144.859}", "{\"n\": 9402, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.61, \"learn_time_ms\": 28118.263}", "{\"n\": 9403, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.61, \"learn_time_ms\": 28109.073}", "{\"n\": 9404, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.61, \"learn_time_ms\": 28136.011}", "{\"n\": 9405, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.59, \"learn_time_ms\": 28106.11}", "{\"n\": 9406, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.59, \"learn_time_ms\": 28077.654}", "{\"n\": 9407, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.4, \"learn_time_ms\": 28053.521}", "{\"n\": 9408, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.13, \"learn_time_ms\": 28057.41}", "{\"n\": 9409, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.13, \"learn_time_ms\": 28034.366}", "{\"n\": 9410, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.15, \"learn_time_ms\": 28015.59}", "{\"n\": 9411, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.46, \"learn_time_ms\": 27988.067}", "{\"n\": 9412, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.46, \"learn_time_ms\": 28021.662}", "{\"n\": 9413, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.08, \"learn_time_ms\": 28007.375}", "{\"n\": 9414, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.16, \"learn_time_ms\": 27950.537}", "{\"n\": 9415, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.16, \"learn_time_ms\": 27980.144}", "{\"n\": 9416, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.6, \"learn_time_ms\": 27977.978}", "{\"n\": 9417, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.99, \"learn_time_ms\": 28012.275}", "{\"n\": 9418, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.39, \"learn_time_ms\": 27973.508}", "{\"n\": 9419, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.05, \"learn_time_ms\": 27991.14}", "{\"n\": 9420, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.18, \"learn_time_ms\": 28019.211}", "{\"n\": 9421, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.25, \"learn_time_ms\": 28070.862}", "{\"n\": 9422, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.11, \"learn_time_ms\": 28065.099}", "{\"n\": 9423, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.2, \"learn_time_ms\": 28078.545}", "{\"n\": 9424, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.78, \"learn_time_ms\": 28110.007}", "{\"n\": 9425, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.78, \"learn_time_ms\": 28063.239}", "{\"n\": 9426, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.25, \"learn_time_ms\": 28057.076}", "{\"n\": 9427, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.61, \"learn_time_ms\": 27994.409}", "{\"n\": 9428, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.51, \"learn_time_ms\": 28026.968}", "{\"n\": 9429, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.25, \"learn_time_ms\": 28031.491}", "{\"n\": 9430, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.22, \"learn_time_ms\": 28028.291}", "{\"n\": 9431, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.22, \"learn_time_ms\": 28030.758}", "{\"n\": 9432, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.03, \"learn_time_ms\": 27962.655}", "{\"n\": 9433, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.24, \"learn_time_ms\": 27986.896}", "{\"n\": 9434, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.01, \"learn_time_ms\": 27991.423}", "{\"n\": 9435, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.5, \"learn_time_ms\": 28030.317}", "{\"n\": 9436, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.5, \"learn_time_ms\": 28058.797}", "{\"n\": 9437, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.06, \"learn_time_ms\": 28085.47}", "{\"n\": 9438, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.61, \"learn_time_ms\": 28103.178}", "{\"n\": 9439, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.97, \"learn_time_ms\": 28117.321}", "{\"n\": 9440, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.75, \"learn_time_ms\": 28097.776}", "{\"n\": 9441, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.49, \"learn_time_ms\": 28043.847}", "{\"n\": 9442, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.31, \"learn_time_ms\": 28091.185}", "{\"n\": 9443, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.74, \"learn_time_ms\": 28069.126}", "{\"n\": 9444, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.38, \"learn_time_ms\": 28033.659}", "{\"n\": 9445, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.04, \"learn_time_ms\": 28011.469}", "{\"n\": 9446, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.04, \"learn_time_ms\": 27970.163}", "{\"n\": 9447, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.33, \"learn_time_ms\": 28003.096}", "{\"n\": 9448, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.31, \"learn_time_ms\": 27975.135}", "{\"n\": 9449, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.31, \"learn_time_ms\": 27933.446}", "{\"n\": 9450, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.95, \"learn_time_ms\": 27941.757}", "{\"n\": 9451, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.12, \"learn_time_ms\": 27996.915}", "{\"n\": 9452, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.73, \"learn_time_ms\": 27992.937}", "{\"n\": 9453, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.62, \"learn_time_ms\": 27994.009}", "{\"n\": 9454, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.5, \"learn_time_ms\": 27992.131}", "{\"n\": 9455, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.46, \"learn_time_ms\": 27969.043}", "{\"n\": 9456, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.26, \"learn_time_ms\": 27981.43}", "{\"n\": 9457, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.26, \"learn_time_ms\": 27951.873}", "{\"n\": 9458, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.93, \"learn_time_ms\": 27965.848}", "{\"n\": 9459, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.08, \"learn_time_ms\": 27973.591}", "{\"n\": 9460, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.81, \"learn_time_ms\": 27969.676}", "{\"n\": 9461, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.81, \"learn_time_ms\": 27960.432}", "{\"n\": 9462, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.48, \"learn_time_ms\": 27971.652}", "{\"n\": 9463, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.8, \"learn_time_ms\": 28037.073}", "{\"n\": 9464, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.13, \"learn_time_ms\": 28064.863}", "{\"n\": 9465, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.64, \"learn_time_ms\": 28067.839}", "{\"n\": 9466, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.42, \"learn_time_ms\": 28103.766}", "{\"n\": 9467, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.36, \"learn_time_ms\": 28160.092}", "{\"n\": 9468, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.36, \"learn_time_ms\": 28150.19}", "{\"n\": 9469, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.2, \"learn_time_ms\": 28144.874}", "{\"n\": 9470, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.08, \"learn_time_ms\": 28177.277}", "{\"n\": 9471, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.09, \"learn_time_ms\": 28178.814}", "{\"n\": 9472, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.79, \"learn_time_ms\": 28161.552}", "{\"n\": 9473, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.79, \"learn_time_ms\": 28097.89}", "{\"n\": 9474, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.76, \"learn_time_ms\": 28043.346}", "{\"n\": 9475, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.76, \"learn_time_ms\": 28015.225}", "{\"n\": 9476, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.1, \"learn_time_ms\": 28020.221}", "{\"n\": 9477, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.34, \"learn_time_ms\": 27973.01}", "{\"n\": 9478, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.57, \"learn_time_ms\": 27949.977}", "{\"n\": 9479, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.57, \"learn_time_ms\": 27964.598}", "{\"n\": 9480, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.55, \"learn_time_ms\": 27952.583}", "{\"n\": 9481, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.97, \"learn_time_ms\": 27969.912}", "{\"n\": 9482, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.65, \"learn_time_ms\": 27982.387}", "{\"n\": 9483, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.0, \"learn_time_ms\": 27980.175}", "{\"n\": 9484, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.0, \"learn_time_ms\": 28052.292}", "{\"n\": 9485, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.0, \"learn_time_ms\": 28111.213}", "{\"n\": 9486, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.55, \"learn_time_ms\": 28094.344}", "{\"n\": 9487, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.29, \"learn_time_ms\": 28095.042}", "{\"n\": 9488, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.29, \"learn_time_ms\": 28101.887}", "{\"n\": 9489, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.96, \"learn_time_ms\": 28093.031}", "{\"n\": 9490, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.96, \"learn_time_ms\": 28070.251}", "{\"n\": 9491, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.98, \"learn_time_ms\": 28042.035}", "{\"n\": 9492, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.1, \"learn_time_ms\": 28061.329}", "{\"n\": 9493, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.07, \"learn_time_ms\": 28074.748}", "{\"n\": 9494, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.66, \"learn_time_ms\": 28099.285}", "{\"n\": 9495, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.0, \"learn_time_ms\": 28099.372}", "{\"n\": 9496, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.0, \"learn_time_ms\": 28079.607}", "{\"n\": 9497, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.25, \"learn_time_ms\": 28057.609}", "{\"n\": 9498, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.34, \"learn_time_ms\": 28089.133}", "{\"n\": 9499, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.56, \"learn_time_ms\": 28134.509}", "{\"n\": 9500, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.56, \"learn_time_ms\": 28136.289}", "{\"n\": 9501, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.56, \"learn_time_ms\": 28127.613}", "{\"n\": 9502, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.4, \"learn_time_ms\": 28078.166}", "{\"n\": 9503, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.64, \"learn_time_ms\": 28047.208}", "{\"n\": 9504, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.54, \"learn_time_ms\": 28058.14}", "{\"n\": 9505, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.8, \"learn_time_ms\": 28056.446}", "{\"n\": 9506, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.43, \"learn_time_ms\": 28060.376}", "{\"n\": 9507, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.43, \"learn_time_ms\": 28076.93}", "{\"n\": 9508, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.64, \"learn_time_ms\": 28035.404}", "{\"n\": 9509, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.24, \"learn_time_ms\": 28031.951}", "{\"n\": 9510, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.69, \"learn_time_ms\": 28016.373}", "{\"n\": 9511, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.16, \"learn_time_ms\": 28019.93}", "{\"n\": 9512, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.16, \"learn_time_ms\": 28069.739}", "{\"n\": 9513, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.54, \"learn_time_ms\": 28106.023}", "{\"n\": 9514, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.18, \"learn_time_ms\": 28049.357}", "{\"n\": 9515, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.14, \"learn_time_ms\": 28039.641}", "{\"n\": 9516, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.63, \"learn_time_ms\": 28077.761}", "{\"n\": 9517, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.58, \"learn_time_ms\": 28105.483}", "{\"n\": 9518, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.05, \"learn_time_ms\": 28178.569}", "{\"n\": 9519, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.96, \"learn_time_ms\": 28162.808}", "{\"n\": 9520, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.4, \"learn_time_ms\": 28236.961}", "{\"n\": 9521, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.4, \"learn_time_ms\": 28222.397}", "{\"n\": 9522, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.34, \"learn_time_ms\": 28229.176}", "{\"n\": 9523, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.97, \"learn_time_ms\": 28230.125}", "{\"n\": 9524, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.6, \"learn_time_ms\": 28244.111}", "{\"n\": 9525, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.48, \"learn_time_ms\": 28250.962}", "{\"n\": 9526, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.96, \"learn_time_ms\": 28252.623}", "{\"n\": 9527, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.05, \"learn_time_ms\": 28249.658}", "{\"n\": 9528, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.08, \"learn_time_ms\": 28204.622}", "{\"n\": 9529, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.08, \"learn_time_ms\": 28194.733}", "{\"n\": 9530, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.55, \"learn_time_ms\": 28127.042}", "{\"n\": 9531, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.22, \"learn_time_ms\": 28166.584}", "{\"n\": 9532, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.07, \"learn_time_ms\": 28157.778}", "{\"n\": 9533, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.38, \"learn_time_ms\": 28142.71}", "{\"n\": 9534, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.38, \"learn_time_ms\": 28173.055}", "{\"n\": 9535, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.38, \"learn_time_ms\": 28150.449}", "{\"n\": 9536, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.19, \"learn_time_ms\": 28163.888}", "{\"n\": 9537, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.01, \"learn_time_ms\": 28127.864}", "{\"n\": 9538, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.01, \"learn_time_ms\": 28102.347}", "{\"n\": 9539, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.75, \"learn_time_ms\": 28055.6}", "{\"n\": 9540, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.75, \"learn_time_ms\": 28094.86}", "{\"n\": 9541, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.53, \"learn_time_ms\": 28055.01}", "{\"n\": 9542, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.12, \"learn_time_ms\": 28027.402}", "{\"n\": 9543, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.12, \"learn_time_ms\": 28050.85}", "{\"n\": 9544, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.25, \"learn_time_ms\": 27972.903}", "{\"n\": 9545, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.25, \"learn_time_ms\": 28001.445}", "{\"n\": 9546, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.81, \"learn_time_ms\": 27995.107}", "{\"n\": 9547, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.24, \"learn_time_ms\": 28038.216}", "{\"n\": 9548, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 28043.8}", "{\"n\": 9549, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 28112.986}", "{\"n\": 9550, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.66, \"learn_time_ms\": 28076.88}", "{\"n\": 9551, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.66, \"learn_time_ms\": 28095.667}", "{\"n\": 9552, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.66, \"learn_time_ms\": 28099.119}", "{\"n\": 9553, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.89, \"learn_time_ms\": 28081.39}", "{\"n\": 9554, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.78, \"learn_time_ms\": 28104.209}", "{\"n\": 9555, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.12, \"learn_time_ms\": 28092.616}", "{\"n\": 9556, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.03, \"learn_time_ms\": 28041.572}", "{\"n\": 9557, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.03, \"learn_time_ms\": 28060.602}", "{\"n\": 9558, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.38, \"learn_time_ms\": 28079.721}", "{\"n\": 9559, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.66, \"learn_time_ms\": 28045.174}", "{\"n\": 9560, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.27, \"learn_time_ms\": 28065.65}", "{\"n\": 9561, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.52, \"learn_time_ms\": 28045.885}", "{\"n\": 9562, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.27, \"learn_time_ms\": 28070.895}", "{\"n\": 9563, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.27, \"learn_time_ms\": 28066.434}", "{\"n\": 9564, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.54, \"learn_time_ms\": 28058.888}", "{\"n\": 9565, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.07, \"learn_time_ms\": 28028.99}", "{\"n\": 9566, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.0, \"learn_time_ms\": 28031.94}", "{\"n\": 9567, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.0, \"learn_time_ms\": 28000.244}", "{\"n\": 9568, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.04, \"learn_time_ms\": 27995.179}", "{\"n\": 9569, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3375.55, \"learn_time_ms\": 27972.611}", "{\"n\": 9570, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3380.16, \"learn_time_ms\": 27935.176}", "{\"n\": 9571, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3374.09, \"learn_time_ms\": 27994.934}", "{\"n\": 9572, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.03, \"learn_time_ms\": 27946.863}", "{\"n\": 9573, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.61, \"learn_time_ms\": 27943.137}", "{\"n\": 9574, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.68, \"learn_time_ms\": 27957.056}", "{\"n\": 9575, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3374.08, \"learn_time_ms\": 28000.812}", "{\"n\": 9576, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.43, \"learn_time_ms\": 28034.216}", "{\"n\": 9577, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.94, \"learn_time_ms\": 28024.13}", "{\"n\": 9578, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.83, \"learn_time_ms\": 28032.052}", "{\"n\": 9579, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.39, \"learn_time_ms\": 28081.258}", "{\"n\": 9580, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.64, \"learn_time_ms\": 28128.278}", "{\"n\": 9581, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.59, \"learn_time_ms\": 28137.284}", "{\"n\": 9582, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.59, \"learn_time_ms\": 28166.467}", "{\"n\": 9583, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.4, \"learn_time_ms\": 28152.333}", "{\"n\": 9584, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3405.68, \"learn_time_ms\": 28107.926}", "{\"n\": 9585, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3404.69, \"learn_time_ms\": 28097.042}", "{\"n\": 9586, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3408.5, \"learn_time_ms\": 28077.059}", "{\"n\": 9587, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3408.5, \"learn_time_ms\": 28064.046}", "{\"n\": 9588, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.65, \"learn_time_ms\": 28078.128}", "{\"n\": 9589, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.39, \"learn_time_ms\": 28074.638}", "{\"n\": 9590, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.94, \"learn_time_ms\": 28051.92}", "{\"n\": 9591, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.5, \"learn_time_ms\": 28026.233}", "{\"n\": 9592, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.5, \"learn_time_ms\": 28031.681}", "{\"n\": 9593, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.5, \"learn_time_ms\": 28041.468}", "{\"n\": 9594, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.66, \"learn_time_ms\": 28061.811}", "{\"n\": 9595, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.32, \"learn_time_ms\": 28067.704}", "{\"n\": 9596, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.65, \"learn_time_ms\": 28085.786}", "{\"n\": 9597, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3409.12, \"learn_time_ms\": 28112.215}", "{\"n\": 9598, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3409.12, \"learn_time_ms\": 28044.575}", "{\"n\": 9599, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3409.12, \"learn_time_ms\": 28030.722}", "{\"n\": 9600, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.8, \"learn_time_ms\": 28007.271}", "{\"n\": 9601, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.11, \"learn_time_ms\": 27950.673}", "{\"n\": 9602, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.75, \"learn_time_ms\": 27953.839}", "{\"n\": 9603, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.61, \"learn_time_ms\": 27978.861}", "{\"n\": 9604, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.61, \"learn_time_ms\": 27976.426}", "{\"n\": 9605, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3409.44, \"learn_time_ms\": 27996.439}", "{\"n\": 9606, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.57, \"learn_time_ms\": 27978.45}", "{\"n\": 9607, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.54, \"learn_time_ms\": 28027.121}", "{\"n\": 9608, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.57, \"learn_time_ms\": 28056.352}", "{\"n\": 9609, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.57, \"learn_time_ms\": 28082.245}", "{\"n\": 9610, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.57, \"learn_time_ms\": 28109.79}", "{\"n\": 9611, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3416.94, \"learn_time_ms\": 28182.401}", "{\"n\": 9612, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3419.84, \"learn_time_ms\": 28184.658}", "{\"n\": 9613, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3417.2, \"learn_time_ms\": 28132.189}", "{\"n\": 9614, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3417.11, \"learn_time_ms\": 28144.16}", "{\"n\": 9615, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3417.11, \"learn_time_ms\": 28125.028}", "{\"n\": 9616, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3417.28, \"learn_time_ms\": 28124.938}", "{\"n\": 9617, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.2, \"learn_time_ms\": 28015.988}", "{\"n\": 9618, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.42, \"learn_time_ms\": 28009.365}", "{\"n\": 9619, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.42, \"learn_time_ms\": 27983.835}", "{\"n\": 9620, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.05, \"learn_time_ms\": 27977.146}", "{\"n\": 9621, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.05, \"learn_time_ms\": 27913.227}", "{\"n\": 9622, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.94, \"learn_time_ms\": 27876.534}", "{\"n\": 9623, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3393.78, \"learn_time_ms\": 27945.918}", "{\"n\": 9624, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3393.78, \"learn_time_ms\": 27959.923}", "{\"n\": 9625, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.73, \"learn_time_ms\": 27963.101}", "{\"n\": 9626, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.73, \"learn_time_ms\": 27951.757}", "{\"n\": 9627, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3393.72, \"learn_time_ms\": 28002.167}", "{\"n\": 9628, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.99, \"learn_time_ms\": 27992.311}", "{\"n\": 9629, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.72, \"learn_time_ms\": 27984.718}", "{\"n\": 9630, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.72, \"learn_time_ms\": 27969.285}", "{\"n\": 9631, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.58, \"learn_time_ms\": 27966.825}", "{\"n\": 9632, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.03, \"learn_time_ms\": 28011.73}", "{\"n\": 9633, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.31, \"learn_time_ms\": 27973.879}", "{\"n\": 9634, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.55, \"learn_time_ms\": 27946.913}", "{\"n\": 9635, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.09, \"learn_time_ms\": 27897.664}", "{\"n\": 9636, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.36, \"learn_time_ms\": 27881.882}", "{\"n\": 9637, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.06, \"learn_time_ms\": 27857.471}", "{\"n\": 9638, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.06, \"learn_time_ms\": 27923.541}", "{\"n\": 9639, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.47, \"learn_time_ms\": 27921.347}", "{\"n\": 9640, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.78, \"learn_time_ms\": 27945.522}", "{\"n\": 9641, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.78, \"learn_time_ms\": 27962.017}", "{\"n\": 9642, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3374.55, \"learn_time_ms\": 27929.377}", "{\"n\": 9643, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3369.74, \"learn_time_ms\": 27951.322}", "{\"n\": 9644, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.94, \"learn_time_ms\": 27965.338}", "{\"n\": 9645, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.15, \"learn_time_ms\": 28009.953}", "{\"n\": 9646, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.48, \"learn_time_ms\": 28075.744}", "{\"n\": 9647, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.48, \"learn_time_ms\": 28108.81}", "{\"n\": 9648, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3361.57, \"learn_time_ms\": 28078.166}", "{\"n\": 9649, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3356.21, \"learn_time_ms\": 28086.315}", "{\"n\": 9650, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.05, \"learn_time_ms\": 28061.592}", "{\"n\": 9651, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.08, \"learn_time_ms\": 28028.388}", "{\"n\": 9652, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.18, \"learn_time_ms\": 28068.303}", "{\"n\": 9653, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.95, \"learn_time_ms\": 28064.657}", "{\"n\": 9654, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.24, \"learn_time_ms\": 28090.244}", "{\"n\": 9655, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.59, \"learn_time_ms\": 28086.221}", "{\"n\": 9656, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.78, \"learn_time_ms\": 28076.553}", "{\"n\": 9657, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3350.41, \"learn_time_ms\": 28039.108}", "{\"n\": 9658, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.93, \"learn_time_ms\": 28063.4}", "{\"n\": 9659, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3346.93, \"learn_time_ms\": 28087.003}", "{\"n\": 9660, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.22, \"learn_time_ms\": 28111.403}", "{\"n\": 9661, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.18, \"learn_time_ms\": 28103.915}", "{\"n\": 9662, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3347.43, \"learn_time_ms\": 28089.433}", "{\"n\": 9663, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3336.3, \"learn_time_ms\": 28057.35}", "{\"n\": 9664, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3336.3, \"learn_time_ms\": 28039.368}", "{\"n\": 9665, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.57, \"learn_time_ms\": 28034.814}", "{\"n\": 9666, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3336.39, \"learn_time_ms\": 28017.941}", "{\"n\": 9667, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.09, \"learn_time_ms\": 28035.77}", "{\"n\": 9668, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.03, \"learn_time_ms\": 27960.367}", "{\"n\": 9669, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.01, \"learn_time_ms\": 27928.837}", "{\"n\": 9670, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.01, \"learn_time_ms\": 27883.325}", "{\"n\": 9671, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.49, \"learn_time_ms\": 27935.663}", "{\"n\": 9672, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3325.95, \"learn_time_ms\": 27924.912}", "{\"n\": 9673, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.33, \"learn_time_ms\": 27922.113}", "{\"n\": 9674, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.81, \"learn_time_ms\": 27938.147}", "{\"n\": 9675, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.81, \"learn_time_ms\": 27908.779}", "{\"n\": 9676, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.32, \"learn_time_ms\": 27895.373}", "{\"n\": 9677, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.8, \"learn_time_ms\": 27919.533}", "{\"n\": 9678, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3321.19, \"learn_time_ms\": 27962.428}", "{\"n\": 9679, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.16, \"learn_time_ms\": 28027.711}", "{\"n\": 9680, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.16, \"learn_time_ms\": 28095.45}", "{\"n\": 9681, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.16, \"learn_time_ms\": 28061.455}", "{\"n\": 9682, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.11, \"learn_time_ms\": 28021.799}", "{\"n\": 9683, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.58, \"learn_time_ms\": 28022.423}", "{\"n\": 9684, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.57, \"learn_time_ms\": 28068.152}", "{\"n\": 9685, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.79, \"learn_time_ms\": 28094.993}", "{\"n\": 9686, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.79, \"learn_time_ms\": 28084.553}", "{\"n\": 9687, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.39, \"learn_time_ms\": 28084.87}", "{\"n\": 9688, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.39, \"learn_time_ms\": 28103.982}", "{\"n\": 9689, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.08, \"learn_time_ms\": 28034.594}", "{\"n\": 9690, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3315.08, \"learn_time_ms\": 28009.506}", "{\"n\": 9691, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.87, \"learn_time_ms\": 28050.933}", "{\"n\": 9692, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.68, \"learn_time_ms\": 28105.815}", "{\"n\": 9693, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3308.04, \"learn_time_ms\": 28137.497}", "{\"n\": 9694, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3310.79, \"learn_time_ms\": 28108.153}", "{\"n\": 9695, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.18, \"learn_time_ms\": 28092.752}", "{\"n\": 9696, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3309.18, \"learn_time_ms\": 28127.589}", "{\"n\": 9697, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.19, \"learn_time_ms\": 28106.984}", "{\"n\": 9698, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.85, \"learn_time_ms\": 28092.204}", "{\"n\": 9699, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.49, \"learn_time_ms\": 28122.068}", "{\"n\": 9700, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3314.15, \"learn_time_ms\": 28111.431}", "{\"n\": 9701, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.81, \"learn_time_ms\": 28088.419}", "{\"n\": 9702, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.81, \"learn_time_ms\": 28090.951}", "{\"n\": 9703, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.04, \"learn_time_ms\": 28090.521}", "{\"n\": 9704, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3311.04, \"learn_time_ms\": 28083.182}", "{\"n\": 9705, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.66, \"learn_time_ms\": 28154.486}", "{\"n\": 9706, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.04, \"learn_time_ms\": 28156.701}", "{\"n\": 9707, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3317.67, \"learn_time_ms\": 28154.111}", "{\"n\": 9708, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.98, \"learn_time_ms\": 28170.849}", "{\"n\": 9709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.37, \"learn_time_ms\": 28153.795}", "{\"n\": 9710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3312.96, \"learn_time_ms\": 28163.875}", "{\"n\": 9711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.72, \"learn_time_ms\": 28207.828}", "{\"n\": 9712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.72, \"learn_time_ms\": 28220.268}", "{\"n\": 9713, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.68, \"learn_time_ms\": 28217.809}", "{\"n\": 9714, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3330.85, \"learn_time_ms\": 28213.4}", "{\"n\": 9715, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3329.71, \"learn_time_ms\": 28157.19}", "{\"n\": 9716, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.2, \"learn_time_ms\": 28143.123}", "{\"n\": 9717, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3323.94, \"learn_time_ms\": 28200.797}", "{\"n\": 9718, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3327.68, \"learn_time_ms\": 28187.009}", "{\"n\": 9719, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.23, \"learn_time_ms\": 28224.05}", "{\"n\": 9720, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3316.2, \"learn_time_ms\": 28221.33}", "{\"n\": 9721, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3316.2, \"learn_time_ms\": 28188.366}", "{\"n\": 9722, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3313.28, \"learn_time_ms\": 28166.247}", "{\"n\": 9723, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3312.18, \"learn_time_ms\": 28173.998}", "{\"n\": 9724, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3312.18, \"learn_time_ms\": 28174.007}", "{\"n\": 9725, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3310.81, \"learn_time_ms\": 28211.034}", "{\"n\": 9726, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3306.44, \"learn_time_ms\": 28203.437}", "{\"n\": 9727, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.73, \"learn_time_ms\": 28150.521}", "{\"n\": 9728, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3306.22, \"learn_time_ms\": 28163.937}", "{\"n\": 9729, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3306.22, \"learn_time_ms\": 28118.018}", "{\"n\": 9730, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3306.25, \"learn_time_ms\": 28150.584}", "{\"n\": 9731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3310.98, \"learn_time_ms\": 28151.349}", "{\"n\": 9732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3313.76, \"learn_time_ms\": 28127.88}", "{\"n\": 9733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3312.85, \"learn_time_ms\": 28129.843}", "{\"n\": 9734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.43, \"learn_time_ms\": 28102.937}", "{\"n\": 9735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3310.45, \"learn_time_ms\": 28058.105}", "{\"n\": 9736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3310.45, \"learn_time_ms\": 28028.992}", "{\"n\": 9737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.94, \"learn_time_ms\": 28046.576}", "{\"n\": 9738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3306.33, \"learn_time_ms\": 28035.535}", "{\"n\": 9739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.1, \"learn_time_ms\": 28061.386}", "{\"n\": 9740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.1, \"learn_time_ms\": 27982.409}", "{\"n\": 9741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3305.44, \"learn_time_ms\": 27985.984}", "{\"n\": 9742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3310.22, \"learn_time_ms\": 27999.487}", "{\"n\": 9743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3303.74, \"learn_time_ms\": 28010.805}", "{\"n\": 9744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.68, \"learn_time_ms\": 28047.858}", "{\"n\": 9745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.94, \"learn_time_ms\": 28025.891}", "{\"n\": 9746, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3297.94, \"learn_time_ms\": 28077.625}", "{\"n\": 9747, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3305.18, \"learn_time_ms\": 28076.254}", "{\"n\": 9748, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3306.5, \"learn_time_ms\": 28073.776}", "{\"n\": 9749, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3306.5, \"learn_time_ms\": 28047.422}", "{\"n\": 9750, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3313.24, \"learn_time_ms\": 28088.167}", "{\"n\": 9751, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3313.24, \"learn_time_ms\": 28105.538}", "{\"n\": 9752, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3313.24, \"learn_time_ms\": 28076.724}", "{\"n\": 9753, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3314.87, \"learn_time_ms\": 28070.789}", "{\"n\": 9754, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.13, \"learn_time_ms\": 28055.995}", "{\"n\": 9755, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.86, \"learn_time_ms\": 28092.859}", "{\"n\": 9756, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.02, \"learn_time_ms\": 28130.033}", "{\"n\": 9757, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3309.02, \"learn_time_ms\": 28130.032}", "{\"n\": 9758, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3310.88, \"learn_time_ms\": 28146.35}", "{\"n\": 9759, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.59, \"learn_time_ms\": 28148.561}", "{\"n\": 9760, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3315.26, \"learn_time_ms\": 28119.911}", "{\"n\": 9761, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3320.69, \"learn_time_ms\": 28129.532}", "{\"n\": 9762, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3324.65, \"learn_time_ms\": 28165.469}", "{\"n\": 9763, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.1, \"learn_time_ms\": 28138.774}", "{\"n\": 9764, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.89, \"learn_time_ms\": 28112.916}", "{\"n\": 9765, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.89, \"learn_time_ms\": 28150.14}", "{\"n\": 9766, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3305.66, \"learn_time_ms\": 28121.411}", "{\"n\": 9767, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3305.66, \"learn_time_ms\": 28074.656}", "{\"n\": 9768, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3308.71, \"learn_time_ms\": 28051.665}", "{\"n\": 9769, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3299.0, \"learn_time_ms\": 28083.193}", "{\"n\": 9770, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.1, \"learn_time_ms\": 28110.12}", "{\"n\": 9771, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.1, \"learn_time_ms\": 28096.258}", "{\"n\": 9772, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.63, \"learn_time_ms\": 28093.805}", "{\"n\": 9773, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3307.63, \"learn_time_ms\": 28072.296}", "{\"n\": 9774, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.3, \"learn_time_ms\": 28090.777}", "{\"n\": 9775, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.61, \"learn_time_ms\": 28052.425}", "{\"n\": 9776, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3313.69, \"learn_time_ms\": 27970.021}", "{\"n\": 9777, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3311.34, \"learn_time_ms\": 27993.216}", "{\"n\": 9778, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3316.66, \"learn_time_ms\": 28009.099}", "{\"n\": 9779, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.76, \"learn_time_ms\": 28013.909}", "{\"n\": 9780, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3319.76, \"learn_time_ms\": 28024.855}", "{\"n\": 9781, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.08, \"learn_time_ms\": 28005.517}", "{\"n\": 9782, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.39, \"learn_time_ms\": 28005.103}", "{\"n\": 9783, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.1, \"learn_time_ms\": 28064.145}", "{\"n\": 9784, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.9, \"learn_time_ms\": 28072.178}", "{\"n\": 9785, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.37, \"learn_time_ms\": 28102.961}", "{\"n\": 9786, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.87, \"learn_time_ms\": 28177.904}", "{\"n\": 9787, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.06, \"learn_time_ms\": 28211.498}", "{\"n\": 9788, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.06, \"learn_time_ms\": 28195.579}", "{\"n\": 9789, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.86, \"learn_time_ms\": 28109.11}", "{\"n\": 9790, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.86, \"learn_time_ms\": 28117.112}", "{\"n\": 9791, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.86, \"learn_time_ms\": 28119.517}", "{\"n\": 9792, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.79, \"learn_time_ms\": 28160.22}", "{\"n\": 9793, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.33, \"learn_time_ms\": 28163.373}", "{\"n\": 9794, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.54, \"learn_time_ms\": 28170.11}", "{\"n\": 9795, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.54, \"learn_time_ms\": 28147.949}", "{\"n\": 9796, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.54, \"learn_time_ms\": 28157.007}", "{\"n\": 9797, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.95, \"learn_time_ms\": 28161.33}", "{\"n\": 9798, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.73, \"learn_time_ms\": 28137.135}", "{\"n\": 9799, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.73, \"learn_time_ms\": 28252.26}", "{\"n\": 9800, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.06, \"learn_time_ms\": 28196.399}", "{\"n\": 9801, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.06, \"learn_time_ms\": 28200.007}", "{\"n\": 9802, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.06, \"learn_time_ms\": 28189.025}", "{\"n\": 9803, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.17, \"learn_time_ms\": 28190.298}", "{\"n\": 9804, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.28, \"learn_time_ms\": 28194.47}", "{\"n\": 9805, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.15, \"learn_time_ms\": 28198.635}", "{\"n\": 9806, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.23, \"learn_time_ms\": 28199.862}", "{\"n\": 9807, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.23, \"learn_time_ms\": 28222.586}", "{\"n\": 9808, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.55, \"learn_time_ms\": 28254.533}", "{\"n\": 9809, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.4, \"learn_time_ms\": 28194.653}", "{\"n\": 9810, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.4, \"learn_time_ms\": 28234.356}", "{\"n\": 9811, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.77, \"learn_time_ms\": 28209.904}", "{\"n\": 9812, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.77, \"learn_time_ms\": 28177.759}", "{\"n\": 9813, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.77, \"learn_time_ms\": 28140.711}", "{\"n\": 9814, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.82, \"learn_time_ms\": 28131.049}", "{\"n\": 9815, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.98, \"learn_time_ms\": 28162.195}", "{\"n\": 9816, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.98, \"learn_time_ms\": 28154.083}", "{\"n\": 9817, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.78, \"learn_time_ms\": 28090.356}", "{\"n\": 9818, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.78, \"learn_time_ms\": 28055.084}", "{\"n\": 9819, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.2, \"learn_time_ms\": 28085.825}", "{\"n\": 9820, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.22, \"learn_time_ms\": 28087.959}", "{\"n\": 9821, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3368.64, \"learn_time_ms\": 28094.343}", "{\"n\": 9822, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3375.72, \"learn_time_ms\": 28099.464}", "{\"n\": 9823, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3375.72, \"learn_time_ms\": 28152.757}", "{\"n\": 9824, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3372.82, \"learn_time_ms\": 28192.825}", "{\"n\": 9825, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3375.83, \"learn_time_ms\": 28160.787}", "{\"n\": 9826, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3375.44, \"learn_time_ms\": 28157.829}", "{\"n\": 9827, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3377.01, \"learn_time_ms\": 28149.052}", "{\"n\": 9828, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.0, \"learn_time_ms\": 28167.586}", "{\"n\": 9829, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3377.67, \"learn_time_ms\": 28149.133}", "{\"n\": 9830, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.21, \"learn_time_ms\": 28153.183}", "{\"n\": 9831, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.76, \"learn_time_ms\": 28203.29}", "{\"n\": 9832, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.44, \"learn_time_ms\": 28188.433}", "{\"n\": 9833, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3387.64, \"learn_time_ms\": 28117.916}", "{\"n\": 9834, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3388.55, \"learn_time_ms\": 28048.158}", "{\"n\": 9835, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.28, \"learn_time_ms\": 28076.723}", "{\"n\": 9836, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.74, \"learn_time_ms\": 28069.074}", "{\"n\": 9837, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.6, \"learn_time_ms\": 28091.855}", "{\"n\": 9838, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.14, \"learn_time_ms\": 28095.055}", "{\"n\": 9839, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.87, \"learn_time_ms\": 28098.363}", "{\"n\": 9840, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.13, \"learn_time_ms\": 28117.533}", "{\"n\": 9841, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.65, \"learn_time_ms\": 28103.692}", "{\"n\": 9842, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3395.25, \"learn_time_ms\": 28093.556}", "{\"n\": 9843, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3393.63, \"learn_time_ms\": 28115.453}", "{\"n\": 9844, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.59, \"learn_time_ms\": 28181.359}", "{\"n\": 9845, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.98, \"learn_time_ms\": 28178.078}", "{\"n\": 9846, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.98, \"learn_time_ms\": 28195.21}", "{\"n\": 9847, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3389.99, \"learn_time_ms\": 28235.092}", "{\"n\": 9848, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3392.52, \"learn_time_ms\": 28226.637}", "{\"n\": 9849, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.51, \"learn_time_ms\": 28221.05}", "{\"n\": 9850, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.81, \"learn_time_ms\": 28147.014}", "{\"n\": 9851, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.12, \"learn_time_ms\": 28131.206}", "{\"n\": 9852, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.12, \"learn_time_ms\": 28145.875}", "{\"n\": 9853, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.54, \"learn_time_ms\": 28145.47}", "{\"n\": 9854, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.4, \"learn_time_ms\": 28127.218}", "{\"n\": 9855, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.93, \"learn_time_ms\": 28055.498}", "{\"n\": 9856, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3387.95, \"learn_time_ms\": 28075.003}", "{\"n\": 9857, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3387.95, \"learn_time_ms\": 28039.208}", "{\"n\": 9858, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3387.95, \"learn_time_ms\": 28057.319}", "{\"n\": 9859, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3373.66, \"learn_time_ms\": 28048.48}", "{\"n\": 9860, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.88, \"learn_time_ms\": 28132.132}", "{\"n\": 9861, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3373.6, \"learn_time_ms\": 28133.708}", "{\"n\": 9862, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.61, \"learn_time_ms\": 28160.1}", "{\"n\": 9863, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.61, \"learn_time_ms\": 28187.347}", "{\"n\": 9864, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.53, \"learn_time_ms\": 28153.519}", "{\"n\": 9865, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.71, \"learn_time_ms\": 28205.998}", "{\"n\": 9866, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.63, \"learn_time_ms\": 28157.182}", "{\"n\": 9867, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.01, \"learn_time_ms\": 28159.495}", "{\"n\": 9868, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.01, \"learn_time_ms\": 28192.99}", "{\"n\": 9869, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.48, \"learn_time_ms\": 28219.852}", "{\"n\": 9870, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.56, \"learn_time_ms\": 28180.216}", "{\"n\": 9871, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3366.24, \"learn_time_ms\": 28223.344}", "{\"n\": 9872, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.57, \"learn_time_ms\": 28198.887}", "{\"n\": 9873, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.57, \"learn_time_ms\": 28166.147}", "{\"n\": 9874, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.57, \"learn_time_ms\": 28195.221}", "{\"n\": 9875, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.67, \"learn_time_ms\": 28173.26}", "{\"n\": 9876, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.45, \"learn_time_ms\": 28184.991}", "{\"n\": 9877, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.65, \"learn_time_ms\": 28214.677}", "{\"n\": 9878, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.65, \"learn_time_ms\": 28201.654}", "{\"n\": 9879, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.65, \"learn_time_ms\": 28165.922}", "{\"n\": 9880, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.4, \"learn_time_ms\": 28198.595}", "{\"n\": 9881, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.32, \"learn_time_ms\": 28148.642}", "{\"n\": 9882, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.59, \"learn_time_ms\": 28182.966}", "{\"n\": 9883, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.92, \"learn_time_ms\": 28199.294}", "{\"n\": 9884, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.92, \"learn_time_ms\": 28150.465}", "{\"n\": 9885, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.92, \"learn_time_ms\": 28151.882}", "{\"n\": 9886, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.22, \"learn_time_ms\": 28180.773}", "{\"n\": 9887, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3359.66, \"learn_time_ms\": 28158.05}", "{\"n\": 9888, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.44, \"learn_time_ms\": 28151.811}", "{\"n\": 9889, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.24, \"learn_time_ms\": 28168.024}", "{\"n\": 9890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.24, \"learn_time_ms\": 28172.249}", "{\"n\": 9891, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.4, \"learn_time_ms\": 28159.287}", "{\"n\": 9892, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.24, \"learn_time_ms\": 28114.746}", "{\"n\": 9893, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.88, \"learn_time_ms\": 28093.216}", "{\"n\": 9894, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.2, \"learn_time_ms\": 28127.636}", "{\"n\": 9895, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.89, \"learn_time_ms\": 28140.077}", "{\"n\": 9896, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.89, \"learn_time_ms\": 28098.242}", "{\"n\": 9897, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3342.82, \"learn_time_ms\": 28124.055}", "{\"n\": 9898, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.33, \"learn_time_ms\": 28125.791}", "{\"n\": 9899, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.95, \"learn_time_ms\": 28125.766}", "{\"n\": 9900, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3339.52, \"learn_time_ms\": 28118.872}", "{\"n\": 9901, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3339.52, \"learn_time_ms\": 28161.074}", "{\"n\": 9902, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3339.52, \"learn_time_ms\": 28161.554}", "{\"n\": 9903, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3327.14, \"learn_time_ms\": 28173.991}", "{\"n\": 9904, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3329.84, \"learn_time_ms\": 28149.594}", "{\"n\": 9905, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3327.3, \"learn_time_ms\": 28158.645}", "{\"n\": 9906, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.35, \"learn_time_ms\": 28184.47}", "{\"n\": 9907, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.35, \"learn_time_ms\": 28098.893}", "{\"n\": 9908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3328.09, \"learn_time_ms\": 28122.758}", "{\"n\": 9909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.83, \"learn_time_ms\": 28136.555}", "{\"n\": 9910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3333.04, \"learn_time_ms\": 28101.202}", "{\"n\": 9911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3330.11, \"learn_time_ms\": 28029.825}", "{\"n\": 9912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3330.11, \"learn_time_ms\": 28047.571}", "{\"n\": 9913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3330.11, \"learn_time_ms\": 28000.797}", "{\"n\": 9914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3317.17, \"learn_time_ms\": 28017.944}", "{\"n\": 9915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.97, \"learn_time_ms\": 27954.0}", "{\"n\": 9916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.02, \"learn_time_ms\": 27958.862}", "{\"n\": 9917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.02, \"learn_time_ms\": 28022.459}", "{\"n\": 9918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.02, \"learn_time_ms\": 28002.292}", "{\"n\": 9919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.07, \"learn_time_ms\": 27987.933}", "{\"n\": 9920, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.48, \"learn_time_ms\": 28024.826}", "{\"n\": 9921, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.73, \"learn_time_ms\": 28081.114}", "{\"n\": 9922, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.83, \"learn_time_ms\": 28097.343}", "{\"n\": 9923, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.83, \"learn_time_ms\": 28090.621}", "{\"n\": 9924, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.77, \"learn_time_ms\": 28103.011}", "{\"n\": 9925, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.77, \"learn_time_ms\": 28179.148}", "{\"n\": 9926, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.88, \"learn_time_ms\": 28180.625}", "{\"n\": 9927, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.3, \"learn_time_ms\": 28149.047}", "{\"n\": 9928, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.63, \"learn_time_ms\": 28127.355}", "{\"n\": 9929, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.63, \"learn_time_ms\": 28140.422}", "{\"n\": 9930, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.66, \"learn_time_ms\": 28126.099}", "{\"n\": 9931, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.88, \"learn_time_ms\": 28116.221}", "{\"n\": 9932, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.85, \"learn_time_ms\": 28098.549}", "{\"n\": 9933, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.41, \"learn_time_ms\": 28146.567}", "{\"n\": 9934, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.41, \"learn_time_ms\": 28148.293}", "{\"n\": 9935, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.41, \"learn_time_ms\": 28142.767}", "{\"n\": 9936, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.25, \"learn_time_ms\": 28114.86}", "{\"n\": 9937, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.97, \"learn_time_ms\": 28112.958}", "{\"n\": 9938, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.74, \"learn_time_ms\": 28131.567}", "{\"n\": 9939, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.22, \"learn_time_ms\": 28116.011}", "{\"n\": 9940, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.22, \"learn_time_ms\": 28060.77}", "{\"n\": 9941, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.81, \"learn_time_ms\": 28103.894}", "{\"n\": 9942, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.5, \"learn_time_ms\": 28111.543}", "{\"n\": 9943, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.99, \"learn_time_ms\": 28107.97}", "{\"n\": 9944, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.05, \"learn_time_ms\": 28098.71}", "{\"n\": 9945, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.05, \"learn_time_ms\": 28090.484}", "{\"n\": 9946, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.05, \"learn_time_ms\": 28149.685}", "{\"n\": 9947, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.84, \"learn_time_ms\": 28175.56}", "{\"n\": 9948, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.79, \"learn_time_ms\": 28132.231}", "{\"n\": 9949, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.32, \"learn_time_ms\": 28150.319}", "{\"n\": 9950, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.32, \"learn_time_ms\": 28176.029}", "{\"n\": 9951, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.32, \"learn_time_ms\": 28194.667}", "{\"n\": 9952, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.31, \"learn_time_ms\": 28176.637}", "{\"n\": 9953, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.99, \"learn_time_ms\": 28208.055}", "{\"n\": 9954, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.49, \"learn_time_ms\": 28215.363}", "{\"n\": 9955, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.25, \"learn_time_ms\": 28205.996}", "{\"n\": 9956, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.25, \"learn_time_ms\": 28146.027}", "{\"n\": 9957, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.25, \"learn_time_ms\": 28172.72}", "{\"n\": 9958, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.87, \"learn_time_ms\": 28201.235}", "{\"n\": 9959, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.16, \"learn_time_ms\": 28201.736}", "{\"n\": 9960, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.94, \"learn_time_ms\": 28192.057}", "{\"n\": 9961, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.54, \"learn_time_ms\": 28099.194}", "{\"n\": 9962, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.54, \"learn_time_ms\": 28097.981}", "{\"n\": 9963, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.54, \"learn_time_ms\": 28040.42}", "{\"n\": 9964, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.2, \"learn_time_ms\": 28095.615}", "{\"n\": 9965, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.23, \"learn_time_ms\": 28095.423}", "{\"n\": 9966, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.98, \"learn_time_ms\": 28079.547}", "{\"n\": 9967, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.98, \"learn_time_ms\": 28062.979}", "{\"n\": 9968, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.98, \"learn_time_ms\": 28098.121}", "{\"n\": 9969, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.9, \"learn_time_ms\": 28094.927}", "{\"n\": 9970, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.04, \"learn_time_ms\": 28102.295}", "{\"n\": 9971, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.36, \"learn_time_ms\": 28165.842}", "{\"n\": 9972, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.36, \"learn_time_ms\": 28178.822}", "{\"n\": 9973, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.36, \"learn_time_ms\": 28218.772}", "{\"n\": 9974, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.36, \"learn_time_ms\": 28184.658}", "{\"n\": 9975, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.16, \"learn_time_ms\": 28207.114}", "{\"n\": 9976, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.85, \"learn_time_ms\": 28202.016}", "{\"n\": 9977, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.44, \"learn_time_ms\": 28230.401}", "{\"n\": 9978, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.44, \"learn_time_ms\": 28151.785}", "{\"n\": 9979, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.44, \"learn_time_ms\": 28128.157}", "{\"n\": 9980, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.38, \"learn_time_ms\": 28134.577}", "{\"n\": 9981, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.33, \"learn_time_ms\": 28095.521}", "{\"n\": 9982, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.23, \"learn_time_ms\": 28083.213}", "{\"n\": 9983, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.23, \"learn_time_ms\": 28053.618}", "{\"n\": 9984, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.23, \"learn_time_ms\": 28011.36}", "{\"n\": 9985, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.07, \"learn_time_ms\": 27996.888}", "{\"n\": 9986, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.3, \"learn_time_ms\": 28015.184}", "{\"n\": 9987, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.13, \"learn_time_ms\": 27989.882}", "{\"n\": 9988, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.64, \"learn_time_ms\": 28067.172}", "{\"n\": 9989, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.64, \"learn_time_ms\": 28089.278}", "{\"n\": 9990, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.02, \"learn_time_ms\": 28099.538}", "{\"n\": 9991, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.83, \"learn_time_ms\": 28093.379}", "{\"n\": 9992, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.43, \"learn_time_ms\": 28124.705}", "{\"n\": 9993, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.46, \"learn_time_ms\": 28177.228}", "{\"n\": 9994, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.46, \"learn_time_ms\": 28141.554}", "{\"n\": 9995, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.12, \"learn_time_ms\": 28108.086}", "{\"n\": 9996, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.43, \"learn_time_ms\": 28131.007}", "{\"n\": 9997, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.55, \"learn_time_ms\": 28114.63}", "{\"n\": 9998, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.39, \"learn_time_ms\": 28090.821}", "{\"n\": 9999, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.05, \"learn_time_ms\": 28079.474}", "{\"n\": 10000, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3305.05, \"learn_time_ms\": 28104.882}"]["{\"n\": 10001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29804.585}", "{\"n\": 10002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29473.15}", "{\"n\": 10003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29319.207}", "{\"n\": 10004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29156.44}", "{\"n\": 10005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29112.506}", "{\"n\": 10006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29050.551}", "{\"n\": 10007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29019.457}", "{\"n\": 10008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28991.211}", "{\"n\": 10009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28960.646}", "{\"n\": 10010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28949.364}", "{\"n\": 10011, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3367.75, \"learn_time_ms\": 28840.849}", "{\"n\": 10012, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3369.5, \"learn_time_ms\": 28803.934}", "{\"n\": 10013, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3369.5, \"learn_time_ms\": 28742.732}", "{\"n\": 10014, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3369.5, \"learn_time_ms\": 28751.404}", "{\"n\": 10015, \"episode_reward_min\": -7.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3369.5, \"learn_time_ms\": 28727.498}", "{\"n\": 10016, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.333333333333333, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3332.1111111111113, \"learn_time_ms\": 28669.79}", "{\"n\": 10017, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.285714285714286, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.3571428571427, \"learn_time_ms\": 28649.189}", "{\"n\": 10018, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.3125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.0625, \"learn_time_ms\": 28604.964}", "{\"n\": 10019, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.3125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.0625, \"learn_time_ms\": 28550.698}", "{\"n\": 10020, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.3125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.0625, \"learn_time_ms\": 28523.519}", "{\"n\": 10021, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.411764705882353, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.823529411765, \"learn_time_ms\": 28467.647}", "{\"n\": 10022, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3309.277777777778, \"learn_time_ms\": 28467.999}", "{\"n\": 10023, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.521739130434782, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.5652173913045, \"learn_time_ms\": 28440.885}", "{\"n\": 10024, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.9583333333335, \"learn_time_ms\": 28422.107}", "{\"n\": 10025, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.9583333333335, \"learn_time_ms\": 28413.745}", "{\"n\": 10026, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.9583333333335, \"learn_time_ms\": 28464.776}", "{\"n\": 10027, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.56, \"learn_time_ms\": 28398.542}", "{\"n\": 10028, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.571428571428571, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.8928571428573, \"learn_time_ms\": 28451.348}", "{\"n\": 10029, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.9375, \"learn_time_ms\": 28487.385}", "{\"n\": 10030, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.9375, \"learn_time_ms\": 28452.891}", "{\"n\": 10031, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.9375, \"learn_time_ms\": 28462.996}", "{\"n\": 10032, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.9375, \"learn_time_ms\": 28433.878}", "{\"n\": 10033, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.638888888888889, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.0, \"learn_time_ms\": 28487.087}", "{\"n\": 10034, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.621621621621622, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3341.5675675675675, \"learn_time_ms\": 28442.188}", "{\"n\": 10035, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.825, \"learn_time_ms\": 28431.022}", "{\"n\": 10036, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.825, \"learn_time_ms\": 28405.861}", "{\"n\": 10037, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.825, \"learn_time_ms\": 28472.877}", "{\"n\": 10038, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.825, \"learn_time_ms\": 28378.859}", "{\"n\": 10039, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.622222222222222, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.266666666667, \"learn_time_ms\": 28380.384}", "{\"n\": 10040, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.479166666666667, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.9166666666665, \"learn_time_ms\": 28420.344}", "{\"n\": 10041, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.479166666666667, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.9166666666665, \"learn_time_ms\": 28468.069}", "{\"n\": 10042, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.479166666666667, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.9166666666665, \"learn_time_ms\": 28462.227}", "{\"n\": 10043, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.479166666666667, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3349.9166666666665, \"learn_time_ms\": 28432.541}", "{\"n\": 10044, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.94, \"learn_time_ms\": 28429.85}", "{\"n\": 10045, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.381818181818182, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.090909090909, \"learn_time_ms\": 28449.375}", "{\"n\": 10046, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.589285714286, \"learn_time_ms\": 28440.443}", "{\"n\": 10047, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.589285714286, \"learn_time_ms\": 28446.142}", "{\"n\": 10048, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.589285714286, \"learn_time_ms\": 28496.122}", "{\"n\": 10049, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.589285714286, \"learn_time_ms\": 28440.438}", "{\"n\": 10050, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.372881355932203, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.8813559322034, \"learn_time_ms\": 28408.879}", "{\"n\": 10051, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.59375, \"learn_time_ms\": 28345.114}", "{\"n\": 10052, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.59375, \"learn_time_ms\": 28351.07}", "{\"n\": 10053, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.59375, \"learn_time_ms\": 28396.139}", "{\"n\": 10054, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.59375, \"learn_time_ms\": 28454.51}", "{\"n\": 10055, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.454545454545454, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.378787878788, \"learn_time_ms\": 28372.465}", "{\"n\": 10056, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.428571428571429, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.842857142857, \"learn_time_ms\": 28416.101}", "{\"n\": 10057, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.388888888888889, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.7638888888887, \"learn_time_ms\": 28389.967}", "{\"n\": 10058, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.388888888888889, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.7638888888887, \"learn_time_ms\": 28398.592}", "{\"n\": 10059, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.388888888888889, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.7638888888887, \"learn_time_ms\": 28453.324}", "{\"n\": 10060, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.383561643835616, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.1369863013697, \"learn_time_ms\": 28463.38}", "{\"n\": 10061, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.4605263157894735, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.3552631578946, \"learn_time_ms\": 28508.586}", "{\"n\": 10062, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.430379746835443, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.3291139240505, \"learn_time_ms\": 28464.518}", "{\"n\": 10063, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.7625, \"learn_time_ms\": 28431.349}", "{\"n\": 10064, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.7625, \"learn_time_ms\": 28425.17}", "{\"n\": 10065, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.7625, \"learn_time_ms\": 28469.145}", "{\"n\": 10066, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5476190476190474, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.0119047619046, \"learn_time_ms\": 28454.359}", "{\"n\": 10067, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.546511627906977, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.313953488372, \"learn_time_ms\": 28490.775}", "{\"n\": 10068, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.511363636363637, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.715909090909, \"learn_time_ms\": 28450.525}", "{\"n\": 10069, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.511363636363637, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.715909090909, \"learn_time_ms\": 28449.706}", "{\"n\": 10070, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.511363636363637, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.715909090909, \"learn_time_ms\": 28460.328}", "{\"n\": 10071, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.549450549450549, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.901098901099, \"learn_time_ms\": 28459.902}", "{\"n\": 10072, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.548387096774194, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.1182795698924, \"learn_time_ms\": 28507.917}", "{\"n\": 10073, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.536842105263158, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.294736842105, \"learn_time_ms\": 28520.382}", "{\"n\": 10074, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53125, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.625, \"learn_time_ms\": 28483.31}", "{\"n\": 10075, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53125, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.625, \"learn_time_ms\": 28479.615}", "{\"n\": 10076, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.536082474226804, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.319587628866, \"learn_time_ms\": 28465.709}", "{\"n\": 10077, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5353535353535355, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.151515151515, \"learn_time_ms\": 28422.773}", "{\"n\": 10078, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.42, \"learn_time_ms\": 28416.766}", "{\"n\": 10079, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.23, \"learn_time_ms\": 28383.222}", "{\"n\": 10080, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.23, \"learn_time_ms\": 28359.635}", "{\"n\": 10081, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.23, \"learn_time_ms\": 28338.143}", "{\"n\": 10082, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.4, \"learn_time_ms\": 28321.359}", "{\"n\": 10083, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.88, \"learn_time_ms\": 28287.491}", "{\"n\": 10084, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.5, \"learn_time_ms\": 28293.895}", "{\"n\": 10085, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.2, \"learn_time_ms\": 28287.4}", "{\"n\": 10086, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.2, \"learn_time_ms\": 28295.643}", "{\"n\": 10087, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.2, \"learn_time_ms\": 28300.597}", "{\"n\": 10088, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.51, \"learn_time_ms\": 28367.092}", "{\"n\": 10089, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.08, \"learn_time_ms\": 28382.68}", "{\"n\": 10090, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.23, \"learn_time_ms\": 28391.683}", "{\"n\": 10091, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.23, \"learn_time_ms\": 28364.567}", "{\"n\": 10092, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.23, \"learn_time_ms\": 28308.181}", "{\"n\": 10093, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.2, \"learn_time_ms\": 28270.578}", "{\"n\": 10094, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.12, \"learn_time_ms\": 28258.429}", "{\"n\": 10095, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.32, \"learn_time_ms\": 28267.757}", "{\"n\": 10096, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.97, \"learn_time_ms\": 28256.976}", "{\"n\": 10097, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.97, \"learn_time_ms\": 28233.701}", "{\"n\": 10098, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.46, \"learn_time_ms\": 28215.181}", "{\"n\": 10099, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.84, \"learn_time_ms\": 28233.29}", "{\"n\": 10100, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.35, \"learn_time_ms\": 28233.211}", "{\"n\": 10101, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3321.52, \"learn_time_ms\": 28260.6}", "{\"n\": 10102, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.14, \"learn_time_ms\": 28311.051}", "{\"n\": 10103, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.14, \"learn_time_ms\": 28358.882}", "{\"n\": 10104, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.65, \"learn_time_ms\": 28361.511}", "{\"n\": 10105, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.51, \"learn_time_ms\": 28353.652}", "{\"n\": 10106, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.3, \"learn_time_ms\": 28321.292}", "{\"n\": 10107, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.81, \"learn_time_ms\": 28352.423}", "{\"n\": 10108, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3324.27, \"learn_time_ms\": 28350.881}", "{\"n\": 10109, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.19, \"learn_time_ms\": 28330.835}", "{\"n\": 10110, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.46, \"learn_time_ms\": 28339.635}", "{\"n\": 10111, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.06, \"learn_time_ms\": 28342.284}", "{\"n\": 10112, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.14, \"learn_time_ms\": 28306.225}", "{\"n\": 10113, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.34, \"learn_time_ms\": 28286.832}", "{\"n\": 10114, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.34, \"learn_time_ms\": 28245.672}", "{\"n\": 10115, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.27, \"learn_time_ms\": 28263.152}", "{\"n\": 10116, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.24, \"learn_time_ms\": 28299.613}", "{\"n\": 10117, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.04, \"learn_time_ms\": 28292.124}", "{\"n\": 10118, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.24, \"learn_time_ms\": 28265.307}", "{\"n\": 10119, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.24, \"learn_time_ms\": 28265.009}", "{\"n\": 10120, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.47, \"learn_time_ms\": 28232.04}", "{\"n\": 10121, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.3, \"learn_time_ms\": 28268.986}", "{\"n\": 10122, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.37, \"learn_time_ms\": 28326.672}", "{\"n\": 10123, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.37, \"learn_time_ms\": 28362.624}", "{\"n\": 10124, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.21, \"learn_time_ms\": 28419.993}", "{\"n\": 10125, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.53, \"learn_time_ms\": 28467.357}", "{\"n\": 10126, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.43, \"learn_time_ms\": 28409.903}", "{\"n\": 10127, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.09, \"learn_time_ms\": 28370.193}", "{\"n\": 10128, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.84, \"learn_time_ms\": 28338.277}", "{\"n\": 10129, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.84, \"learn_time_ms\": 28323.244}", "{\"n\": 10130, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.71, \"learn_time_ms\": 28306.767}", "{\"n\": 10131, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.56, \"learn_time_ms\": 28253.047}", "{\"n\": 10132, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.21, \"learn_time_ms\": 28176.621}", "{\"n\": 10133, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.32, \"learn_time_ms\": 28149.924}", "{\"n\": 10134, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.45, \"learn_time_ms\": 28126.902}", "{\"n\": 10135, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3336.22, \"learn_time_ms\": 28029.283}", "{\"n\": 10136, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.67, \"learn_time_ms\": 27996.492}", "{\"n\": 10137, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.47, \"learn_time_ms\": 28018.697}", "{\"n\": 10138, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.73, \"learn_time_ms\": 28051.732}", "{\"n\": 10139, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.74, \"learn_time_ms\": 28041.788}", "{\"n\": 10140, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.75, \"learn_time_ms\": 28042.369}", "{\"n\": 10141, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.75, \"learn_time_ms\": 28016.263}", "{\"n\": 10142, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.09, \"learn_time_ms\": 28072.385}", "{\"n\": 10143, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.39, \"learn_time_ms\": 28069.345}", "{\"n\": 10144, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.39, \"learn_time_ms\": 28097.28}", "{\"n\": 10145, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.2, \"learn_time_ms\": 28105.458}", "{\"n\": 10146, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.2, \"learn_time_ms\": 28156.777}", "{\"n\": 10147, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.2, \"learn_time_ms\": 28153.385}", "{\"n\": 10148, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.31, \"learn_time_ms\": 28162.207}", "{\"n\": 10149, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.97, \"learn_time_ms\": 28174.037}", "{\"n\": 10150, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.81, \"learn_time_ms\": 28242.576}", "{\"n\": 10151, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.81, \"learn_time_ms\": 28292.991}", "{\"n\": 10152, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.81, \"learn_time_ms\": 28270.868}", "{\"n\": 10153, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.71, \"learn_time_ms\": 28257.149}", "{\"n\": 10154, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.15, \"learn_time_ms\": 28224.677}", "{\"n\": 10155, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.85, \"learn_time_ms\": 28246.053}", "{\"n\": 10156, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.22, \"learn_time_ms\": 28234.712}", "{\"n\": 10157, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.22, \"learn_time_ms\": 28233.696}", "{\"n\": 10158, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.22, \"learn_time_ms\": 28175.629}", "{\"n\": 10159, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.47, \"learn_time_ms\": 28188.538}", "{\"n\": 10160, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.73, \"learn_time_ms\": 28159.473}", "{\"n\": 10161, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.96, \"learn_time_ms\": 28119.173}", "{\"n\": 10162, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.96, \"learn_time_ms\": 28122.462}", "{\"n\": 10163, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.96, \"learn_time_ms\": 28172.885}", "{\"n\": 10164, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.0, \"learn_time_ms\": 28169.917}", "{\"n\": 10165, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.28, \"learn_time_ms\": 28159.12}", "{\"n\": 10166, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.67, \"learn_time_ms\": 28203.453}", "{\"n\": 10167, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.06, \"learn_time_ms\": 28216.81}", "{\"n\": 10168, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.06, \"learn_time_ms\": 28246.14}", "{\"n\": 10169, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.26, \"learn_time_ms\": 28230.824}", "{\"n\": 10170, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.67, \"learn_time_ms\": 28228.701}", "{\"n\": 10171, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.39, \"learn_time_ms\": 28217.42}", "{\"n\": 10172, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.82, \"learn_time_ms\": 28256.066}", "{\"n\": 10173, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.91, \"learn_time_ms\": 28205.497}", "{\"n\": 10174, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.91, \"learn_time_ms\": 28207.371}", "{\"n\": 10175, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.91, \"learn_time_ms\": 28212.584}", "{\"n\": 10176, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.94, \"learn_time_ms\": 28238.541}", "{\"n\": 10177, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.21, \"learn_time_ms\": 28226.311}", "{\"n\": 10178, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.49, \"learn_time_ms\": 28256.8}", "{\"n\": 10179, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.49, \"learn_time_ms\": 28278.187}", "{\"n\": 10180, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.49, \"learn_time_ms\": 28300.832}", "{\"n\": 10181, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.91, \"learn_time_ms\": 28347.149}", "{\"n\": 10182, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.17, \"learn_time_ms\": 28335.137}", "{\"n\": 10183, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.92, \"learn_time_ms\": 28370.641}", "{\"n\": 10184, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.0, \"learn_time_ms\": 28396.522}", "{\"n\": 10185, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.0, \"learn_time_ms\": 28416.46}", "{\"n\": 10186, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.0, \"learn_time_ms\": 28402.291}", "{\"n\": 10187, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.23, \"learn_time_ms\": 28412.557}", "{\"n\": 10188, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.03, \"learn_time_ms\": 28389.869}", "{\"n\": 10189, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.39, \"learn_time_ms\": 28362.403}", "{\"n\": 10190, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.16, \"learn_time_ms\": 28333.013}", "{\"n\": 10191, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.16, \"learn_time_ms\": 28324.209}", "{\"n\": 10192, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.14, \"learn_time_ms\": 28303.804}", "{\"n\": 10193, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.14, \"learn_time_ms\": 28281.212}", "{\"n\": 10194, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.49, \"learn_time_ms\": 28280.328}", "{\"n\": 10195, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.01, \"learn_time_ms\": 28302.08}", "{\"n\": 10196, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.01, \"learn_time_ms\": 28273.392}", "{\"n\": 10197, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.01, \"learn_time_ms\": 28286.742}", "{\"n\": 10198, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.61, \"learn_time_ms\": 28293.483}", "{\"n\": 10199, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.61, \"learn_time_ms\": 28335.19}", "{\"n\": 10200, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.04, \"learn_time_ms\": 28335.375}", "{\"n\": 10201, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.78, \"learn_time_ms\": 28296.886}", "{\"n\": 10202, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.78, \"learn_time_ms\": 28291.281}", "{\"n\": 10203, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.02, \"learn_time_ms\": 28282.427}", "{\"n\": 10204, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.02, \"learn_time_ms\": 28245.31}", "{\"n\": 10205, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.47, \"learn_time_ms\": 28238.678}", "{\"n\": 10206, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 28267.978}", "{\"n\": 10207, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 28251.944}", "{\"n\": 10208, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 28249.41}", "{\"n\": 10209, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.48, \"learn_time_ms\": 28203.648}", "{\"n\": 10210, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.48, \"learn_time_ms\": 28208.827}", "{\"n\": 10211, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.74, \"learn_time_ms\": 28245.93}", "{\"n\": 10212, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.64, \"learn_time_ms\": 28207.256}", "{\"n\": 10213, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.64, \"learn_time_ms\": 28227.111}", "{\"n\": 10214, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.94, \"learn_time_ms\": 28235.317}", "{\"n\": 10215, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.94, \"learn_time_ms\": 28228.07}", "{\"n\": 10216, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.8, \"learn_time_ms\": 28175.172}", "{\"n\": 10217, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.48, \"learn_time_ms\": 28161.573}", "{\"n\": 10218, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.24, \"learn_time_ms\": 28132.501}", "{\"n\": 10219, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.62, \"learn_time_ms\": 28174.376}", "{\"n\": 10220, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.86, \"learn_time_ms\": 28170.599}", "{\"n\": 10221, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.77, \"learn_time_ms\": 28174.92}", "{\"n\": 10222, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.58, \"learn_time_ms\": 28217.024}", "{\"n\": 10223, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.81, \"learn_time_ms\": 28202.079}", "{\"n\": 10224, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.82, \"learn_time_ms\": 28243.847}", "{\"n\": 10225, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.98, \"learn_time_ms\": 28235.322}", "{\"n\": 10226, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.98, \"learn_time_ms\": 28235.965}", "{\"n\": 10227, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.68, \"learn_time_ms\": 28202.208}", "{\"n\": 10228, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.43, \"learn_time_ms\": 28229.129}", "{\"n\": 10229, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.43, \"learn_time_ms\": 28188.045}", "{\"n\": 10230, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.64, \"learn_time_ms\": 28159.136}", "{\"n\": 10231, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.92, \"learn_time_ms\": 28142.431}", "{\"n\": 10232, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.66, \"learn_time_ms\": 28140.898}", "{\"n\": 10233, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.67, \"learn_time_ms\": 28128.934}", "{\"n\": 10234, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.15, \"learn_time_ms\": 28091.958}", "{\"n\": 10235, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.15, \"learn_time_ms\": 28042.088}", "{\"n\": 10236, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3358.01, \"learn_time_ms\": 28017.769}", "{\"n\": 10237, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.67, \"learn_time_ms\": 28068.767}", "{\"n\": 10238, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.99, \"learn_time_ms\": 28055.243}", "{\"n\": 10239, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.1, \"learn_time_ms\": 28062.072}", "{\"n\": 10240, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.92, \"learn_time_ms\": 28075.139}", "{\"n\": 10241, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.52, \"learn_time_ms\": 28088.011}", "{\"n\": 10242, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.52, \"learn_time_ms\": 28136.899}", "{\"n\": 10243, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.4, \"learn_time_ms\": 28169.25}", "{\"n\": 10244, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.32, \"learn_time_ms\": 28152.825}", "{\"n\": 10245, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.92, \"learn_time_ms\": 28194.501}", "{\"n\": 10246, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.93, \"learn_time_ms\": 28231.07}", "{\"n\": 10247, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.93, \"learn_time_ms\": 28233.736}", "{\"n\": 10248, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.09, \"learn_time_ms\": 28222.904}", "{\"n\": 10249, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.46, \"learn_time_ms\": 28215.632}", "{\"n\": 10250, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.17, \"learn_time_ms\": 28199.25}", "{\"n\": 10251, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.18, \"learn_time_ms\": 28228.976}", "{\"n\": 10252, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.18, \"learn_time_ms\": 28174.109}", "{\"n\": 10253, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3331.46, \"learn_time_ms\": 28142.397}", "{\"n\": 10254, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.3, \"learn_time_ms\": 28165.589}", "{\"n\": 10255, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3327.18, \"learn_time_ms\": 28189.595}", "{\"n\": 10256, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.35, \"learn_time_ms\": 28184.643}", "{\"n\": 10257, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.49, \"learn_time_ms\": 28175.659}", "{\"n\": 10258, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.49, \"learn_time_ms\": 28224.016}", "{\"n\": 10259, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3332.48, \"learn_time_ms\": 28257.851}", "{\"n\": 10260, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.88, \"learn_time_ms\": 28245.606}", "{\"n\": 10261, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.82, \"learn_time_ms\": 28234.185}", "{\"n\": 10262, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.91, \"learn_time_ms\": 28258.973}", "{\"n\": 10263, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.69, \"learn_time_ms\": 28276.641}", "{\"n\": 10264, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.69, \"learn_time_ms\": 28242.594}", "{\"n\": 10265, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.21, \"learn_time_ms\": 28176.874}", "{\"n\": 10266, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.62, \"learn_time_ms\": 28172.111}", "{\"n\": 10267, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.09, \"learn_time_ms\": 28201.837}", "{\"n\": 10268, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.09, \"learn_time_ms\": 28187.175}", "{\"n\": 10269, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.31, \"learn_time_ms\": 28173.12}", "{\"n\": 10270, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.3, \"learn_time_ms\": 28193.233}", "{\"n\": 10271, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.76, \"learn_time_ms\": 28163.65}", "{\"n\": 10272, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.6, \"learn_time_ms\": 28132.067}", "{\"n\": 10273, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.07, \"learn_time_ms\": 28137.34}", "{\"n\": 10274, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.06, \"learn_time_ms\": 28193.306}", "{\"n\": 10275, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.06, \"learn_time_ms\": 28220.509}", "{\"n\": 10276, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.2, \"learn_time_ms\": 28195.365}", "{\"n\": 10277, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.2, \"learn_time_ms\": 28120.242}", "{\"n\": 10278, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.86, \"learn_time_ms\": 28120.596}", "{\"n\": 10279, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.23, \"learn_time_ms\": 28125.616}", "{\"n\": 10280, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.18, \"learn_time_ms\": 28132.477}", "{\"n\": 10281, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.18, \"learn_time_ms\": 28149.83}", "{\"n\": 10282, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.89, \"learn_time_ms\": 28171.813}", "{\"n\": 10283, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.89, \"learn_time_ms\": 28164.132}", "{\"n\": 10284, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.62, \"learn_time_ms\": 28146.972}", "{\"n\": 10285, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.77, \"learn_time_ms\": 28125.678}", "{\"n\": 10286, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.75, \"learn_time_ms\": 28134.756}", "{\"n\": 10287, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.0, \"learn_time_ms\": 28190.366}", "{\"n\": 10288, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.03, \"learn_time_ms\": 28207.652}", "{\"n\": 10289, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.56, \"learn_time_ms\": 28188.405}", "{\"n\": 10290, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.25, \"learn_time_ms\": 28170.734}", "{\"n\": 10291, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.79, \"learn_time_ms\": 28119.117}", "{\"n\": 10292, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.79, \"learn_time_ms\": 28130.116}", "{\"n\": 10293, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.49, \"learn_time_ms\": 28121.401}", "{\"n\": 10294, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.12, \"learn_time_ms\": 28088.717}", "{\"n\": 10295, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.72, \"learn_time_ms\": 28087.505}", "{\"n\": 10296, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.42, \"learn_time_ms\": 28145.625}", "{\"n\": 10297, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.89, \"learn_time_ms\": 28138.87}", "{\"n\": 10298, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.76, \"learn_time_ms\": 28123.444}", "{\"n\": 10299, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.88, \"learn_time_ms\": 28136.486}", "{\"n\": 10300, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.56, \"learn_time_ms\": 28185.543}", "{\"n\": 10301, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.61, \"learn_time_ms\": 28240.772}", "{\"n\": 10302, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.61, \"learn_time_ms\": 28202.584}", "{\"n\": 10303, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.22, \"learn_time_ms\": 28222.661}", "{\"n\": 10304, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.65, \"learn_time_ms\": 28277.376}", "{\"n\": 10305, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.99, \"learn_time_ms\": 28307.545}", "{\"n\": 10306, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.2, \"learn_time_ms\": 28283.057}", "{\"n\": 10307, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.8, \"learn_time_ms\": 28262.543}", "{\"n\": 10308, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.44, \"learn_time_ms\": 28283.863}", "{\"n\": 10309, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.44, \"learn_time_ms\": 28281.672}", "{\"n\": 10310, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.43, \"learn_time_ms\": 28277.307}", "{\"n\": 10311, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.68, \"learn_time_ms\": 28265.091}", "{\"n\": 10312, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.26, \"learn_time_ms\": 28287.239}", "{\"n\": 10313, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.04, \"learn_time_ms\": 28273.103}", "{\"n\": 10314, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.04, \"learn_time_ms\": 28267.304}", "{\"n\": 10315, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.34, \"learn_time_ms\": 28264.003}", "{\"n\": 10316, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.2, \"learn_time_ms\": 28245.862}", "{\"n\": 10317, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.23, \"learn_time_ms\": 28267.332}", "{\"n\": 10318, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.39, \"learn_time_ms\": 28198.953}", "{\"n\": 10319, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.03, \"learn_time_ms\": 28213.804}", "{\"n\": 10320, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.03, \"learn_time_ms\": 28178.148}", "{\"n\": 10321, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.62, \"learn_time_ms\": 28152.399}", "{\"n\": 10322, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.81, \"learn_time_ms\": 28131.619}", "{\"n\": 10323, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.38, \"learn_time_ms\": 28141.663}", "{\"n\": 10324, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.55, \"learn_time_ms\": 28109.045}", "{\"n\": 10325, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.32, \"learn_time_ms\": 28143.466}", "{\"n\": 10326, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.32, \"learn_time_ms\": 28143.485}", "{\"n\": 10327, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.72, \"learn_time_ms\": 28148.05}", "{\"n\": 10328, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.47, \"learn_time_ms\": 28176.593}", "{\"n\": 10329, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.02, \"learn_time_ms\": 28194.55}", "{\"n\": 10330, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.52, \"learn_time_ms\": 28214.252}", "{\"n\": 10331, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.52, \"learn_time_ms\": 28238.358}", "{\"n\": 10332, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.89, \"learn_time_ms\": 28253.22}", "{\"n\": 10333, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.85, \"learn_time_ms\": 28256.822}", "{\"n\": 10334, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.63, \"learn_time_ms\": 28261.153}", "{\"n\": 10335, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.23, \"learn_time_ms\": 28219.449}", "{\"n\": 10336, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.23, \"learn_time_ms\": 28263.844}", "{\"n\": 10337, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.23, \"learn_time_ms\": 28239.775}", "{\"n\": 10338, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.33, \"learn_time_ms\": 28246.9}", "{\"n\": 10339, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.33, \"learn_time_ms\": 28194.619}", "{\"n\": 10340, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.37, \"learn_time_ms\": 28179.35}", "{\"n\": 10341, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.85, \"learn_time_ms\": 28203.423}", "{\"n\": 10342, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.85, \"learn_time_ms\": 28236.246}", "{\"n\": 10343, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.03, \"learn_time_ms\": 28219.871}", "{\"n\": 10344, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.14, \"learn_time_ms\": 28197.717}", "{\"n\": 10345, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.05, \"learn_time_ms\": 28189.774}", "{\"n\": 10346, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.02, \"learn_time_ms\": 28156.13}", "{\"n\": 10347, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.02, \"learn_time_ms\": 28138.84}", "{\"n\": 10348, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.02, \"learn_time_ms\": 28155.739}", "{\"n\": 10349, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.83, \"learn_time_ms\": 28133.465}", "{\"n\": 10350, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.42, \"learn_time_ms\": 28159.024}", "{\"n\": 10351, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.78, \"learn_time_ms\": 28111.228}", "{\"n\": 10352, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.76, \"learn_time_ms\": 28067.518}", "{\"n\": 10353, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.76, \"learn_time_ms\": 28062.101}", "{\"n\": 10354, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.76, \"learn_time_ms\": 28076.624}", "{\"n\": 10355, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.51, \"learn_time_ms\": 28059.069}", "{\"n\": 10356, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.72, \"learn_time_ms\": 28109.573}", "{\"n\": 10357, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.44, \"learn_time_ms\": 28152.481}", "{\"n\": 10358, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.44, \"learn_time_ms\": 28151.661}", "{\"n\": 10359, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.44, \"learn_time_ms\": 28172.13}", "{\"n\": 10360, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.44, \"learn_time_ms\": 28199.721}", "{\"n\": 10361, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.73, \"learn_time_ms\": 28230.079}", "{\"n\": 10362, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.68, \"learn_time_ms\": 28226.563}", "{\"n\": 10363, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.51, \"learn_time_ms\": 28206.327}", "{\"n\": 10364, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.51, \"learn_time_ms\": 28192.942}", "{\"n\": 10365, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.51, \"learn_time_ms\": 28225.381}", "{\"n\": 10366, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.81, \"learn_time_ms\": 28196.053}", "{\"n\": 10367, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.05, \"learn_time_ms\": 28173.621}", "{\"n\": 10368, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.78, \"learn_time_ms\": 28079.952}", "{\"n\": 10369, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.35, \"learn_time_ms\": 28079.577}", "{\"n\": 10370, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.35, \"learn_time_ms\": 28043.063}", "{\"n\": 10371, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.35, \"learn_time_ms\": 28028.395}", "{\"n\": 10372, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.81, \"learn_time_ms\": 28031.746}", "{\"n\": 10373, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.95, \"learn_time_ms\": 28019.963}", "{\"n\": 10374, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.53, \"learn_time_ms\": 28045.371}", "{\"n\": 10375, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.84, \"learn_time_ms\": 28039.264}", "{\"n\": 10376, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.84, \"learn_time_ms\": 28014.251}", "{\"n\": 10377, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.11, \"learn_time_ms\": 27997.927}", "{\"n\": 10378, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.84, \"learn_time_ms\": 28053.063}", "{\"n\": 10379, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.22, \"learn_time_ms\": 28065.747}", "{\"n\": 10380, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.69, \"learn_time_ms\": 28071.236}", "{\"n\": 10381, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.69, \"learn_time_ms\": 28093.261}", "{\"n\": 10382, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.69, \"learn_time_ms\": 28105.691}", "{\"n\": 10383, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3373.78, \"learn_time_ms\": 28139.81}", "{\"n\": 10384, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.96, \"learn_time_ms\": 28135.234}", "{\"n\": 10385, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.25, \"learn_time_ms\": 28137.17}", "{\"n\": 10386, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.26, \"learn_time_ms\": 28148.301}", "{\"n\": 10387, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.26, \"learn_time_ms\": 28196.533}", "{\"n\": 10388, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.26, \"learn_time_ms\": 28207.767}", "{\"n\": 10389, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.76, \"learn_time_ms\": 28217.871}", "{\"n\": 10390, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.21, \"learn_time_ms\": 28226.187}", "{\"n\": 10391, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.76, \"learn_time_ms\": 28252.64}", "{\"n\": 10392, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.6, \"learn_time_ms\": 28278.464}", "{\"n\": 10393, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.6, \"learn_time_ms\": 28265.447}", "{\"n\": 10394, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.25, \"learn_time_ms\": 28289.222}", "{\"n\": 10395, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.26, \"learn_time_ms\": 28313.451}", "{\"n\": 10396, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.39, \"learn_time_ms\": 28293.703}", "{\"n\": 10397, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.57, \"learn_time_ms\": 28252.324}", "{\"n\": 10398, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.92, \"learn_time_ms\": 28286.708}", "{\"n\": 10399, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.92, \"learn_time_ms\": 28287.418}", "{\"n\": 10400, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.89, \"learn_time_ms\": 28263.348}", "{\"n\": 10401, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.53, \"learn_time_ms\": 28242.761}", "{\"n\": 10402, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.51, \"learn_time_ms\": 28228.673}", "{\"n\": 10403, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.51, \"learn_time_ms\": 28257.454}", "{\"n\": 10404, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.39, \"learn_time_ms\": 28247.262}", "{\"n\": 10405, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.86, \"learn_time_ms\": 28264.529}", "{\"n\": 10406, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3374.69, \"learn_time_ms\": 28263.197}", "{\"n\": 10407, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.05, \"learn_time_ms\": 28314.379}", "{\"n\": 10408, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3380.21, \"learn_time_ms\": 28281.685}", "{\"n\": 10409, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3380.67, \"learn_time_ms\": 28228.837}", "{\"n\": 10410, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3382.47, \"learn_time_ms\": 28217.058}", "{\"n\": 10411, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.03, \"learn_time_ms\": 28206.635}", "{\"n\": 10412, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3375.9, \"learn_time_ms\": 28193.81}", "{\"n\": 10413, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3380.66, \"learn_time_ms\": 28193.413}", "{\"n\": 10414, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3375.27, \"learn_time_ms\": 28191.752}", "{\"n\": 10415, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3375.27, \"learn_time_ms\": 28181.971}", "{\"n\": 10416, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3375.68, \"learn_time_ms\": 28220.063}", "{\"n\": 10417, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3380.54, \"learn_time_ms\": 28179.997}", "{\"n\": 10418, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3381.92, \"learn_time_ms\": 28200.666}", "{\"n\": 10419, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.37, \"learn_time_ms\": 28267.913}", "{\"n\": 10420, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.37, \"learn_time_ms\": 28289.136}", "{\"n\": 10421, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.84, \"learn_time_ms\": 28287.559}", "{\"n\": 10422, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.47, \"learn_time_ms\": 28307.383}", "{\"n\": 10423, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3372.69, \"learn_time_ms\": 28277.16}", "{\"n\": 10424, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3374.21, \"learn_time_ms\": 28278.694}", "{\"n\": 10425, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3370.62, \"learn_time_ms\": 28291.598}", "{\"n\": 10426, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3370.62, \"learn_time_ms\": 28301.978}", "{\"n\": 10427, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.03, \"learn_time_ms\": 28293.91}", "{\"n\": 10428, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3370.15, \"learn_time_ms\": 28324.848}", "{\"n\": 10429, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.74, \"learn_time_ms\": 28313.833}", "{\"n\": 10430, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.0, \"learn_time_ms\": 28347.447}", "{\"n\": 10431, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.68, \"learn_time_ms\": 28339.931}", "{\"n\": 10432, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.68, \"learn_time_ms\": 28350.344}", "{\"n\": 10433, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.17, \"learn_time_ms\": 28355.439}", "{\"n\": 10434, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.11, \"learn_time_ms\": 28389.153}", "{\"n\": 10435, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.59, \"learn_time_ms\": 28340.916}", "{\"n\": 10436, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.7, \"learn_time_ms\": 28302.161}", "{\"n\": 10437, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.7, \"learn_time_ms\": 28340.819}", "{\"n\": 10438, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.52, \"learn_time_ms\": 28296.6}", "{\"n\": 10439, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.66, \"learn_time_ms\": 28300.133}", "{\"n\": 10440, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.89, \"learn_time_ms\": 28262.688}", "{\"n\": 10441, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.43, \"learn_time_ms\": 28251.263}", "{\"n\": 10442, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.39, \"learn_time_ms\": 28208.437}", "{\"n\": 10443, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.69, \"learn_time_ms\": 28252.385}", "{\"n\": 10444, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.29, \"learn_time_ms\": 28200.969}", "{\"n\": 10445, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.83, \"learn_time_ms\": 28231.24}", "{\"n\": 10446, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.25, \"learn_time_ms\": 28235.327}", "{\"n\": 10447, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3353.78, \"learn_time_ms\": 28234.221}", "{\"n\": 10448, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.4, \"learn_time_ms\": 28258.132}", "{\"n\": 10449, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3360.4, \"learn_time_ms\": 28239.606}", "{\"n\": 10450, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3358.23, \"learn_time_ms\": 28249.545}", "{\"n\": 10451, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3354.82, \"learn_time_ms\": 28219.103}", "{\"n\": 10452, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.98, \"learn_time_ms\": 28230.032}", "{\"n\": 10453, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.98, \"learn_time_ms\": 28153.125}", "{\"n\": 10454, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3358.96, \"learn_time_ms\": 28156.755}", "{\"n\": 10455, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.12, \"learn_time_ms\": 28147.312}", "{\"n\": 10456, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.09, \"learn_time_ms\": 28131.887}", "{\"n\": 10457, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3350.14, \"learn_time_ms\": 28105.019}", "{\"n\": 10458, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.58, \"learn_time_ms\": 28122.37}", "{\"n\": 10459, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.19, \"learn_time_ms\": 28103.147}", "{\"n\": 10460, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.21, \"learn_time_ms\": 28087.616}", "{\"n\": 10461, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.21, \"learn_time_ms\": 28093.774}", "{\"n\": 10462, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.65, \"learn_time_ms\": 28079.686}", "{\"n\": 10463, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.65, \"learn_time_ms\": 28133.201}", "{\"n\": 10464, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.59, \"learn_time_ms\": 28122.885}", "{\"n\": 10465, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.52, \"learn_time_ms\": 28115.175}", "{\"n\": 10466, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.6, \"learn_time_ms\": 28095.705}", "{\"n\": 10467, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.44, \"learn_time_ms\": 28116.316}", "{\"n\": 10468, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.29, \"learn_time_ms\": 28079.18}", "{\"n\": 10469, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.29, \"learn_time_ms\": 28096.417}", "{\"n\": 10470, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.24, \"learn_time_ms\": 28104.916}", "{\"n\": 10471, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.24, \"learn_time_ms\": 28088.02}", "{\"n\": 10472, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.65, \"learn_time_ms\": 28126.332}", "{\"n\": 10473, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.69, \"learn_time_ms\": 28071.078}", "{\"n\": 10474, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.69, \"learn_time_ms\": 28043.906}", "{\"n\": 10475, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3333.09, \"learn_time_ms\": 28027.889}", "{\"n\": 10476, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.39, \"learn_time_ms\": 28028.803}", "{\"n\": 10477, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.39, \"learn_time_ms\": 27995.262}", "{\"n\": 10478, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.37, \"learn_time_ms\": 28014.425}", "{\"n\": 10479, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.78, \"learn_time_ms\": 28012.646}", "{\"n\": 10480, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.78, \"learn_time_ms\": 27992.323}", "{\"n\": 10481, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.01, \"learn_time_ms\": 28016.687}", "{\"n\": 10482, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.01, \"learn_time_ms\": 27957.549}", "{\"n\": 10483, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.01, \"learn_time_ms\": 28007.656}", "{\"n\": 10484, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.01, \"learn_time_ms\": 28048.153}", "{\"n\": 10485, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.27, \"learn_time_ms\": 28057.346}", "{\"n\": 10486, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.28, \"learn_time_ms\": 28076.186}", "{\"n\": 10487, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.52, \"learn_time_ms\": 28132.617}", "{\"n\": 10488, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3342.52, \"learn_time_ms\": 28088.389}", "{\"n\": 10489, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3344.71, \"learn_time_ms\": 28120.118}", "{\"n\": 10490, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.12, \"learn_time_ms\": 28130.272}", "{\"n\": 10491, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.32, \"learn_time_ms\": 28125.622}", "{\"n\": 10492, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.93, \"learn_time_ms\": 28197.397}", "{\"n\": 10493, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.53, \"learn_time_ms\": 28219.711}", "{\"n\": 10494, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.43, \"learn_time_ms\": 28239.574}", "{\"n\": 10495, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.53, \"learn_time_ms\": 28223.084}", "{\"n\": 10496, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.58, \"learn_time_ms\": 28212.52}", "{\"n\": 10497, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.58, \"learn_time_ms\": 28109.648}", "{\"n\": 10498, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.79, \"learn_time_ms\": 28139.855}", "{\"n\": 10499, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.79, \"learn_time_ms\": 28132.995}", "{\"n\": 10500, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.41, \"learn_time_ms\": 28137.369}", "{\"n\": 10501, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.97, \"learn_time_ms\": 28154.135}", "{\"n\": 10502, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.04, \"learn_time_ms\": 28119.227}", "{\"n\": 10503, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.13, \"learn_time_ms\": 28081.181}", "{\"n\": 10504, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.07, \"learn_time_ms\": 28076.371}", "{\"n\": 10505, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.07, \"learn_time_ms\": 28071.566}", "{\"n\": 10506, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.62, \"learn_time_ms\": 28085.409}", "{\"n\": 10507, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.96, \"learn_time_ms\": 28138.435}", "{\"n\": 10508, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.52, \"learn_time_ms\": 28132.586}", "{\"n\": 10509, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.31, \"learn_time_ms\": 28089.366}", "{\"n\": 10510, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.01, \"learn_time_ms\": 28118.624}", "{\"n\": 10511, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.01, \"learn_time_ms\": 28146.373}", "{\"n\": 10512, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.87, \"learn_time_ms\": 28123.126}", "{\"n\": 10513, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.2, \"learn_time_ms\": 28120.19}", "{\"n\": 10514, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.72, \"learn_time_ms\": 28089.02}", "{\"n\": 10515, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.27, \"learn_time_ms\": 28117.516}", "{\"n\": 10516, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.13, \"learn_time_ms\": 28125.275}", "{\"n\": 10517, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.15, \"learn_time_ms\": 28119.191}", "{\"n\": 10518, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.15, \"learn_time_ms\": 28127.382}", "{\"n\": 10519, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.7, \"learn_time_ms\": 28127.595}", "{\"n\": 10520, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.35, \"learn_time_ms\": 28092.61}", "{\"n\": 10521, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.35, \"learn_time_ms\": 28050.778}", "{\"n\": 10522, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.24, \"learn_time_ms\": 28064.807}", "{\"n\": 10523, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.45, \"learn_time_ms\": 28120.346}", "{\"n\": 10524, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.12, \"learn_time_ms\": 28164.122}", "{\"n\": 10525, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.04, \"learn_time_ms\": 28177.702}", "{\"n\": 10526, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.14, \"learn_time_ms\": 28172.254}", "{\"n\": 10527, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.74, \"learn_time_ms\": 28174.124}", "{\"n\": 10528, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.09, \"learn_time_ms\": 28167.629}", "{\"n\": 10529, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.53, \"learn_time_ms\": 28234.03}", "{\"n\": 10530, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.64, \"learn_time_ms\": 28234.006}", "{\"n\": 10531, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.76, \"learn_time_ms\": 28274.106}", "{\"n\": 10532, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.66, \"learn_time_ms\": 28256.816}", "{\"n\": 10533, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.66, \"learn_time_ms\": 28209.613}", "{\"n\": 10534, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.48, \"learn_time_ms\": 28165.854}", "{\"n\": 10535, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.93, \"learn_time_ms\": 28138.967}", "{\"n\": 10536, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.53, \"learn_time_ms\": 28130.418}", "{\"n\": 10537, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.99, \"learn_time_ms\": 28181.5}", "{\"n\": 10538, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.08, \"learn_time_ms\": 28164.179}", "{\"n\": 10539, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.64, \"learn_time_ms\": 28124.656}", "{\"n\": 10540, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.39, \"learn_time_ms\": 28100.246}", "{\"n\": 10541, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.94, \"learn_time_ms\": 28100.114}", "{\"n\": 10542, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.61, \"learn_time_ms\": 28112.66}", "{\"n\": 10543, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.3, \"learn_time_ms\": 28137.286}", "{\"n\": 10544, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.13, \"learn_time_ms\": 28187.794}", "{\"n\": 10545, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.13, \"learn_time_ms\": 28198.63}", "{\"n\": 10546, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.31, \"learn_time_ms\": 28224.132}", "{\"n\": 10547, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.28, \"learn_time_ms\": 28194.195}", "{\"n\": 10548, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.7, \"learn_time_ms\": 28204.801}", "{\"n\": 10549, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.7, \"learn_time_ms\": 28212.558}", "{\"n\": 10550, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.53, \"learn_time_ms\": 28244.281}", "{\"n\": 10551, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.53, \"learn_time_ms\": 28212.316}", "{\"n\": 10552, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.73, \"learn_time_ms\": 28226.701}", "{\"n\": 10553, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.22, \"learn_time_ms\": 28215.5}", "{\"n\": 10554, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.41, \"learn_time_ms\": 28210.872}", "{\"n\": 10555, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3352.23, \"learn_time_ms\": 28216.416}", "{\"n\": 10556, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.23, \"learn_time_ms\": 28220.206}", "{\"n\": 10557, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.83, \"learn_time_ms\": 28200.11}", "{\"n\": 10558, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.32, \"learn_time_ms\": 28216.307}", "{\"n\": 10559, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.38, \"learn_time_ms\": 28175.503}", "{\"n\": 10560, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3350.13, \"learn_time_ms\": 28132.232}", "{\"n\": 10561, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.44, \"learn_time_ms\": 28145.47}", "{\"n\": 10562, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.25, \"learn_time_ms\": 28133.933}", "{\"n\": 10563, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.15, \"learn_time_ms\": 28144.146}", "{\"n\": 10564, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.43, \"learn_time_ms\": 28118.075}", "{\"n\": 10565, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.58, \"learn_time_ms\": 28073.855}", "{\"n\": 10566, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.12, \"learn_time_ms\": 28067.173}", "{\"n\": 10567, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.68, \"learn_time_ms\": 28082.7}", "{\"n\": 10568, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.95, \"learn_time_ms\": 28081.844}", "{\"n\": 10569, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.95, \"learn_time_ms\": 28090.499}", "{\"n\": 10570, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.09, \"learn_time_ms\": 28108.706}", "{\"n\": 10571, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.84, \"learn_time_ms\": 28094.417}", "{\"n\": 10572, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.25, \"learn_time_ms\": 28104.987}", "{\"n\": 10573, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.1, \"learn_time_ms\": 28096.889}", "{\"n\": 10574, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.13, \"learn_time_ms\": 28121.308}", "{\"n\": 10575, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.69, \"learn_time_ms\": 28154.201}", "{\"n\": 10576, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.5, \"learn_time_ms\": 28164.287}", "{\"n\": 10577, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.98, \"learn_time_ms\": 28155.295}", "{\"n\": 10578, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.16, \"learn_time_ms\": 28158.198}", "{\"n\": 10579, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.84, \"learn_time_ms\": 28192.921}", "{\"n\": 10580, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.23, \"learn_time_ms\": 28207.75}", "{\"n\": 10581, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.33, \"learn_time_ms\": 28217.678}", "{\"n\": 10582, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.33, \"learn_time_ms\": 28193.728}", "{\"n\": 10583, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.15, \"learn_time_ms\": 28171.472}", "{\"n\": 10584, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.0, \"learn_time_ms\": 28129.184}", "{\"n\": 10585, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.53, \"learn_time_ms\": 28134.161}", "{\"n\": 10586, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.87, \"learn_time_ms\": 28110.766}", "{\"n\": 10587, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.1, \"learn_time_ms\": 28072.834}", "{\"n\": 10588, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.5, \"learn_time_ms\": 28050.369}", "{\"n\": 10589, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.99, \"learn_time_ms\": 28049.033}", "{\"n\": 10590, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.11, \"learn_time_ms\": 28049.028}", "{\"n\": 10591, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.78, \"learn_time_ms\": 28057.279}", "{\"n\": 10592, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.04, \"learn_time_ms\": 28082.929}", "{\"n\": 10593, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.25, \"learn_time_ms\": 28107.788}", "{\"n\": 10594, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.0, \"learn_time_ms\": 28141.833}", "{\"n\": 10595, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.81, \"learn_time_ms\": 28186.025}", "{\"n\": 10596, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.08, \"learn_time_ms\": 28199.63}", "{\"n\": 10597, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.71, \"learn_time_ms\": 28291.023}", "{\"n\": 10598, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.71, \"learn_time_ms\": 28312.592}", "{\"n\": 10599, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.91, \"learn_time_ms\": 28256.22}", "{\"n\": 10600, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.37, \"learn_time_ms\": 28221.506}", "{\"n\": 10601, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.47, \"learn_time_ms\": 28191.324}", "{\"n\": 10602, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.58, \"learn_time_ms\": 28178.773}", "{\"n\": 10603, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.91, \"learn_time_ms\": 28156.009}", "{\"n\": 10604, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.25, \"learn_time_ms\": 28138.962}", "{\"n\": 10605, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.25, \"learn_time_ms\": 28089.856}", "{\"n\": 10606, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.46, \"learn_time_ms\": 28112.686}", "{\"n\": 10607, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.45, \"learn_time_ms\": 28058.974}", "{\"n\": 10608, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.59, \"learn_time_ms\": 28038.226}", "{\"n\": 10609, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.3, \"learn_time_ms\": 28098.483}", "{\"n\": 10610, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.39, \"learn_time_ms\": 28153.897}", "{\"n\": 10611, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.78, \"learn_time_ms\": 28166.584}", "{\"n\": 10612, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.99, \"learn_time_ms\": 28124.734}", "{\"n\": 10613, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.36, \"learn_time_ms\": 28093.608}", "{\"n\": 10614, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.33, \"learn_time_ms\": 28190.482}", "{\"n\": 10615, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.69, \"learn_time_ms\": 28166.943}", "{\"n\": 10616, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.29, \"learn_time_ms\": 28117.377}", "{\"n\": 10617, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.4, \"learn_time_ms\": 28088.029}", "{\"n\": 10618, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.15, \"learn_time_ms\": 28104.029}", "{\"n\": 10619, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.59, \"learn_time_ms\": 28085.255}", "{\"n\": 10620, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.16, \"learn_time_ms\": 28052.971}", "{\"n\": 10621, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.63, \"learn_time_ms\": 28036.491}", "{\"n\": 10622, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.31, \"learn_time_ms\": 28114.72}", "{\"n\": 10623, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.18, \"learn_time_ms\": 28183.593}", "{\"n\": 10624, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.18, \"learn_time_ms\": 28094.419}", "{\"n\": 10625, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.18, \"learn_time_ms\": 28135.049}", "{\"n\": 10626, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.85, \"learn_time_ms\": 28157.246}", "{\"n\": 10627, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.68, \"learn_time_ms\": 28196.915}", "{\"n\": 10628, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.89, \"learn_time_ms\": 28210.583}", "{\"n\": 10629, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.89, \"learn_time_ms\": 28199.387}", "{\"n\": 10630, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.41, \"learn_time_ms\": 28233.952}", "{\"n\": 10631, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.22, \"learn_time_ms\": 28277.019}", "{\"n\": 10632, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.22, \"learn_time_ms\": 28246.68}", "{\"n\": 10633, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.39, \"learn_time_ms\": 28198.024}", "{\"n\": 10634, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.97, \"learn_time_ms\": 28207.929}", "{\"n\": 10635, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.34, \"learn_time_ms\": 28134.384}", "{\"n\": 10636, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.53, \"learn_time_ms\": 28171.15}", "{\"n\": 10637, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.55, \"learn_time_ms\": 28170.689}", "{\"n\": 10638, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3369.1, \"learn_time_ms\": 28130.621}", "{\"n\": 10639, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3368.52, \"learn_time_ms\": 28169.794}", "{\"n\": 10640, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.9, \"learn_time_ms\": 28179.026}", "{\"n\": 10641, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.05, \"learn_time_ms\": 28146.44}", "{\"n\": 10642, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.05, \"learn_time_ms\": 28197.52}", "{\"n\": 10643, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.42, \"learn_time_ms\": 28215.947}", "{\"n\": 10644, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3373.42, \"learn_time_ms\": 28202.193}", "{\"n\": 10645, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.06, \"learn_time_ms\": 28250.656}", "{\"n\": 10646, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.01, \"learn_time_ms\": 28226.737}", "{\"n\": 10647, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.76, \"learn_time_ms\": 28223.159}", "{\"n\": 10648, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3390.36, \"learn_time_ms\": 28234.17}", "{\"n\": 10649, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.64, \"learn_time_ms\": 28219.271}", "{\"n\": 10650, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.8, \"learn_time_ms\": 28174.081}", "{\"n\": 10651, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.73, \"learn_time_ms\": 28225.264}", "{\"n\": 10652, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3390.02, \"learn_time_ms\": 28162.86}", "{\"n\": 10653, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3395.89, \"learn_time_ms\": 28194.436}", "{\"n\": 10654, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3391.06, \"learn_time_ms\": 28194.618}", "{\"n\": 10655, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.26, \"learn_time_ms\": 28232.74}", "{\"n\": 10656, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.01, \"learn_time_ms\": 28231.756}", "{\"n\": 10657, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3392.97, \"learn_time_ms\": 28227.745}", "{\"n\": 10658, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3392.97, \"learn_time_ms\": 28211.064}", "{\"n\": 10659, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.1, \"learn_time_ms\": 28133.69}", "{\"n\": 10660, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3390.45, \"learn_time_ms\": 28153.806}", "{\"n\": 10661, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3374.75, \"learn_time_ms\": 28118.505}", "{\"n\": 10662, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3374.75, \"learn_time_ms\": 28123.628}", "{\"n\": 10663, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3376.99, \"learn_time_ms\": 28058.379}", "{\"n\": 10664, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3376.99, \"learn_time_ms\": 28018.082}", "{\"n\": 10665, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.71, \"learn_time_ms\": 27979.966}", "{\"n\": 10666, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.97, \"learn_time_ms\": 27963.523}", "{\"n\": 10667, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3375.16, \"learn_time_ms\": 27972.859}", "{\"n\": 10668, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3375.16, \"learn_time_ms\": 28020.597}", "{\"n\": 10669, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.29, \"learn_time_ms\": 28101.772}", "{\"n\": 10670, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3374.3, \"learn_time_ms\": 28117.21}", "{\"n\": 10671, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3367.61, \"learn_time_ms\": 28122.353}", "{\"n\": 10672, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3378.59, \"learn_time_ms\": 28134.269}", "{\"n\": 10673, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3378.51, \"learn_time_ms\": 28152.556}", "{\"n\": 10674, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.86, \"learn_time_ms\": 28205.836}", "{\"n\": 10675, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.86, \"learn_time_ms\": 28235.9}", "{\"n\": 10676, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.22, \"learn_time_ms\": 28220.389}", "{\"n\": 10677, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3375.31, \"learn_time_ms\": 28207.859}", "{\"n\": 10678, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3387.14, \"learn_time_ms\": 28164.765}", "{\"n\": 10679, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3387.14, \"learn_time_ms\": 28152.577}", "{\"n\": 10680, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.96, \"learn_time_ms\": 28121.849}", "{\"n\": 10681, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.96, \"learn_time_ms\": 28123.435}", "{\"n\": 10682, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.55, \"learn_time_ms\": 28155.997}", "{\"n\": 10683, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.4, \"learn_time_ms\": 28202.296}", "{\"n\": 10684, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.98, \"learn_time_ms\": 28208.803}", "{\"n\": 10685, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.98, \"learn_time_ms\": 28190.557}", "{\"n\": 10686, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.56, \"learn_time_ms\": 28218.765}", "{\"n\": 10687, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.98, \"learn_time_ms\": 28243.659}", "{\"n\": 10688, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3382.9, \"learn_time_ms\": 28253.201}", "{\"n\": 10689, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3384.04, \"learn_time_ms\": 28265.814}", "{\"n\": 10690, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.35, \"learn_time_ms\": 28284.324}", "{\"n\": 10691, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.35, \"learn_time_ms\": 28302.551}", "{\"n\": 10692, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3392.55, \"learn_time_ms\": 28269.535}", "{\"n\": 10693, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.16, \"learn_time_ms\": 28268.262}", "{\"n\": 10694, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3390.0, \"learn_time_ms\": 28258.61}", "{\"n\": 10695, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3397.72, \"learn_time_ms\": 28278.626}", "{\"n\": 10696, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3397.72, \"learn_time_ms\": 28267.629}", "{\"n\": 10697, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3398.82, \"learn_time_ms\": 28286.23}", "{\"n\": 10698, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3393.99, \"learn_time_ms\": 28282.109}", "{\"n\": 10699, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3387.41, \"learn_time_ms\": 28298.675}", "{\"n\": 10700, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3387.41, \"learn_time_ms\": 28290.787}", "{\"n\": 10701, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.6, \"learn_time_ms\": 28268.896}", "{\"n\": 10702, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.6, \"learn_time_ms\": 28298.021}", "{\"n\": 10703, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.78, \"learn_time_ms\": 28238.738}", "{\"n\": 10704, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.35, \"learn_time_ms\": 28228.894}", "{\"n\": 10705, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3381.34, \"learn_time_ms\": 28208.402}", "{\"n\": 10706, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3381.34, \"learn_time_ms\": 28196.033}", "{\"n\": 10707, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.33, \"learn_time_ms\": 28178.989}", "{\"n\": 10708, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.33, \"learn_time_ms\": 28200.469}", "{\"n\": 10709, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.58, \"learn_time_ms\": 28162.621}", "{\"n\": 10710, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.75, \"learn_time_ms\": 28176.374}", "{\"n\": 10711, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.96, \"learn_time_ms\": 28166.802}", "{\"n\": 10712, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.96, \"learn_time_ms\": 28088.201}", "{\"n\": 10713, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.32, \"learn_time_ms\": 28136.732}", "{\"n\": 10714, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.43, \"learn_time_ms\": 28134.948}", "{\"n\": 10715, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.63, \"learn_time_ms\": 28132.232}", "{\"n\": 10716, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.79, \"learn_time_ms\": 28199.814}", "{\"n\": 10717, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.39, \"learn_time_ms\": 28201.919}", "{\"n\": 10718, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.28, \"learn_time_ms\": 28168.348}", "{\"n\": 10719, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.28, \"learn_time_ms\": 28160.067}", "{\"n\": 10720, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.36, \"learn_time_ms\": 28118.04}", "{\"n\": 10721, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.65, \"learn_time_ms\": 28150.73}", "{\"n\": 10722, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.96, \"learn_time_ms\": 28206.128}", "{\"n\": 10723, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.01, \"learn_time_ms\": 28219.153}", "{\"n\": 10724, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.01, \"learn_time_ms\": 28207.469}", "{\"n\": 10725, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.01, \"learn_time_ms\": 28215.672}", "{\"n\": 10726, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.84, \"learn_time_ms\": 28154.632}", "{\"n\": 10727, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.08, \"learn_time_ms\": 28119.523}", "{\"n\": 10728, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.32, \"learn_time_ms\": 28113.817}", "{\"n\": 10729, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.48, \"learn_time_ms\": 28092.961}", "{\"n\": 10730, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3363.48, \"learn_time_ms\": 28134.245}", "{\"n\": 10731, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.5, \"learn_time_ms\": 28095.336}", "{\"n\": 10732, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.4, \"learn_time_ms\": 28090.686}", "{\"n\": 10733, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.23, \"learn_time_ms\": 28049.806}", "{\"n\": 10734, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.23, \"learn_time_ms\": 28092.604}", "{\"n\": 10735, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.6, \"learn_time_ms\": 28080.101}", "{\"n\": 10736, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.43, \"learn_time_ms\": 28091.139}", "{\"n\": 10737, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.43, \"learn_time_ms\": 28125.309}", "{\"n\": 10738, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.66, \"learn_time_ms\": 28184.775}", "{\"n\": 10739, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.66, \"learn_time_ms\": 28243.509}", "{\"n\": 10740, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.66, \"learn_time_ms\": 28218.383}", "{\"n\": 10741, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.76, \"learn_time_ms\": 28250.607}", "{\"n\": 10742, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.76, \"learn_time_ms\": 28243.104}", "{\"n\": 10743, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.12, \"learn_time_ms\": 28223.624}", "{\"n\": 10744, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.39, \"learn_time_ms\": 28181.179}", "{\"n\": 10745, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.39, \"learn_time_ms\": 28173.562}", "{\"n\": 10746, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.97, \"learn_time_ms\": 28166.087}", "{\"n\": 10747, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.97, \"learn_time_ms\": 28129.574}", "{\"n\": 10748, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.17, \"learn_time_ms\": 28112.954}", "{\"n\": 10749, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.47, \"learn_time_ms\": 28092.621}", "{\"n\": 10750, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.21, \"learn_time_ms\": 28133.241}", "{\"n\": 10751, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.21, \"learn_time_ms\": 28135.246}", "{\"n\": 10752, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.14, \"learn_time_ms\": 28188.342}", "{\"n\": 10753, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.57, \"learn_time_ms\": 28178.147}", "{\"n\": 10754, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.38, \"learn_time_ms\": 28188.284}", "{\"n\": 10755, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.57, \"learn_time_ms\": 28207.516}", "{\"n\": 10756, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.57, \"learn_time_ms\": 28231.626}", "{\"n\": 10757, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.18, \"learn_time_ms\": 28232.891}", "{\"n\": 10758, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.9, \"learn_time_ms\": 28198.556}", "{\"n\": 10759, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3362.59, \"learn_time_ms\": 28175.2}", "{\"n\": 10760, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.83, \"learn_time_ms\": 28171.78}", "{\"n\": 10761, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.91, \"learn_time_ms\": 28176.885}", "{\"n\": 10762, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.91, \"learn_time_ms\": 28159.006}", "{\"n\": 10763, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.91, \"learn_time_ms\": 28182.029}", "{\"n\": 10764, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.9, \"learn_time_ms\": 28171.179}", "{\"n\": 10765, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.58, \"learn_time_ms\": 28120.055}", "{\"n\": 10766, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.44, \"learn_time_ms\": 28132.412}", "{\"n\": 10767, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.67, \"learn_time_ms\": 28121.495}", "{\"n\": 10768, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.67, \"learn_time_ms\": 28116.51}", "{\"n\": 10769, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.57, \"learn_time_ms\": 28145.313}", "{\"n\": 10770, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.38, \"learn_time_ms\": 28122.148}", "{\"n\": 10771, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.38, \"learn_time_ms\": 28110.782}", "{\"n\": 10772, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.02, \"learn_time_ms\": 28092.823}", "{\"n\": 10773, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.02, \"learn_time_ms\": 28136.861}", "{\"n\": 10774, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.92, \"learn_time_ms\": 28146.18}", "{\"n\": 10775, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.84, \"learn_time_ms\": 28207.023}", "{\"n\": 10776, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.26, \"learn_time_ms\": 28170.243}", "{\"n\": 10777, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.99, \"learn_time_ms\": 28190.143}", "{\"n\": 10778, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.82, \"learn_time_ms\": 28197.888}", "{\"n\": 10779, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.82, \"learn_time_ms\": 28168.844}", "{\"n\": 10780, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.87, \"learn_time_ms\": 28167.591}", "{\"n\": 10781, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.87, \"learn_time_ms\": 28128.672}", "{\"n\": 10782, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.06, \"learn_time_ms\": 28078.594}", "{\"n\": 10783, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.95, \"learn_time_ms\": 28066.274}", "{\"n\": 10784, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.95, \"learn_time_ms\": 28052.778}", "{\"n\": 10785, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.25, \"learn_time_ms\": 28077.276}", "{\"n\": 10786, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3356.25, \"learn_time_ms\": 28076.121}", "{\"n\": 10787, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.34, \"learn_time_ms\": 28047.911}", "{\"n\": 10788, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.99, \"learn_time_ms\": 28076.922}", "{\"n\": 10789, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.15, \"learn_time_ms\": 28137.421}", "{\"n\": 10790, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.19, \"learn_time_ms\": 28152.953}", "{\"n\": 10791, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.19, \"learn_time_ms\": 28108.568}", "{\"n\": 10792, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.4, \"learn_time_ms\": 28209.617}", "{\"n\": 10793, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.75, \"learn_time_ms\": 28226.505}", "{\"n\": 10794, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.15, \"learn_time_ms\": 28228.323}", "{\"n\": 10795, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.09, \"learn_time_ms\": 28186.473}", "{\"n\": 10796, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3338.5, \"learn_time_ms\": 28188.742}", "{\"n\": 10797, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.71, \"learn_time_ms\": 28227.349}", "{\"n\": 10798, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.17, \"learn_time_ms\": 28184.576}", "{\"n\": 10799, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.43, \"learn_time_ms\": 28155.476}", "{\"n\": 10800, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.46, \"learn_time_ms\": 28162.952}", "{\"n\": 10801, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.25, \"learn_time_ms\": 28201.312}", "{\"n\": 10802, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.25, \"learn_time_ms\": 28120.725}", "{\"n\": 10803, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.84, \"learn_time_ms\": 28094.163}", "{\"n\": 10804, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.23, \"learn_time_ms\": 28117.687}", "{\"n\": 10805, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.31, \"learn_time_ms\": 28117.52}", "{\"n\": 10806, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.72, \"learn_time_ms\": 28099.976}", "{\"n\": 10807, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.72, \"learn_time_ms\": 28093.574}", "{\"n\": 10808, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.72, \"learn_time_ms\": 28113.726}", "{\"n\": 10809, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.23, \"learn_time_ms\": 28144.048}", "{\"n\": 10810, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.71, \"learn_time_ms\": 28120.901}", "{\"n\": 10811, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.1, \"learn_time_ms\": 28134.298}", "{\"n\": 10812, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.33, \"learn_time_ms\": 28114.717}", "{\"n\": 10813, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.33, \"learn_time_ms\": 28108.536}", "{\"n\": 10814, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.95, \"learn_time_ms\": 28137.629}", "{\"n\": 10815, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.51, \"learn_time_ms\": 28161.612}", "{\"n\": 10816, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.13, \"learn_time_ms\": 28151.834}", "{\"n\": 10817, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.34, \"learn_time_ms\": 28110.504}", "{\"n\": 10818, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.34, \"learn_time_ms\": 28129.104}", "{\"n\": 10819, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.34, \"learn_time_ms\": 28083.001}", "{\"n\": 10820, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3304.6, \"learn_time_ms\": 28094.988}", "{\"n\": 10821, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.81, \"learn_time_ms\": 28101.538}", "{\"n\": 10822, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.87, \"learn_time_ms\": 28155.291}", "{\"n\": 10823, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.16, \"learn_time_ms\": 28140.019}", "{\"n\": 10824, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.16, \"learn_time_ms\": 28068.461}", "{\"n\": 10825, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.16, \"learn_time_ms\": 28076.311}", "{\"n\": 10826, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.71, \"learn_time_ms\": 28100.67}", "{\"n\": 10827, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.14, \"learn_time_ms\": 28157.668}", "{\"n\": 10828, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.91, \"learn_time_ms\": 28152.084}", "{\"n\": 10829, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.91, \"learn_time_ms\": 28167.934}", "{\"n\": 10830, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.91, \"learn_time_ms\": 28175.325}", "{\"n\": 10831, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.28, \"learn_time_ms\": 28195.587}", "{\"n\": 10832, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.01, \"learn_time_ms\": 28189.807}", "{\"n\": 10833, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.69, \"learn_time_ms\": 28191.747}", "{\"n\": 10834, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.37, \"learn_time_ms\": 28229.162}", "{\"n\": 10835, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.37, \"learn_time_ms\": 28221.638}", "{\"n\": 10836, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.37, \"learn_time_ms\": 28215.892}", "{\"n\": 10837, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.36, \"learn_time_ms\": 28159.64}", "{\"n\": 10838, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3301.79, \"learn_time_ms\": 28132.916}", "{\"n\": 10839, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3304.9, \"learn_time_ms\": 28130.38}", "{\"n\": 10840, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3304.9, \"learn_time_ms\": 28086.218}", "{\"n\": 10841, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3304.9, \"learn_time_ms\": 28020.455}", "{\"n\": 10842, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3302.16, \"learn_time_ms\": 28008.925}", "{\"n\": 10843, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3308.56, \"learn_time_ms\": 27999.671}", "{\"n\": 10844, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3315.7, \"learn_time_ms\": 28039.436}", "{\"n\": 10845, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.62, \"learn_time_ms\": 28014.698}", "{\"n\": 10846, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.62, \"learn_time_ms\": 28024.461}", "{\"n\": 10847, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.62, \"learn_time_ms\": 28052.471}", "{\"n\": 10848, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.62, \"learn_time_ms\": 28092.821}", "{\"n\": 10849, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3326.26, \"learn_time_ms\": 28092.482}", "{\"n\": 10850, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3331.29, \"learn_time_ms\": 28108.212}", "{\"n\": 10851, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.83, \"learn_time_ms\": 28165.003}", "{\"n\": 10852, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.83, \"learn_time_ms\": 28210.688}", "{\"n\": 10853, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.83, \"learn_time_ms\": 28209.075}", "{\"n\": 10854, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3340.73, \"learn_time_ms\": 28163.302}", "{\"n\": 10855, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3340.89, \"learn_time_ms\": 28173.143}", "{\"n\": 10856, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3339.75, \"learn_time_ms\": 28193.463}", "{\"n\": 10857, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3339.75, \"learn_time_ms\": 28187.131}", "{\"n\": 10858, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3339.75, \"learn_time_ms\": 28176.027}", "{\"n\": 10859, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3338.31, \"learn_time_ms\": 28178.499}", "{\"n\": 10860, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3338.31, \"learn_time_ms\": 28171.333}", "{\"n\": 10861, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3337.94, \"learn_time_ms\": 28124.379}", "{\"n\": 10862, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3342.29, \"learn_time_ms\": 28090.349}", "{\"n\": 10863, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3342.29, \"learn_time_ms\": 28114.856}", "{\"n\": 10864, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3342.29, \"learn_time_ms\": 28124.73}", "{\"n\": 10865, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3337.25, \"learn_time_ms\": 28089.919}", "{\"n\": 10866, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3341.57, \"learn_time_ms\": 28050.906}", "{\"n\": 10867, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.86, \"learn_time_ms\": 28109.563}", "{\"n\": 10868, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3350.42, \"learn_time_ms\": 28124.013}", "{\"n\": 10869, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3350.42, \"learn_time_ms\": 28106.403}", "{\"n\": 10870, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.91, \"learn_time_ms\": 28149.335}", "{\"n\": 10871, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.28, \"learn_time_ms\": 28212.251}", "{\"n\": 10872, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.46, \"learn_time_ms\": 28189.852}", "{\"n\": 10873, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3354.21, \"learn_time_ms\": 28173.67}", "{\"n\": 10874, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3360.39, \"learn_time_ms\": 28164.003}", "{\"n\": 10875, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3356.96, \"learn_time_ms\": 28223.329}", "{\"n\": 10876, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3357.12, \"learn_time_ms\": 28225.937}", "{\"n\": 10877, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3357.12, \"learn_time_ms\": 28195.594}", "{\"n\": 10878, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3354.21, \"learn_time_ms\": 28201.878}", "{\"n\": 10879, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3355.44, \"learn_time_ms\": 28190.772}", "{\"n\": 10880, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3362.72, \"learn_time_ms\": 28128.857}", "{\"n\": 10881, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3363.99, \"learn_time_ms\": 28184.391}", "{\"n\": 10882, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3362.27, \"learn_time_ms\": 28219.422}", "{\"n\": 10883, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3362.27, \"learn_time_ms\": 28214.593}", "{\"n\": 10884, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3364.96, \"learn_time_ms\": 28173.271}", "{\"n\": 10885, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3366.12, \"learn_time_ms\": 28155.558}", "{\"n\": 10886, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3363.76, \"learn_time_ms\": 28177.989}", "{\"n\": 10887, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3360.46, \"learn_time_ms\": 28156.133}", "{\"n\": 10888, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3364.29, \"learn_time_ms\": 28127.484}", "{\"n\": 10889, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3375.0, \"learn_time_ms\": 28125.919}", "{\"n\": 10890, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3383.69, \"learn_time_ms\": 28193.328}", "{\"n\": 10891, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.63, \"learn_time_ms\": 28074.067}", "{\"n\": 10892, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3397.82, \"learn_time_ms\": 28029.935}", "{\"n\": 10893, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3397.82, \"learn_time_ms\": 28058.637}", "{\"n\": 10894, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3399.58, \"learn_time_ms\": 28081.953}", "{\"n\": 10895, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3397.87, \"learn_time_ms\": 28048.378}", "{\"n\": 10896, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3405.86, \"learn_time_ms\": 28051.848}", "{\"n\": 10897, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3406.19, \"learn_time_ms\": 28069.512}", "{\"n\": 10898, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3406.88, \"learn_time_ms\": 28092.119}", "{\"n\": 10899, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3404.03, \"learn_time_ms\": 28072.791}", "{\"n\": 10900, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3407.03, \"learn_time_ms\": 28034.472}", "{\"n\": 10901, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3407.03, \"learn_time_ms\": 28089.291}", "{\"n\": 10902, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3415.3, \"learn_time_ms\": 28111.456}", "{\"n\": 10903, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3416.58, \"learn_time_ms\": 28089.716}", "{\"n\": 10904, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3416.81, \"learn_time_ms\": 28111.656}", "{\"n\": 10905, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3417.78, \"learn_time_ms\": 28160.268}", "{\"n\": 10906, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3416.34, \"learn_time_ms\": 28155.834}", "{\"n\": 10907, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3411.25, \"learn_time_ms\": 28119.368}", "{\"n\": 10908, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3408.54, \"learn_time_ms\": 28101.054}", "{\"n\": 10909, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3408.54, \"learn_time_ms\": 28129.582}", "{\"n\": 10910, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3412.21, \"learn_time_ms\": 28152.028}", "{\"n\": 10911, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3415.39, \"learn_time_ms\": 28141.619}", "{\"n\": 10912, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3415.39, \"learn_time_ms\": 28145.62}", "{\"n\": 10913, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.05, \"learn_time_ms\": 28209.608}", "{\"n\": 10914, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.71, \"learn_time_ms\": 28203.513}", "{\"n\": 10915, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.53, \"learn_time_ms\": 28140.535}", "{\"n\": 10916, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.53, \"learn_time_ms\": 28109.691}", "{\"n\": 10917, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.19, \"learn_time_ms\": 28116.135}", "{\"n\": 10918, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.19, \"learn_time_ms\": 28082.6}", "{\"n\": 10919, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.13, \"learn_time_ms\": 28138.45}", "{\"n\": 10920, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3426.85, \"learn_time_ms\": 28109.358}", "{\"n\": 10921, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3426.85, \"learn_time_ms\": 28103.559}", "{\"n\": 10922, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.77, \"learn_time_ms\": 28095.936}", "{\"n\": 10923, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.01, \"learn_time_ms\": 28047.436}", "{\"n\": 10924, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.01, \"learn_time_ms\": 28056.729}", "{\"n\": 10925, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3412.2, \"learn_time_ms\": 28127.215}", "{\"n\": 10926, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3417.66, \"learn_time_ms\": 28163.868}", "{\"n\": 10927, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.12, \"learn_time_ms\": 28156.67}", "{\"n\": 10928, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.29, \"learn_time_ms\": 28155.015}", "{\"n\": 10929, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.29, \"learn_time_ms\": 28135.556}", "{\"n\": 10930, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.63, \"learn_time_ms\": 28172.327}", "{\"n\": 10931, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3431.21, \"learn_time_ms\": 28162.151}", "{\"n\": 10932, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.05, \"learn_time_ms\": 28194.445}", "{\"n\": 10933, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.36, \"learn_time_ms\": 28216.93}", "{\"n\": 10934, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.74, \"learn_time_ms\": 28220.285}", "{\"n\": 10935, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.47, \"learn_time_ms\": 28180.121}", "{\"n\": 10936, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.37, \"learn_time_ms\": 28159.801}", "{\"n\": 10937, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.37, \"learn_time_ms\": 28190.664}", "{\"n\": 10938, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.94, \"learn_time_ms\": 28244.741}", "{\"n\": 10939, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.94, \"learn_time_ms\": 28210.378}", "{\"n\": 10940, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.34, \"learn_time_ms\": 28170.327}", "{\"n\": 10941, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.8, \"learn_time_ms\": 28195.029}", "{\"n\": 10942, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.8, \"learn_time_ms\": 28171.031}", "{\"n\": 10943, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.8, \"learn_time_ms\": 28182.843}", "{\"n\": 10944, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.2, \"learn_time_ms\": 28163.047}", "{\"n\": 10945, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.92, \"learn_time_ms\": 28167.146}", "{\"n\": 10946, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.92, \"learn_time_ms\": 28215.344}", "{\"n\": 10947, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.85, \"learn_time_ms\": 28192.817}", "{\"n\": 10948, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.66, \"learn_time_ms\": 28182.168}", "{\"n\": 10949, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3426.39, \"learn_time_ms\": 28150.186}", "{\"n\": 10950, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.3, \"learn_time_ms\": 28164.762}", "{\"n\": 10951, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3426.18, \"learn_time_ms\": 28142.964}", "{\"n\": 10952, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.43, \"learn_time_ms\": 28129.668}", "{\"n\": 10953, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.08, \"learn_time_ms\": 28110.942}", "{\"n\": 10954, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3435.59, \"learn_time_ms\": 28075.378}", "{\"n\": 10955, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3431.68, \"learn_time_ms\": 28096.673}", "{\"n\": 10956, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3431.68, \"learn_time_ms\": 28071.834}", "{\"n\": 10957, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3426.49, \"learn_time_ms\": 28096.734}", "{\"n\": 10958, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.71, \"learn_time_ms\": 28113.976}", "{\"n\": 10959, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.22, \"learn_time_ms\": 28200.763}", "{\"n\": 10960, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.22, \"learn_time_ms\": 28215.277}", "{\"n\": 10961, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3419.35, \"learn_time_ms\": 28286.458}", "{\"n\": 10962, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3422.9, \"learn_time_ms\": 28278.809}", "{\"n\": 10963, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3422.9, \"learn_time_ms\": 28280.7}", "{\"n\": 10964, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.66, \"learn_time_ms\": 28286.587}", "{\"n\": 10965, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.61, \"learn_time_ms\": 28210.841}", "{\"n\": 10966, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.64, \"learn_time_ms\": 28165.444}", "{\"n\": 10967, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.64, \"learn_time_ms\": 28184.951}", "{\"n\": 10968, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3411.8, \"learn_time_ms\": 28156.64}", "{\"n\": 10969, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.04, \"learn_time_ms\": 28073.557}", "{\"n\": 10970, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3419.84, \"learn_time_ms\": 28050.554}", "{\"n\": 10971, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.27, \"learn_time_ms\": 27977.463}", "{\"n\": 10972, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.74, \"learn_time_ms\": 28006.089}", "{\"n\": 10973, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.74, \"learn_time_ms\": 27974.519}", "{\"n\": 10974, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.63, \"learn_time_ms\": 28030.495}", "{\"n\": 10975, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3411.34, \"learn_time_ms\": 28068.173}", "{\"n\": 10976, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.54, \"learn_time_ms\": 28069.827}", "{\"n\": 10977, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.3, \"learn_time_ms\": 28023.042}", "{\"n\": 10978, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.55, \"learn_time_ms\": 28013.336}", "{\"n\": 10979, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.88, \"learn_time_ms\": 28037.479}", "{\"n\": 10980, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.02, \"learn_time_ms\": 28075.201}", "{\"n\": 10981, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.72, \"learn_time_ms\": 28119.897}", "{\"n\": 10982, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.72, \"learn_time_ms\": 28081.146}", "{\"n\": 10983, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.44, \"learn_time_ms\": 28118.091}", "{\"n\": 10984, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.96, \"learn_time_ms\": 28100.369}", "{\"n\": 10985, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.38, \"learn_time_ms\": 28135.541}", "{\"n\": 10986, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.02, \"learn_time_ms\": 28155.746}", "{\"n\": 10987, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.67, \"learn_time_ms\": 28166.796}", "{\"n\": 10988, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.67, \"learn_time_ms\": 28192.179}", "{\"n\": 10989, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.18, \"learn_time_ms\": 28224.965}", "{\"n\": 10990, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.65, \"learn_time_ms\": 28230.711}", "{\"n\": 10991, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.38, \"learn_time_ms\": 28204.548}", "{\"n\": 10992, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.31, \"learn_time_ms\": 28231.247}", "{\"n\": 10993, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.71, \"learn_time_ms\": 28231.905}", "{\"n\": 10994, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.92, \"learn_time_ms\": 28187.8}", "{\"n\": 10995, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.86, \"learn_time_ms\": 28161.369}", "{\"n\": 10996, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.99, \"learn_time_ms\": 28168.167}", "{\"n\": 10997, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.67, \"learn_time_ms\": 28156.367}", "{\"n\": 10998, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.34, \"learn_time_ms\": 28133.255}", "{\"n\": 10999, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.77, \"learn_time_ms\": 28118.753}", "{\"n\": 11000, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.92, \"learn_time_ms\": 28100.751}"]["{\"n\": 11001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29816.849}", "{\"n\": 11002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29471.585}", "{\"n\": 11003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29377.279}", "{\"n\": 11004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29290.266}", "{\"n\": 11005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29258.378}", "{\"n\": 11006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29141.992}", "{\"n\": 11007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29059.86}", "{\"n\": 11008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29043.006}", "{\"n\": 11009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29008.384}", "{\"n\": 11010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28994.609}", "{\"n\": 11011, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3242.25, \"learn_time_ms\": 28869.597}", "{\"n\": 11012, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3335.625, \"learn_time_ms\": 28838.056}", "{\"n\": 11013, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3335.625, \"learn_time_ms\": 28814.612}", "{\"n\": 11014, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3335.625, \"learn_time_ms\": 28775.914}", "{\"n\": 11015, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3335.625, \"learn_time_ms\": 28715.458}", "{\"n\": 11016, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3335.625, \"learn_time_ms\": 28723.02}", "{\"n\": 11017, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.230769230769231, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3343.153846153846, \"learn_time_ms\": 28740.342}", "{\"n\": 11018, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.1875, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3328.4375, \"learn_time_ms\": 28710.257}", "{\"n\": 11019, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.1875, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3328.4375, \"learn_time_ms\": 28738.482}", "{\"n\": 11020, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.1875, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3328.4375, \"learn_time_ms\": 28713.607}", "{\"n\": 11021, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.1875, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3328.4375, \"learn_time_ms\": 28737.126}", "{\"n\": 11022, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.0588235294117645, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3339.705882352941, \"learn_time_ms\": 28736.791}", "{\"n\": 11023, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -4.695652173913044, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.1739130434785, \"learn_time_ms\": 28715.905}", "{\"n\": 11024, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -4.583333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.125, \"learn_time_ms\": 28729.307}", "{\"n\": 11025, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -4.583333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.125, \"learn_time_ms\": 28721.725}", "{\"n\": 11026, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -4.583333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.125, \"learn_time_ms\": 28708.663}", "{\"n\": 11027, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -4.583333333333333, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.125, \"learn_time_ms\": 28660.861}", "{\"n\": 11028, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.896551724137931, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3382.310344827586, \"learn_time_ms\": 28604.962}", "{\"n\": 11029, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.870967741935484, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3386.8709677419356, \"learn_time_ms\": 28558.268}", "{\"n\": 11030, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.78125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3400.0, \"learn_time_ms\": 28566.519}", "{\"n\": 11031, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.78125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3400.0, \"learn_time_ms\": 28551.491}", "{\"n\": 11032, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.78125, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3400.0, \"learn_time_ms\": 28550.042}", "{\"n\": 11033, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.878787878787879, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.090909090909, \"learn_time_ms\": 28482.794}", "{\"n\": 11034, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.9743589743589745, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.769230769231, \"learn_time_ms\": 28451.975}", "{\"n\": 11035, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -4.9743589743589745, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.769230769231, \"learn_time_ms\": 28453.328}", "{\"n\": 11036, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.075, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.9, \"learn_time_ms\": 28397.067}", "{\"n\": 11037, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.075, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.9, \"learn_time_ms\": 28432.752}", "{\"n\": 11038, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.075, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.9, \"learn_time_ms\": 28502.664}", "{\"n\": 11039, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.2727272727272725, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.9545454545455, \"learn_time_ms\": 28510.49}", "{\"n\": 11040, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.319148936170213, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.3829787234044, \"learn_time_ms\": 28482.853}", "{\"n\": 11041, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.3125, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.625, \"learn_time_ms\": 28448.208}", "{\"n\": 11042, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.3125, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.625, \"learn_time_ms\": 28424.094}", "{\"n\": 11043, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.3125, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.625, \"learn_time_ms\": 28446.045}", "{\"n\": 11044, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.346938775510204, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.1428571428573, \"learn_time_ms\": 28460.986}", "{\"n\": 11045, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.3584905660377355, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.4716981132074, \"learn_time_ms\": 28477.177}", "{\"n\": 11046, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.345454545454546, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.490909090909, \"learn_time_ms\": 28555.17}", "{\"n\": 11047, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.321428571428571, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.75, \"learn_time_ms\": 28558.655}", "{\"n\": 11048, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.321428571428571, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.75, \"learn_time_ms\": 28543.983}", "{\"n\": 11049, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.333333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.438596491228, \"learn_time_ms\": 28513.464}", "{\"n\": 11050, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.338983050847458, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.186440677966, \"learn_time_ms\": 28540.278}", "{\"n\": 11051, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.360655737704918, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.27868852459, \"learn_time_ms\": 28542.037}", "{\"n\": 11052, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.349206349206349, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.4920634920636, \"learn_time_ms\": 28554.143}", "{\"n\": 11053, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.28125, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.328125, \"learn_time_ms\": 28567.437}", "{\"n\": 11054, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.28125, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.328125, \"learn_time_ms\": 28554.36}", "{\"n\": 11055, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.276923076923077, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.0923076923077, \"learn_time_ms\": 28559.754}", "{\"n\": 11056, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.264705882352941, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.073529411765, \"learn_time_ms\": 28504.253}", "{\"n\": 11057, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.242857142857143, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.9857142857145, \"learn_time_ms\": 28516.367}", "{\"n\": 11058, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.236111111111111, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.1944444444443, \"learn_time_ms\": 28495.328}", "{\"n\": 11059, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.236111111111111, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.1944444444443, \"learn_time_ms\": 28512.71}", "{\"n\": 11060, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.236111111111111, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.1944444444443, \"learn_time_ms\": 28491.478}", "{\"n\": 11061, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.253333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.9466666666667, \"learn_time_ms\": 28503.839}", "{\"n\": 11062, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.246753246753247, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.5974025974024, \"learn_time_ms\": 28465.576}", "{\"n\": 11063, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.253164556962025, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.215189873418, \"learn_time_ms\": 28457.876}", "{\"n\": 11064, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2625, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.6375, \"learn_time_ms\": 28450.347}", "{\"n\": 11065, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2625, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.6375, \"learn_time_ms\": 28418.602}", "{\"n\": 11066, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.341463414634147, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.2195121951218, \"learn_time_ms\": 28428.457}", "{\"n\": 11067, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.385542168674699, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.5662650602408, \"learn_time_ms\": 28356.256}", "{\"n\": 11068, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4186046511627906, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.906976744186, \"learn_time_ms\": 28312.561}", "{\"n\": 11069, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3977272727272725, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.5227272727275, \"learn_time_ms\": 28276.976}", "{\"n\": 11070, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3977272727272725, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3377.5227272727275, \"learn_time_ms\": 28187.863}", "{\"n\": 11071, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.393258426966292, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.5955056179773, \"learn_time_ms\": 28194.84}", "{\"n\": 11072, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4222222222222225, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.766666666667, \"learn_time_ms\": 28182.536}", "{\"n\": 11073, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.417582417582418, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.4725274725274, \"learn_time_ms\": 28164.101}", "{\"n\": 11074, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3936170212765955, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.5851063829787, \"learn_time_ms\": 28152.599}", "{\"n\": 11075, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.416666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.4895833333335, \"learn_time_ms\": 28113.809}", "{\"n\": 11076, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.416666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.4895833333335, \"learn_time_ms\": 28105.904}", "{\"n\": 11077, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.463917525773196, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.1134020618556, \"learn_time_ms\": 28060.165}", "{\"n\": 11078, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.434343434343434, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.4646464646466, \"learn_time_ms\": 28071.879}", "{\"n\": 11079, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.35, \"learn_time_ms\": 28108.283}", "{\"n\": 11080, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.5, \"learn_time_ms\": 28196.467}", "{\"n\": 11081, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.37, \"learn_time_ms\": 28216.165}", "{\"n\": 11082, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.16, \"learn_time_ms\": 28288.946}", "{\"n\": 11083, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3388.16, \"learn_time_ms\": 28346.648}", "{\"n\": 11084, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.23, \"learn_time_ms\": 28359.338}", "{\"n\": 11085, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.36, \"learn_time_ms\": 28352.402}", "{\"n\": 11086, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.7, \"learn_time_ms\": 28290.784}", "{\"n\": 11087, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.88, \"learn_time_ms\": 28353.37}", "{\"n\": 11088, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.88, \"learn_time_ms\": 28408.429}", "{\"n\": 11089, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.45, \"learn_time_ms\": 28388.808}", "{\"n\": 11090, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.4, \"learn_time_ms\": 28352.532}", "{\"n\": 11091, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.88, \"learn_time_ms\": 28340.977}", "{\"n\": 11092, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.31, \"learn_time_ms\": 28292.734}", "{\"n\": 11093, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.79, \"learn_time_ms\": 28234.7}", "{\"n\": 11094, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.93, \"learn_time_ms\": 28231.346}", "{\"n\": 11095, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.16, \"learn_time_ms\": 28283.699}", "{\"n\": 11096, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.91, \"learn_time_ms\": 28391.191}", "{\"n\": 11097, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.04, \"learn_time_ms\": 28390.916}", "{\"n\": 11098, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.04, \"learn_time_ms\": 28350.755}", "{\"n\": 11099, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.16, \"learn_time_ms\": 28376.435}", "{\"n\": 11100, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.16, \"learn_time_ms\": 28419.224}", "{\"n\": 11101, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.86, \"learn_time_ms\": 28399.699}", "{\"n\": 11102, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.14, \"learn_time_ms\": 28435.812}", "{\"n\": 11103, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.87, \"learn_time_ms\": 28498.038}", "{\"n\": 11104, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.87, \"learn_time_ms\": 28485.069}", "{\"n\": 11105, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.22, \"learn_time_ms\": 28476.105}", "{\"n\": 11106, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.82, \"learn_time_ms\": 28392.949}", "{\"n\": 11107, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.03, \"learn_time_ms\": 28424.477}", "{\"n\": 11108, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.81, \"learn_time_ms\": 28454.425}", "{\"n\": 11109, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.64, \"learn_time_ms\": 28484.821}", "{\"n\": 11110, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.94, \"learn_time_ms\": 28484.763}", "{\"n\": 11111, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.79, \"learn_time_ms\": 28483.793}", "{\"n\": 11112, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.34, \"learn_time_ms\": 28458.874}", "{\"n\": 11113, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.34, \"learn_time_ms\": 28407.132}", "{\"n\": 11114, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.73, \"learn_time_ms\": 28447.863}", "{\"n\": 11115, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.73, \"learn_time_ms\": 28469.876}", "{\"n\": 11116, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.64, \"learn_time_ms\": 28531.237}", "{\"n\": 11117, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.64, \"learn_time_ms\": 28535.928}", "{\"n\": 11118, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.98, \"learn_time_ms\": 28535.91}", "{\"n\": 11119, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.93, \"learn_time_ms\": 28461.094}", "{\"n\": 11120, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.11, \"learn_time_ms\": 28479.22}", "{\"n\": 11121, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.96, \"learn_time_ms\": 28463.511}", "{\"n\": 11122, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.8, \"learn_time_ms\": 28448.459}", "{\"n\": 11123, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.16, \"learn_time_ms\": 28463.954}", "{\"n\": 11124, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.17, \"learn_time_ms\": 28462.875}", "{\"n\": 11125, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.42, \"learn_time_ms\": 28436.394}", "{\"n\": 11126, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.42, \"learn_time_ms\": 28481.514}", "{\"n\": 11127, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.59, \"learn_time_ms\": 28461.936}", "{\"n\": 11128, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.67, \"learn_time_ms\": 28447.319}", "{\"n\": 11129, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.93, \"learn_time_ms\": 28438.858}", "{\"n\": 11130, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.12, \"learn_time_ms\": 28435.906}", "{\"n\": 11131, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.92, \"learn_time_ms\": 28387.873}", "{\"n\": 11132, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.92, \"learn_time_ms\": 28373.892}", "{\"n\": 11133, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.9, \"learn_time_ms\": 28366.662}", "{\"n\": 11134, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.12, \"learn_time_ms\": 28379.939}", "{\"n\": 11135, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.12, \"learn_time_ms\": 28401.903}", "{\"n\": 11136, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.82, \"learn_time_ms\": 28338.174}", "{\"n\": 11137, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.38, \"learn_time_ms\": 28367.503}", "{\"n\": 11138, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.38, \"learn_time_ms\": 28341.166}", "{\"n\": 11139, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.0, \"learn_time_ms\": 28404.823}", "{\"n\": 11140, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.7, \"learn_time_ms\": 28350.284}", "{\"n\": 11141, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.26, \"learn_time_ms\": 28386.969}", "{\"n\": 11142, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.67, \"learn_time_ms\": 28413.769}", "{\"n\": 11143, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.67, \"learn_time_ms\": 28429.857}", "{\"n\": 11144, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.79, \"learn_time_ms\": 28401.337}", "{\"n\": 11145, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3386.44, \"learn_time_ms\": 28384.203}", "{\"n\": 11146, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.31, \"learn_time_ms\": 28404.925}", "{\"n\": 11147, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3383.61, \"learn_time_ms\": 28373.846}", "{\"n\": 11148, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.89, \"learn_time_ms\": 28389.375}", "{\"n\": 11149, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.24, \"learn_time_ms\": 28379.452}", "{\"n\": 11150, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.24, \"learn_time_ms\": 28454.558}", "{\"n\": 11151, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.89, \"learn_time_ms\": 28462.722}", "{\"n\": 11152, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.02, \"learn_time_ms\": 28445.998}", "{\"n\": 11153, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.35, \"learn_time_ms\": 28397.789}", "{\"n\": 11154, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.23, \"learn_time_ms\": 28368.717}", "{\"n\": 11155, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.08, \"learn_time_ms\": 28346.539}", "{\"n\": 11156, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3372.6, \"learn_time_ms\": 28359.134}", "{\"n\": 11157, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.55, \"learn_time_ms\": 28359.138}", "{\"n\": 11158, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.03, \"learn_time_ms\": 28402.185}", "{\"n\": 11159, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.35, \"learn_time_ms\": 28384.534}", "{\"n\": 11160, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.35, \"learn_time_ms\": 28277.96}", "{\"n\": 11161, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.15, \"learn_time_ms\": 28277.56}", "{\"n\": 11162, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3380.78, \"learn_time_ms\": 28225.219}", "{\"n\": 11163, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.1, \"learn_time_ms\": 28244.573}", "{\"n\": 11164, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.1, \"learn_time_ms\": 28218.915}", "{\"n\": 11165, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.17, \"learn_time_ms\": 28197.964}", "{\"n\": 11166, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.17, \"learn_time_ms\": 28124.89}", "{\"n\": 11167, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.27, \"learn_time_ms\": 28095.534}", "{\"n\": 11168, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.63, \"learn_time_ms\": 28017.714}", "{\"n\": 11169, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.15, \"learn_time_ms\": 28003.871}", "{\"n\": 11170, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.36, \"learn_time_ms\": 28010.473}", "{\"n\": 11171, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.36, \"learn_time_ms\": 28032.235}", "{\"n\": 11172, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.36, \"learn_time_ms\": 28103.367}", "{\"n\": 11173, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.03, \"learn_time_ms\": 28120.451}", "{\"n\": 11174, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.22, \"learn_time_ms\": 28104.523}", "{\"n\": 11175, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.26, \"learn_time_ms\": 28168.483}", "{\"n\": 11176, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.25, \"learn_time_ms\": 28200.209}", "{\"n\": 11177, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.25, \"learn_time_ms\": 28227.461}", "{\"n\": 11178, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.2, \"learn_time_ms\": 28294.174}", "{\"n\": 11179, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.14, \"learn_time_ms\": 28316.49}", "{\"n\": 11180, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.51, \"learn_time_ms\": 28375.921}", "{\"n\": 11181, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.67, \"learn_time_ms\": 28361.395}", "{\"n\": 11182, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.23, \"learn_time_ms\": 28375.383}", "{\"n\": 11183, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.35, \"learn_time_ms\": 28349.745}", "{\"n\": 11184, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.35, \"learn_time_ms\": 28390.872}", "{\"n\": 11185, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.72, \"learn_time_ms\": 28359.518}", "{\"n\": 11186, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.61, \"learn_time_ms\": 28402.364}", "{\"n\": 11187, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.61, \"learn_time_ms\": 28365.663}", "{\"n\": 11188, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.05, \"learn_time_ms\": 28374.361}", "{\"n\": 11189, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.15, \"learn_time_ms\": 28373.78}", "{\"n\": 11190, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.12, \"learn_time_ms\": 28377.882}", "{\"n\": 11191, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.9, \"learn_time_ms\": 28353.304}", "{\"n\": 11192, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.63, \"learn_time_ms\": 28297.384}", "{\"n\": 11193, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.86, \"learn_time_ms\": 28317.156}", "{\"n\": 11194, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.86, \"learn_time_ms\": 28309.105}", "{\"n\": 11195, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.83, \"learn_time_ms\": 28293.225}", "{\"n\": 11196, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.75, \"learn_time_ms\": 28263.857}", "{\"n\": 11197, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.02, \"learn_time_ms\": 28289.981}", "{\"n\": 11198, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.65, \"learn_time_ms\": 28254.832}", "{\"n\": 11199, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.65, \"learn_time_ms\": 28277.884}", "{\"n\": 11200, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.65, \"learn_time_ms\": 28264.301}", "{\"n\": 11201, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.85, \"learn_time_ms\": 28337.052}", "{\"n\": 11202, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.93, \"learn_time_ms\": 28365.109}", "{\"n\": 11203, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.76, \"learn_time_ms\": 28374.857}", "{\"n\": 11204, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.16, \"learn_time_ms\": 28384.1}", "{\"n\": 11205, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.1, \"learn_time_ms\": 28422.541}", "{\"n\": 11206, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.1, \"learn_time_ms\": 28375.16}", "{\"n\": 11207, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.6, \"learn_time_ms\": 28417.684}", "{\"n\": 11208, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.92, \"learn_time_ms\": 28423.855}", "{\"n\": 11209, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.73, \"learn_time_ms\": 28403.883}", "{\"n\": 11210, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.66, \"learn_time_ms\": 28406.748}", "{\"n\": 11211, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.66, \"learn_time_ms\": 28351.594}", "{\"n\": 11212, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.66, \"learn_time_ms\": 28376.125}", "{\"n\": 11213, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.87, \"learn_time_ms\": 28378.168}", "{\"n\": 11214, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.87, \"learn_time_ms\": 28334.17}", "{\"n\": 11215, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.77, \"learn_time_ms\": 28327.177}", "{\"n\": 11216, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.13, \"learn_time_ms\": 28403.663}", "{\"n\": 11217, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.13, \"learn_time_ms\": 28370.053}", "{\"n\": 11218, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.53, \"learn_time_ms\": 28382.686}", "{\"n\": 11219, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.11, \"learn_time_ms\": 28352.305}", "{\"n\": 11220, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.11, \"learn_time_ms\": 28344.392}", "{\"n\": 11221, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.85, \"learn_time_ms\": 28384.89}", "{\"n\": 11222, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.85, \"learn_time_ms\": 28277.543}", "{\"n\": 11223, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.85, \"learn_time_ms\": 28271.064}", "{\"n\": 11224, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.7, \"learn_time_ms\": 28330.507}", "{\"n\": 11225, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.85, \"learn_time_ms\": 28270.535}", "{\"n\": 11226, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.78, \"learn_time_ms\": 28237.708}", "{\"n\": 11227, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.19, \"learn_time_ms\": 28239.864}", "{\"n\": 11228, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.19, \"learn_time_ms\": 28219.112}", "{\"n\": 11229, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.3, \"learn_time_ms\": 28228.893}", "{\"n\": 11230, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.09, \"learn_time_ms\": 28231.757}", "{\"n\": 11231, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.83, \"learn_time_ms\": 28196.039}", "{\"n\": 11232, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.04, \"learn_time_ms\": 28259.332}", "{\"n\": 11233, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.04, \"learn_time_ms\": 28240.619}", "{\"n\": 11234, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.04, \"learn_time_ms\": 28244.388}", "{\"n\": 11235, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.27, \"learn_time_ms\": 28276.73}", "{\"n\": 11236, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.75, \"learn_time_ms\": 28302.647}", "{\"n\": 11237, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.67, \"learn_time_ms\": 28320.815}", "{\"n\": 11238, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.07, \"learn_time_ms\": 28253.622}", "{\"n\": 11239, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.07, \"learn_time_ms\": 28232.052}", "{\"n\": 11240, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.07, \"learn_time_ms\": 28240.626}", "{\"n\": 11241, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.34, \"learn_time_ms\": 28213.526}", "{\"n\": 11242, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.34, \"learn_time_ms\": 28188.137}", "{\"n\": 11243, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.01, \"learn_time_ms\": 28193.795}", "{\"n\": 11244, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.01, \"learn_time_ms\": 28177.816}", "{\"n\": 11245, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3362.01, \"learn_time_ms\": 28169.142}", "{\"n\": 11246, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.06, \"learn_time_ms\": 28158.018}", "{\"n\": 11247, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.06, \"learn_time_ms\": 28115.129}", "{\"n\": 11248, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.2, \"learn_time_ms\": 28183.336}", "{\"n\": 11249, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.78, \"learn_time_ms\": 28208.735}", "{\"n\": 11250, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.78, \"learn_time_ms\": 28216.14}", "{\"n\": 11251, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.78, \"learn_time_ms\": 28246.86}", "{\"n\": 11252, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.44, \"learn_time_ms\": 28341.022}", "{\"n\": 11253, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.44, \"learn_time_ms\": 28339.826}", "{\"n\": 11254, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.29, \"learn_time_ms\": 28303.283}", "{\"n\": 11255, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.29, \"learn_time_ms\": 28293.493}", "{\"n\": 11256, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.29, \"learn_time_ms\": 28268.631}", "{\"n\": 11257, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.77, \"learn_time_ms\": 28277.778}", "{\"n\": 11258, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.6, \"learn_time_ms\": 28234.929}", "{\"n\": 11259, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3380.16, \"learn_time_ms\": 28181.278}", "{\"n\": 11260, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.18, \"learn_time_ms\": 28125.74}", "{\"n\": 11261, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3381.18, \"learn_time_ms\": 28136.398}", "{\"n\": 11262, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.48, \"learn_time_ms\": 28062.327}", "{\"n\": 11263, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3375.34, \"learn_time_ms\": 28034.103}", "{\"n\": 11264, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.93, \"learn_time_ms\": 28085.193}", "{\"n\": 11265, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.13, \"learn_time_ms\": 28082.257}", "{\"n\": 11266, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.73, \"learn_time_ms\": 28109.2}", "{\"n\": 11267, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.73, \"learn_time_ms\": 28152.024}", "{\"n\": 11268, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.2, \"learn_time_ms\": 28191.257}", "{\"n\": 11269, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.2, \"learn_time_ms\": 28265.758}", "{\"n\": 11270, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3379.79, \"learn_time_ms\": 28317.941}", "{\"n\": 11271, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3390.04, \"learn_time_ms\": 28294.142}", "{\"n\": 11272, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3388.42, \"learn_time_ms\": 28282.321}", "{\"n\": 11273, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3388.42, \"learn_time_ms\": 28337.933}", "{\"n\": 11274, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3388.42, \"learn_time_ms\": 28331.39}", "{\"n\": 11275, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3374.57, \"learn_time_ms\": 28345.202}", "{\"n\": 11276, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3387.43, \"learn_time_ms\": 28335.757}", "{\"n\": 11277, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3384.07, \"learn_time_ms\": 28300.928}", "{\"n\": 11278, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3384.07, \"learn_time_ms\": 28315.465}", "{\"n\": 11279, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3384.07, \"learn_time_ms\": 28287.362}", "{\"n\": 11280, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3392.6, \"learn_time_ms\": 28194.372}", "{\"n\": 11281, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3406.07, \"learn_time_ms\": 28246.216}", "{\"n\": 11282, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3408.76, \"learn_time_ms\": 28284.939}", "{\"n\": 11283, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3409.79, \"learn_time_ms\": 28258.002}", "{\"n\": 11284, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3409.79, \"learn_time_ms\": 28218.264}", "{\"n\": 11285, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3409.79, \"learn_time_ms\": 28261.197}", "{\"n\": 11286, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3410.03, \"learn_time_ms\": 28225.669}", "{\"n\": 11287, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3409.61, \"learn_time_ms\": 28242.811}", "{\"n\": 11288, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3407.37, \"learn_time_ms\": 28224.998}", "{\"n\": 11289, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3411.49, \"learn_time_ms\": 28282.743}", "{\"n\": 11290, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3411.49, \"learn_time_ms\": 28339.635}", "{\"n\": 11291, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3409.87, \"learn_time_ms\": 28281.612}", "{\"n\": 11292, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3412.6, \"learn_time_ms\": 28275.657}", "{\"n\": 11293, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3414.81, \"learn_time_ms\": 28267.457}", "{\"n\": 11294, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3419.83, \"learn_time_ms\": 28298.971}", "{\"n\": 11295, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3426.97, \"learn_time_ms\": 28335.884}", "{\"n\": 11296, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3418.84, \"learn_time_ms\": 28371.576}", "{\"n\": 11297, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3418.84, \"learn_time_ms\": 28376.192}", "{\"n\": 11298, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3420.88, \"learn_time_ms\": 28388.874}", "{\"n\": 11299, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3422.7, \"learn_time_ms\": 28351.615}", "{\"n\": 11300, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3428.17, \"learn_time_ms\": 28374.052}", "{\"n\": 11301, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3424.07, \"learn_time_ms\": 28403.399}", "{\"n\": 11302, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3420.85, \"learn_time_ms\": 28415.664}", "{\"n\": 11303, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3419.72, \"learn_time_ms\": 28440.859}", "{\"n\": 11304, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3420.03, \"learn_time_ms\": 28399.908}", "{\"n\": 11305, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3428.44, \"learn_time_ms\": 28340.619}", "{\"n\": 11306, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3428.44, \"learn_time_ms\": 28372.718}", "{\"n\": 11307, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3430.38, \"learn_time_ms\": 28356.537}", "{\"n\": 11308, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3427.42, \"learn_time_ms\": 28330.69}", "{\"n\": 11309, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3431.23, \"learn_time_ms\": 28273.336}", "{\"n\": 11310, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3432.54, \"learn_time_ms\": 28279.881}", "{\"n\": 11311, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3433.57, \"learn_time_ms\": 28293.936}", "{\"n\": 11312, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3433.57, \"learn_time_ms\": 28269.721}", "{\"n\": 11313, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3437.4, \"learn_time_ms\": 28270.394}", "{\"n\": 11314, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3437.4, \"learn_time_ms\": 28323.321}", "{\"n\": 11315, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3435.58, \"learn_time_ms\": 28340.868}", "{\"n\": 11316, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3434.37, \"learn_time_ms\": 28317.524}", "{\"n\": 11317, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3432.82, \"learn_time_ms\": 28310.433}", "{\"n\": 11318, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3435.64, \"learn_time_ms\": 28262.262}", "{\"n\": 11319, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3428.63, \"learn_time_ms\": 28305.151}", "{\"n\": 11320, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3423.29, \"learn_time_ms\": 28283.583}", "{\"n\": 11321, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3424.15, \"learn_time_ms\": 28278.672}", "{\"n\": 11322, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3420.6, \"learn_time_ms\": 28311.416}", "{\"n\": 11323, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3419.33, \"learn_time_ms\": 28297.522}", "{\"n\": 11324, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3413.53, \"learn_time_ms\": 28274.101}", "{\"n\": 11325, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3413.53, \"learn_time_ms\": 28278.582}", "{\"n\": 11326, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3411.6, \"learn_time_ms\": 28269.971}", "{\"n\": 11327, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3416.66, \"learn_time_ms\": 28288.681}", "{\"n\": 11328, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3419.12, \"learn_time_ms\": 28357.224}", "{\"n\": 11329, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3421.1, \"learn_time_ms\": 28366.603}", "{\"n\": 11330, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3421.0, \"learn_time_ms\": 28390.302}", "{\"n\": 11331, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3420.6, \"learn_time_ms\": 28359.872}", "{\"n\": 11332, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3420.6, \"learn_time_ms\": 28291.65}", "{\"n\": 11333, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3423.65, \"learn_time_ms\": 28272.858}", "{\"n\": 11334, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3429.53, \"learn_time_ms\": 28309.214}", "{\"n\": 11335, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3430.12, \"learn_time_ms\": 28291.858}", "{\"n\": 11336, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3432.71, \"learn_time_ms\": 28329.654}", "{\"n\": 11337, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3427.37, \"learn_time_ms\": 28337.107}", "{\"n\": 11338, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3419.07, \"learn_time_ms\": 28257.812}", "{\"n\": 11339, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3422.78, \"learn_time_ms\": 28220.53}", "{\"n\": 11340, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.15, \"learn_time_ms\": 28201.656}", "{\"n\": 11341, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.56, \"learn_time_ms\": 28220.175}", "{\"n\": 11342, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.56, \"learn_time_ms\": 28216.887}", "{\"n\": 11343, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3425.89, \"learn_time_ms\": 28243.27}", "{\"n\": 11344, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3423.81, \"learn_time_ms\": 28161.81}", "{\"n\": 11345, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.26, \"learn_time_ms\": 28194.299}", "{\"n\": 11346, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.43, \"learn_time_ms\": 28176.264}", "{\"n\": 11347, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.58, \"learn_time_ms\": 28156.759}", "{\"n\": 11348, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.2, \"learn_time_ms\": 28208.799}", "{\"n\": 11349, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.2, \"learn_time_ms\": 28246.162}", "{\"n\": 11350, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.31, \"learn_time_ms\": 28194.278}", "{\"n\": 11351, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.31, \"learn_time_ms\": 28210.132}", "{\"n\": 11352, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.63, \"learn_time_ms\": 28295.443}", "{\"n\": 11353, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.35, \"learn_time_ms\": 28300.237}", "{\"n\": 11354, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.04, \"learn_time_ms\": 28396.403}", "{\"n\": 11355, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.42, \"learn_time_ms\": 28378.272}", "{\"n\": 11356, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.65, \"learn_time_ms\": 28370.222}", "{\"n\": 11357, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.17, \"learn_time_ms\": 28335.677}", "{\"n\": 11358, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.59, \"learn_time_ms\": 28367.688}", "{\"n\": 11359, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.09, \"learn_time_ms\": 28299.402}", "{\"n\": 11360, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.86, \"learn_time_ms\": 28350.46}", "{\"n\": 11361, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.23, \"learn_time_ms\": 28291.117}", "{\"n\": 11362, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.66, \"learn_time_ms\": 28253.61}", "{\"n\": 11363, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.0, \"learn_time_ms\": 28282.871}", "{\"n\": 11364, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.88, \"learn_time_ms\": 28235.567}", "{\"n\": 11365, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.8, \"learn_time_ms\": 28217.794}", "{\"n\": 11366, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.26, \"learn_time_ms\": 28168.899}", "{\"n\": 11367, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.32, \"learn_time_ms\": 28235.098}", "{\"n\": 11368, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.76, \"learn_time_ms\": 28252.252}", "{\"n\": 11369, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.58, \"learn_time_ms\": 28251.325}", "{\"n\": 11370, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.14, \"learn_time_ms\": 28222.34}", "{\"n\": 11371, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.24, \"learn_time_ms\": 28265.461}", "{\"n\": 11372, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.19, \"learn_time_ms\": 28244.836}", "{\"n\": 11373, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.78, \"learn_time_ms\": 28141.197}", "{\"n\": 11374, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.35, \"learn_time_ms\": 28175.324}", "{\"n\": 11375, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.19, \"learn_time_ms\": 28182.481}", "{\"n\": 11376, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.19, \"learn_time_ms\": 28186.776}", "{\"n\": 11377, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.66, \"learn_time_ms\": 28144.511}", "{\"n\": 11378, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.09, \"learn_time_ms\": 28068.037}", "{\"n\": 11379, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.29, \"learn_time_ms\": 28095.259}", "{\"n\": 11380, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.17, \"learn_time_ms\": 28110.302}", "{\"n\": 11381, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.84, \"learn_time_ms\": 28081.575}", "{\"n\": 11382, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.78, \"learn_time_ms\": 28092.44}", "{\"n\": 11383, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.78, \"learn_time_ms\": 28164.381}", "{\"n\": 11384, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.15, \"learn_time_ms\": 28136.353}", "{\"n\": 11385, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.15, \"learn_time_ms\": 28140.985}", "{\"n\": 11386, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.19, \"learn_time_ms\": 28137.215}", "{\"n\": 11387, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.52, \"learn_time_ms\": 28124.439}", "{\"n\": 11388, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.52, \"learn_time_ms\": 28184.484}", "{\"n\": 11389, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.54, \"learn_time_ms\": 28217.183}", "{\"n\": 11390, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.01, \"learn_time_ms\": 28244.355}", "{\"n\": 11391, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.84, \"learn_time_ms\": 28266.419}", "{\"n\": 11392, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.16, \"learn_time_ms\": 28309.502}", "{\"n\": 11393, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.78, \"learn_time_ms\": 28318.329}", "{\"n\": 11394, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.78, \"learn_time_ms\": 28315.902}", "{\"n\": 11395, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.49, \"learn_time_ms\": 28328.778}", "{\"n\": 11396, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.45, \"learn_time_ms\": 28361.256}", "{\"n\": 11397, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.4, \"learn_time_ms\": 28351.464}", "{\"n\": 11398, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3409.62, \"learn_time_ms\": 28361.468}", "{\"n\": 11399, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3409.62, \"learn_time_ms\": 28353.953}", "{\"n\": 11400, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.56, \"learn_time_ms\": 28305.486}", "{\"n\": 11401, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3416.57, \"learn_time_ms\": 28275.359}", "{\"n\": 11402, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3413.62, \"learn_time_ms\": 28234.007}", "{\"n\": 11403, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3411.28, \"learn_time_ms\": 28212.588}", "{\"n\": 11404, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.42, \"learn_time_ms\": 28214.285}", "{\"n\": 11405, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.42, \"learn_time_ms\": 28197.686}", "{\"n\": 11406, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.67, \"learn_time_ms\": 28235.086}", "{\"n\": 11407, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3419.04, \"learn_time_ms\": 28253.22}", "{\"n\": 11408, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3419.17, \"learn_time_ms\": 28213.175}", "{\"n\": 11409, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3419.81, \"learn_time_ms\": 28180.789}", "{\"n\": 11410, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3416.32, \"learn_time_ms\": 28253.351}", "{\"n\": 11411, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3413.39, \"learn_time_ms\": 28323.786}", "{\"n\": 11412, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3413.39, \"learn_time_ms\": 28314.271}", "{\"n\": 11413, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.92, \"learn_time_ms\": 28267.017}", "{\"n\": 11414, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.08, \"learn_time_ms\": 28307.784}", "{\"n\": 11415, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.11, \"learn_time_ms\": 28301.265}", "{\"n\": 11416, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.89, \"learn_time_ms\": 28199.567}", "{\"n\": 11417, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.89, \"learn_time_ms\": 28201.717}", "{\"n\": 11418, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3416.29, \"learn_time_ms\": 28223.399}", "{\"n\": 11419, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3419.94, \"learn_time_ms\": 28214.852}", "{\"n\": 11420, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3427.32, \"learn_time_ms\": 28147.587}", "{\"n\": 11421, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3425.86, \"learn_time_ms\": 28110.623}", "{\"n\": 11422, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.09, \"learn_time_ms\": 28100.498}", "{\"n\": 11423, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.09, \"learn_time_ms\": 28173.614}", "{\"n\": 11424, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3414.24, \"learn_time_ms\": 28092.79}", "{\"n\": 11425, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3414.74, \"learn_time_ms\": 28126.724}", "{\"n\": 11426, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3418.17, \"learn_time_ms\": 28214.35}", "{\"n\": 11427, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3418.65, \"learn_time_ms\": 28207.547}", "{\"n\": 11428, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3418.65, \"learn_time_ms\": 28197.619}", "{\"n\": 11429, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3423.06, \"learn_time_ms\": 28254.892}", "{\"n\": 11430, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3423.05, \"learn_time_ms\": 28265.589}", "{\"n\": 11431, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3423.05, \"learn_time_ms\": 28258.424}", "{\"n\": 11432, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.08, \"learn_time_ms\": 28300.628}", "{\"n\": 11433, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.08, \"learn_time_ms\": 28256.653}", "{\"n\": 11434, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.08, \"learn_time_ms\": 28319.339}", "{\"n\": 11435, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.42, \"learn_time_ms\": 28336.799}", "{\"n\": 11436, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3414.96, \"learn_time_ms\": 28334.116}", "{\"n\": 11437, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3415.15, \"learn_time_ms\": 28381.096}", "{\"n\": 11438, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.23, \"learn_time_ms\": 28408.834}", "{\"n\": 11439, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.23, \"learn_time_ms\": 28394.245}", "{\"n\": 11440, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.07, \"learn_time_ms\": 28444.366}", "{\"n\": 11441, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3414.72, \"learn_time_ms\": 28493.134}", "{\"n\": 11442, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3418.16, \"learn_time_ms\": 28455.923}", "{\"n\": 11443, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3423.37, \"learn_time_ms\": 28457.229}", "{\"n\": 11444, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3423.37, \"learn_time_ms\": 28461.067}", "{\"n\": 11445, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3420.72, \"learn_time_ms\": 28367.792}", "{\"n\": 11446, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.06, \"learn_time_ms\": 28366.939}", "{\"n\": 11447, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3415.88, \"learn_time_ms\": 28320.042}", "{\"n\": 11448, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3411.01, \"learn_time_ms\": 28311.891}", "{\"n\": 11449, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.56, \"learn_time_ms\": 28336.511}", "{\"n\": 11450, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.16, \"learn_time_ms\": 28312.261}", "{\"n\": 11451, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.16, \"learn_time_ms\": 28280.527}", "{\"n\": 11452, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.9, \"learn_time_ms\": 28343.774}", "{\"n\": 11453, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.23, \"learn_time_ms\": 28355.711}", "{\"n\": 11454, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3409.77, \"learn_time_ms\": 28340.1}", "{\"n\": 11455, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3409.77, \"learn_time_ms\": 28384.59}", "{\"n\": 11456, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3414.57, \"learn_time_ms\": 28361.954}", "{\"n\": 11457, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3420.77, \"learn_time_ms\": 28395.722}", "{\"n\": 11458, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3419.64, \"learn_time_ms\": 28385.617}", "{\"n\": 11459, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3419.04, \"learn_time_ms\": 28324.392}", "{\"n\": 11460, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.31, \"learn_time_ms\": 28274.101}", "{\"n\": 11461, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.31, \"learn_time_ms\": 28229.51}", "{\"n\": 11462, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3420.5, \"learn_time_ms\": 28194.322}", "{\"n\": 11463, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3419.26, \"learn_time_ms\": 28230.144}", "{\"n\": 11464, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3422.7, \"learn_time_ms\": 28246.327}", "{\"n\": 11465, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3434.34, \"learn_time_ms\": 28237.921}", "{\"n\": 11466, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3434.34, \"learn_time_ms\": 28207.283}", "{\"n\": 11467, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3434.34, \"learn_time_ms\": 28192.716}", "{\"n\": 11468, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.86, \"learn_time_ms\": 28228.163}", "{\"n\": 11469, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3431.24, \"learn_time_ms\": 28253.049}", "{\"n\": 11470, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3430.47, \"learn_time_ms\": 28324.84}", "{\"n\": 11471, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3426.7, \"learn_time_ms\": 28377.865}", "{\"n\": 11472, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3426.7, \"learn_time_ms\": 28386.752}", "{\"n\": 11473, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.99, \"learn_time_ms\": 28399.412}", "{\"n\": 11474, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.99, \"learn_time_ms\": 28355.823}", "{\"n\": 11475, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3441.44, \"learn_time_ms\": 28389.324}", "{\"n\": 11476, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3441.09, \"learn_time_ms\": 28450.564}", "{\"n\": 11477, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3442.36, \"learn_time_ms\": 28418.117}", "{\"n\": 11478, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3442.36, \"learn_time_ms\": 28383.624}", "{\"n\": 11479, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.59, \"learn_time_ms\": 28404.55}", "{\"n\": 11480, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3439.62, \"learn_time_ms\": 28361.104}", "{\"n\": 11481, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3444.74, \"learn_time_ms\": 28346.962}", "{\"n\": 11482, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3447.33, \"learn_time_ms\": 28266.07}", "{\"n\": 11483, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3447.33, \"learn_time_ms\": 28246.648}", "{\"n\": 11484, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3443.91, \"learn_time_ms\": 28267.01}", "{\"n\": 11485, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3437.44, \"learn_time_ms\": 28249.308}", "{\"n\": 11486, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3436.1, \"learn_time_ms\": 28201.159}", "{\"n\": 11487, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.97, \"learn_time_ms\": 28182.284}", "{\"n\": 11488, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3427.27, \"learn_time_ms\": 28136.244}", "{\"n\": 11489, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3427.27, \"learn_time_ms\": 28153.432}", "{\"n\": 11490, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3420.43, \"learn_time_ms\": 28111.532}", "{\"n\": 11491, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3404.23, \"learn_time_ms\": 28068.739}", "{\"n\": 11492, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.31, \"learn_time_ms\": 28132.736}", "{\"n\": 11493, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3411.71, \"learn_time_ms\": 28094.457}", "{\"n\": 11494, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3415.85, \"learn_time_ms\": 28073.411}", "{\"n\": 11495, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3415.89, \"learn_time_ms\": 28055.838}", "{\"n\": 11496, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3412.39, \"learn_time_ms\": 28100.798}", "{\"n\": 11497, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.08, \"learn_time_ms\": 28172.12}", "{\"n\": 11498, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.56, \"learn_time_ms\": 28212.342}", "{\"n\": 11499, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.64, \"learn_time_ms\": 28179.157}", "{\"n\": 11500, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.64, \"learn_time_ms\": 28237.038}", "{\"n\": 11501, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.87, \"learn_time_ms\": 28257.252}", "{\"n\": 11502, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.93, \"learn_time_ms\": 28257.282}", "{\"n\": 11503, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.15, \"learn_time_ms\": 28287.874}", "{\"n\": 11504, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.96, \"learn_time_ms\": 28341.337}", "{\"n\": 11505, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.68, \"learn_time_ms\": 28360.975}", "{\"n\": 11506, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.06, \"learn_time_ms\": 28340.066}", "{\"n\": 11507, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.79, \"learn_time_ms\": 28314.538}", "{\"n\": 11508, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.12, \"learn_time_ms\": 28336.994}", "{\"n\": 11509, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.24, \"learn_time_ms\": 28348.402}", "{\"n\": 11510, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.29, \"learn_time_ms\": 28354.82}", "{\"n\": 11511, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3396.28, \"learn_time_ms\": 28352.351}", "{\"n\": 11512, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.39, \"learn_time_ms\": 28379.0}", "{\"n\": 11513, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.8, \"learn_time_ms\": 28372.942}", "{\"n\": 11514, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.81, \"learn_time_ms\": 28346.421}", "{\"n\": 11515, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.81, \"learn_time_ms\": 28331.759}", "{\"n\": 11516, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.62, \"learn_time_ms\": 28371.236}", "{\"n\": 11517, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.4, \"learn_time_ms\": 28386.186}", "{\"n\": 11518, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.11, \"learn_time_ms\": 28325.77}", "{\"n\": 11519, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.76, \"learn_time_ms\": 28364.566}", "{\"n\": 11520, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3386.61, \"learn_time_ms\": 28357.112}", "{\"n\": 11521, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3392.5, \"learn_time_ms\": 28337.937}", "{\"n\": 11522, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.96, \"learn_time_ms\": 28339.476}", "{\"n\": 11523, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3392.07, \"learn_time_ms\": 28366.264}", "{\"n\": 11524, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3395.34, \"learn_time_ms\": 28351.054}", "{\"n\": 11525, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.13, \"learn_time_ms\": 28408.139}", "{\"n\": 11526, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.76, \"learn_time_ms\": 28371.218}", "{\"n\": 11527, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.76, \"learn_time_ms\": 28395.464}", "{\"n\": 11528, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3392.11, \"learn_time_ms\": 28421.095}", "{\"n\": 11529, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3390.51, \"learn_time_ms\": 28419.676}", "{\"n\": 11530, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.16, \"learn_time_ms\": 28446.849}", "{\"n\": 11531, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3393.11, \"learn_time_ms\": 28506.889}", "{\"n\": 11532, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.85, \"learn_time_ms\": 28488.755}", "{\"n\": 11533, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.85, \"learn_time_ms\": 28475.219}", "{\"n\": 11534, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.02, \"learn_time_ms\": 28483.284}", "{\"n\": 11535, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.02, \"learn_time_ms\": 28422.994}", "{\"n\": 11536, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.3, \"learn_time_ms\": 28403.735}", "{\"n\": 11537, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3375.65, \"learn_time_ms\": 28365.176}", "{\"n\": 11538, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.65, \"learn_time_ms\": 28396.577}", "{\"n\": 11539, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3373.75, \"learn_time_ms\": 28374.812}", "{\"n\": 11540, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3370.78, \"learn_time_ms\": 28351.803}", "{\"n\": 11541, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.04, \"learn_time_ms\": 28303.662}", "{\"n\": 11542, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3369.39, \"learn_time_ms\": 28239.451}", "{\"n\": 11543, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.19, \"learn_time_ms\": 28262.507}", "{\"n\": 11544, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3366.32, \"learn_time_ms\": 28244.574}", "{\"n\": 11545, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3368.22, \"learn_time_ms\": 28227.288}", "{\"n\": 11546, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.69, \"learn_time_ms\": 28281.0}", "{\"n\": 11547, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3365.69, \"learn_time_ms\": 28274.192}", "{\"n\": 11548, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3369.16, \"learn_time_ms\": 28227.177}", "{\"n\": 11549, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.03, \"learn_time_ms\": 28257.842}", "{\"n\": 11550, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.22, \"learn_time_ms\": 28293.371}", "{\"n\": 11551, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.81, \"learn_time_ms\": 28302.075}", "{\"n\": 11552, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.9, \"learn_time_ms\": 28346.523}", "{\"n\": 11553, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3366.95, \"learn_time_ms\": 28321.363}", "{\"n\": 11554, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3366.95, \"learn_time_ms\": 28352.729}", "{\"n\": 11555, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.6, \"learn_time_ms\": 28375.742}", "{\"n\": 11556, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.55, \"learn_time_ms\": 28324.084}", "{\"n\": 11557, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3374.91, \"learn_time_ms\": 28343.484}", "{\"n\": 11558, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3374.91, \"learn_time_ms\": 28343.789}", "{\"n\": 11559, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3375.78, \"learn_time_ms\": 28314.677}", "{\"n\": 11560, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.72, \"learn_time_ms\": 28327.262}", "{\"n\": 11561, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.41, \"learn_time_ms\": 28372.181}", "{\"n\": 11562, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.2, \"learn_time_ms\": 28429.947}", "{\"n\": 11563, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.95, \"learn_time_ms\": 28417.198}", "{\"n\": 11564, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.95, \"learn_time_ms\": 28389.568}", "{\"n\": 11565, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.21, \"learn_time_ms\": 28345.468}", "{\"n\": 11566, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.61, \"learn_time_ms\": 28388.575}", "{\"n\": 11567, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3387.9, \"learn_time_ms\": 28399.749}", "{\"n\": 11568, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3390.24, \"learn_time_ms\": 28442.888}", "{\"n\": 11569, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3390.24, \"learn_time_ms\": 28388.051}", "{\"n\": 11570, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3390.24, \"learn_time_ms\": 28315.657}", "{\"n\": 11571, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.87, \"learn_time_ms\": 28284.701}", "{\"n\": 11572, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3392.59, \"learn_time_ms\": 28212.236}", "{\"n\": 11573, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.36, \"learn_time_ms\": 28240.605}", "{\"n\": 11574, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.6, \"learn_time_ms\": 28276.041}", "{\"n\": 11575, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.6, \"learn_time_ms\": 28295.325}", "{\"n\": 11576, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3395.48, \"learn_time_ms\": 28285.602}", "{\"n\": 11577, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3396.43, \"learn_time_ms\": 28253.421}", "{\"n\": 11578, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.66, \"learn_time_ms\": 28265.331}", "{\"n\": 11579, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3396.22, \"learn_time_ms\": 28303.825}", "{\"n\": 11580, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3395.64, \"learn_time_ms\": 28378.956}", "{\"n\": 11581, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3393.93, \"learn_time_ms\": 28427.123}", "{\"n\": 11582, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3395.05, \"learn_time_ms\": 28446.166}", "{\"n\": 11583, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.26, \"learn_time_ms\": 28439.139}", "{\"n\": 11584, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.87, \"learn_time_ms\": 28418.373}", "{\"n\": 11585, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.64, \"learn_time_ms\": 28504.022}", "{\"n\": 11586, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.13, \"learn_time_ms\": 28458.604}", "{\"n\": 11587, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.13, \"learn_time_ms\": 28497.494}", "{\"n\": 11588, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.21, \"learn_time_ms\": 28464.75}", "{\"n\": 11589, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.21, \"learn_time_ms\": 28471.798}", "{\"n\": 11590, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3393.85, \"learn_time_ms\": 28405.132}", "{\"n\": 11591, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.96, \"learn_time_ms\": 28378.084}", "{\"n\": 11592, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.63, \"learn_time_ms\": 28351.426}", "{\"n\": 11593, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.63, \"learn_time_ms\": 28361.487}", "{\"n\": 11594, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.31, \"learn_time_ms\": 28320.899}", "{\"n\": 11595, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.31, \"learn_time_ms\": 28240.87}", "{\"n\": 11596, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3383.86, \"learn_time_ms\": 28250.176}", "{\"n\": 11597, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.54, \"learn_time_ms\": 28216.678}", "{\"n\": 11598, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.54, \"learn_time_ms\": 28225.025}", "{\"n\": 11599, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.54, \"learn_time_ms\": 28211.247}", "{\"n\": 11600, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.63, \"learn_time_ms\": 28193.7}", "{\"n\": 11601, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.36, \"learn_time_ms\": 28211.423}", "{\"n\": 11602, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.79, \"learn_time_ms\": 28268.186}", "{\"n\": 11603, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.23, \"learn_time_ms\": 28237.381}", "{\"n\": 11604, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.23, \"learn_time_ms\": 28291.17}", "{\"n\": 11605, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.23, \"learn_time_ms\": 28316.745}", "{\"n\": 11606, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.04, \"learn_time_ms\": 28342.267}", "{\"n\": 11607, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.55, \"learn_time_ms\": 28356.099}", "{\"n\": 11608, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.85, \"learn_time_ms\": 28359.29}", "{\"n\": 11609, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.41, \"learn_time_ms\": 28350.584}", "{\"n\": 11610, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.41, \"learn_time_ms\": 28419.643}", "{\"n\": 11611, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.41, \"learn_time_ms\": 28434.985}", "{\"n\": 11612, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.71, \"learn_time_ms\": 28388.641}", "{\"n\": 11613, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.01, \"learn_time_ms\": 28369.834}", "{\"n\": 11614, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.01, \"learn_time_ms\": 28379.405}", "{\"n\": 11615, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.71, \"learn_time_ms\": 28379.421}", "{\"n\": 11616, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.71, \"learn_time_ms\": 28373.663}", "{\"n\": 11617, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.17, \"learn_time_ms\": 28350.409}", "{\"n\": 11618, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3409.68, \"learn_time_ms\": 28362.92}", "{\"n\": 11619, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.34, \"learn_time_ms\": 28363.882}", "{\"n\": 11620, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.34, \"learn_time_ms\": 28309.706}", "{\"n\": 11621, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.16, \"learn_time_ms\": 28252.702}", "{\"n\": 11622, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.16, \"learn_time_ms\": 28321.863}", "{\"n\": 11623, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.27, \"learn_time_ms\": 28371.359}", "{\"n\": 11624, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.16, \"learn_time_ms\": 28360.78}", "{\"n\": 11625, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.59, \"learn_time_ms\": 28387.959}", "{\"n\": 11626, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.59, \"learn_time_ms\": 28398.925}", "{\"n\": 11627, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.96, \"learn_time_ms\": 28441.714}", "{\"n\": 11628, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.23, \"learn_time_ms\": 28404.555}", "{\"n\": 11629, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.05, \"learn_time_ms\": 28444.355}", "{\"n\": 11630, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.01, \"learn_time_ms\": 28450.472}", "{\"n\": 11631, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.38, \"learn_time_ms\": 28430.068}", "{\"n\": 11632, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.52, \"learn_time_ms\": 28341.051}", "{\"n\": 11633, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.9, \"learn_time_ms\": 28306.879}", "{\"n\": 11634, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3410.17, \"learn_time_ms\": 28301.859}", "{\"n\": 11635, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.71, \"learn_time_ms\": 28233.913}", "{\"n\": 11636, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.77, \"learn_time_ms\": 28228.09}", "{\"n\": 11637, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.5, \"learn_time_ms\": 28147.67}", "{\"n\": 11638, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.5, \"learn_time_ms\": 28188.271}", "{\"n\": 11639, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.95, \"learn_time_ms\": 28153.989}", "{\"n\": 11640, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.38, \"learn_time_ms\": 28160.038}", "{\"n\": 11641, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.83, \"learn_time_ms\": 28198.115}", "{\"n\": 11642, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.82, \"learn_time_ms\": 28216.466}", "{\"n\": 11643, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.82, \"learn_time_ms\": 28228.679}", "{\"n\": 11644, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3404.18, \"learn_time_ms\": 28206.414}", "{\"n\": 11645, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.07, \"learn_time_ms\": 28232.528}", "{\"n\": 11646, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.07, \"learn_time_ms\": 28254.136}", "{\"n\": 11647, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.58, \"learn_time_ms\": 28329.758}", "{\"n\": 11648, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.12, \"learn_time_ms\": 28306.368}", "{\"n\": 11649, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.12, \"learn_time_ms\": 28366.081}", "{\"n\": 11650, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.99, \"learn_time_ms\": 28363.854}", "{\"n\": 11651, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.88, \"learn_time_ms\": 28373.227}", "{\"n\": 11652, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3415.51, \"learn_time_ms\": 28398.579}", "{\"n\": 11653, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3417.36, \"learn_time_ms\": 28427.607}", "{\"n\": 11654, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3418.42, \"learn_time_ms\": 28435.247}", "{\"n\": 11655, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3418.02, \"learn_time_ms\": 28453.098}", "{\"n\": 11656, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3412.22, \"learn_time_ms\": 28443.411}", "{\"n\": 11657, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3412.22, \"learn_time_ms\": 28428.104}", "{\"n\": 11658, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3414.69, \"learn_time_ms\": 28451.677}", "{\"n\": 11659, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3416.34, \"learn_time_ms\": 28373.828}", "{\"n\": 11660, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3415.86, \"learn_time_ms\": 28404.362}", "{\"n\": 11661, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3420.21, \"learn_time_ms\": 28394.704}", "{\"n\": 11662, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3423.9, \"learn_time_ms\": 28417.157}", "{\"n\": 11663, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.29, \"learn_time_ms\": 28374.333}", "{\"n\": 11664, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3434.0, \"learn_time_ms\": 28386.454}", "{\"n\": 11665, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.18, \"learn_time_ms\": 28365.356}", "{\"n\": 11666, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3432.22, \"learn_time_ms\": 28339.217}", "{\"n\": 11667, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3433.02, \"learn_time_ms\": 28332.611}", "{\"n\": 11668, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3433.02, \"learn_time_ms\": 28316.724}", "{\"n\": 11669, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3432.55, \"learn_time_ms\": 28355.996}", "{\"n\": 11670, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3432.79, \"learn_time_ms\": 28304.852}", "{\"n\": 11671, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3431.6, \"learn_time_ms\": 28294.426}", "{\"n\": 11672, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3431.7, \"learn_time_ms\": 28310.347}", "{\"n\": 11673, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3425.12, \"learn_time_ms\": 28280.343}", "{\"n\": 11674, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3425.12, \"learn_time_ms\": 28270.314}", "{\"n\": 11675, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.71, \"learn_time_ms\": 28279.328}", "{\"n\": 11676, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3420.2, \"learn_time_ms\": 28281.064}", "{\"n\": 11677, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3422.19, \"learn_time_ms\": 28288.389}", "{\"n\": 11678, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.44, \"learn_time_ms\": 28318.493}", "{\"n\": 11679, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.77, \"learn_time_ms\": 28314.862}", "{\"n\": 11680, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3433.36, \"learn_time_ms\": 28357.908}", "{\"n\": 11681, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3431.39, \"learn_time_ms\": 28395.775}", "{\"n\": 11682, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.93, \"learn_time_ms\": 28373.646}", "{\"n\": 11683, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.93, \"learn_time_ms\": 28393.367}", "{\"n\": 11684, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3433.22, \"learn_time_ms\": 28432.169}", "{\"n\": 11685, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3431.39, \"learn_time_ms\": 28435.913}", "{\"n\": 11686, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3434.7, \"learn_time_ms\": 28485.646}", "{\"n\": 11687, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3431.17, \"learn_time_ms\": 28459.061}", "{\"n\": 11688, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.6, \"learn_time_ms\": 28380.918}", "{\"n\": 11689, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.6, \"learn_time_ms\": 28412.271}", "{\"n\": 11690, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3424.39, \"learn_time_ms\": 28400.434}", "{\"n\": 11691, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3423.45, \"learn_time_ms\": 28397.014}", "{\"n\": 11692, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3424.56, \"learn_time_ms\": 28396.468}", "{\"n\": 11693, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3432.1, \"learn_time_ms\": 28429.505}", "{\"n\": 11694, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3433.37, \"learn_time_ms\": 28394.873}", "{\"n\": 11695, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3432.15, \"learn_time_ms\": 28421.243}", "{\"n\": 11696, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3432.15, \"learn_time_ms\": 28337.409}", "{\"n\": 11697, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3438.23, \"learn_time_ms\": 28377.569}", "{\"n\": 11698, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3427.63, \"learn_time_ms\": 28423.652}", "{\"n\": 11699, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3433.33, \"learn_time_ms\": 28364.966}", "{\"n\": 11700, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3439.72, \"learn_time_ms\": 28364.492}", "{\"n\": 11701, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3440.73, \"learn_time_ms\": 28333.36}", "{\"n\": 11702, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3440.53, \"learn_time_ms\": 28333.552}", "{\"n\": 11703, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3437.05, \"learn_time_ms\": 28345.479}", "{\"n\": 11704, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3437.59, \"learn_time_ms\": 28313.846}", "{\"n\": 11705, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3436.48, \"learn_time_ms\": 28289.347}", "{\"n\": 11706, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3434.95, \"learn_time_ms\": 28311.125}", "{\"n\": 11707, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3432.53, \"learn_time_ms\": 28302.973}", "{\"n\": 11708, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.29, \"learn_time_ms\": 28278.134}", "{\"n\": 11709, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.29, \"learn_time_ms\": 28274.51}", "{\"n\": 11710, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3437.33, \"learn_time_ms\": 28250.325}", "{\"n\": 11711, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3435.7, \"learn_time_ms\": 28223.282}", "{\"n\": 11712, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3435.7, \"learn_time_ms\": 28166.703}", "{\"n\": 11713, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3429.38, \"learn_time_ms\": 28107.239}", "{\"n\": 11714, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.76, \"learn_time_ms\": 28112.761}", "{\"n\": 11715, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.49, \"learn_time_ms\": 28124.969}", "{\"n\": 11716, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.49, \"learn_time_ms\": 28107.869}", "{\"n\": 11717, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3429.87, \"learn_time_ms\": 28092.28}", "{\"n\": 11718, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3425.78, \"learn_time_ms\": 28132.211}", "{\"n\": 11719, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3430.08, \"learn_time_ms\": 28138.353}", "{\"n\": 11720, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3426.81, \"learn_time_ms\": 28120.689}", "{\"n\": 11721, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3426.81, \"learn_time_ms\": 28189.711}", "{\"n\": 11722, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.34, \"learn_time_ms\": 28241.625}", "{\"n\": 11723, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.34, \"learn_time_ms\": 28291.159}", "{\"n\": 11724, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.26, \"learn_time_ms\": 28337.834}", "{\"n\": 11725, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.14, \"learn_time_ms\": 28336.424}", "{\"n\": 11726, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.14, \"learn_time_ms\": 28356.313}", "{\"n\": 11727, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3428.37, \"learn_time_ms\": 28361.924}", "{\"n\": 11728, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3426.73, \"learn_time_ms\": 28341.338}", "{\"n\": 11729, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3429.39, \"learn_time_ms\": 28339.152}", "{\"n\": 11730, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.67, \"learn_time_ms\": 28367.604}", "{\"n\": 11731, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.67, \"learn_time_ms\": 28323.775}", "{\"n\": 11732, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.02, \"learn_time_ms\": 28292.737}", "{\"n\": 11733, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3433.02, \"learn_time_ms\": 28247.984}", "{\"n\": 11734, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3434.39, \"learn_time_ms\": 28259.098}", "{\"n\": 11735, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.48, \"learn_time_ms\": 28207.165}", "{\"n\": 11736, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.59, \"learn_time_ms\": 28241.167}", "{\"n\": 11737, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.62, \"learn_time_ms\": 28226.905}", "{\"n\": 11738, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.44, \"learn_time_ms\": 28245.982}", "{\"n\": 11739, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.14, \"learn_time_ms\": 28259.545}", "{\"n\": 11740, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.0, \"learn_time_ms\": 28244.824}", "{\"n\": 11741, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.27, \"learn_time_ms\": 28200.604}", "{\"n\": 11742, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3413.27, \"learn_time_ms\": 28269.233}", "{\"n\": 11743, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.4, \"learn_time_ms\": 28280.583}", "{\"n\": 11744, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.34, \"learn_time_ms\": 28255.438}", "{\"n\": 11745, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3414.36, \"learn_time_ms\": 28291.85}", "{\"n\": 11746, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.83, \"learn_time_ms\": 28235.283}", "{\"n\": 11747, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.75, \"learn_time_ms\": 28269.775}", "{\"n\": 11748, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.75, \"learn_time_ms\": 28252.729}", "{\"n\": 11749, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.33, \"learn_time_ms\": 28262.755}", "{\"n\": 11750, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.5, \"learn_time_ms\": 28293.159}", "{\"n\": 11751, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.83, \"learn_time_ms\": 28360.251}", "{\"n\": 11752, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.43, \"learn_time_ms\": 28328.164}", "{\"n\": 11753, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3408.48, \"learn_time_ms\": 28345.599}", "{\"n\": 11754, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.42, \"learn_time_ms\": 28350.555}", "{\"n\": 11755, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.55, \"learn_time_ms\": 28360.799}", "{\"n\": 11756, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3407.15, \"learn_time_ms\": 28430.045}", "{\"n\": 11757, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.62, \"learn_time_ms\": 28409.341}", "{\"n\": 11758, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.85, \"learn_time_ms\": 28364.168}", "{\"n\": 11759, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.21, \"learn_time_ms\": 28395.51}", "{\"n\": 11760, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3400.21, \"learn_time_ms\": 28440.523}", "{\"n\": 11761, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.12, \"learn_time_ms\": 28402.996}", "{\"n\": 11762, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.39, \"learn_time_ms\": 28371.275}", "{\"n\": 11763, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.17, \"learn_time_ms\": 28378.831}", "{\"n\": 11764, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.48, \"learn_time_ms\": 28344.0}", "{\"n\": 11765, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.48, \"learn_time_ms\": 28320.263}", "{\"n\": 11766, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3395.48, \"learn_time_ms\": 28309.022}", "{\"n\": 11767, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.95, \"learn_time_ms\": 28323.629}", "{\"n\": 11768, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3398.91, \"learn_time_ms\": 28357.585}", "{\"n\": 11769, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3394.38, \"learn_time_ms\": 28357.558}", "{\"n\": 11770, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.2, \"learn_time_ms\": 28320.376}", "{\"n\": 11771, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.2, \"learn_time_ms\": 28360.022}", "{\"n\": 11772, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3386.2, \"learn_time_ms\": 28409.482}", "{\"n\": 11773, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.98, \"learn_time_ms\": 28366.058}", "{\"n\": 11774, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3385.28, \"learn_time_ms\": 28340.449}", "{\"n\": 11775, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3389.57, \"learn_time_ms\": 28312.293}", "{\"n\": 11776, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.35, \"learn_time_ms\": 28303.982}", "{\"n\": 11777, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3393.35, \"learn_time_ms\": 28287.163}", "{\"n\": 11778, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.98, \"learn_time_ms\": 28332.979}", "{\"n\": 11779, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.63, \"learn_time_ms\": 28287.636}", "{\"n\": 11780, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.16, \"learn_time_ms\": 28327.762}", "{\"n\": 11781, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.61, \"learn_time_ms\": 28322.374}", "{\"n\": 11782, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.61, \"learn_time_ms\": 28240.269}", "{\"n\": 11783, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.61, \"learn_time_ms\": 28306.432}", "{\"n\": 11784, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3402.28, \"learn_time_ms\": 28366.95}", "{\"n\": 11785, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.81, \"learn_time_ms\": 28458.078}", "{\"n\": 11786, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.04, \"learn_time_ms\": 28481.377}", "{\"n\": 11787, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.04, \"learn_time_ms\": 28506.329}", "{\"n\": 11788, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.04, \"learn_time_ms\": 28458.206}", "{\"n\": 11789, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.13, \"learn_time_ms\": 28450.53}", "{\"n\": 11790, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3374.68, \"learn_time_ms\": 28423.352}", "{\"n\": 11791, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.63, \"learn_time_ms\": 28391.22}", "{\"n\": 11792, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.63, \"learn_time_ms\": 28442.474}", "{\"n\": 11793, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.63, \"learn_time_ms\": 28418.09}", "{\"n\": 11794, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.63, \"learn_time_ms\": 28423.801}", "{\"n\": 11795, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.54, \"learn_time_ms\": 28397.738}", "{\"n\": 11796, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3364.78, \"learn_time_ms\": 28385.875}", "{\"n\": 11797, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.99, \"learn_time_ms\": 28383.479}", "{\"n\": 11798, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.99, \"learn_time_ms\": 28425.883}", "{\"n\": 11799, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.99, \"learn_time_ms\": 28438.099}", "{\"n\": 11800, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.57, \"learn_time_ms\": 28439.251}", "{\"n\": 11801, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.57, \"learn_time_ms\": 28455.359}", "{\"n\": 11802, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3349.72, \"learn_time_ms\": 28435.784}", "{\"n\": 11803, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.74, \"learn_time_ms\": 28429.724}", "{\"n\": 11804, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.74, \"learn_time_ms\": 28387.055}", "{\"n\": 11805, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.32, \"learn_time_ms\": 28391.26}", "{\"n\": 11806, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.31, \"learn_time_ms\": 28333.611}", "{\"n\": 11807, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.06, \"learn_time_ms\": 28293.726}", "{\"n\": 11808, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.5, \"learn_time_ms\": 28308.474}", "{\"n\": 11809, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.5, \"learn_time_ms\": 28308.636}", "{\"n\": 11810, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.29, \"learn_time_ms\": 28301.43}", "{\"n\": 11811, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.61, \"learn_time_ms\": 28297.76}", "{\"n\": 11812, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.3, \"learn_time_ms\": 28301.14}", "{\"n\": 11813, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.3, \"learn_time_ms\": 28311.752}", "{\"n\": 11814, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3345.3, \"learn_time_ms\": 28294.265}", "{\"n\": 11815, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3346.04, \"learn_time_ms\": 28246.985}", "{\"n\": 11816, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.97, \"learn_time_ms\": 28311.531}", "{\"n\": 11817, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3340.97, \"learn_time_ms\": 28336.036}", "{\"n\": 11818, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.23, \"learn_time_ms\": 28322.251}", "{\"n\": 11819, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.3, \"learn_time_ms\": 28333.089}", "{\"n\": 11820, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.16, \"learn_time_ms\": 28338.662}", "{\"n\": 11821, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3332.88, \"learn_time_ms\": 28355.255}", "{\"n\": 11822, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.88, \"learn_time_ms\": 28398.667}", "{\"n\": 11823, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3323.2, \"learn_time_ms\": 28403.778}", "{\"n\": 11824, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.64, \"learn_time_ms\": 28439.188}", "{\"n\": 11825, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.26, \"learn_time_ms\": 28429.306}", "{\"n\": 11826, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.84, \"learn_time_ms\": 28388.519}", "{\"n\": 11827, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.84, \"learn_time_ms\": 28433.412}", "{\"n\": 11828, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3318.63, \"learn_time_ms\": 28431.846}", "{\"n\": 11829, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.96, \"learn_time_ms\": 28430.587}", "{\"n\": 11830, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.08, \"learn_time_ms\": 28453.144}", "{\"n\": 11831, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.99, \"learn_time_ms\": 28450.202}", "{\"n\": 11832, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.99, \"learn_time_ms\": 28420.774}", "{\"n\": 11833, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.99, \"learn_time_ms\": 28382.64}", "{\"n\": 11834, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.91, \"learn_time_ms\": 28440.88}", "{\"n\": 11835, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.74, \"learn_time_ms\": 28500.633}", "{\"n\": 11836, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.81, \"learn_time_ms\": 28540.632}", "{\"n\": 11837, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.81, \"learn_time_ms\": 28481.091}", "{\"n\": 11838, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3329.81, \"learn_time_ms\": 28412.066}", "{\"n\": 11839, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.87, \"learn_time_ms\": 28422.483}", "{\"n\": 11840, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3334.41, \"learn_time_ms\": 28321.299}", "{\"n\": 11841, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3328.44, \"learn_time_ms\": 28328.354}", "{\"n\": 11842, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.7, \"learn_time_ms\": 28352.717}", "{\"n\": 11843, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.7, \"learn_time_ms\": 28347.314}", "{\"n\": 11844, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.7, \"learn_time_ms\": 28330.362}", "{\"n\": 11845, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.23, \"learn_time_ms\": 28341.246}", "{\"n\": 11846, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3322.23, \"learn_time_ms\": 28283.215}", "{\"n\": 11847, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.92, \"learn_time_ms\": 28271.726}", "{\"n\": 11848, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.74, \"learn_time_ms\": 28324.775}", "{\"n\": 11849, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.74, \"learn_time_ms\": 28331.518}", "{\"n\": 11850, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.25, \"learn_time_ms\": 28408.152}", "{\"n\": 11851, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3334.25, \"learn_time_ms\": 28413.503}", "{\"n\": 11852, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.9, \"learn_time_ms\": 28353.546}", "{\"n\": 11853, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.09, \"learn_time_ms\": 28386.414}", "{\"n\": 11854, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.07, \"learn_time_ms\": 28383.633}", "{\"n\": 11855, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3345.07, \"learn_time_ms\": 28341.328}", "{\"n\": 11856, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.35, \"learn_time_ms\": 28372.539}", "{\"n\": 11857, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.01, \"learn_time_ms\": 28371.128}", "{\"n\": 11858, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.02, \"learn_time_ms\": 28349.281}", "{\"n\": 11859, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.34, \"learn_time_ms\": 28327.273}", "{\"n\": 11860, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.34, \"learn_time_ms\": 28268.974}", "{\"n\": 11861, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.34, \"learn_time_ms\": 28237.475}", "{\"n\": 11862, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.11, \"learn_time_ms\": 28283.95}", "{\"n\": 11863, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3360.22, \"learn_time_ms\": 28280.12}", "{\"n\": 11864, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.13, \"learn_time_ms\": 28270.376}", "{\"n\": 11865, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.63, \"learn_time_ms\": 28289.206}", "{\"n\": 11866, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.63, \"learn_time_ms\": 28319.872}", "{\"n\": 11867, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.64, \"learn_time_ms\": 28333.02}", "{\"n\": 11868, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.5, \"learn_time_ms\": 28341.356}", "{\"n\": 11869, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.0, \"learn_time_ms\": 28368.625}", "{\"n\": 11870, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3352.96, \"learn_time_ms\": 28437.625}", "{\"n\": 11871, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.15, \"learn_time_ms\": 28411.045}", "{\"n\": 11872, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3355.15, \"learn_time_ms\": 28419.276}", "{\"n\": 11873, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3354.48, \"learn_time_ms\": 28479.436}", "{\"n\": 11874, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3347.94, \"learn_time_ms\": 28399.489}", "{\"n\": 11875, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.78, \"learn_time_ms\": 28403.577}", "{\"n\": 11876, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.4, \"learn_time_ms\": 28399.536}", "{\"n\": 11877, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.4, \"learn_time_ms\": 28406.305}", "{\"n\": 11878, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.86, \"learn_time_ms\": 28434.143}", "{\"n\": 11879, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.86, \"learn_time_ms\": 28397.619}", "{\"n\": 11880, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3359.47, \"learn_time_ms\": 28363.17}", "{\"n\": 11881, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.5, \"learn_time_ms\": 28422.884}", "{\"n\": 11882, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.03, \"learn_time_ms\": 28425.86}", "{\"n\": 11883, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.03, \"learn_time_ms\": 28375.993}", "{\"n\": 11884, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.16, \"learn_time_ms\": 28430.87}", "{\"n\": 11885, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.16, \"learn_time_ms\": 28451.564}", "{\"n\": 11886, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.37, \"learn_time_ms\": 28444.158}", "{\"n\": 11887, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3396.1, \"learn_time_ms\": 28466.334}", "{\"n\": 11888, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.89, \"learn_time_ms\": 28463.452}", "{\"n\": 11889, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.89, \"learn_time_ms\": 28471.393}", "{\"n\": 11890, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.92, \"learn_time_ms\": 28523.925}", "{\"n\": 11891, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.94, \"learn_time_ms\": 28453.676}", "{\"n\": 11892, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3401.81, \"learn_time_ms\": 28387.319}", "{\"n\": 11893, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.02, \"learn_time_ms\": 28380.404}", "{\"n\": 11894, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.02, \"learn_time_ms\": 28389.965}", "{\"n\": 11895, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3409.39, \"learn_time_ms\": 28307.539}", "{\"n\": 11896, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3406.07, \"learn_time_ms\": 28317.895}", "{\"n\": 11897, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.29, \"learn_time_ms\": 28307.815}", "{\"n\": 11898, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3405.22, \"learn_time_ms\": 28268.302}", "{\"n\": 11899, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.79, \"learn_time_ms\": 28295.757}", "{\"n\": 11900, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.13, \"learn_time_ms\": 28248.177}", "{\"n\": 11901, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.13, \"learn_time_ms\": 28283.111}", "{\"n\": 11902, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3392.21, \"learn_time_ms\": 28304.613}", "{\"n\": 11903, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3397.23, \"learn_time_ms\": 28303.221}", "{\"n\": 11904, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.96, \"learn_time_ms\": 28337.757}", "{\"n\": 11905, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.12, \"learn_time_ms\": 28317.72}", "{\"n\": 11906, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3395.1, \"learn_time_ms\": 28243.027}", "{\"n\": 11907, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3395.1, \"learn_time_ms\": 28225.791}", "{\"n\": 11908, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.06, \"learn_time_ms\": 28237.334}", "{\"n\": 11909, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3389.89, \"learn_time_ms\": 28205.507}", "{\"n\": 11910, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3389.89, \"learn_time_ms\": 28192.179}", "{\"n\": 11911, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.61, \"learn_time_ms\": 28166.272}", "{\"n\": 11912, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.61, \"learn_time_ms\": 28220.444}", "{\"n\": 11913, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3397.61, \"learn_time_ms\": 28207.909}", "{\"n\": 11914, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3402.1, \"learn_time_ms\": 28150.696}", "{\"n\": 11915, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.07, \"learn_time_ms\": 28201.283}", "{\"n\": 11916, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3396.01, \"learn_time_ms\": 28274.538}", "{\"n\": 11917, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.88, \"learn_time_ms\": 28278.311}", "{\"n\": 11918, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.88, \"learn_time_ms\": 28299.384}", "{\"n\": 11919, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3387.59, \"learn_time_ms\": 28279.208}", "{\"n\": 11920, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3386.04, \"learn_time_ms\": 28296.675}", "{\"n\": 11921, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3383.81, \"learn_time_ms\": 28332.866}", "{\"n\": 11922, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.15, \"learn_time_ms\": 28323.856}", "{\"n\": 11923, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3385.2, \"learn_time_ms\": 28329.448}", "{\"n\": 11924, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3377.09, \"learn_time_ms\": 28357.324}", "{\"n\": 11925, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3376.18, \"learn_time_ms\": 28378.778}", "{\"n\": 11926, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3383.86, \"learn_time_ms\": 28352.373}", "{\"n\": 11927, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3387.81, \"learn_time_ms\": 28343.513}", "{\"n\": 11928, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3392.47, \"learn_time_ms\": 28350.821}", "{\"n\": 11929, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.13, \"learn_time_ms\": 28367.964}", "{\"n\": 11930, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3388.57, \"learn_time_ms\": 28372.158}", "{\"n\": 11931, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.0, \"learn_time_ms\": 28355.642}", "{\"n\": 11932, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3381.0, \"learn_time_ms\": 28356.965}", "{\"n\": 11933, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3386.39, \"learn_time_ms\": 28348.333}", "{\"n\": 11934, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3390.2, \"learn_time_ms\": 28354.065}", "{\"n\": 11935, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3394.97, \"learn_time_ms\": 28334.996}", "{\"n\": 11936, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.41, \"learn_time_ms\": 28370.725}", "{\"n\": 11937, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.89, \"learn_time_ms\": 28379.282}", "{\"n\": 11938, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.89, \"learn_time_ms\": 28335.724}", "{\"n\": 11939, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.62, \"learn_time_ms\": 28345.121}", "{\"n\": 11940, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.03, \"learn_time_ms\": 28344.306}", "{\"n\": 11941, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.03, \"learn_time_ms\": 28398.901}", "{\"n\": 11942, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3399.63, \"learn_time_ms\": 28388.53}", "{\"n\": 11943, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.38, \"learn_time_ms\": 28402.806}", "{\"n\": 11944, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.38, \"learn_time_ms\": 28434.655}", "{\"n\": 11945, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3404.24, \"learn_time_ms\": 28448.609}", "{\"n\": 11946, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.43, \"learn_time_ms\": 28391.751}", "{\"n\": 11947, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.88, \"learn_time_ms\": 28372.424}", "{\"n\": 11948, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3404.92, \"learn_time_ms\": 28372.587}", "{\"n\": 11949, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.67, \"learn_time_ms\": 28364.78}", "{\"n\": 11950, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.67, \"learn_time_ms\": 28343.506}", "{\"n\": 11951, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3403.46, \"learn_time_ms\": 28338.342}", "{\"n\": 11952, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.02, \"learn_time_ms\": 28311.404}", "{\"n\": 11953, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3398.35, \"learn_time_ms\": 28346.436}", "{\"n\": 11954, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.24, \"learn_time_ms\": 28332.774}", "{\"n\": 11955, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.33, \"learn_time_ms\": 28320.967}", "{\"n\": 11956, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3401.63, \"learn_time_ms\": 28304.359}", "{\"n\": 11957, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3395.11, \"learn_time_ms\": 28373.399}", "{\"n\": 11958, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.06, \"learn_time_ms\": 28370.637}", "{\"n\": 11959, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.05, \"learn_time_ms\": 28312.543}", "{\"n\": 11960, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3391.05, \"learn_time_ms\": 28304.541}", "{\"n\": 11961, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.79, \"learn_time_ms\": 28237.648}", "{\"n\": 11962, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3382.12, \"learn_time_ms\": 28214.917}", "{\"n\": 11963, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.96, \"learn_time_ms\": 28119.531}", "{\"n\": 11964, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.96, \"learn_time_ms\": 28134.659}", "{\"n\": 11965, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.23, \"learn_time_ms\": 28141.639}", "{\"n\": 11966, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3383.37, \"learn_time_ms\": 28169.211}", "{\"n\": 11967, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3386.32, \"learn_time_ms\": 28146.298}", "{\"n\": 11968, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.57, \"learn_time_ms\": 28188.339}", "{\"n\": 11969, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.17, \"learn_time_ms\": 28214.514}", "{\"n\": 11970, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.55, \"learn_time_ms\": 28229.072}", "{\"n\": 11971, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.55, \"learn_time_ms\": 28293.391}", "{\"n\": 11972, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.93, \"learn_time_ms\": 28348.131}", "{\"n\": 11973, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.68, \"learn_time_ms\": 28391.815}", "{\"n\": 11974, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3379.03, \"learn_time_ms\": 28362.521}", "{\"n\": 11975, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.64, \"learn_time_ms\": 28347.39}", "{\"n\": 11976, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.49, \"learn_time_ms\": 28395.003}", "{\"n\": 11977, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.49, \"learn_time_ms\": 28344.741}", "{\"n\": 11978, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.81, \"learn_time_ms\": 28298.256}", "{\"n\": 11979, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.47, \"learn_time_ms\": 28326.291}", "{\"n\": 11980, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.51, \"learn_time_ms\": 28323.007}", "{\"n\": 11981, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.12, \"learn_time_ms\": 28286.868}", "{\"n\": 11982, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.42, \"learn_time_ms\": 28232.236}", "{\"n\": 11983, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.82, \"learn_time_ms\": 28161.481}", "{\"n\": 11984, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3381.74, \"learn_time_ms\": 28157.47}", "{\"n\": 11985, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.38, \"learn_time_ms\": 28147.131}", "{\"n\": 11986, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3377.18, \"learn_time_ms\": 28036.406}", "{\"n\": 11987, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.7, \"learn_time_ms\": 28060.822}", "{\"n\": 11988, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.7, \"learn_time_ms\": 28032.208}", "{\"n\": 11989, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3375.04, \"learn_time_ms\": 28040.85}", "{\"n\": 11990, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3370.85, \"learn_time_ms\": 28054.662}", "{\"n\": 11991, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3367.81, \"learn_time_ms\": 28037.853}", "{\"n\": 11992, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3365.5, \"learn_time_ms\": 28068.163}", "{\"n\": 11993, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.05, \"learn_time_ms\": 28174.638}", "{\"n\": 11994, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3361.05, \"learn_time_ms\": 28136.516}", "{\"n\": 11995, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3353.87, \"learn_time_ms\": 28162.82}", "{\"n\": 11996, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3358.44, \"learn_time_ms\": 28239.693}", "{\"n\": 11997, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3357.14, \"learn_time_ms\": 28188.358}", "{\"n\": 11998, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.45, \"learn_time_ms\": 28258.209}", "{\"n\": 11999, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.45, \"learn_time_ms\": 28268.0}", "{\"n\": 12000, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3351.45, \"learn_time_ms\": 28271.599}"]