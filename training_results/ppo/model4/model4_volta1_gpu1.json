["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 11362.269}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 11063.151}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10970.174}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.375, \"learn_time_ms\": 10921.135}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.2727272727273, \"learn_time_ms\": 10891.436}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.6875, \"learn_time_ms\": 10877.753}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 10868.516}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 10939.209}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.125, \"learn_time_ms\": 10997.457}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.8888888888889, \"learn_time_ms\": 11003.615}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.05, \"learn_time_ms\": 10945.022}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5833333333334, \"learn_time_ms\": 10943.626}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5833333333334, \"learn_time_ms\": 10941.471}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.125, \"learn_time_ms\": 10941.061}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2203389830509, \"learn_time_ms\": 10941.677}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34375, \"learn_time_ms\": 10939.564}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2361111111111, \"learn_time_ms\": 10937.821}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2361111111111, \"learn_time_ms\": 10872.961}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7125, \"learn_time_ms\": 10806.693}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5853658536586, \"learn_time_ms\": 10780.257}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1477272727273, \"learn_time_ms\": 10782.463}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2708333333334, \"learn_time_ms\": 10786.729}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2708333333334, \"learn_time_ms\": 10790.861}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 10793.156}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.86, \"learn_time_ms\": 10795.089}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 10798.117}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 10799.016}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 10801.524}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 10803.904}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.22, \"learn_time_ms\": 10866.849}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 10958.054}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 10998.96}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 10992.732}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.84, \"learn_time_ms\": 10990.317}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 10997.422}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.36, \"learn_time_ms\": 10999.537}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.03, \"learn_time_ms\": 10999.01}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.03, \"learn_time_ms\": 11002.289}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.24, \"learn_time_ms\": 11013.85}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.83, \"learn_time_ms\": 10968.561}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.66, \"learn_time_ms\": 10877.17}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.73, \"learn_time_ms\": 10835.077}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.73, \"learn_time_ms\": 10838.567}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.98, \"learn_time_ms\": 10838.02}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.06, \"learn_time_ms\": 10828.33}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.03, \"learn_time_ms\": 10823.413}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.78, \"learn_time_ms\": 10820.69}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.79, \"learn_time_ms\": 10814.031}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 10805.011}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1019.74, \"learn_time_ms\": 10789.642}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1019.75, \"learn_time_ms\": 10890.675}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.17, \"learn_time_ms\": 10993.694}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.22, \"learn_time_ms\": 11027.992}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.16, \"learn_time_ms\": 11053.356}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.09, \"learn_time_ms\": 11067.131}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.24, \"learn_time_ms\": 11080.464}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.12, \"learn_time_ms\": 11103.508}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.14, \"learn_time_ms\": 11122.067}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.28, \"learn_time_ms\": 11120.002}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.3, \"learn_time_ms\": 11118.77}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.87, \"learn_time_ms\": 11018.553}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.19, \"learn_time_ms\": 10914.736}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.21, \"learn_time_ms\": 10882.271}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.41, \"learn_time_ms\": 10859.04}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.44, \"learn_time_ms\": 10849.083}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.13, \"learn_time_ms\": 10835.346}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.5, \"learn_time_ms\": 10814.49}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.56, \"learn_time_ms\": 10798.003}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.54, \"learn_time_ms\": 10794.633}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.54, \"learn_time_ms\": 10828.174}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.21, \"learn_time_ms\": 10903.112}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.96, \"learn_time_ms\": 10987.192}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.94, \"learn_time_ms\": 10990.286}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 10991.132}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 10985.734}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.75, \"learn_time_ms\": 10988.032}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.47, \"learn_time_ms\": 10995.902}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.31, \"learn_time_ms\": 11001.878}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 11009.231}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 10979.646}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 10905.547}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.41, \"learn_time_ms\": 10827.927}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 10828.226}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 10831.111}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 10836.867}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 10839.549}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 10834.568}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.9, \"learn_time_ms\": 10890.476}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 10950.283}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 10950.82}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.8, \"learn_time_ms\": 10952.769}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.57, \"learn_time_ms\": 10950.339}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 10948.243}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 10946.9}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 10949.848}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.52, \"learn_time_ms\": 10951.829}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.7, \"learn_time_ms\": 10953.56}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 10897.039}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.44, \"learn_time_ms\": 10835.813}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.44, \"learn_time_ms\": 10834.104}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.82, \"learn_time_ms\": 10833.559}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.84, \"learn_time_ms\": 10835.432}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 10837.209}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 10845.958}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 10902.197}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.26, \"learn_time_ms\": 10991.41}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.09, \"learn_time_ms\": 11007.049}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.21, \"learn_time_ms\": 11008.008}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.29, \"learn_time_ms\": 11005.047}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.29, \"learn_time_ms\": 11002.877}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.81, \"learn_time_ms\": 11016.039}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 11019.898}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.98, \"learn_time_ms\": 11023.838}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 11027.712}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 10973.952}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.02, \"learn_time_ms\": 10884.636}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.75, \"learn_time_ms\": 10868.96}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.58, \"learn_time_ms\": 10867.871}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.55, \"learn_time_ms\": 10870.82}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 10876.493}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 10927.364}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 10998.808}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 10997.463}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 10988.672}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 10989.287}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.48, \"learn_time_ms\": 10991.258}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 10997.18}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 11001.9}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 11010.676}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 11030.7}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.37, \"learn_time_ms\": 10985.871}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 10921.3}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 10928.732}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 10934.307}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 10939.709}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.15, \"learn_time_ms\": 10981.625}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.92, \"learn_time_ms\": 11033.243}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.07, \"learn_time_ms\": 11097.357}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1, \"learn_time_ms\": 11118.027}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.17, \"learn_time_ms\": 11124.794}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1023.76, \"learn_time_ms\": 11134.404}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1023.81, \"learn_time_ms\": 11152.115}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1023.89, \"learn_time_ms\": 11171.119}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.37, \"learn_time_ms\": 11191.909}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.48, \"learn_time_ms\": 11207.812}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1022.46, \"learn_time_ms\": 11188.014}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1022.5, \"learn_time_ms\": 11153.873}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.45, \"learn_time_ms\": 11107.911}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.5, \"learn_time_ms\": 11096.795}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.87, \"learn_time_ms\": 11092.405}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.34, \"learn_time_ms\": 11122.068}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.52, \"learn_time_ms\": 11179.702}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1028.72, \"learn_time_ms\": 11174.921}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.99, \"learn_time_ms\": 11163.684}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.14, \"learn_time_ms\": 11160.347}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.13, \"learn_time_ms\": 11148.469}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.11, \"learn_time_ms\": 11142.165}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.5, \"learn_time_ms\": 11143.165}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.43, \"learn_time_ms\": 11139.826}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.32, \"learn_time_ms\": 11130.506}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.77, \"learn_time_ms\": 11085.407}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.45, \"learn_time_ms\": 11014.619}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.59, \"learn_time_ms\": 11005.757}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.7, \"learn_time_ms\": 11004.535}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.69, \"learn_time_ms\": 11032.857}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.69, \"learn_time_ms\": 11076.23}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.84, \"learn_time_ms\": 11109.993}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.92, \"learn_time_ms\": 11122.686}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.95, \"learn_time_ms\": 11142.69}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.57, \"learn_time_ms\": 11167.369}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.33, \"learn_time_ms\": 11190.663}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.85, \"learn_time_ms\": 11217.616}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.68, \"learn_time_ms\": 11240.247}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.07, \"learn_time_ms\": 11263.992}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.56, \"learn_time_ms\": 11249.458}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1032.77, \"learn_time_ms\": 11224.372}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.0, \"learn_time_ms\": 11202.016}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.42, \"learn_time_ms\": 11192.653}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.59, \"learn_time_ms\": 11220.017}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.74, \"learn_time_ms\": 11240.26}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.5, \"learn_time_ms\": 11240.446}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.5, \"learn_time_ms\": 11238.535}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.0, \"learn_time_ms\": 11234.48}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.29, \"learn_time_ms\": 11229.255}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1040.4, \"learn_time_ms\": 11228.836}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1040.71, \"learn_time_ms\": 11232.041}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1041.0, \"learn_time_ms\": 11239.636}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1042.2, \"learn_time_ms\": 11247.099}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1042.24, \"learn_time_ms\": 11216.513}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1045.28, \"learn_time_ms\": 11188.404}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1043.43, \"learn_time_ms\": 11189.516}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1043.77, \"learn_time_ms\": 11190.127}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1042.65, \"learn_time_ms\": 11193.876}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1042.31, \"learn_time_ms\": 11201.033}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1041.27, \"learn_time_ms\": 11216.015}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1041.5, \"learn_time_ms\": 11238.141}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1044.67, \"learn_time_ms\": 11252.065}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1044.3, \"learn_time_ms\": 11263.382}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1044.04, \"learn_time_ms\": 11279.527}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1043.6, \"learn_time_ms\": 11292.595}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1043.06, \"learn_time_ms\": 11302.162}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1040.07, \"learn_time_ms\": 11305.949}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1040.3, \"learn_time_ms\": 11311.857}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1042.23, \"learn_time_ms\": 11319.51}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1041.63, \"learn_time_ms\": 11315.167}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.89, \"learn_time_ms\": 11301.748}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.05, \"learn_time_ms\": 11295.313}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.02, \"learn_time_ms\": 11292.46}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.26, \"learn_time_ms\": 11287.961}", "{\"n\": 210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1039.87, \"learn_time_ms\": 11298.195}", "{\"n\": 211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1041.84, \"learn_time_ms\": 11302.557}", "{\"n\": 212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.83, \"learn_time_ms\": 11314.363}", "{\"n\": 213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.72, \"learn_time_ms\": 11319.528}", "{\"n\": 214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.7, \"learn_time_ms\": 11319.214}", "{\"n\": 215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1042.46, \"learn_time_ms\": 11319.347}", "{\"n\": 216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.53, \"learn_time_ms\": 11320.541}", "{\"n\": 217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1045.59, \"learn_time_ms\": 11319.496}", "{\"n\": 218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1042.51, \"learn_time_ms\": 11319.556}", "{\"n\": 219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1045.53, \"learn_time_ms\": 11319.127}", "{\"n\": 220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1045.75, \"learn_time_ms\": 11306.9}", "{\"n\": 221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1049.24, \"learn_time_ms\": 11299.441}", "{\"n\": 222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1049.86, \"learn_time_ms\": 11289.126}", "{\"n\": 223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1050.51, \"learn_time_ms\": 11286.882}", "{\"n\": 224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1050.92, \"learn_time_ms\": 11284.47}", "{\"n\": 225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1048.19, \"learn_time_ms\": 11284.64}", "{\"n\": 226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1048.27, \"learn_time_ms\": 11295.714}", "{\"n\": 227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.88, \"learn_time_ms\": 11309.525}", "{\"n\": 228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1054.35, \"learn_time_ms\": 11324.845}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1053.04, \"learn_time_ms\": 11327.602}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.21, \"learn_time_ms\": 11331.325}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.53, \"learn_time_ms\": 11332.575}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.07, \"learn_time_ms\": 11334.248}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1054.13, \"learn_time_ms\": 11335.815}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1054.68, \"learn_time_ms\": 11336.048}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.14, \"learn_time_ms\": 11337.928}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.28, \"learn_time_ms\": 11327.595}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.45, \"learn_time_ms\": 11315.346}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.43, \"learn_time_ms\": 11300.737}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1058.07, \"learn_time_ms\": 11301.88}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1058.27, \"learn_time_ms\": 11301.343}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.39, \"learn_time_ms\": 11304.057}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1054.52, \"learn_time_ms\": 11314.671}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1054.72, \"learn_time_ms\": 11324.516}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.78, \"learn_time_ms\": 11332.922}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.69, \"learn_time_ms\": 11330.759}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.91, \"learn_time_ms\": 11331.554}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.8, \"learn_time_ms\": 11347.954}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.06, \"learn_time_ms\": 11355.651}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1054.91, \"learn_time_ms\": 11357.516}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.33, \"learn_time_ms\": 11361.801}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.13, \"learn_time_ms\": 11359.06}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.13, \"learn_time_ms\": 11349.329}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.81, \"learn_time_ms\": 11338.561}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1058.74, \"learn_time_ms\": 11331.289}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1059.98, \"learn_time_ms\": 11329.414}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1055.91, \"learn_time_ms\": 11329.057}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1051.95, \"learn_time_ms\": 11322.545}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1053.44, \"learn_time_ms\": 11326.971}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.27, \"learn_time_ms\": 11332.972}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.61, \"learn_time_ms\": 11335.014}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1051.02, \"learn_time_ms\": 11339.522}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1056.34, \"learn_time_ms\": 11346.926}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1054.19, \"learn_time_ms\": 11346.315}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.69, \"learn_time_ms\": 11349.201}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.08, \"learn_time_ms\": 11355.419}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1051.85, \"learn_time_ms\": 11357.994}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1052.18, \"learn_time_ms\": 11349.803}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.85, \"learn_time_ms\": 11342.452}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.5, \"learn_time_ms\": 11331.799}", "{\"n\": 270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.97, \"learn_time_ms\": 11326.944}", "{\"n\": 271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.68, \"learn_time_ms\": 11321.969}", "{\"n\": 272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.91, \"learn_time_ms\": 11322.04}", "{\"n\": 273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.83, \"learn_time_ms\": 11335.136}", "{\"n\": 274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1053.44, \"learn_time_ms\": 11345.468}", "{\"n\": 275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1052.41, \"learn_time_ms\": 11348.045}", "{\"n\": 276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1054.52, \"learn_time_ms\": 11346.275}", "{\"n\": 277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1052.92, \"learn_time_ms\": 11350.47}", "{\"n\": 278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1053.27, \"learn_time_ms\": 11347.571}", "{\"n\": 279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.33, \"learn_time_ms\": 11352.028}", "{\"n\": 280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.33, \"learn_time_ms\": 11353.745}", "{\"n\": 281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1058.73, \"learn_time_ms\": 11353.696}", "{\"n\": 282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1058.96, \"learn_time_ms\": 11341.177}", "{\"n\": 283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1052.74, \"learn_time_ms\": 11327.586}", "{\"n\": 284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1053.88, \"learn_time_ms\": 11312.002}", "{\"n\": 285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.88, \"learn_time_ms\": 11301.598}", "{\"n\": 286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1056.77, \"learn_time_ms\": 11298.603}", "{\"n\": 287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1056.83, \"learn_time_ms\": 11295.619}", "{\"n\": 288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1056.2, \"learn_time_ms\": 11300.448}", "{\"n\": 289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.78, \"learn_time_ms\": 11300.72}", "{\"n\": 290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1052.5, \"learn_time_ms\": 11296.676}", "{\"n\": 291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.03, \"learn_time_ms\": 11303.476}", "{\"n\": 292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.09, \"learn_time_ms\": 11306.912}", "{\"n\": 293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1048.1, \"learn_time_ms\": 11305.135}", "{\"n\": 294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1048.49, \"learn_time_ms\": 11308.196}", "{\"n\": 295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.78, \"learn_time_ms\": 11311.809}", "{\"n\": 296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1045.82, \"learn_time_ms\": 11314.936}", "{\"n\": 297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1058.15, \"learn_time_ms\": 11311.72}", "{\"n\": 298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1061.65, \"learn_time_ms\": 11303.524}", "{\"n\": 299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1061.59, \"learn_time_ms\": 11296.537}", "{\"n\": 300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1061.44, \"learn_time_ms\": 11293.003}", "{\"n\": 301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1061.99, \"learn_time_ms\": 11288.477}", "{\"n\": 302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1062.26, \"learn_time_ms\": 11297.549}", "{\"n\": 303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1059.68, \"learn_time_ms\": 11328.314}", "{\"n\": 304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1058.98, \"learn_time_ms\": 11364.334}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1066.27, \"learn_time_ms\": 11323.355}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1066.12, \"learn_time_ms\": 11282.3}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.15, \"learn_time_ms\": 11244.451}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.41, \"learn_time_ms\": 11209.586}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.49, \"learn_time_ms\": 11174.332}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1059.9, \"learn_time_ms\": 11141.295}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.79, \"learn_time_ms\": 11103.543}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1066.66, \"learn_time_ms\": 11056.97}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1068.03, \"learn_time_ms\": 10985.705}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1073.53, \"learn_time_ms\": 10909.702}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1072.05, \"learn_time_ms\": 10911.86}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1071.76, \"learn_time_ms\": 10933.369}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1071.75, \"learn_time_ms\": 10998.923}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1064.79, \"learn_time_ms\": 11071.525}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.45, \"learn_time_ms\": 11062.017}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.19, \"learn_time_ms\": 11053.052}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.77, \"learn_time_ms\": 11042.672}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1058.22, \"learn_time_ms\": 11033.32}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1058.17, \"learn_time_ms\": 11035.469}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.13, \"learn_time_ms\": 11031.819}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.72, \"learn_time_ms\": 11028.46}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.38, \"learn_time_ms\": 11005.288}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1050.32, \"learn_time_ms\": 10934.376}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1055.12, \"learn_time_ms\": 10855.087}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1053.86, \"learn_time_ms\": 10854.877}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1053.12, \"learn_time_ms\": 10854.092}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.15, \"learn_time_ms\": 10856.888}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.29, \"learn_time_ms\": 10911.404}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1068.84, \"learn_time_ms\": 10976.415}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1069.26, \"learn_time_ms\": 10983.079}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1068.08, \"learn_time_ms\": 10979.066}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1065.75, \"learn_time_ms\": 10974.581}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1070.87, \"learn_time_ms\": 10976.153}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1070.91, \"learn_time_ms\": 10977.084}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1074.58, \"learn_time_ms\": 10983.492}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1077.46, \"learn_time_ms\": 10988.607}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1076.54, \"learn_time_ms\": 10989.603}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1075.03, \"learn_time_ms\": 10938.367}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1075.56, \"learn_time_ms\": 10869.315}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1075.31, \"learn_time_ms\": 10862.505}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1077.35, \"learn_time_ms\": 10865.196}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1077.97, \"learn_time_ms\": 10870.092}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1078.5, \"learn_time_ms\": 10926.591}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1081.13, \"learn_time_ms\": 10978.789}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1082.99, \"learn_time_ms\": 10970.016}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1076.94, \"learn_time_ms\": 10965.987}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1076.79, \"learn_time_ms\": 10968.804}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1083.27, \"learn_time_ms\": 10970.738}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1077.27, \"learn_time_ms\": 10971.322}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1071.73, \"learn_time_ms\": 10974.266}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1072.62, \"learn_time_ms\": 10974.642}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1077.81, \"learn_time_ms\": 10973.834}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1080.97, \"learn_time_ms\": 10915.431}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1085.56, \"learn_time_ms\": 10862.928}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1078.12, \"learn_time_ms\": 10869.024}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1078.13, \"learn_time_ms\": 10874.829}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1079.43, \"learn_time_ms\": 10891.51}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1081.53, \"learn_time_ms\": 10942.739}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1082.12, \"learn_time_ms\": 11006.062}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1084.71, \"learn_time_ms\": 11004.693}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1086.66, \"learn_time_ms\": 11005.801}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1098.61, \"learn_time_ms\": 11006.612}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1105.74, \"learn_time_ms\": 11010.634}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1113.95, \"learn_time_ms\": 11012.851}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1110.73, \"learn_time_ms\": 11018.4}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1111.58, \"learn_time_ms\": 11016.68}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1113.55, \"learn_time_ms\": 11011.683}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1111.38, \"learn_time_ms\": 10964.766}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1119.66, \"learn_time_ms\": 10910.6}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1123.7, \"learn_time_ms\": 10915.498}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1126.65, \"learn_time_ms\": 10921.692}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1128.45, \"learn_time_ms\": 10970.194}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1133.79, \"learn_time_ms\": 11021.749}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1133.55, \"learn_time_ms\": 11053.267}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1131.94, \"learn_time_ms\": 11054.053}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1130.52, \"learn_time_ms\": 11060.809}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1137.31, \"learn_time_ms\": 11053.912}", "{\"n\": 382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1139.38, \"learn_time_ms\": 11051.459}", "{\"n\": 383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1147.88, \"learn_time_ms\": 11049.887}", "{\"n\": 384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1157.79, \"learn_time_ms\": 11049.237}", "{\"n\": 385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1158.26, \"learn_time_ms\": 11048.592}", "{\"n\": 386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1159.19, \"learn_time_ms\": 11008.96}", "{\"n\": 387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1167.9, \"learn_time_ms\": 10962.831}", "{\"n\": 388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1165.22, \"learn_time_ms\": 10936.439}", "{\"n\": 389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1160.72, \"learn_time_ms\": 10934.903}", "{\"n\": 390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1169.78, \"learn_time_ms\": 10954.007}", "{\"n\": 391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1176.07, \"learn_time_ms\": 11019.538}", "{\"n\": 392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1170.47, \"learn_time_ms\": 11101.1}", "{\"n\": 393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1172.92, \"learn_time_ms\": 11105.167}", "{\"n\": 394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1185.21, \"learn_time_ms\": 11099.355}", "{\"n\": 395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1196.16, \"learn_time_ms\": 11096.078}", "{\"n\": 396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1190.92, \"learn_time_ms\": 11100.426}", "{\"n\": 397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1195.46, \"learn_time_ms\": 11100.567}", "{\"n\": 398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1198.02, \"learn_time_ms\": 11098.951}", "{\"n\": 399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.38, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1210.74, \"learn_time_ms\": 11098.988}", "{\"n\": 400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1207.88, \"learn_time_ms\": 11068.773}", "{\"n\": 401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.33, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1223.99, \"learn_time_ms\": 11002.226}", "{\"n\": 402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.31, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1226.39, \"learn_time_ms\": 10929.626}", "{\"n\": 403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.33, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1226.56, \"learn_time_ms\": 10925.065}", "{\"n\": 404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.33, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1225.91, \"learn_time_ms\": 10935.461}", "{\"n\": 405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.32, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1230.17, \"learn_time_ms\": 10992.177}", "{\"n\": 406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1224.33, \"learn_time_ms\": 11062.109}", "{\"n\": 407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.31, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1228.48, \"learn_time_ms\": 11058.022}", "{\"n\": 408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.29, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1234.05, \"learn_time_ms\": 11059.856}", "{\"n\": 409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.32, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1230.86, \"learn_time_ms\": 11052.511}", "{\"n\": 410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.26, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1244.05, \"learn_time_ms\": 11050.984}", "{\"n\": 411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1249.94, \"learn_time_ms\": 11046.804}", "{\"n\": 412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1256.9, \"learn_time_ms\": 11037.056}", "{\"n\": 413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.26, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1256.51, \"learn_time_ms\": 11030.422}", "{\"n\": 414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.26, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1262.23, \"learn_time_ms\": 11021.029}", "{\"n\": 415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.26, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1267.79, \"learn_time_ms\": 10963.526}", "{\"n\": 416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1264.71, \"learn_time_ms\": 10882.187}", "{\"n\": 417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1260.19, \"learn_time_ms\": 10882.691}", "{\"n\": 418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1264.18, \"learn_time_ms\": 10877.707}", "{\"n\": 419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.19, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1272.91, \"learn_time_ms\": 10927.504}", "{\"n\": 420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1274.24, \"learn_time_ms\": 11019.386}", "{\"n\": 421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1280.02, \"learn_time_ms\": 11104.973}", "{\"n\": 422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1286.19, \"learn_time_ms\": 11104.783}", "{\"n\": 423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1297.87, \"learn_time_ms\": 11102.274}", "{\"n\": 424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1296.46, \"learn_time_ms\": 11101.614}", "{\"n\": 425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1293.7, \"learn_time_ms\": 11098.017}", "{\"n\": 426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1290.57, \"learn_time_ms\": 11096.646}", "{\"n\": 427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1293.17, \"learn_time_ms\": 11098.503}", "{\"n\": 428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1306.29, \"learn_time_ms\": 11102.682}", "{\"n\": 429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1305.92, \"learn_time_ms\": 11060.548}", "{\"n\": 430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1317.0, \"learn_time_ms\": 10979.894}", "{\"n\": 431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.08, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1325.87, \"learn_time_ms\": 10906.412}", "{\"n\": 432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1322.36, \"learn_time_ms\": 10910.266}", "{\"n\": 433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.09, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1332.58, \"learn_time_ms\": 10928.83}", "{\"n\": 434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1337.47, \"learn_time_ms\": 11017.67}", "{\"n\": 435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.08, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1346.01, \"learn_time_ms\": 11103.017}", "{\"n\": 436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.08, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1353.02, \"learn_time_ms\": 11207.724}", "{\"n\": 437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1363.8, \"learn_time_ms\": 11300.154}", "{\"n\": 438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.06, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1365.62, \"learn_time_ms\": 11384.924}", "{\"n\": 439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1357.77, \"learn_time_ms\": 11472.992}", "{\"n\": 440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.08, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1366.45, \"learn_time_ms\": 11560.217}", "{\"n\": 441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.03, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1372.58, \"learn_time_ms\": 11646.097}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.97, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1383.83, \"learn_time_ms\": 11734.153}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1394.14, \"learn_time_ms\": 11812.014}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1403.9, \"learn_time_ms\": 11805.288}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.85, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1411.34, \"learn_time_ms\": 11811.28}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1411.77, \"learn_time_ms\": 11778.441}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1411.61, \"learn_time_ms\": 11754.172}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1410.9, \"learn_time_ms\": 11729.488}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.88, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1411.12, \"learn_time_ms\": 11698.211}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.83, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1421.12, \"learn_time_ms\": 11661.092}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.82, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1423.92, \"learn_time_ms\": 11619.399}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.75, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1432.12, \"learn_time_ms\": 11585.164}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.76, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1446.32, \"learn_time_ms\": 11563.209}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.75, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1459.38, \"learn_time_ms\": 11551.706}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.72, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1478.18, \"learn_time_ms\": 11520.997}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.7, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1483.71, \"learn_time_ms\": 11522.145}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1490.83, \"learn_time_ms\": 11527.912}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.65, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1506.93, \"learn_time_ms\": 11558.221}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.63, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1507.01, \"learn_time_ms\": 11568.914}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.66, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1505.09, \"learn_time_ms\": 11601.2}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.65, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1517.55, \"learn_time_ms\": 11602.137}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.65, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1516.65, \"learn_time_ms\": 11605.188}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.63, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1527.23, \"learn_time_ms\": 11599.658}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.54, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1544.47, \"learn_time_ms\": 11591.772}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.53, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1543.9, \"learn_time_ms\": 11605.091}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.53, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1557.76, \"learn_time_ms\": 11599.369}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1569.89, \"learn_time_ms\": 11574.359}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1570.6, \"learn_time_ms\": 11540.198}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1576.46, \"learn_time_ms\": 11532.923}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1575.21, \"learn_time_ms\": 11513.701}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.48, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1582.0, \"learn_time_ms\": 11525.603}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.44, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1586.8, \"learn_time_ms\": 11524.814}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.43, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1592.54, \"learn_time_ms\": 11519.267}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1601.72, \"learn_time_ms\": 11520.809}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1607.55, \"learn_time_ms\": 11506.915}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1604.97, \"learn_time_ms\": 11500.207}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.53, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1608.86, \"learn_time_ms\": 11509.216}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1617.83, \"learn_time_ms\": 11520.171}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1621.24, \"learn_time_ms\": 11516.001}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1632.27, \"learn_time_ms\": 11501.396}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.39, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1647.9, \"learn_time_ms\": 11487.541}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.41, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1648.15, \"learn_time_ms\": 11484.182}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1652.42, \"learn_time_ms\": 11495.592}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1665.22, \"learn_time_ms\": 11489.717}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.48, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1666.77, \"learn_time_ms\": 11502.408}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.46, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1678.22, \"learn_time_ms\": 11502.179}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.48, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1675.51, \"learn_time_ms\": 11496.258}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1679.31, \"learn_time_ms\": 11483.263}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1683.03, \"learn_time_ms\": 11487.099}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.46, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1680.96, \"learn_time_ms\": 11499.986}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.41, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1692.35, \"learn_time_ms\": 11508.908}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.43, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1688.8, \"learn_time_ms\": 11516.053}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.39, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1700.17, \"learn_time_ms\": 11504.008}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.34, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1705.57, \"learn_time_ms\": 11501.234}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.34, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1710.2, \"learn_time_ms\": 11491.696}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.35, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1718.78, \"learn_time_ms\": 11496.843}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.36, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1727.26, \"learn_time_ms\": 11493.51}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.34, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1735.16, \"learn_time_ms\": 11490.037}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.32, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1737.59, \"learn_time_ms\": 11483.914}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.35, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1738.57, \"learn_time_ms\": 11478.89}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.35, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1737.06, \"learn_time_ms\": 11494.603}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.35, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1743.35, \"learn_time_ms\": 11480.54}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.33, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1755.7, \"learn_time_ms\": 11491.053}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.33, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1758.67, \"learn_time_ms\": 11503.431}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1767.06, \"learn_time_ms\": 11501.236}", "{\"n\": 506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1772.92, \"learn_time_ms\": 11501.819}", "{\"n\": 507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1774.74, \"learn_time_ms\": 11506.2}", "{\"n\": 508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1773.69, \"learn_time_ms\": 11505.428}", "{\"n\": 509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1773.12, \"learn_time_ms\": 11502.854}", "{\"n\": 510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.33, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1783.75, \"learn_time_ms\": 11500.191}", "{\"n\": 511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.33, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1787.17, \"learn_time_ms\": 11486.326}", "{\"n\": 512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.32, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1790.0, \"learn_time_ms\": 11495.678}", "{\"n\": 513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1797.42, \"learn_time_ms\": 11489.698}", "{\"n\": 514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.26, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1796.98, \"learn_time_ms\": 11478.332}", "{\"n\": 515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1798.7, \"learn_time_ms\": 11479.663}", "{\"n\": 516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1795.09, \"learn_time_ms\": 11472.899}", "{\"n\": 517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.26, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1802.51, \"learn_time_ms\": 11470.77}", "{\"n\": 518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.26, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1799.17, \"learn_time_ms\": 11472.536}", "{\"n\": 519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1796.01, \"learn_time_ms\": 11472.258}", "{\"n\": 520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1815.5, \"learn_time_ms\": 11473.506}", "{\"n\": 521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.09, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1825.84, \"learn_time_ms\": 11459.406}", "{\"n\": 522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.08, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1828.94, \"learn_time_ms\": 11465.589}", "{\"n\": 523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.08, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1832.25, \"learn_time_ms\": 11463.646}", "{\"n\": 524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.06, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1835.38, \"learn_time_ms\": 11464.568}", "{\"n\": 525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1838.02, \"learn_time_ms\": 11465.424}", "{\"n\": 526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1847.84, \"learn_time_ms\": 11465.7}", "{\"n\": 527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.99, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1848.87, \"learn_time_ms\": 11467.075}", "{\"n\": 528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.91, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1857.15, \"learn_time_ms\": 11471.726}", "{\"n\": 529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.92, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1860.44, \"learn_time_ms\": 11471.593}", "{\"n\": 530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1861.14, \"learn_time_ms\": 11470.209}", "{\"n\": 531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1867.36, \"learn_time_ms\": 11477.707}", "{\"n\": 532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1874.88, \"learn_time_ms\": 11470.886}", "{\"n\": 533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1883.82, \"learn_time_ms\": 11464.764}", "{\"n\": 534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1885.53, \"learn_time_ms\": 11479.447}", "{\"n\": 535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.85, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1885.56, \"learn_time_ms\": 11478.384}", "{\"n\": 536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.85, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1885.56, \"learn_time_ms\": 11480.801}", "{\"n\": 537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1883.6, \"learn_time_ms\": 11490.086}", "{\"n\": 538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.82, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1887.11, \"learn_time_ms\": 11494.885}", "{\"n\": 539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.82, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1887.11, \"learn_time_ms\": 11500.355}", "{\"n\": 540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.8, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1894.43, \"learn_time_ms\": 11500.413}", "{\"n\": 541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.82, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1882.33, \"learn_time_ms\": 11507.109}", "{\"n\": 542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1882.56, \"learn_time_ms\": 11499.355}", "{\"n\": 543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1885.21, \"learn_time_ms\": 11505.84}", "{\"n\": 544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1889.65, \"learn_time_ms\": 11497.924}", "{\"n\": 545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1889.41, \"learn_time_ms\": 11500.399}", "{\"n\": 546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1898.22, \"learn_time_ms\": 11499.555}", "{\"n\": 547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1904.34, \"learn_time_ms\": 11491.056}", "{\"n\": 548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.63, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1919.93, \"learn_time_ms\": 11489.04}", "{\"n\": 549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1926.98, \"learn_time_ms\": 11491.567}", "{\"n\": 550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1926.99, \"learn_time_ms\": 11491.543}", "{\"n\": 551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1925.79, \"learn_time_ms\": 11485.763}", "{\"n\": 552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1925.79, \"learn_time_ms\": 11484.428}", "{\"n\": 553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.58, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1923.31, \"learn_time_ms\": 11484.057}", "{\"n\": 554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1929.7, \"learn_time_ms\": 11478.77}", "{\"n\": 555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1931.74, \"learn_time_ms\": 11477.203}", "{\"n\": 556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1933.94, \"learn_time_ms\": 11480.769}", "{\"n\": 557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.54, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1953.1, \"learn_time_ms\": 11484.019}", "{\"n\": 558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1960.5, \"learn_time_ms\": 11483.411}", "{\"n\": 559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1958.95, \"learn_time_ms\": 11474.521}", "{\"n\": 560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1971.03, \"learn_time_ms\": 11490.167}", "{\"n\": 561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1977.92, \"learn_time_ms\": 11499.093}", "{\"n\": 562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1983.26, \"learn_time_ms\": 11505.395}", "{\"n\": 563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.49, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1981.8, \"learn_time_ms\": 11505.614}", "{\"n\": 564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1991.44, \"learn_time_ms\": 11497.829}", "{\"n\": 565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1989.94, \"learn_time_ms\": 11510.254}", "{\"n\": 566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1991.61, \"learn_time_ms\": 11509.671}", "{\"n\": 567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1992.47, \"learn_time_ms\": 11514.826}", "{\"n\": 568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1988.62, \"learn_time_ms\": 11511.381}", "{\"n\": 569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1984.92, \"learn_time_ms\": 11516.938}", "{\"n\": 570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1985.39, \"learn_time_ms\": 11502.658}", "{\"n\": 571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1995.97, \"learn_time_ms\": 11501.075}", "{\"n\": 572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2002.85, \"learn_time_ms\": 11503.12}", "{\"n\": 573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.45, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1994.52, \"learn_time_ms\": 11505.316}", "{\"n\": 574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1991.8, \"learn_time_ms\": 11522.19}", "{\"n\": 575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1994.12, \"learn_time_ms\": 11505.427}", "{\"n\": 576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.42, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2003.92, \"learn_time_ms\": 11495.818}", "{\"n\": 577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2001.64, \"learn_time_ms\": 11487.689}", "{\"n\": 578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.38, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2004.74, \"learn_time_ms\": 11485.91}", "{\"n\": 579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2008.29, \"learn_time_ms\": 11490.947}", "{\"n\": 580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2011.1, \"learn_time_ms\": 11485.104}", "{\"n\": 581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2013.94, \"learn_time_ms\": 11479.086}", "{\"n\": 582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.36, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2020.68, \"learn_time_ms\": 11484.579}", "{\"n\": 583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2027.18, \"learn_time_ms\": 11484.716}", "{\"n\": 584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.28, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2047.11, \"learn_time_ms\": 11483.011}", "{\"n\": 585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.25, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2057.67, \"learn_time_ms\": 11486.655}", "{\"n\": 586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.25, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2057.67, \"learn_time_ms\": 11494.165}", "{\"n\": 587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.28, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2060.81, \"learn_time_ms\": 11499.742}", "{\"n\": 588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.29, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2058.84, \"learn_time_ms\": 11504.478}", "{\"n\": 589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.29, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2058.84, \"learn_time_ms\": 11502.106}", "{\"n\": 590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.29, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2058.84, \"learn_time_ms\": 11509.994}", "{\"n\": 591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2074.45, \"learn_time_ms\": 11512.922}", "{\"n\": 592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2074.45, \"learn_time_ms\": 11521.256}", "{\"n\": 593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2074.45, \"learn_time_ms\": 11519.759}", "{\"n\": 594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2073.55, \"learn_time_ms\": 11507.403}", "{\"n\": 595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.25, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2075.75, \"learn_time_ms\": 11511.848}", "{\"n\": 596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.25, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2075.75, \"learn_time_ms\": 11510.43}", "{\"n\": 597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2076.53, \"learn_time_ms\": 11511.884}", "{\"n\": 598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2090.59, \"learn_time_ms\": 11506.526}", "{\"n\": 599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2099.3, \"learn_time_ms\": 11508.055}", "{\"n\": 600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.06, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2085.48, \"learn_time_ms\": 11503.43}", "{\"n\": 601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2076.56, \"learn_time_ms\": 11501.301}", "{\"n\": 602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2086.04, \"learn_time_ms\": 11484.158}", "{\"n\": 603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2078.71, \"learn_time_ms\": 11474.173}", "{\"n\": 604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2070.31, \"learn_time_ms\": 11485.232}", "{\"n\": 605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2068.61, \"learn_time_ms\": 11483.796}", "{\"n\": 606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2069.87, \"learn_time_ms\": 11487.209}", "{\"n\": 607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2070.8, \"learn_time_ms\": 11476.82}", "{\"n\": 608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2071.76, \"learn_time_ms\": 11473.918}", "{\"n\": 609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2073.89, \"learn_time_ms\": 11473.785}", "{\"n\": 610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2073.89, \"learn_time_ms\": 11477.255}", "{\"n\": 611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2072.35, \"learn_time_ms\": 11468.683}", "{\"n\": 612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2071.05, \"learn_time_ms\": 11470.467}", "{\"n\": 613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.1, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2059.66, \"learn_time_ms\": 11484.02}", "{\"n\": 614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.09, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2065.8, \"learn_time_ms\": 11480.8}", "{\"n\": 615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.09, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2066.0, \"learn_time_ms\": 11481.274}", "{\"n\": 616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2074.75, \"learn_time_ms\": 11494.676}", "{\"n\": 617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2071.57, \"learn_time_ms\": 11498.364}", "{\"n\": 618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2069.9, \"learn_time_ms\": 11500.209}", "{\"n\": 619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2066.52, \"learn_time_ms\": 11510.607}", "{\"n\": 620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2068.45, \"learn_time_ms\": 11502.771}", "{\"n\": 621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2078.16, \"learn_time_ms\": 11506.375}", "{\"n\": 622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2079.08, \"learn_time_ms\": 11512.789}", "{\"n\": 623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2081.91, \"learn_time_ms\": 11502.816}", "{\"n\": 624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2081.91, \"learn_time_ms\": 11498.339}", "{\"n\": 625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2086.63, \"learn_time_ms\": 11501.63}", "{\"n\": 626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2079.06, \"learn_time_ms\": 11479.563}", "{\"n\": 627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2078.53, \"learn_time_ms\": 11481.76}", "{\"n\": 628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2078.53, \"learn_time_ms\": 11486.73}", "{\"n\": 629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2075.69, \"learn_time_ms\": 11468.855}", "{\"n\": 630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2073.22, \"learn_time_ms\": 11476.605}", "{\"n\": 631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2081.12, \"learn_time_ms\": 11474.887}", "{\"n\": 632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2079.59, \"learn_time_ms\": 11472.388}", "{\"n\": 633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2077.07, \"learn_time_ms\": 11481.384}", "{\"n\": 634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2077.38, \"learn_time_ms\": 11489.417}", "{\"n\": 635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2079.86, \"learn_time_ms\": 11486.756}", "{\"n\": 636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2079.44, \"learn_time_ms\": 11495.431}", "{\"n\": 637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2080.71, \"learn_time_ms\": 11497.176}", "{\"n\": 638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2080.71, \"learn_time_ms\": 11503.489}", "{\"n\": 639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2079.0, \"learn_time_ms\": 11509.017}", "{\"n\": 640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2082.51, \"learn_time_ms\": 11500.242}", "{\"n\": 641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2071.21, \"learn_time_ms\": 11497.245}", "{\"n\": 642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2071.21, \"learn_time_ms\": 11505.437}", "{\"n\": 643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2069.23, \"learn_time_ms\": 11499.624}", "{\"n\": 644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2082.17, \"learn_time_ms\": 11491.656}", "{\"n\": 645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2085.52, \"learn_time_ms\": 11495.409}", "{\"n\": 646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2081.94, \"learn_time_ms\": 11492.722}", "{\"n\": 647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2092.26, \"learn_time_ms\": 11492.579}", "{\"n\": 648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.32, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2089.68, \"learn_time_ms\": 11489.065}", "{\"n\": 649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.28, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2095.84, \"learn_time_ms\": 11494.777}", "{\"n\": 650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.35, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2093.37, \"learn_time_ms\": 11496.279}", "{\"n\": 651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.42, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2083.57, \"learn_time_ms\": 11512.87}", "{\"n\": 652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2097.79, \"learn_time_ms\": 11506.77}", "{\"n\": 653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.36, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2100.68, \"learn_time_ms\": 11515.382}", "{\"n\": 654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2112.35, \"learn_time_ms\": 11518.806}", "{\"n\": 655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2121.31, \"learn_time_ms\": 11510.749}", "{\"n\": 656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.28, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2120.56, \"learn_time_ms\": 11508.212}", "{\"n\": 657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2135.1, \"learn_time_ms\": 11511.172}", "{\"n\": 658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.29, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2136.93, \"learn_time_ms\": 11508.725}", "{\"n\": 659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2132.18, \"learn_time_ms\": 11497.051}", "{\"n\": 660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2134.17, \"learn_time_ms\": 11521.26}", "{\"n\": 661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2132.72, \"learn_time_ms\": 11508.762}", "{\"n\": 662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.28, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2147.03, \"learn_time_ms\": 11505.985}", "{\"n\": 663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.25, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2147.77, \"learn_time_ms\": 11497.313}", "{\"n\": 664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2146.1, \"learn_time_ms\": 11497.237}", "{\"n\": 665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2139.63, \"learn_time_ms\": 11497.636}", "{\"n\": 666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.25, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2146.55, \"learn_time_ms\": 11500.857}", "{\"n\": 667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2148.24, \"learn_time_ms\": 11495.106}", "{\"n\": 668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2148.24, \"learn_time_ms\": 11503.355}", "{\"n\": 669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2144.38, \"learn_time_ms\": 11515.321}", "{\"n\": 670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2144.38, \"learn_time_ms\": 11503.306}", "{\"n\": 671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2147.57, \"learn_time_ms\": 11506.326}", "{\"n\": 672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2147.57, \"learn_time_ms\": 11510.217}", "{\"n\": 673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.06, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2151.47, \"learn_time_ms\": 11520.8}", "{\"n\": 674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.06, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2146.33, \"learn_time_ms\": 11536.883}", "{\"n\": 675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2156.45, \"learn_time_ms\": 11539.81}", "{\"n\": 676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2152.3, \"learn_time_ms\": 11535.218}", "{\"n\": 677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2150.63, \"learn_time_ms\": 11538.108}", "{\"n\": 678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2152.61, \"learn_time_ms\": 11526.743}", "{\"n\": 679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2152.61, \"learn_time_ms\": 11519.343}", "{\"n\": 680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2147.32, \"learn_time_ms\": 11516.166}", "{\"n\": 681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2149.9, \"learn_time_ms\": 11522.209}", "{\"n\": 682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2150.29, \"learn_time_ms\": 11524.035}", "{\"n\": 683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2158.33, \"learn_time_ms\": 11517.62}", "{\"n\": 684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2154.23, \"learn_time_ms\": 11496.354}", "{\"n\": 685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2155.38, \"learn_time_ms\": 11496.758}", "{\"n\": 686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2149.69, \"learn_time_ms\": 11499.98}", "{\"n\": 687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2151.72, \"learn_time_ms\": 11498.032}", "{\"n\": 688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2154.14, \"learn_time_ms\": 11507.659}", "{\"n\": 689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2156.82, \"learn_time_ms\": 11507.764}", "{\"n\": 690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2140.17, \"learn_time_ms\": 11505.613}", "{\"n\": 691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.93, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2139.21, \"learn_time_ms\": 11501.117}", "{\"n\": 692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2139.53, \"learn_time_ms\": 11498.017}", "{\"n\": 693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2143.81, \"learn_time_ms\": 11505.205}", "{\"n\": 694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.81, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2145.97, \"learn_time_ms\": 11508.642}", "{\"n\": 695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2149.15, \"learn_time_ms\": 11509.264}", "{\"n\": 696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2153.97, \"learn_time_ms\": 11502.995}", "{\"n\": 697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2151.37, \"learn_time_ms\": 11504.502}", "{\"n\": 698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2142.42, \"learn_time_ms\": 11498.098}", "{\"n\": 699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2136.42, \"learn_time_ms\": 11504.354}", "{\"n\": 700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2140.53, \"learn_time_ms\": 11505.144}", "{\"n\": 701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.81, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2136.97, \"learn_time_ms\": 11504.933}", "{\"n\": 702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2138.07, \"learn_time_ms\": 11507.414}", "{\"n\": 703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2133.94, \"learn_time_ms\": 11519.433}", "{\"n\": 704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2134.1, \"learn_time_ms\": 11528.24}", "{\"n\": 705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2125.71, \"learn_time_ms\": 11523.403}", "{\"n\": 706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2124.3, \"learn_time_ms\": 11541.927}", "{\"n\": 707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2126.31, \"learn_time_ms\": 11540.108}", "{\"n\": 708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2125.9, \"learn_time_ms\": 11544.602}", "{\"n\": 709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2126.26, \"learn_time_ms\": 11544.629}", "{\"n\": 710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.68, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2120.89, \"learn_time_ms\": 11535.198}", "{\"n\": 711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.68, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2127.79, \"learn_time_ms\": 11540.115}", "{\"n\": 712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2130.56, \"learn_time_ms\": 11534.168}", "{\"n\": 713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.64, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2135.0, \"learn_time_ms\": 11508.823}", "{\"n\": 714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2131.54, \"learn_time_ms\": 11503.873}", "{\"n\": 715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2129.36, \"learn_time_ms\": 11504.547}", "{\"n\": 716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2133.98, \"learn_time_ms\": 11498.251}", "{\"n\": 717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2134.08, \"learn_time_ms\": 11504.883}", "{\"n\": 718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2135.39, \"learn_time_ms\": 11510.817}", "{\"n\": 719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2130.42, \"learn_time_ms\": 11508.508}", "{\"n\": 720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2130.97, \"learn_time_ms\": 11514.232}", "{\"n\": 721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2132.65, \"learn_time_ms\": 11507.969}", "{\"n\": 722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2135.04, \"learn_time_ms\": 11505.074}", "{\"n\": 723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.64, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2131.29, \"learn_time_ms\": 11513.36}", "{\"n\": 724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2138.54, \"learn_time_ms\": 11506.125}", "{\"n\": 725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2137.59, \"learn_time_ms\": 11511.443}", "{\"n\": 726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.52, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2142.84, \"learn_time_ms\": 11500.196}", "{\"n\": 727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2151.04, \"learn_time_ms\": 11496.691}", "{\"n\": 728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.56, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2141.07, \"learn_time_ms\": 11488.896}", "{\"n\": 729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.52, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2142.18, \"learn_time_ms\": 11486.602}", "{\"n\": 730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2142.65, \"learn_time_ms\": 11492.403}", "{\"n\": 731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.45, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2142.91, \"learn_time_ms\": 11501.343}", "{\"n\": 732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.41, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2154.53, \"learn_time_ms\": 11500.65}", "{\"n\": 733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.44, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2150.35, \"learn_time_ms\": 11495.637}", "{\"n\": 734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.46, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2152.57, \"learn_time_ms\": 11502.371}", "{\"n\": 735, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.39, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2157.87, \"learn_time_ms\": 11501.725}", "{\"n\": 736, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.36, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2163.92, \"learn_time_ms\": 11509.683}", "{\"n\": 737, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.36, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2163.92, \"learn_time_ms\": 11509.97}", "{\"n\": 738, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.33, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2161.65, \"learn_time_ms\": 11508.183}", "{\"n\": 739, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.38, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2156.26, \"learn_time_ms\": 11502.82}", "{\"n\": 740, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.36, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2158.46, \"learn_time_ms\": 11500.273}", "{\"n\": 741, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.39, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2149.97, \"learn_time_ms\": 11491.063}", "{\"n\": 742, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.41, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2153.53, \"learn_time_ms\": 11491.998}", "{\"n\": 743, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2151.97, \"learn_time_ms\": 11490.832}", "{\"n\": 744, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2151.93, \"learn_time_ms\": 11488.642}", "{\"n\": 745, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2150.3, \"learn_time_ms\": 11491.571}", "{\"n\": 746, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.39, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2148.29, \"learn_time_ms\": 11495.287}", "{\"n\": 747, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.41, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2153.63, \"learn_time_ms\": 11487.107}", "{\"n\": 748, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.41, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2153.26, \"learn_time_ms\": 11491.023}", "{\"n\": 749, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2152.92, \"learn_time_ms\": 11495.134}", "{\"n\": 750, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.35, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2159.34, \"learn_time_ms\": 11500.128}", "{\"n\": 751, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.36, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2158.39, \"learn_time_ms\": 11501.571}", "{\"n\": 752, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2159.95, \"learn_time_ms\": 11511.764}", "{\"n\": 753, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2168.18, \"learn_time_ms\": 11510.624}", "{\"n\": 754, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2170.52, \"learn_time_ms\": 11509.369}", "{\"n\": 755, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2172.29, \"learn_time_ms\": 11502.598}", "{\"n\": 756, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2168.02, \"learn_time_ms\": 11496.413}", "{\"n\": 757, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2168.62, \"learn_time_ms\": 11508.413}", "{\"n\": 758, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2171.41, \"learn_time_ms\": 11503.326}", "{\"n\": 759, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2172.09, \"learn_time_ms\": 11500.805}", "{\"n\": 760, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2178.1, \"learn_time_ms\": 11501.716}", "{\"n\": 761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2180.72, \"learn_time_ms\": 11494.107}", "{\"n\": 762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2173.13, \"learn_time_ms\": 11489.524}", "{\"n\": 763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2170.16, \"learn_time_ms\": 11492.961}", "{\"n\": 764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2174.32, \"learn_time_ms\": 11498.076}", "{\"n\": 765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2195.71, \"learn_time_ms\": 11495.125}", "{\"n\": 766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2193.33, \"learn_time_ms\": 11488.108}", "{\"n\": 767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2188.25, \"learn_time_ms\": 11476.994}", "{\"n\": 768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2191.84, \"learn_time_ms\": 11486.05}", "{\"n\": 769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.12, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2196.55, \"learn_time_ms\": 11490.852}", "{\"n\": 770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2191.8, \"learn_time_ms\": 11491.382}", "{\"n\": 771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2192.18, \"learn_time_ms\": 11493.826}", "{\"n\": 772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2185.72, \"learn_time_ms\": 11497.242}", "{\"n\": 773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2203.09, \"learn_time_ms\": 11499.862}", "{\"n\": 774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2194.68, \"learn_time_ms\": 11489.315}", "{\"n\": 775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2196.48, \"learn_time_ms\": 11496.185}", "{\"n\": 776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2198.8, \"learn_time_ms\": 11504.239}", "{\"n\": 777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2200.58, \"learn_time_ms\": 11516.558}", "{\"n\": 778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2211.97, \"learn_time_ms\": 11504.099}", "{\"n\": 779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2211.97, \"learn_time_ms\": 11504.867}", "{\"n\": 780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.07, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2214.1, \"learn_time_ms\": 11501.29}", "{\"n\": 781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.04, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2222.27, \"learn_time_ms\": 11508.254}", "{\"n\": 782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.04, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2226.07, \"learn_time_ms\": 11507.872}", "{\"n\": 783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2221.87, \"learn_time_ms\": 11503.727}", "{\"n\": 784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2221.87, \"learn_time_ms\": 11510.251}", "{\"n\": 785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2220.6, \"learn_time_ms\": 11506.23}", "{\"n\": 786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2228.33, \"learn_time_ms\": 11514.82}", "{\"n\": 787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2229.22, \"learn_time_ms\": 11510.211}", "{\"n\": 788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2229.68, \"learn_time_ms\": 11515.881}", "{\"n\": 789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2227.63, \"learn_time_ms\": 11520.227}", "{\"n\": 790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2229.67, \"learn_time_ms\": 11523.539}", "{\"n\": 791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2243.51, \"learn_time_ms\": 11521.451}", "{\"n\": 792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2243.71, \"learn_time_ms\": 11516.351}", "{\"n\": 793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2245.87, \"learn_time_ms\": 11517.347}", "{\"n\": 794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2250.97, \"learn_time_ms\": 11525.636}", "{\"n\": 795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2249.61, \"learn_time_ms\": 11522.654}", "{\"n\": 796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2253.59, \"learn_time_ms\": 11504.331}", "{\"n\": 797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2251.24, \"learn_time_ms\": 11499.811}", "{\"n\": 798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2247.46, \"learn_time_ms\": 11498.951}", "{\"n\": 799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2240.04, \"learn_time_ms\": 11493.122}", "{\"n\": 800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.38, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2230.89, \"learn_time_ms\": 11481.331}", "{\"n\": 801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.38, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2230.89, \"learn_time_ms\": 11476.638}", "{\"n\": 802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.41, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2225.99, \"learn_time_ms\": 11471.929}", "{\"n\": 803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2222.36, \"learn_time_ms\": 11467.887}", "{\"n\": 804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2219.48, \"learn_time_ms\": 11463.124}", "{\"n\": 805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.44, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2213.52, \"learn_time_ms\": 11466.946}", "{\"n\": 806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.39, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2214.96, \"learn_time_ms\": 11468.887}", "{\"n\": 807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2212.98, \"learn_time_ms\": 11467.115}", "{\"n\": 808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2218.36, \"learn_time_ms\": 11463.267}", "{\"n\": 809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.39, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2220.11, \"learn_time_ms\": 11464.334}", "{\"n\": 810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2220.58, \"learn_time_ms\": 11473.131}", "{\"n\": 811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2220.58, \"learn_time_ms\": 11477.516}", "{\"n\": 812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.38, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2214.84, \"learn_time_ms\": 11480.23}", "{\"n\": 813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.36, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2219.4, \"learn_time_ms\": 11478.418}", "{\"n\": 814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.33, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2222.33, \"learn_time_ms\": 11483.11}", "{\"n\": 815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2222.3, \"learn_time_ms\": 11477.793}", "{\"n\": 816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2226.03, \"learn_time_ms\": 11491.235}", "{\"n\": 817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2229.43, \"learn_time_ms\": 11492.777}", "{\"n\": 818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2227.85, \"learn_time_ms\": 11502.006}", "{\"n\": 819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2240.58, \"learn_time_ms\": 11493.013}", "{\"n\": 820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2235.73, \"learn_time_ms\": 11485.097}", "{\"n\": 821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.12, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2249.58, \"learn_time_ms\": 11487.529}", "{\"n\": 822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.02, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2264.54, \"learn_time_ms\": 11487.116}", "{\"n\": 823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2265.86, \"learn_time_ms\": 11493.674}", "{\"n\": 824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2266.95, \"learn_time_ms\": 11490.438}", "{\"n\": 825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.06, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2262.99, \"learn_time_ms\": 11495.389}", "{\"n\": 826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2253.95, \"learn_time_ms\": 11485.842}", "{\"n\": 827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2248.37, \"learn_time_ms\": 11497.089}", "{\"n\": 828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2241.33, \"learn_time_ms\": 11497.141}", "{\"n\": 829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2241.33, \"learn_time_ms\": 11502.718}", "{\"n\": 830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2252.1, \"learn_time_ms\": 11510.913}", "{\"n\": 831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2263.15, \"learn_time_ms\": 11506.093}", "{\"n\": 832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.04, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2257.83, \"learn_time_ms\": 11512.007}", "{\"n\": 833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.04, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2257.31, \"learn_time_ms\": 11513.849}", "{\"n\": 834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2263.31, \"learn_time_ms\": 11501.279}", "{\"n\": 835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2260.38, \"learn_time_ms\": 11501.906}", "{\"n\": 836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2268.59, \"learn_time_ms\": 11494.624}", "{\"n\": 837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2268.59, \"learn_time_ms\": 11491.576}", "{\"n\": 838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2258.4, \"learn_time_ms\": 11479.019}", "{\"n\": 839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2258.4, \"learn_time_ms\": 11479.707}", "{\"n\": 840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2267.36, \"learn_time_ms\": 11485.946}", "{\"n\": 841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2268.01, \"learn_time_ms\": 11489.281}", "{\"n\": 842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2272.56, \"learn_time_ms\": 11489.053}", "{\"n\": 843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2271.21, \"learn_time_ms\": 11493.523}", "{\"n\": 844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2275.91, \"learn_time_ms\": 11497.27}", "{\"n\": 845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2277.51, \"learn_time_ms\": 11500.298}", "{\"n\": 846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2287.59, \"learn_time_ms\": 11512.0}", "{\"n\": 847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2291.74, \"learn_time_ms\": 11507.382}", "{\"n\": 848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2300.26, \"learn_time_ms\": 11520.283}", "{\"n\": 849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2300.26, \"learn_time_ms\": 11518.31}", "{\"n\": 850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.68, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2307.0, \"learn_time_ms\": 11506.423}", "{\"n\": 851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2305.54, \"learn_time_ms\": 11510.845}", "{\"n\": 852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2309.41, \"learn_time_ms\": 11510.34}", "{\"n\": 853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2320.12, \"learn_time_ms\": 11499.561}", "{\"n\": 854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2327.25, \"learn_time_ms\": 11517.829}", "{\"n\": 855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.61, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2325.74, \"learn_time_ms\": 11514.406}", "{\"n\": 856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2326.31, \"learn_time_ms\": 11511.218}", "{\"n\": 857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2318.57, \"learn_time_ms\": 11511.189}", "{\"n\": 858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2316.03, \"learn_time_ms\": 11507.538}", "{\"n\": 859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2317.56, \"learn_time_ms\": 11509.523}", "{\"n\": 860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.61, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2314.44, \"learn_time_ms\": 11511.875}", "{\"n\": 861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2310.15, \"learn_time_ms\": 11503.8}", "{\"n\": 862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2305.6, \"learn_time_ms\": 11503.057}", "{\"n\": 863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2309.76, \"learn_time_ms\": 11499.835}", "{\"n\": 864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2307.06, \"learn_time_ms\": 11480.855}", "{\"n\": 865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2305.71, \"learn_time_ms\": 11475.954}", "{\"n\": 866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2304.7, \"learn_time_ms\": 11483.589}", "{\"n\": 867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2304.7, \"learn_time_ms\": 11482.267}", "{\"n\": 868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2319.49, \"learn_time_ms\": 11481.028}", "{\"n\": 869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2311.73, \"learn_time_ms\": 11473.932}", "{\"n\": 870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2304.31, \"learn_time_ms\": 11480.362}", "{\"n\": 871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2302.77, \"learn_time_ms\": 11484.442}", "{\"n\": 872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2297.86, \"learn_time_ms\": 11486.377}", "{\"n\": 873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2315.43, \"learn_time_ms\": 11487.235}", "{\"n\": 874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2324.17, \"learn_time_ms\": 11499.723}", "{\"n\": 875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2328.9, \"learn_time_ms\": 11499.63}", "{\"n\": 876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2325.42, \"learn_time_ms\": 11492.846}", "{\"n\": 877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2331.38, \"learn_time_ms\": 11506.013}", "{\"n\": 878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2326.24, \"learn_time_ms\": 11512.954}", "{\"n\": 879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2321.5, \"learn_time_ms\": 11525.126}", "{\"n\": 880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2321.5, \"learn_time_ms\": 11524.471}", "{\"n\": 881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2322.87, \"learn_time_ms\": 11523.812}", "{\"n\": 882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2326.31, \"learn_time_ms\": 11515.531}", "{\"n\": 883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2333.74, \"learn_time_ms\": 11526.762}", "{\"n\": 884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2334.29, \"learn_time_ms\": 11516.763}", "{\"n\": 885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2336.98, \"learn_time_ms\": 11516.331}", "{\"n\": 886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2336.68, \"learn_time_ms\": 11519.687}", "{\"n\": 887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2342.76, \"learn_time_ms\": 11507.589}", "{\"n\": 888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2335.16, \"learn_time_ms\": 11498.385}", "{\"n\": 889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2329.75, \"learn_time_ms\": 11498.095}", "{\"n\": 890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2325.44, \"learn_time_ms\": 11497.132}", "{\"n\": 891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2323.92, \"learn_time_ms\": 11498.859}", "{\"n\": 892, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2333.15, \"learn_time_ms\": 11510.724}", "{\"n\": 893, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2330.7, \"learn_time_ms\": 11510.64}", "{\"n\": 894, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2332.22, \"learn_time_ms\": 11517.045}", "{\"n\": 895, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2335.56, \"learn_time_ms\": 11528.15}", "{\"n\": 896, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.02, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2324.79, \"learn_time_ms\": 11528.143}", "{\"n\": 897, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2327.23, \"learn_time_ms\": 11527.83}", "{\"n\": 898, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.06, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2326.82, \"learn_time_ms\": 11537.927}", "{\"n\": 899, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.06, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2326.82, \"learn_time_ms\": 11544.07}", "{\"n\": 900, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2334.72, \"learn_time_ms\": 11539.47}", "{\"n\": 901, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2333.46, \"learn_time_ms\": 11543.492}", "{\"n\": 902, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2337.34, \"learn_time_ms\": 11532.852}", "{\"n\": 903, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2341.12, \"learn_time_ms\": 11535.713}", "{\"n\": 904, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2338.6, \"learn_time_ms\": 11532.89}", "{\"n\": 905, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2347.15, \"learn_time_ms\": 11528.299}", "{\"n\": 906, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2350.72, \"learn_time_ms\": 11537.913}", "{\"n\": 907, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.02, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2349.86, \"learn_time_ms\": 11533.297}", "{\"n\": 908, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2354.18, \"learn_time_ms\": 11521.269}", "{\"n\": 909, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2360.17, \"learn_time_ms\": 11508.792}", "{\"n\": 910, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2356.74, \"learn_time_ms\": 11503.311}", "{\"n\": 911, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2363.69, \"learn_time_ms\": 11496.403}", "{\"n\": 912, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2361.8, \"learn_time_ms\": 11491.25}", "{\"n\": 913, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2355.04, \"learn_time_ms\": 11480.733}", "{\"n\": 914, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2355.04, \"learn_time_ms\": 11474.188}", "{\"n\": 915, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2356.55, \"learn_time_ms\": 11470.934}", "{\"n\": 916, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2348.95, \"learn_time_ms\": 11460.141}", "{\"n\": 917, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2359.22, \"learn_time_ms\": 11470.858}", "{\"n\": 918, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2359.22, \"learn_time_ms\": 11467.744}", "{\"n\": 919, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2360.26, \"learn_time_ms\": 11470.194}", "{\"n\": 920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2340.22, \"learn_time_ms\": 11473.198}", "{\"n\": 921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2336.16, \"learn_time_ms\": 11473.895}", "{\"n\": 922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2336.16, \"learn_time_ms\": 11488.828}", "{\"n\": 923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2321.84, \"learn_time_ms\": 11488.024}", "{\"n\": 924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2328.15, \"learn_time_ms\": 11498.984}", "{\"n\": 925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2330.4, \"learn_time_ms\": 11496.447}", "{\"n\": 926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2327.48, \"learn_time_ms\": 11494.699}", "{\"n\": 927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2326.07, \"learn_time_ms\": 11487.587}", "{\"n\": 928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.68, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2322.22, \"learn_time_ms\": 11490.267}", "{\"n\": 929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2330.05, \"learn_time_ms\": 11483.31}", "{\"n\": 930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2335.25, \"learn_time_ms\": 11481.39}", "{\"n\": 931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2337.32, \"learn_time_ms\": 11482.244}", "{\"n\": 932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2336.74, \"learn_time_ms\": 11485.186}", "{\"n\": 933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.13, \"learn_time_ms\": 11483.834}", "{\"n\": 934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.13, \"learn_time_ms\": 11479.595}", "{\"n\": 935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.01, \"learn_time_ms\": 11482.585}", "{\"n\": 936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2341.73, \"learn_time_ms\": 11486.956}", "{\"n\": 937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.46, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.52, \"learn_time_ms\": 11488.356}", "{\"n\": 938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.4, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2351.19, \"learn_time_ms\": 11494.483}", "{\"n\": 939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2350.48, \"learn_time_ms\": 11498.754}", "{\"n\": 940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2355.5, \"learn_time_ms\": 11505.829}", "{\"n\": 941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2351.5, \"learn_time_ms\": 11508.927}", "{\"n\": 942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2355.24, \"learn_time_ms\": 11503.377}", "{\"n\": 943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2353.59, \"learn_time_ms\": 11513.811}", "{\"n\": 944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2348.92, \"learn_time_ms\": 11514.062}", "{\"n\": 945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2350.89, \"learn_time_ms\": 11514.134}", "{\"n\": 946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.15, \"learn_time_ms\": 11504.788}", "{\"n\": 947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.15, \"learn_time_ms\": 11517.336}", "{\"n\": 948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2339.44, \"learn_time_ms\": 11510.905}", "{\"n\": 949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2350.65, \"learn_time_ms\": 11515.479}", "{\"n\": 950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2346.96, \"learn_time_ms\": 11520.477}", "{\"n\": 951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2346.96, \"learn_time_ms\": 11518.522}", "{\"n\": 952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2345.7, \"learn_time_ms\": 11512.365}", "{\"n\": 953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2346.4, \"learn_time_ms\": 11514.367}", "{\"n\": 954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2345.1, \"learn_time_ms\": 11514.968}", "{\"n\": 955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2346.94, \"learn_time_ms\": 11522.503}", "{\"n\": 956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2339.85, \"learn_time_ms\": 11529.69}", "{\"n\": 957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2339.85, \"learn_time_ms\": 11519.239}", "{\"n\": 958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2343.62, \"learn_time_ms\": 11524.098}", "{\"n\": 959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2335.88, \"learn_time_ms\": 11527.559}", "{\"n\": 960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2334.26, \"learn_time_ms\": 11527.196}", "{\"n\": 961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2335.34, \"learn_time_ms\": 11524.416}", "{\"n\": 962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2340.88, \"learn_time_ms\": 11527.829}", "{\"n\": 963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2335.92, \"learn_time_ms\": 11526.095}", "{\"n\": 964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2342.61, \"learn_time_ms\": 11529.379}", "{\"n\": 965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2328.15, \"learn_time_ms\": 11525.292}", "{\"n\": 966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2329.77, \"learn_time_ms\": 11521.648}", "{\"n\": 967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2329.83, \"learn_time_ms\": 11525.641}", "{\"n\": 968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2322.6, \"learn_time_ms\": 11529.353}", "{\"n\": 969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2343.97, \"learn_time_ms\": 11529.663}", "{\"n\": 970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2340.39, \"learn_time_ms\": 11515.695}", "{\"n\": 971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2342.14, \"learn_time_ms\": 11519.369}", "{\"n\": 972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2346.19, \"learn_time_ms\": 11520.534}", "{\"n\": 973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2356.81, \"learn_time_ms\": 11511.978}", "{\"n\": 974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2366.5, \"learn_time_ms\": 11505.697}", "{\"n\": 975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2362.9, \"learn_time_ms\": 11493.106}", "{\"n\": 976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2362.89, \"learn_time_ms\": 11490.95}", "{\"n\": 977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2359.99, \"learn_time_ms\": 11486.0}", "{\"n\": 978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2361.48, \"learn_time_ms\": 11480.651}", "{\"n\": 979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2361.48, \"learn_time_ms\": 11476.664}", "{\"n\": 980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2357.3, \"learn_time_ms\": 11480.568}", "{\"n\": 981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2364.93, \"learn_time_ms\": 11475.599}", "{\"n\": 982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2355.45, \"learn_time_ms\": 11472.139}", "{\"n\": 983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2355.45, \"learn_time_ms\": 11480.496}", "{\"n\": 984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2360.08, \"learn_time_ms\": 11492.666}", "{\"n\": 985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2363.55, \"learn_time_ms\": 11499.548}", "{\"n\": 986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2370.75, \"learn_time_ms\": 11506.207}", "{\"n\": 987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2370.75, \"learn_time_ms\": 11505.866}", "{\"n\": 988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2370.94, \"learn_time_ms\": 11504.716}", "{\"n\": 989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2369.25, \"learn_time_ms\": 11505.521}", "{\"n\": 990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2364.76, \"learn_time_ms\": 11511.739}", "{\"n\": 991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2364.76, \"learn_time_ms\": 11516.017}", "{\"n\": 992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2372.3, \"learn_time_ms\": 11514.222}", "{\"n\": 993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2380.29, \"learn_time_ms\": 11520.875}", "{\"n\": 994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2389.44, \"learn_time_ms\": 11521.422}", "{\"n\": 995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2400.77, \"learn_time_ms\": 11528.27}", "{\"n\": 996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.16, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2402.82, \"learn_time_ms\": 11515.093}", "{\"n\": 997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2391.1, \"learn_time_ms\": 11519.327}", "{\"n\": 998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2388.71, \"learn_time_ms\": 11523.774}", "{\"n\": 999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2388.71, \"learn_time_ms\": 11527.073}", "{\"n\": 1000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2391.66, \"learn_time_ms\": 11528.656}"]