["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 37825.4, \"total_train_time_s\": 48.82182264328003}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 26391.884, \"total_train_time_s\": 21.426745653152466}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 22581.365, \"total_train_time_s\": 21.487061738967896}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1039.75, \"learn_time_ms\": 20671.052, \"total_train_time_s\": 21.415092945098877}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1036.6, \"learn_time_ms\": 19528.621, \"total_train_time_s\": 21.433680295944214}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1045.875, \"learn_time_ms\": 18763.686, \"total_train_time_s\": 21.46646022796631}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1040.0, \"learn_time_ms\": 18218.703, \"total_train_time_s\": 21.46771216392517}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1047.7916666666667, \"learn_time_ms\": 17792.525, \"total_train_time_s\": 21.319942474365234}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.933333333333334, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1056.5, \"learn_time_ms\": 17480.203, \"total_train_time_s\": 21.474735021591187}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.90625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1060.21875, \"learn_time_ms\": 17221.938, \"total_train_time_s\": 21.35746479034424}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.871794871794872, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1065.7179487179487, \"learn_time_ms\": 14935.422, \"total_train_time_s\": 21.501697301864624}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1066.45, \"learn_time_ms\": 14905.934, \"total_train_time_s\": 21.227232217788696}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.851063829787233, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1076.276595744681, \"learn_time_ms\": 14907.691, \"total_train_time_s\": 21.4924213886261}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.854166666666668, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1081.0625, \"learn_time_ms\": 14908.903, \"total_train_time_s\": 21.41577696800232}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.833333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1084.9259259259259, \"learn_time_ms\": 14884.546, \"total_train_time_s\": 21.1767098903656}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.771929824561404, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1095.0, \"learn_time_ms\": 14886.217, \"total_train_time_s\": 21.446516036987305}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.758064516129032, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1103.0, \"learn_time_ms\": 14886.947, \"total_train_time_s\": 21.46850037574768}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.753846153846155, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1112.4, \"learn_time_ms\": 14900.8, \"total_train_time_s\": 21.44821858406067}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.760563380281692, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1123.5915492957747, \"learn_time_ms\": 14896.946, \"total_train_time_s\": 21.480990886688232}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1123.6805555555557, \"learn_time_ms\": 14876.952, \"total_train_time_s\": 21.168780088424683}"]