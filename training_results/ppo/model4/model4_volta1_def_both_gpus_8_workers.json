["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 36576.897, \"total_train_time_s\": 46.058592081069946}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 23882.471, \"total_train_time_s\": 16.273961782455444}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 19623.754, \"total_train_time_s\": 16.16045594215393}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1047.0, \"learn_time_ms\": 17507.094, \"total_train_time_s\": 16.249467849731445}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.5, \"learn_time_ms\": 16225.046, \"total_train_time_s\": 16.091023921966553}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1057.3125, \"learn_time_ms\": 15371.726, \"total_train_time_s\": 16.205604076385498}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.666666666666668, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1057.4761904761904, \"learn_time_ms\": 14790.605, \"total_train_time_s\": 16.336196422576904}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.666666666666668, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1057.875, \"learn_time_ms\": 14332.1, \"total_train_time_s\": 16.201664447784424}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1057.15625, \"learn_time_ms\": 13981.085, \"total_train_time_s\": 16.23065185546875}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1057.15625, \"learn_time_ms\": 13692.761, \"total_train_time_s\": 16.11666488647461}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1059.325, \"learn_time_ms\": 11145.187, \"total_train_time_s\": 16.210591316223145}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1059.325, \"learn_time_ms\": 11133.713, \"total_train_time_s\": 16.012143850326538}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.645833333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1065.9583333333333, \"learn_time_ms\": 11150.55, \"total_train_time_s\": 16.308669328689575}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.653846153846153, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1064.8461538461538, \"learn_time_ms\": 11141.605, \"total_train_time_s\": 16.08795976638794}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1068.9464285714287, \"learn_time_ms\": 11138.657, \"total_train_time_s\": 16.191903591156006}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62295081967213, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1070.1967213114754, \"learn_time_ms\": 11133.637, \"total_train_time_s\": 16.107868671417236}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.609375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1071.59375, \"learn_time_ms\": 11108.567, \"total_train_time_s\": 16.10489535331726}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.577464788732396, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1076.056338028169, \"learn_time_ms\": 11102.404, \"total_train_time_s\": 16.191256999969482}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.589041095890412, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1075.5205479452054, \"learn_time_ms\": 11107.037, \"total_train_time_s\": 16.290372133255005}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.575, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1076.55, \"learn_time_ms\": 11102.445, \"total_train_time_s\": 16.089231491088867}"]