["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 40020.354}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 25115.132}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 20139.832}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1143.5, \"learn_time_ms\": 17650.02}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1143.5, \"learn_time_ms\": 16154.321}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.9375, \"learn_time_ms\": 15173.333}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.9375, \"learn_time_ms\": 14459.595}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.583333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.6666666666667, \"learn_time_ms\": 13927.095}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.615384615384617, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1113.4615384615386, \"learn_time_ms\": 13514.05}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1122.65625, \"learn_time_ms\": 13186.24}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.666666666666668, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.5277777777778, \"learn_time_ms\": 10201.825}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.675, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1115.125, \"learn_time_ms\": 10196.394}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.695652173913043, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.7608695652175, \"learn_time_ms\": 10201.657}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.708333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.5, \"learn_time_ms\": 10205.387}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69811320754717, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.754716981132, \"learn_time_ms\": 10204.368}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.714285714285715, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.5, \"learn_time_ms\": 10207.519}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71186440677966, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.7118644067796, \"learn_time_ms\": 10210.171}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.70769230769231, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1128.2769230769231, \"learn_time_ms\": 10219.533}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71014492753623, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1131.0869565217392, \"learn_time_ms\": 10221.929}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.698630136986303, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1141.7260273972602, \"learn_time_ms\": 10217.707}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71794871794872, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1138.9102564102564, \"learn_time_ms\": 10220.009}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73170731707317, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1138.6829268292684, \"learn_time_ms\": 10231.407}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74712643678161, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1139.816091954023, \"learn_time_ms\": 10229.879}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.752808988764045, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1143.0337078651685, \"learn_time_ms\": 10241.452}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.736842105263158, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1145.1684210526316, \"learn_time_ms\": 10246.996}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.742268041237114, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1145.7113402061855, \"learn_time_ms\": 10238.186}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1151.2, \"learn_time_ms\": 10238.482}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1153.21, \"learn_time_ms\": 10234.996}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1155.96, \"learn_time_ms\": 10232.462}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1155.19, \"learn_time_ms\": 10241.907}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1162.27, \"learn_time_ms\": 10243.956}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1163.59, \"learn_time_ms\": 10251.276}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1171.99, \"learn_time_ms\": 10247.639}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1171.54, \"learn_time_ms\": 10231.793}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1176.36, \"learn_time_ms\": 10229.568}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1177.71, \"learn_time_ms\": 10227.23}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1185.59, \"learn_time_ms\": 10223.762}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1193.25, \"learn_time_ms\": 10215.506}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1194.66, \"learn_time_ms\": 10213.945}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1203.44, \"learn_time_ms\": 10202.978}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1204.43, \"learn_time_ms\": 10206.995}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1206.68, \"learn_time_ms\": 10191.971}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1208.5, \"learn_time_ms\": 10190.474}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1208.13, \"learn_time_ms\": 10193.797}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1208.32, \"learn_time_ms\": 10191.56}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1214.48, \"learn_time_ms\": 10196.361}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1223.21, \"learn_time_ms\": 10197.852}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1226.99, \"learn_time_ms\": 10202.011}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1235.12, \"learn_time_ms\": 10200.087}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1242.85, \"learn_time_ms\": 10201.065}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1246.43, \"learn_time_ms\": 10192.909}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1258.63, \"learn_time_ms\": 10191.87}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1265.06, \"learn_time_ms\": 10193.244}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1279.07, \"learn_time_ms\": 10195.208}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1289.06, \"learn_time_ms\": 10194.763}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1295.05, \"learn_time_ms\": 10190.178}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1303.38, \"learn_time_ms\": 10189.686}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1327.94, \"learn_time_ms\": 10186.828}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1330.37, \"learn_time_ms\": 10185.213}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1334.39, \"learn_time_ms\": 10183.882}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1343.16, \"learn_time_ms\": 10182.921}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1342.88, \"learn_time_ms\": 10180.891}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.33, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1355.71, \"learn_time_ms\": 10178.75}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1376.33, \"learn_time_ms\": 10176.42}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1380.87, \"learn_time_ms\": 10178.725}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1394.45, \"learn_time_ms\": 10179.24}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1394.74, \"learn_time_ms\": 10180.015}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1392.17, \"learn_time_ms\": 10182.839}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1410.69, \"learn_time_ms\": 10183.46}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.26, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1417.99, \"learn_time_ms\": 10189.521}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1426.23, \"learn_time_ms\": 10195.902}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1452.41, \"learn_time_ms\": 10198.117}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1453.18, \"learn_time_ms\": 10199.544}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1453.18, \"learn_time_ms\": 10195.708}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1472.78, \"learn_time_ms\": 10194.518}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1473.15, \"learn_time_ms\": 10194.164}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.08, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1484.28, \"learn_time_ms\": 10194.191}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.07, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1489.67, \"learn_time_ms\": 10191.11}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.07, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1489.67, \"learn_time_ms\": 10192.576}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.02, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1508.14, \"learn_time_ms\": 10189.301}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.97, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1515.4, \"learn_time_ms\": 10184.518}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1527.08, \"learn_time_ms\": 10182.323}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1539.96, \"learn_time_ms\": 10188.576}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1549.74, \"learn_time_ms\": 10194.782}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1552.49, \"learn_time_ms\": 10198.582}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1560.6, \"learn_time_ms\": 10190.996}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.85, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1558.33, \"learn_time_ms\": 10190.659}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1564.64, \"learn_time_ms\": 10195.538}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1570.68, \"learn_time_ms\": 10199.396}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.74, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1576.84, \"learn_time_ms\": 10198.773}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.75, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1580.12, \"learn_time_ms\": 10197.011}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1587.41, \"learn_time_ms\": 10198.028}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1593.92, \"learn_time_ms\": 10198.779}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.65, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1597.37, \"learn_time_ms\": 10194.401}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.6, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1624.34, \"learn_time_ms\": 10199.8}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.58, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1633.47, \"learn_time_ms\": 10208.926}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.54, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1653.55, \"learn_time_ms\": 10217.051}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.53, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1657.49, \"learn_time_ms\": 10211.997}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1658.12, \"learn_time_ms\": 10212.861}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.46, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1659.92, \"learn_time_ms\": 10215.475}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.46, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1670.26, \"learn_time_ms\": 10216.951}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1678.15, \"learn_time_ms\": 10221.802}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1688.83, \"learn_time_ms\": 10215.94}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.36, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1700.96, \"learn_time_ms\": 10217.036}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.33, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1705.53, \"learn_time_ms\": 10208.885}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1717.47, \"learn_time_ms\": 10205.579}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1719.45, \"learn_time_ms\": 10199.802}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.32, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1717.14, \"learn_time_ms\": 10204.791}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1725.5, \"learn_time_ms\": 10206.856}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1725.5, \"learn_time_ms\": 10209.11}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1737.57, \"learn_time_ms\": 10209.455}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1748.69, \"learn_time_ms\": 10212.464}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1755.5, \"learn_time_ms\": 10213.342}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1758.18, \"learn_time_ms\": 10212.01}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1773.78, \"learn_time_ms\": 10211.02}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1773.78, \"learn_time_ms\": 10218.295}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1781.28, \"learn_time_ms\": 10216.289}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.31, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1780.89, \"learn_time_ms\": 10208.571}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.35, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1775.7, \"learn_time_ms\": 10209.516}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.29, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1776.91, \"learn_time_ms\": 10202.914}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1777.23, \"learn_time_ms\": 10201.104}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1787.84, \"learn_time_ms\": 10199.096}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1784.43, \"learn_time_ms\": 10197.934}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1790.15, \"learn_time_ms\": 10196.645}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1793.94, \"learn_time_ms\": 10206.53}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1809.07, \"learn_time_ms\": 10199.253}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1806.25, \"learn_time_ms\": 10199.124}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1807.45, \"learn_time_ms\": 10209.979}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1809.86, \"learn_time_ms\": 10201.398}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1817.52, \"learn_time_ms\": 10208.809}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1817.52, \"learn_time_ms\": 10210.769}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.15, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1818.99, \"learn_time_ms\": 10205.926}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1810.07, \"learn_time_ms\": 10210.626}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1804.8, \"learn_time_ms\": 10220.373}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1800.95, \"learn_time_ms\": 10210.831}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1808.53, \"learn_time_ms\": 10219.417}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.24, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1816.97, \"learn_time_ms\": 10229.263}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1823.93, \"learn_time_ms\": 10221.633}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1825.19, \"learn_time_ms\": 10220.348}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1832.09, \"learn_time_ms\": 10214.902}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1832.82, \"learn_time_ms\": 10215.748}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1830.19, \"learn_time_ms\": 10218.96}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1839.44, \"learn_time_ms\": 10215.372}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1839.02, \"learn_time_ms\": 10214.484}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1843.91, \"learn_time_ms\": 10230.655}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1849.15, \"learn_time_ms\": 10249.997}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.02, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1857.46, \"learn_time_ms\": 10242.435}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1859.85, \"learn_time_ms\": 10241.365}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1859.48, \"learn_time_ms\": 10248.52}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.96, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1854.21, \"learn_time_ms\": 10255.533}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1858.6, \"learn_time_ms\": 10261.442}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1859.93, \"learn_time_ms\": 10266.241}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.89, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1860.76, \"learn_time_ms\": 10263.189}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.89, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1860.78, \"learn_time_ms\": 10260.834}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.92, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1851.23, \"learn_time_ms\": 10244.666}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.92, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1864.73, \"learn_time_ms\": 10225.475}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1870.94, \"learn_time_ms\": 10229.056}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.89, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1876.61, \"learn_time_ms\": 10241.078}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1879.77, \"learn_time_ms\": 10238.36}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1875.16, \"learn_time_ms\": 10238.25}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.97, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1877.95, \"learn_time_ms\": 10233.502}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1878.96, \"learn_time_ms\": 10230.323}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.97, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1883.74, \"learn_time_ms\": 10234.047}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1882.33, \"learn_time_ms\": 10230.043}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1880.56, \"learn_time_ms\": 10231.786}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.92, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1888.54, \"learn_time_ms\": 10223.285}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.88, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1898.51, \"learn_time_ms\": 10238.614}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1898.05, \"learn_time_ms\": 10272.296}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1894.35, \"learn_time_ms\": 10285.954}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1895.39, \"learn_time_ms\": 10285.997}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1888.06, \"learn_time_ms\": 10315.749}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1889.49, \"learn_time_ms\": 10334.899}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1889.89, \"learn_time_ms\": 10351.87}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.97, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1890.23, \"learn_time_ms\": 10361.282}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1888.39, \"learn_time_ms\": 10383.905}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1884.39, \"learn_time_ms\": 10407.994}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1878.71, \"learn_time_ms\": 10389.904}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.97, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1884.07, \"learn_time_ms\": 10367.987}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1875.43, \"learn_time_ms\": 10396.215}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1878.87, \"learn_time_ms\": 10426.233}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.1, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1878.77, \"learn_time_ms\": 10397.431}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1876.56, \"learn_time_ms\": 10376.657}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1880.36, \"learn_time_ms\": 10359.345}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1876.43, \"learn_time_ms\": 10358.424}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1874.27, \"learn_time_ms\": 10341.204}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1878.51, \"learn_time_ms\": 10318.217}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.1, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1875.62, \"learn_time_ms\": 10321.043}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1876.54, \"learn_time_ms\": 10317.132}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.08, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1887.14, \"learn_time_ms\": 10303.654}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1893.92, \"learn_time_ms\": 10296.623}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1905.65, \"learn_time_ms\": 10312.435}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1912.14, \"learn_time_ms\": 10314.688}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1911.29, \"learn_time_ms\": 10346.095}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1915.85, \"learn_time_ms\": 10371.606}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1915.85, \"learn_time_ms\": 10390.378}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.1, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1896.35, \"learn_time_ms\": 10410.254}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1892.47, \"learn_time_ms\": 10405.345}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1895.27, \"learn_time_ms\": 10387.224}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.08, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1901.5, \"learn_time_ms\": 10359.164}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.09, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1904.45, \"learn_time_ms\": 10327.464}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1911.74, \"learn_time_ms\": 10309.08}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1911.96, \"learn_time_ms\": 10304.982}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1907.32, \"learn_time_ms\": 10278.877}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1911.9, \"learn_time_ms\": 10270.982}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1909.93, \"learn_time_ms\": 10282.93}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1907.53, \"learn_time_ms\": 10292.25}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1905.88, \"learn_time_ms\": 10331.071}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1904.32, \"learn_time_ms\": 10346.989}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1898.36, \"learn_time_ms\": 10367.328}", "{\"n\": 210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1899.49, \"learn_time_ms\": 10372.384}", "{\"n\": 211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1910.93, \"learn_time_ms\": 10373.398}", "{\"n\": 212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1922.81, \"learn_time_ms\": 10407.489}", "{\"n\": 213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.08, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1930.56, \"learn_time_ms\": 10427.886}", "{\"n\": 214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.08, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1931.65, \"learn_time_ms\": 10405.241}", "{\"n\": 215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1930.17, \"learn_time_ms\": 10395.528}", "{\"n\": 216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1934.7, \"learn_time_ms\": 10394.189}", "{\"n\": 217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1933.52, \"learn_time_ms\": 10382.012}", "{\"n\": 218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1934.04, \"learn_time_ms\": 10385.691}", "{\"n\": 219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1933.92, \"learn_time_ms\": 10392.224}", "{\"n\": 220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1930.09, \"learn_time_ms\": 10393.302}", "{\"n\": 221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1930.87, \"learn_time_ms\": 10391.522}", "{\"n\": 222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1934.84, \"learn_time_ms\": 10353.945}", "{\"n\": 223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1931.18, \"learn_time_ms\": 10329.965}", "{\"n\": 224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1925.4, \"learn_time_ms\": 10334.533}", "{\"n\": 225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1930.14, \"learn_time_ms\": 10327.642}", "{\"n\": 226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1926.64, \"learn_time_ms\": 10337.405}", "{\"n\": 227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1926.64, \"learn_time_ms\": 10335.353}", "{\"n\": 228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1933.4, \"learn_time_ms\": 10322.399}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1929.95, \"learn_time_ms\": 10294.721}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.09, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1914.15, \"learn_time_ms\": 10320.185}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1908.17, \"learn_time_ms\": 10347.214}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1899.46, \"learn_time_ms\": 10373.808}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1908.72, \"learn_time_ms\": 10404.632}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.06, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1911.72, \"learn_time_ms\": 10436.579}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.99, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1915.87, \"learn_time_ms\": 10420.652}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1926.41, \"learn_time_ms\": 10407.87}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1926.54, \"learn_time_ms\": 10431.323}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1933.02, \"learn_time_ms\": 10470.598}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1935.71, \"learn_time_ms\": 10509.768}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1934.06, \"learn_time_ms\": 10508.856}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1931.17, \"learn_time_ms\": 10514.513}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.88, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1933.63, \"learn_time_ms\": 10536.568}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1928.05, \"learn_time_ms\": 10543.892}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1923.62, \"learn_time_ms\": 10547.242}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1923.19, \"learn_time_ms\": 10585.193}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1921.33, \"learn_time_ms\": 10616.934}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1921.62, \"learn_time_ms\": 10619.127}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1932.21, \"learn_time_ms\": 10595.019}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1934.13, \"learn_time_ms\": 10585.485}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1932.78, \"learn_time_ms\": 10582.302}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1925.61, \"learn_time_ms\": 10577.094}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1922.05, \"learn_time_ms\": 10573.145}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1916.63, \"learn_time_ms\": 10585.71}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.09, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1914.88, \"learn_time_ms\": 10572.754}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1920.29, \"learn_time_ms\": 10564.536}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1920.29, \"learn_time_ms\": 10550.169}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1920.35, \"learn_time_ms\": 10524.281}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1927.65, \"learn_time_ms\": 10522.195}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1940.21, \"learn_time_ms\": 10521.387}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1950.36, \"learn_time_ms\": 10536.482}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1959.2, \"learn_time_ms\": 10556.751}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.09, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1957.27, \"learn_time_ms\": 10576.443}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.09, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1964.72, \"learn_time_ms\": 10574.504}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1965.37, \"learn_time_ms\": 10590.208}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.08, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1976.01, \"learn_time_ms\": 10605.522}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.09, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1974.81, \"learn_time_ms\": 10606.529}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1985.69, \"learn_time_ms\": 10630.191}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1988.54, \"learn_time_ms\": 10659.689}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1990.1, \"learn_time_ms\": 10692.341}", "{\"n\": 270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1992.08, \"learn_time_ms\": 10702.818}", "{\"n\": 271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2002.11, \"learn_time_ms\": 10691.168}", "{\"n\": 272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2010.07, \"learn_time_ms\": 10659.43}", "{\"n\": 273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2007.52, \"learn_time_ms\": 10641.448}", "{\"n\": 274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2009.08, \"learn_time_ms\": 10643.973}", "{\"n\": 275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2003.89, \"learn_time_ms\": 10635.061}", "{\"n\": 276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2001.7, \"learn_time_ms\": 10623.288}", "{\"n\": 277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2007.67, \"learn_time_ms\": 10595.062}", "{\"n\": 278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1997.96, \"learn_time_ms\": 10548.275}", "{\"n\": 279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1994.38, \"learn_time_ms\": 10488.905}", "{\"n\": 280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1994.38, \"learn_time_ms\": 10468.973}", "{\"n\": 281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1990.91, \"learn_time_ms\": 10479.435}", "{\"n\": 282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.31, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1984.38, \"learn_time_ms\": 10501.238}", "{\"n\": 283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1981.93, \"learn_time_ms\": 10501.181}", "{\"n\": 284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1979.71, \"learn_time_ms\": 10490.049}", "{\"n\": 285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1985.6, \"learn_time_ms\": 10478.643}", "{\"n\": 286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.24, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1994.81, \"learn_time_ms\": 10495.973}", "{\"n\": 287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1990.95, \"learn_time_ms\": 10507.944}", "{\"n\": 288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.24, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1994.12, \"learn_time_ms\": 10558.401}", "{\"n\": 289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1995.68, \"learn_time_ms\": 10591.895}", "{\"n\": 290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.26, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1986.06, \"learn_time_ms\": 10596.895}", "{\"n\": 291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1976.16, \"learn_time_ms\": 10602.23}", "{\"n\": 292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.24, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1982.95, \"learn_time_ms\": 10602.513}", "{\"n\": 293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1985.82, \"learn_time_ms\": 10624.123}", "{\"n\": 294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1985.82, \"learn_time_ms\": 10628.474}", "{\"n\": 295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1985.93, \"learn_time_ms\": 10622.855}", "{\"n\": 296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1985.43, \"learn_time_ms\": 10604.033}", "{\"n\": 297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1991.82, \"learn_time_ms\": 10619.834}", "{\"n\": 298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1992.1, \"learn_time_ms\": 10609.989}", "{\"n\": 299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1993.26, \"learn_time_ms\": 10636.337}", "{\"n\": 300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1986.22, \"learn_time_ms\": 10662.528}", "{\"n\": 301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1973.29, \"learn_time_ms\": 10674.928}", "{\"n\": 302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.2, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1964.5, \"learn_time_ms\": 10689.737}", "{\"n\": 303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1970.33, \"learn_time_ms\": 10704.113}", "{\"n\": 304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.2, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1958.68, \"learn_time_ms\": 10734.518}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1959.15, \"learn_time_ms\": 10784.409}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1959.2, \"learn_time_ms\": 10819.021}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1963.5, \"learn_time_ms\": 10839.645}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1964.23, \"learn_time_ms\": 10861.17}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1969.38, \"learn_time_ms\": 10864.111}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1967.17, \"learn_time_ms\": 10869.2}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.15, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1962.74, \"learn_time_ms\": 10872.983}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1964.14, \"learn_time_ms\": 10875.706}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.11, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1966.23, \"learn_time_ms\": 10878.744}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1979.7, \"learn_time_ms\": 10864.973}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1980.44, \"learn_time_ms\": 10862.019}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1984.96, \"learn_time_ms\": 10860.344}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1988.13, \"learn_time_ms\": 10857.469}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1994.22, \"learn_time_ms\": 10855.291}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1995.29, \"learn_time_ms\": 10863.674}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1998.3, \"learn_time_ms\": 10860.962}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -16.0, \"episode_len_mean\": 2009.43, \"learn_time_ms\": 10863.335}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -16.0, \"episode_len_mean\": 2009.26, \"learn_time_ms\": 10862.287}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2018.94, \"learn_time_ms\": 10855.116}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2026.91, \"learn_time_ms\": 10860.854}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.85, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2035.8, \"learn_time_ms\": 10859.221}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2047.44, \"learn_time_ms\": 10863.327}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2047.44, \"learn_time_ms\": 10859.358}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2049.17, \"learn_time_ms\": 10869.106}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.89, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2039.77, \"learn_time_ms\": 10855.795}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.88, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2041.49, \"learn_time_ms\": 10851.951}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2041.93, \"learn_time_ms\": 10851.6}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2050.09, \"learn_time_ms\": 10847.652}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.8, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2072.62, \"learn_time_ms\": 10846.722}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.8, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2072.62, \"learn_time_ms\": 10851.668}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2079.3, \"learn_time_ms\": 10849.908}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2090.62, \"learn_time_ms\": 10849.517}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2093.51, \"learn_time_ms\": 10847.997}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2102.54, \"learn_time_ms\": 10830.869}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2108.6, \"learn_time_ms\": 10827.053}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2124.17, \"learn_time_ms\": 10827.754}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2118.05, \"learn_time_ms\": 10819.609}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2114.79, \"learn_time_ms\": 10818.726}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.62, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2118.93, \"learn_time_ms\": 10817.798}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.62, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2123.4, \"learn_time_ms\": 10820.047}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.62, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2123.4, \"learn_time_ms\": 10819.718}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.52, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2134.44, \"learn_time_ms\": 10816.875}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2149.18, \"learn_time_ms\": 10821.905}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2153.63, \"learn_time_ms\": 10821.567}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2159.81, \"learn_time_ms\": 10825.799}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.36, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2175.11, \"learn_time_ms\": 10824.365}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2181.72, \"learn_time_ms\": 10827.446}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2178.77, \"learn_time_ms\": 10829.657}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2178.53, \"learn_time_ms\": 10825.928}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.32, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2185.04, \"learn_time_ms\": 10816.405}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2180.86, \"learn_time_ms\": 10811.096}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2182.0, \"learn_time_ms\": 10818.21}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2186.42, \"learn_time_ms\": 10819.736}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2195.25, \"learn_time_ms\": 10832.435}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.28, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2193.54, \"learn_time_ms\": 10840.312}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2190.96, \"learn_time_ms\": 10842.12}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2201.65, \"learn_time_ms\": 10850.141}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2200.19, \"learn_time_ms\": 10838.24}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2200.73, \"learn_time_ms\": 10843.925}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2200.73, \"learn_time_ms\": 10837.98}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2203.22, \"learn_time_ms\": 10838.409}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2201.88, \"learn_time_ms\": 10834.504}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2199.63, \"learn_time_ms\": 10831.122}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2202.61, \"learn_time_ms\": 10834.198}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2205.36, \"learn_time_ms\": 10831.77}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2206.12, \"learn_time_ms\": 10827.391}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2215.55, \"learn_time_ms\": 10817.893}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2214.26, \"learn_time_ms\": 10827.021}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2216.14, \"learn_time_ms\": 10826.602}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2222.12, \"learn_time_ms\": 10831.733}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2234.55, \"learn_time_ms\": 10841.244}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2246.85, \"learn_time_ms\": 10838.324}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.03, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2241.18, \"learn_time_ms\": 10835.602}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.07, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2240.48, \"learn_time_ms\": 10827.041}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.09, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2240.0, \"learn_time_ms\": 10821.179}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2241.98, \"learn_time_ms\": 10813.644}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2237.46, \"learn_time_ms\": 10815.414}", "{\"n\": 382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2240.87, \"learn_time_ms\": 10822.913}", "{\"n\": 383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2246.08, \"learn_time_ms\": 10826.695}", "{\"n\": 384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.09, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2255.93, \"learn_time_ms\": 10837.583}", "{\"n\": 385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.08, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2259.61, \"learn_time_ms\": 10828.264}", "{\"n\": 386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.03, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2271.28, \"learn_time_ms\": 10830.847}", "{\"n\": 387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.03, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2271.28, \"learn_time_ms\": 10831.134}", "{\"n\": 388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2282.23, \"learn_time_ms\": 10832.889}", "{\"n\": 389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2289.43, \"learn_time_ms\": 10826.577}", "{\"n\": 390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2289.18, \"learn_time_ms\": 10846.063}", "{\"n\": 391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2286.65, \"learn_time_ms\": 10852.946}", "{\"n\": 392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2297.37, \"learn_time_ms\": 10848.349}", "{\"n\": 393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2291.92, \"learn_time_ms\": 10843.901}", "{\"n\": 394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.04, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2297.32, \"learn_time_ms\": 10828.125}", "{\"n\": 395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.1, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2295.42, \"learn_time_ms\": 10831.152}", "{\"n\": 396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.1, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2295.42, \"learn_time_ms\": 10828.486}", "{\"n\": 397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2296.86, \"learn_time_ms\": 10836.163}", "{\"n\": 398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2282.79, \"learn_time_ms\": 10844.125}", "{\"n\": 399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2283.19, \"learn_time_ms\": 10843.566}", "{\"n\": 400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2283.19, \"learn_time_ms\": 10838.929}", "{\"n\": 401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.14, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2289.04, \"learn_time_ms\": 10834.39}", "{\"n\": 402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.14, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2286.72, \"learn_time_ms\": 10828.004}", "{\"n\": 403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2300.14, \"learn_time_ms\": 10831.119}", "{\"n\": 404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2299.39, \"learn_time_ms\": 10839.689}", "{\"n\": 405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2302.08, \"learn_time_ms\": 10840.447}", "{\"n\": 406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2302.08, \"learn_time_ms\": 10843.774}", "{\"n\": 407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2311.8, \"learn_time_ms\": 10845.866}", "{\"n\": 408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.08, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2320.6, \"learn_time_ms\": 10838.017}", "{\"n\": 409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2316.02, \"learn_time_ms\": 10845.37}", "{\"n\": 410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2315.09, \"learn_time_ms\": 10836.584}", "{\"n\": 411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2326.45, \"learn_time_ms\": 10831.771}", "{\"n\": 412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2332.06, \"learn_time_ms\": 10844.673}", "{\"n\": 413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2335.56, \"learn_time_ms\": 10844.201}", "{\"n\": 414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2335.56, \"learn_time_ms\": 10839.606}", "{\"n\": 415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2357.03, \"learn_time_ms\": 10831.292}", "{\"n\": 416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2359.68, \"learn_time_ms\": 10828.569}", "{\"n\": 417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2360.42, \"learn_time_ms\": 10820.133}", "{\"n\": 418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2378.11, \"learn_time_ms\": 10818.768}", "{\"n\": 419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2387.42, \"learn_time_ms\": 10816.059}", "{\"n\": 420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2379.99, \"learn_time_ms\": 10821.776}", "{\"n\": 421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.81, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2387.18, \"learn_time_ms\": 10822.955}", "{\"n\": 422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.79, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2380.63, \"learn_time_ms\": 10819.956}", "{\"n\": 423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2379.63, \"learn_time_ms\": 10812.497}", "{\"n\": 424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.81, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2383.83, \"learn_time_ms\": 10814.387}", "{\"n\": 425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2382.86, \"learn_time_ms\": 10804.2}", "{\"n\": 426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.82, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2378.88, \"learn_time_ms\": 10779.359}", "{\"n\": 427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2394.3, \"learn_time_ms\": 10769.223}", "{\"n\": 428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2398.95, \"learn_time_ms\": 10767.573}", "{\"n\": 429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2403.56, \"learn_time_ms\": 10770.863}", "{\"n\": 430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2415.68, \"learn_time_ms\": 10777.137}", "{\"n\": 431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2426.67, \"learn_time_ms\": 10779.195}", "{\"n\": 432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2428.68, \"learn_time_ms\": 10780.491}", "{\"n\": 433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2419.86, \"learn_time_ms\": 10784.131}", "{\"n\": 434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.46, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2404.36, \"learn_time_ms\": 10787.959}", "{\"n\": 435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.46, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2405.9, \"learn_time_ms\": 10806.082}", "{\"n\": 436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.49, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2403.46, \"learn_time_ms\": 10827.85}", "{\"n\": 437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2392.61, \"learn_time_ms\": 10836.959}", "{\"n\": 438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2391.75, \"learn_time_ms\": 10838.527}", "{\"n\": 439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2398.71, \"learn_time_ms\": 10842.59}", "{\"n\": 440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.49, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2398.67, \"learn_time_ms\": 10835.471}", "{\"n\": 441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2399.74, \"learn_time_ms\": 10829.745}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2393.52, \"learn_time_ms\": 10820.343}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2394.57, \"learn_time_ms\": 10813.466}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2399.65, \"learn_time_ms\": 10817.376}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2391.36, \"learn_time_ms\": 10817.72}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2389.1, \"learn_time_ms\": 10826.467}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2399.07, \"learn_time_ms\": 10825.727}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2394.49, \"learn_time_ms\": 10839.394}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2396.94, \"learn_time_ms\": 10845.889}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2394.46, \"learn_time_ms\": 10847.382}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.22, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2393.04, \"learn_time_ms\": 10856.924}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2382.91, \"learn_time_ms\": 10868.168}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2382.91, \"learn_time_ms\": 10882.823}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2389.95, \"learn_time_ms\": 10865.76}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2380.52, \"learn_time_ms\": 10845.494}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2377.9, \"learn_time_ms\": 10836.58}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2375.66, \"learn_time_ms\": 10841.053}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2372.33, \"learn_time_ms\": 10830.502}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2383.65, \"learn_time_ms\": 10822.99}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2383.08, \"learn_time_ms\": 10822.853}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2380.9, \"learn_time_ms\": 10815.399}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2384.86, \"learn_time_ms\": 10810.815}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2370.57, \"learn_time_ms\": 10800.136}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2376.54, \"learn_time_ms\": 10815.9}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2377.03, \"learn_time_ms\": 10828.602}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2375.02, \"learn_time_ms\": 10837.491}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2370.21, \"learn_time_ms\": 10832.649}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2360.7, \"learn_time_ms\": 10833.506}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2363.25, \"learn_time_ms\": 10829.844}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2365.55, \"learn_time_ms\": 10828.291}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2372.53, \"learn_time_ms\": 10829.822}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2382.44, \"learn_time_ms\": 10817.763}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2391.74, \"learn_time_ms\": 10818.795}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2396.61, \"learn_time_ms\": 10815.331}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.12, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2395.53, \"learn_time_ms\": 10805.497}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2391.64, \"learn_time_ms\": 10785.317}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.04, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2397.84, \"learn_time_ms\": 10767.962}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.16, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2388.09, \"learn_time_ms\": 10768.966}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2378.66, \"learn_time_ms\": 10770.372}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2375.1, \"learn_time_ms\": 10774.731}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2367.7, \"learn_time_ms\": 10774.507}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2371.92, \"learn_time_ms\": 10785.559}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2384.69, \"learn_time_ms\": 10790.403}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2384.69, \"learn_time_ms\": 10788.668}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2377.23, \"learn_time_ms\": 10803.149}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2379.06, \"learn_time_ms\": 10809.307}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.16, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2384.02, \"learn_time_ms\": 10826.687}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.18, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2379.15, \"learn_time_ms\": 10802.453}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2380.54, \"learn_time_ms\": 10807.032}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2383.97, \"learn_time_ms\": 10803.043}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2398.77, \"learn_time_ms\": 10811.565}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.06, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2403.15, \"learn_time_ms\": 10808.593}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2404.17, \"learn_time_ms\": 10805.54}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2406.56, \"learn_time_ms\": 10805.676}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2414.44, \"learn_time_ms\": 10800.387}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2414.44, \"learn_time_ms\": 10797.128}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2413.91, \"learn_time_ms\": 10795.095}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2414.34, \"learn_time_ms\": 10813.495}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2418.38, \"learn_time_ms\": 10809.286}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2416.99, \"learn_time_ms\": 10808.212}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2425.12, \"learn_time_ms\": 10800.131}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2425.12, \"learn_time_ms\": 10805.38}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2430.01, \"learn_time_ms\": 10793.657}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2425.95, \"learn_time_ms\": 10792.204}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2429.97, \"learn_time_ms\": 10794.653}", "{\"n\": 506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2429.97, \"learn_time_ms\": 10803.452}", "{\"n\": 507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2429.83, \"learn_time_ms\": 10811.743}", "{\"n\": 508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2430.2, \"learn_time_ms\": 10815.627}", "{\"n\": 509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2417.16, \"learn_time_ms\": 10808.457}", "{\"n\": 510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2417.39, \"learn_time_ms\": 10809.215}", "{\"n\": 511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2418.5, \"learn_time_ms\": 10811.86}", "{\"n\": 512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2416.52, \"learn_time_ms\": 10800.988}", "{\"n\": 513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2427.78, \"learn_time_ms\": 10813.983}", "{\"n\": 514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2437.16, \"learn_time_ms\": 10823.245}", "{\"n\": 515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2432.5, \"learn_time_ms\": 10834.869}", "{\"n\": 516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2437.81, \"learn_time_ms\": 10840.818}", "{\"n\": 517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2444.4, \"learn_time_ms\": 10846.222}", "{\"n\": 518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2444.4, \"learn_time_ms\": 10849.595}", "{\"n\": 519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2444.4, \"learn_time_ms\": 10863.991}", "{\"n\": 520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2433.72, \"learn_time_ms\": 10866.139}", "{\"n\": 521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2432.83, \"learn_time_ms\": 10863.725}", "{\"n\": 522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2423.69, \"learn_time_ms\": 10863.492}", "{\"n\": 523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2423.69, \"learn_time_ms\": 10857.693}", "{\"n\": 524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2416.78, \"learn_time_ms\": 10842.952}", "{\"n\": 525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2435.49, \"learn_time_ms\": 10836.198}", "{\"n\": 526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2443.27, \"learn_time_ms\": 10828.953}", "{\"n\": 527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2438.28, \"learn_time_ms\": 10815.314}", "{\"n\": 528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2434.98, \"learn_time_ms\": 10812.335}", "{\"n\": 529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2444.08, \"learn_time_ms\": 10803.944}", "{\"n\": 530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2444.04, \"learn_time_ms\": 10801.838}", "{\"n\": 531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2441.99, \"learn_time_ms\": 10808.079}", "{\"n\": 532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2449.37, \"learn_time_ms\": 10822.363}", "{\"n\": 533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2456.04, \"learn_time_ms\": 10824.417}", "{\"n\": 534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2449.53, \"learn_time_ms\": 10828.845}", "{\"n\": 535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2451.51, \"learn_time_ms\": 10820.817}", "{\"n\": 536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2456.41, \"learn_time_ms\": 10825.965}", "{\"n\": 537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2452.65, \"learn_time_ms\": 10837.039}", "{\"n\": 538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2452.65, \"learn_time_ms\": 10835.071}", "{\"n\": 539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2451.73, \"learn_time_ms\": 10838.916}", "{\"n\": 540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2451.73, \"learn_time_ms\": 10843.835}", "{\"n\": 541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2443.99, \"learn_time_ms\": 10838.701}", "{\"n\": 542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2441.51, \"learn_time_ms\": 10827.154}", "{\"n\": 543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2441.51, \"learn_time_ms\": 10827.839}", "{\"n\": 544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2439.32, \"learn_time_ms\": 10830.673}", "{\"n\": 545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2444.06, \"learn_time_ms\": 10835.197}", "{\"n\": 546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2461.77, \"learn_time_ms\": 10810.277}", "{\"n\": 547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.61, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2468.42, \"learn_time_ms\": 10788.874}", "{\"n\": 548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.61, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2468.42, \"learn_time_ms\": 10790.835}", "{\"n\": 549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.62, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2473.64, \"learn_time_ms\": 10782.247}", "{\"n\": 550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.55, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2486.76, \"learn_time_ms\": 10777.128}", "{\"n\": 551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2504.67, \"learn_time_ms\": 10781.562}", "{\"n\": 552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2502.89, \"learn_time_ms\": 10787.168}", "{\"n\": 553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2502.89, \"learn_time_ms\": 10796.196}", "{\"n\": 554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2499.05, \"learn_time_ms\": 10794.174}", "{\"n\": 555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2512.87, \"learn_time_ms\": 10802.425}", "{\"n\": 556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2519.17, \"learn_time_ms\": 10827.441}", "{\"n\": 557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2519.17, \"learn_time_ms\": 10830.391}", "{\"n\": 558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2524.93, \"learn_time_ms\": 10816.294}", "{\"n\": 559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2529.93, \"learn_time_ms\": 10825.012}", "{\"n\": 560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2540.36, \"learn_time_ms\": 10825.766}", "{\"n\": 561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2545.12, \"learn_time_ms\": 10819.485}", "{\"n\": 562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.16, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2552.36, \"learn_time_ms\": 10820.778}", "{\"n\": 563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2550.4, \"learn_time_ms\": 10813.312}", "{\"n\": 564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2549.73, \"learn_time_ms\": 10808.181}", "{\"n\": 565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2544.23, \"learn_time_ms\": 10801.539}", "{\"n\": 566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2529.48, \"learn_time_ms\": 10800.015}", "{\"n\": 567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2523.18, \"learn_time_ms\": 10813.571}", "{\"n\": 568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2541.78, \"learn_time_ms\": 10824.118}", "{\"n\": 569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2542.33, \"learn_time_ms\": 10818.76}", "{\"n\": 570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.21, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2542.32, \"learn_time_ms\": 10820.453}", "{\"n\": 571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2540.95, \"learn_time_ms\": 10822.424}", "{\"n\": 572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2551.44, \"learn_time_ms\": 10817.281}", "{\"n\": 573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2561.74, \"learn_time_ms\": 10814.195}", "{\"n\": 574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2559.73, \"learn_time_ms\": 10823.284}", "{\"n\": 575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2551.42, \"learn_time_ms\": 10826.25}", "{\"n\": 576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2551.42, \"learn_time_ms\": 10826.754}", "{\"n\": 577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2547.41, \"learn_time_ms\": 10832.086}", "{\"n\": 578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2529.01, \"learn_time_ms\": 10826.889}", "{\"n\": 579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2529.01, \"learn_time_ms\": 10821.297}", "{\"n\": 580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2535.17, \"learn_time_ms\": 10822.819}", "{\"n\": 581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2531.68, \"learn_time_ms\": 10819.988}", "{\"n\": 582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2525.18, \"learn_time_ms\": 10819.945}", "{\"n\": 583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2526.72, \"learn_time_ms\": 10822.202}", "{\"n\": 584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2526.72, \"learn_time_ms\": 10818.322}", "{\"n\": 585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2520.18, \"learn_time_ms\": 10817.214}", "{\"n\": 586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2522.74, \"learn_time_ms\": 10814.58}", "{\"n\": 587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2543.13, \"learn_time_ms\": 10789.426}", "{\"n\": 588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2536.64, \"learn_time_ms\": 10775.48}", "{\"n\": 589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.99, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2539.99, \"learn_time_ms\": 10760.83}", "{\"n\": 590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2548.01, \"learn_time_ms\": 10760.554}", "{\"n\": 591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2555.4, \"learn_time_ms\": 10758.418}", "{\"n\": 592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.84, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2563.73, \"learn_time_ms\": 10751.261}", "{\"n\": 593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.81, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2565.89, \"learn_time_ms\": 10750.005}", "{\"n\": 594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.81, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2565.89, \"learn_time_ms\": 10750.727}", "{\"n\": 595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2576.57, \"learn_time_ms\": 10752.241}", "{\"n\": 596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2575.33, \"learn_time_ms\": 10754.339}", "{\"n\": 597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2585.49, \"learn_time_ms\": 10763.0}", "{\"n\": 598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2578.26, \"learn_time_ms\": 10759.602}", "{\"n\": 599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.84, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2578.55, \"learn_time_ms\": 10785.843}", "{\"n\": 600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2577.65, \"learn_time_ms\": 10776.186}", "{\"n\": 601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2577.65, \"learn_time_ms\": 10766.091}", "{\"n\": 602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2576.2, \"learn_time_ms\": 10760.004}", "{\"n\": 603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2572.68, \"learn_time_ms\": 10762.704}", "{\"n\": 604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2555.61, \"learn_time_ms\": 10750.734}", "{\"n\": 605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2555.61, \"learn_time_ms\": 10734.523}", "{\"n\": 606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2555.57, \"learn_time_ms\": 10736.129}", "{\"n\": 607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2570.33, \"learn_time_ms\": 10747.438}", "{\"n\": 608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2561.47, \"learn_time_ms\": 10773.352}", "{\"n\": 609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2557.68, \"learn_time_ms\": 10767.251}", "{\"n\": 610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2561.6, \"learn_time_ms\": 10761.996}", "{\"n\": 611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.98, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2558.48, \"learn_time_ms\": 10757.376}", "{\"n\": 612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2564.41, \"learn_time_ms\": 10742.931}", "{\"n\": 613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.99, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2546.08, \"learn_time_ms\": 10721.982}", "{\"n\": 614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2549.34, \"learn_time_ms\": 10716.833}", "{\"n\": 615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2541.08, \"learn_time_ms\": 10709.751}", "{\"n\": 616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2542.79, \"learn_time_ms\": 10694.459}", "{\"n\": 617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2554.14, \"learn_time_ms\": 10672.755}", "{\"n\": 618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.82, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2571.69, \"learn_time_ms\": 10666.215}", "{\"n\": 619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.8, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2577.36, \"learn_time_ms\": 10672.597}", "{\"n\": 620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2583.79, \"learn_time_ms\": 10693.451}", "{\"n\": 621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.82, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2577.99, \"learn_time_ms\": 10687.97}", "{\"n\": 622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2576.71, \"learn_time_ms\": 10704.103}", "{\"n\": 623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.84, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2567.74, \"learn_time_ms\": 10709.993}", "{\"n\": 624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2572.14, \"learn_time_ms\": 10706.914}", "{\"n\": 625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2572.14, \"learn_time_ms\": 10711.749}", "{\"n\": 626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2571.1, \"learn_time_ms\": 10734.015}", "{\"n\": 627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.81, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2572.7, \"learn_time_ms\": 10752.066}", "{\"n\": 628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2574.15, \"learn_time_ms\": 10753.937}", "{\"n\": 629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2581.18, \"learn_time_ms\": 10728.509}", "{\"n\": 630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2584.0, \"learn_time_ms\": 10722.347}", "{\"n\": 631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2585.59, \"learn_time_ms\": 10742.247}", "{\"n\": 632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2590.45, \"learn_time_ms\": 10760.223}", "{\"n\": 633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.67, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2585.88, \"learn_time_ms\": 10777.918}", "{\"n\": 634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2598.27, \"learn_time_ms\": 10801.409}", "{\"n\": 635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2599.84, \"learn_time_ms\": 10814.185}", "{\"n\": 636, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2619.22, \"learn_time_ms\": 10792.932}", "{\"n\": 637, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2619.22, \"learn_time_ms\": 10783.719}", "{\"n\": 638, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2627.35, \"learn_time_ms\": 10779.686}", "{\"n\": 639, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2640.14, \"learn_time_ms\": 10798.443}", "{\"n\": 640, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.26, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2654.58, \"learn_time_ms\": 10792.491}", "{\"n\": 641, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.28, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2650.39, \"learn_time_ms\": 10795.808}", "{\"n\": 642, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2652.87, \"learn_time_ms\": 10790.082}", "{\"n\": 643, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2645.89, \"learn_time_ms\": 10788.547}", "{\"n\": 644, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2658.44, \"learn_time_ms\": 10785.503}", "{\"n\": 645, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2661.04, \"learn_time_ms\": 10785.869}", "{\"n\": 646, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.28, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2661.66, \"learn_time_ms\": 10801.868}", "{\"n\": 647, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2666.05, \"learn_time_ms\": 10811.786}", "{\"n\": 648, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2672.38, \"learn_time_ms\": 10816.706}", "{\"n\": 649, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2659.27, \"learn_time_ms\": 10824.869}", "{\"n\": 650, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2669.98, \"learn_time_ms\": 10826.418}", "{\"n\": 651, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.13, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2676.97, \"learn_time_ms\": 10828.693}", "{\"n\": 652, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.13, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2676.97, \"learn_time_ms\": 10828.322}", "{\"n\": 653, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2676.15, \"learn_time_ms\": 10831.402}", "{\"n\": 654, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2673.6, \"learn_time_ms\": 10839.396}", "{\"n\": 655, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2686.1, \"learn_time_ms\": 10831.444}", "{\"n\": 656, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2685.05, \"learn_time_ms\": 10820.29}", "{\"n\": 657, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2685.05, \"learn_time_ms\": 10801.805}", "{\"n\": 658, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2696.12, \"learn_time_ms\": 10804.311}", "{\"n\": 659, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2696.53, \"learn_time_ms\": 10792.813}", "{\"n\": 660, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2713.11, \"learn_time_ms\": 10798.209}", "{\"n\": 661, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2722.89, \"learn_time_ms\": 10799.374}", "{\"n\": 662, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2729.43, \"learn_time_ms\": 10779.927}", "{\"n\": 663, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2730.01, \"learn_time_ms\": 10755.566}", "{\"n\": 664, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2727.3, \"learn_time_ms\": 10725.692}", "{\"n\": 665, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2733.38, \"learn_time_ms\": 10737.369}", "{\"n\": 666, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2737.15, \"learn_time_ms\": 10744.445}", "{\"n\": 667, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2742.98, \"learn_time_ms\": 10767.697}", "{\"n\": 668, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2755.46, \"learn_time_ms\": 10771.834}", "{\"n\": 669, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2755.46, \"learn_time_ms\": 10785.472}", "{\"n\": 670, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2769.68, \"learn_time_ms\": 10778.345}", "{\"n\": 671, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2775.42, \"learn_time_ms\": 10767.585}", "{\"n\": 672, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2779.11, \"learn_time_ms\": 10768.209}", "{\"n\": 673, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2796.46, \"learn_time_ms\": 10775.052}", "{\"n\": 674, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2800.87, \"learn_time_ms\": 10777.37}", "{\"n\": 675, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2803.02, \"learn_time_ms\": 10774.879}", "{\"n\": 676, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2800.26, \"learn_time_ms\": 10776.641}", "{\"n\": 677, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2790.07, \"learn_time_ms\": 10776.25}", "{\"n\": 678, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2788.89, \"learn_time_ms\": 10772.924}", "{\"n\": 679, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2799.58, \"learn_time_ms\": 10771.789}", "{\"n\": 680, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2798.83, \"learn_time_ms\": 10777.619}", "{\"n\": 681, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2797.32, \"learn_time_ms\": 10780.48}", "{\"n\": 682, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2803.39, \"learn_time_ms\": 10806.575}", "{\"n\": 683, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2802.86, \"learn_time_ms\": 10827.661}", "{\"n\": 684, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2797.87, \"learn_time_ms\": 10850.065}", "{\"n\": 685, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2799.06, \"learn_time_ms\": 10858.685}", "{\"n\": 686, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2799.06, \"learn_time_ms\": 10845.261}", "{\"n\": 687, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2800.32, \"learn_time_ms\": 10823.909}", "{\"n\": 688, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2803.66, \"learn_time_ms\": 10824.031}", "{\"n\": 689, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2798.15, \"learn_time_ms\": 10800.105}", "{\"n\": 690, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2798.15, \"learn_time_ms\": 10801.207}", "{\"n\": 691, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2816.07, \"learn_time_ms\": 10807.548}", "{\"n\": 692, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2816.07, \"learn_time_ms\": 10798.321}", "{\"n\": 693, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2825.83, \"learn_time_ms\": 10789.866}", "{\"n\": 694, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2825.83, \"learn_time_ms\": 10783.637}", "{\"n\": 695, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2825.83, \"learn_time_ms\": 10744.173}", "{\"n\": 696, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2820.86, \"learn_time_ms\": 10732.198}", "{\"n\": 697, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2810.63, \"learn_time_ms\": 10728.829}", "{\"n\": 698, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2809.2, \"learn_time_ms\": 10718.939}", "{\"n\": 699, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2812.01, \"learn_time_ms\": 10727.303}", "{\"n\": 700, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2806.06, \"learn_time_ms\": 10713.1}", "{\"n\": 701, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2804.43, \"learn_time_ms\": 10682.344}", "{\"n\": 702, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2810.81, \"learn_time_ms\": 10665.654}", "{\"n\": 703, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2824.36, \"learn_time_ms\": 10667.35}", "{\"n\": 704, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2818.07, \"learn_time_ms\": 10658.808}", "{\"n\": 705, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2818.33, \"learn_time_ms\": 10689.938}", "{\"n\": 706, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2818.08, \"learn_time_ms\": 10716.64}", "{\"n\": 707, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2826.58, \"learn_time_ms\": 10739.861}", "{\"n\": 708, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2822.9, \"learn_time_ms\": 10747.125}", "{\"n\": 709, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2827.09, \"learn_time_ms\": 10760.98}", "{\"n\": 710, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2815.5, \"learn_time_ms\": 10773.197}", "{\"n\": 711, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2812.29, \"learn_time_ms\": 10799.185}", "{\"n\": 712, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2825.15, \"learn_time_ms\": 10820.346}", "{\"n\": 713, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2828.06, \"learn_time_ms\": 10817.575}", "{\"n\": 714, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2831.96, \"learn_time_ms\": 10820.224}", "{\"n\": 715, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2840.07, \"learn_time_ms\": 10802.478}", "{\"n\": 716, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2830.85, \"learn_time_ms\": 10786.0}", "{\"n\": 717, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2833.16, \"learn_time_ms\": 10789.895}", "{\"n\": 718, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2836.97, \"learn_time_ms\": 10787.353}", "{\"n\": 719, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2818.52, \"learn_time_ms\": 10769.17}", "{\"n\": 720, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2804.23, \"learn_time_ms\": 10772.093}", "{\"n\": 721, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2816.02, \"learn_time_ms\": 10778.639}", "{\"n\": 722, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2822.93, \"learn_time_ms\": 10758.206}", "{\"n\": 723, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2816.33, \"learn_time_ms\": 10752.967}", "{\"n\": 724, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2803.31, \"learn_time_ms\": 10736.852}", "{\"n\": 725, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2803.43, \"learn_time_ms\": 10758.244}", "{\"n\": 726, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2808.98, \"learn_time_ms\": 10775.93}", "{\"n\": 727, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2820.21, \"learn_time_ms\": 10772.105}", "{\"n\": 728, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.48, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2828.14, \"learn_time_ms\": 10777.909}", "{\"n\": 729, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2813.21, \"learn_time_ms\": 10779.854}", "{\"n\": 730, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2817.73, \"learn_time_ms\": 10760.042}", "{\"n\": 731, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2824.29, \"learn_time_ms\": 10750.287}", "{\"n\": 732, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2824.29, \"learn_time_ms\": 10768.055}", "{\"n\": 733, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2822.24, \"learn_time_ms\": 10764.709}", "{\"n\": 734, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2822.62, \"learn_time_ms\": 10767.455}", "{\"n\": 735, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2815.39, \"learn_time_ms\": 10756.89}", "{\"n\": 736, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2818.59, \"learn_time_ms\": 10741.466}", "{\"n\": 737, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2809.53, \"learn_time_ms\": 10735.515}", "{\"n\": 738, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2811.18, \"learn_time_ms\": 10737.386}", "{\"n\": 739, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2811.06, \"learn_time_ms\": 10751.303}", "{\"n\": 740, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2813.87, \"learn_time_ms\": 10773.617}", "{\"n\": 741, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2828.56, \"learn_time_ms\": 10783.387}", "{\"n\": 742, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2828.56, \"learn_time_ms\": 10777.593}", "{\"n\": 743, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2823.21, \"learn_time_ms\": 10783.474}", "{\"n\": 744, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2840.01, \"learn_time_ms\": 10807.318}", "{\"n\": 745, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.5, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2844.43, \"learn_time_ms\": 10812.14}", "{\"n\": 746, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.48, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2846.47, \"learn_time_ms\": 10833.314}", "{\"n\": 747, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.48, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2846.47, \"learn_time_ms\": 10838.213}", "{\"n\": 748, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2854.73, \"learn_time_ms\": 10802.484}", "{\"n\": 749, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2854.73, \"learn_time_ms\": 10776.992}", "{\"n\": 750, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2871.63, \"learn_time_ms\": 10751.628}", "{\"n\": 751, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2869.0, \"learn_time_ms\": 10728.297}", "{\"n\": 752, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2863.51, \"learn_time_ms\": 10717.562}", "{\"n\": 753, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2843.58, \"learn_time_ms\": 10709.968}", "{\"n\": 754, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2856.63, \"learn_time_ms\": 10703.928}", "{\"n\": 755, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2864.8, \"learn_time_ms\": 10711.908}", "{\"n\": 756, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2863.83, \"learn_time_ms\": 10686.726}", "{\"n\": 757, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2847.49, \"learn_time_ms\": 10659.667}", "{\"n\": 758, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2847.01, \"learn_time_ms\": 10673.62}", "{\"n\": 759, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2850.06, \"learn_time_ms\": 10679.865}", "{\"n\": 760, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2844.97, \"learn_time_ms\": 10682.328}", "{\"n\": 761, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2851.93, \"learn_time_ms\": 10689.969}", "{\"n\": 762, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2843.63, \"learn_time_ms\": 10706.835}", "{\"n\": 763, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2845.57, \"learn_time_ms\": 10719.379}", "{\"n\": 764, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2851.71, \"learn_time_ms\": 10715.279}", "{\"n\": 765, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2856.47, \"learn_time_ms\": 10699.18}", "{\"n\": 766, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2848.62, \"learn_time_ms\": 10716.58}", "{\"n\": 767, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2849.28, \"learn_time_ms\": 10741.463}", "{\"n\": 768, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2847.9, \"learn_time_ms\": 10755.613}", "{\"n\": 769, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2846.83, \"learn_time_ms\": 10773.096}", "{\"n\": 770, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2854.16, \"learn_time_ms\": 10791.555}", "{\"n\": 771, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2831.78, \"learn_time_ms\": 10806.207}", "{\"n\": 772, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2838.68, \"learn_time_ms\": 10806.827}", "{\"n\": 773, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2838.68, \"learn_time_ms\": 10806.81}", "{\"n\": 774, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.03, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2830.28, \"learn_time_ms\": 10817.648}", "{\"n\": 775, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.05, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2838.1, \"learn_time_ms\": 10824.28}", "{\"n\": 776, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2838.37, \"learn_time_ms\": 10799.992}", "{\"n\": 777, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.06, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2839.48, \"learn_time_ms\": 10778.852}", "{\"n\": 778, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2863.51, \"learn_time_ms\": 10762.111}", "{\"n\": 779, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2863.51, \"learn_time_ms\": 10754.32}", "{\"n\": 780, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2862.68, \"learn_time_ms\": 10755.228}", "{\"n\": 781, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2887.31, \"learn_time_ms\": 10754.909}", "{\"n\": 782, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2891.15, \"learn_time_ms\": 10760.053}", "{\"n\": 783, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2909.39, \"learn_time_ms\": 10758.821}", "{\"n\": 784, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2909.39, \"learn_time_ms\": 10758.019}", "{\"n\": 785, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2919.32, \"learn_time_ms\": 10756.006}", "{\"n\": 786, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2917.84, \"learn_time_ms\": 10765.752}", "{\"n\": 787, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2914.96, \"learn_time_ms\": 10790.284}", "{\"n\": 788, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2906.34, \"learn_time_ms\": 10811.148}", "{\"n\": 789, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2912.94, \"learn_time_ms\": 10812.211}", "{\"n\": 790, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2922.34, \"learn_time_ms\": 10810.582}", "{\"n\": 791, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2929.88, \"learn_time_ms\": 10806.963}", "{\"n\": 792, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2921.33, \"learn_time_ms\": 10781.235}", "{\"n\": 793, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2921.33, \"learn_time_ms\": 10762.194}", "{\"n\": 794, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2914.79, \"learn_time_ms\": 10739.979}", "{\"n\": 795, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2923.16, \"learn_time_ms\": 10734.852}", "{\"n\": 796, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2933.5, \"learn_time_ms\": 10732.865}", "{\"n\": 797, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2926.69, \"learn_time_ms\": 10723.148}", "{\"n\": 798, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2924.3, \"learn_time_ms\": 10722.905}", "{\"n\": 799, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2924.49, \"learn_time_ms\": 10715.874}", "{\"n\": 800, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2910.36, \"learn_time_ms\": 10696.845}", "{\"n\": 801, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2897.52, \"learn_time_ms\": 10700.639}", "{\"n\": 802, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2897.11, \"learn_time_ms\": 10721.457}", "{\"n\": 803, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2895.03, \"learn_time_ms\": 10743.459}", "{\"n\": 804, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2904.39, \"learn_time_ms\": 10750.494}", "{\"n\": 805, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2897.9, \"learn_time_ms\": 10761.817}", "{\"n\": 806, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2897.9, \"learn_time_ms\": 10775.893}", "{\"n\": 807, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2909.66, \"learn_time_ms\": 10764.664}", "{\"n\": 808, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2905.84, \"learn_time_ms\": 10742.901}", "{\"n\": 809, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2888.64, \"learn_time_ms\": 10745.947}", "{\"n\": 810, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2897.17, \"learn_time_ms\": 10747.543}", "{\"n\": 811, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2896.22, \"learn_time_ms\": 10729.638}", "{\"n\": 812, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2896.22, \"learn_time_ms\": 10708.751}", "{\"n\": 813, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2902.21, \"learn_time_ms\": 10684.529}", "{\"n\": 814, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2890.2, \"learn_time_ms\": 10672.039}", "{\"n\": 815, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2903.05, \"learn_time_ms\": 10651.09}", "{\"n\": 816, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2903.05, \"learn_time_ms\": 10632.098}", "{\"n\": 817, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2913.97, \"learn_time_ms\": 10636.416}", "{\"n\": 818, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2922.09, \"learn_time_ms\": 10641.923}", "{\"n\": 819, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2927.27, \"learn_time_ms\": 10626.572}", "{\"n\": 820, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2920.69, \"learn_time_ms\": 10623.565}", "{\"n\": 821, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2934.96, \"learn_time_ms\": 10624.807}", "{\"n\": 822, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2921.11, \"learn_time_ms\": 10642.878}", "{\"n\": 823, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2933.48, \"learn_time_ms\": 10651.897}", "{\"n\": 824, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2935.63, \"learn_time_ms\": 10679.92}", "{\"n\": 825, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2938.03, \"learn_time_ms\": 10703.33}", "{\"n\": 826, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2939.55, \"learn_time_ms\": 10716.155}", "{\"n\": 827, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2947.91, \"learn_time_ms\": 10731.707}", "{\"n\": 828, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2933.11, \"learn_time_ms\": 10751.726}", "{\"n\": 829, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2948.2, \"learn_time_ms\": 10780.743}", "{\"n\": 830, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2948.33, \"learn_time_ms\": 10798.307}", "{\"n\": 831, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2956.02, \"learn_time_ms\": 10804.351}", "{\"n\": 832, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2950.89, \"learn_time_ms\": 10793.543}", "{\"n\": 833, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2947.01, \"learn_time_ms\": 10791.361}", "{\"n\": 834, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2935.33, \"learn_time_ms\": 10784.938}", "{\"n\": 835, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2936.06, \"learn_time_ms\": 10766.878}", "{\"n\": 836, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2937.25, \"learn_time_ms\": 10769.92}", "{\"n\": 837, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2941.28, \"learn_time_ms\": 10747.997}", "{\"n\": 838, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2918.74, \"learn_time_ms\": 10724.627}", "{\"n\": 839, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2918.74, \"learn_time_ms\": 10705.782}", "{\"n\": 840, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2923.64, \"learn_time_ms\": 10691.13}", "{\"n\": 841, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2919.01, \"learn_time_ms\": 10687.251}", "{\"n\": 842, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2901.85, \"learn_time_ms\": 10690.478}", "{\"n\": 843, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2892.97, \"learn_time_ms\": 10696.706}", "{\"n\": 844, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2892.97, \"learn_time_ms\": 10711.699}", "{\"n\": 845, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2896.36, \"learn_time_ms\": 10726.313}", "{\"n\": 846, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2903.15, \"learn_time_ms\": 10731.828}", "{\"n\": 847, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2902.21, \"learn_time_ms\": 10758.914}", "{\"n\": 848, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2918.09, \"learn_time_ms\": 10773.636}", "{\"n\": 849, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2914.13, \"learn_time_ms\": 10778.426}", "{\"n\": 850, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2913.03, \"learn_time_ms\": 10783.269}", "{\"n\": 851, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2903.25, \"learn_time_ms\": 10784.138}", "{\"n\": 852, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2910.09, \"learn_time_ms\": 10772.325}", "{\"n\": 853, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2901.96, \"learn_time_ms\": 10762.44}", "{\"n\": 854, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2913.74, \"learn_time_ms\": 10734.697}", "{\"n\": 855, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2917.72, \"learn_time_ms\": 10739.934}", "{\"n\": 856, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2908.21, \"learn_time_ms\": 10746.857}", "{\"n\": 857, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2908.21, \"learn_time_ms\": 10722.739}", "{\"n\": 858, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2908.9, \"learn_time_ms\": 10709.441}", "{\"n\": 859, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2909.6, \"learn_time_ms\": 10713.897}", "{\"n\": 860, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2909.6, \"learn_time_ms\": 10717.462}", "{\"n\": 861, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2920.45, \"learn_time_ms\": 10716.414}", "{\"n\": 862, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2917.63, \"learn_time_ms\": 10719.23}", "{\"n\": 863, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2930.13, \"learn_time_ms\": 10722.059}", "{\"n\": 864, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2944.88, \"learn_time_ms\": 10736.755}", "{\"n\": 865, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2940.05, \"learn_time_ms\": 10730.965}", "{\"n\": 866, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2940.05, \"learn_time_ms\": 10727.539}", "{\"n\": 867, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2940.05, \"learn_time_ms\": 10731.579}", "{\"n\": 868, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2934.36, \"learn_time_ms\": 10736.149}", "{\"n\": 869, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2937.88, \"learn_time_ms\": 10723.705}", "{\"n\": 870, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2938.18, \"learn_time_ms\": 10737.59}", "{\"n\": 871, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2938.18, \"learn_time_ms\": 10754.658}", "{\"n\": 872, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2938.18, \"learn_time_ms\": 10780.559}", "{\"n\": 873, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.42, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2945.25, \"learn_time_ms\": 10790.917}", "{\"n\": 874, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.37, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2955.84, \"learn_time_ms\": 10797.801}", "{\"n\": 875, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2967.85, \"learn_time_ms\": 10782.236}", "{\"n\": 876, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2967.85, \"learn_time_ms\": 10764.693}", "{\"n\": 877, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2967.85, \"learn_time_ms\": 10768.31}", "{\"n\": 878, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2964.07, \"learn_time_ms\": 10770.59}", "{\"n\": 879, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2961.99, \"learn_time_ms\": 10771.128}", "{\"n\": 880, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2961.99, \"learn_time_ms\": 10746.268}", "{\"n\": 881, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.2, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2965.3, \"learn_time_ms\": 10725.589}", "{\"n\": 882, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2955.41, \"learn_time_ms\": 10703.764}", "{\"n\": 883, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2955.41, \"learn_time_ms\": 10710.632}", "{\"n\": 884, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2959.08, \"learn_time_ms\": 10707.638}", "{\"n\": 885, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2959.08, \"learn_time_ms\": 10725.111}", "{\"n\": 886, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2984.75, \"learn_time_ms\": 10721.448}", "{\"n\": 887, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2984.75, \"learn_time_ms\": 10723.918}", "{\"n\": 888, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2980.17, \"learn_time_ms\": 10718.394}", "{\"n\": 889, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2973.19, \"learn_time_ms\": 10712.715}", "{\"n\": 890, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2980.04, \"learn_time_ms\": 10704.982}", "{\"n\": 891, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2995.86, \"learn_time_ms\": 10697.046}", "{\"n\": 892, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2992.75, \"learn_time_ms\": 10698.174}", "{\"n\": 893, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2992.75, \"learn_time_ms\": 10662.788}", "{\"n\": 894, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2998.38, \"learn_time_ms\": 10642.019}", "{\"n\": 895, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3001.92, \"learn_time_ms\": 10625.856}", "{\"n\": 896, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3007.53, \"learn_time_ms\": 10629.219}", "{\"n\": 897, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3035.05, \"learn_time_ms\": 10624.737}", "{\"n\": 898, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3052.45, \"learn_time_ms\": 10656.703}", "{\"n\": 899, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3053.48, \"learn_time_ms\": 10675.718}", "{\"n\": 900, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3072.59, \"learn_time_ms\": 10699.803}", "{\"n\": 901, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3072.59, \"learn_time_ms\": 10709.278}", "{\"n\": 902, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3070.15, \"learn_time_ms\": 10720.389}", "{\"n\": 903, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3068.74, \"learn_time_ms\": 10755.348}", "{\"n\": 904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3087.59, \"learn_time_ms\": 10779.367}", "{\"n\": 905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3093.53, \"learn_time_ms\": 10782.912}", "{\"n\": 906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3093.53, \"learn_time_ms\": 10777.822}", "{\"n\": 907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3094.34, \"learn_time_ms\": 10771.739}", "{\"n\": 908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3101.29, \"learn_time_ms\": 10738.466}", "{\"n\": 909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3103.39, \"learn_time_ms\": 10725.804}", "{\"n\": 910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3094.54, \"learn_time_ms\": 10698.427}", "{\"n\": 911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3093.66, \"learn_time_ms\": 10700.94}", "{\"n\": 912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3093.66, \"learn_time_ms\": 10686.967}", "{\"n\": 913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3091.63, \"learn_time_ms\": 10664.381}", "{\"n\": 914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3090.95, \"learn_time_ms\": 10644.634}", "{\"n\": 915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3090.95, \"learn_time_ms\": 10641.765}", "{\"n\": 916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3094.35, \"learn_time_ms\": 10653.206}", "{\"n\": 917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3094.35, \"learn_time_ms\": 10655.369}", "{\"n\": 918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3098.99, \"learn_time_ms\": 10666.11}", "{\"n\": 919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3094.54, \"learn_time_ms\": 10690.441}", "{\"n\": 920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3097.62, \"learn_time_ms\": 10723.167}", "{\"n\": 921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.16, \"learn_time_ms\": 10733.774}", "{\"n\": 922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.16, \"learn_time_ms\": 10747.84}", "{\"n\": 923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.16, \"learn_time_ms\": 10768.085}", "{\"n\": 924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3132.39, \"learn_time_ms\": 10788.074}", "{\"n\": 925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3143.24, \"learn_time_ms\": 10797.309}", "{\"n\": 926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3143.68, \"learn_time_ms\": 10814.851}", "{\"n\": 927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.16, \"learn_time_ms\": 10844.369}", "{\"n\": 928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.74, \"learn_time_ms\": 10854.884}", "{\"n\": 929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.11, \"learn_time_ms\": 10842.083}", "{\"n\": 930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.54, \"learn_time_ms\": 10846.907}", "{\"n\": 931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.73, \"learn_time_ms\": 10849.483}", "{\"n\": 932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.8, \"learn_time_ms\": 10841.244}", "{\"n\": 933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.07, \"learn_time_ms\": 10837.575}", "{\"n\": 934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.62, \"learn_time_ms\": 10839.593}", "{\"n\": 935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.73, \"learn_time_ms\": 10847.829}", "{\"n\": 936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.77, \"learn_time_ms\": 10836.494}", "{\"n\": 937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.43, \"learn_time_ms\": 10813.647}", "{\"n\": 938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.75, \"learn_time_ms\": 10817.839}", "{\"n\": 939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.39, \"learn_time_ms\": 10824.485}", "{\"n\": 940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.86, \"learn_time_ms\": 10813.944}", "{\"n\": 941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.29, \"learn_time_ms\": 10803.097}", "{\"n\": 942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.64, \"learn_time_ms\": 10799.416}", "{\"n\": 943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.18, \"learn_time_ms\": 10784.74}", "{\"n\": 944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.19, \"learn_time_ms\": 10765.019}", "{\"n\": 945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.62, \"learn_time_ms\": 10760.216}", "{\"n\": 946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.62, \"learn_time_ms\": 10755.68}", "{\"n\": 947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.62, \"learn_time_ms\": 10766.115}", "{\"n\": 948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.62, \"learn_time_ms\": 10753.073}", "{\"n\": 949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.0, \"learn_time_ms\": 10743.919}", "{\"n\": 950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.13, \"learn_time_ms\": 10731.855}", "{\"n\": 951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.93, \"learn_time_ms\": 10744.173}", "{\"n\": 952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.72, \"learn_time_ms\": 10757.283}", "{\"n\": 953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.59, \"learn_time_ms\": 10767.923}", "{\"n\": 954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.41, \"learn_time_ms\": 10787.253}", "{\"n\": 955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.36, \"learn_time_ms\": 10786.959}", "{\"n\": 956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.78, \"learn_time_ms\": 10797.007}", "{\"n\": 957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.86, \"learn_time_ms\": 10799.112}", "{\"n\": 958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.24, \"learn_time_ms\": 10809.841}", "{\"n\": 959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.12, \"learn_time_ms\": 10827.021}", "{\"n\": 960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.23, \"learn_time_ms\": 10839.755}", "{\"n\": 961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.48, \"learn_time_ms\": 10842.439}", "{\"n\": 962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.48, \"learn_time_ms\": 10850.278}", "{\"n\": 963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.07, \"learn_time_ms\": 10868.038}", "{\"n\": 964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.26, \"learn_time_ms\": 10860.12}", "{\"n\": 965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.53, \"learn_time_ms\": 10866.845}", "{\"n\": 966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.53, \"learn_time_ms\": 10863.651}", "{\"n\": 967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.48, \"learn_time_ms\": 10859.11}", "{\"n\": 968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -12.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.23, \"learn_time_ms\": 10852.557}", "{\"n\": 969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.88, \"learn_time_ms\": 10845.999}", "{\"n\": 970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3217.65, \"learn_time_ms\": 10840.667}", "{\"n\": 971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3217.65, \"learn_time_ms\": 10823.403}", "{\"n\": 972, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3223.46, \"learn_time_ms\": 10818.28}", "{\"n\": 973, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3227.6, \"learn_time_ms\": 10797.536}", "{\"n\": 974, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3225.74, \"learn_time_ms\": 10787.524}", "{\"n\": 975, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3197.16, \"learn_time_ms\": 10773.454}", "{\"n\": 976, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3212.97, \"learn_time_ms\": 10766.953}", "{\"n\": 977, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3212.97, \"learn_time_ms\": 10753.398}", "{\"n\": 978, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3202.24, \"learn_time_ms\": 10725.442}", "{\"n\": 979, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3202.24, \"learn_time_ms\": 10706.448}", "{\"n\": 980, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3206.6, \"learn_time_ms\": 10698.324}", "{\"n\": 981, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.28, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3214.39, \"learn_time_ms\": 10700.99}", "{\"n\": 982, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3212.63, \"learn_time_ms\": 10681.828}", "{\"n\": 983, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3220.32, \"learn_time_ms\": 10678.587}", "{\"n\": 984, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3222.38, \"learn_time_ms\": 10690.927}", "{\"n\": 985, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3219.49, \"learn_time_ms\": 10700.495}", "{\"n\": 986, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3219.49, \"learn_time_ms\": 10710.302}", "{\"n\": 987, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3212.71, \"learn_time_ms\": 10718.02}", "{\"n\": 988, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3218.85, \"learn_time_ms\": 10741.261}", "{\"n\": 989, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3219.91, \"learn_time_ms\": 10759.134}", "{\"n\": 990, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3219.91, \"learn_time_ms\": 10777.867}", "{\"n\": 991, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3227.3, \"learn_time_ms\": 10792.684}", "{\"n\": 992, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3245.3, \"learn_time_ms\": 10807.166}", "{\"n\": 993, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3228.26, \"learn_time_ms\": 10833.002}", "{\"n\": 994, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3228.26, \"learn_time_ms\": 10834.823}", "{\"n\": 995, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3228.26, \"learn_time_ms\": 10835.39}", "{\"n\": 996, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3216.14, \"learn_time_ms\": 10828.67}", "{\"n\": 997, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3229.67, \"learn_time_ms\": 10820.763}", "{\"n\": 998, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3236.8, \"learn_time_ms\": 10814.413}", "{\"n\": 999, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3229.87, \"learn_time_ms\": 10795.233}", "{\"n\": 1000, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3229.87, \"learn_time_ms\": 10775.563}"]