["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 645161.862, \"total_train_time_s\": 652.0197882652283}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 644789.893, \"total_train_time_s\": 648.5446743965149}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 644426.591, \"total_train_time_s\": 647.7440521717072}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1050.5, \"learn_time_ms\": 644476.889, \"total_train_time_s\": 648.7758159637451}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1050.5, \"learn_time_ms\": 644353.062, \"total_train_time_s\": 647.9203104972839}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1075.75, \"learn_time_ms\": 644247.46, \"total_train_time_s\": 647.8390324115753}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1075.75, \"learn_time_ms\": 644139.741, \"total_train_time_s\": 647.5858554840088}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.608695652173914, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1105.9130434782608, \"learn_time_ms\": 644123.374, \"total_train_time_s\": 648.1019566059113}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.653846153846153, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1108.0, \"learn_time_ms\": 644091.412, \"total_train_time_s\": 647.805960893631}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.70967741935484, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1116.483870967742, \"learn_time_ms\": 644097.218, \"total_train_time_s\": 648.1319439411163}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.714285714285715, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1132.9142857142858, \"learn_time_ms\": 643965.053, \"total_train_time_s\": 647.8592419624329}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1130.325, \"learn_time_ms\": 643963.605, \"total_train_time_s\": 648.4151165485382}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.772727272727273, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1126.8181818181818, \"learn_time_ms\": 643969.148, \"total_train_time_s\": 647.7983496189117}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1137.1875, \"learn_time_ms\": 643887.336, \"total_train_time_s\": 647.819331407547}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76923076923077, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1136.5576923076924, \"learn_time_ms\": 643901.949, \"total_train_time_s\": 647.9996290206909}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.785714285714285, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1141.732142857143, \"learn_time_ms\": 643864.849, \"total_train_time_s\": 647.3709402084351}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.796610169491526, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1142.4915254237287, \"learn_time_ms\": 643921.713, \"total_train_time_s\": 648.1186785697937}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78125, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1151.484375, \"learn_time_ms\": 643899.408, \"total_train_time_s\": 647.7693626880646}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1152.2058823529412, \"learn_time_ms\": 643931.844, \"total_train_time_s\": 648.1586492061615}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73611111111111, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.236111111111, \"learn_time_ms\": 643881.116, \"total_train_time_s\": 647.719300031662}"]