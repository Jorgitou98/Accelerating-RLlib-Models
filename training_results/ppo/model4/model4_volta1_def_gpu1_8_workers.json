["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 16944.18, \"total_train_time_s\": 26.83705973625183}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 16657.921, \"total_train_time_s\": 23.46372652053833}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 16560.779, \"total_train_time_s\": 23.425005435943604}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1013.0, \"learn_time_ms\": 16511.832, \"total_train_time_s\": 23.38061022758484}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1011.5, \"learn_time_ms\": 16480.044, \"total_train_time_s\": 23.43916964530945}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1015.3125, \"learn_time_ms\": 16458.359, \"total_train_time_s\": 23.43853759765625}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.4166666666666, \"learn_time_ms\": 16435.303, \"total_train_time_s\": 23.358376264572144}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.4166666666666, \"learn_time_ms\": 16421.735, \"total_train_time_s\": 23.436500072479248}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.03125, \"learn_time_ms\": 16412.567, \"total_train_time_s\": 23.435057878494263}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.2857142857143, \"learn_time_ms\": 16402.643, \"total_train_time_s\": 23.40188765525818}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.125, \"learn_time_ms\": 16331.954, \"total_train_time_s\": 23.29654622077942}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2708333333334, \"learn_time_ms\": 16326.609, \"total_train_time_s\": 23.409501791000366}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2708333333334, \"learn_time_ms\": 16319.444, \"total_train_time_s\": 23.354572296142578}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5714285714286, \"learn_time_ms\": 16311.931, \"total_train_time_s\": 23.400066614151}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4745762711865, \"learn_time_ms\": 16281.427, \"total_train_time_s\": 23.174569845199585}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.40625, \"learn_time_ms\": 16232.519, \"total_train_time_s\": 22.877394914627075}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9166666666666, \"learn_time_ms\": 16150.882, \"total_train_time_s\": 22.54658269882202}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9166666666666, \"learn_time_ms\": 16141.012, \"total_train_time_s\": 23.306276321411133}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.375, \"learn_time_ms\": 16114.199, \"total_train_time_s\": 23.125784397125244}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4512195121952, \"learn_time_ms\": 16111.286, \"total_train_time_s\": 23.3400616645813}"]