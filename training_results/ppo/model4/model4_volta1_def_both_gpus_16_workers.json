["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 45258.66, \"total_train_time_s\": 55.920762062072754}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 32773.1, \"total_train_time_s\": 25.812516927719116}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 28618.113, \"total_train_time_s\": 25.966553688049316}", "{\"n\": 4, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 26535.478, \"total_train_time_s\": 25.8875789642334}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1009.7142857142857, \"learn_time_ms\": 25084.993, \"total_train_time_s\": 25.002541303634644}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.8125, \"learn_time_ms\": 24220.877, \"total_train_time_s\": 25.528836011886597}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.8125, \"learn_time_ms\": 23654.619, \"total_train_time_s\": 25.79177188873291}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96551724137931, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.5172413793102, \"learn_time_ms\": 23230.997, \"total_train_time_s\": 25.832074880599976}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1036.40625, \"learn_time_ms\": 22753.624, \"total_train_time_s\": 24.641023635864258}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97142857142857, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.6571428571428, \"learn_time_ms\": 22414.146, \"total_train_time_s\": 24.990375518798828}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.953488372093023, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.0697674418604, \"learn_time_ms\": 19910.41, \"total_train_time_s\": 25.829814195632935}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1058.125, \"learn_time_ms\": 19736.382, \"total_train_time_s\": 24.08106303215027}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1057.98, \"learn_time_ms\": 19702.732, \"total_train_time_s\": 25.532102823257446}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94736842105263, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1060.0526315789473, \"learn_time_ms\": 19697.091, \"total_train_time_s\": 25.833911180496216}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88888888888889, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1081.6349206349207, \"learn_time_ms\": 19801.149, \"total_train_time_s\": 25.91482901573181}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.863636363636363, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1090.2424242424242, \"learn_time_ms\": 19831.36, \"total_train_time_s\": 25.89615535736084}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.797101449275363, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1105.0869565217392, \"learn_time_ms\": 19828.68, \"total_train_time_s\": 25.798667669296265}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.753246753246753, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1123.1038961038962, \"learn_time_ms\": 19827.394, \"total_train_time_s\": 25.80318331718445}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.725, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1135.3625, \"learn_time_ms\": 19748.187, \"total_train_time_s\": 23.700050354003906}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.728395061728396, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1133.8271604938273, \"learn_time_ms\": 19841.492, \"total_train_time_s\": 25.918822288513184}"]