["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29548.475, \"total_train_time_s\": 37.85724329948425}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 19234.332, \"total_train_time_s\": 14.474233150482178}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15815.443, \"total_train_time_s\": 14.562686681747437}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.75, \"learn_time_ms\": 14114.345, \"total_train_time_s\": 14.570362091064453}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.9, \"learn_time_ms\": 13093.069, \"total_train_time_s\": 14.587110757827759}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.8125, \"learn_time_ms\": 12361.849, \"total_train_time_s\": 14.27537202835083}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.2083333333334, \"learn_time_ms\": 11882.457, \"total_train_time_s\": 14.572555780410767}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.2083333333334, \"learn_time_ms\": 11518.927, \"total_train_time_s\": 14.51464295387268}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.84375, \"learn_time_ms\": 11209.701, \"total_train_time_s\": 14.321967124938965}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.4242424242424, \"learn_time_ms\": 10955.866, \"total_train_time_s\": 14.222641944885254}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.5, \"learn_time_ms\": 8872.282, \"total_train_time_s\": 14.286771535873413}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.2291666666666, \"learn_time_ms\": 8866.513, \"total_train_time_s\": 14.466335773468018}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.2291666666666, \"learn_time_ms\": 8869.323, \"total_train_time_s\": 14.561983585357666}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.4821428571429, \"learn_time_ms\": 8868.916, \"total_train_time_s\": 14.59583306312561}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.4137931034483, \"learn_time_ms\": 8869.019, \"total_train_time_s\": 14.576119184494019}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.203125, \"learn_time_ms\": 8898.276, \"total_train_time_s\": 14.603971719741821}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.2361111111111, \"learn_time_ms\": 8899.199, \"total_train_time_s\": 14.571119785308838}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.2361111111111, \"learn_time_ms\": 8887.531, \"total_train_time_s\": 14.404654026031494}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.4875, \"learn_time_ms\": 8865.49, \"total_train_time_s\": 14.080945491790771}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.320987654321, \"learn_time_ms\": 8857.849, \"total_train_time_s\": 14.158716917037964}"]["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 29032.992, \"total_train_time_s\": 37.32208704948425}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 19020.267, \"total_train_time_s\": 14.412728786468506}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15671.285, \"total_train_time_s\": 14.342078924179077}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.125, \"learn_time_ms\": 14014.526, \"total_train_time_s\": 14.512994527816772}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1, \"learn_time_ms\": 13012.913, \"total_train_time_s\": 14.412262439727783}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0625, \"learn_time_ms\": 12347.855, \"total_train_time_s\": 14.442762613296509}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.090909090909, \"learn_time_ms\": 11831.658, \"total_train_time_s\": 14.14677619934082}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.1666666666667, \"learn_time_ms\": 11471.082, \"total_train_time_s\": 14.3412344455719}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1032.0, \"learn_time_ms\": 11172.448, \"total_train_time_s\": 14.202385425567627}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1062.78125, \"learn_time_ms\": 10959.621, \"total_train_time_s\": 14.46549940109253}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.945945945945947, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1082.2972972972973, \"learn_time_ms\": 8959.986, \"total_train_time_s\": 14.48780369758606}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.925, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1093.1, \"learn_time_ms\": 8961.03, \"total_train_time_s\": 14.443123817443848}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.933333333333334, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1095.4, \"learn_time_ms\": 8966.408, \"total_train_time_s\": 14.482707500457764}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93617021276596, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1100.7659574468084, \"learn_time_ms\": 8964.483, \"total_train_time_s\": 14.42586374282837}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93877551020408, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1106.0204081632653, \"learn_time_ms\": 8969.703, \"total_train_time_s\": 14.467060804367065}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85185185185185, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1129.351851851852, \"learn_time_ms\": 8968.126, \"total_train_time_s\": 14.449589490890503}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.854545454545455, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1131.6363636363637, \"learn_time_ms\": 8994.453, \"total_train_time_s\": 14.407572746276855}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78688524590164, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1149.5737704918033, \"learn_time_ms\": 9001.897, \"total_train_time_s\": 14.433053255081177}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.741935483870968, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1173.2096774193549, \"learn_time_ms\": 9028.953, \"total_train_time_s\": 14.460723161697388}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.651515151515152, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1205.560606060606, \"learn_time_ms\": 9025.073, \"total_train_time_s\": 14.412853002548218}"]