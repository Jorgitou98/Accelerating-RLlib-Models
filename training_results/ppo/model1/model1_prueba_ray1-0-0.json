["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 31325.937}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 19830.387}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15979.746}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1062.25, \"learn_time_ms\": 14060.009}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1062.25, \"learn_time_ms\": 12919.193}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1083.1875, \"learn_time_ms\": 12154.379}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58823529411765, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1081.764705882353, \"learn_time_ms\": 11614.67}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.541666666666668, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1088.625, \"learn_time_ms\": 11213.965}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.551724137931036, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1087.0689655172414, \"learn_time_ms\": 10904.098}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53125, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1087.0, \"learn_time_ms\": 10648.075}"]