["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9303.516}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9109.415}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9008.252}", "{\"n\": 4, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 8975.256}", "{\"n\": 5, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 8965.365}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.454545454545453, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1174.1818181818182, \"learn_time_ms\": 8926.335}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3125, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1216.0625, \"learn_time_ms\": 8914.878}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3125, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1216.0625, \"learn_time_ms\": 8903.667}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1204.76, \"learn_time_ms\": 8907.73}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4375, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1200.59375, \"learn_time_ms\": 8913.96}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4375, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1200.59375, \"learn_time_ms\": 8880.575}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.511627906976745, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1188.4418604651162, \"learn_time_ms\": 8913.207}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.479166666666668, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1200.75, \"learn_time_ms\": 8943.626}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.489795918367346, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1202.734693877551, \"learn_time_ms\": 8970.671}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.50877192982456, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1198.438596491228, \"learn_time_ms\": 8997.426}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.515625, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1196.625, \"learn_time_ms\": 9038.124}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.515151515151516, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1192.9848484848485, \"learn_time_ms\": 9057.005}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.493150684931507, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1194.3424657534247, \"learn_time_ms\": 9077.232}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.417721518987342, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1209.1518987341772, \"learn_time_ms\": 9098.605}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.426829268292682, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1207.3658536585365, \"learn_time_ms\": 9125.812}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46067415730337, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1204.9887640449438, \"learn_time_ms\": 9144.739}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.442105263157895, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1207.4947368421053, \"learn_time_ms\": 9133.646}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.443298969072163, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1208.5670103092784, \"learn_time_ms\": 9138.551}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1212.29, \"learn_time_ms\": 9154.178}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1216.72, \"learn_time_ms\": 9160.224}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1213.66, \"learn_time_ms\": 9172.826}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1210.0, \"learn_time_ms\": 9189.527}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1215.55, \"learn_time_ms\": 9210.746}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1209.96, \"learn_time_ms\": 9220.261}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1211.48, \"learn_time_ms\": 9228.982}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1205.54, \"learn_time_ms\": 9236.275}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1199.17, \"learn_time_ms\": 9247.685}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1196.13, \"learn_time_ms\": 9265.011}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1197.7, \"learn_time_ms\": 9261.291}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1196.91, \"learn_time_ms\": 9256.731}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1191.2, \"learn_time_ms\": 9245.467}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1178.03, \"learn_time_ms\": 9252.269}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1180.04, \"learn_time_ms\": 9247.827}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1174.78, \"learn_time_ms\": 9250.518}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1171.29, \"learn_time_ms\": 9249.066}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1166.58, \"learn_time_ms\": 9255.2}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1159.84, \"learn_time_ms\": 9244.351}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1153.45, \"learn_time_ms\": 9221.476}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1146.49, \"learn_time_ms\": 9211.356}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1142.63, \"learn_time_ms\": 9204.637}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1146.01, \"learn_time_ms\": 9218.314}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1146.66, \"learn_time_ms\": 9210.018}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1145.78, \"learn_time_ms\": 9220.756}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1144.45, \"learn_time_ms\": 9205.794}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1153.83, \"learn_time_ms\": 9187.464}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.05, \"learn_time_ms\": 9183.637}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1162.63, \"learn_time_ms\": 9185.351}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1172.03, \"learn_time_ms\": 9190.624}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1179.09, \"learn_time_ms\": 9194.55}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1182.04, \"learn_time_ms\": 9202.791}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1184.22, \"learn_time_ms\": 9188.411}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1180.87, \"learn_time_ms\": 9193.563}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1181.09, \"learn_time_ms\": 9183.869}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1179.71, \"learn_time_ms\": 9185.949}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1188.85, \"learn_time_ms\": 9181.893}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1189.71, \"learn_time_ms\": 9177.213}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1201.47, \"learn_time_ms\": 9181.456}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1204.56, \"learn_time_ms\": 9187.872}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1207.67, \"learn_time_ms\": 9179.787}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1204.0, \"learn_time_ms\": 9164.582}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1203.38, \"learn_time_ms\": 9162.377}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1204.81, \"learn_time_ms\": 9149.781}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1193.19, \"learn_time_ms\": 9151.945}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1192.93, \"learn_time_ms\": 9161.655}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1184.45, \"learn_time_ms\": 9150.68}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1175.64, \"learn_time_ms\": 9146.313}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1170.05, \"learn_time_ms\": 9148.771}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1165.51, \"learn_time_ms\": 9145.583}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1158.22, \"learn_time_ms\": 9138.008}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1162.67, \"learn_time_ms\": 9144.902}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1165.61, \"learn_time_ms\": 9149.996}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1192.56, \"learn_time_ms\": 9137.94}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1192.95, \"learn_time_ms\": 9145.964}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1184.73, \"learn_time_ms\": 9126.965}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1178.97, \"learn_time_ms\": 9148.382}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1178.05, \"learn_time_ms\": 9160.197}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1176.26, \"learn_time_ms\": 9169.191}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1181.8, \"learn_time_ms\": 9181.792}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1187.69, \"learn_time_ms\": 9218.762}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1187.21, \"learn_time_ms\": 9232.427}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1189.56, \"learn_time_ms\": 9241.342}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1189.88, \"learn_time_ms\": 9269.334}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1198.62, \"learn_time_ms\": 9265.119}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1207.6, \"learn_time_ms\": 9273.973}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1217.38, \"learn_time_ms\": 9275.063}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1216.11, \"learn_time_ms\": 9246.617}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1221.3, \"learn_time_ms\": 9227.001}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1226.7, \"learn_time_ms\": 9231.687}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1221.23, \"learn_time_ms\": 9218.837}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1208.79, \"learn_time_ms\": 9211.325}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1202.9, \"learn_time_ms\": 9213.972}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1197.1, \"learn_time_ms\": 9198.629}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1195.92, \"learn_time_ms\": 9194.326}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1197.8, \"learn_time_ms\": 9204.267}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1196.25, \"learn_time_ms\": 9205.055}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1199.97, \"learn_time_ms\": 9229.985}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1199.78, \"learn_time_ms\": 9241.585}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1208.99, \"learn_time_ms\": 9231.023}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1211.59, \"learn_time_ms\": 9228.067}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1223.9, \"learn_time_ms\": 9233.551}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1231.99, \"learn_time_ms\": 9228.403}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1228.13, \"learn_time_ms\": 9234.422}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1233.48, \"learn_time_ms\": 9226.612}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1225.48, \"learn_time_ms\": 9210.863}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1226.5, \"learn_time_ms\": 9221.678}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1225.08, \"learn_time_ms\": 9217.615}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1217.69, \"learn_time_ms\": 9216.258}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1212.57, \"learn_time_ms\": 9216.742}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1211.91, \"learn_time_ms\": 9221.05}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1209.71, \"learn_time_ms\": 9225.519}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1207.91, \"learn_time_ms\": 9244.154}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1205.57, \"learn_time_ms\": 9243.616}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1203.14, \"learn_time_ms\": 9241.979}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1198.76, \"learn_time_ms\": 9254.837}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1195.36, \"learn_time_ms\": 9253.141}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1181.2, \"learn_time_ms\": 9243.547}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1174.18, \"learn_time_ms\": 9238.547}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1166.7, \"learn_time_ms\": 9233.157}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1163.44, \"learn_time_ms\": 9238.034}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1153.0, \"learn_time_ms\": 9241.924}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1142.58, \"learn_time_ms\": 9232.642}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1144.34, \"learn_time_ms\": 9252.611}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1147.62, \"learn_time_ms\": 9268.496}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1145.24, \"learn_time_ms\": 9268.07}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1147.7, \"learn_time_ms\": 9274.025}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1151.88, \"learn_time_ms\": 9283.903}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1154.23, \"learn_time_ms\": 9288.282}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1152.69, \"learn_time_ms\": 9291.178}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1153.13, \"learn_time_ms\": 9276.389}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1151.98, \"learn_time_ms\": 9260.663}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1158.14, \"learn_time_ms\": 9250.382}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1158.95, \"learn_time_ms\": 9233.328}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1158.32, \"learn_time_ms\": 9225.606}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1158.03, \"learn_time_ms\": 9232.357}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1160.75, \"learn_time_ms\": 9224.719}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1158.22, \"learn_time_ms\": 9211.581}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1158.29, \"learn_time_ms\": 9212.183}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1161.04, \"learn_time_ms\": 9202.575}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1165.8, \"learn_time_ms\": 9215.164}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1165.85, \"learn_time_ms\": 9215.186}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1167.51, \"learn_time_ms\": 9219.279}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1173.09, \"learn_time_ms\": 9228.501}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1177.32, \"learn_time_ms\": 9219.502}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1176.79, \"learn_time_ms\": 9213.304}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1188.1, \"learn_time_ms\": 9202.303}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1201.22, \"learn_time_ms\": 9220.58}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1217.49, \"learn_time_ms\": 9214.811}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1225.93, \"learn_time_ms\": 9227.831}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1231.1, \"learn_time_ms\": 9216.647}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1230.94, \"learn_time_ms\": 9221.174}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1237.13, \"learn_time_ms\": 9214.714}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1247.98, \"learn_time_ms\": 9208.254}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1254.45, \"learn_time_ms\": 9219.252}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1256.41, \"learn_time_ms\": 9224.916}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1270.48, \"learn_time_ms\": 9232.979}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1280.64, \"learn_time_ms\": 9224.779}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1291.24, \"learn_time_ms\": 9239.148}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1295.22, \"learn_time_ms\": 9240.111}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1309.71, \"learn_time_ms\": 9247.93}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1317.37, \"learn_time_ms\": 9257.372}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1323.5, \"learn_time_ms\": 9251.257}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1333.56, \"learn_time_ms\": 9247.377}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1329.93, \"learn_time_ms\": 9241.026}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1333.33, \"learn_time_ms\": 9251.731}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1332.07, \"learn_time_ms\": 9262.033}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1319.78, \"learn_time_ms\": 9272.057}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1313.99, \"learn_time_ms\": 9265.007}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1304.74, \"learn_time_ms\": 9257.133}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1303.67, \"learn_time_ms\": 9255.524}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1317.34, \"learn_time_ms\": 9238.889}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1328.45, \"learn_time_ms\": 9255.258}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1333.2, \"learn_time_ms\": 9274.745}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1331.73, \"learn_time_ms\": 9230.91}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1338.48, \"learn_time_ms\": 9190.903}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1334.67, \"learn_time_ms\": 9166.155}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1329.16, \"learn_time_ms\": 9160.381}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1326.29, \"learn_time_ms\": 9142.03}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1316.8, \"learn_time_ms\": 9116.548}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1314.14, \"learn_time_ms\": 9115.783}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1304.77, \"learn_time_ms\": 9126.429}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1295.38, \"learn_time_ms\": 9131.472}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1278.46, \"learn_time_ms\": 9113.387}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1261.87, \"learn_time_ms\": 9164.907}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1245.26, \"learn_time_ms\": 9189.735}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1233.3, \"learn_time_ms\": 9189.357}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1223.5, \"learn_time_ms\": 9172.055}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1197.61, \"learn_time_ms\": 9174.44}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1169.01, \"learn_time_ms\": 9167.281}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1139.52, \"learn_time_ms\": 9148.38}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1123.66, \"learn_time_ms\": 9135.186}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1108.93, \"learn_time_ms\": 9126.672}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1085.81, \"learn_time_ms\": 9130.052}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1066.3, \"learn_time_ms\": 9132.109}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1042.3, \"learn_time_ms\": 9135.745}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1030.06, \"learn_time_ms\": 9143.564}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1030.76, \"learn_time_ms\": 9158.47}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.09, \"learn_time_ms\": 9180.667}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 9215.039}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 9228.325}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 9244.511}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 9259.947}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 9271.165}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 9271.193}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 9265.064}", "{\"n\": 210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.53, \"learn_time_ms\": 9265.202}", "{\"n\": 211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.66, \"learn_time_ms\": 9251.579}", "{\"n\": 212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.12, \"learn_time_ms\": 9231.645}", "{\"n\": 213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.94, \"learn_time_ms\": 9231.421}", "{\"n\": 214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.16, \"learn_time_ms\": 9236.261}", "{\"n\": 215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.16, \"learn_time_ms\": 9218.596}", "{\"n\": 216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.24, \"learn_time_ms\": 9211.037}", "{\"n\": 217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.82, \"learn_time_ms\": 9196.907}", "{\"n\": 218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.87, \"learn_time_ms\": 9193.023}", "{\"n\": 219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.09, \"learn_time_ms\": 9196.014}", "{\"n\": 220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1, \"learn_time_ms\": 9217.066}", "{\"n\": 221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 9229.297}", "{\"n\": 222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 9242.852}", "{\"n\": 223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.02, \"learn_time_ms\": 9244.309}", "{\"n\": 224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 9229.027}", "{\"n\": 225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.97, \"learn_time_ms\": 9222.456}", "{\"n\": 226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.98, \"learn_time_ms\": 9163.911}", "{\"n\": 227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.91, \"learn_time_ms\": 9161.919}", "{\"n\": 228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.74, \"learn_time_ms\": 9151.846}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.92, \"learn_time_ms\": 9159.979}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.46, \"learn_time_ms\": 9107.613}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 9100.663}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 9089.223}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 9098.528}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 9113.116}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.41, \"learn_time_ms\": 9122.371}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 9156.865}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 9166.858}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 9185.133}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.15, \"learn_time_ms\": 9160.576}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.84, \"learn_time_ms\": 9198.352}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8, \"learn_time_ms\": 9205.0}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 9207.428}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 9200.888}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.78, \"learn_time_ms\": 9197.942}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 9185.767}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 9177.268}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 9172.021}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 9170.022}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 9181.963}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.71, \"learn_time_ms\": 9183.06}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.48, \"learn_time_ms\": 9187.69}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 9201.508}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.09, \"learn_time_ms\": 9210.727}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 9215.251}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 9256.526}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 9293.454}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 9305.186}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.62, \"learn_time_ms\": 9307.696}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.55, \"learn_time_ms\": 9315.586}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 9312.353}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.91, \"learn_time_ms\": 9318.882}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.69, \"learn_time_ms\": 9329.296}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.57, \"learn_time_ms\": 9332.343}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.83, \"learn_time_ms\": 9333.318}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.71, \"learn_time_ms\": 9322.178}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.62, \"learn_time_ms\": 9316.153}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.63, \"learn_time_ms\": 9320.917}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.76, \"learn_time_ms\": 9327.589}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.89, \"learn_time_ms\": 9332.282}", "{\"n\": 270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.88, \"learn_time_ms\": 9344.068}", "{\"n\": 271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.04, \"learn_time_ms\": 9343.238}", "{\"n\": 272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 9344.728}", "{\"n\": 273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.41, \"learn_time_ms\": 9354.387}", "{\"n\": 274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 9358.8}", "{\"n\": 275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 9364.655}", "{\"n\": 276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8, \"learn_time_ms\": 9362.286}", "{\"n\": 277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.67, \"learn_time_ms\": 9359.261}", "{\"n\": 278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 9363.913}", "{\"n\": 279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.14, \"learn_time_ms\": 9377.968}", "{\"n\": 280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 9379.933}", "{\"n\": 281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 9387.372}", "{\"n\": 282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 9387.21}", "{\"n\": 283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 9372.412}", "{\"n\": 284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.47, \"learn_time_ms\": 9382.096}", "{\"n\": 285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.41, \"learn_time_ms\": 9368.762}", "{\"n\": 286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.86, \"learn_time_ms\": 9373.503}", "{\"n\": 287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 9375.4}", "{\"n\": 288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.42, \"learn_time_ms\": 9392.391}", "{\"n\": 289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.2, \"learn_time_ms\": 9387.355}", "{\"n\": 290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 9385.018}", "{\"n\": 291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.23, \"learn_time_ms\": 9382.906}", "{\"n\": 292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.67, \"learn_time_ms\": 9383.636}", "{\"n\": 293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.88, \"learn_time_ms\": 9384.231}", "{\"n\": 294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 9371.561}", "{\"n\": 295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 9387.008}", "{\"n\": 296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 9392.684}", "{\"n\": 297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 9385.355}", "{\"n\": 298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 9353.633}", "{\"n\": 299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 9355.578}", "{\"n\": 300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 9352.328}", "{\"n\": 301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.4, \"learn_time_ms\": 9356.541}", "{\"n\": 302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 9354.259}", "{\"n\": 303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.54, \"learn_time_ms\": 9353.18}", "{\"n\": 304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.03, \"learn_time_ms\": 9358.172}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 9357.263}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 9345.965}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9347.721}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.4, \"learn_time_ms\": 9352.509}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.39, \"learn_time_ms\": 9354.621}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 9356.976}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 9361.119}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 9359.108}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.19, \"learn_time_ms\": 9368.169}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.82, \"learn_time_ms\": 9372.698}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.68, \"learn_time_ms\": 9365.216}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.19, \"learn_time_ms\": 9371.094}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.14, \"learn_time_ms\": 9378.566}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.92, \"learn_time_ms\": 9372.339}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.2, \"learn_time_ms\": 9361.001}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.42, \"learn_time_ms\": 9362.313}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.39, \"learn_time_ms\": 9358.598}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.54, \"learn_time_ms\": 9352.714}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 9356.176}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.59, \"learn_time_ms\": 9351.995}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.15, \"learn_time_ms\": 9359.376}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.83, \"learn_time_ms\": 9363.127}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.63, \"learn_time_ms\": 9353.955}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.62, \"learn_time_ms\": 9357.155}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.85, \"learn_time_ms\": 9361.174}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.7, \"learn_time_ms\": 9365.459}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 9374.708}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 9385.027}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.24, \"learn_time_ms\": 9387.869}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.4, \"learn_time_ms\": 9388.139}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.28, \"learn_time_ms\": 9406.951}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 9423.072}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 9430.29}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.38, \"learn_time_ms\": 9457.908}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.04, \"learn_time_ms\": 9454.356}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.26, \"learn_time_ms\": 9470.041}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 9464.362}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 9475.393}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.63, \"learn_time_ms\": 9465.826}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.78, \"learn_time_ms\": 9469.165}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 9442.62}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 9430.829}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.02, \"learn_time_ms\": 9428.677}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.22, \"learn_time_ms\": 9412.775}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.18, \"learn_time_ms\": 9426.82}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.73, \"learn_time_ms\": 9399.774}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.74, \"learn_time_ms\": 9398.739}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.3, \"learn_time_ms\": 9389.174}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.34, \"learn_time_ms\": 9395.638}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.49, \"learn_time_ms\": 9387.643}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.85, \"learn_time_ms\": 9396.053}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.44, \"learn_time_ms\": 9398.742}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.45, \"learn_time_ms\": 9387.186}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.91, \"learn_time_ms\": 9387.295}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.96, \"learn_time_ms\": 9380.938}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.56, \"learn_time_ms\": 9395.827}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.45, \"learn_time_ms\": 9402.842}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.6, \"learn_time_ms\": 9397.047}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.86, \"learn_time_ms\": 9395.151}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.26, \"learn_time_ms\": 9412.691}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.81, \"learn_time_ms\": 9409.399}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 9393.175}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.37, \"learn_time_ms\": 9398.05}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.66, \"learn_time_ms\": 9399.319}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 9403.21}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 9407.701}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 9412.886}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 9416.581}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.92, \"learn_time_ms\": 9433.268}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.57, \"learn_time_ms\": 9428.813}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 9444.793}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.07, \"learn_time_ms\": 9458.08}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.35, \"learn_time_ms\": 9464.485}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.5, \"learn_time_ms\": 9470.194}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.4, \"learn_time_ms\": 9467.847}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.11, \"learn_time_ms\": 9453.516}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.63, \"learn_time_ms\": 9451.229}", "{\"n\": 382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 9474.926}", "{\"n\": 383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 9463.747}", "{\"n\": 384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.88, \"learn_time_ms\": 9456.526}", "{\"n\": 385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.81, \"learn_time_ms\": 9460.087}", "{\"n\": 386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.98, \"learn_time_ms\": 9458.024}", "{\"n\": 387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 9474.582}", "{\"n\": 388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.73, \"learn_time_ms\": 9450.902}", "{\"n\": 389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 9457.493}", "{\"n\": 390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 9476.59}", "{\"n\": 391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 9474.562}", "{\"n\": 392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.06, \"learn_time_ms\": 9447.413}", "{\"n\": 393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.31, \"learn_time_ms\": 9448.631}", "{\"n\": 394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34, \"learn_time_ms\": 9464.763}", "{\"n\": 395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.15, \"learn_time_ms\": 9451.424}", "{\"n\": 396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 9448.894}", "{\"n\": 397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.94, \"learn_time_ms\": 9432.396}", "{\"n\": 398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 9459.589}", "{\"n\": 399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 9445.013}", "{\"n\": 400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.78, \"learn_time_ms\": 9434.114}", "{\"n\": 401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 9418.885}", "{\"n\": 402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.65, \"learn_time_ms\": 9413.845}", "{\"n\": 403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.37, \"learn_time_ms\": 9414.291}", "{\"n\": 404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.53, \"learn_time_ms\": 9392.792}", "{\"n\": 405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 9395.162}", "{\"n\": 406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.0, \"learn_time_ms\": 9405.806}", "{\"n\": 407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.15, \"learn_time_ms\": 9418.184}", "{\"n\": 408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.25, \"learn_time_ms\": 9393.301}", "{\"n\": 409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.71, \"learn_time_ms\": 9403.327}", "{\"n\": 410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.04, \"learn_time_ms\": 9407.622}", "{\"n\": 411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.2, \"learn_time_ms\": 9411.608}", "{\"n\": 412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.44, \"learn_time_ms\": 9416.695}", "{\"n\": 413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 9404.671}", "{\"n\": 414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 9406.941}", "{\"n\": 415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 9416.849}", "{\"n\": 416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8, \"learn_time_ms\": 9406.018}", "{\"n\": 417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 9397.039}", "{\"n\": 418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 9404.014}", "{\"n\": 419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 9394.559}", "{\"n\": 420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 9387.395}", "{\"n\": 421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.58, \"learn_time_ms\": 9385.797}", "{\"n\": 422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 9391.728}", "{\"n\": 423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 9399.806}", "{\"n\": 424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 9405.799}", "{\"n\": 425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.23, \"learn_time_ms\": 9392.787}", "{\"n\": 426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.03, \"learn_time_ms\": 9380.549}", "{\"n\": 427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 9377.652}", "{\"n\": 428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 9383.638}", "{\"n\": 429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.78, \"learn_time_ms\": 9410.839}", "{\"n\": 430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 9407.041}", "{\"n\": 431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 9411.366}", "{\"n\": 432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 9399.235}", "{\"n\": 433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.56, \"learn_time_ms\": 9384.242}", "{\"n\": 434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.36, \"learn_time_ms\": 9380.156}", "{\"n\": 435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.7, \"learn_time_ms\": 9363.934}", "{\"n\": 436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.59, \"learn_time_ms\": 9375.093}", "{\"n\": 437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.23, \"learn_time_ms\": 9375.968}", "{\"n\": 438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.63, \"learn_time_ms\": 9374.527}", "{\"n\": 439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 9341.349}", "{\"n\": 440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.82, \"learn_time_ms\": 9332.948}", "{\"n\": 441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.76, \"learn_time_ms\": 9317.233}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.83, \"learn_time_ms\": 9321.606}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.33, \"learn_time_ms\": 9337.814}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 9343.572}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 9352.686}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 9351.149}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.82, \"learn_time_ms\": 9346.235}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.51, \"learn_time_ms\": 9352.553}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.6, \"learn_time_ms\": 9362.074}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.55, \"learn_time_ms\": 9364.514}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 9370.825}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 9365.794}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.56, \"learn_time_ms\": 9358.968}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 9349.947}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.95, \"learn_time_ms\": 9345.81}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.96, \"learn_time_ms\": 9345.958}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.99, \"learn_time_ms\": 9353.479}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 9340.635}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 9330.757}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 9335.514}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 9337.887}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.67, \"learn_time_ms\": 9344.185}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9339.855}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.71, \"learn_time_ms\": 9340.885}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.88, \"learn_time_ms\": 9342.566}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.18, \"learn_time_ms\": 9346.555}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 9339.349}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.71, \"learn_time_ms\": 9344.973}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 9351.102}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 9351.411}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.38, \"learn_time_ms\": 9353.727}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.38, \"learn_time_ms\": 9356.488}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 9346.51}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.15, \"learn_time_ms\": 9350.199}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.47, \"learn_time_ms\": 9348.737}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.62, \"learn_time_ms\": 9345.097}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 9343.272}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.12, \"learn_time_ms\": 9338.403}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 9338.76}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 9339.409}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9341.788}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 9343.554}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 9360.226}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.38, \"learn_time_ms\": 9364.323}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 9363.887}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 9364.058}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 9361.851}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.56, \"learn_time_ms\": 9370.698}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.97, \"learn_time_ms\": 9371.766}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.8, \"learn_time_ms\": 9373.701}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.67, \"learn_time_ms\": 9372.699}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.05, \"learn_time_ms\": 9364.17}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 9358.143}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.82, \"learn_time_ms\": 9352.288}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 9348.79}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 9347.048}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.42, \"learn_time_ms\": 9344.232}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.41, \"learn_time_ms\": 9320.071}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 9308.048}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.15, \"learn_time_ms\": 9299.932}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.19, \"learn_time_ms\": 9283.328}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 9280.271}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 9269.004}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.68, \"learn_time_ms\": 9264.213}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.53, \"learn_time_ms\": 9269.511}", "{\"n\": 506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.15, \"learn_time_ms\": 9261.566}", "{\"n\": 507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.03, \"learn_time_ms\": 9259.064}", "{\"n\": 508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.31, \"learn_time_ms\": 9272.141}", "{\"n\": 509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.23, \"learn_time_ms\": 9276.437}", "{\"n\": 510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.3, \"learn_time_ms\": 9279.651}", "{\"n\": 511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.68, \"learn_time_ms\": 9281.324}", "{\"n\": 512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.36, \"learn_time_ms\": 9274.938}", "{\"n\": 513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.55, \"learn_time_ms\": 9281.157}", "{\"n\": 514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.01, \"learn_time_ms\": 9270.788}", "{\"n\": 515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.21, \"learn_time_ms\": 9257.488}", "{\"n\": 516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.28, \"learn_time_ms\": 9240.323}", "{\"n\": 517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 9240.756}", "{\"n\": 518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.92, \"learn_time_ms\": 9237.863}", "{\"n\": 519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.59, \"learn_time_ms\": 9244.215}", "{\"n\": 520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.72, \"learn_time_ms\": 9231.732}", "{\"n\": 521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.21, \"learn_time_ms\": 9225.514}", "{\"n\": 522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9226.138}", "{\"n\": 523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.86, \"learn_time_ms\": 9223.083}", "{\"n\": 524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.86, \"learn_time_ms\": 9241.422}", "{\"n\": 525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.44, \"learn_time_ms\": 9247.784}", "{\"n\": 526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.42, \"learn_time_ms\": 9266.524}", "{\"n\": 527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 9273.443}", "{\"n\": 528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 9279.016}", "{\"n\": 529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.29, \"learn_time_ms\": 9274.991}", "{\"n\": 530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.75, \"learn_time_ms\": 9275.193}", "{\"n\": 531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.71, \"learn_time_ms\": 9283.493}", "{\"n\": 532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.79, \"learn_time_ms\": 9291.432}", "{\"n\": 533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.78, \"learn_time_ms\": 9296.024}", "{\"n\": 534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.27, \"learn_time_ms\": 9284.958}", "{\"n\": 535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 9287.642}", "{\"n\": 536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5, \"learn_time_ms\": 9292.985}", "{\"n\": 537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.67, \"learn_time_ms\": 9288.789}", "{\"n\": 538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.53, \"learn_time_ms\": 9279.475}", "{\"n\": 539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.73, \"learn_time_ms\": 9257.331}", "{\"n\": 540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 9257.497}", "{\"n\": 541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.36, \"learn_time_ms\": 9256.588}", "{\"n\": 542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.19, \"learn_time_ms\": 9239.972}", "{\"n\": 543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.98, \"learn_time_ms\": 9218.915}", "{\"n\": 544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 9217.336}", "{\"n\": 545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.18, \"learn_time_ms\": 9216.083}", "{\"n\": 546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.27, \"learn_time_ms\": 9188.561}", "{\"n\": 547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.37, \"learn_time_ms\": 9185.318}", "{\"n\": 548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 9179.864}", "{\"n\": 549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.57, \"learn_time_ms\": 9190.912}", "{\"n\": 550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 9202.125}", "{\"n\": 551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 9207.518}", "{\"n\": 552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.31, \"learn_time_ms\": 9225.396}", "{\"n\": 553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.94, \"learn_time_ms\": 9239.717}", "{\"n\": 554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.67, \"learn_time_ms\": 9231.362}", "{\"n\": 555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 9224.723}", "{\"n\": 556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 9240.142}", "{\"n\": 557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 9248.356}", "{\"n\": 558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9258.732}", "{\"n\": 559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 9270.897}", "{\"n\": 560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 9272.372}", "{\"n\": 561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 9270.313}", "{\"n\": 562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.15, \"learn_time_ms\": 9260.554}", "{\"n\": 563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.48, \"learn_time_ms\": 9262.283}", "{\"n\": 564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.79, \"learn_time_ms\": 9270.889}", "{\"n\": 565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.64, \"learn_time_ms\": 9268.2}", "{\"n\": 566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 9269.518}", "{\"n\": 567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 9262.987}", "{\"n\": 568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 9247.292}", "{\"n\": 569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.42, \"learn_time_ms\": 9232.153}", "{\"n\": 570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 9215.755}", "{\"n\": 571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.51, \"learn_time_ms\": 9209.374}", "{\"n\": 572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.67, \"learn_time_ms\": 9230.576}", "{\"n\": 573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 9222.233}", "{\"n\": 574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 9214.044}", "{\"n\": 575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.43, \"learn_time_ms\": 9225.253}", "{\"n\": 576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 9243.847}", "{\"n\": 577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.22, \"learn_time_ms\": 9264.66}", "{\"n\": 578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.53, \"learn_time_ms\": 9285.168}", "{\"n\": 579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 9307.942}", "{\"n\": 580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 9331.163}", "{\"n\": 581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.6, \"learn_time_ms\": 9344.669}", "{\"n\": 582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 9347.451}", "{\"n\": 583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.41, \"learn_time_ms\": 9371.461}", "{\"n\": 584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.02, \"learn_time_ms\": 9396.526}", "{\"n\": 585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.46, \"learn_time_ms\": 9402.168}", "{\"n\": 586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.06, \"learn_time_ms\": 9397.033}", "{\"n\": 587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 9392.874}", "{\"n\": 588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.33, \"learn_time_ms\": 9398.631}", "{\"n\": 589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.58, \"learn_time_ms\": 9409.487}", "{\"n\": 590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.11, \"learn_time_ms\": 9408.069}", "{\"n\": 591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1, \"learn_time_ms\": 9414.137}", "{\"n\": 592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.45, \"learn_time_ms\": 9407.216}", "{\"n\": 593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.38, \"learn_time_ms\": 9408.725}", "{\"n\": 594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.08, \"learn_time_ms\": 9408.105}", "{\"n\": 595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.97, \"learn_time_ms\": 9412.398}", "{\"n\": 596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.19, \"learn_time_ms\": 9410.324}", "{\"n\": 597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.05, \"learn_time_ms\": 9404.207}", "{\"n\": 598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1, \"learn_time_ms\": 9402.903}", "{\"n\": 599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.64, \"learn_time_ms\": 9389.101}", "{\"n\": 600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 9388.746}", "{\"n\": 601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.76, \"learn_time_ms\": 9391.047}", "{\"n\": 602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 9387.737}", "{\"n\": 603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.63, \"learn_time_ms\": 9393.951}", "{\"n\": 604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.63, \"learn_time_ms\": 9388.591}", "{\"n\": 605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 9385.837}", "{\"n\": 606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.14, \"learn_time_ms\": 9387.544}", "{\"n\": 607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.15, \"learn_time_ms\": 9393.434}", "{\"n\": 608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.26, \"learn_time_ms\": 9390.052}", "{\"n\": 609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.59, \"learn_time_ms\": 9388.486}", "{\"n\": 610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.84, \"learn_time_ms\": 9384.13}", "{\"n\": 611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.17, \"learn_time_ms\": 9377.111}", "{\"n\": 612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 9372.624}", "{\"n\": 613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.63, \"learn_time_ms\": 9372.452}", "{\"n\": 614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.68, \"learn_time_ms\": 9375.441}", "{\"n\": 615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 9379.417}", "{\"n\": 616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 9368.737}", "{\"n\": 617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.96, \"learn_time_ms\": 9360.934}", "{\"n\": 618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.07, \"learn_time_ms\": 9365.551}", "{\"n\": 619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.55, \"learn_time_ms\": 9381.715}", "{\"n\": 620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.23, \"learn_time_ms\": 9384.786}", "{\"n\": 621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.27, \"learn_time_ms\": 9386.898}", "{\"n\": 622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.47, \"learn_time_ms\": 9393.431}", "{\"n\": 623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.86, \"learn_time_ms\": 9373.372}", "{\"n\": 624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.93, \"learn_time_ms\": 9368.52}", "{\"n\": 625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.89, \"learn_time_ms\": 9376.053}", "{\"n\": 626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.05, \"learn_time_ms\": 9377.885}", "{\"n\": 627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.16, \"learn_time_ms\": 9382.256}", "{\"n\": 628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.94, \"learn_time_ms\": 9375.533}", "{\"n\": 629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.66, \"learn_time_ms\": 9358.955}", "{\"n\": 630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.63, \"learn_time_ms\": 9363.155}", "{\"n\": 631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.86, \"learn_time_ms\": 9362.764}", "{\"n\": 632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.92, \"learn_time_ms\": 9357.518}", "{\"n\": 633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.89, \"learn_time_ms\": 9357.705}", "{\"n\": 634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.84, \"learn_time_ms\": 9360.88}", "{\"n\": 635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 9348.665}", "{\"n\": 636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.41, \"learn_time_ms\": 9361.569}", "{\"n\": 637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 9364.019}", "{\"n\": 638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.12, \"learn_time_ms\": 9368.027}", "{\"n\": 639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.24, \"learn_time_ms\": 9366.848}", "{\"n\": 640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 9362.704}", "{\"n\": 641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.03, \"learn_time_ms\": 9359.914}", "{\"n\": 642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.85, \"learn_time_ms\": 9370.829}", "{\"n\": 643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.97, \"learn_time_ms\": 9376.022}", "{\"n\": 644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.91, \"learn_time_ms\": 9378.883}", "{\"n\": 645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.9, \"learn_time_ms\": 9382.031}", "{\"n\": 646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0, \"learn_time_ms\": 9376.429}", "{\"n\": 647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.41, \"learn_time_ms\": 9380.796}", "{\"n\": 648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.31, \"learn_time_ms\": 9385.292}", "{\"n\": 649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.57, \"learn_time_ms\": 9390.508}", "{\"n\": 650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.98, \"learn_time_ms\": 9392.825}", "{\"n\": 651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.33, \"learn_time_ms\": 9400.694}", "{\"n\": 652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.9, \"learn_time_ms\": 9396.196}", "{\"n\": 653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 9402.137}", "{\"n\": 654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.17, \"learn_time_ms\": 9400.274}", "{\"n\": 655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 9395.888}", "{\"n\": 656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 9388.663}", "{\"n\": 657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.68, \"learn_time_ms\": 9380.469}", "{\"n\": 658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.45, \"learn_time_ms\": 9377.532}", "{\"n\": 659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.46, \"learn_time_ms\": 9375.642}", "{\"n\": 660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.71, \"learn_time_ms\": 9372.187}", "{\"n\": 661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9367.553}", "{\"n\": 662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 9371.887}", "{\"n\": 663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.51, \"learn_time_ms\": 9368.693}", "{\"n\": 664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.6, \"learn_time_ms\": 9367.291}", "{\"n\": 665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.17, \"learn_time_ms\": 9372.331}", "{\"n\": 666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.21, \"learn_time_ms\": 9407.135}", "{\"n\": 667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.43, \"learn_time_ms\": 9411.994}", "{\"n\": 668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 9417.998}", "{\"n\": 669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.83, \"learn_time_ms\": 9420.474}", "{\"n\": 670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 9428.127}", "{\"n\": 671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 9429.188}", "{\"n\": 672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 9417.667}", "{\"n\": 673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.67, \"learn_time_ms\": 9422.359}", "{\"n\": 674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.86, \"learn_time_ms\": 9428.734}", "{\"n\": 675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.93, \"learn_time_ms\": 9437.241}", "{\"n\": 676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 9416.023}", "{\"n\": 677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7, \"learn_time_ms\": 9420.419}", "{\"n\": 678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.51, \"learn_time_ms\": 9417.691}", "{\"n\": 679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.3, \"learn_time_ms\": 9424.795}", "{\"n\": 680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 9422.745}", "{\"n\": 681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 9433.909}", "{\"n\": 682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.54, \"learn_time_ms\": 9429.939}", "{\"n\": 683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 9425.366}", "{\"n\": 684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.53, \"learn_time_ms\": 9417.594}", "{\"n\": 685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.41, \"learn_time_ms\": 9411.466}", "{\"n\": 686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 9408.81}", "{\"n\": 687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.92, \"learn_time_ms\": 9396.549}", "{\"n\": 688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.51, \"learn_time_ms\": 9393.896}", "{\"n\": 689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 9384.336}", "{\"n\": 690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.62, \"learn_time_ms\": 9379.988}", "{\"n\": 691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 9358.532}", "{\"n\": 692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.68, \"learn_time_ms\": 9371.603}", "{\"n\": 693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.62, \"learn_time_ms\": 9370.582}", "{\"n\": 694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.37, \"learn_time_ms\": 9366.01}", "{\"n\": 695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 9354.024}", "{\"n\": 696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.27, \"learn_time_ms\": 9356.092}", "{\"n\": 697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.18, \"learn_time_ms\": 9353.286}", "{\"n\": 698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.29, \"learn_time_ms\": 9337.816}", "{\"n\": 699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 9318.553}", "{\"n\": 700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 9314.31}", "{\"n\": 701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.28, \"learn_time_ms\": 9303.1}", "{\"n\": 702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.29, \"learn_time_ms\": 9287.821}", "{\"n\": 703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.46, \"learn_time_ms\": 9271.282}", "{\"n\": 704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.68, \"learn_time_ms\": 9256.321}", "{\"n\": 705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.76, \"learn_time_ms\": 9246.131}", "{\"n\": 706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9229.052}", "{\"n\": 707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 9223.729}", "{\"n\": 708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.94, \"learn_time_ms\": 9221.251}", "{\"n\": 709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 9220.804}", "{\"n\": 710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.66, \"learn_time_ms\": 9213.082}", "{\"n\": 711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.89, \"learn_time_ms\": 9214.999}", "{\"n\": 712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.49, \"learn_time_ms\": 9208.806}", "{\"n\": 713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.19, \"learn_time_ms\": 9215.366}", "{\"n\": 714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.18, \"learn_time_ms\": 9214.339}", "{\"n\": 715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.96, \"learn_time_ms\": 9220.079}", "{\"n\": 716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.06, \"learn_time_ms\": 9227.332}", "{\"n\": 717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.15, \"learn_time_ms\": 9231.824}", "{\"n\": 718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 9244.78}", "{\"n\": 719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.83, \"learn_time_ms\": 9262.581}", "{\"n\": 720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 9257.326}", "{\"n\": 721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.71, \"learn_time_ms\": 9256.239}", "{\"n\": 722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.18, \"learn_time_ms\": 9259.468}", "{\"n\": 723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.61, \"learn_time_ms\": 9261.761}", "{\"n\": 724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.42, \"learn_time_ms\": 9278.402}", "{\"n\": 725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.76, \"learn_time_ms\": 9286.777}", "{\"n\": 726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.7, \"learn_time_ms\": 9294.68}", "{\"n\": 727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.92, \"learn_time_ms\": 9294.489}", "{\"n\": 728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.49, \"learn_time_ms\": 9302.999}", "{\"n\": 729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9301.153}", "{\"n\": 730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 9313.783}", "{\"n\": 731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.42, \"learn_time_ms\": 9335.886}", "{\"n\": 732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.13, \"learn_time_ms\": 9349.159}", "{\"n\": 733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.16, \"learn_time_ms\": 9354.335}", "{\"n\": 734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.62, \"learn_time_ms\": 9353.951}", "{\"n\": 735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 9355.011}", "{\"n\": 736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 9357.239}", "{\"n\": 737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.08, \"learn_time_ms\": 9357.594}", "{\"n\": 738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.28, \"learn_time_ms\": 9359.191}", "{\"n\": 739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.57, \"learn_time_ms\": 9363.417}", "{\"n\": 740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.92, \"learn_time_ms\": 9365.285}", "{\"n\": 741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.25, \"learn_time_ms\": 9364.217}", "{\"n\": 742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.12, \"learn_time_ms\": 9362.648}", "{\"n\": 743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 9366.755}", "{\"n\": 744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.82, \"learn_time_ms\": 9371.022}", "{\"n\": 745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 9372.155}", "{\"n\": 746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 9365.069}", "{\"n\": 747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 9369.504}", "{\"n\": 748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 9359.075}", "{\"n\": 749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.18, \"learn_time_ms\": 9361.87}", "{\"n\": 750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 9370.679}", "{\"n\": 751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 9365.256}", "{\"n\": 752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 9360.896}", "{\"n\": 753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 9355.636}", "{\"n\": 754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.06, \"learn_time_ms\": 9357.85}", "{\"n\": 755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.21, \"learn_time_ms\": 9358.169}", "{\"n\": 756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.19, \"learn_time_ms\": 9354.585}", "{\"n\": 757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.27, \"learn_time_ms\": 9355.311}", "{\"n\": 758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7, \"learn_time_ms\": 9360.626}", "{\"n\": 759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 9360.634}", "{\"n\": 760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.82, \"learn_time_ms\": 9347.767}", "{\"n\": 761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.05, \"learn_time_ms\": 9347.592}", "{\"n\": 762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.13, \"learn_time_ms\": 9352.93}", "{\"n\": 763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.48, \"learn_time_ms\": 9352.38}", "{\"n\": 764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.83, \"learn_time_ms\": 9356.368}", "{\"n\": 765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.8, \"learn_time_ms\": 9360.348}", "{\"n\": 766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.81, \"learn_time_ms\": 9360.24}", "{\"n\": 767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.7, \"learn_time_ms\": 9365.785}", "{\"n\": 768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.49, \"learn_time_ms\": 9368.337}", "{\"n\": 769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.47, \"learn_time_ms\": 9367.483}", "{\"n\": 770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.73, \"learn_time_ms\": 9376.626}", "{\"n\": 771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.96, \"learn_time_ms\": 9375.666}", "{\"n\": 772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.59, \"learn_time_ms\": 9379.603}", "{\"n\": 773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.47, \"learn_time_ms\": 9379.358}", "{\"n\": 774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.72, \"learn_time_ms\": 9378.483}", "{\"n\": 775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.39, \"learn_time_ms\": 9360.174}", "{\"n\": 776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.54, \"learn_time_ms\": 9372.754}", "{\"n\": 777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.2, \"learn_time_ms\": 9366.705}", "{\"n\": 778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.06, \"learn_time_ms\": 9359.289}", "{\"n\": 779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.68, \"learn_time_ms\": 9361.197}", "{\"n\": 780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.58, \"learn_time_ms\": 9365.268}", "{\"n\": 781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 9376.666}", "{\"n\": 782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 9378.649}", "{\"n\": 783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 9387.592}", "{\"n\": 784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.79, \"learn_time_ms\": 9384.89}", "{\"n\": 785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 9415.637}", "{\"n\": 786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 9426.346}", "{\"n\": 787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 9434.539}", "{\"n\": 788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 9441.315}", "{\"n\": 789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.55, \"learn_time_ms\": 9439.96}", "{\"n\": 790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.86, \"learn_time_ms\": 9433.216}", "{\"n\": 791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 9440.938}", "{\"n\": 792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.49, \"learn_time_ms\": 9442.426}", "{\"n\": 793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.6, \"learn_time_ms\": 9437.146}", "{\"n\": 794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.62, \"learn_time_ms\": 9440.312}", "{\"n\": 795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.28, \"learn_time_ms\": 9427.682}", "{\"n\": 796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.45, \"learn_time_ms\": 9410.166}", "{\"n\": 797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.91, \"learn_time_ms\": 9415.534}", "{\"n\": 798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8, \"learn_time_ms\": 9410.864}", "{\"n\": 799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.56, \"learn_time_ms\": 9408.315}", "{\"n\": 800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 9405.406}", "{\"n\": 801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 9391.389}", "{\"n\": 802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 9378.106}", "{\"n\": 803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.93, \"learn_time_ms\": 9367.746}", "{\"n\": 804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.59, \"learn_time_ms\": 9361.675}", "{\"n\": 805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.71, \"learn_time_ms\": 9355.445}", "{\"n\": 806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 9354.364}", "{\"n\": 807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 9333.161}", "{\"n\": 808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 9347.162}", "{\"n\": 809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 9342.577}", "{\"n\": 810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 9338.937}", "{\"n\": 811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.37, \"learn_time_ms\": 9333.213}", "{\"n\": 812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 9334.501}", "{\"n\": 813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 9338.696}", "{\"n\": 814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.18, \"learn_time_ms\": 9323.193}", "{\"n\": 815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 9309.649}", "{\"n\": 816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9307.412}", "{\"n\": 817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 9305.925}", "{\"n\": 818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.23, \"learn_time_ms\": 9298.493}", "{\"n\": 819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.43, \"learn_time_ms\": 9301.307}", "{\"n\": 820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 9302.204}", "{\"n\": 821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.46, \"learn_time_ms\": 9302.809}", "{\"n\": 822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.85, \"learn_time_ms\": 9303.747}", "{\"n\": 823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 9305.694}", "{\"n\": 824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 9317.644}", "{\"n\": 825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 9334.766}", "{\"n\": 826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 9335.167}", "{\"n\": 827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.82, \"learn_time_ms\": 9350.125}", "{\"n\": 828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.73, \"learn_time_ms\": 9340.539}", "{\"n\": 829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 9333.893}", "{\"n\": 830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.49, \"learn_time_ms\": 9335.718}", "{\"n\": 831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.55, \"learn_time_ms\": 9337.082}", "{\"n\": 832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.91, \"learn_time_ms\": 9342.143}", "{\"n\": 833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 9336.885}", "{\"n\": 834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9344.576}", "{\"n\": 835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 9346.497}", "{\"n\": 836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.46, \"learn_time_ms\": 9350.797}", "{\"n\": 837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 9349.174}", "{\"n\": 838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.83, \"learn_time_ms\": 9351.543}", "{\"n\": 839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.76, \"learn_time_ms\": 9353.515}", "{\"n\": 840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.52, \"learn_time_ms\": 9364.079}", "{\"n\": 841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.44, \"learn_time_ms\": 9357.556}", "{\"n\": 842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.54, \"learn_time_ms\": 9354.616}", "{\"n\": 843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.59, \"learn_time_ms\": 9359.243}", "{\"n\": 844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.03, \"learn_time_ms\": 9340.139}", "{\"n\": 845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.46, \"learn_time_ms\": 9322.055}", "{\"n\": 846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 9300.735}", "{\"n\": 847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.09, \"learn_time_ms\": 9295.618}", "{\"n\": 848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.42, \"learn_time_ms\": 9298.378}", "{\"n\": 849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.27, \"learn_time_ms\": 9288.146}", "{\"n\": 850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.41, \"learn_time_ms\": 9272.627}", "{\"n\": 851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.41, \"learn_time_ms\": 9265.645}", "{\"n\": 852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.84, \"learn_time_ms\": 9260.342}", "{\"n\": 853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.87, \"learn_time_ms\": 9250.796}", "{\"n\": 854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.09, \"learn_time_ms\": 9249.517}", "{\"n\": 855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 9268.678}", "{\"n\": 856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.73, \"learn_time_ms\": 9274.641}", "{\"n\": 857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 9252.042}", "{\"n\": 858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.83, \"learn_time_ms\": 9234.028}", "{\"n\": 859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.84, \"learn_time_ms\": 9238.417}", "{\"n\": 860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 9243.672}", "{\"n\": 861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 9257.962}", "{\"n\": 862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 9265.362}", "{\"n\": 863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.86, \"learn_time_ms\": 9272.5}", "{\"n\": 864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.23, \"learn_time_ms\": 9278.913}", "{\"n\": 865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 9264.259}", "{\"n\": 866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.97, \"learn_time_ms\": 9259.487}", "{\"n\": 867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.92, \"learn_time_ms\": 9272.059}", "{\"n\": 868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.02, \"learn_time_ms\": 9271.72}", "{\"n\": 869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.17, \"learn_time_ms\": 9263.096}", "{\"n\": 870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.88, \"learn_time_ms\": 9262.708}", "{\"n\": 871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.71, \"learn_time_ms\": 9247.516}", "{\"n\": 872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.58, \"learn_time_ms\": 9233.058}", "{\"n\": 873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.07, \"learn_time_ms\": 9222.533}", "{\"n\": 874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.14, \"learn_time_ms\": 9224.973}", "{\"n\": 875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 9232.699}", "{\"n\": 876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.25, \"learn_time_ms\": 9234.098}", "{\"n\": 877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0, \"learn_time_ms\": 9231.357}", "{\"n\": 878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.07, \"learn_time_ms\": 9227.609}", "{\"n\": 879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.91, \"learn_time_ms\": 9225.107}", "{\"n\": 880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.61, \"learn_time_ms\": 9215.494}", "{\"n\": 881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 9217.957}", "{\"n\": 882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.01, \"learn_time_ms\": 9220.548}", "{\"n\": 883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.23, \"learn_time_ms\": 9216.908}", "{\"n\": 884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.39, \"learn_time_ms\": 9217.242}", "{\"n\": 885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.65, \"learn_time_ms\": 9211.323}", "{\"n\": 886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 9217.407}", "{\"n\": 887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.63, \"learn_time_ms\": 9219.697}", "{\"n\": 888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.2, \"learn_time_ms\": 9228.805}", "{\"n\": 889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.88, \"learn_time_ms\": 9242.297}", "{\"n\": 890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.17, \"learn_time_ms\": 9247.775}", "{\"n\": 891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.53, \"learn_time_ms\": 9247.886}", "{\"n\": 892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.26, \"learn_time_ms\": 9244.001}", "{\"n\": 893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 9247.2}", "{\"n\": 894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 9246.04}", "{\"n\": 895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 9252.753}", "{\"n\": 896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 9248.046}", "{\"n\": 897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.07, \"learn_time_ms\": 9242.671}", "{\"n\": 898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.95, \"learn_time_ms\": 9245.106}", "{\"n\": 899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.97, \"learn_time_ms\": 9244.855}", "{\"n\": 900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.06, \"learn_time_ms\": 9239.47}", "{\"n\": 901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.89, \"learn_time_ms\": 9241.983}", "{\"n\": 902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.35, \"learn_time_ms\": 9245.228}", "{\"n\": 903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.88, \"learn_time_ms\": 9285.832}", "{\"n\": 904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.85, \"learn_time_ms\": 9275.013}", "{\"n\": 905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.81, \"learn_time_ms\": 9270.016}", "{\"n\": 906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.92, \"learn_time_ms\": 9279.116}", "{\"n\": 907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.9, \"learn_time_ms\": 9297.861}", "{\"n\": 908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.75, \"learn_time_ms\": 9292.902}", "{\"n\": 909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 9302.046}", "{\"n\": 910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.19, \"learn_time_ms\": 9306.908}", "{\"n\": 911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.37, \"learn_time_ms\": 9294.78}", "{\"n\": 912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.35, \"learn_time_ms\": 9299.947}", "{\"n\": 913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.55, \"learn_time_ms\": 9267.435}", "{\"n\": 914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.34, \"learn_time_ms\": 9280.013}", "{\"n\": 915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.35, \"learn_time_ms\": 9289.062}", "{\"n\": 916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.06, \"learn_time_ms\": 9300.554}", "{\"n\": 917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.86, \"learn_time_ms\": 9288.626}", "{\"n\": 918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.11, \"learn_time_ms\": 9297.651}", "{\"n\": 919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 9290.766}", "{\"n\": 920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.48, \"learn_time_ms\": 9288.692}", "{\"n\": 921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 9297.164}", "{\"n\": 922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34, \"learn_time_ms\": 9292.166}", "{\"n\": 923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 9289.474}", "{\"n\": 924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 9289.572}", "{\"n\": 925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.76, \"learn_time_ms\": 9279.876}", "{\"n\": 926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.51, \"learn_time_ms\": 9267.813}", "{\"n\": 927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 9279.106}", "{\"n\": 928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.18, \"learn_time_ms\": 9279.742}", "{\"n\": 929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.97, \"learn_time_ms\": 9281.391}", "{\"n\": 930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.84, \"learn_time_ms\": 9301.766}", "{\"n\": 931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.85, \"learn_time_ms\": 9320.721}", "{\"n\": 932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.06, \"learn_time_ms\": 9342.915}", "{\"n\": 933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.4, \"learn_time_ms\": 9354.749}", "{\"n\": 934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.06, \"learn_time_ms\": 9355.947}", "{\"n\": 935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.54, \"learn_time_ms\": 9353.693}", "{\"n\": 936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 9369.097}", "{\"n\": 937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.97, \"learn_time_ms\": 9374.333}", "{\"n\": 938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.4, \"learn_time_ms\": 9373.151}", "{\"n\": 939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.23, \"learn_time_ms\": 9361.88}", "{\"n\": 940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.25, \"learn_time_ms\": 9350.399}", "{\"n\": 941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.24, \"learn_time_ms\": 9343.279}", "{\"n\": 942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.08, \"learn_time_ms\": 9332.447}", "{\"n\": 943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 9322.359}", "{\"n\": 944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.6, \"learn_time_ms\": 9318.867}", "{\"n\": 945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.71, \"learn_time_ms\": 9324.108}", "{\"n\": 946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 9307.206}", "{\"n\": 947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.47, \"learn_time_ms\": 9298.492}", "{\"n\": 948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.11, \"learn_time_ms\": 9298.564}", "{\"n\": 949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.22, \"learn_time_ms\": 9315.728}", "{\"n\": 950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.83, \"learn_time_ms\": 9332.699}", "{\"n\": 951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.52, \"learn_time_ms\": 9338.679}", "{\"n\": 952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 9328.325}", "{\"n\": 953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.57, \"learn_time_ms\": 9331.185}", "{\"n\": 954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34, \"learn_time_ms\": 9337.877}", "{\"n\": 955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.83, \"learn_time_ms\": 9336.405}", "{\"n\": 956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.29, \"learn_time_ms\": 9335.137}", "{\"n\": 957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.35, \"learn_time_ms\": 9336.255}", "{\"n\": 958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.16, \"learn_time_ms\": 9331.151}", "{\"n\": 959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.07, \"learn_time_ms\": 9333.147}", "{\"n\": 960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.45, \"learn_time_ms\": 9318.145}", "{\"n\": 961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.64, \"learn_time_ms\": 9312.205}", "{\"n\": 962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.53, \"learn_time_ms\": 9305.795}", "{\"n\": 963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.2, \"learn_time_ms\": 9301.146}", "{\"n\": 964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.15, \"learn_time_ms\": 9296.048}", "{\"n\": 965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.01, \"learn_time_ms\": 9289.803}", "{\"n\": 966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.53, \"learn_time_ms\": 9292.027}", "{\"n\": 967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.39, \"learn_time_ms\": 9277.466}", "{\"n\": 968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 9280.512}", "{\"n\": 969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.68, \"learn_time_ms\": 9257.491}", "{\"n\": 970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.66, \"learn_time_ms\": 9250.079}", "{\"n\": 971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 9238.144}", "{\"n\": 972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 9252.527}", "{\"n\": 973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 9251.893}", "{\"n\": 974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 9256.606}", "{\"n\": 975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 9264.338}", "{\"n\": 976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 9275.718}", "{\"n\": 977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.53, \"learn_time_ms\": 9292.829}", "{\"n\": 978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.02, \"learn_time_ms\": 9288.342}", "{\"n\": 979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.91, \"learn_time_ms\": 9308.308}", "{\"n\": 980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.01, \"learn_time_ms\": 9316.382}", "{\"n\": 981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.65, \"learn_time_ms\": 9327.794}", "{\"n\": 982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.67, \"learn_time_ms\": 9327.781}", "{\"n\": 983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.91, \"learn_time_ms\": 9337.599}", "{\"n\": 984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.47, \"learn_time_ms\": 9336.535}", "{\"n\": 985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.6, \"learn_time_ms\": 9336.657}", "{\"n\": 986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.27, \"learn_time_ms\": 9330.185}", "{\"n\": 987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.99, \"learn_time_ms\": 9342.348}", "{\"n\": 988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.88, \"learn_time_ms\": 9352.701}", "{\"n\": 989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.72, \"learn_time_ms\": 9349.247}", "{\"n\": 990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.91, \"learn_time_ms\": 9352.571}", "{\"n\": 991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.76, \"learn_time_ms\": 9358.024}", "{\"n\": 992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.97, \"learn_time_ms\": 9364.071}", "{\"n\": 993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.14, \"learn_time_ms\": 9373.473}", "{\"n\": 994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.11, \"learn_time_ms\": 9370.745}", "{\"n\": 995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.47, \"learn_time_ms\": 9379.527}", "{\"n\": 996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.51, \"learn_time_ms\": 9380.598}", "{\"n\": 997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.93, \"learn_time_ms\": 9393.54}", "{\"n\": 998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 9398.326}", "{\"n\": 999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.54, \"learn_time_ms\": 9399.928}", "{\"n\": 1000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 9404.269}"]["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 40156.418}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27181.009}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 22871.92}", "{\"n\": 4, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 20702.782}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1014.0, \"learn_time_ms\": 19392.64}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.9375, \"learn_time_ms\": 18536.726}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.9375, \"learn_time_ms\": 17933.421}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.892857142857142, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.0, \"learn_time_ms\": 17454.656}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.0625, \"learn_time_ms\": 17092.396}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.0625, \"learn_time_ms\": 16799.035}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.708333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1064.3541666666667, \"learn_time_ms\": 14201.919}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.708333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1064.3541666666667, \"learn_time_ms\": 14203.617}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1064.0, \"learn_time_ms\": 14213.898}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1073.59375, \"learn_time_ms\": 14220.304}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1073.59375, \"learn_time_ms\": 14233.995}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.635135135135137, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1075.8783783783783, \"learn_time_ms\": 14239.76}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6125, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1078.375, \"learn_time_ms\": 14228.869}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6125, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1078.375, \"learn_time_ms\": 14240.747}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.595744680851062, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1081.776595744681, \"learn_time_ms\": 14253.51}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1082.8229166666667, \"learn_time_ms\": 14290.257}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1082.8229166666667, \"learn_time_ms\": 14306.511}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1093.05, \"learn_time_ms\": 14315.658}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1094.34, \"learn_time_ms\": 14313.381}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1097.14, \"learn_time_ms\": 14313.072}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1106.31, \"learn_time_ms\": 14309.59}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1108.98, \"learn_time_ms\": 14297.647}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1108.64, \"learn_time_ms\": 14313.438}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1112.66, \"learn_time_ms\": 14325.693}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1111.71, \"learn_time_ms\": 14319.302}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1113.15, \"learn_time_ms\": 14293.06}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1113.38, \"learn_time_ms\": 14287.386}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1112.6, \"learn_time_ms\": 14289.879}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1116.05, \"learn_time_ms\": 14285.834}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.24, \"learn_time_ms\": 14299.388}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.28, \"learn_time_ms\": 14303.814}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1122.02, \"learn_time_ms\": 14302.903}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1122.67, \"learn_time_ms\": 14304.672}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1123.79, \"learn_time_ms\": 14298.204}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.39, \"learn_time_ms\": 14307.13}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.12, \"learn_time_ms\": 14311.107}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.93, \"learn_time_ms\": 14317.288}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.41, \"learn_time_ms\": 14313.467}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.01, \"learn_time_ms\": 14309.879}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.14, \"learn_time_ms\": 14299.442}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.62, \"learn_time_ms\": 14305.491}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.99, \"learn_time_ms\": 14317.14}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.13, \"learn_time_ms\": 14316.396}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1123.43, \"learn_time_ms\": 14327.329}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1122.99, \"learn_time_ms\": 14328.218}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1127.01, \"learn_time_ms\": 14325.881}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1127.07, \"learn_time_ms\": 14323.362}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1124.26, \"learn_time_ms\": 14344.129}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.87, \"learn_time_ms\": 14353.154}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.95, \"learn_time_ms\": 14365.791}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1123.67, \"learn_time_ms\": 14361.87}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1125.54, \"learn_time_ms\": 14365.849}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1128.55, \"learn_time_ms\": 14354.437}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1132.93, \"learn_time_ms\": 14339.012}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1134.89, \"learn_time_ms\": 14343.154}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1135.44, \"learn_time_ms\": 14338.812}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1134.69, \"learn_time_ms\": 14326.232}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1133.6, \"learn_time_ms\": 14294.283}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1136.19, \"learn_time_ms\": 14282.041}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1135.75, \"learn_time_ms\": 14267.187}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1132.65, \"learn_time_ms\": 14254.157}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1132.65, \"learn_time_ms\": 14239.711}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1138.53, \"learn_time_ms\": 14236.344}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1133.58, \"learn_time_ms\": 14233.284}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1138.01, \"learn_time_ms\": 14212.062}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1147.04, \"learn_time_ms\": 14201.774}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1148.95, \"learn_time_ms\": 14206.156}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1155.33, \"learn_time_ms\": 14205.364}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1163.6, \"learn_time_ms\": 14198.347}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1161.85, \"learn_time_ms\": 14188.845}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1161.05, \"learn_time_ms\": 14190.701}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1165.43, \"learn_time_ms\": 14190.26}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1167.81, \"learn_time_ms\": 14196.352}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1168.71, \"learn_time_ms\": 14204.989}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1174.96, \"learn_time_ms\": 14214.754}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1174.67, \"learn_time_ms\": 14224.771}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1173.54, \"learn_time_ms\": 14228.165}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1177.38, \"learn_time_ms\": 14232.874}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1181.26, \"learn_time_ms\": 14238.518}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1181.55, \"learn_time_ms\": 14239.553}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1184.13, \"learn_time_ms\": 14241.759}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1179.98, \"learn_time_ms\": 14238.049}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1172.72, \"learn_time_ms\": 14227.944}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1171.5, \"learn_time_ms\": 14216.43}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1172.4, \"learn_time_ms\": 14212.302}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1164.99, \"learn_time_ms\": 14212.483}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1164.29, \"learn_time_ms\": 14208.513}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1162.78, \"learn_time_ms\": 14211.042}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1165.95, \"learn_time_ms\": 14209.89}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1174.42, \"learn_time_ms\": 14209.695}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1171.91, \"learn_time_ms\": 14211.216}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1174.03, \"learn_time_ms\": 14223.621}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1173.38, \"learn_time_ms\": 14226.816}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.82, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1169.66, \"learn_time_ms\": 14232.66}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1171.37, \"learn_time_ms\": 14233.213}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1175.72, \"learn_time_ms\": 14230.721}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1170.48, \"learn_time_ms\": 14236.383}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1175.72, \"learn_time_ms\": 14244.158}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1176.26, \"learn_time_ms\": 14253.806}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1176.91, \"learn_time_ms\": 14274.519}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1175.49, \"learn_time_ms\": 14275.377}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1179.39, \"learn_time_ms\": 14276.933}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1176.89, \"learn_time_ms\": 14280.543}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1184.39, \"learn_time_ms\": 14285.514}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1180.6, \"learn_time_ms\": 14294.371}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1185.63, \"learn_time_ms\": 14293.424}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1187.97, \"learn_time_ms\": 14295.27}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1180.69, \"learn_time_ms\": 14287.124}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1179.44, \"learn_time_ms\": 14274.947}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1182.86, \"learn_time_ms\": 14248.016}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1187.5, \"learn_time_ms\": 14249.535}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1189.35, \"learn_time_ms\": 14243.653}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1191.01, \"learn_time_ms\": 14230.721}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1191.35, \"learn_time_ms\": 14223.365}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1190.12, \"learn_time_ms\": 14215.852}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1197.85, \"learn_time_ms\": 14229.239}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1198.69, \"learn_time_ms\": 14211.218}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1202.71, \"learn_time_ms\": 14198.94}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1205.29, \"learn_time_ms\": 14197.546}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1218.68, \"learn_time_ms\": 14207.125}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1216.14, \"learn_time_ms\": 14187.799}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1213.6, \"learn_time_ms\": 14186.408}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1210.78, \"learn_time_ms\": 14192.488}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1213.31, \"learn_time_ms\": 14189.432}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1215.69, \"learn_time_ms\": 14182.894}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1224.61, \"learn_time_ms\": 14162.98}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1223.25, \"learn_time_ms\": 14178.748}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1225.03, \"learn_time_ms\": 14185.261}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1218.47, \"learn_time_ms\": 14185.84}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1216.45, \"learn_time_ms\": 14176.066}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1222.55, \"learn_time_ms\": 14183.58}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1228.61, \"learn_time_ms\": 14167.197}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1228.02, \"learn_time_ms\": 14163.574}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1241.82, \"learn_time_ms\": 14180.552}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1238.4, \"learn_time_ms\": 14187.813}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1245.45, \"learn_time_ms\": 14207.347}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1237.53, \"learn_time_ms\": 14196.253}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1243.02, \"learn_time_ms\": 14201.717}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1242.59, \"learn_time_ms\": 14207.931}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1245.1, \"learn_time_ms\": 14233.081}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1251.13, \"learn_time_ms\": 14241.782}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1255.67, \"learn_time_ms\": 14268.872}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1256.62, \"learn_time_ms\": 14285.005}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1257.88, \"learn_time_ms\": 14278.808}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1258.27, \"learn_time_ms\": 14276.222}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1261.68, \"learn_time_ms\": 14271.784}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1268.47, \"learn_time_ms\": 14289.796}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1283.59, \"learn_time_ms\": 14297.716}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1283.06, \"learn_time_ms\": 14293.308}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1284.38, \"learn_time_ms\": 14284.86}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1282.77, \"learn_time_ms\": 14290.754}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1284.21, \"learn_time_ms\": 14270.352}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1286.63, \"learn_time_ms\": 14246.754}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1285.81, \"learn_time_ms\": 14226.684}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1283.7, \"learn_time_ms\": 14222.605}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1286.03, \"learn_time_ms\": 14215.524}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1285.66, \"learn_time_ms\": 14197.507}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1297.67, \"learn_time_ms\": 14186.226}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1302.21, \"learn_time_ms\": 14198.562}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1298.01, \"learn_time_ms\": 14190.176}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1298.56, \"learn_time_ms\": 14187.533}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1295.23, \"learn_time_ms\": 14200.05}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1294.59, \"learn_time_ms\": 14205.405}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1307.27, \"learn_time_ms\": 14218.592}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1309.82, \"learn_time_ms\": 14198.179}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1303.13, \"learn_time_ms\": 14203.686}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1301.17, \"learn_time_ms\": 14210.626}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1299.21, \"learn_time_ms\": 14213.476}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1297.61, \"learn_time_ms\": 14216.581}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1301.84, \"learn_time_ms\": 14222.192}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1306.55, \"learn_time_ms\": 14230.443}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1304.85, \"learn_time_ms\": 14245.961}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.35, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1322.31, \"learn_time_ms\": 14260.061}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1325.15, \"learn_time_ms\": 14262.969}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1324.25, \"learn_time_ms\": 14299.269}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1327.82, \"learn_time_ms\": 14297.654}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1327.56, \"learn_time_ms\": 14300.121}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.35, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1332.43, \"learn_time_ms\": 14289.42}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1330.33, \"learn_time_ms\": 14280.335}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1323.44, \"learn_time_ms\": 14265.348}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.35, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1336.08, \"learn_time_ms\": 14246.064}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1342.68, \"learn_time_ms\": 14226.964}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1355.01, \"learn_time_ms\": 14208.453}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1361.41, \"learn_time_ms\": 14196.406}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1377.55, \"learn_time_ms\": 14182.958}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.23, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1379.94, \"learn_time_ms\": 14178.758}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.23, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1381.8, \"learn_time_ms\": 14171.642}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.21, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1396.25, \"learn_time_ms\": 14198.151}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.21, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1411.72, \"learn_time_ms\": 14207.301}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1416.49, \"learn_time_ms\": 14244.927}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.19, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1432.43, \"learn_time_ms\": 14254.272}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1434.06, \"learn_time_ms\": 14273.93}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1436.8, \"learn_time_ms\": 14311.513}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1436.54, \"learn_time_ms\": 14343.207}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.21, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1454.33, \"learn_time_ms\": 14348.902}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.18, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1457.37, \"learn_time_ms\": 14379.171}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1455.41, \"learn_time_ms\": 14410.491}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1463.27, \"learn_time_ms\": 14410.652}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1467.63, \"learn_time_ms\": 14407.61}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1473.47, \"learn_time_ms\": 14378.736}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1480.17, \"learn_time_ms\": 14386.703}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1483.05, \"learn_time_ms\": 14369.054}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1487.17, \"learn_time_ms\": 14336.68}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.06, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1485.31, \"learn_time_ms\": 14323.749}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.03, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1493.55, \"learn_time_ms\": 14325.411}", "{\"n\": 210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.01, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1490.7, \"learn_time_ms\": 14293.163}", "{\"n\": 211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.04, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1507.5, \"learn_time_ms\": 14274.067}", "{\"n\": 212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.07, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1507.46, \"learn_time_ms\": 14261.263}", "{\"n\": 213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1513.5, \"learn_time_ms\": 14262.958}", "{\"n\": 214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.03, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1526.94, \"learn_time_ms\": 14277.259}", "{\"n\": 215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1536.55, \"learn_time_ms\": 14279.957}", "{\"n\": 216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.98, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1532.12, \"learn_time_ms\": 14280.199}", "{\"n\": 217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.94, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1536.25, \"learn_time_ms\": 14293.895}", "{\"n\": 218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.92, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1529.8, \"learn_time_ms\": 14280.804}", "{\"n\": 219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1534.72, \"learn_time_ms\": 14287.962}", "{\"n\": 220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1546.38, \"learn_time_ms\": 14304.357}", "{\"n\": 221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1545.91, \"learn_time_ms\": 14300.244}", "{\"n\": 222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1560.85, \"learn_time_ms\": 14288.52}", "{\"n\": 223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.77, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1562.9, \"learn_time_ms\": 14291.023}", "{\"n\": 224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1564.67, \"learn_time_ms\": 14277.991}", "{\"n\": 225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1575.8, \"learn_time_ms\": 14269.884}", "{\"n\": 226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1582.01, \"learn_time_ms\": 14274.444}", "{\"n\": 227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1592.44, \"learn_time_ms\": 14279.64}", "{\"n\": 228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1608.21, \"learn_time_ms\": 14290.472}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.7, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1612.58, \"learn_time_ms\": 14276.063}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.71, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1628.57, \"learn_time_ms\": 14279.86}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.69, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1625.54, \"learn_time_ms\": 14275.969}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.64, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1648.22, \"learn_time_ms\": 14285.334}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.63, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1652.31, \"learn_time_ms\": 14266.948}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.6, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1661.05, \"learn_time_ms\": 14266.968}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.61, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1668.39, \"learn_time_ms\": 14251.085}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.62, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1684.36, \"learn_time_ms\": 14239.339}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.61, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1688.74, \"learn_time_ms\": 14214.23}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.63, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1688.17, \"learn_time_ms\": 14207.727}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.64, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1691.9, \"learn_time_ms\": 14205.035}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.55, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1713.44, \"learn_time_ms\": 14193.506}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.51, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1714.74, \"learn_time_ms\": 14206.996}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.52, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1712.75, \"learn_time_ms\": 14210.249}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.51, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1723.13, \"learn_time_ms\": 14219.905}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.53, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1731.18, \"learn_time_ms\": 14249.748}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1740.46, \"learn_time_ms\": 14269.337}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1746.52, \"learn_time_ms\": 14280.116}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.51, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1752.69, \"learn_time_ms\": 14299.118}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1752.47, \"learn_time_ms\": 14313.044}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.51, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1767.45, \"learn_time_ms\": 14335.385}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.53, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1777.54, \"learn_time_ms\": 14341.65}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.56, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1777.24, \"learn_time_ms\": 14331.755}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.55, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1793.68, \"learn_time_ms\": 14332.216}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.52, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1795.72, \"learn_time_ms\": 14319.578}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.47, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1806.2, \"learn_time_ms\": 14291.195}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1818.71, \"learn_time_ms\": 14288.197}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1816.63, \"learn_time_ms\": 14300.027}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1812.39, \"learn_time_ms\": 14301.865}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1820.36, \"learn_time_ms\": 14289.364}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.51, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1816.79, \"learn_time_ms\": 14282.632}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.46, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1823.04, \"learn_time_ms\": 14274.86}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.47, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1819.37, \"learn_time_ms\": 14271.14}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1834.13, \"learn_time_ms\": 14271.774}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.43, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1842.02, \"learn_time_ms\": 14285.144}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.36, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1848.77, \"learn_time_ms\": 14290.948}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.37, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1846.72, \"learn_time_ms\": 14296.718}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.29, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1866.02, \"learn_time_ms\": 14280.968}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1874.67, \"learn_time_ms\": 14268.692}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.26, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1879.77, \"learn_time_ms\": 14257.379}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1886.43, \"learn_time_ms\": 14231.271}", "{\"n\": 270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1882.87, \"learn_time_ms\": 14209.601}", "{\"n\": 271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1880.27, \"learn_time_ms\": 14196.222}", "{\"n\": 272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1897.61, \"learn_time_ms\": 14180.58}", "{\"n\": 273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1904.12, \"learn_time_ms\": 14154.05}", "{\"n\": 274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1919.39, \"learn_time_ms\": 14135.112}", "{\"n\": 275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1929.74, \"learn_time_ms\": 14128.289}", "{\"n\": 276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.09, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1930.88, \"learn_time_ms\": 14123.32}", "{\"n\": 277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.07, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1931.08, \"learn_time_ms\": 14126.591}", "{\"n\": 278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1935.69, \"learn_time_ms\": 14114.814}", "{\"n\": 279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1942.21, \"learn_time_ms\": 14118.707}", "{\"n\": 280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1974.36, \"learn_time_ms\": 14128.15}", "{\"n\": 281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1974.36, \"learn_time_ms\": 14139.019}", "{\"n\": 282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.92, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1977.45, \"learn_time_ms\": 14152.17}", "{\"n\": 283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.92, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1977.45, \"learn_time_ms\": 14177.986}", "{\"n\": 284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.92, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1978.26, \"learn_time_ms\": 14200.878}", "{\"n\": 285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1978.21, \"learn_time_ms\": 14199.673}", "{\"n\": 286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.96, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1974.91, \"learn_time_ms\": 14223.845}", "{\"n\": 287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.96, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1980.78, \"learn_time_ms\": 14240.163}", "{\"n\": 288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1995.85, \"learn_time_ms\": 14276.041}", "{\"n\": 289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2007.43, \"learn_time_ms\": 14278.71}", "{\"n\": 290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2031.69, \"learn_time_ms\": 14291.556}", "{\"n\": 291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2032.26, \"learn_time_ms\": 14299.337}", "{\"n\": 292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2039.08, \"learn_time_ms\": 14290.662}", "{\"n\": 293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2054.54, \"learn_time_ms\": 14303.557}", "{\"n\": 294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2060.22, \"learn_time_ms\": 14296.626}", "{\"n\": 295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2065.68, \"learn_time_ms\": 14306.734}", "{\"n\": 296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2068.29, \"learn_time_ms\": 14280.775}", "{\"n\": 297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2081.14, \"learn_time_ms\": 14275.409}", "{\"n\": 298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.58, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2093.39, \"learn_time_ms\": 14257.528}", "{\"n\": 299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2094.21, \"learn_time_ms\": 14270.5}", "{\"n\": 300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2106.38, \"learn_time_ms\": 14272.98}", "{\"n\": 301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2113.35, \"learn_time_ms\": 14269.853}", "{\"n\": 302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2123.97, \"learn_time_ms\": 14287.724}", "{\"n\": 303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.42, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2119.57, \"learn_time_ms\": 14284.027}", "{\"n\": 304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2131.77, \"learn_time_ms\": 14287.979}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.46, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2132.88, \"learn_time_ms\": 14284.037}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.45, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2133.57, \"learn_time_ms\": 14299.287}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2125.49, \"learn_time_ms\": 14297.649}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2140.53, \"learn_time_ms\": 14302.294}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.46, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2145.11, \"learn_time_ms\": 14299.337}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2148.4, \"learn_time_ms\": 14299.986}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2153.01, \"learn_time_ms\": 14306.689}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2163.01, \"learn_time_ms\": 14289.433}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2180.88, \"learn_time_ms\": 14285.791}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.45, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2180.55, \"learn_time_ms\": 14276.684}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2185.89, \"learn_time_ms\": 14260.395}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2189.07, \"learn_time_ms\": 14249.575}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2187.35, \"learn_time_ms\": 14252.065}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.46, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2188.04, \"learn_time_ms\": 14251.023}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.45, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2186.82, \"learn_time_ms\": 14253.002}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2189.06, \"learn_time_ms\": 14244.626}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.42, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2196.16, \"learn_time_ms\": 14230.948}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.46, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2197.71, \"learn_time_ms\": 14239.174}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2199.09, \"learn_time_ms\": 14237.843}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.49, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2216.33, \"learn_time_ms\": 14251.424}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2214.13, \"learn_time_ms\": 14263.435}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2225.06, \"learn_time_ms\": 14257.071}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2218.73, \"learn_time_ms\": 14255.4}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.45, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2220.46, \"learn_time_ms\": 14268.415}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2219.51, \"learn_time_ms\": 14264.043}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2221.81, \"learn_time_ms\": 14270.264}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.53, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2209.33, \"learn_time_ms\": 14291.541}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.61, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2195.99, \"learn_time_ms\": 14280.364}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2180.51, \"learn_time_ms\": 14267.876}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2177.33, \"learn_time_ms\": 14259.148}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2177.17, \"learn_time_ms\": 14249.195}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2178.5, \"learn_time_ms\": 14262.143}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2171.38, \"learn_time_ms\": 14250.899}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2165.01, \"learn_time_ms\": 14251.115}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2168.99, \"learn_time_ms\": 14250.834}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2171.6, \"learn_time_ms\": 14252.762}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2170.8, \"learn_time_ms\": 14242.563}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2170.8, \"learn_time_ms\": 14249.765}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.64, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2185.5, \"learn_time_ms\": 14258.741}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2182.38, \"learn_time_ms\": 14249.197}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2189.54, \"learn_time_ms\": 14242.816}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2185.7, \"learn_time_ms\": 14248.016}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2185.6, \"learn_time_ms\": 14266.907}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2185.6, \"learn_time_ms\": 14251.25}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2188.42, \"learn_time_ms\": 14244.236}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2187.23, \"learn_time_ms\": 14238.611}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2192.46, \"learn_time_ms\": 14240.351}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2211.93, \"learn_time_ms\": 14249.011}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2211.93, \"learn_time_ms\": 14257.996}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.46, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2222.11, \"learn_time_ms\": 14273.727}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2225.37, \"learn_time_ms\": 14292.001}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2241.22, \"learn_time_ms\": 14299.259}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2247.69, \"learn_time_ms\": 14290.525}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2250.04, \"learn_time_ms\": 14282.563}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2246.64, \"learn_time_ms\": 14284.567}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.35, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2252.04, \"learn_time_ms\": 14275.381}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.35, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2253.2, \"learn_time_ms\": 14249.381}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2256.26, \"learn_time_ms\": 14227.499}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2257.59, \"learn_time_ms\": 14207.611}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.38, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2266.23, \"learn_time_ms\": 14190.369}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.38, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2266.23, \"learn_time_ms\": 14168.95}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2285.12, \"learn_time_ms\": 14152.179}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2289.3, \"learn_time_ms\": 14134.845}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2316.84, \"learn_time_ms\": 14124.532}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2333.37, \"learn_time_ms\": 14123.313}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2351.83, \"learn_time_ms\": 14126.693}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.09, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2362.56, \"learn_time_ms\": 14144.735}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2363.06, \"learn_time_ms\": 14157.445}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.08, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2362.1, \"learn_time_ms\": 14167.095}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.06, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2366.35, \"learn_time_ms\": 14161.516}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2383.54, \"learn_time_ms\": 14184.972}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.88, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2410.95, \"learn_time_ms\": 14198.762}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.86, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2419.9, \"learn_time_ms\": 14215.551}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.81, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2434.43, \"learn_time_ms\": 14242.724}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.81, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2434.43, \"learn_time_ms\": 14248.726}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.86, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2436.34, \"learn_time_ms\": 14257.677}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.85, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2442.66, \"learn_time_ms\": 14256.942}", "{\"n\": 382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.77, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2453.16, \"learn_time_ms\": 14256.069}", "{\"n\": 383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.79, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2450.57, \"learn_time_ms\": 14272.032}", "{\"n\": 384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.79, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2450.57, \"learn_time_ms\": 14302.31}", "{\"n\": 385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.7, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2459.48, \"learn_time_ms\": 14288.232}", "{\"n\": 386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2452.67, \"learn_time_ms\": 14280.782}", "{\"n\": 387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.72, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2457.54, \"learn_time_ms\": 14270.842}", "{\"n\": 388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2476.89, \"learn_time_ms\": 14260.353}", "{\"n\": 389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2484.89, \"learn_time_ms\": 14268.89}", "{\"n\": 390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2481.33, \"learn_time_ms\": 14269.82}", "{\"n\": 391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2475.18, \"learn_time_ms\": 14279.385}", "{\"n\": 392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.7, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2480.13, \"learn_time_ms\": 14288.82}", "{\"n\": 393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2475.22, \"learn_time_ms\": 14264.842}", "{\"n\": 394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2475.74, \"learn_time_ms\": 14251.08}", "{\"n\": 395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2466.66, \"learn_time_ms\": 14248.826}", "{\"n\": 396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2461.71, \"learn_time_ms\": 14253.316}", "{\"n\": 397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2451.74, \"learn_time_ms\": 14252.387}", "{\"n\": 398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.64, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2454.67, \"learn_time_ms\": 14258.64}", "{\"n\": 399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.64, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2454.67, \"learn_time_ms\": 14244.624}", "{\"n\": 400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2455.81, \"learn_time_ms\": 14217.574}", "{\"n\": 401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2455.53, \"learn_time_ms\": 14202.037}", "{\"n\": 402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2455.53, \"learn_time_ms\": 14194.613}", "{\"n\": 403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2447.49, \"learn_time_ms\": 14191.256}", "{\"n\": 404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2448.22, \"learn_time_ms\": 14188.579}", "{\"n\": 405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2448.22, \"learn_time_ms\": 14190.844}", "{\"n\": 406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.52, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2448.8, \"learn_time_ms\": 14158.379}", "{\"n\": 407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2448.27, \"learn_time_ms\": 14151.862}", "{\"n\": 408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2448.27, \"learn_time_ms\": 14144.82}", "{\"n\": 409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.51, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2450.62, \"learn_time_ms\": 14153.026}", "{\"n\": 410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.51, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2450.62, \"learn_time_ms\": 14162.067}", "{\"n\": 411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2452.04, \"learn_time_ms\": 14163.011}", "{\"n\": 412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.55, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2453.04, \"learn_time_ms\": 14157.411}", "{\"n\": 413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2450.32, \"learn_time_ms\": 14158.875}", "{\"n\": 414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2435.59, \"learn_time_ms\": 14152.622}", "{\"n\": 415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.68, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2433.74, \"learn_time_ms\": 14141.71}", "{\"n\": 416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2434.55, \"learn_time_ms\": 14159.849}", "{\"n\": 417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2434.92, \"learn_time_ms\": 14173.427}", "{\"n\": 418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2434.92, \"learn_time_ms\": 14158.761}", "{\"n\": 419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2433.46, \"learn_time_ms\": 14144.104}", "{\"n\": 420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2430.28, \"learn_time_ms\": 14136.385}", "{\"n\": 421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2437.91, \"learn_time_ms\": 14119.417}", "{\"n\": 422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2444.4, \"learn_time_ms\": 14118.44}", "{\"n\": 423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2442.18, \"learn_time_ms\": 14120.139}", "{\"n\": 424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2432.87, \"learn_time_ms\": 14123.936}", "{\"n\": 425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2432.08, \"learn_time_ms\": 14128.534}", "{\"n\": 426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2433.18, \"learn_time_ms\": 14130.746}", "{\"n\": 427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2430.64, \"learn_time_ms\": 14120.511}", "{\"n\": 428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2423.85, \"learn_time_ms\": 14133.927}", "{\"n\": 429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2419.24, \"learn_time_ms\": 14148.562}", "{\"n\": 430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2430.86, \"learn_time_ms\": 14155.12}", "{\"n\": 431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2430.86, \"learn_time_ms\": 14159.99}", "{\"n\": 432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2423.63, \"learn_time_ms\": 14152.553}", "{\"n\": 433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2422.96, \"learn_time_ms\": 14138.442}", "{\"n\": 434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2434.81, \"learn_time_ms\": 14125.738}", "{\"n\": 435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.68, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2434.69, \"learn_time_ms\": 14135.348}", "{\"n\": 436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2456.47, \"learn_time_ms\": 14131.159}", "{\"n\": 437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2456.47, \"learn_time_ms\": 14135.396}", "{\"n\": 438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2457.54, \"learn_time_ms\": 14145.816}", "{\"n\": 439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2458.16, \"learn_time_ms\": 14156.895}", "{\"n\": 440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2462.84, \"learn_time_ms\": 14172.617}", "{\"n\": 441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2473.23, \"learn_time_ms\": 14188.428}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.52, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2477.29, \"learn_time_ms\": 14210.158}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2477.51, \"learn_time_ms\": 14224.149}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2477.51, \"learn_time_ms\": 14237.969}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2486.33, \"learn_time_ms\": 14240.343}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2483.8, \"learn_time_ms\": 14236.797}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2485.03, \"learn_time_ms\": 14237.703}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2488.08, \"learn_time_ms\": 14240.16}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2499.82, \"learn_time_ms\": 14227.611}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2499.82, \"learn_time_ms\": 14219.002}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.22, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2499.46, \"learn_time_ms\": 14221.578}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.22, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2494.65, \"learn_time_ms\": 14211.695}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2487.05, \"learn_time_ms\": 14221.418}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2485.63, \"learn_time_ms\": 14219.997}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2484.26, \"learn_time_ms\": 14213.772}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2487.44, \"learn_time_ms\": 14213.891}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2481.25, \"learn_time_ms\": 14222.423}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2465.26, \"learn_time_ms\": 14223.538}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2470.91, \"learn_time_ms\": 14232.519}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2478.68, \"learn_time_ms\": 14255.406}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2476.59, \"learn_time_ms\": 14243.999}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.06, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2483.86, \"learn_time_ms\": 14253.373}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2489.75, \"learn_time_ms\": 14262.056}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.02, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2502.29, \"learn_time_ms\": 14269.609}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2503.85, \"learn_time_ms\": 14274.436}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2502.99, \"learn_time_ms\": 14273.734}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2506.83, \"learn_time_ms\": 14275.823}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2509.14, \"learn_time_ms\": 14275.479}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2530.74, \"learn_time_ms\": 14265.458}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2524.39, \"learn_time_ms\": 14255.701}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2524.39, \"learn_time_ms\": 14266.17}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2530.36, \"learn_time_ms\": 14257.215}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2537.75, \"learn_time_ms\": 14249.654}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2535.75, \"learn_time_ms\": 14255.918}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2541.74, \"learn_time_ms\": 14255.104}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2547.07, \"learn_time_ms\": 14267.348}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2547.07, \"learn_time_ms\": 14262.586}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2540.71, \"learn_time_ms\": 14251.002}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2541.85, \"learn_time_ms\": 14258.112}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2534.51, \"learn_time_ms\": 14238.026}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2525.13, \"learn_time_ms\": 14224.575}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2523.88, \"learn_time_ms\": 14231.324}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2534.55, \"learn_time_ms\": 14210.962}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2527.3, \"learn_time_ms\": 14198.431}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2511.42, \"learn_time_ms\": 14195.778}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.12, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2508.14, \"learn_time_ms\": 14183.224}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2501.82, \"learn_time_ms\": 14175.84}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2498.6, \"learn_time_ms\": 14172.886}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2508.26, \"learn_time_ms\": 14159.403}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2508.26, \"learn_time_ms\": 14175.636}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2504.23, \"learn_time_ms\": 14169.698}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2522.62, \"learn_time_ms\": 14164.123}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2521.69, \"learn_time_ms\": 14171.514}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2527.56, \"learn_time_ms\": 14186.032}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.31, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2533.11, \"learn_time_ms\": 14176.159}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.3, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2540.81, \"learn_time_ms\": 14171.895}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2555.29, \"learn_time_ms\": 14163.194}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2562.81, \"learn_time_ms\": 14156.952}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2562.81, \"learn_time_ms\": 14172.237}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2556.18, \"learn_time_ms\": 14165.985}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2563.56, \"learn_time_ms\": 14182.823}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.28, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2563.07, \"learn_time_ms\": 14173.499}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2563.27, \"learn_time_ms\": 14181.679}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2561.94, \"learn_time_ms\": 14182.871}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2556.09, \"learn_time_ms\": 14213.01}", "{\"n\": 506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2556.29, \"learn_time_ms\": 14238.316}", "{\"n\": 507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.12, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2560.59, \"learn_time_ms\": 14255.884}", "{\"n\": 508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.06, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2559.92, \"learn_time_ms\": 14278.076}", "{\"n\": 509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2548.93, \"learn_time_ms\": 14273.684}", "{\"n\": 510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2550.03, \"learn_time_ms\": 14281.359}", "{\"n\": 511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2558.68, \"learn_time_ms\": 14289.26}", "{\"n\": 512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.04, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2553.22, \"learn_time_ms\": 14295.379}", "{\"n\": 513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2552.27, \"learn_time_ms\": 14294.459}", "{\"n\": 514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2552.27, \"learn_time_ms\": 14282.298}", "{\"n\": 515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2557.66, \"learn_time_ms\": 14273.258}", "{\"n\": 516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2553.34, \"learn_time_ms\": 14269.39}", "{\"n\": 517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2543.46, \"learn_time_ms\": 14271.183}", "{\"n\": 518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2560.98, \"learn_time_ms\": 14258.86}", "{\"n\": 519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2558.16, \"learn_time_ms\": 14260.734}", "{\"n\": 520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2561.96, \"learn_time_ms\": 14253.46}", "{\"n\": 521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2566.48, \"learn_time_ms\": 14253.834}", "{\"n\": 522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2575.64, \"learn_time_ms\": 14261.67}", "{\"n\": 523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2572.01, \"learn_time_ms\": 14265.418}", "{\"n\": 524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2574.24, \"learn_time_ms\": 14254.189}", "{\"n\": 525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2574.24, \"learn_time_ms\": 14250.1}", "{\"n\": 526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2577.23, \"learn_time_ms\": 14224.312}", "{\"n\": 527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.52, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2578.57, \"learn_time_ms\": 14208.861}", "{\"n\": 528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2569.43, \"learn_time_ms\": 14202.282}", "{\"n\": 529, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2573.26, \"learn_time_ms\": 14202.253}", "{\"n\": 530, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.46, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2571.39, \"learn_time_ms\": 14193.864}", "{\"n\": 531, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2562.54, \"learn_time_ms\": 14187.24}", "{\"n\": 532, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2562.54, \"learn_time_ms\": 14185.893}", "{\"n\": 533, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2571.02, \"learn_time_ms\": 14195.824}", "{\"n\": 534, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2564.97, \"learn_time_ms\": 14209.026}", "{\"n\": 535, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.4, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2575.03, \"learn_time_ms\": 14210.508}", "{\"n\": 536, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2559.13, \"learn_time_ms\": 14238.612}", "{\"n\": 537, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2559.13, \"learn_time_ms\": 14255.434}", "{\"n\": 538, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2566.17, \"learn_time_ms\": 14268.398}", "{\"n\": 539, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2569.8, \"learn_time_ms\": 14259.215}", "{\"n\": 540, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2568.1, \"learn_time_ms\": 14272.787}", "{\"n\": 541, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2563.08, \"learn_time_ms\": 14279.646}", "{\"n\": 542, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2556.78, \"learn_time_ms\": 14281.521}", "{\"n\": 543, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2567.36, \"learn_time_ms\": 14271.813}", "{\"n\": 544, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2567.36, \"learn_time_ms\": 14273.199}", "{\"n\": 545, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2567.36, \"learn_time_ms\": 14259.934}", "{\"n\": 546, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2580.35, \"learn_time_ms\": 14262.024}", "{\"n\": 547, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2583.86, \"learn_time_ms\": 14251.499}", "{\"n\": 548, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2596.1, \"learn_time_ms\": 14254.438}", "{\"n\": 549, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2600.94, \"learn_time_ms\": 14258.751}", "{\"n\": 550, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2603.48, \"learn_time_ms\": 14250.444}", "{\"n\": 551, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2608.71, \"learn_time_ms\": 14248.867}", "{\"n\": 552, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2595.57, \"learn_time_ms\": 14247.786}", "{\"n\": 553, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2589.42, \"learn_time_ms\": 14247.889}", "{\"n\": 554, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2590.7, \"learn_time_ms\": 14233.597}", "{\"n\": 555, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2590.65, \"learn_time_ms\": 14239.497}", "{\"n\": 556, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.1, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2588.36, \"learn_time_ms\": 14225.225}", "{\"n\": 557, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2582.75, \"learn_time_ms\": 14230.412}", "{\"n\": 558, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2572.48, \"learn_time_ms\": 14225.231}", "{\"n\": 559, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2563.69, \"learn_time_ms\": 14234.94}", "{\"n\": 560, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2563.69, \"learn_time_ms\": 14247.452}", "{\"n\": 561, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2567.91, \"learn_time_ms\": 14242.39}", "{\"n\": 562, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2567.91, \"learn_time_ms\": 14238.432}", "{\"n\": 563, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2557.91, \"learn_time_ms\": 14224.236}", "{\"n\": 564, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2553.6, \"learn_time_ms\": 14240.407}", "{\"n\": 565, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2549.42, \"learn_time_ms\": 14259.371}", "{\"n\": 566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2542.02, \"learn_time_ms\": 14258.606}", "{\"n\": 567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2547.33, \"learn_time_ms\": 14263.102}", "{\"n\": 568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2565.28, \"learn_time_ms\": 14248.0}", "{\"n\": 569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.16, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2567.57, \"learn_time_ms\": 14237.292}", "{\"n\": 570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2569.28, \"learn_time_ms\": 14235.92}", "{\"n\": 571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.09, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2566.75, \"learn_time_ms\": 14244.269}", "{\"n\": 572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2571.61, \"learn_time_ms\": 14254.852}", "{\"n\": 573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2560.24, \"learn_time_ms\": 14279.112}", "{\"n\": 574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.1, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2557.07, \"learn_time_ms\": 14279.443}", "{\"n\": 575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2552.61, \"learn_time_ms\": 14273.682}", "{\"n\": 576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2560.61, \"learn_time_ms\": 14277.756}", "{\"n\": 577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2545.71, \"learn_time_ms\": 14281.848}", "{\"n\": 578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2537.31, \"learn_time_ms\": 14296.758}", "{\"n\": 579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2531.11, \"learn_time_ms\": 14297.579}", "{\"n\": 580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2531.57, \"learn_time_ms\": 14286.923}", "{\"n\": 581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2532.59, \"learn_time_ms\": 14284.547}", "{\"n\": 582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2523.07, \"learn_time_ms\": 14281.169}", "{\"n\": 583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2542.99, \"learn_time_ms\": 14273.832}", "{\"n\": 584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2531.87, \"learn_time_ms\": 14270.223}", "{\"n\": 585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2520.34, \"learn_time_ms\": 14262.189}", "{\"n\": 586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2517.24, \"learn_time_ms\": 14257.233}", "{\"n\": 587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2502.93, \"learn_time_ms\": 14254.524}", "{\"n\": 588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2494.72, \"learn_time_ms\": 14251.966}", "{\"n\": 589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2486.02, \"learn_time_ms\": 14252.165}", "{\"n\": 590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2483.06, \"learn_time_ms\": 14261.173}", "{\"n\": 591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2494.05, \"learn_time_ms\": 14262.085}", "{\"n\": 592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2495.69, \"learn_time_ms\": 14266.029}", "{\"n\": 593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2506.46, \"learn_time_ms\": 14260.105}", "{\"n\": 594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2501.19, \"learn_time_ms\": 14269.274}", "{\"n\": 595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2516.69, \"learn_time_ms\": 14268.892}", "{\"n\": 596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2506.67, \"learn_time_ms\": 14263.978}", "{\"n\": 597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2511.12, \"learn_time_ms\": 14246.186}", "{\"n\": 598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2509.12, \"learn_time_ms\": 14225.439}", "{\"n\": 599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2509.12, \"learn_time_ms\": 14222.045}", "{\"n\": 600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2514.01, \"learn_time_ms\": 14213.132}", "{\"n\": 601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2501.74, \"learn_time_ms\": 14199.95}", "{\"n\": 602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2504.01, \"learn_time_ms\": 14188.597}", "{\"n\": 603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2509.01, \"learn_time_ms\": 14174.273}", "{\"n\": 604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2503.66, \"learn_time_ms\": 14147.832}", "{\"n\": 605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2497.03, \"learn_time_ms\": 14140.132}", "{\"n\": 606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2501.97, \"learn_time_ms\": 14150.531}", "{\"n\": 607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2501.97, \"learn_time_ms\": 14151.056}", "{\"n\": 608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2504.83, \"learn_time_ms\": 14168.681}", "{\"n\": 609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2504.49, \"learn_time_ms\": 14164.004}", "{\"n\": 610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2502.59, \"learn_time_ms\": 14169.652}", "{\"n\": 611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2511.82, \"learn_time_ms\": 14159.339}", "{\"n\": 612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2512.35, \"learn_time_ms\": 14155.612}", "{\"n\": 613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2515.93, \"learn_time_ms\": 14174.882}", "{\"n\": 614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2527.62, \"learn_time_ms\": 14179.48}", "{\"n\": 615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2538.99, \"learn_time_ms\": 14193.256}", "{\"n\": 616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.06, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2555.77, \"learn_time_ms\": 14182.254}", "{\"n\": 617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.06, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2555.77, \"learn_time_ms\": 14172.862}", "{\"n\": 618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2563.2, \"learn_time_ms\": 14177.586}", "{\"n\": 619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2575.42, \"learn_time_ms\": 14171.357}", "{\"n\": 620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2582.91, \"learn_time_ms\": 14166.231}", "{\"n\": 621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.99, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2573.22, \"learn_time_ms\": 14179.68}", "{\"n\": 622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2565.14, \"learn_time_ms\": 14179.515}", "{\"n\": 623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2565.14, \"learn_time_ms\": 14167.023}", "{\"n\": 624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2569.73, \"learn_time_ms\": 14157.32}", "{\"n\": 625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2579.35, \"learn_time_ms\": 14138.74}", "{\"n\": 626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2583.99, \"learn_time_ms\": 14145.281}", "{\"n\": 627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2582.81, \"learn_time_ms\": 14159.001}", "{\"n\": 628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2587.95, \"learn_time_ms\": 14142.776}", "{\"n\": 629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2585.01, \"learn_time_ms\": 14149.565}", "{\"n\": 630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2583.47, \"learn_time_ms\": 14144.52}", "{\"n\": 631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2580.26, \"learn_time_ms\": 14139.002}", "{\"n\": 632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2578.31, \"learn_time_ms\": 14133.633}", "{\"n\": 633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2574.88, \"learn_time_ms\": 14143.363}", "{\"n\": 634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2580.29, \"learn_time_ms\": 14166.783}", "{\"n\": 635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2570.86, \"learn_time_ms\": 14173.019}", "{\"n\": 636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2566.55, \"learn_time_ms\": 14168.916}", "{\"n\": 637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2578.69, \"learn_time_ms\": 14171.318}", "{\"n\": 638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2578.69, \"learn_time_ms\": 14193.388}", "{\"n\": 639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2580.07, \"learn_time_ms\": 14199.59}", "{\"n\": 640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2593.94, \"learn_time_ms\": 14212.669}", "{\"n\": 641, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.81, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2600.13, \"learn_time_ms\": 14223.78}", "{\"n\": 642, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2611.68, \"learn_time_ms\": 14211.592}", "{\"n\": 643, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2616.5, \"learn_time_ms\": 14196.003}", "{\"n\": 644, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2621.65, \"learn_time_ms\": 14190.281}", "{\"n\": 645, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2621.65, \"learn_time_ms\": 14200.22}", "{\"n\": 646, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.65, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2639.13, \"learn_time_ms\": 14197.669}", "{\"n\": 647, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2630.54, \"learn_time_ms\": 14191.412}", "{\"n\": 648, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2624.02, \"learn_time_ms\": 14177.079}", "{\"n\": 649, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.74, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2616.83, \"learn_time_ms\": 14163.709}", "{\"n\": 650, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2621.37, \"learn_time_ms\": 14147.43}", "{\"n\": 651, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2622.45, \"learn_time_ms\": 14129.105}", "{\"n\": 652, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.69, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2629.18, \"learn_time_ms\": 14123.361}", "{\"n\": 653, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2613.11, \"learn_time_ms\": 14125.894}", "{\"n\": 654, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2613.1, \"learn_time_ms\": 14112.999}", "{\"n\": 655, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.74, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2611.57, \"learn_time_ms\": 14087.623}", "{\"n\": 656, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2621.07, \"learn_time_ms\": 14091.353}", "{\"n\": 657, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2621.94, \"learn_time_ms\": 14098.963}", "{\"n\": 658, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2613.59, \"learn_time_ms\": 14094.471}", "{\"n\": 659, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2623.66, \"learn_time_ms\": 14106.005}", "{\"n\": 660, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.66, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2611.97, \"learn_time_ms\": 14108.297}", "{\"n\": 661, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2612.44, \"learn_time_ms\": 14109.46}", "{\"n\": 662, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.57, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2616.35, \"learn_time_ms\": 14127.168}", "{\"n\": 663, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.54, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2622.18, \"learn_time_ms\": 14120.703}", "{\"n\": 664, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.52, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2617.75, \"learn_time_ms\": 14136.011}", "{\"n\": 665, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2633.26, \"learn_time_ms\": 14144.502}", "{\"n\": 666, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2634.23, \"learn_time_ms\": 14150.858}", "{\"n\": 667, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2644.16, \"learn_time_ms\": 14142.652}", "{\"n\": 668, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2641.77, \"learn_time_ms\": 14136.759}", "{\"n\": 669, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2668.62, \"learn_time_ms\": 14138.102}", "{\"n\": 670, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2675.87, \"learn_time_ms\": 14139.015}", "{\"n\": 671, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.26, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2678.73, \"learn_time_ms\": 14151.275}", "{\"n\": 672, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2683.87, \"learn_time_ms\": 14148.473}", "{\"n\": 673, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2687.82, \"learn_time_ms\": 14144.01}", "{\"n\": 674, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2691.28, \"learn_time_ms\": 14152.703}", "{\"n\": 675, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2697.22, \"learn_time_ms\": 14162.456}", "{\"n\": 676, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2711.77, \"learn_time_ms\": 14164.039}", "{\"n\": 677, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2715.2, \"learn_time_ms\": 14161.829}", "{\"n\": 678, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2729.73, \"learn_time_ms\": 14168.881}", "{\"n\": 679, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2738.54, \"learn_time_ms\": 14149.64}", "{\"n\": 680, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2739.5, \"learn_time_ms\": 14149.081}", "{\"n\": 681, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2750.18, \"learn_time_ms\": 14136.894}", "{\"n\": 682, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2750.18, \"learn_time_ms\": 14151.847}", "{\"n\": 683, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2750.67, \"learn_time_ms\": 14167.725}", "{\"n\": 684, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2757.82, \"learn_time_ms\": 14152.613}", "{\"n\": 685, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2754.51, \"learn_time_ms\": 14149.471}", "{\"n\": 686, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2755.08, \"learn_time_ms\": 14138.442}", "{\"n\": 687, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2758.94, \"learn_time_ms\": 14141.106}", "{\"n\": 688, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2764.37, \"learn_time_ms\": 14147.116}", "{\"n\": 689, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2764.19, \"learn_time_ms\": 14159.11}", "{\"n\": 690, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2764.19, \"learn_time_ms\": 14167.214}", "{\"n\": 691, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2774.75, \"learn_time_ms\": 14173.381}", "{\"n\": 692, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2784.07, \"learn_time_ms\": 14158.47}", "{\"n\": 693, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2782.43, \"learn_time_ms\": 14167.719}", "{\"n\": 694, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2797.65, \"learn_time_ms\": 14170.093}", "{\"n\": 695, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2793.29, \"learn_time_ms\": 14162.967}", "{\"n\": 696, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2807.01, \"learn_time_ms\": 14165.925}", "{\"n\": 697, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2810.91, \"learn_time_ms\": 14174.347}", "{\"n\": 698, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2812.16, \"learn_time_ms\": 14162.309}", "{\"n\": 699, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2812.16, \"learn_time_ms\": 14166.325}", "{\"n\": 700, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2825.65, \"learn_time_ms\": 14164.299}", "{\"n\": 701, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2833.63, \"learn_time_ms\": 14171.384}", "{\"n\": 702, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2827.41, \"learn_time_ms\": 14178.715}", "{\"n\": 703, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2826.8, \"learn_time_ms\": 14181.081}", "{\"n\": 704, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2828.67, \"learn_time_ms\": 14190.392}", "{\"n\": 705, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2828.5, \"learn_time_ms\": 14204.303}", "{\"n\": 706, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2830.97, \"learn_time_ms\": 14194.456}", "{\"n\": 707, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2831.1, \"learn_time_ms\": 14191.644}", "{\"n\": 708, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2833.1, \"learn_time_ms\": 14210.63}", "{\"n\": 709, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2839.88, \"learn_time_ms\": 14217.578}", "{\"n\": 710, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2833.3, \"learn_time_ms\": 14222.053}", "{\"n\": 711, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2835.94, \"learn_time_ms\": 14210.556}", "{\"n\": 712, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2828.19, \"learn_time_ms\": 14205.518}", "{\"n\": 713, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2825.32, \"learn_time_ms\": 14208.505}", "{\"n\": 714, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2832.49, \"learn_time_ms\": 14214.91}", "{\"n\": 715, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2823.97, \"learn_time_ms\": 14201.481}", "{\"n\": 716, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2863.92, \"learn_time_ms\": 14209.692}", "{\"n\": 717, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2863.27, \"learn_time_ms\": 14212.6}", "{\"n\": 718, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2862.66, \"learn_time_ms\": 14196.365}", "{\"n\": 719, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2874.29, \"learn_time_ms\": 14193.642}", "{\"n\": 720, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.22, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2876.83, \"learn_time_ms\": 14183.12}", "{\"n\": 721, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2866.98, \"learn_time_ms\": 14186.067}", "{\"n\": 722, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2865.32, \"learn_time_ms\": 14183.493}", "{\"n\": 723, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2871.95, \"learn_time_ms\": 14175.381}", "{\"n\": 724, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2860.27, \"learn_time_ms\": 14145.561}", "{\"n\": 725, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2860.18, \"learn_time_ms\": 14149.337}", "{\"n\": 726, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2864.67, \"learn_time_ms\": 14154.463}", "{\"n\": 727, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2882.56, \"learn_time_ms\": 14152.525}", "{\"n\": 728, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2884.64, \"learn_time_ms\": 14168.507}", "{\"n\": 729, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2886.59, \"learn_time_ms\": 14162.523}", "{\"n\": 730, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2892.8, \"learn_time_ms\": 14165.691}", "{\"n\": 731, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2896.63, \"learn_time_ms\": 14162.911}", "{\"n\": 732, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2895.52, \"learn_time_ms\": 14164.718}", "{\"n\": 733, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2910.81, \"learn_time_ms\": 14166.388}", "{\"n\": 734, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2911.01, \"learn_time_ms\": 14187.932}", "{\"n\": 735, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2915.89, \"learn_time_ms\": 14201.454}", "{\"n\": 736, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2926.03, \"learn_time_ms\": 14205.607}", "{\"n\": 737, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.56, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2942.94, \"learn_time_ms\": 14212.414}", "{\"n\": 738, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2953.33, \"learn_time_ms\": 14207.065}", "{\"n\": 739, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.43, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2953.33, \"learn_time_ms\": 14208.425}", "{\"n\": 740, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.63, \"learn_time_ms\": 14218.211}", "{\"n\": 741, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2972.18, \"learn_time_ms\": 14227.503}", "{\"n\": 742, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.33, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2970.01, \"learn_time_ms\": 14224.048}", "{\"n\": 743, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.29, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2971.8, \"learn_time_ms\": 14213.454}", "{\"n\": 744, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2969.13, \"learn_time_ms\": 14198.208}", "{\"n\": 745, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2974.62, \"learn_time_ms\": 14204.214}", "{\"n\": 746, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.18, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2981.68, \"learn_time_ms\": 14213.469}", "{\"n\": 747, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2980.1, \"learn_time_ms\": 14207.026}", "{\"n\": 748, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2971.53, \"learn_time_ms\": 14204.168}", "{\"n\": 749, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2983.58, \"learn_time_ms\": 14206.041}", "{\"n\": 750, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2987.35, \"learn_time_ms\": 14185.46}", "{\"n\": 751, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2995.43, \"learn_time_ms\": 14180.573}", "{\"n\": 752, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2997.99, \"learn_time_ms\": 14179.324}", "{\"n\": 753, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3008.05, \"learn_time_ms\": 14180.066}", "{\"n\": 754, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3007.42, \"learn_time_ms\": 14184.237}", "{\"n\": 755, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3007.42, \"learn_time_ms\": 14163.273}", "{\"n\": 756, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3007.42, \"learn_time_ms\": 14134.48}", "{\"n\": 757, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3012.37, \"learn_time_ms\": 14126.568}", "{\"n\": 758, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3024.25, \"learn_time_ms\": 14126.629}", "{\"n\": 759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3034.06, \"learn_time_ms\": 14125.1}", "{\"n\": 760, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.36, \"learn_time_ms\": 14134.454}", "{\"n\": 761, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3044.67, \"learn_time_ms\": 14144.47}", "{\"n\": 762, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3052.79, \"learn_time_ms\": 14161.91}", "{\"n\": 763, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3052.79, \"learn_time_ms\": 14174.371}", "{\"n\": 764, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3052.79, \"learn_time_ms\": 14192.601}", "{\"n\": 765, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3051.4, \"learn_time_ms\": 14196.97}", "{\"n\": 766, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.62, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3050.16, \"learn_time_ms\": 14225.427}", "{\"n\": 767, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.47, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3069.94, \"learn_time_ms\": 14238.898}", "{\"n\": 768, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.48, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3074.25, \"learn_time_ms\": 14243.998}", "{\"n\": 769, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3078.07, \"learn_time_ms\": 14253.286}", "{\"n\": 770, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3082.43, \"learn_time_ms\": 14284.953}", "{\"n\": 771, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3091.84, \"learn_time_ms\": 14286.846}", "{\"n\": 772, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3091.84, \"learn_time_ms\": 14289.17}", "{\"n\": 773, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3092.42, \"learn_time_ms\": 14292.122}", "{\"n\": 774, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3112.98, \"learn_time_ms\": 14286.093}", "{\"n\": 775, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3103.99, \"learn_time_ms\": 14296.784}", "{\"n\": 776, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.25, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3104.64, \"learn_time_ms\": 14285.662}", "{\"n\": 777, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3102.24, \"learn_time_ms\": 14278.95}", "{\"n\": 778, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3117.45, \"learn_time_ms\": 14273.8}", "{\"n\": 779, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.26, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3123.03, \"learn_time_ms\": 14285.184}", "{\"n\": 780, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.25, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3122.32, \"learn_time_ms\": 14264.291}", "{\"n\": 781, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.25, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3122.32, \"learn_time_ms\": 14276.611}", "{\"n\": 782, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3112.09, \"learn_time_ms\": 14285.645}", "{\"n\": 783, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3106.67, \"learn_time_ms\": 14282.819}", "{\"n\": 784, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3111.04, \"learn_time_ms\": 14283.454}", "{\"n\": 785, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3103.66, \"learn_time_ms\": 14284.101}", "{\"n\": 786, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3103.66, \"learn_time_ms\": 14285.688}", "{\"n\": 787, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3105.55, \"learn_time_ms\": 14298.02}", "{\"n\": 788, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.17, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3104.45, \"learn_time_ms\": 14325.046}", "{\"n\": 789, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.1, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3109.11, \"learn_time_ms\": 14330.351}", "{\"n\": 790, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3110.29, \"learn_time_ms\": 14333.055}", "{\"n\": 791, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3114.59, \"learn_time_ms\": 14313.699}", "{\"n\": 792, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.1, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3111.29, \"learn_time_ms\": 14308.71}", "{\"n\": 793, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3122.18, \"learn_time_ms\": 14308.599}", "{\"n\": 794, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3129.23, \"learn_time_ms\": 14313.912}", "{\"n\": 795, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.06, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3131.92, \"learn_time_ms\": 14306.986}", "{\"n\": 796, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3127.59, \"learn_time_ms\": 14309.707}", "{\"n\": 797, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.11, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3122.06, \"learn_time_ms\": 14294.935}", "{\"n\": 798, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.12, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3122.55, \"learn_time_ms\": 14278.869}", "{\"n\": 799, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3133.07, \"learn_time_ms\": 14273.251}", "{\"n\": 800, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3149.66, \"learn_time_ms\": 14278.234}", "{\"n\": 801, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3149.66, \"learn_time_ms\": 14285.77}", "{\"n\": 802, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3158.74, \"learn_time_ms\": 14279.986}", "{\"n\": 803, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3148.77, \"learn_time_ms\": 14270.131}", "{\"n\": 804, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3158.12, \"learn_time_ms\": 14259.848}", "{\"n\": 805, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.34, \"learn_time_ms\": 14267.029}", "{\"n\": 806, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.35, \"learn_time_ms\": 14261.703}", "{\"n\": 807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.82, \"learn_time_ms\": 14271.738}", "{\"n\": 808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.04, \"learn_time_ms\": 14271.711}", "{\"n\": 809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3151.46, \"learn_time_ms\": 14255.69}", "{\"n\": 810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.91, \"learn_time_ms\": 14253.166}", "{\"n\": 811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.91, \"learn_time_ms\": 14247.642}", "{\"n\": 812, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3145.88, \"learn_time_ms\": 14252.824}", "{\"n\": 813, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3128.8, \"learn_time_ms\": 14258.481}", "{\"n\": 814, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3124.0, \"learn_time_ms\": 14254.652}", "{\"n\": 815, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3114.78, \"learn_time_ms\": 14234.786}", "{\"n\": 816, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3109.14, \"learn_time_ms\": 14237.549}", "{\"n\": 817, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3122.05, \"learn_time_ms\": 14234.078}", "{\"n\": 818, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3122.05, \"learn_time_ms\": 14224.04}", "{\"n\": 819, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3122.05, \"learn_time_ms\": 14220.149}", "{\"n\": 820, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3118.81, \"learn_time_ms\": 14205.838}", "{\"n\": 821, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3101.99, \"learn_time_ms\": 14210.556}", "{\"n\": 822, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3099.4, \"learn_time_ms\": 14204.683}", "{\"n\": 823, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3102.13, \"learn_time_ms\": 14195.006}", "{\"n\": 824, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3102.13, \"learn_time_ms\": 14197.2}", "{\"n\": 825, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3115.36, \"learn_time_ms\": 14209.385}", "{\"n\": 826, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.98, \"learn_time_ms\": 14209.706}", "{\"n\": 827, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.98, \"learn_time_ms\": 14219.969}", "{\"n\": 828, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3120.59, \"learn_time_ms\": 14231.346}", "{\"n\": 829, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3128.81, \"learn_time_ms\": 14242.625}", "{\"n\": 830, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.49, \"learn_time_ms\": 14250.509}", "{\"n\": 831, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3125.21, \"learn_time_ms\": 14252.762}", "{\"n\": 832, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3125.21, \"learn_time_ms\": 14262.058}", "{\"n\": 833, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3120.17, \"learn_time_ms\": 14264.621}", "{\"n\": 834, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3133.83, \"learn_time_ms\": 14248.749}", "{\"n\": 835, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3133.83, \"learn_time_ms\": 14255.464}", "{\"n\": 836, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3127.82, \"learn_time_ms\": 14253.608}", "{\"n\": 837, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3136.38, \"learn_time_ms\": 14256.646}", "{\"n\": 838, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3139.4, \"learn_time_ms\": 14259.421}", "{\"n\": 839, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3134.35, \"learn_time_ms\": 14267.578}", "{\"n\": 840, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3129.37, \"learn_time_ms\": 14255.17}", "{\"n\": 841, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.82, \"learn_time_ms\": 14261.727}", "{\"n\": 842, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3128.89, \"learn_time_ms\": 14251.177}", "{\"n\": 843, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3131.51, \"learn_time_ms\": 14257.311}", "{\"n\": 844, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3132.48, \"learn_time_ms\": 14283.208}", "{\"n\": 845, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3130.89, \"learn_time_ms\": 14283.803}", "{\"n\": 846, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3121.71, \"learn_time_ms\": 14293.326}", "{\"n\": 847, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.38, \"learn_time_ms\": 14287.552}", "{\"n\": 848, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3117.71, \"learn_time_ms\": 14281.727}", "{\"n\": 849, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3121.61, \"learn_time_ms\": 14278.109}", "{\"n\": 850, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3110.66, \"learn_time_ms\": 14276.072}", "{\"n\": 851, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3111.03, \"learn_time_ms\": 14266.123}", "{\"n\": 852, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3123.9, \"learn_time_ms\": 14265.022}", "{\"n\": 853, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3117.51, \"learn_time_ms\": 14276.736}", "{\"n\": 854, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3116.53, \"learn_time_ms\": 14275.865}", "{\"n\": 855, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3116.82, \"learn_time_ms\": 14269.56}", "{\"n\": 856, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3110.75, \"learn_time_ms\": 14262.8}", "{\"n\": 857, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3106.32, \"learn_time_ms\": 14265.808}", "{\"n\": 858, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3110.42, \"learn_time_ms\": 14269.447}", "{\"n\": 859, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.06, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3111.72, \"learn_time_ms\": 14260.432}", "{\"n\": 860, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3112.49, \"learn_time_ms\": 14285.273}", "{\"n\": 861, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3118.56, \"learn_time_ms\": 14297.356}", "{\"n\": 862, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3121.63, \"learn_time_ms\": 14298.733}", "{\"n\": 863, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3117.68, \"learn_time_ms\": 14288.3}", "{\"n\": 864, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3138.38, \"learn_time_ms\": 14277.407}", "{\"n\": 865, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3137.3, \"learn_time_ms\": 14268.628}", "{\"n\": 866, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3138.46, \"learn_time_ms\": 14256.99}", "{\"n\": 867, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3138.46, \"learn_time_ms\": 14249.053}", "{\"n\": 868, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3143.33, \"learn_time_ms\": 14235.689}", "{\"n\": 869, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3151.45, \"learn_time_ms\": 14226.703}", "{\"n\": 870, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3161.39, \"learn_time_ms\": 14216.43}", "{\"n\": 871, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3163.42, \"learn_time_ms\": 14208.604}", "{\"n\": 872, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3170.61, \"learn_time_ms\": 14208.669}", "{\"n\": 873, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3158.83, \"learn_time_ms\": 14224.364}", "{\"n\": 874, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3159.42, \"learn_time_ms\": 14239.241}", "{\"n\": 875, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3148.28, \"learn_time_ms\": 14256.812}", "{\"n\": 876, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3138.78, \"learn_time_ms\": 14262.227}", "{\"n\": 877, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3141.96, \"learn_time_ms\": 14272.104}", "{\"n\": 878, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3152.83, \"learn_time_ms\": 14277.93}", "{\"n\": 879, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3149.47, \"learn_time_ms\": 14292.221}", "{\"n\": 880, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3155.2, \"learn_time_ms\": 14304.977}", "{\"n\": 881, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3146.68, \"learn_time_ms\": 14305.516}", "{\"n\": 882, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3123.94, \"learn_time_ms\": 14303.322}", "{\"n\": 883, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3117.69, \"learn_time_ms\": 14281.158}", "{\"n\": 884, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3120.39, \"learn_time_ms\": 14276.326}", "{\"n\": 885, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3108.79, \"learn_time_ms\": 14274.784}", "{\"n\": 886, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3099.02, \"learn_time_ms\": 14282.317}", "{\"n\": 887, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3094.16, \"learn_time_ms\": 14288.575}", "{\"n\": 888, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3089.32, \"learn_time_ms\": 14292.681}", "{\"n\": 889, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3083.37, \"learn_time_ms\": 14297.048}", "{\"n\": 890, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3075.91, \"learn_time_ms\": 14292.924}", "{\"n\": 891, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3067.54, \"learn_time_ms\": 14292.486}", "{\"n\": 892, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3071.04, \"learn_time_ms\": 14301.583}", "{\"n\": 893, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3078.98, \"learn_time_ms\": 14302.647}", "{\"n\": 894, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3083.86, \"learn_time_ms\": 14284.235}", "{\"n\": 895, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3083.86, \"learn_time_ms\": 14285.781}", "{\"n\": 896, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3088.69, \"learn_time_ms\": 14280.821}", "{\"n\": 897, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3082.69, \"learn_time_ms\": 14262.516}", "{\"n\": 898, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3080.79, \"learn_time_ms\": 14263.62}", "{\"n\": 899, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3080.93, \"learn_time_ms\": 14260.559}", "{\"n\": 900, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3078.19, \"learn_time_ms\": 14251.487}", "{\"n\": 901, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3078.19, \"learn_time_ms\": 14247.85}", "{\"n\": 902, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3083.06, \"learn_time_ms\": 14251.31}", "{\"n\": 903, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3082.44, \"learn_time_ms\": 14266.73}", "{\"n\": 904, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3105.66, \"learn_time_ms\": 14284.666}", "{\"n\": 905, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3107.76, \"learn_time_ms\": 14276.593}", "{\"n\": 906, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3109.24, \"learn_time_ms\": 14274.501}", "{\"n\": 907, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3108.07, \"learn_time_ms\": 14269.966}", "{\"n\": 908, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3115.97, \"learn_time_ms\": 14278.973}", "{\"n\": 909, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3116.03, \"learn_time_ms\": 14277.647}", "{\"n\": 910, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3104.14, \"learn_time_ms\": 14272.871}", "{\"n\": 911, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3098.67, \"learn_time_ms\": 14256.615}", "{\"n\": 912, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3072.47, \"learn_time_ms\": 14234.444}", "{\"n\": 913, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3071.95, \"learn_time_ms\": 14211.47}", "{\"n\": 914, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3065.73, \"learn_time_ms\": 14195.716}", "{\"n\": 915, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3065.37, \"learn_time_ms\": 14202.86}", "{\"n\": 916, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3058.7, \"learn_time_ms\": 14200.216}", "{\"n\": 917, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3049.17, \"learn_time_ms\": 14182.594}", "{\"n\": 918, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3052.29, \"learn_time_ms\": 14180.54}", "{\"n\": 919, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3052.06, \"learn_time_ms\": 14169.351}", "{\"n\": 920, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3038.12, \"learn_time_ms\": 14184.993}", "{\"n\": 921, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3034.21, \"learn_time_ms\": 14212.306}", "{\"n\": 922, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3029.97, \"learn_time_ms\": 14227.069}", "{\"n\": 923, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.02, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3038.76, \"learn_time_ms\": 14238.811}", "{\"n\": 924, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.02, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3038.76, \"learn_time_ms\": 14250.938}", "{\"n\": 925, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3045.31, \"learn_time_ms\": 14247.839}", "{\"n\": 926, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3040.62, \"learn_time_ms\": 14258.86}", "{\"n\": 927, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3044.43, \"learn_time_ms\": 14277.97}", "{\"n\": 928, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3043.93, \"learn_time_ms\": 14267.057}", "{\"n\": 929, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3033.56, \"learn_time_ms\": 14260.669}", "{\"n\": 930, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3042.04, \"learn_time_ms\": 14251.603}", "{\"n\": 931, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3045.93, \"learn_time_ms\": 14238.404}", "{\"n\": 932, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3055.94, \"learn_time_ms\": 14235.641}", "{\"n\": 933, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3068.77, \"learn_time_ms\": 14239.674}", "{\"n\": 934, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3062.17, \"learn_time_ms\": 14241.616}", "{\"n\": 935, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3068.57, \"learn_time_ms\": 14235.616}", "{\"n\": 936, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3077.43, \"learn_time_ms\": 14229.892}", "{\"n\": 937, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3077.34, \"learn_time_ms\": 14232.417}", "{\"n\": 938, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3091.17, \"learn_time_ms\": 14235.453}", "{\"n\": 939, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3093.66, \"learn_time_ms\": 14242.576}", "{\"n\": 940, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3086.13, \"learn_time_ms\": 14242.33}", "{\"n\": 941, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3082.9, \"learn_time_ms\": 14239.622}", "{\"n\": 942, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3072.36, \"learn_time_ms\": 14248.797}", "{\"n\": 943, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3072.73, \"learn_time_ms\": 14252.451}", "{\"n\": 944, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3070.47, \"learn_time_ms\": 14247.604}", "{\"n\": 945, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3074.93, \"learn_time_ms\": 14244.94}", "{\"n\": 946, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3074.93, \"learn_time_ms\": 14242.793}", "{\"n\": 947, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3089.19, \"learn_time_ms\": 14244.674}", "{\"n\": 948, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3075.03, \"learn_time_ms\": 14236.741}", "{\"n\": 949, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3075.03, \"learn_time_ms\": 14234.052}", "{\"n\": 950, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3070.75, \"learn_time_ms\": 14237.319}", "{\"n\": 951, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3059.52, \"learn_time_ms\": 14231.864}", "{\"n\": 952, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3063.47, \"learn_time_ms\": 14230.136}", "{\"n\": 953, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3067.47, \"learn_time_ms\": 14229.834}", "{\"n\": 954, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3050.46, \"learn_time_ms\": 14242.995}", "{\"n\": 955, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3050.46, \"learn_time_ms\": 14253.576}", "{\"n\": 956, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3053.66, \"learn_time_ms\": 14260.354}", "{\"n\": 957, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3050.8, \"learn_time_ms\": 14244.784}", "{\"n\": 958, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3067.01, \"learn_time_ms\": 14252.265}", "{\"n\": 959, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3091.24, \"learn_time_ms\": 14254.788}", "{\"n\": 960, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3091.24, \"learn_time_ms\": 14250.067}", "{\"n\": 961, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3077.17, \"learn_time_ms\": 14262.082}", "{\"n\": 962, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3071.41, \"learn_time_ms\": 14252.657}", "{\"n\": 963, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3076.56, \"learn_time_ms\": 14241.91}", "{\"n\": 964, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3068.44, \"learn_time_ms\": 14234.914}", "{\"n\": 965, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3077.99, \"learn_time_ms\": 14218.208}", "{\"n\": 966, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3073.81, \"learn_time_ms\": 14196.842}", "{\"n\": 967, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3087.31, \"learn_time_ms\": 14216.236}", "{\"n\": 968, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3080.16, \"learn_time_ms\": 14219.203}", "{\"n\": 969, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3071.99, \"learn_time_ms\": 14233.444}", "{\"n\": 970, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3086.0, \"learn_time_ms\": 14233.295}", "{\"n\": 971, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3094.73, \"learn_time_ms\": 14212.879}", "{\"n\": 972, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3085.71, \"learn_time_ms\": 14221.152}", "{\"n\": 973, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3078.74, \"learn_time_ms\": 14221.858}", "{\"n\": 974, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3078.74, \"learn_time_ms\": 14204.226}", "{\"n\": 975, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3078.74, \"learn_time_ms\": 14222.329}", "{\"n\": 976, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3091.77, \"learn_time_ms\": 14235.025}", "{\"n\": 977, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3104.46, \"learn_time_ms\": 14241.356}", "{\"n\": 978, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3092.69, \"learn_time_ms\": 14238.835}", "{\"n\": 979, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3076.74, \"learn_time_ms\": 14242.463}", "{\"n\": 980, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3080.69, \"learn_time_ms\": 14236.595}", "{\"n\": 981, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3094.0, \"learn_time_ms\": 14251.633}", "{\"n\": 982, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3094.0, \"learn_time_ms\": 14247.833}", "{\"n\": 983, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3103.74, \"learn_time_ms\": 14248.173}", "{\"n\": 984, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3088.35, \"learn_time_ms\": 14269.568}", "{\"n\": 985, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3077.0, \"learn_time_ms\": 14264.274}", "{\"n\": 986, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3067.51, \"learn_time_ms\": 14264.1}", "{\"n\": 987, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3074.23, \"learn_time_ms\": 14255.543}", "{\"n\": 988, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3073.38, \"learn_time_ms\": 14254.583}", "{\"n\": 989, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3073.38, \"learn_time_ms\": 14248.223}", "{\"n\": 990, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3064.11, \"learn_time_ms\": 14257.244}", "{\"n\": 991, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3069.22, \"learn_time_ms\": 14263.362}", "{\"n\": 992, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3066.72, \"learn_time_ms\": 14265.48}", "{\"n\": 993, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3058.9, \"learn_time_ms\": 14266.601}", "{\"n\": 994, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3071.7, \"learn_time_ms\": 14264.418}", "{\"n\": 995, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3071.7, \"learn_time_ms\": 14273.962}", "{\"n\": 996, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3078.27, \"learn_time_ms\": 14284.893}", "{\"n\": 997, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3083.33, \"learn_time_ms\": 14280.792}", "{\"n\": 998, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3079.66, \"learn_time_ms\": 14287.153}", "{\"n\": 999, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3075.24, \"learn_time_ms\": 14283.91}", "{\"n\": 1000, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3075.24, \"learn_time_ms\": 14287.866}"]