["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 40031.764, \"total_train_time_s\": 47.478272438049316}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 26063.379, \"total_train_time_s\": 17.105184078216553}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 21407.015, \"total_train_time_s\": 17.22484588623047}", "{\"n\": 4, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 19090.699, \"total_train_time_s\": 16.181275129318237}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.875, \"learn_time_ms\": 17747.571, \"total_train_time_s\": 16.62905263900757}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9375, \"learn_time_ms\": 16863.107, \"total_train_time_s\": 16.49754309654236}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9375, \"learn_time_ms\": 16242.142, \"total_train_time_s\": 16.54431962966919}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.5625, \"learn_time_ms\": 15762.648, \"total_train_time_s\": 16.545963525772095}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.5625, \"learn_time_ms\": 15392.371, \"total_train_time_s\": 16.76028299331665}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.1578947368421, \"learn_time_ms\": 15083.898, \"total_train_time_s\": 16.331921100616455}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5208333333334, \"learn_time_ms\": 12324.036, \"total_train_time_s\": 16.42151689529419}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5208333333334, \"learn_time_ms\": 12342.426, \"total_train_time_s\": 16.291313409805298}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.09375, \"learn_time_ms\": 12345.11, \"total_train_time_s\": 16.19878625869751}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.09375, \"learn_time_ms\": 12347.779, \"total_train_time_s\": 16.29899573326111}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9710144927536, \"learn_time_ms\": 12323.845, \"total_train_time_s\": 16.156001806259155}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3125, \"learn_time_ms\": 12289.425, \"total_train_time_s\": 16.10083770751953}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3125, \"learn_time_ms\": 12248.188, \"total_train_time_s\": 16.117302656173706}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.46875, \"learn_time_ms\": 12231.317, \"total_train_time_s\": 16.321244478225708}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.46875, \"learn_time_ms\": 12194.581, \"total_train_time_s\": 16.15920925140381}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 12182.947, \"total_train_time_s\": 16.16896963119507}"]