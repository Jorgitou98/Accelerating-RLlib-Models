["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 5184.371}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 4928.383}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 4834.351}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1162.75, \"learn_time_ms\": 4862.55}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1178.375, \"learn_time_ms\": 4875.305}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1205.75, \"learn_time_ms\": 4902.561}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3125, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1232.0625, \"learn_time_ms\": 4915.004}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1215.1, \"learn_time_ms\": 4925.952}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.416666666666668, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1224.0833333333333, \"learn_time_ms\": 4932.43}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.451612903225808, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1200.8387096774193, \"learn_time_ms\": 4938.213}"]