["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9808.453, \"total_train_time_s\": 16.415178537368774}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9571.446, \"total_train_time_s\": 15.046183347702026}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9483.648, \"total_train_time_s\": 15.001790761947632}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.375, \"learn_time_ms\": 9445.511, \"total_train_time_s\": 15.03696608543396}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.7272727272727, \"learn_time_ms\": 9419.904, \"total_train_time_s\": 15.019545316696167}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.4375, \"learn_time_ms\": 9398.18, \"total_train_time_s\": 14.976039409637451}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0833333333334, \"learn_time_ms\": 9384.679, \"total_train_time_s\": 15.008473873138428}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0833333333334, \"learn_time_ms\": 9374.832, \"total_train_time_s\": 15.004739999771118}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.53125, \"learn_time_ms\": 9348.551, \"total_train_time_s\": 14.848807573318481}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.6060606060606, \"learn_time_ms\": 9318.143, \"total_train_time_s\": 14.773021459579468}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.3, \"learn_time_ms\": 9269.611, \"total_train_time_s\": 15.009384155273438}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.0416666666666, \"learn_time_ms\": 9267.252, \"total_train_time_s\": 15.0192391872406}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.0416666666666, \"learn_time_ms\": 9261.062, \"total_train_time_s\": 14.927756309509277}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.1785714285714, \"learn_time_ms\": 9257.912, \"total_train_time_s\": 15.039828777313232}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.6379310344828, \"learn_time_ms\": 9255.319, \"total_train_time_s\": 14.981783866882324}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.71875, \"learn_time_ms\": 9257.058, \"total_train_time_s\": 15.018704652786255}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1944444444445, \"learn_time_ms\": 9269.581, \"total_train_time_s\": 15.098646640777588}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1944444444445, \"learn_time_ms\": 9268.631, \"total_train_time_s\": 14.973634004592896}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.2875, \"learn_time_ms\": 9282.396, \"total_train_time_s\": 14.944718360900879}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1604938271605, \"learn_time_ms\": 9284.696, \"total_train_time_s\": 14.754677534103394}"]