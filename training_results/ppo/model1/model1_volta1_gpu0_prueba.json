["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 6894.141}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 6726.894}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 6674.86}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1193.75, \"learn_time_ms\": 6691.438}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1257.5, \"learn_time_ms\": 6701.807}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46153846153846, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1212.076923076923, \"learn_time_ms\": 6722.765}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1875, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1243.3125, \"learn_time_ms\": 6719.73}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1218.25, \"learn_time_ms\": 6702.015}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1226.625, \"learn_time_ms\": 6709.08}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1213.1333333333334, \"learn_time_ms\": 6728.572}"]