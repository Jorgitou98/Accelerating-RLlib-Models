["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 516991.774, \"total_train_time_s\": 520.175324678421}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 516919.758, \"total_train_time_s\": 519.2651135921478}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 516568.222, \"total_train_time_s\": 518.2383663654327}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.375, \"learn_time_ms\": 516382.941, \"total_train_time_s\": 518.3009130954742}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.7272727272727, \"learn_time_ms\": 516526.879, \"total_train_time_s\": 519.4782564640045}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.5, \"learn_time_ms\": 518210.621, \"total_train_time_s\": 528.9955852031708}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.0833333333333, \"learn_time_ms\": 518709.111, \"total_train_time_s\": 524.1565515995026}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1024.0833333333333, \"learn_time_ms\": 518454.284, \"total_train_time_s\": 519.0181159973145}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.0625, \"learn_time_ms\": 518215.898, \"total_train_time_s\": 518.6899108886719}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.0625, \"learn_time_ms\": 518097.08, \"total_train_time_s\": 519.3671824932098}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1028.475, \"learn_time_ms\": 518068.431, \"total_train_time_s\": 519.0746278762817}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.4255319148936, \"learn_time_ms\": 518088.878, \"total_train_time_s\": 519.3993785381317}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.1041666666667, \"learn_time_ms\": 518230.146, \"total_train_time_s\": 519.6067092418671}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.392857142857, \"learn_time_ms\": 518231.629, \"total_train_time_s\": 518.1941792964935}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.392857142857, \"learn_time_ms\": 518219.55, \"total_train_time_s\": 519.2852580547333}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1036.109375, \"learn_time_ms\": 517198.849, \"total_train_time_s\": 518.8161141872406}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.753846153846, \"learn_time_ms\": 516739.738, \"total_train_time_s\": 519.4470238685608}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1042.0694444444443, \"learn_time_ms\": 516807.222, \"total_train_time_s\": 519.6890070438385}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1047.0, \"learn_time_ms\": 516824.643, \"total_train_time_s\": 518.8203268051147}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1049.0125, \"learn_time_ms\": 516831.47, \"total_train_time_s\": 519.472912311554}"]