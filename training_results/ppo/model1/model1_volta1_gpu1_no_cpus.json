["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9805.447}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9551.49}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 9467.78}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1090.25, \"learn_time_ms\": 9413.544}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1090.25, \"learn_time_ms\": 9388.459}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1078.1875, \"learn_time_ms\": 9361.179}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.705882352941178, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1077.235294117647, \"learn_time_ms\": 9349.951}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.708333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1077.7916666666667, \"learn_time_ms\": 9353.349}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.678571428571427, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1079.357142857143, \"learn_time_ms\": 9353.813}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.625, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1084.03125, \"learn_time_ms\": 9349.804}"]