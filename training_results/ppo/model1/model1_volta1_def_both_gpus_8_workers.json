["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 27363.471, \"total_train_time_s\": 33.699443101882935}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 18160.046, \"total_train_time_s\": 12.986786603927612}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15097.097, \"total_train_time_s\": 12.906744241714478}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.75, \"learn_time_ms\": 13571.141, \"total_train_time_s\": 13.054362297058105}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.7142857142857, \"learn_time_ms\": 12660.608, \"total_train_time_s\": 13.004524230957031}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.6875, \"learn_time_ms\": 12049.271, \"total_train_time_s\": 12.95129108428955}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0833333333334, \"learn_time_ms\": 11609.301, \"total_train_time_s\": 12.931285858154297}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0833333333334, \"learn_time_ms\": 11280.858, \"total_train_time_s\": 12.987892150878906}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.03125, \"learn_time_ms\": 11031.49, \"total_train_time_s\": 13.021397590637207}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.5882352941177, \"learn_time_ms\": 10827.924, \"total_train_time_s\": 13.007323503494263}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.975, \"learn_time_ms\": 8993.062, \"total_train_time_s\": 13.037110805511475}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.25, \"learn_time_ms\": 8996.196, \"total_train_time_s\": 12.989353656768799}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.25, \"learn_time_ms\": 9003.634, \"total_train_time_s\": 12.999823331832886}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.9107142857143, \"learn_time_ms\": 9006.714, \"total_train_time_s\": 12.99592137336731}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.6666666666666, \"learn_time_ms\": 9005.03, \"total_train_time_s\": 12.95972728729248}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.90625, \"learn_time_ms\": 9010.853, \"total_train_time_s\": 13.032627582550049}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.25, \"learn_time_ms\": 9012.173, \"total_train_time_s\": 12.953885793685913}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.25, \"learn_time_ms\": 9020.213, \"total_train_time_s\": 13.00560712814331}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.4625, \"learn_time_ms\": 9021.205, \"total_train_time_s\": 13.058441638946533}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.5, \"learn_time_ms\": 9034.2, \"total_train_time_s\": 13.148309230804443}"]