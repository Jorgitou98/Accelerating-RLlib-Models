["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14684.853}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14397.276}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14313.592}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.75, \"learn_time_ms\": 14254.45}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.75, \"learn_time_ms\": 14228.328}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.785714285714285, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1086.7142857142858, \"learn_time_ms\": 14219.665}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1100.3125, \"learn_time_ms\": 14202.905}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.571428571428573, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1138.1904761904761, \"learn_time_ms\": 14193.68}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.347826086956523, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1163.0869565217392, \"learn_time_ms\": 14189.52}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.296296296296298, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1179.888888888889, \"learn_time_ms\": 14187.697}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.06451612903226, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1216.5806451612902, \"learn_time_ms\": 14136.22}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.029411764705884, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1222.1764705882354, \"learn_time_ms\": 14125.153}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.973684210526315, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1236.5263157894738, \"learn_time_ms\": 14115.748}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1240.4878048780488, \"learn_time_ms\": 14103.764}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.869565217391305, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1256.9565217391305, \"learn_time_ms\": 14093.448}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.854166666666668, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1260.2708333333333, \"learn_time_ms\": 14094.59}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.76923076923077, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1276.7692307692307, \"learn_time_ms\": 14086.854}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.745454545454546, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1281.4363636363637, \"learn_time_ms\": 14085.647}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.728813559322035, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1291.915254237288, \"learn_time_ms\": 14079.176}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.70967741935484, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1296.5, \"learn_time_ms\": 14070.185}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.703125, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1298.703125, \"learn_time_ms\": 14066.791}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.691176470588236, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1307.75, \"learn_time_ms\": 14073.238}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.690140845070424, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1311.7605633802816, \"learn_time_ms\": 14082.805}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.589041095890412, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1324.2328767123288, \"learn_time_ms\": 14090.48}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.512820512820515, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1343.6025641025642, \"learn_time_ms\": 14103.153}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49367088607595, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1346.0379746835442, \"learn_time_ms\": 14089.901}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.416666666666668, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1356.9642857142858, \"learn_time_ms\": 14100.038}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.402298850574713, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1361.7586206896551, \"learn_time_ms\": 14090.696}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.402298850574713, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1361.7586206896551, \"learn_time_ms\": 14091.877}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.340425531914892, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1375.7659574468084, \"learn_time_ms\": 14087.244}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.326315789473686, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1378.2631578947369, \"learn_time_ms\": 14083.749}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.298969072164947, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1382.4742268041236, \"learn_time_ms\": 14085.118}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1409.6, \"learn_time_ms\": 14088.469}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1411.28, \"learn_time_ms\": 14087.63}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1438.35, \"learn_time_ms\": 14083.264}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1441.64, \"learn_time_ms\": 14081.842}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.97, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1453.81, \"learn_time_ms\": 14070.388}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.92, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1458.31, \"learn_time_ms\": 14075.831}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.88, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1466.21, \"learn_time_ms\": 14079.221}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.82, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1478.91, \"learn_time_ms\": 14085.562}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.8, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1481.11, \"learn_time_ms\": 14087.743}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1481.16, \"learn_time_ms\": 14087.502}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1493.51, \"learn_time_ms\": 14076.594}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1492.77, \"learn_time_ms\": 14081.538}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1504.29, \"learn_time_ms\": 14071.303}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1504.11, \"learn_time_ms\": 14073.495}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1506.46, \"learn_time_ms\": 14076.177}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1517.43, \"learn_time_ms\": 14069.139}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1518.52, \"learn_time_ms\": 14064.605}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1521.41, \"learn_time_ms\": 14053.536}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1526.22, \"learn_time_ms\": 14049.189}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1526.31, \"learn_time_ms\": 14047.433}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1532.53, \"learn_time_ms\": 14045.938}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.54, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1540.93, \"learn_time_ms\": 14043.514}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1536.9, \"learn_time_ms\": 14054.51}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1533.01, \"learn_time_ms\": 14058.109}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.62, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1530.95, \"learn_time_ms\": 14051.074}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.63, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1529.2, \"learn_time_ms\": 14052.6}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1526.62, \"learn_time_ms\": 14041.336}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1528.82, \"learn_time_ms\": 14053.512}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1528.55, \"learn_time_ms\": 14049.005}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1530.37, \"learn_time_ms\": 14057.372}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1530.37, \"learn_time_ms\": 14053.776}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1528.72, \"learn_time_ms\": 14057.258}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1528.64, \"learn_time_ms\": 14057.119}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1534.46, \"learn_time_ms\": 14064.493}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1535.42, \"learn_time_ms\": 14072.527}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1535.48, \"learn_time_ms\": 14073.466}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.62, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1539.4, \"learn_time_ms\": 14086.821}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.62, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1542.03, \"learn_time_ms\": 14081.256}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1542.19, \"learn_time_ms\": 14078.973}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1547.33, \"learn_time_ms\": 14066.579}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1549.07, \"learn_time_ms\": 14068.306}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1558.1, \"learn_time_ms\": 14066.45}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1559.92, \"learn_time_ms\": 14060.34}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1557.62, \"learn_time_ms\": 14047.977}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1569.55, \"learn_time_ms\": 14047.266}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.45, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1572.37, \"learn_time_ms\": 14058.382}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1577.22, \"learn_time_ms\": 14052.304}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1582.43, \"learn_time_ms\": 14055.004}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.36, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1579.95, \"learn_time_ms\": 14059.733}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1584.91, \"learn_time_ms\": 14065.438}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1585.53, \"learn_time_ms\": 14066.349}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1589.28, \"learn_time_ms\": 14068.147}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1592.0, \"learn_time_ms\": 14075.535}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1591.21, \"learn_time_ms\": 14073.892}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.36, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1587.99, \"learn_time_ms\": 14075.722}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1587.71, \"learn_time_ms\": 14070.979}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.36, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1585.76, \"learn_time_ms\": 14065.223}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.28, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1595.37, \"learn_time_ms\": 14063.869}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1599.39, \"learn_time_ms\": 14071.994}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1602.71, \"learn_time_ms\": 14075.46}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1610.17, \"learn_time_ms\": 14078.253}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1616.01, \"learn_time_ms\": 14077.734}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1617.07, \"learn_time_ms\": 14068.762}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1622.9, \"learn_time_ms\": 14083.246}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1617.21, \"learn_time_ms\": 14079.092}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1619.46, \"learn_time_ms\": 14086.333}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1623.31, \"learn_time_ms\": 14097.332}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1621.08, \"learn_time_ms\": 14096.528}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1622.43, \"learn_time_ms\": 14086.347}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1625.13, \"learn_time_ms\": 14080.285}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1629.97, \"learn_time_ms\": 14081.66}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1631.18, \"learn_time_ms\": 14073.076}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1632.03, \"learn_time_ms\": 14079.633}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1631.09, \"learn_time_ms\": 14078.184}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1627.99, \"learn_time_ms\": 14078.349}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1627.19, \"learn_time_ms\": 14062.562}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1626.77, \"learn_time_ms\": 14063.798}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1622.74, \"learn_time_ms\": 14065.971}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1621.54, \"learn_time_ms\": 14076.187}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1621.04, \"learn_time_ms\": 14078.976}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1620.51, \"learn_time_ms\": 14082.074}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1615.39, \"learn_time_ms\": 14090.019}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1614.82, \"learn_time_ms\": 14077.921}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1618.13, \"learn_time_ms\": 14073.113}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1619.01, \"learn_time_ms\": 14077.919}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1622.99, \"learn_time_ms\": 14085.641}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1635.9, \"learn_time_ms\": 14082.524}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1634.78, \"learn_time_ms\": 14084.19}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.09, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1649.67, \"learn_time_ms\": 14074.937}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1658.69, \"learn_time_ms\": 14071.317}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1658.69, \"learn_time_ms\": 14066.239}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1649.97, \"learn_time_ms\": 14071.422}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1646.98, \"learn_time_ms\": 14082.437}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1646.98, \"learn_time_ms\": 14086.286}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1642.43, \"learn_time_ms\": 14091.667}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1654.17, \"learn_time_ms\": 14092.718}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1654.17, \"learn_time_ms\": 14095.256}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.03, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1656.96, \"learn_time_ms\": 14096.475}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1666.33, \"learn_time_ms\": 14102.409}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1660.95, \"learn_time_ms\": 14099.575}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1657.83, \"learn_time_ms\": 14097.762}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1668.15, \"learn_time_ms\": 14088.431}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1667.2, \"learn_time_ms\": 14089.885}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.86, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1677.88, \"learn_time_ms\": 14091.507}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.82, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1681.77, \"learn_time_ms\": 14090.403}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1683.78, \"learn_time_ms\": 14089.465}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1691.4, \"learn_time_ms\": 14087.253}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1692.05, \"learn_time_ms\": 14086.519}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1693.26, \"learn_time_ms\": 14084.387}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1693.88, \"learn_time_ms\": 14095.242}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.71, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1697.25, \"learn_time_ms\": 14093.017}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.73, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1699.24, \"learn_time_ms\": 14107.713}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1698.89, \"learn_time_ms\": 14111.148}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1707.3, \"learn_time_ms\": 14108.531}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1710.68, \"learn_time_ms\": 14110.5}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1716.89, \"learn_time_ms\": 14109.895}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.55, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1721.98, \"learn_time_ms\": 14114.911}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.52, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1730.87, \"learn_time_ms\": 14118.111}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1743.5, \"learn_time_ms\": 14118.331}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1742.48, \"learn_time_ms\": 14105.01}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1754.72, \"learn_time_ms\": 14106.882}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.28, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1756.8, \"learn_time_ms\": 14097.63}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.33, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1751.5, \"learn_time_ms\": 14096.546}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.34, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1748.16, \"learn_time_ms\": 14091.025}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.34, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1747.09, \"learn_time_ms\": 14088.151}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.34, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1745.9, \"learn_time_ms\": 14092.544}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1748.99, \"learn_time_ms\": 14083.967}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1750.0, \"learn_time_ms\": 14074.71}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1756.8, \"learn_time_ms\": 14070.819}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.27, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1756.12, \"learn_time_ms\": 14082.833}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1753.91, \"learn_time_ms\": 14085.594}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.22, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1754.12, \"learn_time_ms\": 14088.796}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1748.66, \"learn_time_ms\": 14078.143}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1753.51, \"learn_time_ms\": 14077.556}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1763.02, \"learn_time_ms\": 14076.208}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1765.53, \"learn_time_ms\": 14077.038}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1769.33, \"learn_time_ms\": 14079.672}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1774.59, \"learn_time_ms\": 14090.581}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1772.74, \"learn_time_ms\": 14089.322}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1776.85, \"learn_time_ms\": 14085.526}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1775.81, \"learn_time_ms\": 14079.216}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1783.44, \"learn_time_ms\": 14066.632}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1775.32, \"learn_time_ms\": 14068.625}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1776.91, \"learn_time_ms\": 14066.731}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1786.62, \"learn_time_ms\": 14066.146}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1784.27, \"learn_time_ms\": 14051.82}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1791.15, \"learn_time_ms\": 14051.802}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1804.03, \"learn_time_ms\": 14045.108}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1804.03, \"learn_time_ms\": 14045.652}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1815.95, \"learn_time_ms\": 14048.106}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1817.72, \"learn_time_ms\": 14055.573}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1821.98, \"learn_time_ms\": 14065.027}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1817.96, \"learn_time_ms\": 14067.8}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1819.4, \"learn_time_ms\": 14072.772}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1817.73, \"learn_time_ms\": 14071.4}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1822.79, \"learn_time_ms\": 14082.716}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1825.26, \"learn_time_ms\": 14079.531}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1829.63, \"learn_time_ms\": 14078.293}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1826.44, \"learn_time_ms\": 14083.54}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1829.29, \"learn_time_ms\": 14084.372}", "{\"n\": 193, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1835.9, \"learn_time_ms\": 14082.959}", "{\"n\": 194, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1833.24, \"learn_time_ms\": 14086.525}", "{\"n\": 195, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1839.44, \"learn_time_ms\": 14090.678}", "{\"n\": 196, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1846.89, \"learn_time_ms\": 14089.246}", "{\"n\": 197, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1854.36, \"learn_time_ms\": 14090.005}", "{\"n\": 198, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1857.09, \"learn_time_ms\": 14088.751}", "{\"n\": 199, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1857.09, \"learn_time_ms\": 14092.29}", "{\"n\": 200, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1870.52, \"learn_time_ms\": 14093.984}", "{\"n\": 201, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1891.14, \"learn_time_ms\": 14091.942}", "{\"n\": 202, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1891.14, \"learn_time_ms\": 14093.683}", "{\"n\": 203, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1900.26, \"learn_time_ms\": 14082.766}", "{\"n\": 204, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1906.15, \"learn_time_ms\": 14072.42}", "{\"n\": 205, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.52, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1904.75, \"learn_time_ms\": 14066.358}", "{\"n\": 206, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1900.76, \"learn_time_ms\": 14061.795}", "{\"n\": 207, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1904.5, \"learn_time_ms\": 14060.936}", "{\"n\": 208, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1908.85, \"learn_time_ms\": 14058.134}", "{\"n\": 209, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.46, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1915.1, \"learn_time_ms\": 14060.717}", "{\"n\": 210, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1917.66, \"learn_time_ms\": 14055.68}", "{\"n\": 211, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1919.27, \"learn_time_ms\": 14055.66}", "{\"n\": 212, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1916.32, \"learn_time_ms\": 14046.574}", "{\"n\": 213, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1914.65, \"learn_time_ms\": 14051.612}", "{\"n\": 214, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1918.46, \"learn_time_ms\": 14057.244}", "{\"n\": 215, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1918.46, \"learn_time_ms\": 14060.883}", "{\"n\": 216, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1928.31, \"learn_time_ms\": 14062.418}", "{\"n\": 217, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1927.01, \"learn_time_ms\": 14061.161}", "{\"n\": 218, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1926.37, \"learn_time_ms\": 14062.536}", "{\"n\": 219, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1924.35, \"learn_time_ms\": 14066.45}", "{\"n\": 220, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1928.66, \"learn_time_ms\": 14077.954}", "{\"n\": 221, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1918.47, \"learn_time_ms\": 14078.862}", "{\"n\": 222, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1914.29, \"learn_time_ms\": 14081.05}", "{\"n\": 223, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1911.79, \"learn_time_ms\": 14084.605}", "{\"n\": 224, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1910.22, \"learn_time_ms\": 14085.008}", "{\"n\": 225, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.46, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1913.32, \"learn_time_ms\": 14085.27}", "{\"n\": 226, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1915.99, \"learn_time_ms\": 14086.585}", "{\"n\": 227, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1915.43, \"learn_time_ms\": 14087.303}", "{\"n\": 228, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1911.1, \"learn_time_ms\": 14089.658}", "{\"n\": 229, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.55, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1905.22, \"learn_time_ms\": 14083.698}", "{\"n\": 230, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.61, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1895.9, \"learn_time_ms\": 14075.834}", "{\"n\": 231, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1896.29, \"learn_time_ms\": 14082.92}", "{\"n\": 232, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1901.68, \"learn_time_ms\": 14081.889}", "{\"n\": 233, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1905.23, \"learn_time_ms\": 14087.921}", "{\"n\": 234, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1907.26, \"learn_time_ms\": 14079.778}", "{\"n\": 235, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.46, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1905.76, \"learn_time_ms\": 14071.355}", "{\"n\": 236, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1908.43, \"learn_time_ms\": 14070.596}", "{\"n\": 237, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1909.86, \"learn_time_ms\": 14074.302}", "{\"n\": 238, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1902.44, \"learn_time_ms\": 14069.924}", "{\"n\": 239, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1902.84, \"learn_time_ms\": 14069.792}", "{\"n\": 240, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1900.98, \"learn_time_ms\": 14069.97}", "{\"n\": 241, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1895.46, \"learn_time_ms\": 14058.393}", "{\"n\": 242, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 1896.93, \"learn_time_ms\": 14059.941}", "{\"n\": 243, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.68, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1888.52, \"learn_time_ms\": 14057.349}", "{\"n\": 244, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1896.12, \"learn_time_ms\": 14063.956}", "{\"n\": 245, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1909.06, \"learn_time_ms\": 14081.58}", "{\"n\": 246, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.55, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1910.65, \"learn_time_ms\": 14079.178}", "{\"n\": 247, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1899.72, \"learn_time_ms\": 14068.046}", "{\"n\": 248, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1902.08, \"learn_time_ms\": 14075.396}", "{\"n\": 249, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.67, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1898.52, \"learn_time_ms\": 14073.454}", "{\"n\": 250, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1904.3, \"learn_time_ms\": 14074.51}", "{\"n\": 251, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.62, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1905.58, \"learn_time_ms\": 14072.588}", "{\"n\": 252, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1914.59, \"learn_time_ms\": 14067.532}", "{\"n\": 253, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1919.89, \"learn_time_ms\": 14068.046}", "{\"n\": 254, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1929.38, \"learn_time_ms\": 14067.136}", "{\"n\": 255, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1930.88, \"learn_time_ms\": 14058.86}", "{\"n\": 256, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1924.57, \"learn_time_ms\": 14062.336}", "{\"n\": 257, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1919.45, \"learn_time_ms\": 14072.179}", "{\"n\": 258, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1930.27, \"learn_time_ms\": 14067.844}", "{\"n\": 259, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1925.72, \"learn_time_ms\": 14079.019}", "{\"n\": 260, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.46, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1932.76, \"learn_time_ms\": 14078.091}", "{\"n\": 261, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1936.64, \"learn_time_ms\": 14075.239}", "{\"n\": 262, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1936.64, \"learn_time_ms\": 14078.855}", "{\"n\": 263, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1949.55, \"learn_time_ms\": 14079.337}", "{\"n\": 264, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1945.72, \"learn_time_ms\": 14073.853}", "{\"n\": 265, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1953.41, \"learn_time_ms\": 14065.423}", "{\"n\": 266, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1946.95, \"learn_time_ms\": 14062.243}", "{\"n\": 267, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1950.71, \"learn_time_ms\": 14074.531}", "{\"n\": 268, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1956.53, \"learn_time_ms\": 14070.878}", "{\"n\": 269, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1959.32, \"learn_time_ms\": 14064.967}", "{\"n\": 270, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1959.65, \"learn_time_ms\": 14065.058}", "{\"n\": 271, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.21, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1957.57, \"learn_time_ms\": 14074.657}", "{\"n\": 272, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1955.08, \"learn_time_ms\": 14074.387}", "{\"n\": 273, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1954.63, \"learn_time_ms\": 14074.398}", "{\"n\": 274, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1962.63, \"learn_time_ms\": 14083.328}", "{\"n\": 275, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1961.26, \"learn_time_ms\": 14095.019}", "{\"n\": 276, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1959.02, \"learn_time_ms\": 14094.628}", "{\"n\": 277, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1961.32, \"learn_time_ms\": 14087.937}", "{\"n\": 278, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1962.24, \"learn_time_ms\": 14094.676}", "{\"n\": 279, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1969.15, \"learn_time_ms\": 14088.327}", "{\"n\": 280, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1967.16, \"learn_time_ms\": 14081.508}", "{\"n\": 281, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1963.67, \"learn_time_ms\": 14083.331}", "{\"n\": 282, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1973.35, \"learn_time_ms\": 14093.792}", "{\"n\": 283, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1981.19, \"learn_time_ms\": 14087.311}", "{\"n\": 284, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1985.45, \"learn_time_ms\": 14089.395}", "{\"n\": 285, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1989.23, \"learn_time_ms\": 14086.667}", "{\"n\": 286, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1976.85, \"learn_time_ms\": 14087.116}", "{\"n\": 287, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.21, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1981.5, \"learn_time_ms\": 14083.068}", "{\"n\": 288, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1984.51, \"learn_time_ms\": 14082.945}", "{\"n\": 289, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1986.32, \"learn_time_ms\": 14083.12}", "{\"n\": 290, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1986.32, \"learn_time_ms\": 14089.921}", "{\"n\": 291, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1982.12, \"learn_time_ms\": 14087.405}", "{\"n\": 292, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1983.99, \"learn_time_ms\": 14075.524}", "{\"n\": 293, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1972.17, \"learn_time_ms\": 14079.598}", "{\"n\": 294, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1973.4, \"learn_time_ms\": 14067.871}", "{\"n\": 295, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1966.79, \"learn_time_ms\": 14071.29}", "{\"n\": 296, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1977.42, \"learn_time_ms\": 14073.379}", "{\"n\": 297, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1978.32, \"learn_time_ms\": 14072.614}", "{\"n\": 298, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1972.32, \"learn_time_ms\": 14070.207}", "{\"n\": 299, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1965.57, \"learn_time_ms\": 14072.099}", "{\"n\": 300, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1959.34, \"learn_time_ms\": 14063.023}", "{\"n\": 301, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1961.02, \"learn_time_ms\": 14059.504}", "{\"n\": 302, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1961.86, \"learn_time_ms\": 14072.647}", "{\"n\": 303, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1965.92, \"learn_time_ms\": 14074.325}", "{\"n\": 304, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1962.45, \"learn_time_ms\": 14078.718}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1958.7, \"learn_time_ms\": 14077.049}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1957.71, \"learn_time_ms\": 14077.352}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1965.45, \"learn_time_ms\": 14073.308}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1966.0, \"learn_time_ms\": 14077.252}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1966.4, \"learn_time_ms\": 14073.16}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1973.13, \"learn_time_ms\": 14083.304}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1980.54, \"learn_time_ms\": 14083.813}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1987.24, \"learn_time_ms\": 14083.679}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1987.87, \"learn_time_ms\": 14078.174}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1984.0, \"learn_time_ms\": 14090.431}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1989.61, \"learn_time_ms\": 14092.305}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1989.61, \"learn_time_ms\": 14090.676}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1988.88, \"learn_time_ms\": 14104.125}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1989.08, \"learn_time_ms\": 14097.942}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1989.08, \"learn_time_ms\": 14101.859}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -12.0, \"episode_len_mean\": 1988.11, \"learn_time_ms\": 14106.528}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1998.24, \"learn_time_ms\": 14099.502}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1998.24, \"learn_time_ms\": 14085.946}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1996.55, \"learn_time_ms\": 14092.567}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1989.11, \"learn_time_ms\": 14080.987}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1984.21, \"learn_time_ms\": 14073.15}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1984.21, \"learn_time_ms\": 14075.363}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1972.25, \"learn_time_ms\": 14066.332}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1971.59, \"learn_time_ms\": 14067.309}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1971.59, \"learn_time_ms\": 14064.728}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1973.57, \"learn_time_ms\": 14067.68}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1973.97, \"learn_time_ms\": 14079.28}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1976.56, \"learn_time_ms\": 14088.643}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1986.22, \"learn_time_ms\": 14081.908}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1992.82, \"learn_time_ms\": 14078.36}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1994.81, \"learn_time_ms\": 14081.768}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1993.67, \"learn_time_ms\": 14081.653}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1994.9, \"learn_time_ms\": 14087.86}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1993.74, \"learn_time_ms\": 14090.496}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 1995.36, \"learn_time_ms\": 14088.846}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2007.07, \"learn_time_ms\": 14079.995}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2014.91, \"learn_time_ms\": 14081.384}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2016.58, \"learn_time_ms\": 14078.987}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2021.52, \"learn_time_ms\": 14090.893}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2020.27, \"learn_time_ms\": 14106.714}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2026.24, \"learn_time_ms\": 14115.751}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2026.24, \"learn_time_ms\": 14121.042}", "{\"n\": 347, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2033.83, \"learn_time_ms\": 14113.453}", "{\"n\": 348, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2034.58, \"learn_time_ms\": 14106.483}", "{\"n\": 349, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2035.6, \"learn_time_ms\": 14109.141}", "{\"n\": 350, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2042.23, \"learn_time_ms\": 14113.6}", "{\"n\": 351, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2046.47, \"learn_time_ms\": 14107.116}", "{\"n\": 352, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2042.67, \"learn_time_ms\": 14109.934}", "{\"n\": 353, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2044.52, \"learn_time_ms\": 14109.83}", "{\"n\": 354, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2047.78, \"learn_time_ms\": 14098.554}", "{\"n\": 355, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2043.32, \"learn_time_ms\": 14087.454}", "{\"n\": 356, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2040.44, \"learn_time_ms\": 14076.262}", "{\"n\": 357, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.16, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2049.67, \"learn_time_ms\": 14080.196}", "{\"n\": 358, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2051.1, \"learn_time_ms\": 14083.376}", "{\"n\": 359, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2050.42, \"learn_time_ms\": 14086.729}", "{\"n\": 360, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2058.06, \"learn_time_ms\": 14088.071}", "{\"n\": 361, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2059.26, \"learn_time_ms\": 14094.061}", "{\"n\": 362, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2067.34, \"learn_time_ms\": 14094.839}", "{\"n\": 363, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2065.33, \"learn_time_ms\": 14092.417}", "{\"n\": 364, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.09, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2060.83, \"learn_time_ms\": 14093.492}", "{\"n\": 365, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2064.51, \"learn_time_ms\": 14100.916}", "{\"n\": 366, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2064.24, \"learn_time_ms\": 14108.664}", "{\"n\": 367, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2075.11, \"learn_time_ms\": 14108.851}", "{\"n\": 368, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2077.78, \"learn_time_ms\": 14111.128}", "{\"n\": 369, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2086.6, \"learn_time_ms\": 14108.325}", "{\"n\": 370, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2093.06, \"learn_time_ms\": 14105.521}", "{\"n\": 371, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2087.43, \"learn_time_ms\": 14102.769}", "{\"n\": 372, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2088.99, \"learn_time_ms\": 14097.139}", "{\"n\": 373, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2088.87, \"learn_time_ms\": 14096.778}", "{\"n\": 374, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2087.95, \"learn_time_ms\": 14100.744}", "{\"n\": 375, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2088.64, \"learn_time_ms\": 14099.432}", "{\"n\": 376, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2082.49, \"learn_time_ms\": 14101.67}", "{\"n\": 377, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2086.31, \"learn_time_ms\": 14096.252}", "{\"n\": 378, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2084.79, \"learn_time_ms\": 14088.203}", "{\"n\": 379, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2086.72, \"learn_time_ms\": 14078.749}", "{\"n\": 380, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2077.21, \"learn_time_ms\": 14082.296}", "{\"n\": 381, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2076.32, \"learn_time_ms\": 14083.986}", "{\"n\": 382, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2076.32, \"learn_time_ms\": 14090.949}", "{\"n\": 383, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2067.31, \"learn_time_ms\": 14096.143}", "{\"n\": 384, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2072.13, \"learn_time_ms\": 14092.304}", "{\"n\": 385, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2064.88, \"learn_time_ms\": 14091.474}", "{\"n\": 386, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2065.08, \"learn_time_ms\": 14100.754}", "{\"n\": 387, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2067.06, \"learn_time_ms\": 14102.881}", "{\"n\": 388, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2065.56, \"learn_time_ms\": 14115.275}", "{\"n\": 389, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2063.38, \"learn_time_ms\": 14131.291}", "{\"n\": 390, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2063.96, \"learn_time_ms\": 14116.029}", "{\"n\": 391, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2056.85, \"learn_time_ms\": 14119.15}", "{\"n\": 392, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2054.28, \"learn_time_ms\": 14121.632}", "{\"n\": 393, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2049.24, \"learn_time_ms\": 14109.822}", "{\"n\": 394, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2040.79, \"learn_time_ms\": 14111.589}", "{\"n\": 395, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2042.55, \"learn_time_ms\": 14102.967}", "{\"n\": 396, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.16, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2041.8, \"learn_time_ms\": 14088.57}", "{\"n\": 397, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2046.98, \"learn_time_ms\": 14091.145}", "{\"n\": 398, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2047.06, \"learn_time_ms\": 14091.473}", "{\"n\": 399, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.09, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2035.78, \"learn_time_ms\": 14083.957}", "{\"n\": 400, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2033.35, \"learn_time_ms\": 14085.911}", "{\"n\": 401, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.01, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2039.31, \"learn_time_ms\": 14088.376}", "{\"n\": 402, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2038.34, \"learn_time_ms\": 14084.698}", "{\"n\": 403, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2034.5, \"learn_time_ms\": 14087.814}", "{\"n\": 404, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2033.72, \"learn_time_ms\": 14080.22}", "{\"n\": 405, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2028.94, \"learn_time_ms\": 14083.841}", "{\"n\": 406, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2030.87, \"learn_time_ms\": 14081.756}", "{\"n\": 407, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2025.63, \"learn_time_ms\": 14083.5}", "{\"n\": 408, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.16, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2017.89, \"learn_time_ms\": 14073.734}", "{\"n\": 409, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2006.45, \"learn_time_ms\": 14076.637}", "{\"n\": 410, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2006.45, \"learn_time_ms\": 14088.336}", "{\"n\": 411, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2015.19, \"learn_time_ms\": 14087.205}", "{\"n\": 412, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2011.29, \"learn_time_ms\": 14074.523}", "{\"n\": 413, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2021.76, \"learn_time_ms\": 14086.648}", "{\"n\": 414, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.04, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2030.5, \"learn_time_ms\": 14099.226}", "{\"n\": 415, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2026.25, \"learn_time_ms\": 14101.41}", "{\"n\": 416, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.01, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2038.08, \"learn_time_ms\": 14108.143}", "{\"n\": 417, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2033.24, \"learn_time_ms\": 14102.616}", "{\"n\": 418, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.04, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2032.79, \"learn_time_ms\": 14101.864}", "{\"n\": 419, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.98, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2033.38, \"learn_time_ms\": 14103.703}", "{\"n\": 420, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.98, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2033.38, \"learn_time_ms\": 14095.808}", "{\"n\": 421, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2027.38, \"learn_time_ms\": 14091.767}", "{\"n\": 422, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2035.96, \"learn_time_ms\": 14098.955}", "{\"n\": 423, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.06, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2038.38, \"learn_time_ms\": 14091.409}", "{\"n\": 424, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.01, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2047.53, \"learn_time_ms\": 14083.021}", "{\"n\": 425, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.01, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2052.39, \"learn_time_ms\": 14076.698}", "{\"n\": 426, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2056.35, \"learn_time_ms\": 14076.732}", "{\"n\": 427, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2063.27, \"learn_time_ms\": 14078.041}", "{\"n\": 428, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2063.69, \"learn_time_ms\": 14074.779}", "{\"n\": 429, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2058.94, \"learn_time_ms\": 14074.542}", "{\"n\": 430, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2060.57, \"learn_time_ms\": 14078.178}", "{\"n\": 431, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2059.99, \"learn_time_ms\": 14080.534}", "{\"n\": 432, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2064.77, \"learn_time_ms\": 14078.597}", "{\"n\": 433, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2067.33, \"learn_time_ms\": 14072.265}", "{\"n\": 434, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.81, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2084.49, \"learn_time_ms\": 14070.686}", "{\"n\": 435, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2081.24, \"learn_time_ms\": 14076.428}", "{\"n\": 436, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2084.2, \"learn_time_ms\": 14076.872}", "{\"n\": 437, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.89, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2084.17, \"learn_time_ms\": 14082.516}", "{\"n\": 438, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2090.43, \"learn_time_ms\": 14094.582}", "{\"n\": 439, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2098.11, \"learn_time_ms\": 14102.713}", "{\"n\": 440, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2099.08, \"learn_time_ms\": 14097.013}", "{\"n\": 441, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2096.33, \"learn_time_ms\": 14094.633}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2102.55, \"learn_time_ms\": 14101.191}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2102.55, \"learn_time_ms\": 14099.843}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2105.33, \"learn_time_ms\": 14107.169}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2105.5, \"learn_time_ms\": 14104.404}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2104.11, \"learn_time_ms\": 14111.162}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2110.13, \"learn_time_ms\": 14107.123}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2104.82, \"learn_time_ms\": 14105.04}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2109.7, \"learn_time_ms\": 14090.725}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2112.58, \"learn_time_ms\": 14100.875}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2113.46, \"learn_time_ms\": 14104.628}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2116.12, \"learn_time_ms\": 14099.982}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2107.42, \"learn_time_ms\": 14106.971}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2100.05, \"learn_time_ms\": 14107.244}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2100.24, \"learn_time_ms\": 14110.197}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2093.96, \"learn_time_ms\": 14105.029}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2083.39, \"learn_time_ms\": 14102.591}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2081.4, \"learn_time_ms\": 14096.658}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2069.68, \"learn_time_ms\": 14095.702}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2071.65, \"learn_time_ms\": 14093.081}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2064.64, \"learn_time_ms\": 14091.735}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2065.83, \"learn_time_ms\": 14105.777}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2068.84, \"learn_time_ms\": 14106.63}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2067.19, \"learn_time_ms\": 14096.254}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2060.69, \"learn_time_ms\": 14091.85}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2058.35, \"learn_time_ms\": 14086.935}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2054.6, \"learn_time_ms\": 14095.832}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2055.93, \"learn_time_ms\": 14093.026}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2054.93, \"learn_time_ms\": 14097.825}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2061.95, \"learn_time_ms\": 14094.038}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2067.05, \"learn_time_ms\": 14095.031}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2068.75, \"learn_time_ms\": 14086.825}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2068.19, \"learn_time_ms\": 14091.322}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2065.11, \"learn_time_ms\": 14105.404}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2068.42, \"learn_time_ms\": 14109.13}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2068.42, \"learn_time_ms\": 14110.072}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2076.09, \"learn_time_ms\": 14107.612}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2076.78, \"learn_time_ms\": 14118.564}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2081.8, \"learn_time_ms\": 14127.796}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.2, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2081.81, \"learn_time_ms\": 14137.447}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2082.12, \"learn_time_ms\": 14137.63}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2079.84, \"learn_time_ms\": 14139.547}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2073.27, \"learn_time_ms\": 14127.656}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2082.75, \"learn_time_ms\": 14123.865}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2074.49, \"learn_time_ms\": 14128.673}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2073.08, \"learn_time_ms\": 14125.031}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2072.21, \"learn_time_ms\": 14121.449}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2067.63, \"learn_time_ms\": 14113.391}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2068.63, \"learn_time_ms\": 14107.326}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2063.65, \"learn_time_ms\": 14094.959}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2064.75, \"learn_time_ms\": 14087.991}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2065.58, \"learn_time_ms\": 14077.721}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2069.12, \"learn_time_ms\": 14079.188}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2068.19, \"learn_time_ms\": 14082.35}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2070.29, \"learn_time_ms\": 14081.342}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2071.31, \"learn_time_ms\": 14098.711}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2075.33, \"learn_time_ms\": 14096.999}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2089.76, \"learn_time_ms\": 14103.824}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2093.32, \"learn_time_ms\": 14103.199}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2097.59, \"learn_time_ms\": 14104.991}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2100.38, \"learn_time_ms\": 14100.517}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2102.45, \"learn_time_ms\": 14106.305}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2102.21, \"learn_time_ms\": 14108.949}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2102.4, \"learn_time_ms\": 14102.497}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2095.98, \"learn_time_ms\": 14099.167}", "{\"n\": 506, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.09, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2103.11, \"learn_time_ms\": 14082.664}", "{\"n\": 507, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.09, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2102.8, \"learn_time_ms\": 14091.981}", "{\"n\": 508, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2100.65, \"learn_time_ms\": 14098.392}", "{\"n\": 509, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.06, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2110.05, \"learn_time_ms\": 14107.273}", "{\"n\": 510, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2100.04, \"learn_time_ms\": 14118.544}", "{\"n\": 511, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2096.14, \"learn_time_ms\": 14136.965}", "{\"n\": 512, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2094.22, \"learn_time_ms\": 14135.824}", "{\"n\": 513, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2094.27, \"learn_time_ms\": 14128.405}", "{\"n\": 514, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2094.06, \"learn_time_ms\": 14132.975}", "{\"n\": 515, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2091.67, \"learn_time_ms\": 14139.06}", "{\"n\": 516, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.16, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2088.91, \"learn_time_ms\": 14140.983}", "{\"n\": 517, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2090.41, \"learn_time_ms\": 14132.936}", "{\"n\": 518, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2092.89, \"learn_time_ms\": 14119.798}", "{\"n\": 519, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2092.89, \"learn_time_ms\": 14115.619}", "{\"n\": 520, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2073.29, \"learn_time_ms\": 14111.874}", "{\"n\": 521, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2072.92, \"learn_time_ms\": 14096.559}", "{\"n\": 522, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2074.14, \"learn_time_ms\": 14096.333}", "{\"n\": 523, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2074.44, \"learn_time_ms\": 14104.571}", "{\"n\": 524, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2063.42, \"learn_time_ms\": 14107.934}", "{\"n\": 525, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2068.09, \"learn_time_ms\": 14104.044}", "{\"n\": 526, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2070.03, \"learn_time_ms\": 14106.324}", "{\"n\": 527, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2084.4, \"learn_time_ms\": 14101.643}", "{\"n\": 528, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2084.4, \"learn_time_ms\": 14109.949}", "{\"n\": 529, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2089.86, \"learn_time_ms\": 14100.652}", "{\"n\": 530, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2083.21, \"learn_time_ms\": 14103.888}", "{\"n\": 531, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2081.97, \"learn_time_ms\": 14108.146}", "{\"n\": 532, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2081.38, \"learn_time_ms\": 14108.859}", "{\"n\": 533, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2077.58, \"learn_time_ms\": 14119.148}", "{\"n\": 534, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2081.65, \"learn_time_ms\": 14106.245}", "{\"n\": 535, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2083.83, \"learn_time_ms\": 14105.372}", "{\"n\": 536, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2077.5, \"learn_time_ms\": 14113.061}", "{\"n\": 537, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2084.15, \"learn_time_ms\": 14120.866}", "{\"n\": 538, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2091.42, \"learn_time_ms\": 14118.694}", "{\"n\": 539, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2099.27, \"learn_time_ms\": 14126.649}", "{\"n\": 540, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2094.6, \"learn_time_ms\": 14119.756}", "{\"n\": 541, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2090.75, \"learn_time_ms\": 14112.872}", "{\"n\": 542, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2083.56, \"learn_time_ms\": 14105.219}", "{\"n\": 543, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2083.72, \"learn_time_ms\": 14103.71}", "{\"n\": 544, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.21, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2085.19, \"learn_time_ms\": 14113.149}", "{\"n\": 545, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2107.13, \"learn_time_ms\": 14114.797}", "{\"n\": 546, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2109.43, \"learn_time_ms\": 14097.947}", "{\"n\": 547, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2109.41, \"learn_time_ms\": 14089.387}", "{\"n\": 548, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2113.46, \"learn_time_ms\": 14089.355}", "{\"n\": 549, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2112.28, \"learn_time_ms\": 14083.039}", "{\"n\": 550, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2114.74, \"learn_time_ms\": 14077.384}", "{\"n\": 551, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.14, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2110.72, \"learn_time_ms\": 14087.899}", "{\"n\": 552, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2116.79, \"learn_time_ms\": 14102.746}", "{\"n\": 553, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.01, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2123.52, \"learn_time_ms\": 14089.929}", "{\"n\": 554, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2139.01, \"learn_time_ms\": 14088.899}", "{\"n\": 555, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2138.51, \"learn_time_ms\": 14084.689}", "{\"n\": 556, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2140.86, \"learn_time_ms\": 14087.806}", "{\"n\": 557, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2133.16, \"learn_time_ms\": 14096.251}", "{\"n\": 558, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2123.87, \"learn_time_ms\": 14093.402}", "{\"n\": 559, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2122.64, \"learn_time_ms\": 14090.228}", "{\"n\": 560, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2126.65, \"learn_time_ms\": 14096.75}", "{\"n\": 561, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2126.3, \"learn_time_ms\": 14103.328}", "{\"n\": 562, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2126.3, \"learn_time_ms\": 14096.914}", "{\"n\": 563, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2124.01, \"learn_time_ms\": 14108.835}", "{\"n\": 564, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2138.01, \"learn_time_ms\": 14105.528}", "{\"n\": 565, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2138.01, \"learn_time_ms\": 14108.809}", "{\"n\": 566, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.67, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2148.81, \"learn_time_ms\": 14107.059}", "{\"n\": 567, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.61, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2146.1, \"learn_time_ms\": 14106.137}", "{\"n\": 568, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.51, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2157.96, \"learn_time_ms\": 14114.767}", "{\"n\": 569, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2162.27, \"learn_time_ms\": 14123.253}", "{\"n\": 570, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2162.27, \"learn_time_ms\": 14121.807}", "{\"n\": 571, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2164.68, \"learn_time_ms\": 14106.529}", "{\"n\": 572, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2158.96, \"learn_time_ms\": 14100.077}", "{\"n\": 573, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2155.76, \"learn_time_ms\": 14086.619}", "{\"n\": 574, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2156.26, \"learn_time_ms\": 14086.04}", "{\"n\": 575, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2172.87, \"learn_time_ms\": 14088.988}", "{\"n\": 576, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2178.97, \"learn_time_ms\": 14091.638}", "{\"n\": 577, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2182.15, \"learn_time_ms\": 14083.916}", "{\"n\": 578, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2182.61, \"learn_time_ms\": 14074.247}", "{\"n\": 579, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2182.61, \"learn_time_ms\": 14068.939}", "{\"n\": 580, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2188.53, \"learn_time_ms\": 14071.513}", "{\"n\": 581, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2188.24, \"learn_time_ms\": 14078.277}", "{\"n\": 582, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2194.82, \"learn_time_ms\": 14080.211}", "{\"n\": 583, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2199.97, \"learn_time_ms\": 14083.694}", "{\"n\": 584, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2198.32, \"learn_time_ms\": 14088.641}", "{\"n\": 585, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2200.94, \"learn_time_ms\": 14082.413}", "{\"n\": 586, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2200.07, \"learn_time_ms\": 14089.67}", "{\"n\": 587, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2200.59, \"learn_time_ms\": 14100.48}", "{\"n\": 588, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2194.38, \"learn_time_ms\": 14108.763}", "{\"n\": 589, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2198.13, \"learn_time_ms\": 14110.79}", "{\"n\": 590, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2175.55, \"learn_time_ms\": 14109.116}", "{\"n\": 591, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2172.46, \"learn_time_ms\": 14116.867}", "{\"n\": 592, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2181.1, \"learn_time_ms\": 14113.825}", "{\"n\": 593, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2184.79, \"learn_time_ms\": 14114.637}", "{\"n\": 594, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2204.92, \"learn_time_ms\": 14119.474}", "{\"n\": 595, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2204.92, \"learn_time_ms\": 14118.338}", "{\"n\": 596, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2204.67, \"learn_time_ms\": 14114.158}", "{\"n\": 597, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2206.06, \"learn_time_ms\": 14115.829}", "{\"n\": 598, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2211.92, \"learn_time_ms\": 14104.122}", "{\"n\": 599, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2217.0, \"learn_time_ms\": 14106.039}", "{\"n\": 600, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2206.1, \"learn_time_ms\": 14108.912}", "{\"n\": 601, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2210.59, \"learn_time_ms\": 14103.728}", "{\"n\": 602, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2212.69, \"learn_time_ms\": 14117.325}", "{\"n\": 603, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.01, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2219.64, \"learn_time_ms\": 14130.246}", "{\"n\": 604, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2217.5, \"learn_time_ms\": 14115.122}", "{\"n\": 605, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2230.9, \"learn_time_ms\": 14116.076}", "{\"n\": 606, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2233.6, \"learn_time_ms\": 14125.655}", "{\"n\": 607, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2232.58, \"learn_time_ms\": 14118.335}", "{\"n\": 608, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2247.31, \"learn_time_ms\": 14117.597}", "{\"n\": 609, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2249.33, \"learn_time_ms\": 14115.505}", "{\"n\": 610, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2249.95, \"learn_time_ms\": 14115.131}", "{\"n\": 611, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2244.96, \"learn_time_ms\": 14116.551}", "{\"n\": 612, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2234.97, \"learn_time_ms\": 14117.073}", "{\"n\": 613, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2234.97, \"learn_time_ms\": 14101.265}", "{\"n\": 614, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2231.52, \"learn_time_ms\": 14104.362}", "{\"n\": 615, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2234.78, \"learn_time_ms\": 14101.04}", "{\"n\": 616, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2236.49, \"learn_time_ms\": 14090.044}", "{\"n\": 617, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2239.01, \"learn_time_ms\": 14098.271}", "{\"n\": 618, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2239.3, \"learn_time_ms\": 14105.979}", "{\"n\": 619, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2232.73, \"learn_time_ms\": 14100.262}", "{\"n\": 620, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2227.56, \"learn_time_ms\": 14100.842}", "{\"n\": 621, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2222.23, \"learn_time_ms\": 14092.592}", "{\"n\": 622, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2221.14, \"learn_time_ms\": 14090.078}", "{\"n\": 623, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2216.5, \"learn_time_ms\": 14094.419}", "{\"n\": 624, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2216.45, \"learn_time_ms\": 14099.606}", "{\"n\": 625, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2223.1, \"learn_time_ms\": 14111.203}", "{\"n\": 626, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2221.28, \"learn_time_ms\": 14111.684}", "{\"n\": 627, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2227.01, \"learn_time_ms\": 14095.353}", "{\"n\": 628, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2227.01, \"learn_time_ms\": 14088.027}", "{\"n\": 629, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2239.11, \"learn_time_ms\": 14095.589}", "{\"n\": 630, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2244.4, \"learn_time_ms\": 14099.192}", "{\"n\": 631, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2247.72, \"learn_time_ms\": 14101.314}", "{\"n\": 632, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2259.14, \"learn_time_ms\": 14099.038}", "{\"n\": 633, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2259.14, \"learn_time_ms\": 14099.407}", "{\"n\": 634, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2271.77, \"learn_time_ms\": 14098.634}", "{\"n\": 635, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2295.63, \"learn_time_ms\": 14089.68}", "{\"n\": 636, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2292.96, \"learn_time_ms\": 14099.336}", "{\"n\": 637, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2292.96, \"learn_time_ms\": 14104.21}", "{\"n\": 638, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2299.26, \"learn_time_ms\": 14113.774}", "{\"n\": 639, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2293.7, \"learn_time_ms\": 14111.093}", "{\"n\": 640, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2293.7, \"learn_time_ms\": 14105.156}", "{\"n\": 641, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2289.3, \"learn_time_ms\": 14096.391}", "{\"n\": 642, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2287.03, \"learn_time_ms\": 14093.783}", "{\"n\": 643, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2296.01, \"learn_time_ms\": 14093.929}", "{\"n\": 644, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2297.78, \"learn_time_ms\": 14096.814}", "{\"n\": 645, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2289.47, \"learn_time_ms\": 14106.112}", "{\"n\": 646, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2288.11, \"learn_time_ms\": 14102.499}", "{\"n\": 647, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2291.4, \"learn_time_ms\": 14105.661}", "{\"n\": 648, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2291.4, \"learn_time_ms\": 14104.32}", "{\"n\": 649, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2294.48, \"learn_time_ms\": 14104.586}", "{\"n\": 650, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2295.83, \"learn_time_ms\": 14101.061}", "{\"n\": 651, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2296.64, \"learn_time_ms\": 14110.225}", "{\"n\": 652, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2291.14, \"learn_time_ms\": 14117.166}", "{\"n\": 653, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2288.11, \"learn_time_ms\": 14118.904}", "{\"n\": 654, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2289.5, \"learn_time_ms\": 14120.179}", "{\"n\": 655, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2283.02, \"learn_time_ms\": 14114.32}", "{\"n\": 656, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2282.98, \"learn_time_ms\": 14111.578}", "{\"n\": 657, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2284.8, \"learn_time_ms\": 14110.25}", "{\"n\": 658, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2291.59, \"learn_time_ms\": 14107.436}", "{\"n\": 659, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2287.59, \"learn_time_ms\": 14116.871}", "{\"n\": 660, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2283.53, \"learn_time_ms\": 14123.511}", "{\"n\": 661, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2283.53, \"learn_time_ms\": 14131.807}", "{\"n\": 662, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2283.04, \"learn_time_ms\": 14127.644}", "{\"n\": 663, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2280.53, \"learn_time_ms\": 14122.51}", "{\"n\": 664, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2272.15, \"learn_time_ms\": 14116.846}", "{\"n\": 665, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2276.26, \"learn_time_ms\": 14113.407}", "{\"n\": 666, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2289.45, \"learn_time_ms\": 14107.842}", "{\"n\": 667, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2293.23, \"learn_time_ms\": 14106.63}", "{\"n\": 668, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2297.27, \"learn_time_ms\": 14109.341}", "{\"n\": 669, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2305.59, \"learn_time_ms\": 14106.288}", "{\"n\": 670, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2297.22, \"learn_time_ms\": 14101.444}", "{\"n\": 671, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2300.8, \"learn_time_ms\": 14099.079}", "{\"n\": 672, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2300.85, \"learn_time_ms\": 14093.826}", "{\"n\": 673, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2285.37, \"learn_time_ms\": 14092.445}", "{\"n\": 674, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2281.68, \"learn_time_ms\": 14095.961}", "{\"n\": 675, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2274.8, \"learn_time_ms\": 14093.319}", "{\"n\": 676, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2265.58, \"learn_time_ms\": 14100.807}", "{\"n\": 677, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2264.06, \"learn_time_ms\": 14109.406}", "{\"n\": 678, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2264.06, \"learn_time_ms\": 14105.313}", "{\"n\": 679, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2261.44, \"learn_time_ms\": 14101.086}", "{\"n\": 680, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2245.27, \"learn_time_ms\": 14100.154}", "{\"n\": 681, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.05, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2237.25, \"learn_time_ms\": 14098.886}", "{\"n\": 682, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.05, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2237.25, \"learn_time_ms\": 14102.067}", "{\"n\": 683, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2235.77, \"learn_time_ms\": 14104.907}", "{\"n\": 684, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2242.09, \"learn_time_ms\": 14104.182}", "{\"n\": 685, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2244.35, \"learn_time_ms\": 14105.223}", "{\"n\": 686, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2244.35, \"learn_time_ms\": 14099.555}", "{\"n\": 687, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2247.99, \"learn_time_ms\": 14086.114}", "{\"n\": 688, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2243.67, \"learn_time_ms\": 14090.066}", "{\"n\": 689, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2252.1, \"learn_time_ms\": 14085.218}", "{\"n\": 690, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2260.56, \"learn_time_ms\": 14079.37}", "{\"n\": 691, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2260.04, \"learn_time_ms\": 14079.317}", "{\"n\": 692, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2260.95, \"learn_time_ms\": 14072.521}", "{\"n\": 693, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2260.95, \"learn_time_ms\": 14076.397}", "{\"n\": 694, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2257.33, \"learn_time_ms\": 14074.708}", "{\"n\": 695, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2244.24, \"learn_time_ms\": 14078.641}", "{\"n\": 696, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2244.24, \"learn_time_ms\": 14075.6}", "{\"n\": 697, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2245.76, \"learn_time_ms\": 14086.862}", "{\"n\": 698, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2256.01, \"learn_time_ms\": 14081.845}", "{\"n\": 699, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2264.15, \"learn_time_ms\": 14080.314}", "{\"n\": 700, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2270.14, \"learn_time_ms\": 14090.104}", "{\"n\": 701, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2263.48, \"learn_time_ms\": 14088.738}", "{\"n\": 702, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2255.68, \"learn_time_ms\": 14094.903}", "{\"n\": 703, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2252.19, \"learn_time_ms\": 14094.707}", "{\"n\": 704, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2254.04, \"learn_time_ms\": 14095.739}", "{\"n\": 705, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2261.06, \"learn_time_ms\": 14094.098}", "{\"n\": 706, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2263.15, \"learn_time_ms\": 14096.594}", "{\"n\": 707, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2261.96, \"learn_time_ms\": 14090.222}", "{\"n\": 708, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2261.96, \"learn_time_ms\": 14096.95}", "{\"n\": 709, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2258.0, \"learn_time_ms\": 14105.998}", "{\"n\": 710, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2266.23, \"learn_time_ms\": 14105.522}", "{\"n\": 711, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2261.38, \"learn_time_ms\": 14101.881}", "{\"n\": 712, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2261.38, \"learn_time_ms\": 14097.877}", "{\"n\": 713, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2263.45, \"learn_time_ms\": 14093.519}", "{\"n\": 714, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2268.0, \"learn_time_ms\": 14103.091}", "{\"n\": 715, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2267.74, \"learn_time_ms\": 14102.998}", "{\"n\": 716, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2272.02, \"learn_time_ms\": 14102.934}", "{\"n\": 717, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2269.33, \"learn_time_ms\": 14106.1}", "{\"n\": 718, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2278.46, \"learn_time_ms\": 14103.79}", "{\"n\": 719, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2282.6, \"learn_time_ms\": 14098.803}", "{\"n\": 720, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.48, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2300.31, \"learn_time_ms\": 14097.679}", "{\"n\": 721, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2307.2, \"learn_time_ms\": 14098.154}", "{\"n\": 722, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2314.41, \"learn_time_ms\": 14100.926}", "{\"n\": 723, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2316.45, \"learn_time_ms\": 14087.928}", "{\"n\": 724, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2315.51, \"learn_time_ms\": 14078.426}", "{\"n\": 725, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2311.85, \"learn_time_ms\": 14076.948}", "{\"n\": 726, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.42, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2307.07, \"learn_time_ms\": 14073.958}", "{\"n\": 727, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2315.51, \"learn_time_ms\": 14066.819}", "{\"n\": 728, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2315.51, \"learn_time_ms\": 14065.083}", "{\"n\": 729, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2322.83, \"learn_time_ms\": 14073.526}", "{\"n\": 730, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2325.48, \"learn_time_ms\": 14075.514}", "{\"n\": 731, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.37, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2314.8, \"learn_time_ms\": 14069.923}", "{\"n\": 732, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.37, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2314.8, \"learn_time_ms\": 14070.534}", "{\"n\": 733, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.42, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2313.21, \"learn_time_ms\": 14087.557}", "{\"n\": 734, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2309.33, \"learn_time_ms\": 14088.313}", "{\"n\": 735, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2314.2, \"learn_time_ms\": 14091.44}", "{\"n\": 736, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2314.2, \"learn_time_ms\": 14095.969}", "{\"n\": 737, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2296.07, \"learn_time_ms\": 14096.924}", "{\"n\": 738, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2293.65, \"learn_time_ms\": 14093.146}", "{\"n\": 739, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.5, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2301.76, \"learn_time_ms\": 14084.851}", "{\"n\": 740, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2308.0, \"learn_time_ms\": 14085.161}", "{\"n\": 741, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2313.85, \"learn_time_ms\": 14095.016}", "{\"n\": 742, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2313.85, \"learn_time_ms\": 14094.394}", "{\"n\": 743, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2317.07, \"learn_time_ms\": 14101.549}", "{\"n\": 744, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2314.88, \"learn_time_ms\": 14103.088}", "{\"n\": 745, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2324.24, \"learn_time_ms\": 14099.829}", "{\"n\": 746, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2320.01, \"learn_time_ms\": 14106.334}", "{\"n\": 747, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2316.46, \"learn_time_ms\": 14116.304}", "{\"n\": 748, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2304.82, \"learn_time_ms\": 14119.38}", "{\"n\": 749, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.5, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2309.21, \"learn_time_ms\": 14121.485}", "{\"n\": 750, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2323.76, \"learn_time_ms\": 14109.409}", "{\"n\": 751, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2319.42, \"learn_time_ms\": 14104.723}", "{\"n\": 752, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.48, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2318.04, \"learn_time_ms\": 14107.103}", "{\"n\": 753, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2318.77, \"learn_time_ms\": 14098.255}", "{\"n\": 754, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.5, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2321.11, \"learn_time_ms\": 14096.688}", "{\"n\": 755, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2331.1, \"learn_time_ms\": 14103.835}", "{\"n\": 756, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2333.58, \"learn_time_ms\": 14095.241}", "{\"n\": 757, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2338.88, \"learn_time_ms\": 14087.323}", "{\"n\": 758, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2348.34, \"learn_time_ms\": 14086.681}", "{\"n\": 759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2351.09, \"learn_time_ms\": 14089.473}", "{\"n\": 760, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2353.14, \"learn_time_ms\": 14098.16}", "{\"n\": 761, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2353.14, \"learn_time_ms\": 14094.604}", "{\"n\": 762, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.31, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2355.31, \"learn_time_ms\": 14084.825}", "{\"n\": 763, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.31, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2351.24, \"learn_time_ms\": 14078.647}", "{\"n\": 764, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2349.44, \"learn_time_ms\": 14068.927}", "{\"n\": 765, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2358.1, \"learn_time_ms\": 14058.85}", "{\"n\": 766, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2358.1, \"learn_time_ms\": 14056.675}", "{\"n\": 767, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2350.1, \"learn_time_ms\": 14057.711}", "{\"n\": 768, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2353.73, \"learn_time_ms\": 14059.411}", "{\"n\": 769, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2344.82, \"learn_time_ms\": 14057.302}", "{\"n\": 770, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2348.69, \"learn_time_ms\": 14052.246}", "{\"n\": 771, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2341.16, \"learn_time_ms\": 14056.609}", "{\"n\": 772, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2338.59, \"learn_time_ms\": 14068.363}", "{\"n\": 773, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.37, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2340.14, \"learn_time_ms\": 14077.462}", "{\"n\": 774, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2347.65, \"learn_time_ms\": 14078.006}", "{\"n\": 775, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.31, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2353.31, \"learn_time_ms\": 14079.98}", "{\"n\": 776, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2355.33, \"learn_time_ms\": 14082.673}", "{\"n\": 777, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2357.79, \"learn_time_ms\": 14083.131}", "{\"n\": 778, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2357.57, \"learn_time_ms\": 14084.763}", "{\"n\": 779, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2350.29, \"learn_time_ms\": 14079.632}", "{\"n\": 780, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2348.67, \"learn_time_ms\": 14081.705}", "{\"n\": 781, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2356.81, \"learn_time_ms\": 14085.619}", "{\"n\": 782, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2363.67, \"learn_time_ms\": 14083.327}", "{\"n\": 783, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2373.32, \"learn_time_ms\": 14081.324}", "{\"n\": 784, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2386.16, \"learn_time_ms\": 14083.543}", "{\"n\": 785, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2386.16, \"learn_time_ms\": 14089.17}", "{\"n\": 786, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.2, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2389.53, \"learn_time_ms\": 14097.624}", "{\"n\": 787, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.2, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2389.53, \"learn_time_ms\": 14090.445}", "{\"n\": 788, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2387.89, \"learn_time_ms\": 14081.766}", "{\"n\": 789, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2387.89, \"learn_time_ms\": 14089.066}", "{\"n\": 790, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2376.41, \"learn_time_ms\": 14094.444}", "{\"n\": 791, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2380.45, \"learn_time_ms\": 14091.936}", "{\"n\": 792, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2390.53, \"learn_time_ms\": 14090.532}", "{\"n\": 793, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.22, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2391.69, \"learn_time_ms\": 14086.359}", "{\"n\": 794, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2397.12, \"learn_time_ms\": 14087.04}", "{\"n\": 795, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.19, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2396.3, \"learn_time_ms\": 14088.442}", "{\"n\": 796, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2397.71, \"learn_time_ms\": 14084.98}", "{\"n\": 797, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.19, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2394.57, \"learn_time_ms\": 14086.429}", "{\"n\": 798, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.22, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2387.22, \"learn_time_ms\": 14091.337}", "{\"n\": 799, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2386.05, \"learn_time_ms\": 14081.765}", "{\"n\": 800, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.16, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2397.77, \"learn_time_ms\": 14079.084}", "{\"n\": 801, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2406.98, \"learn_time_ms\": 14078.908}", "{\"n\": 802, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2409.63, \"learn_time_ms\": 14082.129}", "{\"n\": 803, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2408.32, \"learn_time_ms\": 14074.952}", "{\"n\": 804, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2409.05, \"learn_time_ms\": 14085.21}", "{\"n\": 805, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2417.5, \"learn_time_ms\": 14077.218}", "{\"n\": 806, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.01, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2407.57, \"learn_time_ms\": 14070.346}", "{\"n\": 807, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2411.1, \"learn_time_ms\": 14079.544}", "{\"n\": 808, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.98, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2412.48, \"learn_time_ms\": 14073.824}", "{\"n\": 809, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2411.08, \"learn_time_ms\": 14083.713}", "{\"n\": 810, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.89, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2416.85, \"learn_time_ms\": 14081.484}", "{\"n\": 811, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.84, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2417.44, \"learn_time_ms\": 14075.078}", "{\"n\": 812, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.84, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2423.7, \"learn_time_ms\": 14064.797}", "{\"n\": 813, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2417.25, \"learn_time_ms\": 14078.834}", "{\"n\": 814, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2407.07, \"learn_time_ms\": 14072.794}", "{\"n\": 815, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2414.97, \"learn_time_ms\": 14080.584}", "{\"n\": 816, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.9, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2420.72, \"learn_time_ms\": 14085.466}", "{\"n\": 817, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.9, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2415.04, \"learn_time_ms\": 14083.679}", "{\"n\": 818, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2413.83, \"learn_time_ms\": 14094.414}", "{\"n\": 819, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2411.15, \"learn_time_ms\": 14089.301}", "{\"n\": 820, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2410.55, \"learn_time_ms\": 14093.438}", "{\"n\": 821, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2418.68, \"learn_time_ms\": 14100.337}", "{\"n\": 822, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.8, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2424.87, \"learn_time_ms\": 14091.563}", "{\"n\": 823, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.77, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2429.11, \"learn_time_ms\": 14089.162}", "{\"n\": 824, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2429.35, \"learn_time_ms\": 14090.067}", "{\"n\": 825, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2429.09, \"learn_time_ms\": 14085.087}", "{\"n\": 826, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2423.12, \"learn_time_ms\": 14090.083}", "{\"n\": 827, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.8, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2421.83, \"learn_time_ms\": 14093.369}", "{\"n\": 828, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.79, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2420.54, \"learn_time_ms\": 14091.513}", "{\"n\": 829, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.8, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2417.2, \"learn_time_ms\": 14089.303}", "{\"n\": 830, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.82, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2420.82, \"learn_time_ms\": 14085.934}", "{\"n\": 831, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.76, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2425.13, \"learn_time_ms\": 14080.559}", "{\"n\": 832, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2430.12, \"learn_time_ms\": 14095.627}", "{\"n\": 833, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2425.47, \"learn_time_ms\": 14091.363}", "{\"n\": 834, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.71, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2414.66, \"learn_time_ms\": 14091.685}", "{\"n\": 835, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2412.27, \"learn_time_ms\": 14092.572}", "{\"n\": 836, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.63, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2420.33, \"learn_time_ms\": 14092.285}", "{\"n\": 837, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.62, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2419.86, \"learn_time_ms\": 14096.49}", "{\"n\": 838, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2427.77, \"learn_time_ms\": 14097.365}", "{\"n\": 839, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.64, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2426.99, \"learn_time_ms\": 14099.285}", "{\"n\": 840, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2435.41, \"learn_time_ms\": 14102.586}", "{\"n\": 841, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2431.7, \"learn_time_ms\": 14094.459}", "{\"n\": 842, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.62, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2428.34, \"learn_time_ms\": 14094.562}", "{\"n\": 843, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2420.36, \"learn_time_ms\": 14097.214}", "{\"n\": 844, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2413.29, \"learn_time_ms\": 14098.641}", "{\"n\": 845, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.69, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2417.5, \"learn_time_ms\": 14105.247}", "{\"n\": 846, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.69, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2417.5, \"learn_time_ms\": 14100.453}", "{\"n\": 847, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.69, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2416.97, \"learn_time_ms\": 14088.827}", "{\"n\": 848, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2434.99, \"learn_time_ms\": 14081.32}", "{\"n\": 849, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.57, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2433.85, \"learn_time_ms\": 14082.081}", "{\"n\": 850, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.56, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2431.42, \"learn_time_ms\": 14084.02}", "{\"n\": 851, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2431.1, \"learn_time_ms\": 14092.383}", "{\"n\": 852, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.42, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2442.32, \"learn_time_ms\": 14093.603}", "{\"n\": 853, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.42, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2442.32, \"learn_time_ms\": 14092.774}", "{\"n\": 854, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.44, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2442.13, \"learn_time_ms\": 14086.091}", "{\"n\": 855, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.4, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2443.47, \"learn_time_ms\": 14077.35}", "{\"n\": 856, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2434.99, \"learn_time_ms\": 14074.778}", "{\"n\": 857, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.4, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2434.6, \"learn_time_ms\": 14075.53}", "{\"n\": 858, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2444.05, \"learn_time_ms\": 14079.425}", "{\"n\": 859, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2447.39, \"learn_time_ms\": 14086.304}", "{\"n\": 860, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2448.46, \"learn_time_ms\": 14082.591}", "{\"n\": 861, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2446.0, \"learn_time_ms\": 14079.145}", "{\"n\": 862, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2443.9, \"learn_time_ms\": 14079.332}", "{\"n\": 863, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2442.38, \"learn_time_ms\": 14080.811}", "{\"n\": 864, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2446.03, \"learn_time_ms\": 14082.737}", "{\"n\": 865, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2454.87, \"learn_time_ms\": 14082.916}", "{\"n\": 866, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2453.57, \"learn_time_ms\": 14089.402}", "{\"n\": 867, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2455.53, \"learn_time_ms\": 14090.492}", "{\"n\": 868, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2453.03, \"learn_time_ms\": 14094.143}", "{\"n\": 869, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2454.27, \"learn_time_ms\": 14088.142}", "{\"n\": 870, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2461.07, \"learn_time_ms\": 14087.672}", "{\"n\": 871, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2467.05, \"learn_time_ms\": 14082.004}", "{\"n\": 872, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2457.6, \"learn_time_ms\": 14074.947}", "{\"n\": 873, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2457.97, \"learn_time_ms\": 14072.784}", "{\"n\": 874, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2462.2, \"learn_time_ms\": 14073.559}", "{\"n\": 875, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2456.41, \"learn_time_ms\": 14075.45}", "{\"n\": 876, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2466.8, \"learn_time_ms\": 14063.808}", "{\"n\": 877, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2472.62, \"learn_time_ms\": 14062.0}", "{\"n\": 878, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2469.19, \"learn_time_ms\": 14066.415}", "{\"n\": 879, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2477.74, \"learn_time_ms\": 14063.533}", "{\"n\": 880, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2473.23, \"learn_time_ms\": 14060.888}", "{\"n\": 881, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2471.12, \"learn_time_ms\": 14063.375}", "{\"n\": 882, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2476.82, \"learn_time_ms\": 14060.359}", "{\"n\": 883, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2469.38, \"learn_time_ms\": 14055.477}", "{\"n\": 884, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2469.4, \"learn_time_ms\": 14056.172}", "{\"n\": 885, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2480.67, \"learn_time_ms\": 14056.093}", "{\"n\": 886, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2476.86, \"learn_time_ms\": 14071.416}", "{\"n\": 887, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2479.13, \"learn_time_ms\": 14071.452}", "{\"n\": 888, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2474.19, \"learn_time_ms\": 14059.114}", "{\"n\": 889, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2472.2, \"learn_time_ms\": 14054.07}", "{\"n\": 890, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2460.24, \"learn_time_ms\": 14061.924}", "{\"n\": 891, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2459.53, \"learn_time_ms\": 14071.795}", "{\"n\": 892, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2467.04, \"learn_time_ms\": 14088.928}", "{\"n\": 893, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2481.63, \"learn_time_ms\": 14093.9}", "{\"n\": 894, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2481.92, \"learn_time_ms\": 14097.217}", "{\"n\": 895, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2497.08, \"learn_time_ms\": 14095.595}", "{\"n\": 896, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2492.26, \"learn_time_ms\": 14088.69}", "{\"n\": 897, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2492.26, \"learn_time_ms\": 14091.261}", "{\"n\": 898, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2492.26, \"learn_time_ms\": 14093.715}", "{\"n\": 899, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2487.31, \"learn_time_ms\": 14108.512}", "{\"n\": 900, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2486.9, \"learn_time_ms\": 14106.756}", "{\"n\": 901, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2484.72, \"learn_time_ms\": 14097.859}", "{\"n\": 902, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2483.81, \"learn_time_ms\": 14089.672}", "{\"n\": 903, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2463.61, \"learn_time_ms\": 14089.064}", "{\"n\": 904, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2463.61, \"learn_time_ms\": 14085.062}", "{\"n\": 905, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2463.61, \"learn_time_ms\": 14084.964}", "{\"n\": 906, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2450.01, \"learn_time_ms\": 14085.481}", "{\"n\": 907, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2470.05, \"learn_time_ms\": 14079.869}", "{\"n\": 908, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2469.94, \"learn_time_ms\": 14089.205}", "{\"n\": 909, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2455.22, \"learn_time_ms\": 14073.255}", "{\"n\": 910, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2461.22, \"learn_time_ms\": 14076.431}", "{\"n\": 911, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2455.25, \"learn_time_ms\": 14083.332}", "{\"n\": 912, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2457.23, \"learn_time_ms\": 14082.104}", "{\"n\": 913, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2457.23, \"learn_time_ms\": 14089.35}", "{\"n\": 914, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2460.2, \"learn_time_ms\": 14092.021}", "{\"n\": 915, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2464.58, \"learn_time_ms\": 14087.826}", "{\"n\": 916, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2466.76, \"learn_time_ms\": 14090.592}", "{\"n\": 917, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2469.8, \"learn_time_ms\": 14101.048}", "{\"n\": 918, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.55, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2474.02, \"learn_time_ms\": 14097.233}", "{\"n\": 919, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.55, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2474.02, \"learn_time_ms\": 14107.315}", "{\"n\": 920, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2470.5, \"learn_time_ms\": 14096.784}", "{\"n\": 921, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2464.5, \"learn_time_ms\": 14094.628}", "{\"n\": 922, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2460.18, \"learn_time_ms\": 14100.944}", "{\"n\": 923, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2465.21, \"learn_time_ms\": 14094.337}", "{\"n\": 924, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2473.17, \"learn_time_ms\": 14088.414}", "{\"n\": 925, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.6, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2460.52, \"learn_time_ms\": 14097.463}", "{\"n\": 926, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2466.41, \"learn_time_ms\": 14103.702}", "{\"n\": 927, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2452.58, \"learn_time_ms\": 14103.69}", "{\"n\": 928, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2448.32, \"learn_time_ms\": 14101.067}", "{\"n\": 929, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2459.94, \"learn_time_ms\": 14102.635}", "{\"n\": 930, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2459.94, \"learn_time_ms\": 14110.615}", "{\"n\": 931, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2457.59, \"learn_time_ms\": 14116.638}", "{\"n\": 932, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2458.7, \"learn_time_ms\": 14101.564}", "{\"n\": 933, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2457.05, \"learn_time_ms\": 14104.664}", "{\"n\": 934, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2457.05, \"learn_time_ms\": 14101.663}", "{\"n\": 935, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2469.14, \"learn_time_ms\": 14100.637}", "{\"n\": 936, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.61, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2461.48, \"learn_time_ms\": 14094.986}", "{\"n\": 937, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2457.33, \"learn_time_ms\": 14091.559}", "{\"n\": 938, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2465.52, \"learn_time_ms\": 14089.793}", "{\"n\": 939, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2475.39, \"learn_time_ms\": 14080.877}", "{\"n\": 940, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.54, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2475.39, \"learn_time_ms\": 14063.903}", "{\"n\": 941, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2480.09, \"learn_time_ms\": 14059.126}", "{\"n\": 942, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2480.09, \"learn_time_ms\": 14073.093}", "{\"n\": 943, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.48, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2481.47, \"learn_time_ms\": 14086.731}", "{\"n\": 944, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.52, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2477.39, \"learn_time_ms\": 14091.799}", "{\"n\": 945, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.53, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2475.46, \"learn_time_ms\": 14082.632}", "{\"n\": 946, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.56, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2470.06, \"learn_time_ms\": 14073.294}", "{\"n\": 947, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2482.55, \"learn_time_ms\": 14063.494}", "{\"n\": 948, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.42, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2487.33, \"learn_time_ms\": 14068.635}", "{\"n\": 949, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.41, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2489.81, \"learn_time_ms\": 14077.911}", "{\"n\": 950, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.42, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2486.37, \"learn_time_ms\": 14090.039}", "{\"n\": 951, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.34, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2493.34, \"learn_time_ms\": 14086.131}", "{\"n\": 952, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.35, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2489.46, \"learn_time_ms\": 14085.985}", "{\"n\": 953, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.31, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2491.41, \"learn_time_ms\": 14069.005}", "{\"n\": 954, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2497.77, \"learn_time_ms\": 14067.698}", "{\"n\": 955, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.31, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2495.91, \"learn_time_ms\": 14073.527}", "{\"n\": 956, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.33, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2488.46, \"learn_time_ms\": 14073.541}", "{\"n\": 957, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.33, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2489.55, \"learn_time_ms\": 14083.818}", "{\"n\": 958, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2494.81, \"learn_time_ms\": 14077.638}", "{\"n\": 959, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2489.03, \"learn_time_ms\": 14072.585}", "{\"n\": 960, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.24, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2494.65, \"learn_time_ms\": 14070.099}", "{\"n\": 961, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.24, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2491.09, \"learn_time_ms\": 14078.524}", "{\"n\": 962, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2497.6, \"learn_time_ms\": 14080.027}", "{\"n\": 963, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.15, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2495.87, \"learn_time_ms\": 14073.519}", "{\"n\": 964, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2488.71, \"learn_time_ms\": 14074.865}", "{\"n\": 965, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2486.32, \"learn_time_ms\": 14073.863}", "{\"n\": 966, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2468.29, \"learn_time_ms\": 14073.181}", "{\"n\": 967, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2468.29, \"learn_time_ms\": 14066.63}", "{\"n\": 968, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2466.6, \"learn_time_ms\": 14061.183}", "{\"n\": 969, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2461.44, \"learn_time_ms\": 14064.893}", "{\"n\": 970, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2464.27, \"learn_time_ms\": 14067.695}", "{\"n\": 971, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2464.27, \"learn_time_ms\": 14067.0}", "{\"n\": 972, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2464.27, \"learn_time_ms\": 14054.367}", "{\"n\": 973, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2468.61, \"learn_time_ms\": 14058.722}", "{\"n\": 974, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.15, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2459.82, \"learn_time_ms\": 14062.994}", "{\"n\": 975, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.15, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2459.82, \"learn_time_ms\": 14073.146}", "{\"n\": 976, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.15, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2459.82, \"learn_time_ms\": 14077.637}", "{\"n\": 977, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2472.01, \"learn_time_ms\": 14089.448}", "{\"n\": 978, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2485.62, \"learn_time_ms\": 14095.868}", "{\"n\": 979, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2485.62, \"learn_time_ms\": 14091.475}", "{\"n\": 980, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2491.37, \"learn_time_ms\": 14090.069}", "{\"n\": 981, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2480.53, \"learn_time_ms\": 14087.531}", "{\"n\": 982, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2483.76, \"learn_time_ms\": 14102.675}", "{\"n\": 983, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2488.63, \"learn_time_ms\": 14103.014}", "{\"n\": 984, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2501.8, \"learn_time_ms\": 14106.165}", "{\"n\": 985, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2499.88, \"learn_time_ms\": 14102.112}", "{\"n\": 986, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.95, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2504.28, \"learn_time_ms\": 14103.769}", "{\"n\": 987, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2497.43, \"learn_time_ms\": 14103.991}", "{\"n\": 988, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2494.54, \"learn_time_ms\": 14108.342}", "{\"n\": 989, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2507.75, \"learn_time_ms\": 14109.748}", "{\"n\": 990, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.88, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2504.1, \"learn_time_ms\": 14108.317}", "{\"n\": 991, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2497.28, \"learn_time_ms\": 14105.259}", "{\"n\": 992, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2508.53, \"learn_time_ms\": 14096.554}", "{\"n\": 993, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2508.53, \"learn_time_ms\": 14100.795}", "{\"n\": 994, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2515.36, \"learn_time_ms\": 14100.603}", "{\"n\": 995, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2519.93, \"learn_time_ms\": 14093.903}", "{\"n\": 996, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2519.93, \"learn_time_ms\": 14097.947}", "{\"n\": 997, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2524.38, \"learn_time_ms\": 14099.484}", "{\"n\": 998, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2534.63, \"learn_time_ms\": 14104.457}", "{\"n\": 999, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2535.1, \"learn_time_ms\": 14115.302}", "{\"n\": 1000, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2535.1, \"learn_time_ms\": 14131.43}"]["{\"n\": 1001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 23170.525}", "{\"n\": 1002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 22570.093}", "{\"n\": 1003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 22355.292}", "{\"n\": 1004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 22236.547}", "{\"n\": 1005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 22173.887}", "{\"n\": 1006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 22112.14}", "{\"n\": 1007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 22066.71}", "{\"n\": 1008, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -14.5, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2390.75, \"learn_time_ms\": 22043.751}", "{\"n\": 1009, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -14.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2383.8, \"learn_time_ms\": 22028.11}", "{\"n\": 1010, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -13.125, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2588.875, \"learn_time_ms\": 22010.592}", "{\"n\": 1011, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -13.125, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2588.875, \"learn_time_ms\": 21885.564}", "{\"n\": 1012, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -13.333333333333334, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2469.4166666666665, \"learn_time_ms\": 21879.47}", "{\"n\": 1013, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -13.333333333333334, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2469.4166666666665, \"learn_time_ms\": 21875.732}", "{\"n\": 1014, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.866666666666667, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2546.866666666667, \"learn_time_ms\": 21883.431}", "{\"n\": 1015, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.058823529411764, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2539.4117647058824, \"learn_time_ms\": 21882.479}", "{\"n\": 1016, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.944444444444445, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2553.722222222222, \"learn_time_ms\": 21886.003}", "{\"n\": 1017, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2544.95, \"learn_time_ms\": 21898.2}", "{\"n\": 1018, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73913043478261, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2562.3478260869565, \"learn_time_ms\": 21902.465}", "{\"n\": 1019, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2575.48, \"learn_time_ms\": 21902.528}", "{\"n\": 1020, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2575.48, \"learn_time_ms\": 21907.97}", "{\"n\": 1021, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.344827586206897, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2588.9310344827586, \"learn_time_ms\": 21898.848}", "{\"n\": 1022, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.344827586206897, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2588.9310344827586, \"learn_time_ms\": 21891.662}", "{\"n\": 1023, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5625, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2559.03125, \"learn_time_ms\": 21886.87}", "{\"n\": 1024, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.606060606060606, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2555.969696969697, \"learn_time_ms\": 21877.789}", "{\"n\": 1025, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.628571428571428, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2551.0857142857144, \"learn_time_ms\": 21883.311}", "{\"n\": 1026, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.722222222222221, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2538.527777777778, \"learn_time_ms\": 21870.075}", "{\"n\": 1027, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.81578947368421, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2537.842105263158, \"learn_time_ms\": 21870.227}", "{\"n\": 1028, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.675, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2556.125, \"learn_time_ms\": 21868.475}", "{\"n\": 1029, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.682926829268293, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2548.7804878048782, \"learn_time_ms\": 21877.23}", "{\"n\": 1030, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.613636363636363, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2559.9772727272725, \"learn_time_ms\": 21877.911}", "{\"n\": 1031, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.673913043478262, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2569.1304347826085, \"learn_time_ms\": 21891.506}", "{\"n\": 1032, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.680851063829786, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2569.276595744681, \"learn_time_ms\": 21884.641}", "{\"n\": 1033, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.489795918367347, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2594.918367346939, \"learn_time_ms\": 21890.755}", "{\"n\": 1034, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.490196078431373, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2598.450980392157, \"learn_time_ms\": 21884.182}", "{\"n\": 1035, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.471698113207546, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2605.867924528302, \"learn_time_ms\": 21869.788}", "{\"n\": 1036, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.618181818181819, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2595.0545454545454, \"learn_time_ms\": 21886.579}", "{\"n\": 1037, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.649122807017545, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2601.0701754385964, \"learn_time_ms\": 21877.014}", "{\"n\": 1038, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.741379310344827, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2587.293103448276, \"learn_time_ms\": 21873.268}", "{\"n\": 1039, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.672131147540984, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2592.7049180327867, \"learn_time_ms\": 21861.472}", "{\"n\": 1040, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.698412698412698, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2599.4444444444443, \"learn_time_ms\": 21857.584}", "{\"n\": 1041, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.698412698412698, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2599.4444444444443, \"learn_time_ms\": 21852.346}", "{\"n\": 1042, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.723076923076922, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2604.923076923077, \"learn_time_ms\": 21859.75}", "{\"n\": 1043, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.695652173913043, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2599.5652173913045, \"learn_time_ms\": 21855.364}", "{\"n\": 1044, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.685714285714285, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2603.114285714286, \"learn_time_ms\": 21866.258}", "{\"n\": 1045, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67605633802817, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2606.3380281690143, \"learn_time_ms\": 21877.175}", "{\"n\": 1046, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.652777777777779, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2611.4861111111113, \"learn_time_ms\": 21878.509}", "{\"n\": 1047, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.657894736842104, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2611.2236842105262, \"learn_time_ms\": 21867.583}", "{\"n\": 1048, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.7012987012987, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2607.6233766233768, \"learn_time_ms\": 21864.118}", "{\"n\": 1049, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.7125, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2607.9375, \"learn_time_ms\": 21856.945}", "{\"n\": 1050, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74074074074074, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2602.074074074074, \"learn_time_ms\": 21861.208}", "{\"n\": 1051, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.734939759036145, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2600.879518072289, \"learn_time_ms\": 21863.309}", "{\"n\": 1052, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.726190476190476, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2604.1071428571427, \"learn_time_ms\": 21869.18}", "{\"n\": 1053, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69767441860465, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2610.732558139535, \"learn_time_ms\": 21873.801}", "{\"n\": 1054, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.784090909090908, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2604.568181818182, \"learn_time_ms\": 21834.885}", "{\"n\": 1055, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.811111111111112, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2599.9444444444443, \"learn_time_ms\": 21820.237}", "{\"n\": 1056, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.835164835164836, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2596.3736263736264, \"learn_time_ms\": 21811.545}", "{\"n\": 1057, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77659574468085, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2602.68085106383, \"learn_time_ms\": 21825.082}", "{\"n\": 1058, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.789473684210526, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2603.021052631579, \"learn_time_ms\": 21835.014}", "{\"n\": 1059, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.775510204081632, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2604.295918367347, \"learn_time_ms\": 21843.92}", "{\"n\": 1060, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.757575757575758, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2605.3232323232323, \"learn_time_ms\": 21835.165}", "{\"n\": 1061, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2609.62, \"learn_time_ms\": 21838.508}", "{\"n\": 1062, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2614.25, \"learn_time_ms\": 21839.15}", "{\"n\": 1063, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2617.83, \"learn_time_ms\": 21835.256}", "{\"n\": 1064, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2613.7, \"learn_time_ms\": 21872.818}", "{\"n\": 1065, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2612.51, \"learn_time_ms\": 21880.438}", "{\"n\": 1066, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2618.25, \"learn_time_ms\": 21885.737}", "{\"n\": 1067, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2631.7, \"learn_time_ms\": 21883.165}", "{\"n\": 1068, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2622.71, \"learn_time_ms\": 21869.143}", "{\"n\": 1069, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2612.13, \"learn_time_ms\": 21873.239}", "{\"n\": 1070, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2617.3, \"learn_time_ms\": 21868.88}", "{\"n\": 1071, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2616.39, \"learn_time_ms\": 21855.792}", "{\"n\": 1072, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2618.04, \"learn_time_ms\": 21845.717}", "{\"n\": 1073, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2599.57, \"learn_time_ms\": 21849.722}", "{\"n\": 1074, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2605.5, \"learn_time_ms\": 21846.573}", "{\"n\": 1075, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2611.26, \"learn_time_ms\": 21830.152}", "{\"n\": 1076, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2605.47, \"learn_time_ms\": 21828.533}", "{\"n\": 1077, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2616.98, \"learn_time_ms\": 21836.735}", "{\"n\": 1078, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2619.44, \"learn_time_ms\": 21835.822}", "{\"n\": 1079, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2619.44, \"learn_time_ms\": 21830.008}", "{\"n\": 1080, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2623.54, \"learn_time_ms\": 21825.231}", "{\"n\": 1081, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2631.0, \"learn_time_ms\": 21831.679}", "{\"n\": 1082, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2629.32, \"learn_time_ms\": 21840.23}", "{\"n\": 1083, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2629.23, \"learn_time_ms\": 21824.153}", "{\"n\": 1084, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.68, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2636.38, \"learn_time_ms\": 21826.515}", "{\"n\": 1085, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2634.85, \"learn_time_ms\": 21846.369}", "{\"n\": 1086, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2637.01, \"learn_time_ms\": 21847.212}", "{\"n\": 1087, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.7, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2633.03, \"learn_time_ms\": 21841.556}", "{\"n\": 1088, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2626.21, \"learn_time_ms\": 21846.824}", "{\"n\": 1089, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2620.58, \"learn_time_ms\": 21843.902}", "{\"n\": 1090, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2622.28, \"learn_time_ms\": 21851.279}", "{\"n\": 1091, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2631.88, \"learn_time_ms\": 21857.191}", "{\"n\": 1092, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2632.31, \"learn_time_ms\": 21852.804}", "{\"n\": 1093, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2641.81, \"learn_time_ms\": 21864.841}", "{\"n\": 1094, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2636.44, \"learn_time_ms\": 21865.725}", "{\"n\": 1095, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.64, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2632.35, \"learn_time_ms\": 21860.0}", "{\"n\": 1096, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2633.94, \"learn_time_ms\": 21858.347}", "{\"n\": 1097, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2627.62, \"learn_time_ms\": 21860.835}", "{\"n\": 1098, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2637.81, \"learn_time_ms\": 21865.49}", "{\"n\": 1099, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2647.13, \"learn_time_ms\": 21871.927}", "{\"n\": 1100, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2650.4, \"learn_time_ms\": 21885.275}", "{\"n\": 1101, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2650.4, \"learn_time_ms\": 21877.599}", "{\"n\": 1102, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2666.07, \"learn_time_ms\": 21879.514}", "{\"n\": 1103, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2669.99, \"learn_time_ms\": 21886.506}", "{\"n\": 1104, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2669.99, \"learn_time_ms\": 21882.976}", "{\"n\": 1105, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2676.87, \"learn_time_ms\": 21888.965}", "{\"n\": 1106, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2680.91, \"learn_time_ms\": 21879.13}", "{\"n\": 1107, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2672.24, \"learn_time_ms\": 21877.519}", "{\"n\": 1108, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2672.24, \"learn_time_ms\": 21873.031}", "{\"n\": 1109, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2665.91, \"learn_time_ms\": 21874.6}", "{\"n\": 1110, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2673.33, \"learn_time_ms\": 21866.605}", "{\"n\": 1111, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2680.58, \"learn_time_ms\": 21858.542}", "{\"n\": 1112, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2685.03, \"learn_time_ms\": 21855.768}", "{\"n\": 1113, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2689.38, \"learn_time_ms\": 21845.784}", "{\"n\": 1114, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2682.31, \"learn_time_ms\": 21839.375}", "{\"n\": 1115, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2697.4, \"learn_time_ms\": 21836.279}", "{\"n\": 1116, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2693.42, \"learn_time_ms\": 21851.284}", "{\"n\": 1117, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2693.62, \"learn_time_ms\": 21843.524}", "{\"n\": 1118, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2689.51, \"learn_time_ms\": 21841.01}", "{\"n\": 1119, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2689.64, \"learn_time_ms\": 21820.537}", "{\"n\": 1120, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2689.64, \"learn_time_ms\": 21822.508}", "{\"n\": 1121, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2693.34, \"learn_time_ms\": 21830.705}", "{\"n\": 1122, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2693.34, \"learn_time_ms\": 21831.014}", "{\"n\": 1123, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2694.37, \"learn_time_ms\": 21835.282}", "{\"n\": 1124, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2692.95, \"learn_time_ms\": 21840.448}", "{\"n\": 1125, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2699.24, \"learn_time_ms\": 21838.828}", "{\"n\": 1126, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2705.48, \"learn_time_ms\": 21828.638}", "{\"n\": 1127, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2716.21, \"learn_time_ms\": 21835.161}", "{\"n\": 1128, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2718.45, \"learn_time_ms\": 21839.036}", "{\"n\": 1129, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2731.39, \"learn_time_ms\": 21848.133}", "{\"n\": 1130, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2733.45, \"learn_time_ms\": 21849.079}", "{\"n\": 1131, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2728.23, \"learn_time_ms\": 21849.597}", "{\"n\": 1132, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2722.27, \"learn_time_ms\": 21858.04}", "{\"n\": 1133, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2724.29, \"learn_time_ms\": 21852.59}", "{\"n\": 1134, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2724.29, \"learn_time_ms\": 21849.916}", "{\"n\": 1135, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2720.11, \"learn_time_ms\": 21856.067}", "{\"n\": 1136, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2723.01, \"learn_time_ms\": 21856.299}", "{\"n\": 1137, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2723.24, \"learn_time_ms\": 21853.913}", "{\"n\": 1138, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2723.24, \"learn_time_ms\": 21854.814}", "{\"n\": 1139, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2725.63, \"learn_time_ms\": 21849.594}", "{\"n\": 1140, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2738.3, \"learn_time_ms\": 21845.315}", "{\"n\": 1141, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2727.32, \"learn_time_ms\": 21844.205}", "{\"n\": 1142, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2727.43, \"learn_time_ms\": 21833.353}", "{\"n\": 1143, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2734.65, \"learn_time_ms\": 21842.089}", "{\"n\": 1144, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2729.2, \"learn_time_ms\": 21846.817}", "{\"n\": 1145, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2738.57, \"learn_time_ms\": 21844.467}", "{\"n\": 1146, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2755.34, \"learn_time_ms\": 21862.75}", "{\"n\": 1147, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2748.19, \"learn_time_ms\": 21875.692}", "{\"n\": 1148, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2748.19, \"learn_time_ms\": 21874.496}", "{\"n\": 1149, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2752.85, \"learn_time_ms\": 21876.793}", "{\"n\": 1150, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.72, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2750.77, \"learn_time_ms\": 21877.625}", "{\"n\": 1151, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2756.57, \"learn_time_ms\": 21867.978}", "{\"n\": 1152, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2760.91, \"learn_time_ms\": 21869.998}", "{\"n\": 1153, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2762.24, \"learn_time_ms\": 21865.202}", "{\"n\": 1154, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2760.16, \"learn_time_ms\": 21855.036}", "{\"n\": 1155, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2764.0, \"learn_time_ms\": 21848.498}", "{\"n\": 1156, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2764.69, \"learn_time_ms\": 21834.892}", "{\"n\": 1157, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2768.59, \"learn_time_ms\": 21816.476}", "{\"n\": 1158, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2751.96, \"learn_time_ms\": 21817.744}", "{\"n\": 1159, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2755.19, \"learn_time_ms\": 21822.353}", "{\"n\": 1160, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2748.53, \"learn_time_ms\": 21825.246}", "{\"n\": 1161, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2746.78, \"learn_time_ms\": 21833.404}", "{\"n\": 1162, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2743.33, \"learn_time_ms\": 21837.813}", "{\"n\": 1163, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2750.34, \"learn_time_ms\": 21835.02}", "{\"n\": 1164, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2745.17, \"learn_time_ms\": 21843.19}", "{\"n\": 1165, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2754.45, \"learn_time_ms\": 21847.13}", "{\"n\": 1166, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2765.15, \"learn_time_ms\": 21844.214}", "{\"n\": 1167, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2758.19, \"learn_time_ms\": 21850.082}", "{\"n\": 1168, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.63, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2758.19, \"learn_time_ms\": 21848.093}", "{\"n\": 1169, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2767.92, \"learn_time_ms\": 21845.588}", "{\"n\": 1170, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2775.33, \"learn_time_ms\": 21837.754}", "{\"n\": 1171, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2777.9, \"learn_time_ms\": 21825.198}", "{\"n\": 1172, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2772.74, \"learn_time_ms\": 21810.423}", "{\"n\": 1173, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2775.67, \"learn_time_ms\": 21803.178}", "{\"n\": 1174, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2768.95, \"learn_time_ms\": 21792.967}", "{\"n\": 1175, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2775.83, \"learn_time_ms\": 21788.326}", "{\"n\": 1176, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2775.86, \"learn_time_ms\": 21788.07}", "{\"n\": 1177, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2781.16, \"learn_time_ms\": 21786.27}", "{\"n\": 1178, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2784.43, \"learn_time_ms\": 21784.813}", "{\"n\": 1179, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2788.82, \"learn_time_ms\": 21784.127}", "{\"n\": 1180, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2788.82, \"learn_time_ms\": 21783.72}", "{\"n\": 1181, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2788.82, \"learn_time_ms\": 21793.144}", "{\"n\": 1182, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2786.89, \"learn_time_ms\": 21809.277}", "{\"n\": 1183, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2787.37, \"learn_time_ms\": 21813.156}", "{\"n\": 1184, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2781.7, \"learn_time_ms\": 21820.333}", "{\"n\": 1185, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2780.23, \"learn_time_ms\": 21831.176}", "{\"n\": 1186, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2788.38, \"learn_time_ms\": 21820.978}", "{\"n\": 1187, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2785.08, \"learn_time_ms\": 21823.624}", "{\"n\": 1188, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2785.99, \"learn_time_ms\": 21813.934}", "{\"n\": 1189, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2794.13, \"learn_time_ms\": 21820.647}", "{\"n\": 1190, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2806.52, \"learn_time_ms\": 21827.236}", "{\"n\": 1191, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2806.52, \"learn_time_ms\": 21820.055}", "{\"n\": 1192, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2813.88, \"learn_time_ms\": 21816.063}", "{\"n\": 1193, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2813.88, \"learn_time_ms\": 21812.564}", "{\"n\": 1194, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2808.49, \"learn_time_ms\": 21810.395}", "{\"n\": 1195, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2812.02, \"learn_time_ms\": 21797.891}", "{\"n\": 1196, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2820.11, \"learn_time_ms\": 21816.432}", "{\"n\": 1197, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2821.73, \"learn_time_ms\": 21814.494}", "{\"n\": 1198, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2829.36, \"learn_time_ms\": 21828.109}", "{\"n\": 1199, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2833.43, \"learn_time_ms\": 21824.932}", "{\"n\": 1200, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2833.43, \"learn_time_ms\": 21826.376}", "{\"n\": 1201, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2843.38, \"learn_time_ms\": 21840.34}", "{\"n\": 1202, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2842.85, \"learn_time_ms\": 21832.486}", "{\"n\": 1203, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2829.9, \"learn_time_ms\": 21843.835}", "{\"n\": 1204, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2829.9, \"learn_time_ms\": 21844.248}", "{\"n\": 1205, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2822.36, \"learn_time_ms\": 21845.617}", "{\"n\": 1206, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2827.48, \"learn_time_ms\": 21841.185}", "{\"n\": 1207, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2840.01, \"learn_time_ms\": 21848.832}", "{\"n\": 1208, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2831.24, \"learn_time_ms\": 21836.389}", "{\"n\": 1209, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2831.24, \"learn_time_ms\": 21835.371}", "{\"n\": 1210, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2831.24, \"learn_time_ms\": 21833.021}", "{\"n\": 1211, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2841.08, \"learn_time_ms\": 21827.908}", "{\"n\": 1212, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2842.71, \"learn_time_ms\": 21831.499}", "{\"n\": 1213, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2840.48, \"learn_time_ms\": 21840.776}", "{\"n\": 1214, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2839.31, \"learn_time_ms\": 21843.577}", "{\"n\": 1215, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2842.19, \"learn_time_ms\": 21841.395}", "{\"n\": 1216, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2837.18, \"learn_time_ms\": 21839.686}", "{\"n\": 1217, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2840.9, \"learn_time_ms\": 21825.373}", "{\"n\": 1218, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2858.91, \"learn_time_ms\": 21830.608}", "{\"n\": 1219, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2854.42, \"learn_time_ms\": 21833.996}", "{\"n\": 1220, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2854.42, \"learn_time_ms\": 21842.664}", "{\"n\": 1221, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2851.22, \"learn_time_ms\": 21839.418}", "{\"n\": 1222, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2858.85, \"learn_time_ms\": 21832.205}", "{\"n\": 1223, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2868.64, \"learn_time_ms\": 21818.567}", "{\"n\": 1224, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2868.64, \"learn_time_ms\": 21799.524}", "{\"n\": 1225, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2865.25, \"learn_time_ms\": 21806.823}", "{\"n\": 1226, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2871.46, \"learn_time_ms\": 21798.481}", "{\"n\": 1227, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2870.68, \"learn_time_ms\": 21799.543}", "{\"n\": 1228, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2866.4, \"learn_time_ms\": 21804.655}", "{\"n\": 1229, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2865.66, \"learn_time_ms\": 21808.854}", "{\"n\": 1230, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2873.71, \"learn_time_ms\": 21795.445}", "{\"n\": 1231, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2862.91, \"learn_time_ms\": 21800.903}", "{\"n\": 1232, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2860.32, \"learn_time_ms\": 21809.722}", "{\"n\": 1233, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2864.22, \"learn_time_ms\": 21815.493}", "{\"n\": 1234, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2882.0, \"learn_time_ms\": 21838.659}", "{\"n\": 1235, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2883.81, \"learn_time_ms\": 21841.449}", "{\"n\": 1236, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2885.9, \"learn_time_ms\": 21853.753}", "{\"n\": 1237, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.4, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2884.58, \"learn_time_ms\": 21867.624}", "{\"n\": 1238, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2900.11, \"learn_time_ms\": 21865.868}", "{\"n\": 1239, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2900.11, \"learn_time_ms\": 21856.571}", "{\"n\": 1240, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2896.36, \"learn_time_ms\": 21861.33}", "{\"n\": 1241, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2893.43, \"learn_time_ms\": 21857.771}", "{\"n\": 1242, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2895.36, \"learn_time_ms\": 21856.504}", "{\"n\": 1243, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2901.88, \"learn_time_ms\": 21849.562}", "{\"n\": 1244, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2914.47, \"learn_time_ms\": 21842.9}", "{\"n\": 1245, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2914.97, \"learn_time_ms\": 21834.144}", "{\"n\": 1246, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2916.88, \"learn_time_ms\": 21824.244}", "{\"n\": 1247, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2905.35, \"learn_time_ms\": 21824.164}", "{\"n\": 1248, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2908.12, \"learn_time_ms\": 21821.704}", "{\"n\": 1249, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2908.67, \"learn_time_ms\": 21822.784}", "{\"n\": 1250, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2894.32, \"learn_time_ms\": 21805.758}", "{\"n\": 1251, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2898.03, \"learn_time_ms\": 21797.38}", "{\"n\": 1252, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2900.37, \"learn_time_ms\": 21808.457}", "{\"n\": 1253, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2908.45, \"learn_time_ms\": 21813.249}", "{\"n\": 1254, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2931.23, \"learn_time_ms\": 21816.97}", "{\"n\": 1255, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2923.62, \"learn_time_ms\": 21820.512}", "{\"n\": 1256, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2923.62, \"learn_time_ms\": 21829.069}", "{\"n\": 1257, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2920.42, \"learn_time_ms\": 21824.368}", "{\"n\": 1258, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2918.82, \"learn_time_ms\": 21826.04}", "{\"n\": 1259, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2912.88, \"learn_time_ms\": 21820.694}", "{\"n\": 1260, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2906.66, \"learn_time_ms\": 21835.788}", "{\"n\": 1261, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2899.58, \"learn_time_ms\": 21843.2}", "{\"n\": 1262, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2894.31, \"learn_time_ms\": 21831.949}", "{\"n\": 1263, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2896.21, \"learn_time_ms\": 21823.815}", "{\"n\": 1264, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2901.51, \"learn_time_ms\": 21816.843}", "{\"n\": 1265, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2912.67, \"learn_time_ms\": 21802.607}", "{\"n\": 1266, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2902.4, \"learn_time_ms\": 21790.429}", "{\"n\": 1267, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2890.58, \"learn_time_ms\": 21786.897}", "{\"n\": 1268, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2889.48, \"learn_time_ms\": 21784.032}", "{\"n\": 1269, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2899.59, \"learn_time_ms\": 21790.213}", "{\"n\": 1270, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2907.77, \"learn_time_ms\": 21796.283}", "{\"n\": 1271, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2915.15, \"learn_time_ms\": 21813.022}", "{\"n\": 1272, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2915.15, \"learn_time_ms\": 21811.093}", "{\"n\": 1273, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2909.91, \"learn_time_ms\": 21813.875}", "{\"n\": 1274, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2911.55, \"learn_time_ms\": 21829.592}", "{\"n\": 1275, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2899.2, \"learn_time_ms\": 21850.765}", "{\"n\": 1276, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2898.87, \"learn_time_ms\": 21860.319}", "{\"n\": 1277, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2898.87, \"learn_time_ms\": 21861.053}", "{\"n\": 1278, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2904.56, \"learn_time_ms\": 21860.64}", "{\"n\": 1279, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2896.89, \"learn_time_ms\": 21868.623}", "{\"n\": 1280, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2901.21, \"learn_time_ms\": 21856.877}", "{\"n\": 1281, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2901.21, \"learn_time_ms\": 21842.796}", "{\"n\": 1282, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2901.21, \"learn_time_ms\": 21839.178}", "{\"n\": 1283, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2908.18, \"learn_time_ms\": 21842.04}", "{\"n\": 1284, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2906.05, \"learn_time_ms\": 21834.214}", "{\"n\": 1285, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2895.57, \"learn_time_ms\": 21815.429}", "{\"n\": 1286, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2895.57, \"learn_time_ms\": 21826.375}", "{\"n\": 1287, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2903.21, \"learn_time_ms\": 21832.329}", "{\"n\": 1288, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2894.38, \"learn_time_ms\": 21840.661}", "{\"n\": 1289, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2881.51, \"learn_time_ms\": 21832.693}", "{\"n\": 1290, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2893.46, \"learn_time_ms\": 21830.495}", "{\"n\": 1291, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2893.46, \"learn_time_ms\": 21823.833}", "{\"n\": 1292, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2893.46, \"learn_time_ms\": 21831.541}", "{\"n\": 1293, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2887.92, \"learn_time_ms\": 21830.155}", "{\"n\": 1294, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2885.79, \"learn_time_ms\": 21824.015}", "{\"n\": 1295, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2889.31, \"learn_time_ms\": 21838.763}", "{\"n\": 1296, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2894.86, \"learn_time_ms\": 21829.082}", "{\"n\": 1297, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2894.86, \"learn_time_ms\": 21825.12}", "{\"n\": 1298, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2892.9, \"learn_time_ms\": 21824.716}", "{\"n\": 1299, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2892.9, \"learn_time_ms\": 21825.972}", "{\"n\": 1300, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.46, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2889.93, \"learn_time_ms\": 21822.608}", "{\"n\": 1301, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2910.37, \"learn_time_ms\": 21832.829}", "{\"n\": 1302, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2907.96, \"learn_time_ms\": 21825.859}", "{\"n\": 1303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2916.38, \"learn_time_ms\": 21833.288}", "{\"n\": 1304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2905.13, \"learn_time_ms\": 21834.883}", "{\"n\": 1305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2905.13, \"learn_time_ms\": 21830.363}", "{\"n\": 1306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2910.14, \"learn_time_ms\": 21841.199}", "{\"n\": 1307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2920.74, \"learn_time_ms\": 21837.169}", "{\"n\": 1308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2925.2, \"learn_time_ms\": 21830.606}", "{\"n\": 1309, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2931.8, \"learn_time_ms\": 21834.927}", "{\"n\": 1310, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2940.06, \"learn_time_ms\": 21839.901}", "{\"n\": 1311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2951.81, \"learn_time_ms\": 21849.245}", "{\"n\": 1312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2967.64, \"learn_time_ms\": 21859.397}", "{\"n\": 1313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2958.72, \"learn_time_ms\": 21845.251}", "{\"n\": 1314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2957.53, \"learn_time_ms\": 21847.783}", "{\"n\": 1315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2947.06, \"learn_time_ms\": 21856.135}", "{\"n\": 1316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2955.5, \"learn_time_ms\": 21831.006}", "{\"n\": 1317, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2955.13, \"learn_time_ms\": 21833.252}", "{\"n\": 1318, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2954.41, \"learn_time_ms\": 21813.34}", "{\"n\": 1319, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2948.17, \"learn_time_ms\": 21803.098}", "{\"n\": 1320, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2948.17, \"learn_time_ms\": 21808.302}", "{\"n\": 1321, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2945.95, \"learn_time_ms\": 21786.02}", "{\"n\": 1322, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.37, \"learn_time_ms\": 21776.902}", "{\"n\": 1323, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2943.4, \"learn_time_ms\": 21782.691}", "{\"n\": 1324, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2954.35, \"learn_time_ms\": 21770.659}", "{\"n\": 1325, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2952.33, \"learn_time_ms\": 21758.995}", "{\"n\": 1326, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2957.55, \"learn_time_ms\": 21773.715}", "{\"n\": 1327, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.84, \"learn_time_ms\": 21779.696}", "{\"n\": 1328, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2949.84, \"learn_time_ms\": 21792.76}", "{\"n\": 1329, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2976.21, \"learn_time_ms\": 21807.049}", "{\"n\": 1330, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2988.98, \"learn_time_ms\": 21808.609}", "{\"n\": 1331, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2985.4, \"learn_time_ms\": 21809.142}", "{\"n\": 1332, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2984.26, \"learn_time_ms\": 21805.013}", "{\"n\": 1333, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2984.41, \"learn_time_ms\": 21810.253}", "{\"n\": 1334, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2990.16, \"learn_time_ms\": 21821.949}", "{\"n\": 1335, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2991.01, \"learn_time_ms\": 21827.749}", "{\"n\": 1336, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2986.18, \"learn_time_ms\": 21830.252}", "{\"n\": 1337, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2998.63, \"learn_time_ms\": 21825.202}", "{\"n\": 1338, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3011.96, \"learn_time_ms\": 21834.393}", "{\"n\": 1339, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3011.96, \"learn_time_ms\": 21829.73}", "{\"n\": 1340, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3001.79, \"learn_time_ms\": 21830.485}", "{\"n\": 1341, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3013.98, \"learn_time_ms\": 21843.002}", "{\"n\": 1342, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3020.03, \"learn_time_ms\": 21867.625}", "{\"n\": 1343, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3023.25, \"learn_time_ms\": 21865.717}", "{\"n\": 1344, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3034.03, \"learn_time_ms\": 21868.08}", "{\"n\": 1345, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3023.28, \"learn_time_ms\": 21861.822}", "{\"n\": 1346, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3023.28, \"learn_time_ms\": 21854.922}", "{\"n\": 1347, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3037.14, \"learn_time_ms\": 21846.379}", "{\"n\": 1348, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3037.14, \"learn_time_ms\": 21848.24}", "{\"n\": 1349, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3046.4, \"learn_time_ms\": 21850.921}", "{\"n\": 1350, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3046.4, \"learn_time_ms\": 21852.535}", "{\"n\": 1351, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3049.44, \"learn_time_ms\": 21849.788}", "{\"n\": 1352, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3074.33, \"learn_time_ms\": 21832.759}", "{\"n\": 1353, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3075.62, \"learn_time_ms\": 21839.225}", "{\"n\": 1354, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3067.98, \"learn_time_ms\": 21839.306}", "{\"n\": 1355, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3074.34, \"learn_time_ms\": 21852.608}", "{\"n\": 1356, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3073.92, \"learn_time_ms\": 21856.811}", "{\"n\": 1357, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3075.64, \"learn_time_ms\": 21877.033}", "{\"n\": 1358, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3063.92, \"learn_time_ms\": 21885.21}", "{\"n\": 1359, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3063.92, \"learn_time_ms\": 21870.245}", "{\"n\": 1360, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3063.34, \"learn_time_ms\": 21860.333}", "{\"n\": 1361, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3062.29, \"learn_time_ms\": 21855.334}", "{\"n\": 1362, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3061.31, \"learn_time_ms\": 21856.911}", "{\"n\": 1363, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3068.41, \"learn_time_ms\": 21858.73}", "{\"n\": 1364, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3069.66, \"learn_time_ms\": 21847.89}", "{\"n\": 1365, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3072.6, \"learn_time_ms\": 21831.196}", "{\"n\": 1366, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3061.38, \"learn_time_ms\": 21837.852}", "{\"n\": 1367, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3070.71, \"learn_time_ms\": 21826.201}", "{\"n\": 1368, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3074.25, \"learn_time_ms\": 21828.76}", "{\"n\": 1369, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3078.91, \"learn_time_ms\": 21841.018}", "{\"n\": 1370, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3076.61, \"learn_time_ms\": 21850.315}", "{\"n\": 1371, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3076.05, \"learn_time_ms\": 21851.046}", "{\"n\": 1372, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3089.16, \"learn_time_ms\": 21843.717}", "{\"n\": 1373, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3095.63, \"learn_time_ms\": 21824.635}", "{\"n\": 1374, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3087.78, \"learn_time_ms\": 21832.823}", "{\"n\": 1375, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3061.76, \"learn_time_ms\": 21841.757}", "{\"n\": 1376, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3055.67, \"learn_time_ms\": 21840.58}", "{\"n\": 1377, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3059.23, \"learn_time_ms\": 21836.173}", "{\"n\": 1378, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3061.24, \"learn_time_ms\": 21813.938}", "{\"n\": 1379, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3078.48, \"learn_time_ms\": 21813.671}", "{\"n\": 1380, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3090.12, \"learn_time_ms\": 21817.607}", "{\"n\": 1381, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3083.58, \"learn_time_ms\": 21817.166}", "{\"n\": 1382, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3089.38, \"learn_time_ms\": 21823.488}", "{\"n\": 1383, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3092.48, \"learn_time_ms\": 21834.901}", "{\"n\": 1384, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3096.81, \"learn_time_ms\": 21826.957}", "{\"n\": 1385, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3102.08, \"learn_time_ms\": 21826.079}", "{\"n\": 1386, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3102.08, \"learn_time_ms\": 21831.884}", "{\"n\": 1387, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3117.28, \"learn_time_ms\": 21836.616}", "{\"n\": 1388, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3117.28, \"learn_time_ms\": 21830.086}", "{\"n\": 1389, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3132.45, \"learn_time_ms\": 21821.566}", "{\"n\": 1390, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3132.45, \"learn_time_ms\": 21815.19}", "{\"n\": 1391, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3139.94, \"learn_time_ms\": 21814.714}", "{\"n\": 1392, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.47, \"learn_time_ms\": 21799.444}", "{\"n\": 1393, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.47, \"learn_time_ms\": 21796.924}", "{\"n\": 1394, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.23, \"learn_time_ms\": 21808.778}", "{\"n\": 1395, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3129.28, \"learn_time_ms\": 21804.897}", "{\"n\": 1396, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3137.95, \"learn_time_ms\": 21773.255}", "{\"n\": 1397, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3131.62, \"learn_time_ms\": 21770.994}", "{\"n\": 1398, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3129.87, \"learn_time_ms\": 21787.931}", "{\"n\": 1399, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3124.67, \"learn_time_ms\": 21793.539}", "{\"n\": 1400, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3132.92, \"learn_time_ms\": 21784.609}", "{\"n\": 1401, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3132.92, \"learn_time_ms\": 21789.127}", "{\"n\": 1402, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3134.51, \"learn_time_ms\": 21806.589}", "{\"n\": 1403, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.5, \"learn_time_ms\": 21813.745}", "{\"n\": 1404, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3160.54, \"learn_time_ms\": 21810.524}", "{\"n\": 1405, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.53, \"learn_time_ms\": 21795.589}", "{\"n\": 1406, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.59, \"learn_time_ms\": 21817.313}", "{\"n\": 1407, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.1, \"learn_time_ms\": 21801.619}", "{\"n\": 1408, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.78, \"learn_time_ms\": 21796.31}", "{\"n\": 1409, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3157.39, \"learn_time_ms\": 21788.2}", "{\"n\": 1410, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3157.39, \"learn_time_ms\": 21802.877}", "{\"n\": 1411, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.08, \"learn_time_ms\": 21809.421}", "{\"n\": 1412, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3149.73, \"learn_time_ms\": 21802.548}", "{\"n\": 1413, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3138.71, \"learn_time_ms\": 21799.736}", "{\"n\": 1414, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3139.43, \"learn_time_ms\": 21804.73}", "{\"n\": 1415, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3155.65, \"learn_time_ms\": 21837.105}", "{\"n\": 1416, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3155.65, \"learn_time_ms\": 21835.101}", "{\"n\": 1417, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3151.17, \"learn_time_ms\": 21853.473}", "{\"n\": 1418, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3137.86, \"learn_time_ms\": 21856.432}", "{\"n\": 1419, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3150.87, \"learn_time_ms\": 21870.833}", "{\"n\": 1420, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3135.77, \"learn_time_ms\": 21860.37}", "{\"n\": 1421, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3136.1, \"learn_time_ms\": 21850.929}", "{\"n\": 1422, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3136.1, \"learn_time_ms\": 21852.652}", "{\"n\": 1423, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3141.89, \"learn_time_ms\": 21849.397}", "{\"n\": 1424, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3145.32, \"learn_time_ms\": 21838.358}", "{\"n\": 1425, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3149.29, \"learn_time_ms\": 21826.233}", "{\"n\": 1426, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.46, \"learn_time_ms\": 21826.36}", "{\"n\": 1427, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.84, \"learn_time_ms\": 21828.186}", "{\"n\": 1428, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.13, \"learn_time_ms\": 21834.021}", "{\"n\": 1429, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3155.36, \"learn_time_ms\": 21838.507}", "{\"n\": 1430, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3155.36, \"learn_time_ms\": 21846.447}", "{\"n\": 1431, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.34, \"learn_time_ms\": 21847.309}", "{\"n\": 1432, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.84, \"learn_time_ms\": 21852.019}", "{\"n\": 1433, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3158.72, \"learn_time_ms\": 21860.839}", "{\"n\": 1434, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.22, \"learn_time_ms\": 21862.458}", "{\"n\": 1435, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.22, \"learn_time_ms\": 21850.49}", "{\"n\": 1436, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.27, \"learn_time_ms\": 21849.625}", "{\"n\": 1437, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3135.37, \"learn_time_ms\": 21858.352}", "{\"n\": 1438, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.17, \"learn_time_ms\": 21850.224}", "{\"n\": 1439, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.17, \"learn_time_ms\": 21840.571}", "{\"n\": 1440, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3142.66, \"learn_time_ms\": 21845.609}", "{\"n\": 1441, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.65, \"learn_time_ms\": 21855.289}", "{\"n\": 1442, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.65, \"learn_time_ms\": 21848.952}", "{\"n\": 1443, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.65, \"learn_time_ms\": 21832.468}", "{\"n\": 1444, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3136.1, \"learn_time_ms\": 21835.656}", "{\"n\": 1445, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3133.04, \"learn_time_ms\": 21846.234}", "{\"n\": 1446, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3128.2, \"learn_time_ms\": 21846.307}", "{\"n\": 1447, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3127.41, \"learn_time_ms\": 21836.876}", "{\"n\": 1448, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3127.41, \"learn_time_ms\": 21826.865}", "{\"n\": 1449, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3122.03, \"learn_time_ms\": 21821.6}", "{\"n\": 1450, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3131.01, \"learn_time_ms\": 21811.504}", "{\"n\": 1451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3131.45, \"learn_time_ms\": 21803.006}", "{\"n\": 1452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3132.17, \"learn_time_ms\": 21807.047}", "{\"n\": 1453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.65, \"learn_time_ms\": 21807.733}", "{\"n\": 1454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3139.44, \"learn_time_ms\": 21794.129}", "{\"n\": 1455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3133.85, \"learn_time_ms\": 21798.362}", "{\"n\": 1456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3136.15, \"learn_time_ms\": 21797.37}", "{\"n\": 1457, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3143.46, \"learn_time_ms\": 21794.373}", "{\"n\": 1458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3145.47, \"learn_time_ms\": 21810.455}", "{\"n\": 1459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3150.41, \"learn_time_ms\": 21808.424}", "{\"n\": 1460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3150.41, \"learn_time_ms\": 21818.326}", "{\"n\": 1461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3143.01, \"learn_time_ms\": 21811.66}", "{\"n\": 1462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3146.71, \"learn_time_ms\": 21818.686}", "{\"n\": 1463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.72, \"learn_time_ms\": 21818.542}", "{\"n\": 1464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.72, \"learn_time_ms\": 21831.471}", "{\"n\": 1465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3134.19, \"learn_time_ms\": 21830.479}", "{\"n\": 1466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3131.59, \"learn_time_ms\": 21834.213}", "{\"n\": 1467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.86, \"learn_time_ms\": 21834.034}", "{\"n\": 1468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.86, \"learn_time_ms\": 21823.959}", "{\"n\": 1469, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3133.96, \"learn_time_ms\": 21827.537}", "{\"n\": 1470, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3128.92, \"learn_time_ms\": 21822.058}", "{\"n\": 1471, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3116.1, \"learn_time_ms\": 21819.151}", "{\"n\": 1472, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3116.1, \"learn_time_ms\": 21808.801}", "{\"n\": 1473, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3118.93, \"learn_time_ms\": 21812.493}", "{\"n\": 1474, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3114.91, \"learn_time_ms\": 21817.136}", "{\"n\": 1475, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3121.04, \"learn_time_ms\": 21814.683}", "{\"n\": 1476, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3124.12, \"learn_time_ms\": 21817.732}", "{\"n\": 1477, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3131.87, \"learn_time_ms\": 21820.745}", "{\"n\": 1478, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3131.4, \"learn_time_ms\": 21826.132}", "{\"n\": 1479, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3129.93, \"learn_time_ms\": 21821.933}", "{\"n\": 1480, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3142.7, \"learn_time_ms\": 21813.253}", "{\"n\": 1481, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3160.23, \"learn_time_ms\": 21827.447}", "{\"n\": 1482, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3161.25, \"learn_time_ms\": 21827.025}", "{\"n\": 1483, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.26, \"learn_time_ms\": 21844.655}", "{\"n\": 1484, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.26, \"learn_time_ms\": 21837.851}", "{\"n\": 1485, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.52, \"learn_time_ms\": 21845.096}", "{\"n\": 1486, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3151.65, \"learn_time_ms\": 21842.511}", "{\"n\": 1487, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3151.65, \"learn_time_ms\": 21850.861}", "{\"n\": 1488, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3151.65, \"learn_time_ms\": 21856.788}", "{\"n\": 1489, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3142.48, \"learn_time_ms\": 21852.49}", "{\"n\": 1490, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3153.13, \"learn_time_ms\": 21861.298}", "{\"n\": 1491, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3144.63, \"learn_time_ms\": 21868.437}", "{\"n\": 1492, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3139.37, \"learn_time_ms\": 21873.512}", "{\"n\": 1493, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3139.37, \"learn_time_ms\": 21862.493}", "{\"n\": 1494, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3133.2, \"learn_time_ms\": 21870.776}", "{\"n\": 1495, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3118.39, \"learn_time_ms\": 21867.769}", "{\"n\": 1496, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3117.61, \"learn_time_ms\": 21862.241}", "{\"n\": 1497, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3122.57, \"learn_time_ms\": 21855.151}", "{\"n\": 1498, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.2, \"learn_time_ms\": 21846.462}", "{\"n\": 1499, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3119.01, \"learn_time_ms\": 21859.413}", "{\"n\": 1500, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3114.25, \"learn_time_ms\": 21857.139}", "{\"n\": 1501, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3118.78, \"learn_time_ms\": 21845.879}", "{\"n\": 1502, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3127.71, \"learn_time_ms\": 21847.239}", "{\"n\": 1503, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3120.92, \"learn_time_ms\": 21832.155}", "{\"n\": 1504, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3123.61, \"learn_time_ms\": 21832.354}", "{\"n\": 1505, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3112.11, \"learn_time_ms\": 21822.924}", "{\"n\": 1506, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3121.08, \"learn_time_ms\": 21826.594}", "{\"n\": 1507, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.69, \"learn_time_ms\": 21820.758}", "{\"n\": 1508, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.69, \"learn_time_ms\": 21826.398}", "{\"n\": 1509, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3127.81, \"learn_time_ms\": 21836.025}", "{\"n\": 1510, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3113.49, \"learn_time_ms\": 21826.187}", "{\"n\": 1511, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3118.09, \"learn_time_ms\": 21828.42}", "{\"n\": 1512, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3124.88, \"learn_time_ms\": 21835.83}", "{\"n\": 1513, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3160.13, \"learn_time_ms\": 21847.139}", "{\"n\": 1514, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3145.44, \"learn_time_ms\": 21843.746}", "{\"n\": 1515, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.68, \"learn_time_ms\": 21847.544}", "{\"n\": 1516, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3139.83, \"learn_time_ms\": 21843.787}", "{\"n\": 1517, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3141.76, \"learn_time_ms\": 21840.384}", "{\"n\": 1518, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3128.81, \"learn_time_ms\": 21838.524}", "{\"n\": 1519, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3134.98, \"learn_time_ms\": 21832.707}", "{\"n\": 1520, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3127.71, \"learn_time_ms\": 21846.532}", "{\"n\": 1521, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3118.24, \"learn_time_ms\": 21832.289}", "{\"n\": 1522, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3109.5, \"learn_time_ms\": 21828.282}", "{\"n\": 1523, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3090.99, \"learn_time_ms\": 21820.434}", "{\"n\": 1524, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3086.1, \"learn_time_ms\": 21815.614}", "{\"n\": 1525, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3079.98, \"learn_time_ms\": 21816.94}", "{\"n\": 1526, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3071.2, \"learn_time_ms\": 21820.014}", "{\"n\": 1527, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3075.09, \"learn_time_ms\": 21814.064}", "{\"n\": 1528, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3078.97, \"learn_time_ms\": 21819.277}", "{\"n\": 1529, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3074.28, \"learn_time_ms\": 21821.005}", "{\"n\": 1530, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3081.17, \"learn_time_ms\": 21814.899}", "{\"n\": 1531, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3074.28, \"learn_time_ms\": 21828.939}", "{\"n\": 1532, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3068.9, \"learn_time_ms\": 21812.41}", "{\"n\": 1533, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3066.05, \"learn_time_ms\": 21821.393}", "{\"n\": 1534, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3066.05, \"learn_time_ms\": 21822.114}", "{\"n\": 1535, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3076.83, \"learn_time_ms\": 21830.096}", "{\"n\": 1536, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3078.53, \"learn_time_ms\": 21825.714}", "{\"n\": 1537, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3081.11, \"learn_time_ms\": 21840.244}", "{\"n\": 1538, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3076.45, \"learn_time_ms\": 21844.399}", "{\"n\": 1539, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3076.45, \"learn_time_ms\": 21840.616}", "{\"n\": 1540, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3078.11, \"learn_time_ms\": 21846.364}", "{\"n\": 1541, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3078.11, \"learn_time_ms\": 21842.41}", "{\"n\": 1542, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3081.95, \"learn_time_ms\": 21859.799}", "{\"n\": 1543, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3069.71, \"learn_time_ms\": 21851.511}", "{\"n\": 1544, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3069.71, \"learn_time_ms\": 21844.832}", "{\"n\": 1545, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3062.09, \"learn_time_ms\": 21842.423}", "{\"n\": 1546, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3062.09, \"learn_time_ms\": 21858.317}", "{\"n\": 1547, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3059.64, \"learn_time_ms\": 21859.805}", "{\"n\": 1548, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3065.87, \"learn_time_ms\": 21858.373}", "{\"n\": 1549, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3069.14, \"learn_time_ms\": 21858.916}", "{\"n\": 1550, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3071.07, \"learn_time_ms\": 21856.394}", "{\"n\": 1551, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3065.4, \"learn_time_ms\": 21863.701}", "{\"n\": 1552, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3073.36, \"learn_time_ms\": 21866.59}", "{\"n\": 1553, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3065.53, \"learn_time_ms\": 21872.128}", "{\"n\": 1554, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3062.83, \"learn_time_ms\": 21882.484}", "{\"n\": 1555, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3064.81, \"learn_time_ms\": 21861.932}", "{\"n\": 1556, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3059.64, \"learn_time_ms\": 21861.152}", "{\"n\": 1557, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3066.29, \"learn_time_ms\": 21870.654}", "{\"n\": 1558, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3079.75, \"learn_time_ms\": 21862.371}", "{\"n\": 1559, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3082.65, \"learn_time_ms\": 21865.769}", "{\"n\": 1560, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3083.55, \"learn_time_ms\": 21867.885}", "{\"n\": 1561, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3083.55, \"learn_time_ms\": 21867.061}", "{\"n\": 1562, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3069.02, \"learn_time_ms\": 21872.083}", "{\"n\": 1563, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3088.22, \"learn_time_ms\": 21866.197}", "{\"n\": 1564, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3094.2, \"learn_time_ms\": 21862.212}", "{\"n\": 1565, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3086.29, \"learn_time_ms\": 21886.011}", "{\"n\": 1566, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3086.29, \"learn_time_ms\": 21871.922}", "{\"n\": 1567, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3078.63, \"learn_time_ms\": 21854.02}", "{\"n\": 1568, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3100.86, \"learn_time_ms\": 21848.224}", "{\"n\": 1569, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3086.9, \"learn_time_ms\": 21841.769}", "{\"n\": 1570, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3089.05, \"learn_time_ms\": 21836.6}", "{\"n\": 1571, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3089.05, \"learn_time_ms\": 21811.614}", "{\"n\": 1572, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3082.95, \"learn_time_ms\": 21791.639}", "{\"n\": 1573, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3089.38, \"learn_time_ms\": 21798.699}", "{\"n\": 1574, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3085.16, \"learn_time_ms\": 21810.018}", "{\"n\": 1575, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3080.22, \"learn_time_ms\": 21792.943}", "{\"n\": 1576, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3068.46, \"learn_time_ms\": 21795.944}", "{\"n\": 1577, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3054.88, \"learn_time_ms\": 21803.134}", "{\"n\": 1578, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3049.93, \"learn_time_ms\": 21809.518}", "{\"n\": 1579, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3060.19, \"learn_time_ms\": 21790.003}", "{\"n\": 1580, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3049.71, \"learn_time_ms\": 21789.854}", "{\"n\": 1581, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3049.71, \"learn_time_ms\": 21819.159}", "{\"n\": 1582, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3045.58, \"learn_time_ms\": 21829.482}", "{\"n\": 1583, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3041.1, \"learn_time_ms\": 21831.346}", "{\"n\": 1584, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3040.41, \"learn_time_ms\": 21821.857}", "{\"n\": 1585, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3040.41, \"learn_time_ms\": 21832.925}", "{\"n\": 1586, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3042.68, \"learn_time_ms\": 21844.545}", "{\"n\": 1587, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3064.95, \"learn_time_ms\": 21840.586}", "{\"n\": 1588, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3073.93, \"learn_time_ms\": 21844.561}", "{\"n\": 1589, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3073.93, \"learn_time_ms\": 21865.1}", "{\"n\": 1590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3071.61, \"learn_time_ms\": 21871.487}", "{\"n\": 1591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3070.61, \"learn_time_ms\": 21861.869}", "{\"n\": 1592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3070.46, \"learn_time_ms\": 21865.298}", "{\"n\": 1593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3073.53, \"learn_time_ms\": 21866.457}", "{\"n\": 1594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3082.84, \"learn_time_ms\": 21874.381}", "{\"n\": 1595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3080.38, \"learn_time_ms\": 21871.59}", "{\"n\": 1596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3076.63, \"learn_time_ms\": 21868.203}", "{\"n\": 1597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3068.49, \"learn_time_ms\": 21874.64}", "{\"n\": 1598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3082.34, \"learn_time_ms\": 21859.468}", "{\"n\": 1599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3080.26, \"learn_time_ms\": 21850.505}", "{\"n\": 1600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3079.59, \"learn_time_ms\": 21844.497}", "{\"n\": 1601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3077.75, \"learn_time_ms\": 21854.982}", "{\"n\": 1602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3072.0, \"learn_time_ms\": 21833.762}", "{\"n\": 1603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3075.29, \"learn_time_ms\": 21832.408}", "{\"n\": 1604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3075.29, \"learn_time_ms\": 21825.877}", "{\"n\": 1605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3080.48, \"learn_time_ms\": 21832.64}", "{\"n\": 1606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3072.31, \"learn_time_ms\": 21821.619}", "{\"n\": 1607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3072.31, \"learn_time_ms\": 21804.048}", "{\"n\": 1608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3073.88, \"learn_time_ms\": 21813.372}", "{\"n\": 1609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3072.84, \"learn_time_ms\": 21817.275}", "{\"n\": 1610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3080.69, \"learn_time_ms\": 21799.312}", "{\"n\": 1611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3077.59, \"learn_time_ms\": 21788.528}", "{\"n\": 1612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3074.89, \"learn_time_ms\": 21807.629}", "{\"n\": 1613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3071.11, \"learn_time_ms\": 21808.672}", "{\"n\": 1614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3072.27, \"learn_time_ms\": 21817.076}", "{\"n\": 1615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3088.84, \"learn_time_ms\": 21813.004}", "{\"n\": 1616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3088.01, \"learn_time_ms\": 21814.018}", "{\"n\": 1617, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3098.3, \"learn_time_ms\": 21824.209}", "{\"n\": 1618, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3098.3, \"learn_time_ms\": 21826.776}", "{\"n\": 1619, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3102.28, \"learn_time_ms\": 21834.142}", "{\"n\": 1620, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3113.14, \"learn_time_ms\": 21847.225}", "{\"n\": 1621, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3121.34, \"learn_time_ms\": 21847.427}", "{\"n\": 1622, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3108.39, \"learn_time_ms\": 21845.144}", "{\"n\": 1623, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3101.13, \"learn_time_ms\": 21821.437}", "{\"n\": 1624, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3108.1, \"learn_time_ms\": 21815.54}", "{\"n\": 1625, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3100.71, \"learn_time_ms\": 21821.166}", "{\"n\": 1626, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3091.49, \"learn_time_ms\": 21825.675}", "{\"n\": 1627, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3087.98, \"learn_time_ms\": 21831.713}", "{\"n\": 1628, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3087.98, \"learn_time_ms\": 21822.985}", "{\"n\": 1629, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3086.27, \"learn_time_ms\": 21821.797}", "{\"n\": 1630, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3086.27, \"learn_time_ms\": 21824.802}", "{\"n\": 1631, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3111.86, \"learn_time_ms\": 21830.144}", "{\"n\": 1632, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3106.36, \"learn_time_ms\": 21825.8}", "{\"n\": 1633, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3106.36, \"learn_time_ms\": 21846.625}", "{\"n\": 1634, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3095.51, \"learn_time_ms\": 21843.809}", "{\"n\": 1635, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3096.52, \"learn_time_ms\": 21821.076}", "{\"n\": 1636, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3107.92, \"learn_time_ms\": 21807.355}", "{\"n\": 1637, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3109.15, \"learn_time_ms\": 21806.083}", "{\"n\": 1638, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3109.15, \"learn_time_ms\": 21818.248}", "{\"n\": 1639, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3115.79, \"learn_time_ms\": 21810.862}", "{\"n\": 1640, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3114.37, \"learn_time_ms\": 21817.222}", "{\"n\": 1641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3106.46, \"learn_time_ms\": 21807.686}", "{\"n\": 1642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.58, \"learn_time_ms\": 21805.763}", "{\"n\": 1643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3110.93, \"learn_time_ms\": 21807.605}", "{\"n\": 1644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3100.43, \"learn_time_ms\": 21802.552}", "{\"n\": 1645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3108.87, \"learn_time_ms\": 21813.197}", "{\"n\": 1646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3111.31, \"learn_time_ms\": 21824.244}", "{\"n\": 1647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3111.31, \"learn_time_ms\": 21821.086}", "{\"n\": 1648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3111.31, \"learn_time_ms\": 21812.994}", "{\"n\": 1649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3116.41, \"learn_time_ms\": 21816.814}", "{\"n\": 1650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3145.41, \"learn_time_ms\": 21806.198}", "{\"n\": 1651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3157.62, \"learn_time_ms\": 21795.638}", "{\"n\": 1652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.59, \"learn_time_ms\": 21791.026}", "{\"n\": 1653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.59, \"learn_time_ms\": 21790.908}", "{\"n\": 1654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3168.12, \"learn_time_ms\": 21793.186}", "{\"n\": 1655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.22, \"learn_time_ms\": 21776.307}", "{\"n\": 1656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.17, \"learn_time_ms\": 21769.106}", "{\"n\": 1657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.1, \"learn_time_ms\": 21766.167}", "{\"n\": 1658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.01, \"learn_time_ms\": 21779.52}", "{\"n\": 1659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3191.84, \"learn_time_ms\": 21783.63}", "{\"n\": 1660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.0, \"learn_time_ms\": 21791.793}", "{\"n\": 1661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.1, \"learn_time_ms\": 21810.095}", "{\"n\": 1662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.1, \"learn_time_ms\": 21814.906}", "{\"n\": 1663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.04, \"learn_time_ms\": 21804.806}", "{\"n\": 1664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.28, \"learn_time_ms\": 21804.904}", "{\"n\": 1665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3214.55, \"learn_time_ms\": 21825.087}", "{\"n\": 1666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.83, \"learn_time_ms\": 21845.585}", "{\"n\": 1667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.57, \"learn_time_ms\": 21854.359}", "{\"n\": 1668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.57, \"learn_time_ms\": 21842.699}", "{\"n\": 1669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.71, \"learn_time_ms\": 21848.085}", "{\"n\": 1670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3229.12, \"learn_time_ms\": 21841.701}", "{\"n\": 1671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.88, \"learn_time_ms\": 21839.951}", "{\"n\": 1672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.98, \"learn_time_ms\": 21846.119}", "{\"n\": 1673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.23, \"learn_time_ms\": 21859.257}", "{\"n\": 1674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.64, \"learn_time_ms\": 21866.108}", "{\"n\": 1675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.64, \"learn_time_ms\": 21868.34}", "{\"n\": 1676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.45, \"learn_time_ms\": 21866.178}", "{\"n\": 1677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.45, \"learn_time_ms\": 21866.733}", "{\"n\": 1678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3255.94, \"learn_time_ms\": 21881.542}", "{\"n\": 1679, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3265.2, \"learn_time_ms\": 21869.333}", "{\"n\": 1680, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.46, \"learn_time_ms\": 21874.567}", "{\"n\": 1681, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.97, \"learn_time_ms\": 21877.066}", "{\"n\": 1682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.97, \"learn_time_ms\": 21869.029}", "{\"n\": 1683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.15, \"learn_time_ms\": 21865.554}", "{\"n\": 1684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.39, \"learn_time_ms\": 21862.204}", "{\"n\": 1685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.25, \"learn_time_ms\": 21857.232}", "{\"n\": 1686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.91, \"learn_time_ms\": 21850.422}", "{\"n\": 1687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.27, \"learn_time_ms\": 21860.216}", "{\"n\": 1688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.29, \"learn_time_ms\": 21854.19}", "{\"n\": 1689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.21, \"learn_time_ms\": 21854.212}", "{\"n\": 1690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3261.64, \"learn_time_ms\": 21854.472}", "{\"n\": 1691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.03, \"learn_time_ms\": 21856.489}", "{\"n\": 1692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3270.03, \"learn_time_ms\": 21869.485}", "{\"n\": 1693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.85, \"learn_time_ms\": 21862.731}", "{\"n\": 1694, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3268.58, \"learn_time_ms\": 21854.313}", "{\"n\": 1695, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.57, \"learn_time_ms\": 21863.443}", "{\"n\": 1696, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.29, \"learn_time_ms\": 21861.122}", "{\"n\": 1697, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.0, \"learn_time_ms\": 21852.687}", "{\"n\": 1698, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.0, \"learn_time_ms\": 21854.43}", "{\"n\": 1699, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3230.3, \"learn_time_ms\": 21854.322}", "{\"n\": 1700, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.77, \"learn_time_ms\": 21858.399}", "{\"n\": 1701, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.04, \"learn_time_ms\": 21851.07}", "{\"n\": 1702, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.93, \"learn_time_ms\": 21841.685}", "{\"n\": 1703, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.6, \"learn_time_ms\": 21853.197}", "{\"n\": 1704, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.7, \"learn_time_ms\": 21858.615}", "{\"n\": 1705, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3211.6, \"learn_time_ms\": 21850.362}", "{\"n\": 1706, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.84, \"learn_time_ms\": 21853.532}", "{\"n\": 1707, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.84, \"learn_time_ms\": 21857.404}", "{\"n\": 1708, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3225.79, \"learn_time_ms\": 21839.768}", "{\"n\": 1709, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.18, \"learn_time_ms\": 21844.318}", "{\"n\": 1710, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.67, \"learn_time_ms\": 21836.057}", "{\"n\": 1711, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.45, \"learn_time_ms\": 21830.137}", "{\"n\": 1712, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.29, \"learn_time_ms\": 21831.67}", "{\"n\": 1713, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.25, \"learn_time_ms\": 21834.551}", "{\"n\": 1714, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.25, \"learn_time_ms\": 21844.695}", "{\"n\": 1715, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.92, \"learn_time_ms\": 21844.182}", "{\"n\": 1716, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3221.08, \"learn_time_ms\": 21841.785}", "{\"n\": 1717, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.11, \"learn_time_ms\": 21838.009}", "{\"n\": 1718, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.77, \"learn_time_ms\": 21854.637}", "{\"n\": 1719, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3154.91, \"learn_time_ms\": 21858.092}", "{\"n\": 1720, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3155.81, \"learn_time_ms\": 21853.196}", "{\"n\": 1721, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3149.02, \"learn_time_ms\": 21851.537}", "{\"n\": 1722, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3149.02, \"learn_time_ms\": 21867.149}", "{\"n\": 1723, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3155.29, \"learn_time_ms\": 21855.393}", "{\"n\": 1724, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3161.71, \"learn_time_ms\": 21852.411}", "{\"n\": 1725, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3131.56, \"learn_time_ms\": 21858.42}", "{\"n\": 1726, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3131.56, \"learn_time_ms\": 21856.35}", "{\"n\": 1727, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3131.56, \"learn_time_ms\": 21846.347}", "{\"n\": 1728, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3121.1, \"learn_time_ms\": 21845.118}", "{\"n\": 1729, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3108.26, \"learn_time_ms\": 21836.919}", "{\"n\": 1730, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3100.49, \"learn_time_ms\": 21846.773}", "{\"n\": 1731, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3106.68, \"learn_time_ms\": 21859.956}", "{\"n\": 1732, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3106.68, \"learn_time_ms\": 21841.219}", "{\"n\": 1733, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3103.6, \"learn_time_ms\": 21856.812}", "{\"n\": 1734, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3101.75, \"learn_time_ms\": 21854.934}", "{\"n\": 1735, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3092.97, \"learn_time_ms\": 21858.085}", "{\"n\": 1736, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3092.97, \"learn_time_ms\": 21859.091}", "{\"n\": 1737, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3092.97, \"learn_time_ms\": 21867.805}", "{\"n\": 1738, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3080.57, \"learn_time_ms\": 21871.149}", "{\"n\": 1739, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3062.37, \"learn_time_ms\": 21884.388}", "{\"n\": 1740, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3062.37, \"learn_time_ms\": 21888.556}", "{\"n\": 1741, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3075.03, \"learn_time_ms\": 21886.964}", "{\"n\": 1742, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3075.03, \"learn_time_ms\": 21886.422}", "{\"n\": 1743, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3070.66, \"learn_time_ms\": 21882.392}", "{\"n\": 1744, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3067.81, \"learn_time_ms\": 21879.954}", "{\"n\": 1745, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3055.86, \"learn_time_ms\": 21873.522}", "{\"n\": 1746, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3059.32, \"learn_time_ms\": 21871.529}", "{\"n\": 1747, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3056.46, \"learn_time_ms\": 21868.947}", "{\"n\": 1748, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3052.38, \"learn_time_ms\": 21866.978}", "{\"n\": 1749, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3053.17, \"learn_time_ms\": 21861.609}", "{\"n\": 1750, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3042.48, \"learn_time_ms\": 21854.328}", "{\"n\": 1751, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3049.53, \"learn_time_ms\": 21868.787}", "{\"n\": 1752, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3049.53, \"learn_time_ms\": 21874.378}", "{\"n\": 1753, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3050.84, \"learn_time_ms\": 21856.057}", "{\"n\": 1754, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3050.84, \"learn_time_ms\": 21848.927}", "{\"n\": 1755, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3030.13, \"learn_time_ms\": 21835.274}", "{\"n\": 1756, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3038.34, \"learn_time_ms\": 21849.685}", "{\"n\": 1757, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3044.0, \"learn_time_ms\": 21844.744}", "{\"n\": 1758, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3055.18, \"learn_time_ms\": 21836.451}", "{\"n\": 1759, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3073.73, \"learn_time_ms\": 21822.454}", "{\"n\": 1760, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3072.87, \"learn_time_ms\": 21823.442}", "{\"n\": 1761, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3082.3, \"learn_time_ms\": 21812.433}", "{\"n\": 1762, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3082.3, \"learn_time_ms\": 21821.149}", "{\"n\": 1763, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3092.67, \"learn_time_ms\": 21825.65}", "{\"n\": 1764, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3085.81, \"learn_time_ms\": 21832.36}", "{\"n\": 1765, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3085.1, \"learn_time_ms\": 21857.288}", "{\"n\": 1766, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3084.78, \"learn_time_ms\": 21852.655}", "{\"n\": 1767, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3087.29, \"learn_time_ms\": 21850.9}", "{\"n\": 1768, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3095.0, \"learn_time_ms\": 21857.857}", "{\"n\": 1769, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3095.0, \"learn_time_ms\": 21875.145}", "{\"n\": 1770, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3088.37, \"learn_time_ms\": 21870.265}", "{\"n\": 1771, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3095.5, \"learn_time_ms\": 21862.439}", "{\"n\": 1772, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3091.46, \"learn_time_ms\": 21854.489}", "{\"n\": 1773, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3085.12, \"learn_time_ms\": 21857.709}", "{\"n\": 1774, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3085.12, \"learn_time_ms\": 21862.618}", "{\"n\": 1775, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3085.12, \"learn_time_ms\": 21861.938}", "{\"n\": 1776, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3099.69, \"learn_time_ms\": 21854.664}", "{\"n\": 1777, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3092.72, \"learn_time_ms\": 21851.577}", "{\"n\": 1778, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3087.43, \"learn_time_ms\": 21845.405}", "{\"n\": 1779, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3087.43, \"learn_time_ms\": 21837.369}", "{\"n\": 1780, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3094.08, \"learn_time_ms\": 21846.277}", "{\"n\": 1781, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3104.7, \"learn_time_ms\": 21841.379}", "{\"n\": 1782, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3107.06, \"learn_time_ms\": 21846.251}", "{\"n\": 1783, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3107.21, \"learn_time_ms\": 21843.698}", "{\"n\": 1784, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3135.73, \"learn_time_ms\": 21845.177}", "{\"n\": 1785, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3135.73, \"learn_time_ms\": 21839.468}", "{\"n\": 1786, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3132.71, \"learn_time_ms\": 21839.757}", "{\"n\": 1787, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3119.58, \"learn_time_ms\": 21856.67}", "{\"n\": 1788, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3119.58, \"learn_time_ms\": 21870.369}", "{\"n\": 1789, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3126.46, \"learn_time_ms\": 21879.662}", "{\"n\": 1790, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3137.01, \"learn_time_ms\": 21875.02}", "{\"n\": 1791, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3137.01, \"learn_time_ms\": 21880.0}", "{\"n\": 1792, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.97, \"learn_time_ms\": 21877.484}", "{\"n\": 1793, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.71, \"learn_time_ms\": 21884.769}", "{\"n\": 1794, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.68, \"learn_time_ms\": 21874.462}", "{\"n\": 1795, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.42, \"learn_time_ms\": 21876.486}", "{\"n\": 1796, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.42, \"learn_time_ms\": 21875.637}", "{\"n\": 1797, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.28, \"learn_time_ms\": 21866.724}", "{\"n\": 1798, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.37, \"learn_time_ms\": 21868.951}", "{\"n\": 1799, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3181.24, \"learn_time_ms\": 21855.271}", "{\"n\": 1800, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.34, \"learn_time_ms\": 21852.87}", "{\"n\": 1801, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.34, \"learn_time_ms\": 21860.812}", "{\"n\": 1802, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.39, \"learn_time_ms\": 21848.192}", "{\"n\": 1803, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.37, \"learn_time_ms\": 21837.045}", "{\"n\": 1804, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.09, \"learn_time_ms\": 21845.619}", "{\"n\": 1805, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.19, \"learn_time_ms\": 21829.532}", "{\"n\": 1806, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.19, \"learn_time_ms\": 21834.704}", "{\"n\": 1807, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.19, \"learn_time_ms\": 21838.316}", "{\"n\": 1808, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.49, \"learn_time_ms\": 21824.433}", "{\"n\": 1809, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.88, \"learn_time_ms\": 21836.153}", "{\"n\": 1810, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.12, \"learn_time_ms\": 21833.63}", "{\"n\": 1811, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.12, \"learn_time_ms\": 21827.035}", "{\"n\": 1812, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.12, \"learn_time_ms\": 21834.664}", "{\"n\": 1813, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.12, \"learn_time_ms\": 21835.318}", "{\"n\": 1814, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.26, \"learn_time_ms\": 21828.35}", "{\"n\": 1815, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.39, \"learn_time_ms\": 21843.553}", "{\"n\": 1816, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.27, \"learn_time_ms\": 21830.16}", "{\"n\": 1817, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.45, \"learn_time_ms\": 21830.155}", "{\"n\": 1818, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.45, \"learn_time_ms\": 21833.317}", "{\"n\": 1819, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.43, \"learn_time_ms\": 21826.265}", "{\"n\": 1820, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.78, \"learn_time_ms\": 21837.153}", "{\"n\": 1821, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3253.66, \"learn_time_ms\": 21835.231}", "{\"n\": 1822, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.64, \"learn_time_ms\": 21834.317}", "{\"n\": 1823, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.98, \"learn_time_ms\": 21844.553}", "{\"n\": 1824, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.66, \"learn_time_ms\": 21847.133}", "{\"n\": 1825, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.06, \"learn_time_ms\": 21842.554}", "{\"n\": 1826, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.06, \"learn_time_ms\": 21843.628}", "{\"n\": 1827, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.09, \"learn_time_ms\": 21832.435}", "{\"n\": 1828, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.09, \"learn_time_ms\": 21832.326}", "{\"n\": 1829, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3262.4, \"learn_time_ms\": 21832.913}", "{\"n\": 1830, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.11, \"learn_time_ms\": 21826.922}", "{\"n\": 1831, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.18, \"learn_time_ms\": 21829.118}", "{\"n\": 1832, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.94, \"learn_time_ms\": 21838.555}", "{\"n\": 1833, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.94, \"learn_time_ms\": 21839.354}", "{\"n\": 1834, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.1, \"learn_time_ms\": 21846.524}", "{\"n\": 1835, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.8, \"learn_time_ms\": 21850.934}", "{\"n\": 1836, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.6, \"learn_time_ms\": 21852.627}", "{\"n\": 1837, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.44, \"learn_time_ms\": 21863.85}", "{\"n\": 1838, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.21, \"learn_time_ms\": 21860.706}", "{\"n\": 1839, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.7, \"learn_time_ms\": 21862.589}", "{\"n\": 1840, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.7, \"learn_time_ms\": 21861.435}", "{\"n\": 1841, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.19, \"learn_time_ms\": 21855.573}", "{\"n\": 1842, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.19, \"learn_time_ms\": 21849.754}", "{\"n\": 1843, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.22, \"learn_time_ms\": 21851.606}", "{\"n\": 1844, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.07, \"learn_time_ms\": 21855.292}", "{\"n\": 1845, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.07, \"learn_time_ms\": 21847.089}", "{\"n\": 1846, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.71, \"learn_time_ms\": 21854.483}", "{\"n\": 1847, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.78, \"learn_time_ms\": 21848.726}", "{\"n\": 1848, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.69, \"learn_time_ms\": 21842.081}", "{\"n\": 1849, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.43, \"learn_time_ms\": 21844.332}", "{\"n\": 1850, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3353.43, \"learn_time_ms\": 21850.77}", "{\"n\": 1851, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.03, \"learn_time_ms\": 21859.854}", "{\"n\": 1852, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.65, \"learn_time_ms\": 21854.54}", "{\"n\": 1853, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.67, \"learn_time_ms\": 21856.107}", "{\"n\": 1854, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.46, \"learn_time_ms\": 21839.362}", "{\"n\": 1855, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.46, \"learn_time_ms\": 21846.581}", "{\"n\": 1856, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.37, \"learn_time_ms\": 21857.434}", "{\"n\": 1857, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.94, \"learn_time_ms\": 21864.489}", "{\"n\": 1858, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.31, \"learn_time_ms\": 21867.991}", "{\"n\": 1859, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.54, \"learn_time_ms\": 21869.187}", "{\"n\": 1860, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.43, \"learn_time_ms\": 21868.214}", "{\"n\": 1861, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.64, \"learn_time_ms\": 21867.288}", "{\"n\": 1862, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.7, \"learn_time_ms\": 21876.577}", "{\"n\": 1863, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.52, \"learn_time_ms\": 21879.923}", "{\"n\": 1864, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.3, \"learn_time_ms\": 21889.993}", "{\"n\": 1865, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3302.87, \"learn_time_ms\": 21882.053}", "{\"n\": 1866, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.11, \"learn_time_ms\": 21874.225}", "{\"n\": 1867, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.11, \"learn_time_ms\": 21877.63}", "{\"n\": 1868, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.07, \"learn_time_ms\": 21872.313}", "{\"n\": 1869, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.56, \"learn_time_ms\": 21871.018}", "{\"n\": 1870, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.52, \"learn_time_ms\": 21865.321}", "{\"n\": 1871, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3226.52, \"learn_time_ms\": 21862.044}", "{\"n\": 1872, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.84, \"learn_time_ms\": 21850.429}", "{\"n\": 1873, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.23, \"learn_time_ms\": 21845.071}", "{\"n\": 1874, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.83, \"learn_time_ms\": 21842.359}", "{\"n\": 1875, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.67, \"learn_time_ms\": 21844.582}", "{\"n\": 1876, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.61, \"learn_time_ms\": 21846.155}", "{\"n\": 1877, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3235.95, \"learn_time_ms\": 21844.825}", "{\"n\": 1878, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3236.79, \"learn_time_ms\": 21864.842}", "{\"n\": 1879, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.38, \"learn_time_ms\": 21863.765}", "{\"n\": 1880, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3239.38, \"learn_time_ms\": 21866.317}", "{\"n\": 1881, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.15, \"learn_time_ms\": 21869.898}", "{\"n\": 1882, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.66, \"learn_time_ms\": 21880.826}", "{\"n\": 1883, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.66, \"learn_time_ms\": 21879.648}", "{\"n\": 1884, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.66, \"learn_time_ms\": 21874.086}", "{\"n\": 1885, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.68, \"learn_time_ms\": 21872.433}", "{\"n\": 1886, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.7, \"learn_time_ms\": 21864.723}", "{\"n\": 1887, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.11, \"learn_time_ms\": 21861.665}", "{\"n\": 1888, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.11, \"learn_time_ms\": 21861.025}", "{\"n\": 1889, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3213.37, \"learn_time_ms\": 21857.581}", "{\"n\": 1890, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.16, \"learn_time_ms\": 21858.794}", "{\"n\": 1891, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3215.67, \"learn_time_ms\": 21844.575}", "{\"n\": 1892, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.81, \"learn_time_ms\": 21841.757}", "{\"n\": 1893, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3218.81, \"learn_time_ms\": 21827.213}", "{\"n\": 1894, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.85, \"learn_time_ms\": 21840.573}", "{\"n\": 1895, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.82, \"learn_time_ms\": 21839.679}", "{\"n\": 1896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3209.82, \"learn_time_ms\": 21850.187}", "{\"n\": 1897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.82, \"learn_time_ms\": 21843.971}", "{\"n\": 1898, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.82, \"learn_time_ms\": 21838.546}", "{\"n\": 1899, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.35, \"learn_time_ms\": 21836.291}", "{\"n\": 1900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3208.35, \"learn_time_ms\": 21837.141}", "{\"n\": 1901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3194.59, \"learn_time_ms\": 21843.081}", "{\"n\": 1902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.1, \"learn_time_ms\": 21843.401}", "{\"n\": 1903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3197.1, \"learn_time_ms\": 21864.454}", "{\"n\": 1904, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3188.69, \"learn_time_ms\": 21852.782}", "{\"n\": 1905, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3179.62, \"learn_time_ms\": 21862.346}", "{\"n\": 1906, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3171.59, \"learn_time_ms\": 21855.653}", "{\"n\": 1907, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.2, \"learn_time_ms\": 21857.907}", "{\"n\": 1908, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3169.74, \"learn_time_ms\": 21850.875}", "{\"n\": 1909, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3168.96, \"learn_time_ms\": 21851.012}", "{\"n\": 1910, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.24, \"learn_time_ms\": 21851.28}", "{\"n\": 1911, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3154.46, \"learn_time_ms\": 21854.122}", "{\"n\": 1912, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.3, \"learn_time_ms\": 21848.773}", "{\"n\": 1913, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.33, \"learn_time_ms\": 21839.777}", "{\"n\": 1914, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.48, \"learn_time_ms\": 21843.823}", "{\"n\": 1915, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3139.1, \"learn_time_ms\": 21830.459}", "{\"n\": 1916, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.65, \"learn_time_ms\": 21820.691}", "{\"n\": 1917, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3124.34, \"learn_time_ms\": 21820.211}", "{\"n\": 1918, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3124.92, \"learn_time_ms\": 21816.578}", "{\"n\": 1919, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3121.53, \"learn_time_ms\": 21814.027}", "{\"n\": 1920, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3118.4, \"learn_time_ms\": 21808.647}", "{\"n\": 1921, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3118.4, \"learn_time_ms\": 21816.955}", "{\"n\": 1922, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3118.4, \"learn_time_ms\": 21811.373}", "{\"n\": 1923, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3113.26, \"learn_time_ms\": 21803.864}", "{\"n\": 1924, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3107.58, \"learn_time_ms\": 21802.186}", "{\"n\": 1925, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3107.58, \"learn_time_ms\": 21812.319}", "{\"n\": 1926, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3113.11, \"learn_time_ms\": 21815.303}", "{\"n\": 1927, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3123.99, \"learn_time_ms\": 21810.79}", "{\"n\": 1928, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3114.34, \"learn_time_ms\": 21815.074}", "{\"n\": 1929, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.82, \"learn_time_ms\": 21819.425}", "{\"n\": 1930, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.82, \"learn_time_ms\": 21825.599}", "{\"n\": 1931, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.9, \"learn_time_ms\": 21820.361}", "{\"n\": 1932, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.17, \"learn_time_ms\": 21817.578}", "{\"n\": 1933, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3145.69, \"learn_time_ms\": 21811.984}", "{\"n\": 1934, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.9, \"learn_time_ms\": 21801.583}", "{\"n\": 1935, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.9, \"learn_time_ms\": 21794.782}", "{\"n\": 1936, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3151.18, \"learn_time_ms\": 21800.154}", "{\"n\": 1937, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3167.15, \"learn_time_ms\": 21801.286}", "{\"n\": 1938, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3175.48, \"learn_time_ms\": 21811.482}", "{\"n\": 1939, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.1, \"learn_time_ms\": 21813.289}", "{\"n\": 1940, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.27, \"learn_time_ms\": 21812.475}", "{\"n\": 1941, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.27, \"learn_time_ms\": 21816.994}", "{\"n\": 1942, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3173.62, \"learn_time_ms\": 21823.89}", "{\"n\": 1943, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.86, \"learn_time_ms\": 21844.111}", "{\"n\": 1944, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.59, \"learn_time_ms\": 21854.518}", "{\"n\": 1945, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.59, \"learn_time_ms\": 21856.499}", "{\"n\": 1946, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3150.71, \"learn_time_ms\": 21858.672}", "{\"n\": 1947, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.51, \"learn_time_ms\": 21865.532}", "{\"n\": 1948, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3138.23, \"learn_time_ms\": 21864.604}", "{\"n\": 1949, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.7, \"learn_time_ms\": 21869.086}", "{\"n\": 1950, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3129.59, \"learn_time_ms\": 21863.47}", "{\"n\": 1951, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3129.59, \"learn_time_ms\": 21859.889}", "{\"n\": 1952, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3133.73, \"learn_time_ms\": 21873.293}", "{\"n\": 1953, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3111.71, \"learn_time_ms\": 21867.912}", "{\"n\": 1954, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3109.16, \"learn_time_ms\": 21860.227}", "{\"n\": 1955, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3100.81, \"learn_time_ms\": 21859.404}", "{\"n\": 1956, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3100.81, \"learn_time_ms\": 21850.076}", "{\"n\": 1957, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3105.75, \"learn_time_ms\": 21826.078}", "{\"n\": 1958, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3120.47, \"learn_time_ms\": 21810.972}", "{\"n\": 1959, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3129.32, \"learn_time_ms\": 21800.213}", "{\"n\": 1960, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3124.93, \"learn_time_ms\": 21799.952}", "{\"n\": 1961, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3124.93, \"learn_time_ms\": 21801.661}", "{\"n\": 1962, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3124.93, \"learn_time_ms\": 21789.419}", "{\"n\": 1963, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3122.77, \"learn_time_ms\": 21788.169}", "{\"n\": 1964, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3120.34, \"learn_time_ms\": 21797.788}", "{\"n\": 1965, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3121.45, \"learn_time_ms\": 21804.333}", "{\"n\": 1966, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3112.11, \"learn_time_ms\": 21813.583}", "{\"n\": 1967, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3112.11, \"learn_time_ms\": 21841.616}", "{\"n\": 1968, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3104.74, \"learn_time_ms\": 21850.674}", "{\"n\": 1969, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3116.7, \"learn_time_ms\": 21846.867}", "{\"n\": 1970, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3114.36, \"learn_time_ms\": 21847.244}", "{\"n\": 1971, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3115.1, \"learn_time_ms\": 21847.696}", "{\"n\": 1972, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3115.1, \"learn_time_ms\": 21849.076}", "{\"n\": 1973, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3123.54, \"learn_time_ms\": 21852.456}", "{\"n\": 1974, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3119.69, \"learn_time_ms\": 21849.468}", "{\"n\": 1975, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3132.47, \"learn_time_ms\": 21846.762}", "{\"n\": 1976, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.31, \"learn_time_ms\": 21842.332}", "{\"n\": 1977, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.98, \"learn_time_ms\": 21840.471}", "{\"n\": 1978, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.98, \"learn_time_ms\": 21830.106}", "{\"n\": 1979, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.62, \"learn_time_ms\": 21839.437}", "{\"n\": 1980, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3129.35, \"learn_time_ms\": 21846.507}", "{\"n\": 1981, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3131.19, \"learn_time_ms\": 21845.009}", "{\"n\": 1982, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3151.95, \"learn_time_ms\": 21839.648}", "{\"n\": 1983, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3151.95, \"learn_time_ms\": 21831.226}", "{\"n\": 1984, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3151.95, \"learn_time_ms\": 21831.996}", "{\"n\": 1985, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3166.83, \"learn_time_ms\": 21829.923}", "{\"n\": 1986, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3185.99, \"learn_time_ms\": 21833.726}", "{\"n\": 1987, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.68, \"learn_time_ms\": 21830.706}", "{\"n\": 1988, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.68, \"learn_time_ms\": 21846.399}", "{\"n\": 1989, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3193.68, \"learn_time_ms\": 21848.563}", "{\"n\": 1990, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.09, \"learn_time_ms\": 21836.131}", "{\"n\": 1991, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3206.09, \"learn_time_ms\": 21825.882}", "{\"n\": 1992, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3207.63, \"learn_time_ms\": 21829.526}", "{\"n\": 1993, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.66, \"learn_time_ms\": 21830.419}", "{\"n\": 1994, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.66, \"learn_time_ms\": 21832.303}", "{\"n\": 1995, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3198.87, \"learn_time_ms\": 21828.891}", "{\"n\": 1996, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3177.88, \"learn_time_ms\": 21816.966}", "{\"n\": 1997, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3173.72, \"learn_time_ms\": 21811.622}", "{\"n\": 1998, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.14, \"learn_time_ms\": 21801.945}", "{\"n\": 1999, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.14, \"learn_time_ms\": 21806.276}", "{\"n\": 2000, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3196.39, \"learn_time_ms\": 21818.774}"]["{\"n\": 2001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15318.942}", "{\"n\": 2002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14896.024}", "{\"n\": 2003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14753.497}", "{\"n\": 2004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14717.81}", "{\"n\": 2005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14677.781}", "{\"n\": 2006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14619.829}", "{\"n\": 2007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14606.681}", "{\"n\": 2008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14614.55}", "{\"n\": 2009, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 3050.0, \"learn_time_ms\": 14610.536}", "{\"n\": 2010, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.333333333333334, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2800.6666666666665, \"learn_time_ms\": 14624.427}", "{\"n\": 2011, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.142857142857142, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2899.285714285714, \"learn_time_ms\": 14559.895}", "{\"n\": 2012, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.142857142857142, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2899.285714285714, \"learn_time_ms\": 14587.389}", "{\"n\": 2013, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.375, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3001.25, \"learn_time_ms\": 14601.98}", "{\"n\": 2014, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.375, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3001.25, \"learn_time_ms\": 14597.114}", "{\"n\": 2015, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.777777777777779, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2935.0, \"learn_time_ms\": 14604.907}", "{\"n\": 2016, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2931.3333333333335, \"learn_time_ms\": 14631.473}", "{\"n\": 2017, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3070.0666666666666, \"learn_time_ms\": 14643.714}", "{\"n\": 2018, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.625, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3119.4375, \"learn_time_ms\": 14641.799}", "{\"n\": 2019, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.588235294117647, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3144.294117647059, \"learn_time_ms\": 14637.817}", "{\"n\": 2020, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.666666666666666, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3138.4444444444443, \"learn_time_ms\": 14633.071}", "{\"n\": 2021, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3164.6, \"learn_time_ms\": 14635.218}", "{\"n\": 2022, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.181818181818182, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3215.6363636363635, \"learn_time_ms\": 14629.451}", "{\"n\": 2023, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.173913043478262, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3236.7391304347825, \"learn_time_ms\": 14637.619}", "{\"n\": 2024, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.333333333333334, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3200.9166666666665, \"learn_time_ms\": 14646.882}", "{\"n\": 2025, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.814814814814815, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3147.3703703703704, \"learn_time_ms\": 14651.45}", "{\"n\": 2026, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.821428571428571, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3160.714285714286, \"learn_time_ms\": 14640.66}", "{\"n\": 2027, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.821428571428571, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3160.714285714286, \"learn_time_ms\": 14635.971}", "{\"n\": 2028, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3139.5333333333333, \"learn_time_ms\": 14644.396}", "{\"n\": 2029, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.90625, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3155.40625, \"learn_time_ms\": 14656.063}", "{\"n\": 2030, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.117647058823529, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3114.676470588235, \"learn_time_ms\": 14648.275}", "{\"n\": 2031, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.117647058823529, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3114.676470588235, \"learn_time_ms\": 14644.082}", "{\"n\": 2032, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.742857142857142, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3140.457142857143, \"learn_time_ms\": 14626.36}", "{\"n\": 2033, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.64864864864865, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3161.810810810811, \"learn_time_ms\": 14623.488}", "{\"n\": 2034, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.692307692307692, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3157.7179487179487, \"learn_time_ms\": 14608.484}", "{\"n\": 2035, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.714285714285714, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3162.3333333333335, \"learn_time_ms\": 14585.164}", "{\"n\": 2036, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.581395348837209, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3183.5116279069766, \"learn_time_ms\": 14586.645}", "{\"n\": 2037, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.581395348837209, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3183.5116279069766, \"learn_time_ms\": 14581.485}", "{\"n\": 2038, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.555555555555555, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3194.688888888889, \"learn_time_ms\": 14570.808}", "{\"n\": 2039, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.652173913043478, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3183.717391304348, \"learn_time_ms\": 14564.931}", "{\"n\": 2040, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3177.1666666666665, \"learn_time_ms\": 14575.366}", "{\"n\": 2041, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3199.24, \"learn_time_ms\": 14547.964}", "{\"n\": 2042, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.529411764705882, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3199.8627450980393, \"learn_time_ms\": 14561.425}", "{\"n\": 2043, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.60377358490566, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3192.2830188679245, \"learn_time_ms\": 14565.461}", "{\"n\": 2044, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.648148148148149, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3183.1111111111113, \"learn_time_ms\": 14582.172}", "{\"n\": 2045, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.654545454545454, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3187.5636363636363, \"learn_time_ms\": 14597.449}", "{\"n\": 2046, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.785714285714286, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3169.3035714285716, \"learn_time_ms\": 14599.468}", "{\"n\": 2047, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.785714285714286, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3169.3035714285716, \"learn_time_ms\": 14597.837}", "{\"n\": 2048, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.583333333333334, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3213.4, \"learn_time_ms\": 14606.653}", "{\"n\": 2049, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.60655737704918, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3214.0, \"learn_time_ms\": 14591.213}", "{\"n\": 2050, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.603174603174603, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3210.3333333333335, \"learn_time_ms\": 14563.303}", "{\"n\": 2051, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.603174603174603, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3210.3333333333335, \"learn_time_ms\": 14575.219}", "{\"n\": 2052, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59375, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3217.234375, \"learn_time_ms\": 14559.328}", "{\"n\": 2053, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.523076923076923, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3220.369230769231, \"learn_time_ms\": 14546.057}", "{\"n\": 2054, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.417910447761194, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3235.3283582089553, \"learn_time_ms\": 14551.092}", "{\"n\": 2055, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.376811594202898, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3251.231884057971, \"learn_time_ms\": 14556.78}", "{\"n\": 2056, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.371428571428572, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3252.957142857143, \"learn_time_ms\": 14555.112}", "{\"n\": 2057, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.36111111111111, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3254.4861111111113, \"learn_time_ms\": 14564.421}", "{\"n\": 2058, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.36111111111111, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3254.4861111111113, \"learn_time_ms\": 14562.323}", "{\"n\": 2059, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.346666666666666, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3262.4266666666667, \"learn_time_ms\": 14586.768}", "{\"n\": 2060, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.346666666666666, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3262.4266666666667, \"learn_time_ms\": 14610.66}", "{\"n\": 2061, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.368421052631579, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3256.9473684210525, \"learn_time_ms\": 14608.044}", "{\"n\": 2062, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.30379746835443, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3271.53164556962, \"learn_time_ms\": 14594.364}", "{\"n\": 2063, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.148148148148149, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3290.0493827160494, \"learn_time_ms\": 14593.35}", "{\"n\": 2064, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.148148148148149, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3290.0493827160494, \"learn_time_ms\": 14578.146}", "{\"n\": 2065, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.146341463414634, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3290.317073170732, \"learn_time_ms\": 14579.824}", "{\"n\": 2066, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.08433734939759, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3305.265060240964, \"learn_time_ms\": 14594.839}", "{\"n\": 2067, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.152941176470588, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3298.564705882353, \"learn_time_ms\": 14607.433}", "{\"n\": 2068, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.093023255813954, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3304.7093023255816, \"learn_time_ms\": 14609.743}", "{\"n\": 2069, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.079545454545455, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3305.409090909091, \"learn_time_ms\": 14616.917}", "{\"n\": 2070, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.033333333333333, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3312.5, \"learn_time_ms\": 14612.773}", "{\"n\": 2071, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.989010989010989, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3324.131868131868, \"learn_time_ms\": 14609.983}", "{\"n\": 2072, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.021505376344086, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.7634408602153, \"learn_time_ms\": 14626.817}", "{\"n\": 2073, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.021505376344086, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.7634408602153, \"learn_time_ms\": 14644.178}", "{\"n\": 2074, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.958333333333334, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3334.96875, \"learn_time_ms\": 14649.327}", "{\"n\": 2075, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.958333333333334, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3334.96875, \"learn_time_ms\": 14641.106}", "{\"n\": 2076, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89795918367347, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3342.5510204081634, \"learn_time_ms\": 14638.281}", "{\"n\": 2077, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.52, \"learn_time_ms\": 14600.776}", "{\"n\": 2078, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3337.71, \"learn_time_ms\": 14583.067}", "{\"n\": 2079, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3343.84, \"learn_time_ms\": 14579.915}", "{\"n\": 2080, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3343.84, \"learn_time_ms\": 14582.342}", "{\"n\": 2081, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3356.64, \"learn_time_ms\": 14599.477}", "{\"n\": 2082, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3367.3, \"learn_time_ms\": 14601.363}", "{\"n\": 2083, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3374.52, \"learn_time_ms\": 14597.892}", "{\"n\": 2084, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3374.52, \"learn_time_ms\": 14609.392}", "{\"n\": 2085, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3374.52, \"learn_time_ms\": 14628.561}", "{\"n\": 2086, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3381.34, \"learn_time_ms\": 14636.124}", "{\"n\": 2087, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.85, \"learn_time_ms\": 14666.004}", "{\"n\": 2088, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3374.52, \"learn_time_ms\": 14679.875}", "{\"n\": 2089, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3358.94, \"learn_time_ms\": 14664.971}", "{\"n\": 2090, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3358.94, \"learn_time_ms\": 14645.834}", "{\"n\": 2091, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3362.82, \"learn_time_ms\": 14651.672}", "{\"n\": 2092, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3354.41, \"learn_time_ms\": 14652.735}", "{\"n\": 2093, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3358.83, \"learn_time_ms\": 14654.727}", "{\"n\": 2094, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3365.25, \"learn_time_ms\": 14617.25}", "{\"n\": 2095, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3381.59, \"learn_time_ms\": 14591.88}", "{\"n\": 2096, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3388.58, \"learn_time_ms\": 14598.596}", "{\"n\": 2097, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3372.06, \"learn_time_ms\": 14599.846}", "{\"n\": 2098, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3376.92, \"learn_time_ms\": 14608.899}", "{\"n\": 2099, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.39, \"learn_time_ms\": 14614.404}", "{\"n\": 2100, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3380.68, \"learn_time_ms\": 14638.4}", "{\"n\": 2101, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3389.9, \"learn_time_ms\": 14635.642}", "{\"n\": 2102, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3408.97, \"learn_time_ms\": 14657.351}", "{\"n\": 2103, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.89, \"learn_time_ms\": 14659.687}", "{\"n\": 2104, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3412.93, \"learn_time_ms\": 14685.594}", "{\"n\": 2105, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3418.51, \"learn_time_ms\": 14706.132}", "{\"n\": 2106, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3418.51, \"learn_time_ms\": 14701.482}", "{\"n\": 2107, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3411.47, \"learn_time_ms\": 14706.146}", "{\"n\": 2108, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3415.13, \"learn_time_ms\": 14690.484}", "{\"n\": 2109, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3415.13, \"learn_time_ms\": 14692.385}", "{\"n\": 2110, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.2, \"learn_time_ms\": 14696.512}", "{\"n\": 2111, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3424.51, \"learn_time_ms\": 14697.44}", "{\"n\": 2112, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3419.7, \"learn_time_ms\": 14673.199}", "{\"n\": 2113, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3414.95, \"learn_time_ms\": 14653.872}", "{\"n\": 2114, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3427.55, \"learn_time_ms\": 14665.706}", "{\"n\": 2115, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3447.2, \"learn_time_ms\": 14674.4}", "{\"n\": 2116, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3447.2, \"learn_time_ms\": 14659.272}", "{\"n\": 2117, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.1, \"learn_time_ms\": 14667.528}", "{\"n\": 2118, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.1, \"learn_time_ms\": 14667.538}", "{\"n\": 2119, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.66, \"learn_time_ms\": 14677.612}", "{\"n\": 2120, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.77, \"learn_time_ms\": 14672.896}", "{\"n\": 2121, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.63, \"learn_time_ms\": 14676.899}", "{\"n\": 2122, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3446.63, \"learn_time_ms\": 14690.685}", "{\"n\": 2123, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.16, \"learn_time_ms\": 14673.413}", "{\"n\": 2124, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.16, \"learn_time_ms\": 14649.527}", "{\"n\": 2125, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3443.14, \"learn_time_ms\": 14628.661}", "{\"n\": 2126, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.76, \"learn_time_ms\": 14639.871}", "{\"n\": 2127, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.76, \"learn_time_ms\": 14627.451}", "{\"n\": 2128, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.2, \"learn_time_ms\": 14640.144}", "{\"n\": 2129, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.2, \"learn_time_ms\": 14642.073}", "{\"n\": 2130, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.54, \"learn_time_ms\": 14656.503}", "{\"n\": 2131, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.15, \"learn_time_ms\": 14645.549}", "{\"n\": 2132, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3491.54, \"learn_time_ms\": 14655.228}", "{\"n\": 2133, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3491.54, \"learn_time_ms\": 14704.282}", "{\"n\": 2134, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3479.54, \"learn_time_ms\": 14710.438}", "{\"n\": 2135, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3479.54, \"learn_time_ms\": 14730.872}", "{\"n\": 2136, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3474.46, \"learn_time_ms\": 14727.097}", "{\"n\": 2137, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.96, \"learn_time_ms\": 14700.77}", "{\"n\": 2138, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.25, \"learn_time_ms\": 14691.665}", "{\"n\": 2139, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.63, \"learn_time_ms\": 14679.93}", "{\"n\": 2140, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.63, \"learn_time_ms\": 14664.093}", "{\"n\": 2141, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.63, \"learn_time_ms\": 14662.065}", "{\"n\": 2142, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3482.26, \"learn_time_ms\": 14646.268}", "{\"n\": 2143, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3481.34, \"learn_time_ms\": 14598.477}", "{\"n\": 2144, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3488.63, \"learn_time_ms\": 14604.314}", "{\"n\": 2145, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3498.43, \"learn_time_ms\": 14545.024}", "{\"n\": 2146, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3504.07, \"learn_time_ms\": 14545.469}", "{\"n\": 2147, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3504.07, \"learn_time_ms\": 14545.319}", "{\"n\": 2148, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3497.51, \"learn_time_ms\": 14544.365}", "{\"n\": 2149, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3495.6, \"learn_time_ms\": 14545.802}", "{\"n\": 2150, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3499.57, \"learn_time_ms\": 14560.412}", "{\"n\": 2151, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3501.63, \"learn_time_ms\": 14573.016}", "{\"n\": 2152, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3525.73, \"learn_time_ms\": 14576.66}", "{\"n\": 2153, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3521.97, \"learn_time_ms\": 14581.596}", "{\"n\": 2154, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.96, \"learn_time_ms\": 14590.523}", "{\"n\": 2155, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3505.17, \"learn_time_ms\": 14645.008}", "{\"n\": 2156, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3512.7, \"learn_time_ms\": 14626.597}", "{\"n\": 2157, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.66, \"learn_time_ms\": 14642.074}", "{\"n\": 2158, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3522.8, \"learn_time_ms\": 14638.436}", "{\"n\": 2159, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3529.9, \"learn_time_ms\": 14645.245}", "{\"n\": 2160, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3537.79, \"learn_time_ms\": 14595.914}", "{\"n\": 2161, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3537.79, \"learn_time_ms\": 14594.126}", "{\"n\": 2162, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3535.45, \"learn_time_ms\": 14607.036}", "{\"n\": 2163, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3552.78, \"learn_time_ms\": 14619.638}", "{\"n\": 2164, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.52, \"learn_time_ms\": 14606.444}", "{\"n\": 2165, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3546.43, \"learn_time_ms\": 14597.663}", "{\"n\": 2166, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3545.0, \"learn_time_ms\": 14596.729}", "{\"n\": 2167, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3553.71, \"learn_time_ms\": 14606.856}", "{\"n\": 2168, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3558.87, \"learn_time_ms\": 14603.019}", "{\"n\": 2169, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3552.12, \"learn_time_ms\": 14589.93}", "{\"n\": 2170, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3556.45, \"learn_time_ms\": 14614.416}", "{\"n\": 2171, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3556.45, \"learn_time_ms\": 14595.293}", "{\"n\": 2172, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3580.92, \"learn_time_ms\": 14581.874}", "{\"n\": 2173, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3585.79, \"learn_time_ms\": 14604.984}", "{\"n\": 2174, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3596.66, \"learn_time_ms\": 14616.72}", "{\"n\": 2175, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3595.96, \"learn_time_ms\": 14612.204}", "{\"n\": 2176, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3595.96, \"learn_time_ms\": 14627.952}", "{\"n\": 2177, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3593.09, \"learn_time_ms\": 14643.443}", "{\"n\": 2178, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3600.67, \"learn_time_ms\": 14659.132}", "{\"n\": 2179, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3608.48, \"learn_time_ms\": 14651.576}", "{\"n\": 2180, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3608.48, \"learn_time_ms\": 14644.271}", "{\"n\": 2181, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3608.47, \"learn_time_ms\": 14641.792}", "{\"n\": 2182, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.18, \"learn_time_ms\": 14644.108}", "{\"n\": 2183, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.18, \"learn_time_ms\": 14640.211}", "{\"n\": 2184, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3602.33, \"learn_time_ms\": 14625.052}", "{\"n\": 2185, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3602.33, \"learn_time_ms\": 14640.058}", "{\"n\": 2186, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3614.32, \"learn_time_ms\": 14635.312}", "{\"n\": 2187, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3629.02, \"learn_time_ms\": 14625.193}", "{\"n\": 2188, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3629.02, \"learn_time_ms\": 14633.678}", "{\"n\": 2189, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3633.58, \"learn_time_ms\": 14662.342}", "{\"n\": 2190, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3630.17, \"learn_time_ms\": 14662.589}", "{\"n\": 2191, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.52, \"learn_time_ms\": 14680.661}", "{\"n\": 2192, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.52, \"learn_time_ms\": 14686.539}", "{\"n\": 2193, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.52, \"learn_time_ms\": 14668.102}", "{\"n\": 2194, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3615.95, \"learn_time_ms\": 14687.737}", "{\"n\": 2195, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3623.63, \"learn_time_ms\": 14681.736}", "{\"n\": 2196, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3639.52, \"learn_time_ms\": 14686.44}", "{\"n\": 2197, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3640.49, \"learn_time_ms\": 14683.399}", "{\"n\": 2198, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3649.06, \"learn_time_ms\": 14664.885}", "{\"n\": 2199, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3659.92, \"learn_time_ms\": 14652.259}", "{\"n\": 2200, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3656.98, \"learn_time_ms\": 14676.752}", "{\"n\": 2201, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3649.45, \"learn_time_ms\": 14686.015}", "{\"n\": 2202, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3651.82, \"learn_time_ms\": 14678.938}", "{\"n\": 2203, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3648.39, \"learn_time_ms\": 14699.911}", "{\"n\": 2204, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3648.39, \"learn_time_ms\": 14665.808}", "{\"n\": 2205, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3624.63, \"learn_time_ms\": 14662.799}", "{\"n\": 2206, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.3, \"learn_time_ms\": 14656.48}", "{\"n\": 2207, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3626.55, \"learn_time_ms\": 14650.412}", "{\"n\": 2208, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3623.21, \"learn_time_ms\": 14648.664}", "{\"n\": 2209, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3634.6, \"learn_time_ms\": 14639.695}", "{\"n\": 2210, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3637.35, \"learn_time_ms\": 14625.12}", "{\"n\": 2211, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3636.4, \"learn_time_ms\": 14626.014}", "{\"n\": 2212, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3622.48, \"learn_time_ms\": 14613.434}", "{\"n\": 2213, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3606.85, \"learn_time_ms\": 14603.398}", "{\"n\": 2214, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3606.85, \"learn_time_ms\": 14629.119}", "{\"n\": 2215, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3596.58, \"learn_time_ms\": 14628.103}", "{\"n\": 2216, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3595.7, \"learn_time_ms\": 14653.15}", "{\"n\": 2217, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3604.29, \"learn_time_ms\": 14655.276}", "{\"n\": 2218, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.21, \"learn_time_ms\": 14639.475}", "{\"n\": 2219, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.12, \"learn_time_ms\": 14644.661}", "{\"n\": 2220, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.12, \"learn_time_ms\": 14635.139}", "{\"n\": 2221, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3565.36, \"learn_time_ms\": 14645.442}", "{\"n\": 2222, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.94, \"learn_time_ms\": 14658.629}", "{\"n\": 2223, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.12, \"learn_time_ms\": 14655.094}", "{\"n\": 2224, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3571.74, \"learn_time_ms\": 14636.689}", "{\"n\": 2225, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.8, \"learn_time_ms\": 14624.554}", "{\"n\": 2226, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3556.07, \"learn_time_ms\": 14606.691}", "{\"n\": 2227, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3558.05, \"learn_time_ms\": 14600.6}", "{\"n\": 2228, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.77, \"learn_time_ms\": 14629.413}", "{\"n\": 2229, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.77, \"learn_time_ms\": 14638.684}", "{\"n\": 2230, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3565.73, \"learn_time_ms\": 14652.924}", "{\"n\": 2231, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.63, \"learn_time_ms\": 14649.344}", "{\"n\": 2232, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3568.34, \"learn_time_ms\": 14644.755}", "{\"n\": 2233, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3560.51, \"learn_time_ms\": 14644.148}", "{\"n\": 2234, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3555.68, \"learn_time_ms\": 14642.749}", "{\"n\": 2235, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3549.33, \"learn_time_ms\": 14663.082}", "{\"n\": 2236, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3545.84, \"learn_time_ms\": 14670.414}", "{\"n\": 2237, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3536.01, \"learn_time_ms\": 14675.508}", "{\"n\": 2238, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3562.29, \"learn_time_ms\": 14655.789}", "{\"n\": 2239, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3562.29, \"learn_time_ms\": 14644.695}", "{\"n\": 2240, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.98, \"learn_time_ms\": 14605.4}", "{\"n\": 2241, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3542.34, \"learn_time_ms\": 14585.043}", "{\"n\": 2242, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3543.2, \"learn_time_ms\": 14600.185}", "{\"n\": 2243, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3536.92, \"learn_time_ms\": 14609.759}", "{\"n\": 2244, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3541.08, \"learn_time_ms\": 14637.483}", "{\"n\": 2245, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3522.7, \"learn_time_ms\": 14634.96}", "{\"n\": 2246, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3519.2, \"learn_time_ms\": 14640.13}", "{\"n\": 2247, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3519.2, \"learn_time_ms\": 14644.865}", "{\"n\": 2248, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3526.28, \"learn_time_ms\": 14635.495}", "{\"n\": 2249, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3525.66, \"learn_time_ms\": 14607.975}", "{\"n\": 2250, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3526.56, \"learn_time_ms\": 14635.146}", "{\"n\": 2251, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3515.29, \"learn_time_ms\": 14653.018}", "{\"n\": 2252, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3511.12, \"learn_time_ms\": 14628.866}", "{\"n\": 2253, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3511.12, \"learn_time_ms\": 14598.974}", "{\"n\": 2254, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3515.95, \"learn_time_ms\": 14601.116}", "{\"n\": 2255, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3521.23, \"learn_time_ms\": 14606.444}", "{\"n\": 2256, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3512.08, \"learn_time_ms\": 14580.391}", "{\"n\": 2257, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3519.59, \"learn_time_ms\": 14552.994}", "{\"n\": 2258, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3519.59, \"learn_time_ms\": 14586.508}", "{\"n\": 2259, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3521.43, \"learn_time_ms\": 14611.909}", "{\"n\": 2260, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3515.75, \"learn_time_ms\": 14613.32}", "{\"n\": 2261, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3505.82, \"learn_time_ms\": 14594.658}", "{\"n\": 2262, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3504.3, \"learn_time_ms\": 14590.788}", "{\"n\": 2263, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3504.3, \"learn_time_ms\": 14622.52}", "{\"n\": 2264, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3504.3, \"learn_time_ms\": 14612.897}", "{\"n\": 2265, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3517.88, \"learn_time_ms\": 14591.057}", "{\"n\": 2266, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3519.62, \"learn_time_ms\": 14615.355}", "{\"n\": 2267, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3520.79, \"learn_time_ms\": 14626.813}", "{\"n\": 2268, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3514.7, \"learn_time_ms\": 14611.384}", "{\"n\": 2269, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3506.74, \"learn_time_ms\": 14606.468}", "{\"n\": 2270, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3514.65, \"learn_time_ms\": 14619.907}", "{\"n\": 2271, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3514.65, \"learn_time_ms\": 14605.828}", "{\"n\": 2272, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3498.88, \"learn_time_ms\": 14623.967}", "{\"n\": 2273, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3513.28, \"learn_time_ms\": 14591.257}", "{\"n\": 2274, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3513.28, \"learn_time_ms\": 14574.612}", "{\"n\": 2275, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3506.76, \"learn_time_ms\": 14591.739}", "{\"n\": 2276, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3524.75, \"learn_time_ms\": 14591.838}", "{\"n\": 2277, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3524.75, \"learn_time_ms\": 14598.047}", "{\"n\": 2278, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3535.29, \"learn_time_ms\": 14593.131}", "{\"n\": 2279, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3530.33, \"learn_time_ms\": 14608.05}", "{\"n\": 2280, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3527.91, \"learn_time_ms\": 14586.587}", "{\"n\": 2281, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3528.55, \"learn_time_ms\": 14623.885}", "{\"n\": 2282, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3528.55, \"learn_time_ms\": 14609.32}", "{\"n\": 2283, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3516.46, \"learn_time_ms\": 14637.653}", "{\"n\": 2284, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3528.02, \"learn_time_ms\": 14662.624}", "{\"n\": 2285, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3518.13, \"learn_time_ms\": 14638.549}", "{\"n\": 2286, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3530.87, \"learn_time_ms\": 14637.639}", "{\"n\": 2287, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3535.31, \"learn_time_ms\": 14640.26}", "{\"n\": 2288, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3558.1, \"learn_time_ms\": 14656.304}", "{\"n\": 2289, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3564.32, \"learn_time_ms\": 14665.907}", "{\"n\": 2290, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3551.09, \"learn_time_ms\": 14669.683}", "{\"n\": 2291, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3551.09, \"learn_time_ms\": 14648.369}", "{\"n\": 2292, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3544.83, \"learn_time_ms\": 14640.426}", "{\"n\": 2293, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3544.8, \"learn_time_ms\": 14632.05}", "{\"n\": 2294, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3560.34, \"learn_time_ms\": 14628.548}", "{\"n\": 2295, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3549.07, \"learn_time_ms\": 14631.366}", "{\"n\": 2296, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3549.07, \"learn_time_ms\": 14625.964}", "{\"n\": 2297, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3538.82, \"learn_time_ms\": 14631.342}", "{\"n\": 2298, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3534.6, \"learn_time_ms\": 14625.271}", "{\"n\": 2299, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3534.6, \"learn_time_ms\": 14616.33}", "{\"n\": 2300, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3546.43, \"learn_time_ms\": 14625.064}", "{\"n\": 2301, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3543.5, \"learn_time_ms\": 14631.449}", "{\"n\": 2302, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3543.5, \"learn_time_ms\": 14636.552}", "{\"n\": 2303, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3537.22, \"learn_time_ms\": 14635.003}", "{\"n\": 2304, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3537.22, \"learn_time_ms\": 14631.76}", "{\"n\": 2305, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3528.26, \"learn_time_ms\": 14649.174}", "{\"n\": 2306, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3535.54, \"learn_time_ms\": 14658.104}", "{\"n\": 2307, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3535.54, \"learn_time_ms\": 14655.644}", "{\"n\": 2308, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3543.8, \"learn_time_ms\": 14663.633}", "{\"n\": 2309, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3550.39, \"learn_time_ms\": 14673.775}", "{\"n\": 2310, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.5, \"learn_time_ms\": 14674.037}", "{\"n\": 2311, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.5, \"learn_time_ms\": 14677.403}", "{\"n\": 2312, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3532.38, \"learn_time_ms\": 14695.028}", "{\"n\": 2313, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3532.38, \"learn_time_ms\": 14706.913}", "{\"n\": 2314, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3547.03, \"learn_time_ms\": 14715.147}", "{\"n\": 2315, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3539.39, \"learn_time_ms\": 14726.286}", "{\"n\": 2316, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3539.39, \"learn_time_ms\": 14720.637}", "{\"n\": 2317, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3542.15, \"learn_time_ms\": 14705.476}", "{\"n\": 2318, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3545.96, \"learn_time_ms\": 14702.493}", "{\"n\": 2319, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3545.96, \"learn_time_ms\": 14683.469}", "{\"n\": 2320, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3530.07, \"learn_time_ms\": 14695.772}", "{\"n\": 2321, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3526.72, \"learn_time_ms\": 14704.42}", "{\"n\": 2322, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3526.72, \"learn_time_ms\": 14706.803}", "{\"n\": 2323, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3522.86, \"learn_time_ms\": 14701.835}", "{\"n\": 2324, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3522.86, \"learn_time_ms\": 14698.139}", "{\"n\": 2325, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3522.86, \"learn_time_ms\": 14683.797}", "{\"n\": 2326, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3521.07, \"learn_time_ms\": 14661.035}", "{\"n\": 2327, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3523.82, \"learn_time_ms\": 14682.859}", "{\"n\": 2328, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3523.82, \"learn_time_ms\": 14650.623}", "{\"n\": 2329, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3527.63, \"learn_time_ms\": 14670.915}", "{\"n\": 2330, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3524.26, \"learn_time_ms\": 14676.779}", "{\"n\": 2331, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3515.21, \"learn_time_ms\": 14671.961}", "{\"n\": 2332, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3515.21, \"learn_time_ms\": 14675.302}", "{\"n\": 2333, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3520.6, \"learn_time_ms\": 14684.248}", "{\"n\": 2334, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3532.89, \"learn_time_ms\": 14661.619}", "{\"n\": 2335, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3538.66, \"learn_time_ms\": 14658.15}", "{\"n\": 2336, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.14, \"learn_time_ms\": 14665.86}", "{\"n\": 2337, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.14, \"learn_time_ms\": 14643.658}", "{\"n\": 2338, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3532.41, \"learn_time_ms\": 14641.433}", "{\"n\": 2339, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3524.81, \"learn_time_ms\": 14611.134}", "{\"n\": 2340, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3512.38, \"learn_time_ms\": 14595.975}", "{\"n\": 2341, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3512.38, \"learn_time_ms\": 14553.614}", "{\"n\": 2342, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3505.98, \"learn_time_ms\": 14540.615}", "{\"n\": 2343, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3505.98, \"learn_time_ms\": 14523.454}", "{\"n\": 2344, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3501.44, \"learn_time_ms\": 14541.086}", "{\"n\": 2345, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3499.38, \"learn_time_ms\": 14550.507}", "{\"n\": 2346, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3499.38, \"learn_time_ms\": 14558.597}", "{\"n\": 2347, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3499.38, \"learn_time_ms\": 14579.14}", "{\"n\": 2348, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3497.18, \"learn_time_ms\": 14612.975}", "{\"n\": 2349, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.96, \"learn_time_ms\": 14637.868}", "{\"n\": 2350, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3477.97, \"learn_time_ms\": 14617.911}", "{\"n\": 2351, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3479.4, \"learn_time_ms\": 14666.722}", "{\"n\": 2352, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3471.77, \"learn_time_ms\": 14665.414}", "{\"n\": 2353, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3471.77, \"learn_time_ms\": 14648.543}", "{\"n\": 2354, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.69, \"learn_time_ms\": 14632.973}", "{\"n\": 2355, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.11, \"learn_time_ms\": 14628.994}", "{\"n\": 2356, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.73, \"learn_time_ms\": 14619.362}", "{\"n\": 2357, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.73, \"learn_time_ms\": 14624.142}", "{\"n\": 2358, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3457.24, \"learn_time_ms\": 14615.897}", "{\"n\": 2359, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3457.24, \"learn_time_ms\": 14605.39}", "{\"n\": 2360, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.57, \"learn_time_ms\": 14617.88}", "{\"n\": 2361, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.02, \"learn_time_ms\": 14604.408}", "{\"n\": 2362, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.02, \"learn_time_ms\": 14608.956}", "{\"n\": 2363, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.61, \"learn_time_ms\": 14633.03}", "{\"n\": 2364, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.7, \"learn_time_ms\": 14656.552}", "{\"n\": 2365, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.34, \"learn_time_ms\": 14648.503}", "{\"n\": 2366, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3463.07, \"learn_time_ms\": 14664.551}", "{\"n\": 2367, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.77, \"learn_time_ms\": 14668.753}", "{\"n\": 2368, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.28, \"learn_time_ms\": 14681.875}", "{\"n\": 2369, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3483.39, \"learn_time_ms\": 14668.914}", "{\"n\": 2370, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3492.24, \"learn_time_ms\": 14675.992}", "{\"n\": 2371, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3492.24, \"learn_time_ms\": 14661.482}", "{\"n\": 2372, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.8, \"learn_time_ms\": 14662.926}", "{\"n\": 2373, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3486.15, \"learn_time_ms\": 14649.99}", "{\"n\": 2374, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3493.34, \"learn_time_ms\": 14641.905}", "{\"n\": 2375, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3493.23, \"learn_time_ms\": 14662.532}", "{\"n\": 2376, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.97, \"learn_time_ms\": 14639.236}", "{\"n\": 2377, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.97, \"learn_time_ms\": 14628.474}", "{\"n\": 2378, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3492.9, \"learn_time_ms\": 14618.526}", "{\"n\": 2379, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3481.67, \"learn_time_ms\": 14628.252}", "{\"n\": 2380, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3481.95, \"learn_time_ms\": 14638.79}", "{\"n\": 2381, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3481.95, \"learn_time_ms\": 14652.38}", "{\"n\": 2382, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.18, \"learn_time_ms\": 14657.631}", "{\"n\": 2383, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3492.87, \"learn_time_ms\": 14642.792}", "{\"n\": 2384, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3497.07, \"learn_time_ms\": 14639.45}", "{\"n\": 2385, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3497.77, \"learn_time_ms\": 14626.109}", "{\"n\": 2386, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.05, \"learn_time_ms\": 14652.772}", "{\"n\": 2387, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.05, \"learn_time_ms\": 14658.282}", "{\"n\": 2388, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.05, \"learn_time_ms\": 14666.377}", "{\"n\": 2389, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3502.01, \"learn_time_ms\": 14685.147}", "{\"n\": 2390, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3518.02, \"learn_time_ms\": 14683.102}", "{\"n\": 2391, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3528.06, \"learn_time_ms\": 14673.322}", "{\"n\": 2392, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3538.12, \"learn_time_ms\": 14655.638}", "{\"n\": 2393, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3538.12, \"learn_time_ms\": 14680.102}", "{\"n\": 2394, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3541.48, \"learn_time_ms\": 14676.856}", "{\"n\": 2395, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3543.66, \"learn_time_ms\": 14675.735}", "{\"n\": 2396, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3530.31, \"learn_time_ms\": 14674.297}", "{\"n\": 2397, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3538.94, \"learn_time_ms\": 14684.078}", "{\"n\": 2398, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3537.4, \"learn_time_ms\": 14677.506}", "{\"n\": 2399, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3539.07, \"learn_time_ms\": 14660.354}", "{\"n\": 2400, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3532.16, \"learn_time_ms\": 14649.213}", "{\"n\": 2401, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3531.62, \"learn_time_ms\": 14654.328}", "{\"n\": 2402, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3520.85, \"learn_time_ms\": 14660.807}", "{\"n\": 2403, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3528.91, \"learn_time_ms\": 14661.998}", "{\"n\": 2404, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3531.75, \"learn_time_ms\": 14654.193}", "{\"n\": 2405, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3525.23, \"learn_time_ms\": 14662.39}", "{\"n\": 2406, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3524.66, \"learn_time_ms\": 14656.687}", "{\"n\": 2407, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3524.66, \"learn_time_ms\": 14632.016}", "{\"n\": 2408, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3517.44, \"learn_time_ms\": 14622.334}", "{\"n\": 2409, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3519.58, \"learn_time_ms\": 14632.773}", "{\"n\": 2410, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3519.58, \"learn_time_ms\": 14620.767}", "{\"n\": 2411, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3514.35, \"learn_time_ms\": 14631.28}", "{\"n\": 2412, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3517.19, \"learn_time_ms\": 14652.319}", "{\"n\": 2413, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3519.07, \"learn_time_ms\": 14647.165}", "{\"n\": 2414, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3529.47, \"learn_time_ms\": 14660.101}", "{\"n\": 2415, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3534.27, \"learn_time_ms\": 14656.842}", "{\"n\": 2416, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3539.74, \"learn_time_ms\": 14657.114}", "{\"n\": 2417, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3526.27, \"learn_time_ms\": 14665.135}", "{\"n\": 2418, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3515.04, \"learn_time_ms\": 14681.874}", "{\"n\": 2419, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3530.43, \"learn_time_ms\": 14670.542}", "{\"n\": 2420, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3526.08, \"learn_time_ms\": 14674.574}", "{\"n\": 2421, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3522.17, \"learn_time_ms\": 14655.644}", "{\"n\": 2422, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3502.55, \"learn_time_ms\": 14654.93}", "{\"n\": 2423, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3502.82, \"learn_time_ms\": 14676.276}", "{\"n\": 2424, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3502.82, \"learn_time_ms\": 14675.927}", "{\"n\": 2425, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3506.61, \"learn_time_ms\": 14678.439}", "{\"n\": 2426, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3506.61, \"learn_time_ms\": 14685.98}", "{\"n\": 2427, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3512.73, \"learn_time_ms\": 14646.401}", "{\"n\": 2428, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3515.7, \"learn_time_ms\": 14651.793}", "{\"n\": 2429, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3501.29, \"learn_time_ms\": 14639.754}", "{\"n\": 2430, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3493.65, \"learn_time_ms\": 14660.386}", "{\"n\": 2431, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3494.8, \"learn_time_ms\": 14672.902}", "{\"n\": 2432, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3494.8, \"learn_time_ms\": 14662.97}", "{\"n\": 2433, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3483.57, \"learn_time_ms\": 14624.437}", "{\"n\": 2434, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3486.53, \"learn_time_ms\": 14625.298}", "{\"n\": 2435, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3477.52, \"learn_time_ms\": 14626.088}", "{\"n\": 2436, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3480.24, \"learn_time_ms\": 14632.209}", "{\"n\": 2437, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3480.24, \"learn_time_ms\": 14665.521}", "{\"n\": 2438, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3471.28, \"learn_time_ms\": 14669.14}", "{\"n\": 2439, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3464.03, \"learn_time_ms\": 14688.81}", "{\"n\": 2440, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3453.5, \"learn_time_ms\": 14699.6}", "{\"n\": 2441, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3456.38, \"learn_time_ms\": 14717.535}", "{\"n\": 2442, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3453.32, \"learn_time_ms\": 14738.774}", "{\"n\": 2443, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3460.18, \"learn_time_ms\": 14765.407}", "{\"n\": 2444, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3460.18, \"learn_time_ms\": 14763.471}", "{\"n\": 2445, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3448.98, \"learn_time_ms\": 14764.811}", "{\"n\": 2446, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3459.0, \"learn_time_ms\": 14754.228}", "{\"n\": 2447, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3453.91, \"learn_time_ms\": 14764.605}", "{\"n\": 2448, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3446.59, \"learn_time_ms\": 14748.005}", "{\"n\": 2449, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3441.58, \"learn_time_ms\": 14742.75}", "{\"n\": 2450, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3441.58, \"learn_time_ms\": 14713.131}", "{\"n\": 2451, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3451.3, \"learn_time_ms\": 14687.325}", "{\"n\": 2452, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3440.53, \"learn_time_ms\": 14663.415}", "{\"n\": 2453, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3436.38, \"learn_time_ms\": 14648.931}", "{\"n\": 2454, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3437.73, \"learn_time_ms\": 14662.37}", "{\"n\": 2455, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3426.48, \"learn_time_ms\": 14659.809}", "{\"n\": 2456, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3426.48, \"learn_time_ms\": 14651.959}", "{\"n\": 2457, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3424.37, \"learn_time_ms\": 14639.506}", "{\"n\": 2458, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3401.03, \"learn_time_ms\": 14654.583}", "{\"n\": 2459, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3385.31, \"learn_time_ms\": 14646.226}", "{\"n\": 2460, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.06, \"learn_time_ms\": 14660.149}", "{\"n\": 2461, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.06, \"learn_time_ms\": 14671.136}", "{\"n\": 2462, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3362.93, \"learn_time_ms\": 14678.249}", "{\"n\": 2463, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3365.26, \"learn_time_ms\": 14685.34}", "{\"n\": 2464, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3346.59, \"learn_time_ms\": 14682.359}", "{\"n\": 2465, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3346.56, \"learn_time_ms\": 14668.072}", "{\"n\": 2466, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3339.06, \"learn_time_ms\": 14674.579}", "{\"n\": 2467, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3330.8, \"learn_time_ms\": 14646.19}", "{\"n\": 2468, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3321.37, \"learn_time_ms\": 14628.719}", "{\"n\": 2469, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3320.7, \"learn_time_ms\": 14647.084}", "{\"n\": 2470, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3336.91, \"learn_time_ms\": 14637.633}", "{\"n\": 2471, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3321.23, \"learn_time_ms\": 14633.815}", "{\"n\": 2472, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3321.23, \"learn_time_ms\": 14630.033}", "{\"n\": 2473, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3315.7, \"learn_time_ms\": 14624.98}", "{\"n\": 2474, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3315.7, \"learn_time_ms\": 14614.801}", "{\"n\": 2475, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3292.09, \"learn_time_ms\": 14628.148}", "{\"n\": 2476, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3292.09, \"learn_time_ms\": 14606.644}", "{\"n\": 2477, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3292.11, \"learn_time_ms\": 14624.694}", "{\"n\": 2478, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3292.11, \"learn_time_ms\": 14612.398}", "{\"n\": 2479, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3281.01, \"learn_time_ms\": 14605.3}", "{\"n\": 2480, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3277.59, \"learn_time_ms\": 14606.598}", "{\"n\": 2481, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3277.59, \"learn_time_ms\": 14593.96}", "{\"n\": 2482, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3281.87, \"learn_time_ms\": 14589.138}", "{\"n\": 2483, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3281.87, \"learn_time_ms\": 14619.214}", "{\"n\": 2484, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3266.39, \"learn_time_ms\": 14627.385}", "{\"n\": 2485, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3267.89, \"learn_time_ms\": 14620.893}", "{\"n\": 2486, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3279.27, \"learn_time_ms\": 14619.117}", "{\"n\": 2487, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3279.27, \"learn_time_ms\": 14641.416}", "{\"n\": 2488, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3283.78, \"learn_time_ms\": 14662.479}", "{\"n\": 2489, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3310.45, \"learn_time_ms\": 14659.768}", "{\"n\": 2490, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3316.68, \"learn_time_ms\": 14671.663}", "{\"n\": 2491, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3328.88, \"learn_time_ms\": 14689.801}", "{\"n\": 2492, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3328.88, \"learn_time_ms\": 14702.648}", "{\"n\": 2493, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3328.88, \"learn_time_ms\": 14667.502}", "{\"n\": 2494, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3328.88, \"learn_time_ms\": 14678.218}", "{\"n\": 2495, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3317.25, \"learn_time_ms\": 14697.209}", "{\"n\": 2496, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3322.85, \"learn_time_ms\": 14719.335}", "{\"n\": 2497, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3322.85, \"learn_time_ms\": 14701.418}", "{\"n\": 2498, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3322.85, \"learn_time_ms\": 14698.924}", "{\"n\": 2499, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3322.85, \"learn_time_ms\": 14697.877}", "{\"n\": 2500, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3331.07, \"learn_time_ms\": 14687.163}", "{\"n\": 2501, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3331.07, \"learn_time_ms\": 14677.384}", "{\"n\": 2502, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3355.11, \"learn_time_ms\": 14649.404}", "{\"n\": 2503, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3355.11, \"learn_time_ms\": 14671.664}", "{\"n\": 2504, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3355.11, \"learn_time_ms\": 14635.445}", "{\"n\": 2505, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3347.47, \"learn_time_ms\": 14627.327}", "{\"n\": 2506, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3342.7, \"learn_time_ms\": 14642.34}", "{\"n\": 2507, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3347.74, \"learn_time_ms\": 14657.249}", "{\"n\": 2508, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3347.74, \"learn_time_ms\": 14643.314}", "{\"n\": 2509, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3347.74, \"learn_time_ms\": 14648.933}", "{\"n\": 2510, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3348.03, \"learn_time_ms\": 14654.969}", "{\"n\": 2511, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3338.3, \"learn_time_ms\": 14671.695}", "{\"n\": 2512, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3353.96, \"learn_time_ms\": 14706.328}", "{\"n\": 2513, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3346.04, \"learn_time_ms\": 14695.926}", "{\"n\": 2514, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3346.04, \"learn_time_ms\": 14698.973}", "{\"n\": 2515, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3346.04, \"learn_time_ms\": 14688.239}", "{\"n\": 2516, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3338.1, \"learn_time_ms\": 14678.422}", "{\"n\": 2517, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3344.69, \"learn_time_ms\": 14676.999}", "{\"n\": 2518, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3339.63, \"learn_time_ms\": 14693.58}", "{\"n\": 2519, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3331.17, \"learn_time_ms\": 14697.679}", "{\"n\": 2520, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3331.17, \"learn_time_ms\": 14690.568}", "{\"n\": 2521, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3333.6, \"learn_time_ms\": 14684.231}", "{\"n\": 2522, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3333.6, \"learn_time_ms\": 14676.307}", "{\"n\": 2523, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3342.63, \"learn_time_ms\": 14683.546}", "{\"n\": 2524, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3339.51, \"learn_time_ms\": 14695.562}", "{\"n\": 2525, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3340.11, \"learn_time_ms\": 14695.496}", "{\"n\": 2526, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3351.02, \"learn_time_ms\": 14693.919}", "{\"n\": 2527, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3351.02, \"learn_time_ms\": 14688.488}", "{\"n\": 2528, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3344.97, \"learn_time_ms\": 14682.867}", "{\"n\": 2529, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3383.77, \"learn_time_ms\": 14683.813}", "{\"n\": 2530, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3383.77, \"learn_time_ms\": 14681.474}", "{\"n\": 2531, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3393.26, \"learn_time_ms\": 14690.032}", "{\"n\": 2532, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3419.11, \"learn_time_ms\": 14689.999}", "{\"n\": 2533, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3419.11, \"learn_time_ms\": 14696.006}", "{\"n\": 2534, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3410.78, \"learn_time_ms\": 14715.544}", "{\"n\": 2535, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3423.29, \"learn_time_ms\": 14721.242}", "{\"n\": 2536, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3432.54, \"learn_time_ms\": 14724.43}", "{\"n\": 2537, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3435.43, \"learn_time_ms\": 14734.196}", "{\"n\": 2538, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3435.43, \"learn_time_ms\": 14740.646}", "{\"n\": 2539, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3439.69, \"learn_time_ms\": 14733.824}", "{\"n\": 2540, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3450.31, \"learn_time_ms\": 14746.738}", "{\"n\": 2541, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3461.96, \"learn_time_ms\": 14735.758}", "{\"n\": 2542, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3456.35, \"learn_time_ms\": 14731.007}", "{\"n\": 2543, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3481.21, \"learn_time_ms\": 14728.059}", "{\"n\": 2544, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3481.21, \"learn_time_ms\": 14708.331}", "{\"n\": 2545, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3493.06, \"learn_time_ms\": 14706.231}", "{\"n\": 2546, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3496.68, \"learn_time_ms\": 14692.369}", "{\"n\": 2547, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3502.63, \"learn_time_ms\": 14696.029}", "{\"n\": 2548, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3510.21, \"learn_time_ms\": 14689.145}", "{\"n\": 2549, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3520.92, \"learn_time_ms\": 14697.497}", "{\"n\": 2550, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3490.96, \"learn_time_ms\": 14702.295}", "{\"n\": 2551, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3512.16, \"learn_time_ms\": 14704.805}", "{\"n\": 2552, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3512.16, \"learn_time_ms\": 14718.411}", "{\"n\": 2553, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3531.14, \"learn_time_ms\": 14729.073}", "{\"n\": 2554, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3531.43, \"learn_time_ms\": 14741.033}", "{\"n\": 2555, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3536.83, \"learn_time_ms\": 14737.831}", "{\"n\": 2556, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3541.82, \"learn_time_ms\": 14738.494}", "{\"n\": 2557, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3541.82, \"learn_time_ms\": 14730.639}", "{\"n\": 2558, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3545.18, \"learn_time_ms\": 14744.456}", "{\"n\": 2559, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3541.32, \"learn_time_ms\": 14727.655}", "{\"n\": 2560, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3524.05, \"learn_time_ms\": 14730.883}", "{\"n\": 2561, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3517.4, \"learn_time_ms\": 14727.108}", "{\"n\": 2562, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3516.0, \"learn_time_ms\": 14714.488}", "{\"n\": 2563, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3508.3, \"learn_time_ms\": 14690.378}", "{\"n\": 2564, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3502.82, \"learn_time_ms\": 14675.798}", "{\"n\": 2565, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3489.8, \"learn_time_ms\": 14683.031}", "{\"n\": 2566, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3489.8, \"learn_time_ms\": 14691.386}", "{\"n\": 2567, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3502.67, \"learn_time_ms\": 14697.236}", "{\"n\": 2568, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3500.8, \"learn_time_ms\": 14667.696}", "{\"n\": 2569, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3487.21, \"learn_time_ms\": 14669.965}", "{\"n\": 2570, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3495.73, \"learn_time_ms\": 14672.252}", "{\"n\": 2571, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3495.73, \"learn_time_ms\": 14668.482}", "{\"n\": 2572, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3504.98, \"learn_time_ms\": 14666.224}", "{\"n\": 2573, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3523.18, \"learn_time_ms\": 14670.485}", "{\"n\": 2574, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3495.2, \"learn_time_ms\": 14688.709}", "{\"n\": 2575, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3495.2, \"learn_time_ms\": 14683.773}", "{\"n\": 2576, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3504.17, \"learn_time_ms\": 14696.839}", "{\"n\": 2577, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3504.17, \"learn_time_ms\": 14690.005}", "{\"n\": 2578, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3498.45, \"learn_time_ms\": 14706.275}", "{\"n\": 2579, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3499.7, \"learn_time_ms\": 14690.438}", "{\"n\": 2580, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3499.7, \"learn_time_ms\": 14681.33}", "{\"n\": 2581, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3498.05, \"learn_time_ms\": 14699.577}", "{\"n\": 2582, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3490.71, \"learn_time_ms\": 14708.197}", "{\"n\": 2583, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3493.52, \"learn_time_ms\": 14712.743}", "{\"n\": 2584, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3487.29, \"learn_time_ms\": 14719.252}", "{\"n\": 2585, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3491.52, \"learn_time_ms\": 14722.059}", "{\"n\": 2586, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3491.52, \"learn_time_ms\": 14688.315}", "{\"n\": 2587, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3500.19, \"learn_time_ms\": 14698.111}", "{\"n\": 2588, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3501.55, \"learn_time_ms\": 14700.418}", "{\"n\": 2589, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3499.02, \"learn_time_ms\": 14702.088}", "{\"n\": 2590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3499.02, \"learn_time_ms\": 14694.134}", "{\"n\": 2591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3495.86, \"learn_time_ms\": 14681.508}", "{\"n\": 2592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3497.83, \"learn_time_ms\": 14680.78}", "{\"n\": 2593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3491.45, \"learn_time_ms\": 14676.118}", "{\"n\": 2594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3491.45, \"learn_time_ms\": 14677.069}", "{\"n\": 2595, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3474.39, \"learn_time_ms\": 14656.167}", "{\"n\": 2596, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3486.46, \"learn_time_ms\": 14653.548}", "{\"n\": 2597, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3476.52, \"learn_time_ms\": 14646.773}", "{\"n\": 2598, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3478.84, \"learn_time_ms\": 14652.918}", "{\"n\": 2599, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3476.16, \"learn_time_ms\": 14663.739}", "{\"n\": 2600, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3469.49, \"learn_time_ms\": 14691.966}", "{\"n\": 2601, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3469.49, \"learn_time_ms\": 14696.782}", "{\"n\": 2602, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3461.79, \"learn_time_ms\": 14695.103}", "{\"n\": 2603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3459.03, \"learn_time_ms\": 14685.863}", "{\"n\": 2604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3459.03, \"learn_time_ms\": 14679.644}", "{\"n\": 2605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3457.34, \"learn_time_ms\": 14710.794}", "{\"n\": 2606, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3472.37, \"learn_time_ms\": 14695.701}", "{\"n\": 2607, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3468.5, \"learn_time_ms\": 14700.955}", "{\"n\": 2608, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3471.06, \"learn_time_ms\": 14693.04}", "{\"n\": 2609, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3471.06, \"learn_time_ms\": 14710.954}", "{\"n\": 2610, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3467.77, \"learn_time_ms\": 14683.295}", "{\"n\": 2611, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3460.19, \"learn_time_ms\": 14659.822}", "{\"n\": 2612, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3461.31, \"learn_time_ms\": 14648.036}", "{\"n\": 2613, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3435.64, \"learn_time_ms\": 14664.283}", "{\"n\": 2614, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3423.62, \"learn_time_ms\": 14651.291}", "{\"n\": 2615, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3416.25, \"learn_time_ms\": 14636.343}", "{\"n\": 2616, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3398.9, \"learn_time_ms\": 14668.883}", "{\"n\": 2617, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3401.76, \"learn_time_ms\": 14648.451}", "{\"n\": 2618, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3409.05, \"learn_time_ms\": 14650.339}", "{\"n\": 2619, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3413.31, \"learn_time_ms\": 14629.115}", "{\"n\": 2620, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3422.64, \"learn_time_ms\": 14644.539}", "{\"n\": 2621, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3412.26, \"learn_time_ms\": 14668.809}", "{\"n\": 2622, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3395.97, \"learn_time_ms\": 14682.962}", "{\"n\": 2623, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3395.97, \"learn_time_ms\": 14690.856}", "{\"n\": 2624, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3386.39, \"learn_time_ms\": 14685.458}", "{\"n\": 2625, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3385.9, \"learn_time_ms\": 14688.105}", "{\"n\": 2626, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3375.84, \"learn_time_ms\": 14696.837}", "{\"n\": 2627, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3372.02, \"learn_time_ms\": 14712.121}", "{\"n\": 2628, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3372.02, \"learn_time_ms\": 14699.211}", "{\"n\": 2629, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3375.13, \"learn_time_ms\": 14714.405}", "{\"n\": 2630, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3375.13, \"learn_time_ms\": 14712.207}", "{\"n\": 2631, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3375.13, \"learn_time_ms\": 14711.465}", "{\"n\": 2632, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3408.22, \"learn_time_ms\": 14705.819}", "{\"n\": 2633, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3406.45, \"learn_time_ms\": 14693.093}", "{\"n\": 2634, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3406.45, \"learn_time_ms\": 14689.356}", "{\"n\": 2635, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3406.45, \"learn_time_ms\": 14693.494}", "{\"n\": 2636, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3403.44, \"learn_time_ms\": 14705.25}", "{\"n\": 2637, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3417.88, \"learn_time_ms\": 14717.244}", "{\"n\": 2638, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3430.95, \"learn_time_ms\": 14738.338}", "{\"n\": 2639, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3430.95, \"learn_time_ms\": 14742.052}", "{\"n\": 2640, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3432.83, \"learn_time_ms\": 14740.02}", "{\"n\": 2641, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3421.82, \"learn_time_ms\": 14734.28}", "{\"n\": 2642, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3416.76, \"learn_time_ms\": 14740.254}", "{\"n\": 2643, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3416.76, \"learn_time_ms\": 14744.184}", "{\"n\": 2644, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3410.78, \"learn_time_ms\": 14743.667}", "{\"n\": 2645, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3410.78, \"learn_time_ms\": 14746.095}", "{\"n\": 2646, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3419.6, \"learn_time_ms\": 14731.463}", "{\"n\": 2647, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3420.5, \"learn_time_ms\": 14703.811}", "{\"n\": 2648, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3405.65, \"learn_time_ms\": 14700.406}", "{\"n\": 2649, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3400.8, \"learn_time_ms\": 14703.901}", "{\"n\": 2650, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3400.8, \"learn_time_ms\": 14707.392}", "{\"n\": 2651, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3400.8, \"learn_time_ms\": 14722.98}", "{\"n\": 2652, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3407.67, \"learn_time_ms\": 14716.478}", "{\"n\": 2653, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3429.26, \"learn_time_ms\": 14723.489}", "{\"n\": 2654, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3431.7, \"learn_time_ms\": 14724.586}", "{\"n\": 2655, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3442.29, \"learn_time_ms\": 14724.214}", "{\"n\": 2656, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3442.29, \"learn_time_ms\": 14723.972}", "{\"n\": 2657, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3442.29, \"learn_time_ms\": 14730.118}", "{\"n\": 2658, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3448.21, \"learn_time_ms\": 14709.484}", "{\"n\": 2659, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3461.39, \"learn_time_ms\": 14690.968}", "{\"n\": 2660, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3460.86, \"learn_time_ms\": 14676.205}", "{\"n\": 2661, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3460.86, \"learn_time_ms\": 14667.749}", "{\"n\": 2662, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3461.18, \"learn_time_ms\": 14674.017}", "{\"n\": 2663, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3469.22, \"learn_time_ms\": 14671.323}", "{\"n\": 2664, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3478.15, \"learn_time_ms\": 14672.827}", "{\"n\": 2665, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3478.15, \"learn_time_ms\": 14672.238}", "{\"n\": 2666, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3479.61, \"learn_time_ms\": 14681.295}", "{\"n\": 2667, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3495.62, \"learn_time_ms\": 14706.617}", "{\"n\": 2668, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3501.24, \"learn_time_ms\": 14732.247}", "{\"n\": 2669, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3498.5, \"learn_time_ms\": 14756.842}", "{\"n\": 2670, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3486.49, \"learn_time_ms\": 14765.337}", "{\"n\": 2671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3494.32, \"learn_time_ms\": 14746.041}", "{\"n\": 2672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3494.32, \"learn_time_ms\": 14731.518}", "{\"n\": 2673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3489.32, \"learn_time_ms\": 14725.546}", "{\"n\": 2674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3481.75, \"learn_time_ms\": 14725.695}", "{\"n\": 2675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3481.75, \"learn_time_ms\": 14703.364}", "{\"n\": 2676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3487.84, \"learn_time_ms\": 14693.493}", "{\"n\": 2677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3487.84, \"learn_time_ms\": 14671.164}", "{\"n\": 2678, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3471.43, \"learn_time_ms\": 14659.939}", "{\"n\": 2679, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3453.85, \"learn_time_ms\": 14655.769}", "{\"n\": 2680, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3453.85, \"learn_time_ms\": 14661.056}", "{\"n\": 2681, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3457.11, \"learn_time_ms\": 14668.771}", "{\"n\": 2682, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3457.11, \"learn_time_ms\": 14677.623}", "{\"n\": 2683, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3466.22, \"learn_time_ms\": 14687.549}", "{\"n\": 2684, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3470.35, \"learn_time_ms\": 14711.171}", "{\"n\": 2685, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3475.25, \"learn_time_ms\": 14724.403}", "{\"n\": 2686, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3476.95, \"learn_time_ms\": 14732.349}", "{\"n\": 2687, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3476.95, \"learn_time_ms\": 14720.811}", "{\"n\": 2688, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3494.07, \"learn_time_ms\": 14713.475}", "{\"n\": 2689, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3484.49, \"learn_time_ms\": 14668.009}", "{\"n\": 2690, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3484.49, \"learn_time_ms\": 14667.556}", "{\"n\": 2691, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.24, \"learn_time_ms\": 14689.89}", "{\"n\": 2692, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3483.57, \"learn_time_ms\": 14693.255}", "{\"n\": 2693, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3474.29, \"learn_time_ms\": 14684.21}", "{\"n\": 2694, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3485.13, \"learn_time_ms\": 14652.674}", "{\"n\": 2695, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3485.13, \"learn_time_ms\": 14663.023}", "{\"n\": 2696, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3485.13, \"learn_time_ms\": 14668.247}", "{\"n\": 2697, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3494.95, \"learn_time_ms\": 14700.854}", "{\"n\": 2698, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3508.16, \"learn_time_ms\": 14710.072}", "{\"n\": 2699, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3493.95, \"learn_time_ms\": 14761.462}", "{\"n\": 2700, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.94, \"learn_time_ms\": 14757.029}", "{\"n\": 2701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.94, \"learn_time_ms\": 14739.582}", "{\"n\": 2702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.94, \"learn_time_ms\": 14736.559}", "{\"n\": 2703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3486.45, \"learn_time_ms\": 14738.257}", "{\"n\": 2704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3469.37, \"learn_time_ms\": 14759.059}", "{\"n\": 2705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3464.78, \"learn_time_ms\": 14754.006}", "{\"n\": 2706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3466.85, \"learn_time_ms\": 14742.691}", "{\"n\": 2707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3466.85, \"learn_time_ms\": 14734.779}", "{\"n\": 2708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3462.69, \"learn_time_ms\": 14742.38}", "{\"n\": 2709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3456.31, \"learn_time_ms\": 14735.07}", "{\"n\": 2710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3443.25, \"learn_time_ms\": 14727.65}", "{\"n\": 2711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3457.37, \"learn_time_ms\": 14723.893}", "{\"n\": 2712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3465.67, \"learn_time_ms\": 14735.337}", "{\"n\": 2713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3461.87, \"learn_time_ms\": 14741.794}", "{\"n\": 2714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3461.87, \"learn_time_ms\": 14763.264}", "{\"n\": 2715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3452.41, \"learn_time_ms\": 14769.637}", "{\"n\": 2716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3434.6, \"learn_time_ms\": 14779.692}", "{\"n\": 2717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.16, \"learn_time_ms\": 14765.293}", "{\"n\": 2718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.16, \"learn_time_ms\": 14745.855}", "{\"n\": 2719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3442.48, \"learn_time_ms\": 14739.634}", "{\"n\": 2720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3442.48, \"learn_time_ms\": 14749.268}", "{\"n\": 2721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3457.65, \"learn_time_ms\": 14736.794}", "{\"n\": 2722, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3450.84, \"learn_time_ms\": 14721.429}", "{\"n\": 2723, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3444.23, \"learn_time_ms\": 14697.504}", "{\"n\": 2724, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3454.29, \"learn_time_ms\": 14679.041}", "{\"n\": 2725, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3455.4, \"learn_time_ms\": 14678.847}", "{\"n\": 2726, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3455.4, \"learn_time_ms\": 14666.447}", "{\"n\": 2727, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3457.72, \"learn_time_ms\": 14669.462}", "{\"n\": 2728, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3459.21, \"learn_time_ms\": 14680.155}", "{\"n\": 2729, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3467.34, \"learn_time_ms\": 14672.16}", "{\"n\": 2730, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3461.03, \"learn_time_ms\": 14658.004}", "{\"n\": 2731, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3462.78, \"learn_time_ms\": 14680.009}", "{\"n\": 2732, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.61, \"learn_time_ms\": 14701.685}", "{\"n\": 2733, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.61, \"learn_time_ms\": 14718.872}", "{\"n\": 2734, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.61, \"learn_time_ms\": 14731.572}", "{\"n\": 2735, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.73, \"learn_time_ms\": 14729.427}", "{\"n\": 2736, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3451.58, \"learn_time_ms\": 14719.388}", "{\"n\": 2737, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3454.35, \"learn_time_ms\": 14737.115}", "{\"n\": 2738, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3454.35, \"learn_time_ms\": 14738.932}", "{\"n\": 2739, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3449.52, \"learn_time_ms\": 14721.443}", "{\"n\": 2740, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3444.49, \"learn_time_ms\": 14733.369}", "{\"n\": 2741, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3461.81, \"learn_time_ms\": 14732.607}", "{\"n\": 2742, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3459.19, \"learn_time_ms\": 14732.113}", "{\"n\": 2743, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3459.19, \"learn_time_ms\": 14743.117}", "{\"n\": 2744, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3455.72, \"learn_time_ms\": 14726.656}", "{\"n\": 2745, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3462.36, \"learn_time_ms\": 14700.746}", "{\"n\": 2746, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3472.13, \"learn_time_ms\": 14711.024}", "{\"n\": 2747, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3477.93, \"learn_time_ms\": 14704.527}", "{\"n\": 2748, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3477.93, \"learn_time_ms\": 14678.994}", "{\"n\": 2749, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3483.18, \"learn_time_ms\": 14668.265}", "{\"n\": 2750, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.97, \"learn_time_ms\": 14665.172}", "{\"n\": 2751, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3471.35, \"learn_time_ms\": 14660.276}", "{\"n\": 2752, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3471.35, \"learn_time_ms\": 14639.76}", "{\"n\": 2753, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.08, \"learn_time_ms\": 14631.241}", "{\"n\": 2754, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.41, \"learn_time_ms\": 14629.106}", "{\"n\": 2755, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.94, \"learn_time_ms\": 14670.882}", "{\"n\": 2756, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.13, \"learn_time_ms\": 14670.552}", "{\"n\": 2757, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.13, \"learn_time_ms\": 14661.45}", "{\"n\": 2758, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.19, \"learn_time_ms\": 14666.856}", "{\"n\": 2759, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3457.53, \"learn_time_ms\": 14689.505}", "{\"n\": 2760, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.17, \"learn_time_ms\": 14703.063}", "{\"n\": 2761, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.01, \"learn_time_ms\": 14717.231}", "{\"n\": 2762, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3446.01, \"learn_time_ms\": 14729.397}", "{\"n\": 2763, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.16, \"learn_time_ms\": 14714.127}", "{\"n\": 2764, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3441.76, \"learn_time_ms\": 14720.51}", "{\"n\": 2765, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.72, \"learn_time_ms\": 14703.626}", "{\"n\": 2766, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.72, \"learn_time_ms\": 14712.269}", "{\"n\": 2767, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.19, \"learn_time_ms\": 14718.013}", "{\"n\": 2768, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3450.31, \"learn_time_ms\": 14733.421}", "{\"n\": 2769, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.88, \"learn_time_ms\": 14729.963}", "{\"n\": 2770, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.27, \"learn_time_ms\": 14709.72}", "{\"n\": 2771, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.27, \"learn_time_ms\": 14696.33}", "{\"n\": 2772, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.86, \"learn_time_ms\": 14689.668}", "{\"n\": 2773, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.86, \"learn_time_ms\": 14693.751}", "{\"n\": 2774, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3472.8, \"learn_time_ms\": 14691.078}", "{\"n\": 2775, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3477.81, \"learn_time_ms\": 14690.836}", "{\"n\": 2776, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3477.01, \"learn_time_ms\": 14684.819}", "{\"n\": 2777, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3477.01, \"learn_time_ms\": 14684.146}", "{\"n\": 2778, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.69, \"learn_time_ms\": 14689.706}", "{\"n\": 2779, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.69, \"learn_time_ms\": 14703.135}", "{\"n\": 2780, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3461.7, \"learn_time_ms\": 14712.926}", "{\"n\": 2781, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.18, \"learn_time_ms\": 14710.4}", "{\"n\": 2782, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.26, \"learn_time_ms\": 14707.653}", "{\"n\": 2783, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3478.83, \"learn_time_ms\": 14705.934}", "{\"n\": 2784, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3478.83, \"learn_time_ms\": 14703.478}", "{\"n\": 2785, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3472.54, \"learn_time_ms\": 14710.242}", "{\"n\": 2786, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3487.92, \"learn_time_ms\": 14723.528}", "{\"n\": 2787, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.98, \"learn_time_ms\": 14715.832}", "{\"n\": 2788, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3489.44, \"learn_time_ms\": 14704.19}", "{\"n\": 2789, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3509.05, \"learn_time_ms\": 14716.871}", "{\"n\": 2790, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3503.42, \"learn_time_ms\": 14722.345}", "{\"n\": 2791, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3502.73, \"learn_time_ms\": 14734.485}", "{\"n\": 2792, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3512.35, \"learn_time_ms\": 14739.02}", "{\"n\": 2793, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3504.88, \"learn_time_ms\": 14756.837}", "{\"n\": 2794, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3531.8, \"learn_time_ms\": 14761.225}", "{\"n\": 2795, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3538.9, \"learn_time_ms\": 14756.399}", "{\"n\": 2796, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3538.9, \"learn_time_ms\": 14733.683}", "{\"n\": 2797, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3523.09, \"learn_time_ms\": 14731.038}", "{\"n\": 2798, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3522.47, \"learn_time_ms\": 14713.826}", "{\"n\": 2799, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3512.99, \"learn_time_ms\": 14707.819}", "{\"n\": 2800, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3500.44, \"learn_time_ms\": 14709.746}", "{\"n\": 2801, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3492.48, \"learn_time_ms\": 14698.85}", "{\"n\": 2802, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3492.48, \"learn_time_ms\": 14688.953}", "{\"n\": 2803, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3492.48, \"learn_time_ms\": 14690.503}", "{\"n\": 2804, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3494.58, \"learn_time_ms\": 14692.787}", "{\"n\": 2805, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3502.5, \"learn_time_ms\": 14704.04}", "{\"n\": 2806, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3491.89, \"learn_time_ms\": 14720.442}", "{\"n\": 2807, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3491.89, \"learn_time_ms\": 14734.049}", "{\"n\": 2808, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3491.89, \"learn_time_ms\": 14767.204}", "{\"n\": 2809, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3495.7, \"learn_time_ms\": 14772.714}", "{\"n\": 2810, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3489.22, \"learn_time_ms\": 14754.08}", "{\"n\": 2811, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3491.49, \"learn_time_ms\": 14758.607}", "{\"n\": 2812, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3472.53, \"learn_time_ms\": 14771.475}", "{\"n\": 2813, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3475.43, \"learn_time_ms\": 14779.88}", "{\"n\": 2814, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3463.15, \"learn_time_ms\": 14777.216}", "{\"n\": 2815, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3463.15, \"learn_time_ms\": 14760.655}", "{\"n\": 2816, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3461.87, \"learn_time_ms\": 14756.391}", "{\"n\": 2817, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3484.68, \"learn_time_ms\": 14757.257}", "{\"n\": 2818, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3481.59, \"learn_time_ms\": 14755.203}", "{\"n\": 2819, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3481.59, \"learn_time_ms\": 14713.275}", "{\"n\": 2820, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3480.86, \"learn_time_ms\": 14722.714}", "{\"n\": 2821, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3480.86, \"learn_time_ms\": 14718.31}", "{\"n\": 2822, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3466.82, \"learn_time_ms\": 14701.315}", "{\"n\": 2823, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3482.77, \"learn_time_ms\": 14668.509}", "{\"n\": 2824, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3482.77, \"learn_time_ms\": 14656.168}", "{\"n\": 2825, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3482.77, \"learn_time_ms\": 14662.478}", "{\"n\": 2826, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3482.77, \"learn_time_ms\": 14661.953}", "{\"n\": 2827, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3468.96, \"learn_time_ms\": 14659.746}", "{\"n\": 2828, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3478.85, \"learn_time_ms\": 14665.63}", "{\"n\": 2829, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3479.66, \"learn_time_ms\": 14685.83}", "{\"n\": 2830, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3479.66, \"learn_time_ms\": 14682.385}", "{\"n\": 2831, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3479.66, \"learn_time_ms\": 14702.942}", "{\"n\": 2832, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3459.93, \"learn_time_ms\": 14717.484}", "{\"n\": 2833, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3471.4, \"learn_time_ms\": 14736.833}", "{\"n\": 2834, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3471.4, \"learn_time_ms\": 14746.346}", "{\"n\": 2835, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3490.52, \"learn_time_ms\": 14757.521}", "{\"n\": 2836, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3501.66, \"learn_time_ms\": 14737.516}", "{\"n\": 2837, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3508.07, \"learn_time_ms\": 14736.714}", "{\"n\": 2838, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3508.07, \"learn_time_ms\": 14715.788}", "{\"n\": 2839, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3508.07, \"learn_time_ms\": 14725.96}", "{\"n\": 2840, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3512.58, \"learn_time_ms\": 14743.114}", "{\"n\": 2841, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3529.62, \"learn_time_ms\": 14726.643}", "{\"n\": 2842, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3524.65, \"learn_time_ms\": 14725.612}", "{\"n\": 2843, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3524.65, \"learn_time_ms\": 14729.889}", "{\"n\": 2844, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3525.2, \"learn_time_ms\": 14731.141}", "{\"n\": 2845, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3525.2, \"learn_time_ms\": 14714.824}", "{\"n\": 2846, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3528.52, \"learn_time_ms\": 14711.063}", "{\"n\": 2847, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3535.16, \"learn_time_ms\": 14706.644}", "{\"n\": 2848, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3535.16, \"learn_time_ms\": 14721.736}", "{\"n\": 2849, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3535.16, \"learn_time_ms\": 14714.504}", "{\"n\": 2850, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3535.16, \"learn_time_ms\": 14681.141}", "{\"n\": 2851, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3547.27, \"learn_time_ms\": 14687.165}", "{\"n\": 2852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3530.17, \"learn_time_ms\": 14689.879}", "{\"n\": 2853, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3528.88, \"learn_time_ms\": 14667.891}", "{\"n\": 2854, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3524.1, \"learn_time_ms\": 14685.429}", "{\"n\": 2855, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3524.1, \"learn_time_ms\": 14665.792}", "{\"n\": 2856, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3524.1, \"learn_time_ms\": 14704.021}", "{\"n\": 2857, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3527.25, \"learn_time_ms\": 14710.797}", "{\"n\": 2858, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3538.56, \"learn_time_ms\": 14708.327}", "{\"n\": 2859, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3542.37, \"learn_time_ms\": 14704.4}", "{\"n\": 2860, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3542.37, \"learn_time_ms\": 14706.458}", "{\"n\": 2861, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3542.37, \"learn_time_ms\": 14690.05}", "{\"n\": 2862, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3529.87, \"learn_time_ms\": 14688.843}", "{\"n\": 2863, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3529.87, \"learn_time_ms\": 14704.328}", "{\"n\": 2864, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3525.71, \"learn_time_ms\": 14695.95}", "{\"n\": 2865, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3537.06, \"learn_time_ms\": 14719.507}", "{\"n\": 2866, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3534.83, \"learn_time_ms\": 14709.415}", "{\"n\": 2867, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3534.83, \"learn_time_ms\": 14709.234}", "{\"n\": 2868, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3522.43, \"learn_time_ms\": 14709.922}", "{\"n\": 2869, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3522.43, \"learn_time_ms\": 14730.262}", "{\"n\": 2870, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3535.13, \"learn_time_ms\": 14745.114}", "{\"n\": 2871, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3556.35, \"learn_time_ms\": 14755.568}", "{\"n\": 2872, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3567.13, \"learn_time_ms\": 14752.534}", "{\"n\": 2873, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3567.13, \"learn_time_ms\": 14751.108}", "{\"n\": 2874, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3560.98, \"learn_time_ms\": 14719.105}", "{\"n\": 2875, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3560.98, \"learn_time_ms\": 14714.736}", "{\"n\": 2876, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3560.98, \"learn_time_ms\": 14710.935}", "{\"n\": 2877, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3553.78, \"learn_time_ms\": 14713.699}", "{\"n\": 2878, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3562.78, \"learn_time_ms\": 14689.067}", "{\"n\": 2879, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3562.78, \"learn_time_ms\": 14668.022}", "{\"n\": 2880, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3557.82, \"learn_time_ms\": 14687.088}", "{\"n\": 2881, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3557.82, \"learn_time_ms\": 14698.634}", "{\"n\": 2882, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3555.64, \"learn_time_ms\": 14697.617}", "{\"n\": 2883, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3562.35, \"learn_time_ms\": 14697.424}", "{\"n\": 2884, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3562.35, \"learn_time_ms\": 14716.103}", "{\"n\": 2885, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3557.25, \"learn_time_ms\": 14716.653}", "{\"n\": 2886, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3580.78, \"learn_time_ms\": 14734.219}", "{\"n\": 2887, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3578.82, \"learn_time_ms\": 14721.614}", "{\"n\": 2888, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3579.03, \"learn_time_ms\": 14734.756}", "{\"n\": 2889, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3582.7, \"learn_time_ms\": 14764.143}", "{\"n\": 2890, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3593.46, \"learn_time_ms\": 14728.49}", "{\"n\": 2891, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3593.46, \"learn_time_ms\": 14698.068}", "{\"n\": 2892, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3596.82, \"learn_time_ms\": 14696.908}", "{\"n\": 2893, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3573.41, \"learn_time_ms\": 14701.217}", "{\"n\": 2894, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3573.41, \"learn_time_ms\": 14709.605}", "{\"n\": 2895, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3575.28, \"learn_time_ms\": 14718.246}", "{\"n\": 2896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3581.93, \"learn_time_ms\": 14700.672}", "{\"n\": 2897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3581.93, \"learn_time_ms\": 14693.352}", "{\"n\": 2898, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3585.96, \"learn_time_ms\": 14704.52}", "{\"n\": 2899, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3604.27, \"learn_time_ms\": 14694.958}", "{\"n\": 2900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3615.32, \"learn_time_ms\": 14718.362}", "{\"n\": 2901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3626.51, \"learn_time_ms\": 14740.428}", "{\"n\": 2902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3612.0, \"learn_time_ms\": 14740.826}", "{\"n\": 2903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3613.63, \"learn_time_ms\": 14736.973}", "{\"n\": 2904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3613.43, \"learn_time_ms\": 14731.218}", "{\"n\": 2905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3612.4, \"learn_time_ms\": 14716.66}", "{\"n\": 2906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3612.49, \"learn_time_ms\": 14706.051}", "{\"n\": 2907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3612.49, \"learn_time_ms\": 14717.695}", "{\"n\": 2908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3610.0, \"learn_time_ms\": 14718.549}", "{\"n\": 2909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3614.22, \"learn_time_ms\": 14711.398}", "{\"n\": 2910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3591.65, \"learn_time_ms\": 14702.547}", "{\"n\": 2911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3591.65, \"learn_time_ms\": 14716.119}", "{\"n\": 2912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3592.52, \"learn_time_ms\": 14718.981}", "{\"n\": 2913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3592.52, \"learn_time_ms\": 14732.44}", "{\"n\": 2914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3593.59, \"learn_time_ms\": 14734.869}", "{\"n\": 2915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3576.07, \"learn_time_ms\": 14742.79}", "{\"n\": 2916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3569.85, \"learn_time_ms\": 14760.801}", "{\"n\": 2917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3577.92, \"learn_time_ms\": 14762.625}", "{\"n\": 2918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3580.88, \"learn_time_ms\": 14760.816}", "{\"n\": 2919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3580.88, \"learn_time_ms\": 14759.287}", "{\"n\": 2920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3575.16, \"learn_time_ms\": 14767.528}", "{\"n\": 2921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3560.84, \"learn_time_ms\": 14752.453}", "{\"n\": 2922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3550.89, \"learn_time_ms\": 14742.329}", "{\"n\": 2923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3557.59, \"learn_time_ms\": 14725.073}", "{\"n\": 2924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3557.59, \"learn_time_ms\": 14686.739}", "{\"n\": 2925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3557.59, \"learn_time_ms\": 14695.175}", "{\"n\": 2926, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3581.27, \"learn_time_ms\": 14700.388}", "{\"n\": 2927, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3581.27, \"learn_time_ms\": 14697.618}", "{\"n\": 2928, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3585.35, \"learn_time_ms\": 14703.375}", "{\"n\": 2929, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3581.13, \"learn_time_ms\": 14697.052}", "{\"n\": 2930, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3576.3, \"learn_time_ms\": 14687.728}", "{\"n\": 2931, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3563.46, \"learn_time_ms\": 14679.917}", "{\"n\": 2932, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3573.5, \"learn_time_ms\": 14653.363}", "{\"n\": 2933, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3570.06, \"learn_time_ms\": 14637.858}", "{\"n\": 2934, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3579.53, \"learn_time_ms\": 14683.93}", "{\"n\": 2935, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.51, \"learn_time_ms\": 14683.546}", "{\"n\": 2936, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3568.07, \"learn_time_ms\": 14668.509}", "{\"n\": 2937, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3568.07, \"learn_time_ms\": 14671.66}", "{\"n\": 2938, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3568.07, \"learn_time_ms\": 14668.147}", "{\"n\": 2939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3567.21, \"learn_time_ms\": 14663.531}", "{\"n\": 2940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3571.34, \"learn_time_ms\": 14658.922}", "{\"n\": 2941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3571.34, \"learn_time_ms\": 14661.164}", "{\"n\": 2942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3552.5, \"learn_time_ms\": 14686.173}", "{\"n\": 2943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3552.5, \"learn_time_ms\": 14709.295}", "{\"n\": 2944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3547.95, \"learn_time_ms\": 14661.073}", "{\"n\": 2945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3525.92, \"learn_time_ms\": 14663.55}", "{\"n\": 2946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3537.45, \"learn_time_ms\": 14648.477}", "{\"n\": 2947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3538.44, \"learn_time_ms\": 14653.126}", "{\"n\": 2948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3542.16, \"learn_time_ms\": 14671.238}", "{\"n\": 2949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3530.86, \"learn_time_ms\": 14684.351}", "{\"n\": 2950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3526.31, \"learn_time_ms\": 14693.454}", "{\"n\": 2951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3516.76, \"learn_time_ms\": 14713.033}", "{\"n\": 2952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3525.63, \"learn_time_ms\": 14694.373}", "{\"n\": 2953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3522.48, \"learn_time_ms\": 14687.22}", "{\"n\": 2954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3519.63, \"learn_time_ms\": 14733.889}", "{\"n\": 2955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3523.39, \"learn_time_ms\": 14728.775}", "{\"n\": 2956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3513.31, \"learn_time_ms\": 14751.147}", "{\"n\": 2957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3505.95, \"learn_time_ms\": 14740.671}", "{\"n\": 2958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3504.79, \"learn_time_ms\": 14678.368}", "{\"n\": 2959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3504.79, \"learn_time_ms\": 14680.715}", "{\"n\": 2960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3511.79, \"learn_time_ms\": 14693.931}", "{\"n\": 2961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3497.2, \"learn_time_ms\": 14673.515}", "{\"n\": 2962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3497.2, \"learn_time_ms\": 14701.353}", "{\"n\": 2963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3470.27, \"learn_time_ms\": 14708.925}", "{\"n\": 2964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3467.35, \"learn_time_ms\": 14682.493}", "{\"n\": 2965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3467.35, \"learn_time_ms\": 14652.653}", "{\"n\": 2966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3463.5, \"learn_time_ms\": 14626.948}", "{\"n\": 2967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3464.8, \"learn_time_ms\": 14613.594}", "{\"n\": 2968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3460.24, \"learn_time_ms\": 14648.625}", "{\"n\": 2969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3461.09, \"learn_time_ms\": 14650.618}", "{\"n\": 2970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3444.56, \"learn_time_ms\": 14633.29}", "{\"n\": 2971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3451.58, \"learn_time_ms\": 14638.068}", "{\"n\": 2972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3451.58, \"learn_time_ms\": 14642.705}", "{\"n\": 2973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3443.86, \"learn_time_ms\": 14655.698}", "{\"n\": 2974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3467.25, \"learn_time_ms\": 14691.528}", "{\"n\": 2975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3467.25, \"learn_time_ms\": 14723.18}", "{\"n\": 2976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3463.35, \"learn_time_ms\": 14751.044}", "{\"n\": 2977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3463.35, \"learn_time_ms\": 14761.72}", "{\"n\": 2978, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3463.35, \"learn_time_ms\": 14774.707}", "{\"n\": 2979, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3471.75, \"learn_time_ms\": 14763.469}", "{\"n\": 2980, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3471.75, \"learn_time_ms\": 14770.107}", "{\"n\": 2981, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3479.8, \"learn_time_ms\": 14773.015}", "{\"n\": 2982, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3453.61, \"learn_time_ms\": 14760.021}", "{\"n\": 2983, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3453.61, \"learn_time_ms\": 14735.302}", "{\"n\": 2984, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3453.61, \"learn_time_ms\": 14728.744}", "{\"n\": 2985, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3453.61, \"learn_time_ms\": 14727.245}", "{\"n\": 2986, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3461.41, \"learn_time_ms\": 14722.125}", "{\"n\": 2987, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3463.62, \"learn_time_ms\": 14730.072}", "{\"n\": 2988, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3470.92, \"learn_time_ms\": 14725.503}", "{\"n\": 2989, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3459.6, \"learn_time_ms\": 14708.601}", "{\"n\": 2990, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3459.6, \"learn_time_ms\": 14709.95}", "{\"n\": 2991, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3459.6, \"learn_time_ms\": 14709.2}", "{\"n\": 2992, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3463.12, \"learn_time_ms\": 14726.956}", "{\"n\": 2993, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3477.51, \"learn_time_ms\": 14736.504}", "{\"n\": 2994, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3477.51, \"learn_time_ms\": 14716.711}", "{\"n\": 2995, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3489.43, \"learn_time_ms\": 14722.528}", "{\"n\": 2996, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3493.33, \"learn_time_ms\": 14725.662}", "{\"n\": 2997, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3493.33, \"learn_time_ms\": 14703.068}", "{\"n\": 2998, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3486.94, \"learn_time_ms\": 14717.492}", "{\"n\": 2999, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3481.49, \"learn_time_ms\": 14728.323}", "{\"n\": 3000, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3481.49, \"learn_time_ms\": 14723.691}"]["{\"n\": 3001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15422.752}", "{\"n\": 3002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15085.936}", "{\"n\": 3003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14967.693}", "{\"n\": 3004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14931.421}", "{\"n\": 3005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14894.613}", "{\"n\": 3006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14894.476}", "{\"n\": 3007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14897.692}", "{\"n\": 3008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14904.806}", "{\"n\": 3009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14901.627}", "{\"n\": 3010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14900.575}", "{\"n\": 3011, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -8.0, \"episode_len_mean\": 3243.0, \"learn_time_ms\": 14853.145}", "{\"n\": 3012, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.666666666666667, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3598.6666666666665, \"learn_time_ms\": 14868.999}", "{\"n\": 3013, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3678.6666666666665, \"learn_time_ms\": 14883.643}", "{\"n\": 3014, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.625, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3728.875, \"learn_time_ms\": 14888.827}", "{\"n\": 3015, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.625, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3728.875, \"learn_time_ms\": 14899.609}", "{\"n\": 3016, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.625, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3728.875, \"learn_time_ms\": 14911.233}", "{\"n\": 3017, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3649.6, \"learn_time_ms\": 14910.095}", "{\"n\": 3018, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -5.916666666666667, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3677.1666666666665, \"learn_time_ms\": 14905.602}", "{\"n\": 3019, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -6.153846153846154, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3647.3076923076924, \"learn_time_ms\": 14901.41}", "{\"n\": 3020, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.928571428571429, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3706.714285714286, \"learn_time_ms\": 14902.244}", "{\"n\": 3021, \"episode_reward_min\": -9.0, \"episode_reward_mean\": -5.866666666666666, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3746.266666666667, \"learn_time_ms\": 14901.663}", "{\"n\": 3022, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.117647058823529, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3717.235294117647, \"learn_time_ms\": 14904.058}", "{\"n\": 3023, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.421052631578948, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3657.315789473684, \"learn_time_ms\": 14909.8}", "{\"n\": 3024, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3624.2, \"learn_time_ms\": 14911.437}", "{\"n\": 3025, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3624.2, \"learn_time_ms\": 14917.438}", "{\"n\": 3026, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3648.409090909091, \"learn_time_ms\": 14902.982}", "{\"n\": 3027, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.260869565217392, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3680.6521739130435, \"learn_time_ms\": 14907.6}", "{\"n\": 3028, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.916666666666667, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3736.5833333333335, \"learn_time_ms\": 14896.769}", "{\"n\": 3029, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.222222222222222, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3681.925925925926, \"learn_time_ms\": 14903.686}", "{\"n\": 3030, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0344827586206895, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3676.2758620689656, \"learn_time_ms\": 14901.519}", "{\"n\": 3031, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.033333333333333, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3672.1, \"learn_time_ms\": 14892.051}", "{\"n\": 3032, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.935483870967742, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3682.064516129032, \"learn_time_ms\": 14881.571}", "{\"n\": 3033, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.03125, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3673.03125, \"learn_time_ms\": 14885.697}", "{\"n\": 3034, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.121212121212121, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3663.3939393939395, \"learn_time_ms\": 14885.51}", "{\"n\": 3035, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.857142857142857, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3698.8285714285716, \"learn_time_ms\": 14881.53}", "{\"n\": 3036, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.054054054054054, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3674.108108108108, \"learn_time_ms\": 14901.34}", "{\"n\": 3037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.2631578947368425, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3642.2894736842104, \"learn_time_ms\": 14897.473}", "{\"n\": 3038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.384615384615385, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3626.769230769231, \"learn_time_ms\": 14906.629}", "{\"n\": 3039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3610.025, \"learn_time_ms\": 14904.786}", "{\"n\": 3040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.666666666666667, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3587.0476190476193, \"learn_time_ms\": 14900.778}", "{\"n\": 3041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72093023255814, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.0697674418607, \"learn_time_ms\": 14906.016}", "{\"n\": 3042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.733333333333333, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3582.8888888888887, \"learn_time_ms\": 14909.504}", "{\"n\": 3043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.782608695652174, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.8478260869565, \"learn_time_ms\": 14898.837}", "{\"n\": 3044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.808510638297872, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3583.659574468085, \"learn_time_ms\": 14892.715}", "{\"n\": 3045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.808510638297872, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3583.659574468085, \"learn_time_ms\": 14902.775}", "{\"n\": 3046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3594.0416666666665, \"learn_time_ms\": 14884.581}", "{\"n\": 3047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3594.0416666666665, \"learn_time_ms\": 14896.131}", "{\"n\": 3048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.867924528301887, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3585.811320754717, \"learn_time_ms\": 14909.412}", "{\"n\": 3049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.944444444444445, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3584.296296296296, \"learn_time_ms\": 14910.673}", "{\"n\": 3050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.944444444444445, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3584.296296296296, \"learn_time_ms\": 14905.297}", "{\"n\": 3051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.909090909090909, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3588.1454545454544, \"learn_time_ms\": 14905.06}", "{\"n\": 3052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.909090909090909, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3588.1454545454544, \"learn_time_ms\": 14914.307}", "{\"n\": 3053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.909090909090909, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3588.1454545454544, \"learn_time_ms\": 14919.472}", "{\"n\": 3054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3620.6666666666665, \"learn_time_ms\": 14918.721}", "{\"n\": 3055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.645161290322581, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3647.064516129032, \"learn_time_ms\": 14911.338}", "{\"n\": 3056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.645161290322581, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3647.064516129032, \"learn_time_ms\": 14910.492}", "{\"n\": 3057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.603174603174603, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3649.9841269841268, \"learn_time_ms\": 14891.01}", "{\"n\": 3058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.603174603174603, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3649.9841269841268, \"learn_time_ms\": 14868.444}", "{\"n\": 3059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.603174603174603, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3649.9841269841268, \"learn_time_ms\": 14856.947}", "{\"n\": 3060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.647058823529412, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3646.3970588235293, \"learn_time_ms\": 14875.069}", "{\"n\": 3061, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.608695652173913, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3654.478260869565, \"learn_time_ms\": 14877.319}", "{\"n\": 3062, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.557142857142857, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3663.8285714285716, \"learn_time_ms\": 14868.16}", "{\"n\": 3063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.557142857142857, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3663.8285714285716, \"learn_time_ms\": 14862.584}", "{\"n\": 3064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.557142857142857, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3663.8285714285716, \"learn_time_ms\": 14865.799}", "{\"n\": 3065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.569444444444445, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3666.777777777778, \"learn_time_ms\": 14853.576}", "{\"n\": 3066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.613333333333333, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3665.1066666666666, \"learn_time_ms\": 14854.386}", "{\"n\": 3067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.532467532467533, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3669.220779220779, \"learn_time_ms\": 14866.357}", "{\"n\": 3068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.532467532467533, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3669.220779220779, \"learn_time_ms\": 14878.377}", "{\"n\": 3069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4743589743589745, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3677.371794871795, \"learn_time_ms\": 14904.549}", "{\"n\": 3070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4743589743589745, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3677.371794871795, \"learn_time_ms\": 14887.575}", "{\"n\": 3071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.419753086419753, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3687.4814814814813, \"learn_time_ms\": 14900.233}", "{\"n\": 3072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.433734939759036, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3686.0722891566265, \"learn_time_ms\": 14913.032}", "{\"n\": 3073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.440476190476191, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3687.345238095238, \"learn_time_ms\": 14918.078}", "{\"n\": 3074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.440476190476191, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3687.345238095238, \"learn_time_ms\": 14929.853}", "{\"n\": 3075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.411764705882353, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3689.3882352941177, \"learn_time_ms\": 14953.006}", "{\"n\": 3076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.383720930232558, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3698.4186046511627, \"learn_time_ms\": 14962.294}", "{\"n\": 3077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.425287356321839, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3690.0919540229884, \"learn_time_ms\": 14956.421}", "{\"n\": 3078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3977272727272725, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3690.4204545454545, \"learn_time_ms\": 14967.429}", "{\"n\": 3079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.489130434782608, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3686.521739130435, \"learn_time_ms\": 14962.987}", "{\"n\": 3080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.489130434782608, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3686.521739130435, \"learn_time_ms\": 14980.928}", "{\"n\": 3081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43010752688172, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3700.1182795698924, \"learn_time_ms\": 14962.447}", "{\"n\": 3082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4361702127659575, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3700.2021276595747, \"learn_time_ms\": 14951.643}", "{\"n\": 3083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.473684210526316, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3695.5789473684213, \"learn_time_ms\": 14943.937}", "{\"n\": 3084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.525773195876289, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3692.59793814433, \"learn_time_ms\": 14934.345}", "{\"n\": 3085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.525773195876289, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3692.59793814433, \"learn_time_ms\": 14909.74}", "{\"n\": 3086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.444444444444445, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3706.5555555555557, \"learn_time_ms\": 14906.531}", "{\"n\": 3087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3704.7, \"learn_time_ms\": 14906.589}", "{\"n\": 3088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3721.96, \"learn_time_ms\": 14900.764}", "{\"n\": 3089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3721.96, \"learn_time_ms\": 14897.49}", "{\"n\": 3090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3724.25, \"learn_time_ms\": 14881.856}", "{\"n\": 3091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3727.59, \"learn_time_ms\": 14889.66}", "{\"n\": 3092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3732.66, \"learn_time_ms\": 14887.192}", "{\"n\": 3093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3742.06, \"learn_time_ms\": 14894.03}", "{\"n\": 3094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3748.04, \"learn_time_ms\": 14898.036}", "{\"n\": 3095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3749.23, \"learn_time_ms\": 14910.028}", "{\"n\": 3096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3749.23, \"learn_time_ms\": 14901.569}", "{\"n\": 3097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3739.02, \"learn_time_ms\": 14895.327}", "{\"n\": 3098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3739.48, \"learn_time_ms\": 14890.794}", "{\"n\": 3099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3733.92, \"learn_time_ms\": 14886.236}", "{\"n\": 3100, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3755.23, \"learn_time_ms\": 14892.638}", "{\"n\": 3101, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3755.23, \"learn_time_ms\": 14894.492}", "{\"n\": 3102, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3755.4, \"learn_time_ms\": 14901.448}", "{\"n\": 3103, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3754.85, \"learn_time_ms\": 14897.478}", "{\"n\": 3104, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3760.78, \"learn_time_ms\": 14892.284}", "{\"n\": 3105, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3746.92, \"learn_time_ms\": 14890.701}", "{\"n\": 3106, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.25, \"learn_time_ms\": 14878.976}", "{\"n\": 3107, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.25, \"learn_time_ms\": 14888.803}", "{\"n\": 3108, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3760.18, \"learn_time_ms\": 14882.692}", "{\"n\": 3109, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3743.98, \"learn_time_ms\": 14885.855}", "{\"n\": 3110, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3743.98, \"learn_time_ms\": 14891.175}", "{\"n\": 3111, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3752.34, \"learn_time_ms\": 14883.618}", "{\"n\": 3112, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3768.13, \"learn_time_ms\": 14885.959}", "{\"n\": 3113, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.41, \"learn_time_ms\": 14883.369}", "{\"n\": 3114, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.75, \"learn_time_ms\": 14881.397}", "{\"n\": 3115, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.75, \"learn_time_ms\": 14880.13}", "{\"n\": 3116, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3785.4, \"learn_time_ms\": 14886.871}", "{\"n\": 3117, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3785.4, \"learn_time_ms\": 14883.872}", "{\"n\": 3118, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3805.72, \"learn_time_ms\": 14891.101}", "{\"n\": 3119, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3831.75, \"learn_time_ms\": 14887.854}", "{\"n\": 3120, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3827.08, \"learn_time_ms\": 14871.849}", "{\"n\": 3121, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3827.08, \"learn_time_ms\": 14865.912}", "{\"n\": 3122, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3821.71, \"learn_time_ms\": 14858.097}", "{\"n\": 3123, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3817.62, \"learn_time_ms\": 14869.906}", "{\"n\": 3124, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3819.91, \"learn_time_ms\": 14875.821}", "{\"n\": 3125, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3838.67, \"learn_time_ms\": 14877.234}", "{\"n\": 3126, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3832.85, \"learn_time_ms\": 14896.281}", "{\"n\": 3127, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3832.85, \"learn_time_ms\": 14897.315}", "{\"n\": 3128, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3840.25, \"learn_time_ms\": 14897.254}", "{\"n\": 3129, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3840.25, \"learn_time_ms\": 14901.79}", "{\"n\": 3130, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3820.33, \"learn_time_ms\": 14915.455}", "{\"n\": 3131, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3805.21, \"learn_time_ms\": 14932.435}", "{\"n\": 3132, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3805.21, \"learn_time_ms\": 14931.669}", "{\"n\": 3133, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3805.21, \"learn_time_ms\": 14924.467}", "{\"n\": 3134, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3815.82, \"learn_time_ms\": 14907.083}", "{\"n\": 3135, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3800.74, \"learn_time_ms\": 14916.801}", "{\"n\": 3136, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3803.97, \"learn_time_ms\": 14904.543}", "{\"n\": 3137, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3797.99, \"learn_time_ms\": 14895.615}", "{\"n\": 3138, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3797.99, \"learn_time_ms\": 14890.75}", "{\"n\": 3139, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3804.72, \"learn_time_ms\": 14891.932}", "{\"n\": 3140, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3803.23, \"learn_time_ms\": 14886.493}", "{\"n\": 3141, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3811.87, \"learn_time_ms\": 14892.334}", "{\"n\": 3142, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3808.14, \"learn_time_ms\": 14900.78}", "{\"n\": 3143, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3808.18, \"learn_time_ms\": 14905.604}", "{\"n\": 3144, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3811.45, \"learn_time_ms\": 14920.581}", "{\"n\": 3145, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3811.45, \"learn_time_ms\": 14905.526}", "{\"n\": 3146, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3821.4, \"learn_time_ms\": 14904.483}", "{\"n\": 3147, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3806.12, \"learn_time_ms\": 14904.486}", "{\"n\": 3148, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3799.03, \"learn_time_ms\": 14899.128}", "{\"n\": 3149, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3797.47, \"learn_time_ms\": 14893.233}", "{\"n\": 3150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3799.48, \"learn_time_ms\": 14893.327}", "{\"n\": 3151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3795.31, \"learn_time_ms\": 14883.605}", "{\"n\": 3152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3786.9, \"learn_time_ms\": 14859.432}", "{\"n\": 3153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3786.9, \"learn_time_ms\": 14858.649}", "{\"n\": 3154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3792.33, \"learn_time_ms\": 14865.987}", "{\"n\": 3155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3792.33, \"learn_time_ms\": 14871.299}", "{\"n\": 3156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3789.37, \"learn_time_ms\": 14880.629}", "{\"n\": 3157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3790.65, \"learn_time_ms\": 14889.656}", "{\"n\": 3158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3770.59, \"learn_time_ms\": 14900.092}", "{\"n\": 3159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3764.15, \"learn_time_ms\": 14890.533}", "{\"n\": 3160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3774.73, \"learn_time_ms\": 14893.985}", "{\"n\": 3161, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3783.47, \"learn_time_ms\": 14892.928}", "{\"n\": 3162, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3783.47, \"learn_time_ms\": 14901.284}", "{\"n\": 3163, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3788.31, \"learn_time_ms\": 14896.416}", "{\"n\": 3164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3792.67, \"learn_time_ms\": 14881.82}", "{\"n\": 3165, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3788.27, \"learn_time_ms\": 14868.565}", "{\"n\": 3166, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3793.0, \"learn_time_ms\": 14870.289}", "{\"n\": 3167, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.08, \"learn_time_ms\": 14861.839}", "{\"n\": 3168, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.08, \"learn_time_ms\": 14841.473}", "{\"n\": 3169, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3782.55, \"learn_time_ms\": 14837.408}", "{\"n\": 3170, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3782.55, \"learn_time_ms\": 14826.518}", "{\"n\": 3171, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3782.55, \"learn_time_ms\": 14818.355}", "{\"n\": 3172, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3782.59, \"learn_time_ms\": 14831.444}", "{\"n\": 3173, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3796.44, \"learn_time_ms\": 14836.188}", "{\"n\": 3174, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3799.77, \"learn_time_ms\": 14843.219}", "{\"n\": 3175, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3799.77, \"learn_time_ms\": 14852.81}", "{\"n\": 3176, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3809.24, \"learn_time_ms\": 14846.54}", "{\"n\": 3177, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3812.15, \"learn_time_ms\": 14869.375}", "{\"n\": 3178, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3832.63, \"learn_time_ms\": 14884.628}", "{\"n\": 3179, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3824.6, \"learn_time_ms\": 14899.824}", "{\"n\": 3180, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3823.24, \"learn_time_ms\": 14896.056}", "{\"n\": 3181, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3826.15, \"learn_time_ms\": 14890.62}", "{\"n\": 3182, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3837.98, \"learn_time_ms\": 14888.648}", "{\"n\": 3183, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3826.98, \"learn_time_ms\": 14888.255}", "{\"n\": 3184, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3830.45, \"learn_time_ms\": 14897.512}", "{\"n\": 3185, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3818.23, \"learn_time_ms\": 14899.381}", "{\"n\": 3186, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3812.89, \"learn_time_ms\": 14896.655}", "{\"n\": 3187, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3831.9, \"learn_time_ms\": 14886.478}", "{\"n\": 3188, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3828.18, \"learn_time_ms\": 14886.024}", "{\"n\": 3189, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3828.18, \"learn_time_ms\": 14881.526}", "{\"n\": 3190, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3823.71, \"learn_time_ms\": 14874.346}", "{\"n\": 3191, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3823.71, \"learn_time_ms\": 14884.608}", "{\"n\": 3192, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3798.22, \"learn_time_ms\": 14899.623}", "{\"n\": 3193, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3798.12, \"learn_time_ms\": 14892.904}", "{\"n\": 3194, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3791.48, \"learn_time_ms\": 14890.966}", "{\"n\": 3195, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3791.48, \"learn_time_ms\": 14883.843}", "{\"n\": 3196, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3795.04, \"learn_time_ms\": 14878.808}", "{\"n\": 3197, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3781.54, \"learn_time_ms\": 14871.816}", "{\"n\": 3198, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3781.54, \"learn_time_ms\": 14874.982}", "{\"n\": 3199, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3781.39, \"learn_time_ms\": 14875.181}", "{\"n\": 3200, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3794.59, \"learn_time_ms\": 14889.29}", "{\"n\": 3201, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3794.59, \"learn_time_ms\": 14889.454}", "{\"n\": 3202, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3793.14, \"learn_time_ms\": 14873.518}", "{\"n\": 3203, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3786.29, \"learn_time_ms\": 14880.782}", "{\"n\": 3204, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3780.87, \"learn_time_ms\": 14876.094}", "{\"n\": 3205, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3777.23, \"learn_time_ms\": 14880.467}", "{\"n\": 3206, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3774.69, \"learn_time_ms\": 14897.619}", "{\"n\": 3207, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3774.69, \"learn_time_ms\": 14889.844}", "{\"n\": 3208, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3785.06, \"learn_time_ms\": 14875.064}", "{\"n\": 3209, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3792.34, \"learn_time_ms\": 14873.039}", "{\"n\": 3210, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3799.32, \"learn_time_ms\": 14882.667}", "{\"n\": 3211, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3794.55, \"learn_time_ms\": 14876.698}", "{\"n\": 3212, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3794.55, \"learn_time_ms\": 14885.816}", "{\"n\": 3213, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3798.84, \"learn_time_ms\": 14885.728}", "{\"n\": 3214, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3798.84, \"learn_time_ms\": 14886.813}", "{\"n\": 3215, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3785.06, \"learn_time_ms\": 14891.47}", "{\"n\": 3216, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3773.64, \"learn_time_ms\": 14876.471}", "{\"n\": 3217, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3769.7, \"learn_time_ms\": 14877.009}", "{\"n\": 3218, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3769.7, \"learn_time_ms\": 14887.415}", "{\"n\": 3219, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3769.91, \"learn_time_ms\": 14887.006}", "{\"n\": 3220, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3767.1, \"learn_time_ms\": 14863.07}", "{\"n\": 3221, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3765.46, \"learn_time_ms\": 14862.037}", "{\"n\": 3222, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3773.39, \"learn_time_ms\": 14863.128}", "{\"n\": 3223, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.46, \"learn_time_ms\": 14863.615}", "{\"n\": 3224, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.46, \"learn_time_ms\": 14846.209}", "{\"n\": 3225, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.46, \"learn_time_ms\": 14849.858}", "{\"n\": 3226, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3767.91, \"learn_time_ms\": 14847.018}", "{\"n\": 3227, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3760.13, \"learn_time_ms\": 14856.138}", "{\"n\": 3228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3768.34, \"learn_time_ms\": 14863.434}", "{\"n\": 3229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3777.64, \"learn_time_ms\": 14864.305}", "{\"n\": 3230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3777.64, \"learn_time_ms\": 14879.437}", "{\"n\": 3231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3777.64, \"learn_time_ms\": 14884.233}", "{\"n\": 3232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3768.46, \"learn_time_ms\": 14867.05}", "{\"n\": 3233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3762.39, \"learn_time_ms\": 14857.396}", "{\"n\": 3234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3766.1, \"learn_time_ms\": 14874.913}", "{\"n\": 3235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.56, \"learn_time_ms\": 14880.011}", "{\"n\": 3236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.56, \"learn_time_ms\": 14878.792}", "{\"n\": 3237, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3761.91, \"learn_time_ms\": 14873.037}", "{\"n\": 3238, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3751.12, \"learn_time_ms\": 14867.105}", "{\"n\": 3239, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3741.99, \"learn_time_ms\": 14874.262}", "{\"n\": 3240, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3729.18, \"learn_time_ms\": 14876.841}", "{\"n\": 3241, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3729.18, \"learn_time_ms\": 14882.798}", "{\"n\": 3242, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3729.18, \"learn_time_ms\": 14892.313}", "{\"n\": 3243, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3729.18, \"learn_time_ms\": 14896.46}", "{\"n\": 3244, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3729.18, \"learn_time_ms\": 14897.809}", "{\"n\": 3245, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3700.98, \"learn_time_ms\": 14898.042}", "{\"n\": 3246, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3701.21, \"learn_time_ms\": 14908.261}", "{\"n\": 3247, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3672.28, \"learn_time_ms\": 14905.087}", "{\"n\": 3248, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3672.28, \"learn_time_ms\": 14912.174}", "{\"n\": 3249, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3672.28, \"learn_time_ms\": 14909.842}", "{\"n\": 3250, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3656.29, \"learn_time_ms\": 14923.447}", "{\"n\": 3251, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.43, \"learn_time_ms\": 14914.845}", "{\"n\": 3252, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3650.22, \"learn_time_ms\": 14902.426}", "{\"n\": 3253, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3648.72, \"learn_time_ms\": 14905.851}", "{\"n\": 3254, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.76, \"learn_time_ms\": 14907.81}", "{\"n\": 3255, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3644.58, \"learn_time_ms\": 14901.516}", "{\"n\": 3256, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3639.49, \"learn_time_ms\": 14895.483}", "{\"n\": 3257, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.52, \"learn_time_ms\": 14914.974}", "{\"n\": 3258, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3663.38, \"learn_time_ms\": 14920.906}", "{\"n\": 3259, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3665.23, \"learn_time_ms\": 14923.3}", "{\"n\": 3260, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.31, \"learn_time_ms\": 14909.027}", "{\"n\": 3261, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.31, \"learn_time_ms\": 14902.919}", "{\"n\": 3262, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.61, \"learn_time_ms\": 14899.465}", "{\"n\": 3263, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3631.07, \"learn_time_ms\": 14905.579}", "{\"n\": 3264, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3631.98, \"learn_time_ms\": 14915.047}", "{\"n\": 3265, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3632.61, \"learn_time_ms\": 14916.992}", "{\"n\": 3266, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3618.07, \"learn_time_ms\": 14920.527}", "{\"n\": 3267, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3622.04, \"learn_time_ms\": 14884.369}", "{\"n\": 3268, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3622.04, \"learn_time_ms\": 14863.6}", "{\"n\": 3269, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3618.49, \"learn_time_ms\": 14852.167}", "{\"n\": 3270, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3614.31, \"learn_time_ms\": 14856.878}", "{\"n\": 3271, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3615.06, \"learn_time_ms\": 14853.099}", "{\"n\": 3272, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3617.57, \"learn_time_ms\": 14864.817}", "{\"n\": 3273, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3616.82, \"learn_time_ms\": 14858.814}", "{\"n\": 3274, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3616.82, \"learn_time_ms\": 14843.191}", "{\"n\": 3275, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3616.82, \"learn_time_ms\": 14838.672}", "{\"n\": 3276, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3622.9, \"learn_time_ms\": 14847.234}", "{\"n\": 3277, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3636.75, \"learn_time_ms\": 14868.332}", "{\"n\": 3278, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3636.75, \"learn_time_ms\": 14874.446}", "{\"n\": 3279, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3645.63, \"learn_time_ms\": 14886.315}", "{\"n\": 3280, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3645.63, \"learn_time_ms\": 14878.441}", "{\"n\": 3281, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3654.72, \"learn_time_ms\": 14896.388}", "{\"n\": 3282, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3653.56, \"learn_time_ms\": 14888.96}", "{\"n\": 3283, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3643.07, \"learn_time_ms\": 14889.654}", "{\"n\": 3284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3630.88, \"learn_time_ms\": 14872.899}", "{\"n\": 3285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3630.88, \"learn_time_ms\": 14867.771}", "{\"n\": 3286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3628.28, \"learn_time_ms\": 14870.597}", "{\"n\": 3287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3622.44, \"learn_time_ms\": 14881.669}", "{\"n\": 3288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3623.84, \"learn_time_ms\": 14884.25}", "{\"n\": 3289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3616.17, \"learn_time_ms\": 14869.852}", "{\"n\": 3290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3648.77, \"learn_time_ms\": 14883.137}", "{\"n\": 3291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3648.77, \"learn_time_ms\": 14871.484}", "{\"n\": 3292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3648.77, \"learn_time_ms\": 14871.263}", "{\"n\": 3293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.42, \"learn_time_ms\": 14874.981}", "{\"n\": 3294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3636.25, \"learn_time_ms\": 14900.197}", "{\"n\": 3295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3636.24, \"learn_time_ms\": 14903.825}", "{\"n\": 3296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3642.45, \"learn_time_ms\": 14896.89}", "{\"n\": 3297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3632.21, \"learn_time_ms\": 14886.481}", "{\"n\": 3298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3632.21, \"learn_time_ms\": 14886.089}", "{\"n\": 3299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3624.58, \"learn_time_ms\": 14890.897}", "{\"n\": 3300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3651.03, \"learn_time_ms\": 14892.723}", "{\"n\": 3301, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3655.16, \"learn_time_ms\": 14892.744}", "{\"n\": 3302, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3655.16, \"learn_time_ms\": 14904.573}", "{\"n\": 3303, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3654.62, \"learn_time_ms\": 14896.195}", "{\"n\": 3304, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3661.75, \"learn_time_ms\": 14875.594}", "{\"n\": 3305, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3656.95, \"learn_time_ms\": 14872.337}", "{\"n\": 3306, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3643.64, \"learn_time_ms\": 14872.519}", "{\"n\": 3307, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3648.78, \"learn_time_ms\": 14872.579}", "{\"n\": 3308, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3654.95, \"learn_time_ms\": 14884.405}", "{\"n\": 3309, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3638.32, \"learn_time_ms\": 14898.232}", "{\"n\": 3310, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3631.31, \"learn_time_ms\": 14885.312}", "{\"n\": 3311, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3635.46, \"learn_time_ms\": 14889.515}", "{\"n\": 3312, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3635.46, \"learn_time_ms\": 14878.679}", "{\"n\": 3313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3650.64, \"learn_time_ms\": 14885.528}", "{\"n\": 3314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3650.64, \"learn_time_ms\": 14887.539}", "{\"n\": 3315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3635.57, \"learn_time_ms\": 14899.95}", "{\"n\": 3316, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3635.37, \"learn_time_ms\": 14897.49}", "{\"n\": 3317, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3638.16, \"learn_time_ms\": 14898.386}", "{\"n\": 3318, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3646.96, \"learn_time_ms\": 14889.883}", "{\"n\": 3319, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3658.72, \"learn_time_ms\": 14879.516}", "{\"n\": 3320, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3653.94, \"learn_time_ms\": 14890.251}", "{\"n\": 3321, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3649.97, \"learn_time_ms\": 14898.495}", "{\"n\": 3322, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3653.53, \"learn_time_ms\": 14907.419}", "{\"n\": 3323, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3661.8, \"learn_time_ms\": 14919.106}", "{\"n\": 3324, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3661.68, \"learn_time_ms\": 14937.585}", "{\"n\": 3325, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3669.1, \"learn_time_ms\": 14941.15}", "{\"n\": 3326, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3672.43, \"learn_time_ms\": 14928.655}", "{\"n\": 3327, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3665.32, \"learn_time_ms\": 14924.68}", "{\"n\": 3328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3636.81, \"learn_time_ms\": 14914.03}", "{\"n\": 3329, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3632.78, \"learn_time_ms\": 14917.83}", "{\"n\": 3330, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3631.55, \"learn_time_ms\": 14927.696}", "{\"n\": 3331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3632.06, \"learn_time_ms\": 14925.775}", "{\"n\": 3332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.14, \"learn_time_ms\": 14920.569}", "{\"n\": 3333, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.14, \"learn_time_ms\": 14906.891}", "{\"n\": 3334, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3617.86, \"learn_time_ms\": 14900.637}", "{\"n\": 3335, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.61, \"learn_time_ms\": 14880.639}", "{\"n\": 3336, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3625.0, \"learn_time_ms\": 14897.177}", "{\"n\": 3337, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3625.0, \"learn_time_ms\": 14914.018}", "{\"n\": 3338, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3625.0, \"learn_time_ms\": 14929.554}", "{\"n\": 3339, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3636.66, \"learn_time_ms\": 14926.218}", "{\"n\": 3340, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3637.91, \"learn_time_ms\": 14909.013}", "{\"n\": 3341, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3643.01, \"learn_time_ms\": 14914.323}", "{\"n\": 3342, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3652.45, \"learn_time_ms\": 14917.558}", "{\"n\": 3343, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3652.45, \"learn_time_ms\": 14906.087}", "{\"n\": 3344, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3654.8, \"learn_time_ms\": 14915.442}", "{\"n\": 3345, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3660.15, \"learn_time_ms\": 14929.292}", "{\"n\": 3346, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3663.98, \"learn_time_ms\": 14927.933}", "{\"n\": 3347, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3663.98, \"learn_time_ms\": 14920.17}", "{\"n\": 3348, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3663.98, \"learn_time_ms\": 14908.243}", "{\"n\": 3349, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3670.73, \"learn_time_ms\": 14916.142}", "{\"n\": 3350, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3670.73, \"learn_time_ms\": 14916.027}", "{\"n\": 3351, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3661.41, \"learn_time_ms\": 14904.211}", "{\"n\": 3352, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3662.3, \"learn_time_ms\": 14890.407}", "{\"n\": 3353, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3653.21, \"learn_time_ms\": 14888.121}", "{\"n\": 3354, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3653.21, \"learn_time_ms\": 14874.184}", "{\"n\": 3355, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3653.21, \"learn_time_ms\": 14862.846}", "{\"n\": 3356, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3635.82, \"learn_time_ms\": 14857.898}", "{\"n\": 3357, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3639.31, \"learn_time_ms\": 14860.371}", "{\"n\": 3358, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3645.44, \"learn_time_ms\": 14858.157}", "{\"n\": 3359, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3653.17, \"learn_time_ms\": 14863.333}", "{\"n\": 3360, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3670.33, \"learn_time_ms\": 14864.749}", "{\"n\": 3361, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3670.33, \"learn_time_ms\": 14870.122}", "{\"n\": 3362, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3674.75, \"learn_time_ms\": 14885.033}", "{\"n\": 3363, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3665.21, \"learn_time_ms\": 14892.483}", "{\"n\": 3364, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3659.23, \"learn_time_ms\": 14901.989}", "{\"n\": 3365, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3659.23, \"learn_time_ms\": 14919.363}", "{\"n\": 3366, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3659.23, \"learn_time_ms\": 14926.507}", "{\"n\": 3367, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.11, \"learn_time_ms\": 14923.939}", "{\"n\": 3368, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.11, \"learn_time_ms\": 14931.458}", "{\"n\": 3369, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3644.23, \"learn_time_ms\": 14921.427}", "{\"n\": 3370, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.99, \"learn_time_ms\": 14923.782}", "{\"n\": 3371, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3640.61, \"learn_time_ms\": 14928.731}", "{\"n\": 3372, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3632.23, \"learn_time_ms\": 14935.766}", "{\"n\": 3373, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3637.27, \"learn_time_ms\": 14948.011}", "{\"n\": 3374, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3653.54, \"learn_time_ms\": 14948.688}", "{\"n\": 3375, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3642.73, \"learn_time_ms\": 14947.004}", "{\"n\": 3376, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3621.39, \"learn_time_ms\": 14936.018}", "{\"n\": 3377, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3621.39, \"learn_time_ms\": 14938.8}", "{\"n\": 3378, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3625.16, \"learn_time_ms\": 14924.199}", "{\"n\": 3379, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3603.25, \"learn_time_ms\": 14924.724}", "{\"n\": 3380, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3603.25, \"learn_time_ms\": 14914.107}", "{\"n\": 3381, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3608.35, \"learn_time_ms\": 14901.539}", "{\"n\": 3382, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3622.89, \"learn_time_ms\": 14897.159}", "{\"n\": 3383, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.97, \"learn_time_ms\": 14883.65}", "{\"n\": 3384, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3637.78, \"learn_time_ms\": 14866.232}", "{\"n\": 3385, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3652.71, \"learn_time_ms\": 14867.105}", "{\"n\": 3386, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3664.35, \"learn_time_ms\": 14870.154}", "{\"n\": 3387, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3654.18, \"learn_time_ms\": 14870.14}", "{\"n\": 3388, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3668.87, \"learn_time_ms\": 14879.993}", "{\"n\": 3389, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3666.81, \"learn_time_ms\": 14877.86}", "{\"n\": 3390, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3661.99, \"learn_time_ms\": 14889.236}", "{\"n\": 3391, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3661.99, \"learn_time_ms\": 14899.865}", "{\"n\": 3392, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3656.95, \"learn_time_ms\": 14884.115}", "{\"n\": 3393, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3656.95, \"learn_time_ms\": 14896.942}", "{\"n\": 3394, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3659.49, \"learn_time_ms\": 14901.479}", "{\"n\": 3395, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3655.18, \"learn_time_ms\": 14887.442}", "{\"n\": 3396, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3681.5, \"learn_time_ms\": 14877.724}", "{\"n\": 3397, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3680.17, \"learn_time_ms\": 14873.938}", "{\"n\": 3398, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3680.17, \"learn_time_ms\": 14873.706}", "{\"n\": 3399, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3680.17, \"learn_time_ms\": 14874.08}", "{\"n\": 3400, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3680.17, \"learn_time_ms\": 14892.154}", "{\"n\": 3401, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3696.59, \"learn_time_ms\": 14882.273}", "{\"n\": 3402, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3694.21, \"learn_time_ms\": 14894.974}", "{\"n\": 3403, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3685.71, \"learn_time_ms\": 14883.95}", "{\"n\": 3404, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3685.92, \"learn_time_ms\": 14892.755}", "{\"n\": 3405, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3685.92, \"learn_time_ms\": 14889.697}", "{\"n\": 3406, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3685.92, \"learn_time_ms\": 14904.362}", "{\"n\": 3407, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3696.66, \"learn_time_ms\": 14894.525}", "{\"n\": 3408, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3700.54, \"learn_time_ms\": 14890.533}", "{\"n\": 3409, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3704.1, \"learn_time_ms\": 14892.957}", "{\"n\": 3410, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3717.28, \"learn_time_ms\": 14870.326}", "{\"n\": 3411, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3717.28, \"learn_time_ms\": 14870.742}", "{\"n\": 3412, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3717.28, \"learn_time_ms\": 14875.833}", "{\"n\": 3413, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3722.53, \"learn_time_ms\": 14893.016}", "{\"n\": 3414, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3718.9, \"learn_time_ms\": 14895.015}", "{\"n\": 3415, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3729.65, \"learn_time_ms\": 14905.522}", "{\"n\": 3416, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3726.88, \"learn_time_ms\": 14902.95}", "{\"n\": 3417, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3717.86, \"learn_time_ms\": 14909.187}", "{\"n\": 3418, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3717.86, \"learn_time_ms\": 14908.479}", "{\"n\": 3419, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3717.86, \"learn_time_ms\": 14906.877}", "{\"n\": 3420, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3723.44, \"learn_time_ms\": 14902.642}", "{\"n\": 3421, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3729.45, \"learn_time_ms\": 14897.942}", "{\"n\": 3422, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3724.42, \"learn_time_ms\": 14899.29}", "{\"n\": 3423, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3729.8, \"learn_time_ms\": 14883.649}", "{\"n\": 3424, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3742.76, \"learn_time_ms\": 14878.687}", "{\"n\": 3425, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3746.53, \"learn_time_ms\": 14879.754}", "{\"n\": 3426, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3746.53, \"learn_time_ms\": 14895.648}", "{\"n\": 3427, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3735.78, \"learn_time_ms\": 14901.072}", "{\"n\": 3428, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3752.7, \"learn_time_ms\": 14905.092}", "{\"n\": 3429, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3767.77, \"learn_time_ms\": 14898.269}", "{\"n\": 3430, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3767.99, \"learn_time_ms\": 14916.185}", "{\"n\": 3431, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3767.99, \"learn_time_ms\": 14924.243}", "{\"n\": 3432, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3770.76, \"learn_time_ms\": 14919.823}", "{\"n\": 3433, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3770.76, \"learn_time_ms\": 14938.367}", "{\"n\": 3434, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3774.99, \"learn_time_ms\": 14949.021}", "{\"n\": 3435, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.48, \"learn_time_ms\": 14948.609}", "{\"n\": 3436, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3773.79, \"learn_time_ms\": 14931.763}", "{\"n\": 3437, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3792.34, \"learn_time_ms\": 14935.527}", "{\"n\": 3438, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3792.34, \"learn_time_ms\": 14937.031}", "{\"n\": 3439, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3787.08, \"learn_time_ms\": 14949.871}", "{\"n\": 3440, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3798.13, \"learn_time_ms\": 14938.336}", "{\"n\": 3441, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3798.04, \"learn_time_ms\": 14938.913}", "{\"n\": 3442, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3798.04, \"learn_time_ms\": 14936.758}", "{\"n\": 3443, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.4, \"learn_time_ms\": 14911.164}", "{\"n\": 3444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3793.95, \"learn_time_ms\": 14898.642}", "{\"n\": 3445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3787.13, \"learn_time_ms\": 14895.949}", "{\"n\": 3446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3782.13, \"learn_time_ms\": 14899.926}", "{\"n\": 3447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.64, \"learn_time_ms\": 14874.008}", "{\"n\": 3448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.37, \"learn_time_ms\": 14879.003}", "{\"n\": 3449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3786.2, \"learn_time_ms\": 14870.972}", "{\"n\": 3450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3793.35, \"learn_time_ms\": 14876.61}", "{\"n\": 3451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3793.35, \"learn_time_ms\": 14880.691}", "{\"n\": 3452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.2, \"learn_time_ms\": 14884.176}", "{\"n\": 3453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.2, \"learn_time_ms\": 14888.772}", "{\"n\": 3454, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3792.5, \"learn_time_ms\": 14894.819}", "{\"n\": 3455, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3802.39, \"learn_time_ms\": 14895.259}", "{\"n\": 3456, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3802.39, \"learn_time_ms\": 14898.803}", "{\"n\": 3457, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3802.21, \"learn_time_ms\": 14905.614}", "{\"n\": 3458, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3812.18, \"learn_time_ms\": 14896.451}", "{\"n\": 3459, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3838.7, \"learn_time_ms\": 14902.053}", "{\"n\": 3460, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3852.18, \"learn_time_ms\": 14898.291}", "{\"n\": 3461, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3860.02, \"learn_time_ms\": 14896.071}", "{\"n\": 3462, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3853.87, \"learn_time_ms\": 14913.521}", "{\"n\": 3463, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3858.32, \"learn_time_ms\": 14908.941}", "{\"n\": 3464, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3858.32, \"learn_time_ms\": 14900.976}", "{\"n\": 3465, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3854.36, \"learn_time_ms\": 14922.061}", "{\"n\": 3466, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3843.75, \"learn_time_ms\": 14912.156}", "{\"n\": 3467, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3848.32, \"learn_time_ms\": 14928.493}", "{\"n\": 3468, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3840.0, \"learn_time_ms\": 14942.957}", "{\"n\": 3469, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3840.0, \"learn_time_ms\": 14936.884}", "{\"n\": 3470, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3846.69, \"learn_time_ms\": 14946.484}", "{\"n\": 3471, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3857.2, \"learn_time_ms\": 14939.529}", "{\"n\": 3472, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3876.09, \"learn_time_ms\": 14914.6}", "{\"n\": 3473, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3883.67, \"learn_time_ms\": 14918.955}", "{\"n\": 3474, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3881.7, \"learn_time_ms\": 14917.132}", "{\"n\": 3475, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3881.7, \"learn_time_ms\": 14883.123}", "{\"n\": 3476, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3872.04, \"learn_time_ms\": 14888.647}", "{\"n\": 3477, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3850.67, \"learn_time_ms\": 14894.414}", "{\"n\": 3478, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3843.47, \"learn_time_ms\": 14887.277}", "{\"n\": 3479, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3840.06, \"learn_time_ms\": 14895.972}", "{\"n\": 3480, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3837.51, \"learn_time_ms\": 14885.337}", "{\"n\": 3481, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3837.51, \"learn_time_ms\": 14883.194}", "{\"n\": 3482, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3849.46, \"learn_time_ms\": 14894.995}", "{\"n\": 3483, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3839.23, \"learn_time_ms\": 14910.329}", "{\"n\": 3484, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3850.77, \"learn_time_ms\": 14927.679}", "{\"n\": 3485, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3850.77, \"learn_time_ms\": 14919.792}", "{\"n\": 3486, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3844.52, \"learn_time_ms\": 14912.204}", "{\"n\": 3487, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3855.85, \"learn_time_ms\": 14902.646}", "{\"n\": 3488, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3855.85, \"learn_time_ms\": 14895.755}", "{\"n\": 3489, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3858.17, \"learn_time_ms\": 14884.337}", "{\"n\": 3490, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3836.36, \"learn_time_ms\": 14878.676}", "{\"n\": 3491, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3839.14, \"learn_time_ms\": 14886.697}", "{\"n\": 3492, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3839.14, \"learn_time_ms\": 14884.871}", "{\"n\": 3493, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3844.58, \"learn_time_ms\": 14875.319}", "{\"n\": 3494, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3846.59, \"learn_time_ms\": 14858.295}", "{\"n\": 3495, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3861.63, \"learn_time_ms\": 14880.125}", "{\"n\": 3496, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3860.33, \"learn_time_ms\": 14875.258}", "{\"n\": 3497, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3867.56, \"learn_time_ms\": 14868.366}", "{\"n\": 3498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3842.06, \"learn_time_ms\": 14860.91}", "{\"n\": 3499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3842.06, \"learn_time_ms\": 14861.999}", "{\"n\": 3500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3856.26, \"learn_time_ms\": 14892.027}", "{\"n\": 3501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3845.5, \"learn_time_ms\": 14896.393}", "{\"n\": 3502, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3817.64, \"learn_time_ms\": 14891.703}", "{\"n\": 3503, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3817.09, \"learn_time_ms\": 14901.557}", "{\"n\": 3504, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3817.09, \"learn_time_ms\": 14908.149}", "{\"n\": 3505, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3821.06, \"learn_time_ms\": 14918.04}", "{\"n\": 3506, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3801.29, \"learn_time_ms\": 14925.218}", "{\"n\": 3507, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3802.3, \"learn_time_ms\": 14932.516}", "{\"n\": 3508, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3802.3, \"learn_time_ms\": 14937.109}", "{\"n\": 3509, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3783.41, \"learn_time_ms\": 14941.182}", "{\"n\": 3510, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3781.54, \"learn_time_ms\": 14917.146}", "{\"n\": 3511, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3787.44, \"learn_time_ms\": 14914.057}", "{\"n\": 3512, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3787.44, \"learn_time_ms\": 14910.562}", "{\"n\": 3513, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3773.94, \"learn_time_ms\": 14903.069}", "{\"n\": 3514, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3769.6, \"learn_time_ms\": 14885.496}", "{\"n\": 3515, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3743.72, \"learn_time_ms\": 14880.563}", "{\"n\": 3516, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3743.72, \"learn_time_ms\": 14899.277}", "{\"n\": 3517, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3743.72, \"learn_time_ms\": 14897.827}", "{\"n\": 3518, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3745.81, \"learn_time_ms\": 14895.675}", "{\"n\": 3519, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3742.73, \"learn_time_ms\": 14882.523}", "{\"n\": 3520, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3756.2, \"learn_time_ms\": 14880.951}", "{\"n\": 3521, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3754.92, \"learn_time_ms\": 14876.034}", "{\"n\": 3522, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3753.65, \"learn_time_ms\": 14866.77}", "{\"n\": 3523, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3753.65, \"learn_time_ms\": 14862.445}", "{\"n\": 3524, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3761.25, \"learn_time_ms\": 14877.769}", "{\"n\": 3525, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3751.38, \"learn_time_ms\": 14877.932}", "{\"n\": 3526, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3723.14, \"learn_time_ms\": 14863.36}", "{\"n\": 3527, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3725.72, \"learn_time_ms\": 14865.924}", "{\"n\": 3528, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3725.72, \"learn_time_ms\": 14877.303}", "{\"n\": 3529, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3715.67, \"learn_time_ms\": 14879.281}", "{\"n\": 3530, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3716.44, \"learn_time_ms\": 14875.616}", "{\"n\": 3531, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3705.09, \"learn_time_ms\": 14875.811}", "{\"n\": 3532, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3694.19, \"learn_time_ms\": 14901.332}", "{\"n\": 3533, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3691.57, \"learn_time_ms\": 14904.386}", "{\"n\": 3534, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3683.87, \"learn_time_ms\": 14901.457}", "{\"n\": 3535, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3683.87, \"learn_time_ms\": 14879.383}", "{\"n\": 3536, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3675.01, \"learn_time_ms\": 14878.659}", "{\"n\": 3537, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3657.49, \"learn_time_ms\": 14879.95}", "{\"n\": 3538, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.41, \"learn_time_ms\": 14879.396}", "{\"n\": 3539, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3636.01, \"learn_time_ms\": 14889.287}", "{\"n\": 3540, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3621.76, \"learn_time_ms\": 14892.559}", "{\"n\": 3541, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3628.52, \"learn_time_ms\": 14904.146}", "{\"n\": 3542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3638.16, \"learn_time_ms\": 14885.88}", "{\"n\": 3543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3626.82, \"learn_time_ms\": 14882.96}", "{\"n\": 3544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3626.82, \"learn_time_ms\": 14887.205}", "{\"n\": 3545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.99, \"learn_time_ms\": 14896.639}", "{\"n\": 3546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3640.46, \"learn_time_ms\": 14895.752}", "{\"n\": 3547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.82, \"learn_time_ms\": 14904.904}", "{\"n\": 3548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3633.5, \"learn_time_ms\": 14900.414}", "{\"n\": 3549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3632.39, \"learn_time_ms\": 14899.711}", "{\"n\": 3550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3636.66, \"learn_time_ms\": 14895.634}", "{\"n\": 3551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3636.66, \"learn_time_ms\": 14889.619}", "{\"n\": 3552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3647.19, \"learn_time_ms\": 14895.388}", "{\"n\": 3553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3645.75, \"learn_time_ms\": 14905.265}", "{\"n\": 3554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3650.18, \"learn_time_ms\": 14914.546}", "{\"n\": 3555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3649.07, \"learn_time_ms\": 14933.438}", "{\"n\": 3556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3635.03, \"learn_time_ms\": 14929.166}", "{\"n\": 3557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3643.03, \"learn_time_ms\": 14925.622}", "{\"n\": 3558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3643.58, \"learn_time_ms\": 14931.478}", "{\"n\": 3559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3643.58, \"learn_time_ms\": 14929.905}", "{\"n\": 3560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3643.77, \"learn_time_ms\": 14925.063}", "{\"n\": 3561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3629.68, \"learn_time_ms\": 14911.21}", "{\"n\": 3562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3620.43, \"learn_time_ms\": 14917.919}", "{\"n\": 3563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3616.86, \"learn_time_ms\": 14906.494}", "{\"n\": 3564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3620.75, \"learn_time_ms\": 14898.383}", "{\"n\": 3565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3616.9, \"learn_time_ms\": 14881.508}", "{\"n\": 3566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3609.41, \"learn_time_ms\": 14888.602}", "{\"n\": 3567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3609.41, \"learn_time_ms\": 14875.219}", "{\"n\": 3568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3608.51, \"learn_time_ms\": 14873.28}", "{\"n\": 3569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3608.51, \"learn_time_ms\": 14874.508}", "{\"n\": 3570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3615.2, \"learn_time_ms\": 14901.418}", "{\"n\": 3571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3598.26, \"learn_time_ms\": 14917.426}", "{\"n\": 3572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3598.26, \"learn_time_ms\": 14897.971}", "{\"n\": 3573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3596.02, \"learn_time_ms\": 14903.773}", "{\"n\": 3574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3592.64, \"learn_time_ms\": 14908.056}", "{\"n\": 3575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3600.08, \"learn_time_ms\": 14915.889}", "{\"n\": 3576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3603.2, \"learn_time_ms\": 14899.108}", "{\"n\": 3577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3617.9, \"learn_time_ms\": 14913.338}", "{\"n\": 3578, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3631.33, \"learn_time_ms\": 14920.637}", "{\"n\": 3579, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3625.86, \"learn_time_ms\": 14911.294}", "{\"n\": 3580, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3610.5, \"learn_time_ms\": 14894.813}", "{\"n\": 3581, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.97, \"learn_time_ms\": 14896.91}", "{\"n\": 3582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.97, \"learn_time_ms\": 14898.261}", "{\"n\": 3583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3590.32, \"learn_time_ms\": 14902.644}", "{\"n\": 3584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3599.06, \"learn_time_ms\": 14904.854}", "{\"n\": 3585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3607.36, \"learn_time_ms\": 14905.745}", "{\"n\": 3586, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3605.32, \"learn_time_ms\": 14928.691}", "{\"n\": 3587, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3596.98, \"learn_time_ms\": 14923.227}", "{\"n\": 3588, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3596.98, \"learn_time_ms\": 14914.742}", "{\"n\": 3589, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3602.38, \"learn_time_ms\": 14924.253}", "{\"n\": 3590, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3577.25, \"learn_time_ms\": 14927.511}", "{\"n\": 3591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3577.25, \"learn_time_ms\": 14938.154}", "{\"n\": 3592, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3585.87, \"learn_time_ms\": 14955.336}", "{\"n\": 3593, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3591.55, \"learn_time_ms\": 14935.455}", "{\"n\": 3594, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3574.89, \"learn_time_ms\": 14922.211}", "{\"n\": 3595, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3581.81, \"learn_time_ms\": 14928.743}", "{\"n\": 3596, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3596.17, \"learn_time_ms\": 14922.92}", "{\"n\": 3597, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3598.71, \"learn_time_ms\": 14919.732}", "{\"n\": 3598, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3603.43, \"learn_time_ms\": 14925.861}", "{\"n\": 3599, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3596.16, \"learn_time_ms\": 14920.37}", "{\"n\": 3600, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.82, \"learn_time_ms\": 14908.527}", "{\"n\": 3601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.82, \"learn_time_ms\": 14884.602}", "{\"n\": 3602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3603.86, \"learn_time_ms\": 14893.906}", "{\"n\": 3603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3606.4, \"learn_time_ms\": 14902.527}", "{\"n\": 3604, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3592.56, \"learn_time_ms\": 14912.37}", "{\"n\": 3605, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3589.2, \"learn_time_ms\": 14899.168}", "{\"n\": 3606, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3581.58, \"learn_time_ms\": 14892.337}", "{\"n\": 3607, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3581.58, \"learn_time_ms\": 14890.125}", "{\"n\": 3608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3581.58, \"learn_time_ms\": 14883.949}", "{\"n\": 3609, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3590.8, \"learn_time_ms\": 14891.561}", "{\"n\": 3610, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3594.91, \"learn_time_ms\": 14906.487}", "{\"n\": 3611, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.53, \"learn_time_ms\": 14908.911}", "{\"n\": 3612, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3589.24, \"learn_time_ms\": 14896.328}", "{\"n\": 3613, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.12, \"learn_time_ms\": 14902.091}", "{\"n\": 3614, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.12, \"learn_time_ms\": 14880.038}", "{\"n\": 3615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.12, \"learn_time_ms\": 14888.008}", "{\"n\": 3616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3619.85, \"learn_time_ms\": 14900.735}", "{\"n\": 3617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3606.7, \"learn_time_ms\": 14902.876}", "{\"n\": 3618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3598.09, \"learn_time_ms\": 14910.685}", "{\"n\": 3619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3598.09, \"learn_time_ms\": 14912.467}", "{\"n\": 3620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.61, \"learn_time_ms\": 14900.33}", "{\"n\": 3621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.61, \"learn_time_ms\": 14906.702}", "{\"n\": 3622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3601.19, \"learn_time_ms\": 14899.831}", "{\"n\": 3623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3598.99, \"learn_time_ms\": 14894.757}", "{\"n\": 3624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3610.78, \"learn_time_ms\": 14918.711}", "{\"n\": 3625, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3616.08, \"learn_time_ms\": 14926.556}", "{\"n\": 3626, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3622.9, \"learn_time_ms\": 14903.522}", "{\"n\": 3627, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3623.4, \"learn_time_ms\": 14900.272}", "{\"n\": 3628, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3614.86, \"learn_time_ms\": 14884.25}", "{\"n\": 3629, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3623.34, \"learn_time_ms\": 14881.213}", "{\"n\": 3630, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3629.56, \"learn_time_ms\": 14889.207}", "{\"n\": 3631, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3639.74, \"learn_time_ms\": 14887.501}", "{\"n\": 3632, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3639.74, \"learn_time_ms\": 14893.582}", "{\"n\": 3633, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3636.84, \"learn_time_ms\": 14897.421}", "{\"n\": 3634, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3636.84, \"learn_time_ms\": 14896.231}", "{\"n\": 3635, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3636.1, \"learn_time_ms\": 14890.178}", "{\"n\": 3636, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3639.86, \"learn_time_ms\": 14904.52}", "{\"n\": 3637, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3649.81, \"learn_time_ms\": 14905.523}", "{\"n\": 3638, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3649.81, \"learn_time_ms\": 14916.306}", "{\"n\": 3639, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3651.37, \"learn_time_ms\": 14926.848}", "{\"n\": 3640, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3661.19, \"learn_time_ms\": 14932.843}", "{\"n\": 3641, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3662.89, \"learn_time_ms\": 14934.854}", "{\"n\": 3642, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3657.39, \"learn_time_ms\": 14925.344}", "{\"n\": 3643, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3663.16, \"learn_time_ms\": 14925.287}", "{\"n\": 3644, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3663.16, \"learn_time_ms\": 14920.913}", "{\"n\": 3645, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3661.11, \"learn_time_ms\": 14924.394}", "{\"n\": 3646, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3659.48, \"learn_time_ms\": 14926.589}", "{\"n\": 3647, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3657.28, \"learn_time_ms\": 14926.522}", "{\"n\": 3648, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3662.56, \"learn_time_ms\": 14937.286}", "{\"n\": 3649, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3671.94, \"learn_time_ms\": 14931.529}", "{\"n\": 3650, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3671.94, \"learn_time_ms\": 14920.534}", "{\"n\": 3651, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3671.94, \"learn_time_ms\": 14921.182}", "{\"n\": 3652, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3675.16, \"learn_time_ms\": 14931.575}", "{\"n\": 3653, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3674.54, \"learn_time_ms\": 14937.223}", "{\"n\": 3654, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3678.27, \"learn_time_ms\": 14936.792}", "{\"n\": 3655, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3674.35, \"learn_time_ms\": 14923.789}", "{\"n\": 3656, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3673.64, \"learn_time_ms\": 14918.373}", "{\"n\": 3657, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3674.48, \"learn_time_ms\": 14927.411}", "{\"n\": 3658, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3674.48, \"learn_time_ms\": 14925.286}", "{\"n\": 3659, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3675.48, \"learn_time_ms\": 14917.536}", "{\"n\": 3660, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3692.3, \"learn_time_ms\": 14918.869}", "{\"n\": 3661, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3692.3, \"learn_time_ms\": 14914.324}", "{\"n\": 3662, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3692.3, \"learn_time_ms\": 14908.471}", "{\"n\": 3663, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3698.48, \"learn_time_ms\": 14901.435}", "{\"n\": 3664, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3701.97, \"learn_time_ms\": 14902.474}", "{\"n\": 3665, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3715.2, \"learn_time_ms\": 14896.165}", "{\"n\": 3666, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3732.78, \"learn_time_ms\": 14897.347}", "{\"n\": 3667, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3737.51, \"learn_time_ms\": 14890.335}", "{\"n\": 3668, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3736.43, \"learn_time_ms\": 14876.025}", "{\"n\": 3669, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3758.15, \"learn_time_ms\": 14874.809}", "{\"n\": 3670, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3748.85, \"learn_time_ms\": 14870.353}", "{\"n\": 3671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3748.16, \"learn_time_ms\": 14861.324}", "{\"n\": 3672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3761.16, \"learn_time_ms\": 14868.549}", "{\"n\": 3673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3762.12, \"learn_time_ms\": 14858.705}", "{\"n\": 3674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.39, \"learn_time_ms\": 14846.213}", "{\"n\": 3675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.39, \"learn_time_ms\": 14848.431}", "{\"n\": 3676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3762.69, \"learn_time_ms\": 14844.059}", "{\"n\": 3677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3754.21, \"learn_time_ms\": 14849.185}", "{\"n\": 3678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3754.21, \"learn_time_ms\": 14855.338}", "{\"n\": 3679, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3771.39, \"learn_time_ms\": 14868.998}", "{\"n\": 3680, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3767.64, \"learn_time_ms\": 14877.365}", "{\"n\": 3681, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3767.64, \"learn_time_ms\": 14884.071}", "{\"n\": 3682, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3761.27, \"learn_time_ms\": 14884.714}", "{\"n\": 3683, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3772.97, \"learn_time_ms\": 14888.029}", "{\"n\": 3684, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3795.84, \"learn_time_ms\": 14895.376}", "{\"n\": 3685, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3798.28, \"learn_time_ms\": 14902.391}", "{\"n\": 3686, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3810.98, \"learn_time_ms\": 14911.907}", "{\"n\": 3687, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3820.06, \"learn_time_ms\": 14912.82}", "{\"n\": 3688, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3820.79, \"learn_time_ms\": 14901.243}", "{\"n\": 3689, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3827.87, \"learn_time_ms\": 14880.523}", "{\"n\": 3690, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3824.56, \"learn_time_ms\": 14879.559}", "{\"n\": 3691, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3839.74, \"learn_time_ms\": 14900.719}", "{\"n\": 3692, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3855.3, \"learn_time_ms\": 14903.254}", "{\"n\": 3693, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3828.61, \"learn_time_ms\": 14916.237}", "{\"n\": 3694, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3828.61, \"learn_time_ms\": 14924.799}", "{\"n\": 3695, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3830.74, \"learn_time_ms\": 14929.864}", "{\"n\": 3696, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3832.14, \"learn_time_ms\": 14936.288}", "{\"n\": 3697, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3832.14, \"learn_time_ms\": 14921.327}", "{\"n\": 3698, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3834.32, \"learn_time_ms\": 14928.97}", "{\"n\": 3699, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3804.89, \"learn_time_ms\": 14941.892}", "{\"n\": 3700, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3804.89, \"learn_time_ms\": 14937.312}", "{\"n\": 3701, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3792.37, \"learn_time_ms\": 14915.21}", "{\"n\": 3702, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3792.37, \"learn_time_ms\": 14898.885}", "{\"n\": 3703, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3780.21, \"learn_time_ms\": 14894.163}", "{\"n\": 3704, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3775.31, \"learn_time_ms\": 14889.019}", "{\"n\": 3705, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3785.87, \"learn_time_ms\": 14888.419}", "{\"n\": 3706, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3785.87, \"learn_time_ms\": 14886.466}", "{\"n\": 3707, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3775.96, \"learn_time_ms\": 14895.238}", "{\"n\": 3708, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3772.74, \"learn_time_ms\": 14893.456}", "{\"n\": 3709, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3772.74, \"learn_time_ms\": 14890.739}", "{\"n\": 3710, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3747.38, \"learn_time_ms\": 14894.494}", "{\"n\": 3711, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3751.24, \"learn_time_ms\": 14904.905}", "{\"n\": 3712, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3751.24, \"learn_time_ms\": 14918.455}", "{\"n\": 3713, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3760.14, \"learn_time_ms\": 14928.377}", "{\"n\": 3714, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3765.57, \"learn_time_ms\": 14927.575}", "{\"n\": 3715, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3767.09, \"learn_time_ms\": 14931.206}", "{\"n\": 3716, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3761.45, \"learn_time_ms\": 14920.42}", "{\"n\": 3717, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3768.93, \"learn_time_ms\": 14922.729}", "{\"n\": 3718, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3768.93, \"learn_time_ms\": 14928.568}", "{\"n\": 3719, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3772.74, \"learn_time_ms\": 14929.393}", "{\"n\": 3720, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3785.37, \"learn_time_ms\": 14936.014}", "{\"n\": 3721, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3800.44, \"learn_time_ms\": 14935.443}", "{\"n\": 3722, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3785.74, \"learn_time_ms\": 14933.634}", "{\"n\": 3723, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3785.74, \"learn_time_ms\": 14922.511}", "{\"n\": 3724, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3775.73, \"learn_time_ms\": 14926.399}", "{\"n\": 3725, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3783.5, \"learn_time_ms\": 14919.738}", "{\"n\": 3726, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3783.5, \"learn_time_ms\": 14930.155}", "{\"n\": 3727, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3786.93, \"learn_time_ms\": 14919.837}", "{\"n\": 3728, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3786.93, \"learn_time_ms\": 14910.839}", "{\"n\": 3729, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3763.67, \"learn_time_ms\": 14911.406}", "{\"n\": 3730, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3756.86, \"learn_time_ms\": 14892.035}", "{\"n\": 3731, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3756.86, \"learn_time_ms\": 14879.515}", "{\"n\": 3732, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3770.91, \"learn_time_ms\": 14877.493}", "{\"n\": 3733, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3771.28, \"learn_time_ms\": 14884.626}", "{\"n\": 3734, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3776.8, \"learn_time_ms\": 14882.48}", "{\"n\": 3735, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3789.96, \"learn_time_ms\": 14898.556}", "{\"n\": 3736, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3789.96, \"learn_time_ms\": 14883.685}", "{\"n\": 3737, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3791.49, \"learn_time_ms\": 14910.996}", "{\"n\": 3738, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3791.49, \"learn_time_ms\": 14916.655}", "{\"n\": 3739, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3786.53, \"learn_time_ms\": 14910.928}", "{\"n\": 3740, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3765.84, \"learn_time_ms\": 14937.721}", "{\"n\": 3741, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3776.83, \"learn_time_ms\": 14937.701}", "{\"n\": 3742, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3769.92, \"learn_time_ms\": 14933.373}", "{\"n\": 3743, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3769.92, \"learn_time_ms\": 14923.453}", "{\"n\": 3744, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3759.24, \"learn_time_ms\": 14915.012}", "{\"n\": 3745, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3753.54, \"learn_time_ms\": 14888.769}", "{\"n\": 3746, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3737.89, \"learn_time_ms\": 14900.517}", "{\"n\": 3747, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3743.82, \"learn_time_ms\": 14876.173}", "{\"n\": 3748, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3743.82, \"learn_time_ms\": 14876.174}", "{\"n\": 3749, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3745.99, \"learn_time_ms\": 14886.454}", "{\"n\": 3750, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3742.93, \"learn_time_ms\": 14888.68}", "{\"n\": 3751, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3742.93, \"learn_time_ms\": 14895.623}", "{\"n\": 3752, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3726.76, \"learn_time_ms\": 14903.716}", "{\"n\": 3753, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3737.11, \"learn_time_ms\": 14913.534}", "{\"n\": 3754, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3737.11, \"learn_time_ms\": 14942.283}", "{\"n\": 3755, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3742.74, \"learn_time_ms\": 14955.827}", "{\"n\": 3756, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3734.4, \"learn_time_ms\": 14954.715}", "{\"n\": 3757, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3734.4, \"learn_time_ms\": 14950.181}", "{\"n\": 3758, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3754.09, \"learn_time_ms\": 14949.231}", "{\"n\": 3759, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3746.41, \"learn_time_ms\": 14942.587}", "{\"n\": 3760, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3747.68, \"learn_time_ms\": 14930.425}", "{\"n\": 3761, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3748.3, \"learn_time_ms\": 14937.751}", "{\"n\": 3762, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3744.65, \"learn_time_ms\": 14930.905}", "{\"n\": 3763, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3739.12, \"learn_time_ms\": 14922.778}", "{\"n\": 3764, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3734.97, \"learn_time_ms\": 14907.421}", "{\"n\": 3765, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.49, \"learn_time_ms\": 14912.027}", "{\"n\": 3766, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.49, \"learn_time_ms\": 14903.859}", "{\"n\": 3767, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.49, \"learn_time_ms\": 14898.408}", "{\"n\": 3768, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3697.66, \"learn_time_ms\": 14900.163}", "{\"n\": 3769, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3704.24, \"learn_time_ms\": 14908.88}", "{\"n\": 3770, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3693.43, \"learn_time_ms\": 14900.059}", "{\"n\": 3771, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3693.43, \"learn_time_ms\": 14896.705}", "{\"n\": 3772, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3694.49, \"learn_time_ms\": 14902.167}", "{\"n\": 3773, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3700.05, \"learn_time_ms\": 14914.045}", "{\"n\": 3774, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3711.45, \"learn_time_ms\": 14918.819}", "{\"n\": 3775, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3701.9, \"learn_time_ms\": 14918.92}", "{\"n\": 3776, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3705.1, \"learn_time_ms\": 14918.294}", "{\"n\": 3777, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.19, \"learn_time_ms\": 14921.901}", "{\"n\": 3778, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3705.13, \"learn_time_ms\": 14920.75}", "{\"n\": 3779, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3705.13, \"learn_time_ms\": 14916.079}", "{\"n\": 3780, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3701.21, \"learn_time_ms\": 14924.726}", "{\"n\": 3781, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3709.25, \"learn_time_ms\": 14910.665}", "{\"n\": 3782, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3709.25, \"learn_time_ms\": 14902.52}", "{\"n\": 3783, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3697.15, \"learn_time_ms\": 14899.197}", "{\"n\": 3784, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3704.18, \"learn_time_ms\": 14891.592}", "{\"n\": 3785, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3708.01, \"learn_time_ms\": 14880.833}", "{\"n\": 3786, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3708.01, \"learn_time_ms\": 14886.02}", "{\"n\": 3787, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3717.28, \"learn_time_ms\": 14898.154}", "{\"n\": 3788, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3723.11, \"learn_time_ms\": 14907.353}", "{\"n\": 3789, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3707.75, \"learn_time_ms\": 14906.977}", "{\"n\": 3790, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3707.75, \"learn_time_ms\": 14892.719}", "{\"n\": 3791, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3696.86, \"learn_time_ms\": 14909.148}", "{\"n\": 3792, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3696.86, \"learn_time_ms\": 14913.639}", "{\"n\": 3793, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3699.19, \"learn_time_ms\": 14905.9}", "{\"n\": 3794, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3699.19, \"learn_time_ms\": 14896.669}", "{\"n\": 3795, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3683.37, \"learn_time_ms\": 14890.182}", "{\"n\": 3796, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3683.37, \"learn_time_ms\": 14881.203}", "{\"n\": 3797, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3678.97, \"learn_time_ms\": 14879.899}", "{\"n\": 3798, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3669.66, \"learn_time_ms\": 14876.327}", "{\"n\": 3799, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3669.66, \"learn_time_ms\": 14870.614}", "{\"n\": 3800, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3690.64, \"learn_time_ms\": 14894.184}", "{\"n\": 3801, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3687.25, \"learn_time_ms\": 14894.519}", "{\"n\": 3802, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3683.54, \"learn_time_ms\": 14891.789}", "{\"n\": 3803, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3685.0, \"learn_time_ms\": 14889.872}", "{\"n\": 3804, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3685.0, \"learn_time_ms\": 14902.097}", "{\"n\": 3805, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3687.32, \"learn_time_ms\": 14915.992}", "{\"n\": 3806, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3695.07, \"learn_time_ms\": 14937.358}", "{\"n\": 3807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3675.31, \"learn_time_ms\": 14947.101}", "{\"n\": 3808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3669.68, \"learn_time_ms\": 14938.099}", "{\"n\": 3809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3674.86, \"learn_time_ms\": 14944.423}", "{\"n\": 3810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3669.81, \"learn_time_ms\": 14932.818}", "{\"n\": 3811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3656.52, \"learn_time_ms\": 14931.333}", "{\"n\": 3812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3656.52, \"learn_time_ms\": 14935.988}", "{\"n\": 3813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3660.1, \"learn_time_ms\": 14957.24}", "{\"n\": 3814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3660.1, \"learn_time_ms\": 14959.236}", "{\"n\": 3815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3668.57, \"learn_time_ms\": 14950.151}", "{\"n\": 3816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3676.49, \"learn_time_ms\": 14939.018}", "{\"n\": 3817, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3664.59, \"learn_time_ms\": 14942.691}", "{\"n\": 3818, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3662.24, \"learn_time_ms\": 14953.186}", "{\"n\": 3819, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3654.56, \"learn_time_ms\": 14952.502}", "{\"n\": 3820, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3668.28, \"learn_time_ms\": 14952.009}", "{\"n\": 3821, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3668.28, \"learn_time_ms\": 14950.478}", "{\"n\": 3822, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3668.28, \"learn_time_ms\": 14940.992}", "{\"n\": 3823, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3667.29, \"learn_time_ms\": 14920.101}", "{\"n\": 3824, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3672.43, \"learn_time_ms\": 14909.272}", "{\"n\": 3825, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3679.36, \"learn_time_ms\": 14912.658}", "{\"n\": 3826, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3667.99, \"learn_time_ms\": 14902.163}", "{\"n\": 3827, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3677.2, \"learn_time_ms\": 14883.155}", "{\"n\": 3828, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3677.2, \"learn_time_ms\": 14885.867}", "{\"n\": 3829, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3689.54, \"learn_time_ms\": 14877.78}", "{\"n\": 3830, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3691.0, \"learn_time_ms\": 14872.717}", "{\"n\": 3831, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3673.91, \"learn_time_ms\": 14855.027}", "{\"n\": 3832, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3705.41, \"learn_time_ms\": 14855.158}", "{\"n\": 3833, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3705.41, \"learn_time_ms\": 14858.093}", "{\"n\": 3834, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3705.41, \"learn_time_ms\": 14865.744}", "{\"n\": 3835, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3696.5, \"learn_time_ms\": 14870.874}", "{\"n\": 3836, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3698.29, \"learn_time_ms\": 14878.454}", "{\"n\": 3837, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3689.49, \"learn_time_ms\": 14889.068}", "{\"n\": 3838, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3678.48, \"learn_time_ms\": 14875.46}", "{\"n\": 3839, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3683.12, \"learn_time_ms\": 14879.57}", "{\"n\": 3840, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3683.12, \"learn_time_ms\": 14881.067}", "{\"n\": 3841, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3683.12, \"learn_time_ms\": 14889.045}", "{\"n\": 3842, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3686.26, \"learn_time_ms\": 14892.098}", "{\"n\": 3843, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3687.38, \"learn_time_ms\": 14897.207}", "{\"n\": 3844, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3701.99, \"learn_time_ms\": 14882.484}", "{\"n\": 3845, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3701.99, \"learn_time_ms\": 14879.883}", "{\"n\": 3846, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3715.97, \"learn_time_ms\": 14876.81}", "{\"n\": 3847, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3715.97, \"learn_time_ms\": 14875.696}", "{\"n\": 3848, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3719.13, \"learn_time_ms\": 14878.59}", "{\"n\": 3849, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3719.87, \"learn_time_ms\": 14875.58}", "{\"n\": 3850, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3718.55, \"learn_time_ms\": 14866.8}", "{\"n\": 3851, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3718.55, \"learn_time_ms\": 14874.223}", "{\"n\": 3852, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3722.19, \"learn_time_ms\": 14865.311}", "{\"n\": 3853, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3722.19, \"learn_time_ms\": 14865.124}", "{\"n\": 3854, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3734.43, \"learn_time_ms\": 14875.511}", "{\"n\": 3855, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3732.0, \"learn_time_ms\": 14868.194}", "{\"n\": 3856, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3733.68, \"learn_time_ms\": 14862.846}", "{\"n\": 3857, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3733.49, \"learn_time_ms\": 14852.076}", "{\"n\": 3858, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3733.49, \"learn_time_ms\": 14854.964}", "{\"n\": 3859, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3719.63, \"learn_time_ms\": 14850.142}", "{\"n\": 3860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3735.43, \"learn_time_ms\": 14854.604}", "{\"n\": 3861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3732.58, \"learn_time_ms\": 14863.674}", "{\"n\": 3862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3732.58, \"learn_time_ms\": 14881.766}", "{\"n\": 3863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3726.28, \"learn_time_ms\": 14881.691}", "{\"n\": 3864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3726.28, \"learn_time_ms\": 14872.206}", "{\"n\": 3865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3726.28, \"learn_time_ms\": 14874.365}", "{\"n\": 3866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3712.54, \"learn_time_ms\": 14879.967}", "{\"n\": 3867, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3713.4, \"learn_time_ms\": 14880.473}", "{\"n\": 3868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3715.1, \"learn_time_ms\": 14891.185}", "{\"n\": 3869, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3705.84, \"learn_time_ms\": 14902.468}", "{\"n\": 3870, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3706.86, \"learn_time_ms\": 14917.867}", "{\"n\": 3871, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3702.86, \"learn_time_ms\": 14914.779}", "{\"n\": 3872, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3715.53, \"learn_time_ms\": 14910.929}", "{\"n\": 3873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3719.62, \"learn_time_ms\": 14904.464}", "{\"n\": 3874, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3719.05, \"learn_time_ms\": 14932.356}", "{\"n\": 3875, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3719.05, \"learn_time_ms\": 14946.269}", "{\"n\": 3876, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3709.96, \"learn_time_ms\": 14951.995}", "{\"n\": 3877, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3689.96, \"learn_time_ms\": 14955.758}", "{\"n\": 3878, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3689.96, \"learn_time_ms\": 14936.853}", "{\"n\": 3879, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3670.33, \"learn_time_ms\": 14937.68}", "{\"n\": 3880, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3678.92, \"learn_time_ms\": 14937.355}", "{\"n\": 3881, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3657.77, \"learn_time_ms\": 14929.81}", "{\"n\": 3882, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3659.63, \"learn_time_ms\": 14930.411}", "{\"n\": 3883, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3659.63, \"learn_time_ms\": 14936.959}", "{\"n\": 3884, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3664.39, \"learn_time_ms\": 14918.035}", "{\"n\": 3885, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.07, \"learn_time_ms\": 14901.833}", "{\"n\": 3886, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3636.64, \"learn_time_ms\": 14894.185}", "{\"n\": 3887, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3641.05, \"learn_time_ms\": 14905.841}", "{\"n\": 3888, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3642.9, \"learn_time_ms\": 14895.04}", "{\"n\": 3889, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3629.72, \"learn_time_ms\": 14890.31}", "{\"n\": 3890, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3633.17, \"learn_time_ms\": 14868.707}", "{\"n\": 3891, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3633.17, \"learn_time_ms\": 14866.257}", "{\"n\": 3892, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3629.07, \"learn_time_ms\": 14851.964}", "{\"n\": 3893, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3634.19, \"learn_time_ms\": 14841.632}", "{\"n\": 3894, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3665.06, \"learn_time_ms\": 14842.952}", "{\"n\": 3895, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3665.06, \"learn_time_ms\": 14862.431}", "{\"n\": 3896, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3665.06, \"learn_time_ms\": 14860.218}", "{\"n\": 3897, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3665.06, \"learn_time_ms\": 14850.3}", "{\"n\": 3898, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3661.56, \"learn_time_ms\": 14862.299}", "{\"n\": 3899, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3653.09, \"learn_time_ms\": 14850.172}", "{\"n\": 3900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3649.51, \"learn_time_ms\": 14839.359}", "{\"n\": 3901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3652.21, \"learn_time_ms\": 14837.866}", "{\"n\": 3902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3652.21, \"learn_time_ms\": 14844.87}", "{\"n\": 3903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3652.21, \"learn_time_ms\": 14854.186}", "{\"n\": 3904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3627.23, \"learn_time_ms\": 14865.171}", "{\"n\": 3905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3631.87, \"learn_time_ms\": 14844.606}", "{\"n\": 3906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3645.01, \"learn_time_ms\": 14848.391}", "{\"n\": 3907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3640.62, \"learn_time_ms\": 14846.215}", "{\"n\": 3908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3640.62, \"learn_time_ms\": 14852.239}", "{\"n\": 3909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3640.62, \"learn_time_ms\": 14869.173}", "{\"n\": 3910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3630.65, \"learn_time_ms\": 14894.142}", "{\"n\": 3911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3639.7, \"learn_time_ms\": 14898.98}", "{\"n\": 3912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3643.93, \"learn_time_ms\": 14902.566}", "{\"n\": 3913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3639.68, \"learn_time_ms\": 14900.578}", "{\"n\": 3914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3645.7, \"learn_time_ms\": 14885.242}", "{\"n\": 3915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3645.7, \"learn_time_ms\": 14903.651}", "{\"n\": 3916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3642.48, \"learn_time_ms\": 14913.114}", "{\"n\": 3917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3633.55, \"learn_time_ms\": 14928.0}", "{\"n\": 3918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3629.58, \"learn_time_ms\": 14921.152}", "{\"n\": 3919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3630.06, \"learn_time_ms\": 14924.204}", "{\"n\": 3920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3613.07, \"learn_time_ms\": 14938.97}", "{\"n\": 3921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3613.07, \"learn_time_ms\": 14938.199}", "{\"n\": 3922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3614.32, \"learn_time_ms\": 14941.655}", "{\"n\": 3923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3614.32, \"learn_time_ms\": 14931.804}", "{\"n\": 3924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3616.78, \"learn_time_ms\": 14929.869}", "{\"n\": 3925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3618.6, \"learn_time_ms\": 14910.445}", "{\"n\": 3926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3618.6, \"learn_time_ms\": 14899.653}", "{\"n\": 3927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3618.6, \"learn_time_ms\": 14882.045}", "{\"n\": 3928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3591.89, \"learn_time_ms\": 14886.188}", "{\"n\": 3929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3591.89, \"learn_time_ms\": 14886.015}", "{\"n\": 3930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3599.08, \"learn_time_ms\": 14869.361}", "{\"n\": 3931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3592.9, \"learn_time_ms\": 14859.826}", "{\"n\": 3932, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3590.17, \"learn_time_ms\": 14866.616}", "{\"n\": 3933, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3605.8, \"learn_time_ms\": 14879.173}", "{\"n\": 3934, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3610.44, \"learn_time_ms\": 14872.77}", "{\"n\": 3935, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3592.81, \"learn_time_ms\": 14880.706}", "{\"n\": 3936, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3586.38, \"learn_time_ms\": 14880.814}", "{\"n\": 3937, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3586.38, \"learn_time_ms\": 14878.77}", "{\"n\": 3938, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3599.38, \"learn_time_ms\": 14894.818}", "{\"n\": 3939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3599.38, \"learn_time_ms\": 14905.455}", "{\"n\": 3940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3601.94, \"learn_time_ms\": 14914.019}", "{\"n\": 3941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3617.99, \"learn_time_ms\": 14909.897}", "{\"n\": 3942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3611.65, \"learn_time_ms\": 14894.478}", "{\"n\": 3943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3611.65, \"learn_time_ms\": 14872.553}", "{\"n\": 3944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3619.72, \"learn_time_ms\": 14893.063}", "{\"n\": 3945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3621.93, \"learn_time_ms\": 14897.182}", "{\"n\": 3946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3628.63, \"learn_time_ms\": 14899.716}", "{\"n\": 3947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3610.08, \"learn_time_ms\": 14907.143}", "{\"n\": 3948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3605.87, \"learn_time_ms\": 14894.121}", "{\"n\": 3949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.49, \"learn_time_ms\": 14883.603}", "{\"n\": 3950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.49, \"learn_time_ms\": 14882.841}", "{\"n\": 3951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3612.51, \"learn_time_ms\": 14890.751}", "{\"n\": 3952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3609.83, \"learn_time_ms\": 14902.984}", "{\"n\": 3953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.35, \"learn_time_ms\": 14923.645}", "{\"n\": 3954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3624.35, \"learn_time_ms\": 14919.356}", "{\"n\": 3955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3620.55, \"learn_time_ms\": 14916.851}", "{\"n\": 3956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3620.55, \"learn_time_ms\": 14923.037}", "{\"n\": 3957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3632.18, \"learn_time_ms\": 14921.282}", "{\"n\": 3958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3635.83, \"learn_time_ms\": 14929.906}", "{\"n\": 3959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3641.18, \"learn_time_ms\": 14920.279}", "{\"n\": 3960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.51, \"learn_time_ms\": 14919.122}", "{\"n\": 3961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3640.63, \"learn_time_ms\": 14917.582}", "{\"n\": 3962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3640.63, \"learn_time_ms\": 14914.255}", "{\"n\": 3963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3633.33, \"learn_time_ms\": 14916.49}", "{\"n\": 3964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3627.55, \"learn_time_ms\": 14935.071}", "{\"n\": 3965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3638.84, \"learn_time_ms\": 14941.418}", "{\"n\": 3966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3638.84, \"learn_time_ms\": 14935.204}", "{\"n\": 3967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3629.77, \"learn_time_ms\": 14948.794}", "{\"n\": 3968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3625.19, \"learn_time_ms\": 14936.349}", "{\"n\": 3969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3613.09, \"learn_time_ms\": 14935.613}", "{\"n\": 3970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3615.47, \"learn_time_ms\": 14917.033}", "{\"n\": 3971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3615.47, \"learn_time_ms\": 14913.658}", "{\"n\": 3972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3607.61, \"learn_time_ms\": 14913.99}", "{\"n\": 3973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3617.43, \"learn_time_ms\": 14891.224}", "{\"n\": 3974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3617.83, \"learn_time_ms\": 14872.415}", "{\"n\": 3975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3617.83, \"learn_time_ms\": 14861.294}", "{\"n\": 3976, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3632.88, \"learn_time_ms\": 14866.987}", "{\"n\": 3977, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3637.54, \"learn_time_ms\": 14853.663}", "{\"n\": 3978, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3620.24, \"learn_time_ms\": 14865.668}", "{\"n\": 3979, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3633.94, \"learn_time_ms\": 14861.831}", "{\"n\": 3980, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3641.97, \"learn_time_ms\": 14871.214}", "{\"n\": 3981, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3641.97, \"learn_time_ms\": 14880.007}", "{\"n\": 3982, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3639.14, \"learn_time_ms\": 14878.018}", "{\"n\": 3983, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3640.48, \"learn_time_ms\": 14893.435}", "{\"n\": 3984, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3625.25, \"learn_time_ms\": 14884.466}", "{\"n\": 3985, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3625.25, \"learn_time_ms\": 14899.681}", "{\"n\": 3986, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3622.16, \"learn_time_ms\": 14902.829}", "{\"n\": 3987, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3642.69, \"learn_time_ms\": 14902.522}", "{\"n\": 3988, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3642.69, \"learn_time_ms\": 14894.647}", "{\"n\": 3989, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3666.39, \"learn_time_ms\": 14903.633}", "{\"n\": 3990, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3666.39, \"learn_time_ms\": 14905.202}", "{\"n\": 3991, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3659.77, \"learn_time_ms\": 14902.326}", "{\"n\": 3992, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3666.25, \"learn_time_ms\": 14890.594}", "{\"n\": 3993, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3673.94, \"learn_time_ms\": 14883.281}", "{\"n\": 3994, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3682.06, \"learn_time_ms\": 14896.223}", "{\"n\": 3995, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3679.32, \"learn_time_ms\": 14876.19}", "{\"n\": 3996, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3679.32, \"learn_time_ms\": 14867.354}", "{\"n\": 3997, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3691.8, \"learn_time_ms\": 14869.302}", "{\"n\": 3998, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3691.8, \"learn_time_ms\": 14867.344}", "{\"n\": 3999, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3689.09, \"learn_time_ms\": 14853.651}", "{\"n\": 4000, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3693.67, \"learn_time_ms\": 14854.46}"]["{\"n\": 4001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15551.401}", "{\"n\": 4002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15164.54}", "{\"n\": 4003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15017.741}", "{\"n\": 4004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14985.728}", "{\"n\": 4005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14952.699}", "{\"n\": 4006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14927.924}", "{\"n\": 4007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14900.867}", "{\"n\": 4008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14890.77}", "{\"n\": 4009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14887.173}", "{\"n\": 4010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14891.238}", "{\"n\": 4011, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14811.152}", "{\"n\": 4012, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -6.666666666666667, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3779.6666666666665, \"learn_time_ms\": 14814.131}", "{\"n\": 4013, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.666666666666667, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3641.3333333333335, \"learn_time_ms\": 14822.634}", "{\"n\": 4014, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.571428571428571, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3640.1428571428573, \"learn_time_ms\": 14805.779}", "{\"n\": 4015, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3688.0, \"learn_time_ms\": 14806.408}", "{\"n\": 4016, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3688.0, \"learn_time_ms\": 14797.912}", "{\"n\": 4017, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.222222222222222, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3647.777777777778, \"learn_time_ms\": 14805.315}", "{\"n\": 4018, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3665.6, \"learn_time_ms\": 14803.76}", "{\"n\": 4019, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -7.454545454545454, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3577.181818181818, \"learn_time_ms\": 14804.376}", "{\"n\": 4020, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.466666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3711.0666666666666, \"learn_time_ms\": 14788.116}", "{\"n\": 4021, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3769.625, \"learn_time_ms\": 14795.922}", "{\"n\": 4022, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3769.625, \"learn_time_ms\": 14795.909}", "{\"n\": 4023, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.294117647058823, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3750.470588235294, \"learn_time_ms\": 14798.756}", "{\"n\": 4024, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.421052631578948, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3723.9473684210525, \"learn_time_ms\": 14814.085}", "{\"n\": 4025, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3741.5, \"learn_time_ms\": 14820.116}", "{\"n\": 4026, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.954545454545454, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3777.5454545454545, \"learn_time_ms\": 14826.946}", "{\"n\": 4027, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.916666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3798.375, \"learn_time_ms\": 14832.543}", "{\"n\": 4028, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.916666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3798.375, \"learn_time_ms\": 14845.52}", "{\"n\": 4029, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.916666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3798.375, \"learn_time_ms\": 14850.313}", "{\"n\": 4030, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.1923076923076925, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3766.0384615384614, \"learn_time_ms\": 14869.919}", "{\"n\": 4031, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.321428571428571, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3741.75, \"learn_time_ms\": 14881.025}", "{\"n\": 4032, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.166666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3742.3, \"learn_time_ms\": 14890.252}", "{\"n\": 4033, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.166666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3742.3, \"learn_time_ms\": 14882.959}", "{\"n\": 4034, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.125, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3747.78125, \"learn_time_ms\": 14884.535}", "{\"n\": 4035, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.96969696969697, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3753.5454545454545, \"learn_time_ms\": 14886.041}", "{\"n\": 4036, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3746.6285714285714, \"learn_time_ms\": 14891.21}", "{\"n\": 4037, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.027777777777778, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3740.972222222222, \"learn_time_ms\": 14891.672}", "{\"n\": 4038, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.947368421052632, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3736.0263157894738, \"learn_time_ms\": 14889.26}", "{\"n\": 4039, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.947368421052632, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3736.0263157894738, \"learn_time_ms\": 14886.277}", "{\"n\": 4040, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.947368421052632, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3736.0263157894738, \"learn_time_ms\": 14872.361}", "{\"n\": 4041, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3766.275, \"learn_time_ms\": 14860.613}", "{\"n\": 4042, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3734.904761904762, \"learn_time_ms\": 14851.198}", "{\"n\": 4043, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.0227272727272725, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3724.9772727272725, \"learn_time_ms\": 14857.338}", "{\"n\": 4044, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.043478260869565, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3728.978260869565, \"learn_time_ms\": 14857.297}", "{\"n\": 4045, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.043478260869565, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3728.978260869565, \"learn_time_ms\": 14854.115}", "{\"n\": 4046, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -6.043478260869565, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3728.978260869565, \"learn_time_ms\": 14860.21}", "{\"n\": 4047, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.895833333333333, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3756.0833333333335, \"learn_time_ms\": 14857.9}", "{\"n\": 4048, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.63265306122449, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3761.734693877551, \"learn_time_ms\": 14855.505}", "{\"n\": 4049, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3748.04, \"learn_time_ms\": 14839.909}", "{\"n\": 4050, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.8076923076923075, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3737.9423076923076, \"learn_time_ms\": 14842.736}", "{\"n\": 4051, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.592592592592593, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3746.203703703704, \"learn_time_ms\": 14856.698}", "{\"n\": 4052, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.592592592592593, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3746.203703703704, \"learn_time_ms\": 14864.072}", "{\"n\": 4053, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.592592592592593, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3746.203703703704, \"learn_time_ms\": 14850.498}", "{\"n\": 4054, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7894736842105265, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3741.5087719298244, \"learn_time_ms\": 14837.998}", "{\"n\": 4055, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.655172413793103, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3751.4655172413795, \"learn_time_ms\": 14840.484}", "{\"n\": 4056, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.627118644067797, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3764.4406779661017, \"learn_time_ms\": 14836.142}", "{\"n\": 4057, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.596774193548387, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3781.4193548387098, \"learn_time_ms\": 14830.266}", "{\"n\": 4058, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.596774193548387, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3781.4193548387098, \"learn_time_ms\": 14833.196}", "{\"n\": 4059, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.640625, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3779.109375, \"learn_time_ms\": 14834.725}", "{\"n\": 4060, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.476923076923077, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3783.892307692308, \"learn_time_ms\": 14833.303}", "{\"n\": 4061, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.46969696969697, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3786.560606060606, \"learn_time_ms\": 14816.267}", "{\"n\": 4062, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.529411764705882, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3779.3970588235293, \"learn_time_ms\": 14811.96}", "{\"n\": 4063, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.542857142857143, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3780.9142857142856, \"learn_time_ms\": 14832.073}", "{\"n\": 4064, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.577464788732394, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3773.7464788732395, \"learn_time_ms\": 14836.057}", "{\"n\": 4065, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.577464788732394, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3773.7464788732395, \"learn_time_ms\": 14826.901}", "{\"n\": 4066, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.712328767123288, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3756.4383561643835, \"learn_time_ms\": 14830.515}", "{\"n\": 4067, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.712328767123288, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3756.4383561643835, \"learn_time_ms\": 14834.609}", "{\"n\": 4068, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3754.36, \"learn_time_ms\": 14820.836}", "{\"n\": 4069, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7894736842105265, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3740.1710526315787, \"learn_time_ms\": 14835.38}", "{\"n\": 4070, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.779220779220779, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3740.155844155844, \"learn_time_ms\": 14838.675}", "{\"n\": 4071, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.784810126582278, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3742.721518987342, \"learn_time_ms\": 14841.246}", "{\"n\": 4072, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.703703703703703, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3744.222222222222, \"learn_time_ms\": 14845.082}", "{\"n\": 4073, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.7317073170731705, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3747.329268292683, \"learn_time_ms\": 14837.998}", "{\"n\": 4074, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.714285714285714, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3752.4285714285716, \"learn_time_ms\": 14843.155}", "{\"n\": 4075, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.764705882352941, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3745.541176470588, \"learn_time_ms\": 14837.278}", "{\"n\": 4076, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.764705882352941, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3745.541176470588, \"learn_time_ms\": 14827.874}", "{\"n\": 4077, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.724137931034483, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3764.5402298850577, \"learn_time_ms\": 14835.991}", "{\"n\": 4078, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.820224719101123, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3753.1348314606744, \"learn_time_ms\": 14845.552}", "{\"n\": 4079, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.9010989010989015, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3749.5274725274726, \"learn_time_ms\": 14849.727}", "{\"n\": 4080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.989130434782608, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3737.25, \"learn_time_ms\": 14853.297}", "{\"n\": 4081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.827956989247312, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3737.3870967741937, \"learn_time_ms\": 14851.375}", "{\"n\": 4082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.797872340425532, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3735.744680851064, \"learn_time_ms\": 14843.745}", "{\"n\": 4083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.822916666666667, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3733.84375, \"learn_time_ms\": 14837.318}", "{\"n\": 4084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.822916666666667, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3733.84375, \"learn_time_ms\": 14825.172}", "{\"n\": 4085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.724489795918367, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3733.030612244898, \"learn_time_ms\": 14835.169}", "{\"n\": 4086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.92, \"learn_time_ms\": 14846.661}", "{\"n\": 4087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.92, \"learn_time_ms\": 14841.977}", "{\"n\": 4088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3729.3, \"learn_time_ms\": 14850.476}", "{\"n\": 4089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3717.22, \"learn_time_ms\": 14849.164}", "{\"n\": 4090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3716.65, \"learn_time_ms\": 14839.318}", "{\"n\": 4091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3725.26, \"learn_time_ms\": 14851.707}", "{\"n\": 4092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3725.26, \"learn_time_ms\": 14866.158}", "{\"n\": 4093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.59, \"learn_time_ms\": 14872.078}", "{\"n\": 4094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3740.21, \"learn_time_ms\": 14882.589}", "{\"n\": 4095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.77, \"learn_time_ms\": 14885.466}", "{\"n\": 4096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3731.39, \"learn_time_ms\": 14884.196}", "{\"n\": 4097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.39, \"learn_time_ms\": 14878.803}", "{\"n\": 4098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.39, \"learn_time_ms\": 14869.126}", "{\"n\": 4099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.29, \"learn_time_ms\": 14860.694}", "{\"n\": 4100, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3708.51, \"learn_time_ms\": 14872.958}", "{\"n\": 4101, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3698.55, \"learn_time_ms\": 14862.03}", "{\"n\": 4102, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.33, \"learn_time_ms\": 14861.739}", "{\"n\": 4103, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3688.27, \"learn_time_ms\": 14869.074}", "{\"n\": 4104, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3678.69, \"learn_time_ms\": 14871.058}", "{\"n\": 4105, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.51, \"learn_time_ms\": 14874.283}", "{\"n\": 4106, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.51, \"learn_time_ms\": 14870.215}", "{\"n\": 4107, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3677.29, \"learn_time_ms\": 14878.025}", "{\"n\": 4108, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.35, \"learn_time_ms\": 14882.738}", "{\"n\": 4109, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.72, \"learn_time_ms\": 14890.346}", "{\"n\": 4110, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.72, \"learn_time_ms\": 14864.472}", "{\"n\": 4111, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.14, \"learn_time_ms\": 14869.336}", "{\"n\": 4112, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.63, \"learn_time_ms\": 14855.461}", "{\"n\": 4113, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3669.87, \"learn_time_ms\": 14854.977}", "{\"n\": 4114, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3669.87, \"learn_time_ms\": 14853.327}", "{\"n\": 4115, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3669.87, \"learn_time_ms\": 14833.61}", "{\"n\": 4116, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3671.44, \"learn_time_ms\": 14821.454}", "{\"n\": 4117, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3674.31, \"learn_time_ms\": 14802.732}", "{\"n\": 4118, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3676.79, \"learn_time_ms\": 14788.248}", "{\"n\": 4119, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.57, \"learn_time_ms\": 14780.945}", "{\"n\": 4120, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.57, \"learn_time_ms\": 14791.526}", "{\"n\": 4121, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.57, \"learn_time_ms\": 14797.945}", "{\"n\": 4122, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3640.6, \"learn_time_ms\": 14804.304}", "{\"n\": 4123, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3645.38, \"learn_time_ms\": 14791.191}", "{\"n\": 4124, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3643.54, \"learn_time_ms\": 14780.391}", "{\"n\": 4125, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3639.76, \"learn_time_ms\": 14772.107}", "{\"n\": 4126, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3639.76, \"learn_time_ms\": 14775.134}", "{\"n\": 4127, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3632.71, \"learn_time_ms\": 14781.468}", "{\"n\": 4128, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.13, \"learn_time_ms\": 14787.59}", "{\"n\": 4129, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.15, \"learn_time_ms\": 14790.677}", "{\"n\": 4130, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3613.05, \"learn_time_ms\": 14787.529}", "{\"n\": 4131, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.18, \"learn_time_ms\": 14778.912}", "{\"n\": 4132, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3600.07, \"learn_time_ms\": 14791.455}", "{\"n\": 4133, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3600.07, \"learn_time_ms\": 14816.009}", "{\"n\": 4134, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.71, \"learn_time_ms\": 14830.553}", "{\"n\": 4135, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3575.23, \"learn_time_ms\": 14848.264}", "{\"n\": 4136, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3576.59, \"learn_time_ms\": 14856.349}", "{\"n\": 4137, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3580.08, \"learn_time_ms\": 14863.313}", "{\"n\": 4138, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3582.1, \"learn_time_ms\": 14860.675}", "{\"n\": 4139, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3568.78, \"learn_time_ms\": 14861.67}", "{\"n\": 4140, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3593.47, \"learn_time_ms\": 14855.451}", "{\"n\": 4141, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.11, \"learn_time_ms\": 14837.372}", "{\"n\": 4142, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.11, \"learn_time_ms\": 14823.665}", "{\"n\": 4143, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.62, \"learn_time_ms\": 14807.573}", "{\"n\": 4144, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3584.21, \"learn_time_ms\": 14788.53}", "{\"n\": 4145, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3585.5, \"learn_time_ms\": 14789.733}", "{\"n\": 4146, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3576.63, \"learn_time_ms\": 14775.572}", "{\"n\": 4147, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3569.05, \"learn_time_ms\": 14771.408}", "{\"n\": 4148, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3569.15, \"learn_time_ms\": 14764.335}", "{\"n\": 4149, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3557.28, \"learn_time_ms\": 14757.084}", "{\"n\": 4150, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3560.97, \"learn_time_ms\": 14770.191}", "{\"n\": 4151, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3545.03, \"learn_time_ms\": 14799.046}", "{\"n\": 4152, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3559.46, \"learn_time_ms\": 14807.08}", "{\"n\": 4153, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3559.46, \"learn_time_ms\": 14805.567}", "{\"n\": 4154, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.91, \"learn_time_ms\": 14808.617}", "{\"n\": 4155, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3576.41, \"learn_time_ms\": 14811.168}", "{\"n\": 4156, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3585.91, \"learn_time_ms\": 14829.449}", "{\"n\": 4157, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3577.59, \"learn_time_ms\": 14847.269}", "{\"n\": 4158, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3568.58, \"learn_time_ms\": 14860.127}", "{\"n\": 4159, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3568.58, \"learn_time_ms\": 14860.294}", "{\"n\": 4160, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3563.92, \"learn_time_ms\": 14862.185}", "{\"n\": 4161, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3560.75, \"learn_time_ms\": 14855.534}", "{\"n\": 4162, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3563.03, \"learn_time_ms\": 14836.301}", "{\"n\": 4163, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3575.56, \"learn_time_ms\": 14834.063}", "{\"n\": 4164, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3577.41, \"learn_time_ms\": 14855.078}", "{\"n\": 4165, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3577.41, \"learn_time_ms\": 14854.013}", "{\"n\": 4166, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3577.41, \"learn_time_ms\": 14851.83}", "{\"n\": 4167, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3566.04, \"learn_time_ms\": 14843.602}", "{\"n\": 4168, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3553.72, \"learn_time_ms\": 14848.189}", "{\"n\": 4169, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3554.43, \"learn_time_ms\": 14842.804}", "{\"n\": 4170, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3554.43, \"learn_time_ms\": 14851.233}", "{\"n\": 4171, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3554.43, \"learn_time_ms\": 14839.581}", "{\"n\": 4172, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3552.65, \"learn_time_ms\": 14848.284}", "{\"n\": 4173, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3557.73, \"learn_time_ms\": 14858.191}", "{\"n\": 4174, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3555.67, \"learn_time_ms\": 14839.59}", "{\"n\": 4175, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3573.99, \"learn_time_ms\": 14825.904}", "{\"n\": 4176, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3573.99, \"learn_time_ms\": 14810.223}", "{\"n\": 4177, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3577.06, \"learn_time_ms\": 14809.319}", "{\"n\": 4178, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3577.06, \"learn_time_ms\": 14802.114}", "{\"n\": 4179, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3577.06, \"learn_time_ms\": 14804.767}", "{\"n\": 4180, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3583.64, \"learn_time_ms\": 14790.192}", "{\"n\": 4181, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3585.81, \"learn_time_ms\": 14791.43}", "{\"n\": 4182, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3614.84, \"learn_time_ms\": 14783.518}", "{\"n\": 4183, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3614.84, \"learn_time_ms\": 14779.347}", "{\"n\": 4184, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3614.84, \"learn_time_ms\": 14788.875}", "{\"n\": 4185, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3614.84, \"learn_time_ms\": 14800.377}", "{\"n\": 4186, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3617.62, \"learn_time_ms\": 14814.526}", "{\"n\": 4187, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3612.98, \"learn_time_ms\": 14821.635}", "{\"n\": 4188, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3608.87, \"learn_time_ms\": 14818.027}", "{\"n\": 4189, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3630.1, \"learn_time_ms\": 14825.091}", "{\"n\": 4190, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3630.1, \"learn_time_ms\": 14841.156}", "{\"n\": 4191, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3630.1, \"learn_time_ms\": 14841.974}", "{\"n\": 4192, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3630.1, \"learn_time_ms\": 14851.164}", "{\"n\": 4193, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3624.29, \"learn_time_ms\": 14851.17}", "{\"n\": 4194, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3632.82, \"learn_time_ms\": 14856.982}", "{\"n\": 4195, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3667.13, \"learn_time_ms\": 14844.019}", "{\"n\": 4196, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3667.13, \"learn_time_ms\": 14840.46}", "{\"n\": 4197, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3667.13, \"learn_time_ms\": 14800.9}", "{\"n\": 4198, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3677.34, \"learn_time_ms\": 14809.905}", "{\"n\": 4199, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3677.49, \"learn_time_ms\": 14808.096}", "{\"n\": 4200, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3681.52, \"learn_time_ms\": 14800.328}", "{\"n\": 4201, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3666.84, \"learn_time_ms\": 14802.699}", "{\"n\": 4202, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3687.78, \"learn_time_ms\": 14798.844}", "{\"n\": 4203, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3687.78, \"learn_time_ms\": 14791.098}", "{\"n\": 4204, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3684.91, \"learn_time_ms\": 14788.696}", "{\"n\": 4205, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3684.91, \"learn_time_ms\": 14808.49}", "{\"n\": 4206, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3690.78, \"learn_time_ms\": 14810.268}", "{\"n\": 4207, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3706.49, \"learn_time_ms\": 14842.893}", "{\"n\": 4208, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3706.49, \"learn_time_ms\": 14837.733}", "{\"n\": 4209, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3704.69, \"learn_time_ms\": 14835.567}", "{\"n\": 4210, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3710.73, \"learn_time_ms\": 14833.694}", "{\"n\": 4211, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3708.01, \"learn_time_ms\": 14833.728}", "{\"n\": 4212, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3716.65, \"learn_time_ms\": 14829.391}", "{\"n\": 4213, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3716.34, \"learn_time_ms\": 14828.387}", "{\"n\": 4214, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3717.26, \"learn_time_ms\": 14833.912}", "{\"n\": 4215, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3720.39, \"learn_time_ms\": 14829.566}", "{\"n\": 4216, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3739.0, \"learn_time_ms\": 14817.691}", "{\"n\": 4217, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3724.19, \"learn_time_ms\": 14808.304}", "{\"n\": 4218, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3723.74, \"learn_time_ms\": 14808.642}", "{\"n\": 4219, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3724.53, \"learn_time_ms\": 14809.028}", "{\"n\": 4220, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3716.96, \"learn_time_ms\": 14805.793}", "{\"n\": 4221, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3709.14, \"learn_time_ms\": 14805.109}", "{\"n\": 4222, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3716.74, \"learn_time_ms\": 14816.059}", "{\"n\": 4223, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3717.92, \"learn_time_ms\": 14817.172}", "{\"n\": 4224, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3729.5, \"learn_time_ms\": 14814.068}", "{\"n\": 4225, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3734.32, \"learn_time_ms\": 14817.897}", "{\"n\": 4226, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3749.89, \"learn_time_ms\": 14827.026}", "{\"n\": 4227, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3749.26, \"learn_time_ms\": 14826.121}", "{\"n\": 4228, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3750.42, \"learn_time_ms\": 14822.669}", "{\"n\": 4229, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3750.42, \"learn_time_ms\": 14809.629}", "{\"n\": 4230, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3758.13, \"learn_time_ms\": 14799.902}", "{\"n\": 4231, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3751.12, \"learn_time_ms\": 14806.319}", "{\"n\": 4232, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3751.12, \"learn_time_ms\": 14794.812}", "{\"n\": 4233, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3754.17, \"learn_time_ms\": 14802.943}", "{\"n\": 4234, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3752.99, \"learn_time_ms\": 14777.871}", "{\"n\": 4235, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3749.06, \"learn_time_ms\": 14772.357}", "{\"n\": 4236, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3749.11, \"learn_time_ms\": 14790.267}", "{\"n\": 4237, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3754.25, \"learn_time_ms\": 14794.995}", "{\"n\": 4238, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3779.28, \"learn_time_ms\": 14795.505}", "{\"n\": 4239, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3791.6, \"learn_time_ms\": 14798.285}", "{\"n\": 4240, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3811.4, \"learn_time_ms\": 14810.447}", "{\"n\": 4241, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3821.09, \"learn_time_ms\": 14811.963}", "{\"n\": 4242, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3828.68, \"learn_time_ms\": 14815.938}", "{\"n\": 4243, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3842.48, \"learn_time_ms\": 14822.012}", "{\"n\": 4244, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3843.31, \"learn_time_ms\": 14858.319}", "{\"n\": 4245, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3849.1, \"learn_time_ms\": 14859.043}", "{\"n\": 4246, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3841.14, \"learn_time_ms\": 14847.909}", "{\"n\": 4247, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3845.62, \"learn_time_ms\": 14842.842}", "{\"n\": 4248, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3845.27, \"learn_time_ms\": 14838.685}", "{\"n\": 4249, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3845.27, \"learn_time_ms\": 14845.075}", "{\"n\": 4250, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3865.0, \"learn_time_ms\": 14846.274}", "{\"n\": 4251, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3866.3, \"learn_time_ms\": 14849.582}", "{\"n\": 4252, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3858.46, \"learn_time_ms\": 14860.481}", "{\"n\": 4253, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3867.6, \"learn_time_ms\": 14849.428}", "{\"n\": 4254, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3867.6, \"learn_time_ms\": 14831.911}", "{\"n\": 4255, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3867.38, \"learn_time_ms\": 14834.554}", "{\"n\": 4256, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3867.38, \"learn_time_ms\": 14812.826}", "{\"n\": 4257, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3853.81, \"learn_time_ms\": 14821.105}", "{\"n\": 4258, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3852.01, \"learn_time_ms\": 14817.843}", "{\"n\": 4259, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3875.39, \"learn_time_ms\": 14838.795}", "{\"n\": 4260, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3875.39, \"learn_time_ms\": 14845.824}", "{\"n\": 4261, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3879.21, \"learn_time_ms\": 14840.157}", "{\"n\": 4262, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3879.21, \"learn_time_ms\": 14834.831}", "{\"n\": 4263, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3879.21, \"learn_time_ms\": 14831.833}", "{\"n\": 4264, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3890.2, \"learn_time_ms\": 14839.733}", "{\"n\": 4265, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3877.38, \"learn_time_ms\": 14846.834}", "{\"n\": 4266, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3879.88, \"learn_time_ms\": 14853.417}", "{\"n\": 4267, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3879.88, \"learn_time_ms\": 14848.66}", "{\"n\": 4268, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3887.45, \"learn_time_ms\": 14862.343}", "{\"n\": 4269, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3887.45, \"learn_time_ms\": 14844.307}", "{\"n\": 4270, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3870.24, \"learn_time_ms\": 14835.108}", "{\"n\": 4271, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3873.8, \"learn_time_ms\": 14835.65}", "{\"n\": 4272, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3862.59, \"learn_time_ms\": 14844.656}", "{\"n\": 4273, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3867.92, \"learn_time_ms\": 14854.877}", "{\"n\": 4274, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3870.25, \"learn_time_ms\": 14844.026}", "{\"n\": 4275, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3869.1, \"learn_time_ms\": 14838.723}", "{\"n\": 4276, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3861.44, \"learn_time_ms\": 14854.528}", "{\"n\": 4277, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3864.17, \"learn_time_ms\": 14849.624}", "{\"n\": 4278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3864.17, \"learn_time_ms\": 14851.992}", "{\"n\": 4279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3869.45, \"learn_time_ms\": 14852.113}", "{\"n\": 4280, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3870.96, \"learn_time_ms\": 14862.761}", "{\"n\": 4281, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3883.45, \"learn_time_ms\": 14869.602}", "{\"n\": 4282, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3878.34, \"learn_time_ms\": 14859.686}", "{\"n\": 4283, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3874.96, \"learn_time_ms\": 14853.571}", "{\"n\": 4284, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3865.08, \"learn_time_ms\": 14867.165}", "{\"n\": 4285, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3865.08, \"learn_time_ms\": 14857.63}", "{\"n\": 4286, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3885.78, \"learn_time_ms\": 14853.819}", "{\"n\": 4287, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3880.65, \"learn_time_ms\": 14862.946}", "{\"n\": 4288, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3879.44, \"learn_time_ms\": 14870.213}", "{\"n\": 4289, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3879.44, \"learn_time_ms\": 14873.301}", "{\"n\": 4290, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3880.16, \"learn_time_ms\": 14866.264}", "{\"n\": 4291, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3892.73, \"learn_time_ms\": 14856.967}", "{\"n\": 4292, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3899.51, \"learn_time_ms\": 14845.802}", "{\"n\": 4293, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3900.08, \"learn_time_ms\": 14861.159}", "{\"n\": 4294, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3896.73, \"learn_time_ms\": 14851.374}", "{\"n\": 4295, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3899.16, \"learn_time_ms\": 14863.11}", "{\"n\": 4296, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3895.53, \"learn_time_ms\": 14869.882}", "{\"n\": 4297, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3895.53, \"learn_time_ms\": 14875.475}", "{\"n\": 4298, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3901.67, \"learn_time_ms\": 14865.974}", "{\"n\": 4299, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3897.27, \"learn_time_ms\": 14865.314}", "{\"n\": 4300, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3901.96, \"learn_time_ms\": 14854.114}", "{\"n\": 4301, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3913.71, \"learn_time_ms\": 14864.808}", "{\"n\": 4302, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3922.87, \"learn_time_ms\": 14884.366}", "{\"n\": 4303, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3922.87, \"learn_time_ms\": 14880.983}", "{\"n\": 4304, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3918.17, \"learn_time_ms\": 14876.988}", "{\"n\": 4305, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3918.17, \"learn_time_ms\": 14872.471}", "{\"n\": 4306, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3914.14, \"learn_time_ms\": 14879.856}", "{\"n\": 4307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3910.39, \"learn_time_ms\": 14873.15}", "{\"n\": 4308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3910.39, \"learn_time_ms\": 14867.122}", "{\"n\": 4309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3905.55, \"learn_time_ms\": 14868.266}", "{\"n\": 4310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3916.31, \"learn_time_ms\": 14878.912}", "{\"n\": 4311, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3916.31, \"learn_time_ms\": 14875.542}", "{\"n\": 4312, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3913.54, \"learn_time_ms\": 14865.165}", "{\"n\": 4313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3911.84, \"learn_time_ms\": 14865.178}", "{\"n\": 4314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3912.69, \"learn_time_ms\": 14867.423}", "{\"n\": 4315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3911.99, \"learn_time_ms\": 14861.537}", "{\"n\": 4316, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3908.12, \"learn_time_ms\": 14844.849}", "{\"n\": 4317, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3907.43, \"learn_time_ms\": 14851.259}", "{\"n\": 4318, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3907.43, \"learn_time_ms\": 14849.847}", "{\"n\": 4319, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3901.1, \"learn_time_ms\": 14847.06}", "{\"n\": 4320, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3905.63, \"learn_time_ms\": 14850.523}", "{\"n\": 4321, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3887.81, \"learn_time_ms\": 14844.702}", "{\"n\": 4322, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3881.26, \"learn_time_ms\": 14846.286}", "{\"n\": 4323, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3861.0, \"learn_time_ms\": 14836.656}", "{\"n\": 4324, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3861.0, \"learn_time_ms\": 14844.153}", "{\"n\": 4325, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3861.0, \"learn_time_ms\": 14837.385}", "{\"n\": 4326, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3860.5, \"learn_time_ms\": 14843.64}", "{\"n\": 4327, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3855.93, \"learn_time_ms\": 14823.607}", "{\"n\": 4328, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3856.09, \"learn_time_ms\": 14831.846}", "{\"n\": 4329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3853.6, \"learn_time_ms\": 14836.984}", "{\"n\": 4330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3853.6, \"learn_time_ms\": 14827.209}", "{\"n\": 4331, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3853.6, \"learn_time_ms\": 14826.13}", "{\"n\": 4332, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3849.39, \"learn_time_ms\": 14827.946}", "{\"n\": 4333, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3846.92, \"learn_time_ms\": 14824.518}", "{\"n\": 4334, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3843.85, \"learn_time_ms\": 14812.357}", "{\"n\": 4335, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3841.84, \"learn_time_ms\": 14825.086}", "{\"n\": 4336, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3853.9, \"learn_time_ms\": 14826.094}", "{\"n\": 4337, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3853.9, \"learn_time_ms\": 14819.879}", "{\"n\": 4338, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3853.9, \"learn_time_ms\": 14810.527}", "{\"n\": 4339, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3847.97, \"learn_time_ms\": 14804.504}", "{\"n\": 4340, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3844.44, \"learn_time_ms\": 14800.227}", "{\"n\": 4341, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3854.59, \"learn_time_ms\": 14796.052}", "{\"n\": 4342, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3841.85, \"learn_time_ms\": 14793.383}", "{\"n\": 4343, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3841.85, \"learn_time_ms\": 14787.14}", "{\"n\": 4344, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3837.17, \"learn_time_ms\": 14795.733}", "{\"n\": 4345, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3851.18, \"learn_time_ms\": 14785.09}", "{\"n\": 4346, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3845.67, \"learn_time_ms\": 14774.915}", "{\"n\": 4347, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3831.69, \"learn_time_ms\": 14803.225}", "{\"n\": 4348, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3844.21, \"learn_time_ms\": 14787.114}", "{\"n\": 4349, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3844.21, \"learn_time_ms\": 14793.363}", "{\"n\": 4350, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3839.13, \"learn_time_ms\": 14809.253}", "{\"n\": 4351, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3823.32, \"learn_time_ms\": 14817.152}", "{\"n\": 4352, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3829.11, \"learn_time_ms\": 14806.917}", "{\"n\": 4353, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3809.37, \"learn_time_ms\": 14829.257}", "{\"n\": 4354, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3821.7, \"learn_time_ms\": 14827.721}", "{\"n\": 4355, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3830.78, \"learn_time_ms\": 14836.135}", "{\"n\": 4356, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3830.78, \"learn_time_ms\": 14840.095}", "{\"n\": 4357, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3820.29, \"learn_time_ms\": 14832.665}", "{\"n\": 4358, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3820.29, \"learn_time_ms\": 14844.678}", "{\"n\": 4359, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3816.25, \"learn_time_ms\": 14849.755}", "{\"n\": 4360, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3810.01, \"learn_time_ms\": 14846.336}", "{\"n\": 4361, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3812.5, \"learn_time_ms\": 14836.695}", "{\"n\": 4362, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3812.5, \"learn_time_ms\": 14849.522}", "{\"n\": 4363, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3808.52, \"learn_time_ms\": 14826.89}", "{\"n\": 4364, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3808.52, \"learn_time_ms\": 14812.986}", "{\"n\": 4365, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3806.09, \"learn_time_ms\": 14814.277}", "{\"n\": 4366, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3806.09, \"learn_time_ms\": 14802.971}", "{\"n\": 4367, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3802.49, \"learn_time_ms\": 14792.528}", "{\"n\": 4368, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3814.91, \"learn_time_ms\": 14812.082}", "{\"n\": 4369, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3811.75, \"learn_time_ms\": 14805.153}", "{\"n\": 4370, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3811.75, \"learn_time_ms\": 14797.404}", "{\"n\": 4371, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3811.75, \"learn_time_ms\": 14804.708}", "{\"n\": 4372, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3809.58, \"learn_time_ms\": 14803.984}", "{\"n\": 4373, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3817.19, \"learn_time_ms\": 14809.702}", "{\"n\": 4374, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3812.46, \"learn_time_ms\": 14815.903}", "{\"n\": 4375, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3811.34, \"learn_time_ms\": 14799.287}", "{\"n\": 4376, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3811.34, \"learn_time_ms\": 14824.615}", "{\"n\": 4377, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3811.34, \"learn_time_ms\": 14827.319}", "{\"n\": 4378, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3822.22, \"learn_time_ms\": 14825.082}", "{\"n\": 4379, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3818.91, \"learn_time_ms\": 14803.506}", "{\"n\": 4380, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3819.29, \"learn_time_ms\": 14808.664}", "{\"n\": 4381, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3819.29, \"learn_time_ms\": 14798.863}", "{\"n\": 4382, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3827.25, \"learn_time_ms\": 14806.075}", "{\"n\": 4383, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3814.87, \"learn_time_ms\": 14813.85}", "{\"n\": 4384, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3803.03, \"learn_time_ms\": 14819.967}", "{\"n\": 4385, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3809.62, \"learn_time_ms\": 14846.328}", "{\"n\": 4386, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3809.62, \"learn_time_ms\": 14832.589}", "{\"n\": 4387, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3816.02, \"learn_time_ms\": 14852.065}", "{\"n\": 4388, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3816.02, \"learn_time_ms\": 14848.321}", "{\"n\": 4389, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3807.36, \"learn_time_ms\": 14868.303}", "{\"n\": 4390, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3792.6, \"learn_time_ms\": 14868.874}", "{\"n\": 4391, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3785.84, \"learn_time_ms\": 14875.991}", "{\"n\": 4392, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.18, \"learn_time_ms\": 14870.925}", "{\"n\": 4393, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.18, \"learn_time_ms\": 14878.158}", "{\"n\": 4394, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.18, \"learn_time_ms\": 14866.234}", "{\"n\": 4395, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.25, \"learn_time_ms\": 14866.662}", "{\"n\": 4396, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3789.26, \"learn_time_ms\": 14865.832}", "{\"n\": 4397, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3789.43, \"learn_time_ms\": 14845.895}", "{\"n\": 4398, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3789.43, \"learn_time_ms\": 14840.208}", "{\"n\": 4399, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.93, \"learn_time_ms\": 14845.98}", "{\"n\": 4400, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.93, \"learn_time_ms\": 14838.347}", "{\"n\": 4401, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.93, \"learn_time_ms\": 14827.94}", "{\"n\": 4402, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3771.61, \"learn_time_ms\": 14823.362}", "{\"n\": 4403, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3780.41, \"learn_time_ms\": 14809.764}", "{\"n\": 4404, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3780.41, \"learn_time_ms\": 14822.812}", "{\"n\": 4405, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.87, \"learn_time_ms\": 14800.784}", "{\"n\": 4406, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.87, \"learn_time_ms\": 14798.25}", "{\"n\": 4407, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.87, \"learn_time_ms\": 14802.689}", "{\"n\": 4408, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.87, \"learn_time_ms\": 14811.225}", "{\"n\": 4409, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.57, \"learn_time_ms\": 14808.31}", "{\"n\": 4410, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3799.44, \"learn_time_ms\": 14817.294}", "{\"n\": 4411, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3826.51, \"learn_time_ms\": 14822.206}", "{\"n\": 4412, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3826.51, \"learn_time_ms\": 14829.589}", "{\"n\": 4413, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3826.51, \"learn_time_ms\": 14828.879}", "{\"n\": 4414, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3826.51, \"learn_time_ms\": 14817.424}", "{\"n\": 4415, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3826.51, \"learn_time_ms\": 14808.778}", "{\"n\": 4416, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3836.25, \"learn_time_ms\": 14807.455}", "{\"n\": 4417, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3836.35, \"learn_time_ms\": 14811.106}", "{\"n\": 4418, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3840.26, \"learn_time_ms\": 14803.444}", "{\"n\": 4419, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3840.26, \"learn_time_ms\": 14799.896}", "{\"n\": 4420, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3840.26, \"learn_time_ms\": 14806.74}", "{\"n\": 4421, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3840.26, \"learn_time_ms\": 14820.351}", "{\"n\": 4422, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3825.37, \"learn_time_ms\": 14799.11}", "{\"n\": 4423, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3837.99, \"learn_time_ms\": 14808.958}", "{\"n\": 4424, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3840.17, \"learn_time_ms\": 14816.71}", "{\"n\": 4425, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3847.69, \"learn_time_ms\": 14831.745}", "{\"n\": 4426, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3847.69, \"learn_time_ms\": 14825.537}", "{\"n\": 4427, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3847.69, \"learn_time_ms\": 14837.564}", "{\"n\": 4428, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3831.25, \"learn_time_ms\": 14827.874}", "{\"n\": 4429, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3840.61, \"learn_time_ms\": 14838.047}", "{\"n\": 4430, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3865.23, \"learn_time_ms\": 14823.377}", "{\"n\": 4431, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3865.23, \"learn_time_ms\": 14810.936}", "{\"n\": 4432, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3864.57, \"learn_time_ms\": 14844.322}", "{\"n\": 4433, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3866.16, \"learn_time_ms\": 14848.382}", "{\"n\": 4434, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3832.02, \"learn_time_ms\": 14855.259}", "{\"n\": 4435, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3824.56, \"learn_time_ms\": 14869.194}", "{\"n\": 4436, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3821.3, \"learn_time_ms\": 14879.99}", "{\"n\": 4437, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3821.3, \"learn_time_ms\": 14862.042}", "{\"n\": 4438, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3830.47, \"learn_time_ms\": 14868.867}", "{\"n\": 4439, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3815.71, \"learn_time_ms\": 14853.405}", "{\"n\": 4440, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3815.71, \"learn_time_ms\": 14869.711}", "{\"n\": 4441, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3812.33, \"learn_time_ms\": 14879.572}", "{\"n\": 4442, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3806.29, \"learn_time_ms\": 14851.395}", "{\"n\": 4443, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3806.29, \"learn_time_ms\": 14848.169}", "{\"n\": 4444, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3799.85, \"learn_time_ms\": 14861.116}", "{\"n\": 4445, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.3, \"learn_time_ms\": 14857.63}", "{\"n\": 4446, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3789.18, \"learn_time_ms\": 14856.368}", "{\"n\": 4447, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3789.18, \"learn_time_ms\": 14868.676}", "{\"n\": 4448, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3779.89, \"learn_time_ms\": 14869.751}", "{\"n\": 4449, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3787.48, \"learn_time_ms\": 14875.784}", "{\"n\": 4450, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3787.48, \"learn_time_ms\": 14856.855}", "{\"n\": 4451, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3777.52, \"learn_time_ms\": 14846.558}", "{\"n\": 4452, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3777.52, \"learn_time_ms\": 14852.047}", "{\"n\": 4453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3761.64, \"learn_time_ms\": 14838.41}", "{\"n\": 4454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3770.4, \"learn_time_ms\": 14817.682}", "{\"n\": 4455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3754.25, \"learn_time_ms\": 14806.915}", "{\"n\": 4456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3757.92, \"learn_time_ms\": 14810.043}", "{\"n\": 4457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3755.18, \"learn_time_ms\": 14814.368}", "{\"n\": 4458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3767.65, \"learn_time_ms\": 14825.701}", "{\"n\": 4459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3767.65, \"learn_time_ms\": 14821.286}", "{\"n\": 4460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3761.6, \"learn_time_ms\": 14817.662}", "{\"n\": 4461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3761.6, \"learn_time_ms\": 14830.272}", "{\"n\": 4462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3763.27, \"learn_time_ms\": 14842.24}", "{\"n\": 4463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3791.1, \"learn_time_ms\": 14856.666}", "{\"n\": 4464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3796.85, \"learn_time_ms\": 14873.004}", "{\"n\": 4465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3795.02, \"learn_time_ms\": 14887.372}", "{\"n\": 4466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3795.02, \"learn_time_ms\": 14890.19}", "{\"n\": 4467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3795.02, \"learn_time_ms\": 14876.674}", "{\"n\": 4468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3811.9, \"learn_time_ms\": 14861.099}", "{\"n\": 4469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3818.21, \"learn_time_ms\": 14864.875}", "{\"n\": 4470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3837.39, \"learn_time_ms\": 14877.867}", "{\"n\": 4471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3832.19, \"learn_time_ms\": 14876.072}", "{\"n\": 4472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3832.19, \"learn_time_ms\": 14878.183}", "{\"n\": 4473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3832.19, \"learn_time_ms\": 14861.017}", "{\"n\": 4474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3835.78, \"learn_time_ms\": 14847.436}", "{\"n\": 4475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3810.06, \"learn_time_ms\": 14834.781}", "{\"n\": 4476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3807.22, \"learn_time_ms\": 14830.707}", "{\"n\": 4477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3812.7, \"learn_time_ms\": 14831.986}", "{\"n\": 4478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3824.25, \"learn_time_ms\": 14844.072}", "{\"n\": 4479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3822.42, \"learn_time_ms\": 14852.197}", "{\"n\": 4480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3822.42, \"learn_time_ms\": 14855.173}", "{\"n\": 4481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3812.57, \"learn_time_ms\": 14850.049}", "{\"n\": 4482, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3802.17, \"learn_time_ms\": 14834.737}", "{\"n\": 4483, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3792.58, \"learn_time_ms\": 14844.432}", "{\"n\": 4484, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3796.27, \"learn_time_ms\": 14842.069}", "{\"n\": 4485, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3781.5, \"learn_time_ms\": 14845.32}", "{\"n\": 4486, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3781.5, \"learn_time_ms\": 14845.456}", "{\"n\": 4487, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3787.48, \"learn_time_ms\": 14856.195}", "{\"n\": 4488, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3777.44, \"learn_time_ms\": 14867.304}", "{\"n\": 4489, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3777.44, \"learn_time_ms\": 14868.003}", "{\"n\": 4490, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3764.09, \"learn_time_ms\": 14863.191}", "{\"n\": 4491, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3747.85, \"learn_time_ms\": 14870.351}", "{\"n\": 4492, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3747.85, \"learn_time_ms\": 14880.813}", "{\"n\": 4493, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3744.81, \"learn_time_ms\": 14877.839}", "{\"n\": 4494, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3744.81, \"learn_time_ms\": 14883.464}", "{\"n\": 4495, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3726.93, \"learn_time_ms\": 14867.313}", "{\"n\": 4496, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3726.93, \"learn_time_ms\": 14869.092}", "{\"n\": 4497, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3722.63, \"learn_time_ms\": 14867.44}", "{\"n\": 4498, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3717.65, \"learn_time_ms\": 14847.413}", "{\"n\": 4499, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3709.18, \"learn_time_ms\": 14834.226}", "{\"n\": 4500, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3709.18, \"learn_time_ms\": 14824.184}", "{\"n\": 4501, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3704.09, \"learn_time_ms\": 14818.384}", "{\"n\": 4502, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3711.67, \"learn_time_ms\": 14816.985}", "{\"n\": 4503, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3711.67, \"learn_time_ms\": 14811.865}", "{\"n\": 4504, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3711.67, \"learn_time_ms\": 14814.223}", "{\"n\": 4505, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3729.81, \"learn_time_ms\": 14850.065}", "{\"n\": 4506, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3731.62, \"learn_time_ms\": 14849.057}", "{\"n\": 4507, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3730.03, \"learn_time_ms\": 14842.261}", "{\"n\": 4508, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3716.98, \"learn_time_ms\": 14853.69}", "{\"n\": 4509, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3720.48, \"learn_time_ms\": 14860.34}", "{\"n\": 4510, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3720.48, \"learn_time_ms\": 14881.674}", "{\"n\": 4511, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3720.48, \"learn_time_ms\": 14875.397}", "{\"n\": 4512, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3735.74, \"learn_time_ms\": 14884.454}", "{\"n\": 4513, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3735.74, \"learn_time_ms\": 14904.128}", "{\"n\": 4514, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3746.82, \"learn_time_ms\": 14899.583}", "{\"n\": 4515, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3746.82, \"learn_time_ms\": 14885.907}", "{\"n\": 4516, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3746.82, \"learn_time_ms\": 14882.858}", "{\"n\": 4517, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3759.78, \"learn_time_ms\": 14880.587}", "{\"n\": 4518, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3757.71, \"learn_time_ms\": 14871.987}", "{\"n\": 4519, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3777.28, \"learn_time_ms\": 14887.025}", "{\"n\": 4520, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3774.18, \"learn_time_ms\": 14883.459}", "{\"n\": 4521, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3774.18, \"learn_time_ms\": 14900.082}", "{\"n\": 4522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3774.18, \"learn_time_ms\": 14885.923}", "{\"n\": 4523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3758.9, \"learn_time_ms\": 14881.687}", "{\"n\": 4524, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3765.55, \"learn_time_ms\": 14892.629}", "{\"n\": 4525, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3752.27, \"learn_time_ms\": 14880.44}", "{\"n\": 4526, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3755.75, \"learn_time_ms\": 14880.297}", "{\"n\": 4527, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3746.93, \"learn_time_ms\": 14877.619}", "{\"n\": 4528, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3746.93, \"learn_time_ms\": 14878.584}", "{\"n\": 4529, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3755.37, \"learn_time_ms\": 14855.364}", "{\"n\": 4530, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3751.27, \"learn_time_ms\": 14848.676}", "{\"n\": 4531, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3755.76, \"learn_time_ms\": 14837.642}", "{\"n\": 4532, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3775.88, \"learn_time_ms\": 14852.42}", "{\"n\": 4533, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3785.27, \"learn_time_ms\": 14841.331}", "{\"n\": 4534, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3781.36, \"learn_time_ms\": 14823.148}", "{\"n\": 4535, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3781.64, \"learn_time_ms\": 14834.708}", "{\"n\": 4536, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.03, \"learn_time_ms\": 14826.011}", "{\"n\": 4537, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.62, \"learn_time_ms\": 14829.663}", "{\"n\": 4538, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.62, \"learn_time_ms\": 14843.828}", "{\"n\": 4539, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3781.57, \"learn_time_ms\": 14859.864}", "{\"n\": 4540, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3784.34, \"learn_time_ms\": 14865.975}", "{\"n\": 4541, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3784.34, \"learn_time_ms\": 14857.403}", "{\"n\": 4542, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3771.27, \"learn_time_ms\": 14844.922}", "{\"n\": 4543, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3765.11, \"learn_time_ms\": 14839.904}", "{\"n\": 4544, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3761.21, \"learn_time_ms\": 14843.711}", "{\"n\": 4545, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3761.21, \"learn_time_ms\": 14832.912}", "{\"n\": 4546, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3760.82, \"learn_time_ms\": 14847.63}", "{\"n\": 4547, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3758.82, \"learn_time_ms\": 14851.077}", "{\"n\": 4548, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3759.14, \"learn_time_ms\": 14829.286}", "{\"n\": 4549, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3770.99, \"learn_time_ms\": 14818.786}", "{\"n\": 4550, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3765.01, \"learn_time_ms\": 14811.873}", "{\"n\": 4551, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3761.56, \"learn_time_ms\": 14816.414}", "{\"n\": 4552, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3761.56, \"learn_time_ms\": 14820.753}", "{\"n\": 4553, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3760.94, \"learn_time_ms\": 14819.293}", "{\"n\": 4554, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3790.98, \"learn_time_ms\": 14829.627}", "{\"n\": 4555, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3787.73, \"learn_time_ms\": 14843.191}", "{\"n\": 4556, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3778.64, \"learn_time_ms\": 14838.113}", "{\"n\": 4557, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3775.15, \"learn_time_ms\": 14833.554}", "{\"n\": 4558, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3775.15, \"learn_time_ms\": 14842.744}", "{\"n\": 4559, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3775.15, \"learn_time_ms\": 14842.223}", "{\"n\": 4560, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3780.51, \"learn_time_ms\": 14851.145}", "{\"n\": 4561, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3787.88, \"learn_time_ms\": 14847.664}", "{\"n\": 4562, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3791.54, \"learn_time_ms\": 14851.301}", "{\"n\": 4563, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3782.23, \"learn_time_ms\": 14853.035}", "{\"n\": 4564, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3782.23, \"learn_time_ms\": 14842.471}", "{\"n\": 4565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3793.2, \"learn_time_ms\": 14842.523}", "{\"n\": 4566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3793.2, \"learn_time_ms\": 14849.422}", "{\"n\": 4567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3801.51, \"learn_time_ms\": 14855.125}", "{\"n\": 4568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3810.2, \"learn_time_ms\": 14851.456}", "{\"n\": 4569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3817.78, \"learn_time_ms\": 14854.671}", "{\"n\": 4570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3836.3, \"learn_time_ms\": 14847.262}", "{\"n\": 4571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3836.3, \"learn_time_ms\": 14852.179}", "{\"n\": 4572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3836.3, \"learn_time_ms\": 14848.361}", "{\"n\": 4573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3836.3, \"learn_time_ms\": 14849.521}", "{\"n\": 4574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3832.34, \"learn_time_ms\": 14847.571}", "{\"n\": 4575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3850.41, \"learn_time_ms\": 14848.321}", "{\"n\": 4576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3859.49, \"learn_time_ms\": 14860.941}", "{\"n\": 4577, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3873.05, \"learn_time_ms\": 14869.509}", "{\"n\": 4578, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3867.04, \"learn_time_ms\": 14879.876}", "{\"n\": 4579, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3870.36, \"learn_time_ms\": 14877.23}", "{\"n\": 4580, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3871.6, \"learn_time_ms\": 14879.521}", "{\"n\": 4581, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3871.6, \"learn_time_ms\": 14882.527}", "{\"n\": 4582, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3860.8, \"learn_time_ms\": 14873.984}", "{\"n\": 4583, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3860.47, \"learn_time_ms\": 14890.66}", "{\"n\": 4584, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3843.14, \"learn_time_ms\": 14886.726}", "{\"n\": 4585, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3851.09, \"learn_time_ms\": 14880.937}", "{\"n\": 4586, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3851.09, \"learn_time_ms\": 14873.769}", "{\"n\": 4587, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3849.85, \"learn_time_ms\": 14863.963}", "{\"n\": 4588, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3853.46, \"learn_time_ms\": 14849.183}", "{\"n\": 4589, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3857.87, \"learn_time_ms\": 14826.265}", "{\"n\": 4590, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3860.71, \"learn_time_ms\": 14818.058}", "{\"n\": 4591, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3867.56, \"learn_time_ms\": 14825.673}", "{\"n\": 4592, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3867.56, \"learn_time_ms\": 14829.455}", "{\"n\": 4593, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3856.9, \"learn_time_ms\": 14822.194}", "{\"n\": 4594, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3849.59, \"learn_time_ms\": 14850.197}", "{\"n\": 4595, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3848.45, \"learn_time_ms\": 14862.428}", "{\"n\": 4596, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3852.73, \"learn_time_ms\": 14851.91}", "{\"n\": 4597, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3831.9, \"learn_time_ms\": 14851.285}", "{\"n\": 4598, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3842.0, \"learn_time_ms\": 14851.416}", "{\"n\": 4599, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3842.0, \"learn_time_ms\": 14882.825}", "{\"n\": 4600, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3842.43, \"learn_time_ms\": 14894.483}", "{\"n\": 4601, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3834.09, \"learn_time_ms\": 14875.862}", "{\"n\": 4602, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3843.26, \"learn_time_ms\": 14871.799}", "{\"n\": 4603, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3843.97, \"learn_time_ms\": 14878.28}", "{\"n\": 4604, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3860.55, \"learn_time_ms\": 14865.591}", "{\"n\": 4605, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3860.55, \"learn_time_ms\": 14851.196}", "{\"n\": 4606, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3860.55, \"learn_time_ms\": 14852.679}", "{\"n\": 4607, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3848.95, \"learn_time_ms\": 14847.217}", "{\"n\": 4608, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3866.63, \"learn_time_ms\": 14861.538}", "{\"n\": 4609, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3866.63, \"learn_time_ms\": 14846.042}", "{\"n\": 4610, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3879.62, \"learn_time_ms\": 14833.694}", "{\"n\": 4611, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3862.05, \"learn_time_ms\": 14846.969}", "{\"n\": 4612, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3862.05, \"learn_time_ms\": 14850.916}", "{\"n\": 4613, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3850.13, \"learn_time_ms\": 14846.279}", "{\"n\": 4614, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3852.44, \"learn_time_ms\": 14836.465}", "{\"n\": 4615, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3847.13, \"learn_time_ms\": 14830.974}", "{\"n\": 4616, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3856.43, \"learn_time_ms\": 14827.281}", "{\"n\": 4617, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3856.08, \"learn_time_ms\": 14833.842}", "{\"n\": 4618, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3827.06, \"learn_time_ms\": 14813.163}", "{\"n\": 4619, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3827.06, \"learn_time_ms\": 14820.054}", "{\"n\": 4620, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3827.06, \"learn_time_ms\": 14847.816}", "{\"n\": 4621, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3812.68, \"learn_time_ms\": 14854.361}", "{\"n\": 4622, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3796.71, \"learn_time_ms\": 14847.205}", "{\"n\": 4623, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3796.71, \"learn_time_ms\": 14851.648}", "{\"n\": 4624, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3796.71, \"learn_time_ms\": 14849.904}", "{\"n\": 4625, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3776.68, \"learn_time_ms\": 14845.934}", "{\"n\": 4626, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3776.68, \"learn_time_ms\": 14848.841}", "{\"n\": 4627, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3782.98, \"learn_time_ms\": 14840.77}", "{\"n\": 4628, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3778.25, \"learn_time_ms\": 14856.435}", "{\"n\": 4629, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3778.25, \"learn_time_ms\": 14858.345}", "{\"n\": 4630, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3780.32, \"learn_time_ms\": 14840.581}", "{\"n\": 4631, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3784.06, \"learn_time_ms\": 14831.755}", "{\"n\": 4632, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3784.06, \"learn_time_ms\": 14837.438}", "{\"n\": 4633, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3784.06, \"learn_time_ms\": 14827.714}", "{\"n\": 4634, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3772.4, \"learn_time_ms\": 14839.169}", "{\"n\": 4635, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3769.85, \"learn_time_ms\": 14831.284}", "{\"n\": 4636, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3769.85, \"learn_time_ms\": 14829.592}", "{\"n\": 4637, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3794.58, \"learn_time_ms\": 14819.417}", "{\"n\": 4638, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3794.58, \"learn_time_ms\": 14828.43}", "{\"n\": 4639, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3775.98, \"learn_time_ms\": 14818.499}", "{\"n\": 4640, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3773.29, \"learn_time_ms\": 14811.205}", "{\"n\": 4641, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3767.01, \"learn_time_ms\": 14805.76}", "{\"n\": 4642, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3770.47, \"learn_time_ms\": 14818.555}", "{\"n\": 4643, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3769.77, \"learn_time_ms\": 14826.343}", "{\"n\": 4644, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3769.77, \"learn_time_ms\": 14823.018}", "{\"n\": 4645, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3769.77, \"learn_time_ms\": 14844.688}", "{\"n\": 4646, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3758.07, \"learn_time_ms\": 14845.778}", "{\"n\": 4647, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3727.25, \"learn_time_ms\": 14868.57}", "{\"n\": 4648, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3727.25, \"learn_time_ms\": 14859.853}", "{\"n\": 4649, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3725.18, \"learn_time_ms\": 14860.894}", "{\"n\": 4650, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3730.44, \"learn_time_ms\": 14876.957}", "{\"n\": 4651, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3730.44, \"learn_time_ms\": 14880.662}", "{\"n\": 4652, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3723.14, \"learn_time_ms\": 14874.785}", "{\"n\": 4653, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3730.16, \"learn_time_ms\": 14868.924}", "{\"n\": 4654, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3725.36, \"learn_time_ms\": 14866.982}", "{\"n\": 4655, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3725.36, \"learn_time_ms\": 14871.368}", "{\"n\": 4656, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.62, \"learn_time_ms\": 14871.508}", "{\"n\": 4657, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.62, \"learn_time_ms\": 14858.915}", "{\"n\": 4658, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.62, \"learn_time_ms\": 14850.991}", "{\"n\": 4659, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3727.64, \"learn_time_ms\": 14862.854}", "{\"n\": 4660, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3713.1, \"learn_time_ms\": 14861.867}", "{\"n\": 4661, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3716.5, \"learn_time_ms\": 14868.992}", "{\"n\": 4662, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3726.59, \"learn_time_ms\": 14865.598}", "{\"n\": 4663, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3714.64, \"learn_time_ms\": 14872.186}", "{\"n\": 4664, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3721.22, \"learn_time_ms\": 14882.085}", "{\"n\": 4665, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3721.62, \"learn_time_ms\": 14884.51}", "{\"n\": 4666, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3721.62, \"learn_time_ms\": 14881.93}", "{\"n\": 4667, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3724.81, \"learn_time_ms\": 14888.611}", "{\"n\": 4668, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3736.6, \"learn_time_ms\": 14882.921}", "{\"n\": 4669, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3728.89, \"learn_time_ms\": 14888.007}", "{\"n\": 4670, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3730.86, \"learn_time_ms\": 14863.135}", "{\"n\": 4671, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3730.86, \"learn_time_ms\": 14857.185}", "{\"n\": 4672, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3724.6, \"learn_time_ms\": 14863.597}", "{\"n\": 4673, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3724.6, \"learn_time_ms\": 14855.497}", "{\"n\": 4674, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3733.63, \"learn_time_ms\": 14853.52}", "{\"n\": 4675, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3731.78, \"learn_time_ms\": 14837.506}", "{\"n\": 4676, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3734.77, \"learn_time_ms\": 14835.142}", "{\"n\": 4677, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3734.77, \"learn_time_ms\": 14822.601}", "{\"n\": 4678, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3736.51, \"learn_time_ms\": 14851.466}", "{\"n\": 4679, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3736.51, \"learn_time_ms\": 14850.134}", "{\"n\": 4680, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3730.99, \"learn_time_ms\": 14875.695}", "{\"n\": 4681, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3706.92, \"learn_time_ms\": 14885.062}", "{\"n\": 4682, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3706.92, \"learn_time_ms\": 14876.682}", "{\"n\": 4683, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3703.98, \"learn_time_ms\": 14879.839}", "{\"n\": 4684, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3722.15, \"learn_time_ms\": 14878.158}", "{\"n\": 4685, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3723.34, \"learn_time_ms\": 14884.247}", "{\"n\": 4686, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3711.76, \"learn_time_ms\": 14887.906}", "{\"n\": 4687, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3711.76, \"learn_time_ms\": 14904.69}", "{\"n\": 4688, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3723.79, \"learn_time_ms\": 14892.809}", "{\"n\": 4689, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3723.44, \"learn_time_ms\": 14879.424}", "{\"n\": 4690, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3723.44, \"learn_time_ms\": 14864.111}", "{\"n\": 4691, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3723.74, \"learn_time_ms\": 14859.739}", "{\"n\": 4692, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3718.94, \"learn_time_ms\": 14866.764}", "{\"n\": 4693, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3725.51, \"learn_time_ms\": 14862.791}", "{\"n\": 4694, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3708.62, \"learn_time_ms\": 14861.042}", "{\"n\": 4695, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3719.81, \"learn_time_ms\": 14866.352}", "{\"n\": 4696, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3719.81, \"learn_time_ms\": 14871.541}", "{\"n\": 4697, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3719.81, \"learn_time_ms\": 14876.154}", "{\"n\": 4698, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3717.34, \"learn_time_ms\": 14867.746}", "{\"n\": 4699, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3729.03, \"learn_time_ms\": 14873.834}", "{\"n\": 4700, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3729.03, \"learn_time_ms\": 14879.544}", "{\"n\": 4701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3731.84, \"learn_time_ms\": 14875.942}", "{\"n\": 4702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3749.84, \"learn_time_ms\": 14867.9}", "{\"n\": 4703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3749.84, \"learn_time_ms\": 14869.052}", "{\"n\": 4704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3745.75, \"learn_time_ms\": 14868.963}", "{\"n\": 4705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3763.25, \"learn_time_ms\": 14875.214}", "{\"n\": 4706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3753.14, \"learn_time_ms\": 14870.677}", "{\"n\": 4707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3753.14, \"learn_time_ms\": 14856.224}", "{\"n\": 4708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3745.2, \"learn_time_ms\": 14857.118}", "{\"n\": 4709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3737.97, \"learn_time_ms\": 14867.472}", "{\"n\": 4710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3741.29, \"learn_time_ms\": 14865.318}", "{\"n\": 4711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3741.29, \"learn_time_ms\": 14860.885}", "{\"n\": 4712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3735.73, \"learn_time_ms\": 14862.611}", "{\"n\": 4713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3735.73, \"learn_time_ms\": 14847.841}", "{\"n\": 4714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3733.38, \"learn_time_ms\": 14846.343}", "{\"n\": 4715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3717.37, \"learn_time_ms\": 14837.727}", "{\"n\": 4716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3717.37, \"learn_time_ms\": 14838.806}", "{\"n\": 4717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3725.6, \"learn_time_ms\": 14833.37}", "{\"n\": 4718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3724.01, \"learn_time_ms\": 14831.831}", "{\"n\": 4719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3735.5, \"learn_time_ms\": 14837.168}", "{\"n\": 4720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3719.56, \"learn_time_ms\": 14816.86}", "{\"n\": 4721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3727.65, \"learn_time_ms\": 14817.499}", "{\"n\": 4722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3727.65, \"learn_time_ms\": 14821.786}", "{\"n\": 4723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3738.95, \"learn_time_ms\": 14849.833}", "{\"n\": 4724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3756.97, \"learn_time_ms\": 14843.254}", "{\"n\": 4725, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3756.97, \"learn_time_ms\": 14843.953}", "{\"n\": 4726, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3746.94, \"learn_time_ms\": 14845.927}", "{\"n\": 4727, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3745.42, \"learn_time_ms\": 14851.278}", "{\"n\": 4728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3727.59, \"learn_time_ms\": 14859.886}", "{\"n\": 4729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3724.81, \"learn_time_ms\": 14830.48}", "{\"n\": 4730, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3713.87, \"learn_time_ms\": 14846.025}", "{\"n\": 4731, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3709.62, \"learn_time_ms\": 14839.017}", "{\"n\": 4732, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3709.62, \"learn_time_ms\": 14842.253}", "{\"n\": 4733, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3707.11, \"learn_time_ms\": 14834.276}", "{\"n\": 4734, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3707.24, \"learn_time_ms\": 14830.356}", "{\"n\": 4735, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3701.44, \"learn_time_ms\": 14810.594}", "{\"n\": 4736, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3708.16, \"learn_time_ms\": 14816.466}", "{\"n\": 4737, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3694.7, \"learn_time_ms\": 14817.23}", "{\"n\": 4738, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3694.7, \"learn_time_ms\": 14807.826}", "{\"n\": 4739, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3695.77, \"learn_time_ms\": 14824.612}", "{\"n\": 4740, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3690.0, \"learn_time_ms\": 14826.293}", "{\"n\": 4741, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3690.0, \"learn_time_ms\": 14834.523}", "{\"n\": 4742, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3682.65, \"learn_time_ms\": 14837.541}", "{\"n\": 4743, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3682.65, \"learn_time_ms\": 14840.98}", "{\"n\": 4744, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3651.65, \"learn_time_ms\": 14853.125}", "{\"n\": 4745, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3662.08, \"learn_time_ms\": 14855.109}", "{\"n\": 4746, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3657.31, \"learn_time_ms\": 14836.874}", "{\"n\": 4747, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3657.48, \"learn_time_ms\": 14837.932}", "{\"n\": 4748, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3656.93, \"learn_time_ms\": 14843.61}", "{\"n\": 4749, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3668.35, \"learn_time_ms\": 14842.613}", "{\"n\": 4750, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3663.49, \"learn_time_ms\": 14845.887}", "{\"n\": 4751, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3653.52, \"learn_time_ms\": 14854.083}", "{\"n\": 4752, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3653.52, \"learn_time_ms\": 14842.117}", "{\"n\": 4753, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3663.43, \"learn_time_ms\": 14841.192}", "{\"n\": 4754, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3663.43, \"learn_time_ms\": 14835.405}", "{\"n\": 4755, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3666.33, \"learn_time_ms\": 14843.499}", "{\"n\": 4756, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3667.1, \"learn_time_ms\": 14859.996}", "{\"n\": 4757, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3655.57, \"learn_time_ms\": 14865.263}", "{\"n\": 4758, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3655.57, \"learn_time_ms\": 14869.534}", "{\"n\": 4759, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3655.57, \"learn_time_ms\": 14876.57}", "{\"n\": 4760, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3646.31, \"learn_time_ms\": 14886.901}", "{\"n\": 4761, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3638.17, \"learn_time_ms\": 14882.653}", "{\"n\": 4762, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3637.5, \"learn_time_ms\": 14883.482}", "{\"n\": 4763, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3623.55, \"learn_time_ms\": 14869.918}", "{\"n\": 4764, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3620.19, \"learn_time_ms\": 14871.237}", "{\"n\": 4765, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3623.37, \"learn_time_ms\": 14877.557}", "{\"n\": 4766, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3623.2, \"learn_time_ms\": 14877.081}", "{\"n\": 4767, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3629.19, \"learn_time_ms\": 14875.665}", "{\"n\": 4768, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3629.19, \"learn_time_ms\": 14860.292}", "{\"n\": 4769, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3629.93, \"learn_time_ms\": 14850.302}", "{\"n\": 4770, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3642.78, \"learn_time_ms\": 14843.306}", "{\"n\": 4771, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3646.61, \"learn_time_ms\": 14835.177}", "{\"n\": 4772, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3655.83, \"learn_time_ms\": 14851.402}", "{\"n\": 4773, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3661.27, \"learn_time_ms\": 14846.96}", "{\"n\": 4774, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3661.27, \"learn_time_ms\": 14846.297}", "{\"n\": 4775, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3660.43, \"learn_time_ms\": 14851.642}", "{\"n\": 4776, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3661.57, \"learn_time_ms\": 14833.339}", "{\"n\": 4777, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3664.04, \"learn_time_ms\": 14828.137}", "{\"n\": 4778, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3671.61, \"learn_time_ms\": 14838.175}", "{\"n\": 4779, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3664.42, \"learn_time_ms\": 14846.88}", "{\"n\": 4780, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.95, \"learn_time_ms\": 14830.767}", "{\"n\": 4781, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.95, \"learn_time_ms\": 14821.414}", "{\"n\": 4782, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3637.67, \"learn_time_ms\": 14813.846}", "{\"n\": 4783, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3647.87, \"learn_time_ms\": 14840.95}", "{\"n\": 4784, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3647.87, \"learn_time_ms\": 14845.831}", "{\"n\": 4785, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3651.14, \"learn_time_ms\": 14836.533}", "{\"n\": 4786, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3652.42, \"learn_time_ms\": 14843.424}", "{\"n\": 4787, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.15, \"learn_time_ms\": 14842.669}", "{\"n\": 4788, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3649.81, \"learn_time_ms\": 14833.449}", "{\"n\": 4789, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3638.81, \"learn_time_ms\": 14811.04}", "{\"n\": 4790, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3643.86, \"learn_time_ms\": 14824.561}", "{\"n\": 4791, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3643.86, \"learn_time_ms\": 14842.765}", "{\"n\": 4792, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3647.47, \"learn_time_ms\": 14833.69}", "{\"n\": 4793, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3647.47, \"learn_time_ms\": 14814.923}", "{\"n\": 4794, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3662.5, \"learn_time_ms\": 14818.024}", "{\"n\": 4795, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3650.76, \"learn_time_ms\": 14813.252}", "{\"n\": 4796, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3655.16, \"learn_time_ms\": 14817.159}", "{\"n\": 4797, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3655.16, \"learn_time_ms\": 14816.44}", "{\"n\": 4798, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3642.03, \"learn_time_ms\": 14830.045}", "{\"n\": 4799, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3636.84, \"learn_time_ms\": 14846.512}", "{\"n\": 4800, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3625.98, \"learn_time_ms\": 14842.125}", "{\"n\": 4801, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3627.38, \"learn_time_ms\": 14850.472}", "{\"n\": 4802, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3627.38, \"learn_time_ms\": 14849.939}", "{\"n\": 4803, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3627.38, \"learn_time_ms\": 14853.448}", "{\"n\": 4804, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3656.89, \"learn_time_ms\": 14843.738}", "{\"n\": 4805, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3657.59, \"learn_time_ms\": 14843.809}", "{\"n\": 4806, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3642.81, \"learn_time_ms\": 14841.283}", "{\"n\": 4807, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3642.81, \"learn_time_ms\": 14841.728}", "{\"n\": 4808, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3640.4, \"learn_time_ms\": 14844.645}", "{\"n\": 4809, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3640.4, \"learn_time_ms\": 14842.495}", "{\"n\": 4810, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3629.96, \"learn_time_ms\": 14833.189}", "{\"n\": 4811, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.39, \"learn_time_ms\": 14820.865}", "{\"n\": 4812, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.39, \"learn_time_ms\": 14815.283}", "{\"n\": 4813, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3643.75, \"learn_time_ms\": 14814.331}", "{\"n\": 4814, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3650.27, \"learn_time_ms\": 14824.681}", "{\"n\": 4815, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3650.27, \"learn_time_ms\": 14838.089}", "{\"n\": 4816, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3658.41, \"learn_time_ms\": 14841.598}", "{\"n\": 4817, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3650.96, \"learn_time_ms\": 14842.76}", "{\"n\": 4818, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3661.38, \"learn_time_ms\": 14818.792}", "{\"n\": 4819, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3661.38, \"learn_time_ms\": 14812.411}", "{\"n\": 4820, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3689.3, \"learn_time_ms\": 14832.031}", "{\"n\": 4821, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3700.91, \"learn_time_ms\": 14839.879}", "{\"n\": 4822, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3700.91, \"learn_time_ms\": 14842.694}", "{\"n\": 4823, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3705.91, \"learn_time_ms\": 14837.233}", "{\"n\": 4824, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.35, \"learn_time_ms\": 14844.614}", "{\"n\": 4825, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.35, \"learn_time_ms\": 14850.228}", "{\"n\": 4826, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.35, \"learn_time_ms\": 14862.011}", "{\"n\": 4827, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3737.4, \"learn_time_ms\": 14882.055}", "{\"n\": 4828, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3741.84, \"learn_time_ms\": 14902.368}", "{\"n\": 4829, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3745.39, \"learn_time_ms\": 14924.006}", "{\"n\": 4830, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.3, \"learn_time_ms\": 14913.063}", "{\"n\": 4831, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.3, \"learn_time_ms\": 14899.893}", "{\"n\": 4832, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.36, \"learn_time_ms\": 14900.968}", "{\"n\": 4833, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.36, \"learn_time_ms\": 14918.072}", "{\"n\": 4834, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3768.1, \"learn_time_ms\": 14911.359}", "{\"n\": 4835, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3776.94, \"learn_time_ms\": 14899.325}", "{\"n\": 4836, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3789.06, \"learn_time_ms\": 14880.259}", "{\"n\": 4837, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3789.06, \"learn_time_ms\": 14876.779}", "{\"n\": 4838, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3789.06, \"learn_time_ms\": 14873.2}", "{\"n\": 4839, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.57, \"learn_time_ms\": 14860.451}", "{\"n\": 4840, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.57, \"learn_time_ms\": 14865.884}", "{\"n\": 4841, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3793.03, \"learn_time_ms\": 14859.371}", "{\"n\": 4842, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3792.24, \"learn_time_ms\": 14875.256}", "{\"n\": 4843, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3801.0, \"learn_time_ms\": 14861.0}", "{\"n\": 4844, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3797.47, \"learn_time_ms\": 14861.054}", "{\"n\": 4845, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3797.47, \"learn_time_ms\": 14855.905}", "{\"n\": 4846, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3803.94, \"learn_time_ms\": 14865.156}", "{\"n\": 4847, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3808.91, \"learn_time_ms\": 14856.792}", "{\"n\": 4848, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3803.27, \"learn_time_ms\": 14850.519}", "{\"n\": 4849, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3810.61, \"learn_time_ms\": 14856.749}", "{\"n\": 4850, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3810.61, \"learn_time_ms\": 14862.086}", "{\"n\": 4851, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.85, \"learn_time_ms\": 14881.101}", "{\"n\": 4852, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.85, \"learn_time_ms\": 14881.085}", "{\"n\": 4853, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.85, \"learn_time_ms\": 14895.28}", "{\"n\": 4854, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3801.75, \"learn_time_ms\": 14878.752}", "{\"n\": 4855, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3828.91, \"learn_time_ms\": 14890.167}", "{\"n\": 4856, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3830.3, \"learn_time_ms\": 14883.101}", "{\"n\": 4857, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3830.3, \"learn_time_ms\": 14883.689}", "{\"n\": 4858, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3830.3, \"learn_time_ms\": 14893.737}", "{\"n\": 4859, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3837.89, \"learn_time_ms\": 14870.255}", "{\"n\": 4860, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3837.89, \"learn_time_ms\": 14857.802}", "{\"n\": 4861, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3850.85, \"learn_time_ms\": 14861.464}", "{\"n\": 4862, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3857.38, \"learn_time_ms\": 14850.145}", "{\"n\": 4863, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3875.27, \"learn_time_ms\": 14844.662}", "{\"n\": 4864, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3875.27, \"learn_time_ms\": 14855.511}", "{\"n\": 4865, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3875.27, \"learn_time_ms\": 14849.254}", "{\"n\": 4866, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3875.27, \"learn_time_ms\": 14856.492}", "{\"n\": 4867, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3867.86, \"learn_time_ms\": 14852.748}", "{\"n\": 4868, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3871.32, \"learn_time_ms\": 14834.294}", "{\"n\": 4869, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3886.16, \"learn_time_ms\": 14858.197}", "{\"n\": 4870, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3894.29, \"learn_time_ms\": 14875.814}", "{\"n\": 4871, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3894.29, \"learn_time_ms\": 14861.973}", "{\"n\": 4872, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3894.29, \"learn_time_ms\": 14855.101}", "{\"n\": 4873, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3892.31, \"learn_time_ms\": 14846.135}", "{\"n\": 4874, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3899.04, \"learn_time_ms\": 14854.232}", "{\"n\": 4875, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3898.05, \"learn_time_ms\": 14865.012}", "{\"n\": 4876, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3914.62, \"learn_time_ms\": 14857.196}", "{\"n\": 4877, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3915.59, \"learn_time_ms\": 14845.35}", "{\"n\": 4878, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3915.59, \"learn_time_ms\": 14873.532}", "{\"n\": 4879, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3915.59, \"learn_time_ms\": 14866.168}", "{\"n\": 4880, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3919.96, \"learn_time_ms\": 14854.927}", "{\"n\": 4881, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3920.92, \"learn_time_ms\": 14847.321}", "{\"n\": 4882, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3923.01, \"learn_time_ms\": 14856.207}", "{\"n\": 4883, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3940.96, \"learn_time_ms\": 14858.357}", "{\"n\": 4884, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3937.16, \"learn_time_ms\": 14852.585}", "{\"n\": 4885, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3937.16, \"learn_time_ms\": 14853.931}", "{\"n\": 4886, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3941.07, \"learn_time_ms\": 14857.552}", "{\"n\": 4887, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3941.43, \"learn_time_ms\": 14873.132}", "{\"n\": 4888, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3941.04, \"learn_time_ms\": 14869.411}", "{\"n\": 4889, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3942.45, \"learn_time_ms\": 14871.761}", "{\"n\": 4890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3958.4, \"learn_time_ms\": 14866.308}", "{\"n\": 4891, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3949.0, \"learn_time_ms\": 14876.054}", "{\"n\": 4892, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3949.0, \"learn_time_ms\": 14877.129}", "{\"n\": 4893, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3964.07, \"learn_time_ms\": 14892.847}", "{\"n\": 4894, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3966.47, \"learn_time_ms\": 14880.668}", "{\"n\": 4895, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3966.47, \"learn_time_ms\": 14869.477}", "{\"n\": 4896, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3966.69, \"learn_time_ms\": 14869.009}", "{\"n\": 4897, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3974.58, \"learn_time_ms\": 14862.73}", "{\"n\": 4898, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3977.31, \"learn_time_ms\": 14864.695}", "{\"n\": 4899, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3985.03, \"learn_time_ms\": 14866.48}", "{\"n\": 4900, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3974.87, \"learn_time_ms\": 14868.261}", "{\"n\": 4901, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3959.57, \"learn_time_ms\": 14873.088}", "{\"n\": 4902, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3959.57, \"learn_time_ms\": 14872.104}", "{\"n\": 4903, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3947.37, \"learn_time_ms\": 14857.98}", "{\"n\": 4904, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3958.12, \"learn_time_ms\": 14863.943}", "{\"n\": 4905, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3958.05, \"learn_time_ms\": 14869.767}", "{\"n\": 4906, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3936.8, \"learn_time_ms\": 14862.914}", "{\"n\": 4907, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3940.05, \"learn_time_ms\": 14872.668}", "{\"n\": 4908, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3934.01, \"learn_time_ms\": 14867.89}", "{\"n\": 4909, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3929.55, \"learn_time_ms\": 14870.257}", "{\"n\": 4910, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3929.55, \"learn_time_ms\": 14868.986}", "{\"n\": 4911, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3936.83, \"learn_time_ms\": 14866.497}", "{\"n\": 4912, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3928.11, \"learn_time_ms\": 14875.091}", "{\"n\": 4913, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3931.93, \"learn_time_ms\": 14877.698}", "{\"n\": 4914, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3937.5, \"learn_time_ms\": 14886.917}", "{\"n\": 4915, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3927.85, \"learn_time_ms\": 14887.108}", "{\"n\": 4916, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3931.74, \"learn_time_ms\": 14904.196}", "{\"n\": 4917, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3928.9, \"learn_time_ms\": 14899.329}", "{\"n\": 4918, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3928.9, \"learn_time_ms\": 14888.286}", "{\"n\": 4919, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3928.5, \"learn_time_ms\": 14889.836}", "{\"n\": 4920, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3928.5, \"learn_time_ms\": 14903.177}", "{\"n\": 4921, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3928.64, \"learn_time_ms\": 14905.576}", "{\"n\": 4922, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3908.61, \"learn_time_ms\": 14888.021}", "{\"n\": 4923, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3896.34, \"learn_time_ms\": 14888.654}", "{\"n\": 4924, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3896.34, \"learn_time_ms\": 14894.113}", "{\"n\": 4925, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3896.34, \"learn_time_ms\": 14900.882}", "{\"n\": 4926, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3883.82, \"learn_time_ms\": 14892.757}", "{\"n\": 4927, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3883.82, \"learn_time_ms\": 14894.304}", "{\"n\": 4928, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3879.17, \"learn_time_ms\": 14904.494}", "{\"n\": 4929, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3879.17, \"learn_time_ms\": 14902.235}", "{\"n\": 4930, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3875.63, \"learn_time_ms\": 14913.294}", "{\"n\": 4931, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3880.41, \"learn_time_ms\": 14913.615}", "{\"n\": 4932, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3880.41, \"learn_time_ms\": 14919.694}", "{\"n\": 4933, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3867.89, \"learn_time_ms\": 14924.114}", "{\"n\": 4934, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3867.89, \"learn_time_ms\": 14920.56}", "{\"n\": 4935, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3863.41, \"learn_time_ms\": 14905.227}", "{\"n\": 4936, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3856.48, \"learn_time_ms\": 14904.753}", "{\"n\": 4937, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3852.15, \"learn_time_ms\": 14905.025}", "{\"n\": 4938, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3840.12, \"learn_time_ms\": 14899.853}", "{\"n\": 4939, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.16, \"learn_time_ms\": 14905.587}", "{\"n\": 4940, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.16, \"learn_time_ms\": 14885.451}", "{\"n\": 4941, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3848.49, \"learn_time_ms\": 14880.873}", "{\"n\": 4942, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3848.49, \"learn_time_ms\": 14887.417}", "{\"n\": 4943, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3854.32, \"learn_time_ms\": 14886.622}", "{\"n\": 4944, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3843.36, \"learn_time_ms\": 14878.352}", "{\"n\": 4945, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3845.78, \"learn_time_ms\": 14887.437}", "{\"n\": 4946, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3845.78, \"learn_time_ms\": 14897.593}", "{\"n\": 4947, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3845.78, \"learn_time_ms\": 14904.818}", "{\"n\": 4948, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3849.59, \"learn_time_ms\": 14910.029}", "{\"n\": 4949, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3840.3, \"learn_time_ms\": 14897.214}", "{\"n\": 4950, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3833.45, \"learn_time_ms\": 14896.575}", "{\"n\": 4951, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3833.45, \"learn_time_ms\": 14900.962}", "{\"n\": 4952, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3855.12, \"learn_time_ms\": 14899.691}", "{\"n\": 4953, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3855.12, \"learn_time_ms\": 14890.373}", "{\"n\": 4954, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3834.57, \"learn_time_ms\": 14890.205}", "{\"n\": 4955, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.76, \"learn_time_ms\": 14877.765}", "{\"n\": 4956, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3807.68, \"learn_time_ms\": 14865.003}", "{\"n\": 4957, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3828.0, \"learn_time_ms\": 14842.815}", "{\"n\": 4958, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3828.0, \"learn_time_ms\": 14837.015}", "{\"n\": 4959, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3816.83, \"learn_time_ms\": 14840.675}", "{\"n\": 4960, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3808.0, \"learn_time_ms\": 14835.014}", "{\"n\": 4961, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3812.65, \"learn_time_ms\": 14830.533}", "{\"n\": 4962, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3807.16, \"learn_time_ms\": 14830.346}", "{\"n\": 4963, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3807.16, \"learn_time_ms\": 14838.272}", "{\"n\": 4964, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3798.75, \"learn_time_ms\": 14848.726}", "{\"n\": 4965, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3788.63, \"learn_time_ms\": 14854.85}", "{\"n\": 4966, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3786.02, \"learn_time_ms\": 14860.008}", "{\"n\": 4967, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3782.74, \"learn_time_ms\": 14879.88}", "{\"n\": 4968, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3773.79, \"learn_time_ms\": 14879.632}", "{\"n\": 4969, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3792.91, \"learn_time_ms\": 14875.704}", "{\"n\": 4970, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3792.91, \"learn_time_ms\": 14887.935}", "{\"n\": 4971, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3790.73, \"learn_time_ms\": 14895.774}", "{\"n\": 4972, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3779.22, \"learn_time_ms\": 14889.634}", "{\"n\": 4973, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3777.7, \"learn_time_ms\": 14891.514}", "{\"n\": 4974, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.17, \"learn_time_ms\": 14872.964}", "{\"n\": 4975, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3748.34, \"learn_time_ms\": 14868.633}", "{\"n\": 4976, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3747.36, \"learn_time_ms\": 14863.45}", "{\"n\": 4977, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3747.36, \"learn_time_ms\": 14852.707}", "{\"n\": 4978, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3743.15, \"learn_time_ms\": 14856.405}", "{\"n\": 4979, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3748.14, \"learn_time_ms\": 14864.077}", "{\"n\": 4980, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3758.74, \"learn_time_ms\": 14861.842}", "{\"n\": 4981, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3749.06, \"learn_time_ms\": 14862.992}", "{\"n\": 4982, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3728.26, \"learn_time_ms\": 14877.953}", "{\"n\": 4983, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3728.26, \"learn_time_ms\": 14877.836}", "{\"n\": 4984, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3727.74, \"learn_time_ms\": 14886.568}", "{\"n\": 4985, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3728.49, \"learn_time_ms\": 14887.329}", "{\"n\": 4986, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3717.69, \"learn_time_ms\": 14895.004}", "{\"n\": 4987, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.34, \"learn_time_ms\": 14902.242}", "{\"n\": 4988, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3702.07, \"learn_time_ms\": 14897.17}", "{\"n\": 4989, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3702.07, \"learn_time_ms\": 14895.264}", "{\"n\": 4990, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3676.86, \"learn_time_ms\": 14892.672}", "{\"n\": 4991, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3676.86, \"learn_time_ms\": 14880.512}", "{\"n\": 4992, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3684.89, \"learn_time_ms\": 14862.587}", "{\"n\": 4993, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3676.18, \"learn_time_ms\": 14853.084}", "{\"n\": 4994, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3675.07, \"learn_time_ms\": 14837.981}", "{\"n\": 4995, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3675.07, \"learn_time_ms\": 14845.255}", "{\"n\": 4996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3662.12, \"learn_time_ms\": 14846.616}", "{\"n\": 4997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3662.12, \"learn_time_ms\": 14839.714}", "{\"n\": 4998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3657.95, \"learn_time_ms\": 14840.141}", "{\"n\": 4999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3667.86, \"learn_time_ms\": 14828.214}", "{\"n\": 5000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3675.04, \"learn_time_ms\": 14820.235}"]["{\"n\": 5001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15058.793}", "{\"n\": 5002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14764.381}", "{\"n\": 5003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14666.518}", "{\"n\": 5004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14616.15}", "{\"n\": 5005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14592.955}", "{\"n\": 5006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14580.545}", "{\"n\": 5007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14569.073}", "{\"n\": 5008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14559.235}", "{\"n\": 5009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14549.797}", "{\"n\": 5010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14537.153}", "{\"n\": 5011, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14486.159}", "{\"n\": 5012, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2800.0, \"learn_time_ms\": 14492.897}", "{\"n\": 5013, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.4285714285714284, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3796.5714285714284, \"learn_time_ms\": 14496.203}", "{\"n\": 5014, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.375, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3870.875, \"learn_time_ms\": 14498.703}", "{\"n\": 5015, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.375, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3870.875, \"learn_time_ms\": 14501.91}", "{\"n\": 5016, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.375, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3870.875, \"learn_time_ms\": 14522.664}", "{\"n\": 5017, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.375, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3870.875, \"learn_time_ms\": 14529.237}", "{\"n\": 5018, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.5454545454545454, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3810.909090909091, \"learn_time_ms\": 14526.384}", "{\"n\": 5019, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.153846153846154, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3750.846153846154, \"learn_time_ms\": 14532.496}", "{\"n\": 5020, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3741.0, \"learn_time_ms\": 14545.146}", "{\"n\": 5021, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3757.25, \"learn_time_ms\": 14536.239}", "{\"n\": 5022, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3757.25, \"learn_time_ms\": 14514.515}", "{\"n\": 5023, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3757.25, \"learn_time_ms\": 14507.426}", "{\"n\": 5024, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.470588235294118, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3765.764705882353, \"learn_time_ms\": 14481.997}", "{\"n\": 5025, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.095238095238095, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3707.904761904762, \"learn_time_ms\": 14470.638}", "{\"n\": 5026, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.3478260869565215, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3708.8695652173915, \"learn_time_ms\": 14435.886}", "{\"n\": 5027, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.166666666666667, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3756.9166666666665, \"learn_time_ms\": 14412.163}", "{\"n\": 5028, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.166666666666667, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3756.9166666666665, \"learn_time_ms\": 14423.938}", "{\"n\": 5029, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.166666666666667, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3756.9166666666665, \"learn_time_ms\": 14428.565}", "{\"n\": 5030, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.1923076923076925, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3738.1923076923076, \"learn_time_ms\": 14414.267}", "{\"n\": 5031, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.142857142857143, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3766.1071428571427, \"learn_time_ms\": 14409.456}", "{\"n\": 5032, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.310344827586207, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3754.0344827586205, \"learn_time_ms\": 14417.206}", "{\"n\": 5033, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3738.15625, \"learn_time_ms\": 14407.214}", "{\"n\": 5034, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3738.15625, \"learn_time_ms\": 14430.204}", "{\"n\": 5035, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.515151515151516, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3734.4848484848485, \"learn_time_ms\": 14426.14}", "{\"n\": 5036, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.5588235294117645, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3724.5, \"learn_time_ms\": 14439.312}", "{\"n\": 5037, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.594594594594595, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3716.864864864865, \"learn_time_ms\": 14448.446}", "{\"n\": 5038, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.461538461538462, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3728.5384615384614, \"learn_time_ms\": 14447.86}", "{\"n\": 5039, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.461538461538462, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3728.5384615384614, \"learn_time_ms\": 14430.679}", "{\"n\": 5040, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3757.95, \"learn_time_ms\": 14440.113}", "{\"n\": 5041, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.463414634146342, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3738.829268292683, \"learn_time_ms\": 14443.831}", "{\"n\": 5042, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.604651162790698, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3718.279069767442, \"learn_time_ms\": 14461.314}", "{\"n\": 5043, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.644444444444445, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3705.3555555555554, \"learn_time_ms\": 14470.215}", "{\"n\": 5044, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.644444444444445, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3705.3555555555554, \"learn_time_ms\": 14470.786}", "{\"n\": 5045, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.770833333333333, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3693.6875, \"learn_time_ms\": 14488.731}", "{\"n\": 5046, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.770833333333333, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3693.6875, \"learn_time_ms\": 14484.203}", "{\"n\": 5047, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.770833333333333, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3693.6875, \"learn_time_ms\": 14483.341}", "{\"n\": 5048, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.795918367346939, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3690.081632653061, \"learn_time_ms\": 14465.628}", "{\"n\": 5049, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.846153846153846, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3674.0576923076924, \"learn_time_ms\": 14470.642}", "{\"n\": 5050, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.830188679245283, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3672.0377358490564, \"learn_time_ms\": 14474.213}", "{\"n\": 5051, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.7407407407407405, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3680.3888888888887, \"learn_time_ms\": 14477.173}", "{\"n\": 5052, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.818181818181818, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3668.018181818182, \"learn_time_ms\": 14468.533}", "{\"n\": 5053, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.719298245614035, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3683.7894736842104, \"learn_time_ms\": 14471.635}", "{\"n\": 5054, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.741379310344827, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3684.2413793103447, \"learn_time_ms\": 14472.751}", "{\"n\": 5055, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3690.0666666666666, \"learn_time_ms\": 14478.87}", "{\"n\": 5056, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.596774193548387, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3701.1774193548385, \"learn_time_ms\": 14477.53}", "{\"n\": 5057, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.596774193548387, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3701.1774193548385, \"learn_time_ms\": 14476.067}", "{\"n\": 5058, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.428571428571429, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3710.5079365079364, \"learn_time_ms\": 14490.97}", "{\"n\": 5059, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.2615384615384615, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3730.476923076923, \"learn_time_ms\": 14493.753}", "{\"n\": 5060, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.3283582089552235, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3719.791044776119, \"learn_time_ms\": 14481.667}", "{\"n\": 5061, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.426470588235294, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3706.3970588235293, \"learn_time_ms\": 14470.743}", "{\"n\": 5062, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.449275362318841, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3707.536231884058, \"learn_time_ms\": 14471.974}", "{\"n\": 5063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.571428571428571, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3695.157142857143, \"learn_time_ms\": 14478.672}", "{\"n\": 5064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.464788732394366, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3707.154929577465, \"learn_time_ms\": 14478.417}", "{\"n\": 5065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3702.9583333333335, \"learn_time_ms\": 14469.199}", "{\"n\": 5066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.586666666666667, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3688.213333333333, \"learn_time_ms\": 14466.957}", "{\"n\": 5067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.592105263157895, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3687.1315789473683, \"learn_time_ms\": 14479.94}", "{\"n\": 5068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.571428571428571, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3689.7012987012986, \"learn_time_ms\": 14472.801}", "{\"n\": 5069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.589743589743589, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3692.7179487179487, \"learn_time_ms\": 14475.254}", "{\"n\": 5070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.417721518987341, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3695.8987341772154, \"learn_time_ms\": 14475.179}", "{\"n\": 5071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.4875, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3690.9, \"learn_time_ms\": 14496.891}", "{\"n\": 5072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.530864197530864, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3685.2098765432097, \"learn_time_ms\": 14493.958}", "{\"n\": 5073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.626506024096385, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3683.722891566265, \"learn_time_ms\": 14486.884}", "{\"n\": 5074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.690476190476191, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3676.059523809524, \"learn_time_ms\": 14486.216}", "{\"n\": 5075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.651162790697675, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3689.4302325581393, \"learn_time_ms\": 14477.217}", "{\"n\": 5076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.651162790697675, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3689.4302325581393, \"learn_time_ms\": 14497.806}", "{\"n\": 5077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.597701149425287, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3698.67816091954, \"learn_time_ms\": 14484.192}", "{\"n\": 5078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.4772727272727275, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3704.590909090909, \"learn_time_ms\": 14488.104}", "{\"n\": 5079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.516483516483516, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3710.6923076923076, \"learn_time_ms\": 14493.955}", "{\"n\": 5080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3711.467391304348, \"learn_time_ms\": 14504.828}", "{\"n\": 5081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3711.467391304348, \"learn_time_ms\": 14490.639}", "{\"n\": 5082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.397849462365591, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3718.2473118279568, \"learn_time_ms\": 14488.705}", "{\"n\": 5083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.347368421052631, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3722.0315789473684, \"learn_time_ms\": 14497.326}", "{\"n\": 5084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.347368421052631, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3722.0315789473684, \"learn_time_ms\": 14491.629}", "{\"n\": 5085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.371134020618556, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3718.6082474226805, \"learn_time_ms\": 14488.538}", "{\"n\": 5086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3719.89, \"learn_time_ms\": 14485.76}", "{\"n\": 5087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3719.89, \"learn_time_ms\": 14504.535}", "{\"n\": 5088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3731.04, \"learn_time_ms\": 14504.532}", "{\"n\": 5089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3735.2, \"learn_time_ms\": 14506.001}", "{\"n\": 5090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3729.97, \"learn_time_ms\": 14521.763}", "{\"n\": 5091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3736.68, \"learn_time_ms\": 14525.061}", "{\"n\": 5092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3738.9, \"learn_time_ms\": 14527.805}", "{\"n\": 5093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3735.79, \"learn_time_ms\": 14527.601}", "{\"n\": 5094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3731.85, \"learn_time_ms\": 14538.337}", "{\"n\": 5095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3715.07, \"learn_time_ms\": 14536.092}", "{\"n\": 5096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3712.18, \"learn_time_ms\": 14510.34}", "{\"n\": 5097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3721.87, \"learn_time_ms\": 14498.917}", "{\"n\": 5098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3712.51, \"learn_time_ms\": 14491.284}", "{\"n\": 5099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3716.79, \"learn_time_ms\": 14490.849}", "{\"n\": 5100, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3719.07, \"learn_time_ms\": 14467.232}", "{\"n\": 5101, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3722.09, \"learn_time_ms\": 14475.723}", "{\"n\": 5102, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3720.45, \"learn_time_ms\": 14474.971}", "{\"n\": 5103, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3720.45, \"learn_time_ms\": 14472.653}", "{\"n\": 5104, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3747.87, \"learn_time_ms\": 14472.017}", "{\"n\": 5105, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.84, \"learn_time_ms\": 14485.432}", "{\"n\": 5106, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3736.12, \"learn_time_ms\": 14487.154}", "{\"n\": 5107, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3750.95, \"learn_time_ms\": 14480.006}", "{\"n\": 5108, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.4, \"learn_time_ms\": 14487.015}", "{\"n\": 5109, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3733.35, \"learn_time_ms\": 14482.976}", "{\"n\": 5110, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.16, \"learn_time_ms\": 14475.958}", "{\"n\": 5111, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.16, \"learn_time_ms\": 14472.879}", "{\"n\": 5112, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.91, \"learn_time_ms\": 14476.958}", "{\"n\": 5113, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3737.06, \"learn_time_ms\": 14469.885}", "{\"n\": 5114, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.05, \"learn_time_ms\": 14463.707}", "{\"n\": 5115, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3721.3, \"learn_time_ms\": 14472.315}", "{\"n\": 5116, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3721.3, \"learn_time_ms\": 14493.461}", "{\"n\": 5117, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3721.3, \"learn_time_ms\": 14499.691}", "{\"n\": 5118, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3717.07, \"learn_time_ms\": 14496.948}", "{\"n\": 5119, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3739.13, \"learn_time_ms\": 14499.987}", "{\"n\": 5120, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.08, \"learn_time_ms\": 14522.418}", "{\"n\": 5121, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3739.33, \"learn_time_ms\": 14516.664}", "{\"n\": 5122, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3737.43, \"learn_time_ms\": 14510.295}", "{\"n\": 5123, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3737.43, \"learn_time_ms\": 14519.139}", "{\"n\": 5124, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3739.15, \"learn_time_ms\": 14520.851}", "{\"n\": 5125, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3739.15, \"learn_time_ms\": 14512.673}", "{\"n\": 5126, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.42, \"learn_time_ms\": 14505.85}", "{\"n\": 5127, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.42, \"learn_time_ms\": 14528.434}", "{\"n\": 5128, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.42, \"learn_time_ms\": 14531.763}", "{\"n\": 5129, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3745.52, \"learn_time_ms\": 14530.665}", "{\"n\": 5130, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3745.52, \"learn_time_ms\": 14514.803}", "{\"n\": 5131, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3726.31, \"learn_time_ms\": 14516.803}", "{\"n\": 5132, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3722.95, \"learn_time_ms\": 14523.902}", "{\"n\": 5133, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3727.73, \"learn_time_ms\": 14514.282}", "{\"n\": 5134, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3727.73, \"learn_time_ms\": 14514.726}", "{\"n\": 5135, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3732.22, \"learn_time_ms\": 14507.432}", "{\"n\": 5136, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3732.22, \"learn_time_ms\": 14503.063}", "{\"n\": 5137, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3732.22, \"learn_time_ms\": 14496.949}", "{\"n\": 5138, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3729.92, \"learn_time_ms\": 14493.666}", "{\"n\": 5139, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.16, \"learn_time_ms\": 14495.173}", "{\"n\": 5140, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.69, \"learn_time_ms\": 14489.255}", "{\"n\": 5141, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.64, \"learn_time_ms\": 14496.088}", "{\"n\": 5142, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.64, \"learn_time_ms\": 14479.449}", "{\"n\": 5143, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.64, \"learn_time_ms\": 14479.271}", "{\"n\": 5144, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.64, \"learn_time_ms\": 14464.283}", "{\"n\": 5145, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3775.69, \"learn_time_ms\": 14464.068}", "{\"n\": 5146, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3783.21, \"learn_time_ms\": 14463.651}", "{\"n\": 5147, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3778.94, \"learn_time_ms\": 14460.809}", "{\"n\": 5148, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3774.97, \"learn_time_ms\": 14462.288}", "{\"n\": 5149, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3774.97, \"learn_time_ms\": 14454.018}", "{\"n\": 5150, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3774.97, \"learn_time_ms\": 14468.438}", "{\"n\": 5151, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3782.89, \"learn_time_ms\": 14455.046}", "{\"n\": 5152, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3788.57, \"learn_time_ms\": 14454.96}", "{\"n\": 5153, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3788.57, \"learn_time_ms\": 14457.246}", "{\"n\": 5154, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3784.58, \"learn_time_ms\": 14464.908}", "{\"n\": 5155, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3784.58, \"learn_time_ms\": 14468.088}", "{\"n\": 5156, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3777.33, \"learn_time_ms\": 14467.862}", "{\"n\": 5157, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3777.2, \"learn_time_ms\": 14460.42}", "{\"n\": 5158, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3774.43, \"learn_time_ms\": 14471.915}", "{\"n\": 5159, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3761.81, \"learn_time_ms\": 14469.366}", "{\"n\": 5160, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3765.73, \"learn_time_ms\": 14477.664}", "{\"n\": 5161, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3765.73, \"learn_time_ms\": 14492.803}", "{\"n\": 5162, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3769.71, \"learn_time_ms\": 14502.755}", "{\"n\": 5163, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3769.71, \"learn_time_ms\": 14500.511}", "{\"n\": 5164, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3756.35, \"learn_time_ms\": 14509.91}", "{\"n\": 5165, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3750.91, \"learn_time_ms\": 14516.918}", "{\"n\": 5166, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3750.91, \"learn_time_ms\": 14527.835}", "{\"n\": 5167, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3757.12, \"learn_time_ms\": 14526.438}", "{\"n\": 5168, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3757.12, \"learn_time_ms\": 14513.998}", "{\"n\": 5169, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3754.27, \"learn_time_ms\": 14521.094}", "{\"n\": 5170, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3754.27, \"learn_time_ms\": 14502.432}", "{\"n\": 5171, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3749.02, \"learn_time_ms\": 14507.245}", "{\"n\": 5172, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3769.3, \"learn_time_ms\": 14512.124}", "{\"n\": 5173, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3769.3, \"learn_time_ms\": 14503.722}", "{\"n\": 5174, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.14, \"learn_time_ms\": 14504.68}", "{\"n\": 5175, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.14, \"learn_time_ms\": 14498.822}", "{\"n\": 5176, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3780.93, \"learn_time_ms\": 14482.476}", "{\"n\": 5177, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3773.13, \"learn_time_ms\": 14488.507}", "{\"n\": 5178, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3779.63, \"learn_time_ms\": 14489.634}", "{\"n\": 5179, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3781.62, \"learn_time_ms\": 14484.364}", "{\"n\": 5180, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3781.62, \"learn_time_ms\": 14497.949}", "{\"n\": 5181, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3780.21, \"learn_time_ms\": 14479.286}", "{\"n\": 5182, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3771.52, \"learn_time_ms\": 14474.603}", "{\"n\": 5183, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3752.16, \"learn_time_ms\": 14479.961}", "{\"n\": 5184, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3728.61, \"learn_time_ms\": 14463.137}", "{\"n\": 5185, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3737.02, \"learn_time_ms\": 14454.25}", "{\"n\": 5186, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3742.46, \"learn_time_ms\": 14460.826}", "{\"n\": 5187, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3737.21, \"learn_time_ms\": 14449.733}", "{\"n\": 5188, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3733.77, \"learn_time_ms\": 14436.921}", "{\"n\": 5189, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3736.81, \"learn_time_ms\": 14446.603}", "{\"n\": 5190, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.24, \"learn_time_ms\": 14443.882}", "{\"n\": 5191, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.24, \"learn_time_ms\": 14439.753}", "{\"n\": 5192, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3747.89, \"learn_time_ms\": 14447.379}", "{\"n\": 5193, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3749.46, \"learn_time_ms\": 14459.535}", "{\"n\": 5194, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3765.99, \"learn_time_ms\": 14478.973}", "{\"n\": 5195, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3765.99, \"learn_time_ms\": 14487.191}", "{\"n\": 5196, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3765.99, \"learn_time_ms\": 14486.976}", "{\"n\": 5197, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3747.01, \"learn_time_ms\": 14492.806}", "{\"n\": 5198, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3758.42, \"learn_time_ms\": 14501.054}", "{\"n\": 5199, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3758.42, \"learn_time_ms\": 14495.595}", "{\"n\": 5200, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3749.07, \"learn_time_ms\": 14494.918}", "{\"n\": 5201, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3749.07, \"learn_time_ms\": 14502.72}", "{\"n\": 5202, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3765.63, \"learn_time_ms\": 14489.565}", "{\"n\": 5203, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3782.09, \"learn_time_ms\": 14482.987}", "{\"n\": 5204, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3786.12, \"learn_time_ms\": 14473.602}", "{\"n\": 5205, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3786.12, \"learn_time_ms\": 14472.43}", "{\"n\": 5206, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3800.35, \"learn_time_ms\": 14475.5}", "{\"n\": 5207, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3782.11, \"learn_time_ms\": 14461.7}", "{\"n\": 5208, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3787.59, \"learn_time_ms\": 14461.653}", "{\"n\": 5209, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3786.38, \"learn_time_ms\": 14468.626}", "{\"n\": 5210, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3786.38, \"learn_time_ms\": 14458.042}", "{\"n\": 5211, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3787.13, \"learn_time_ms\": 14460.268}", "{\"n\": 5212, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3772.84, \"learn_time_ms\": 14473.529}", "{\"n\": 5213, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3766.04, \"learn_time_ms\": 14483.358}", "{\"n\": 5214, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3767.02, \"learn_time_ms\": 14485.068}", "{\"n\": 5215, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.02, \"learn_time_ms\": 14489.979}", "{\"n\": 5216, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.23, \"learn_time_ms\": 14489.487}", "{\"n\": 5217, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.23, \"learn_time_ms\": 14507.605}", "{\"n\": 5218, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3767.41, \"learn_time_ms\": 14507.755}", "{\"n\": 5219, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3751.71, \"learn_time_ms\": 14492.949}", "{\"n\": 5220, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3750.41, \"learn_time_ms\": 14499.883}", "{\"n\": 5221, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3750.41, \"learn_time_ms\": 14501.066}", "{\"n\": 5222, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3758.03, \"learn_time_ms\": 14491.375}", "{\"n\": 5223, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3748.3, \"learn_time_ms\": 14482.534}", "{\"n\": 5224, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3729.17, \"learn_time_ms\": 14494.594}", "{\"n\": 5225, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3730.22, \"learn_time_ms\": 14479.954}", "{\"n\": 5226, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3723.49, \"learn_time_ms\": 14477.245}", "{\"n\": 5227, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3736.61, \"learn_time_ms\": 14471.239}", "{\"n\": 5228, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3747.38, \"learn_time_ms\": 14471.538}", "{\"n\": 5229, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3747.38, \"learn_time_ms\": 14474.391}", "{\"n\": 5230, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3744.54, \"learn_time_ms\": 14479.019}", "{\"n\": 5231, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3743.07, \"learn_time_ms\": 14486.416}", "{\"n\": 5232, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3735.68, \"learn_time_ms\": 14491.959}", "{\"n\": 5233, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3732.54, \"learn_time_ms\": 14499.203}", "{\"n\": 5234, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3718.42, \"learn_time_ms\": 14496.579}", "{\"n\": 5235, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3718.42, \"learn_time_ms\": 14521.033}", "{\"n\": 5236, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3712.45, \"learn_time_ms\": 14523.535}", "{\"n\": 5237, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3710.3, \"learn_time_ms\": 14527.42}", "{\"n\": 5238, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3719.24, \"learn_time_ms\": 14540.773}", "{\"n\": 5239, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3722.39, \"learn_time_ms\": 14542.584}", "{\"n\": 5240, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3722.39, \"learn_time_ms\": 14523.206}", "{\"n\": 5241, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3718.8, \"learn_time_ms\": 14514.442}", "{\"n\": 5242, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3705.27, \"learn_time_ms\": 14514.811}", "{\"n\": 5243, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3692.28, \"learn_time_ms\": 14497.295}", "{\"n\": 5244, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3693.81, \"learn_time_ms\": 14492.298}", "{\"n\": 5245, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3684.75, \"learn_time_ms\": 14474.188}", "{\"n\": 5246, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3684.75, \"learn_time_ms\": 14466.876}", "{\"n\": 5247, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3684.75, \"learn_time_ms\": 14456.344}", "{\"n\": 5248, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3697.61, \"learn_time_ms\": 14441.391}", "{\"n\": 5249, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3695.33, \"learn_time_ms\": 14448.821}", "{\"n\": 5250, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3693.66, \"learn_time_ms\": 14461.487}", "{\"n\": 5251, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3681.14, \"learn_time_ms\": 14468.654}", "{\"n\": 5252, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3681.14, \"learn_time_ms\": 14461.855}", "{\"n\": 5253, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3687.77, \"learn_time_ms\": 14477.487}", "{\"n\": 5254, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3668.27, \"learn_time_ms\": 14485.62}", "{\"n\": 5255, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3659.35, \"learn_time_ms\": 14495.775}", "{\"n\": 5256, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3659.65, \"learn_time_ms\": 14484.888}", "{\"n\": 5257, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3659.65, \"learn_time_ms\": 14501.214}", "{\"n\": 5258, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3660.74, \"learn_time_ms\": 14492.242}", "{\"n\": 5259, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3667.48, \"learn_time_ms\": 14488.331}", "{\"n\": 5260, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3658.51, \"learn_time_ms\": 14487.473}", "{\"n\": 5261, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3658.51, \"learn_time_ms\": 14463.847}", "{\"n\": 5262, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3665.16, \"learn_time_ms\": 14473.998}", "{\"n\": 5263, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3665.37, \"learn_time_ms\": 14473.861}", "{\"n\": 5264, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3671.76, \"learn_time_ms\": 14447.584}", "{\"n\": 5265, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3663.5, \"learn_time_ms\": 14430.931}", "{\"n\": 5266, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3663.5, \"learn_time_ms\": 14462.223}", "{\"n\": 5267, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3658.45, \"learn_time_ms\": 14457.771}", "{\"n\": 5268, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3655.78, \"learn_time_ms\": 14468.831}", "{\"n\": 5269, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3656.7, \"learn_time_ms\": 14462.064}", "{\"n\": 5270, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3631.18, \"learn_time_ms\": 14464.913}", "{\"n\": 5271, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3635.92, \"learn_time_ms\": 14471.66}", "{\"n\": 5272, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3613.09, \"learn_time_ms\": 14471.166}", "{\"n\": 5273, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3618.7, \"learn_time_ms\": 14463.773}", "{\"n\": 5274, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3622.9, \"learn_time_ms\": 14464.099}", "{\"n\": 5275, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3622.9, \"learn_time_ms\": 14469.168}", "{\"n\": 5276, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3615.72, \"learn_time_ms\": 14459.728}", "{\"n\": 5277, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3619.19, \"learn_time_ms\": 14448.787}", "{\"n\": 5278, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3588.58, \"learn_time_ms\": 14451.952}", "{\"n\": 5279, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3584.47, \"learn_time_ms\": 14435.048}", "{\"n\": 5280, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3578.76, \"learn_time_ms\": 14438.411}", "{\"n\": 5281, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3578.76, \"learn_time_ms\": 14452.876}", "{\"n\": 5282, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3584.37, \"learn_time_ms\": 14457.357}", "{\"n\": 5283, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3590.51, \"learn_time_ms\": 14439.422}", "{\"n\": 5284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3580.2, \"learn_time_ms\": 14447.515}", "{\"n\": 5285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3590.46, \"learn_time_ms\": 14448.429}", "{\"n\": 5286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3598.55, \"learn_time_ms\": 14446.38}", "{\"n\": 5287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3598.55, \"learn_time_ms\": 14447.367}", "{\"n\": 5288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3598.55, \"learn_time_ms\": 14446.864}", "{\"n\": 5289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3572.14, \"learn_time_ms\": 14461.39}", "{\"n\": 5290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3555.92, \"learn_time_ms\": 14458.535}", "{\"n\": 5291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3566.43, \"learn_time_ms\": 14450.471}", "{\"n\": 5292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3566.43, \"learn_time_ms\": 14447.612}", "{\"n\": 5293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3570.95, \"learn_time_ms\": 14464.124}", "{\"n\": 5294, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3586.84, \"learn_time_ms\": 14483.385}", "{\"n\": 5295, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3584.08, \"learn_time_ms\": 14495.004}", "{\"n\": 5296, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3581.34, \"learn_time_ms\": 14497.321}", "{\"n\": 5297, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3583.63, \"learn_time_ms\": 14488.431}", "{\"n\": 5298, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3587.41, \"learn_time_ms\": 14481.918}", "{\"n\": 5299, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3573.66, \"learn_time_ms\": 14487.037}", "{\"n\": 5300, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3585.46, \"learn_time_ms\": 14494.961}", "{\"n\": 5301, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3579.49, \"learn_time_ms\": 14501.784}", "{\"n\": 5302, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3563.32, \"learn_time_ms\": 14500.678}", "{\"n\": 5303, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3561.93, \"learn_time_ms\": 14514.469}", "{\"n\": 5304, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3550.2, \"learn_time_ms\": 14502.277}", "{\"n\": 5305, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3550.2, \"learn_time_ms\": 14497.671}", "{\"n\": 5306, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3551.93, \"learn_time_ms\": 14496.06}", "{\"n\": 5307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3545.91, \"learn_time_ms\": 14500.263}", "{\"n\": 5308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3554.63, \"learn_time_ms\": 14515.851}", "{\"n\": 5309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3567.96, \"learn_time_ms\": 14523.792}", "{\"n\": 5310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3559.41, \"learn_time_ms\": 14515.901}", "{\"n\": 5311, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3559.41, \"learn_time_ms\": 14507.374}", "{\"n\": 5312, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3572.33, \"learn_time_ms\": 14507.231}", "{\"n\": 5313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3586.54, \"learn_time_ms\": 14496.077}", "{\"n\": 5314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3579.54, \"learn_time_ms\": 14497.835}", "{\"n\": 5315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3594.49, \"learn_time_ms\": 14486.556}", "{\"n\": 5316, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3610.53, \"learn_time_ms\": 14492.06}", "{\"n\": 5317, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3606.59, \"learn_time_ms\": 14497.82}", "{\"n\": 5318, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3606.59, \"learn_time_ms\": 14485.817}", "{\"n\": 5319, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.4, \"learn_time_ms\": 14461.601}", "{\"n\": 5320, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3607.5, \"learn_time_ms\": 14455.37}", "{\"n\": 5321, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3612.46, \"learn_time_ms\": 14458.377}", "{\"n\": 5322, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3618.59, \"learn_time_ms\": 14459.778}", "{\"n\": 5323, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.35, \"learn_time_ms\": 14462.821}", "{\"n\": 5324, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.35, \"learn_time_ms\": 14458.932}", "{\"n\": 5325, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.35, \"learn_time_ms\": 14459.452}", "{\"n\": 5326, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3607.47, \"learn_time_ms\": 14452.129}", "{\"n\": 5327, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3604.69, \"learn_time_ms\": 14457.048}", "{\"n\": 5328, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3614.99, \"learn_time_ms\": 14455.54}", "{\"n\": 5329, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3614.99, \"learn_time_ms\": 14468.542}", "{\"n\": 5330, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3621.81, \"learn_time_ms\": 14460.789}", "{\"n\": 5331, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3626.42, \"learn_time_ms\": 14463.112}", "{\"n\": 5332, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3616.33, \"learn_time_ms\": 14446.717}", "{\"n\": 5333, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.41, \"learn_time_ms\": 14452.284}", "{\"n\": 5334, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3622.3, \"learn_time_ms\": 14441.757}", "{\"n\": 5335, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3622.3, \"learn_time_ms\": 14461.317}", "{\"n\": 5336, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3622.3, \"learn_time_ms\": 14449.544}", "{\"n\": 5337, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3613.66, \"learn_time_ms\": 14450.667}", "{\"n\": 5338, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.04, \"learn_time_ms\": 14450.757}", "{\"n\": 5339, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3589.61, \"learn_time_ms\": 14458.48}", "{\"n\": 5340, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3594.97, \"learn_time_ms\": 14482.509}", "{\"n\": 5341, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3598.16, \"learn_time_ms\": 14483.171}", "{\"n\": 5342, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3598.16, \"learn_time_ms\": 14506.997}", "{\"n\": 5343, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3584.65, \"learn_time_ms\": 14505.761}", "{\"n\": 5344, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.23, \"learn_time_ms\": 14529.832}", "{\"n\": 5345, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3619.03, \"learn_time_ms\": 14519.606}", "{\"n\": 5346, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3619.07, \"learn_time_ms\": 14528.356}", "{\"n\": 5347, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3619.07, \"learn_time_ms\": 14524.799}", "{\"n\": 5348, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3634.08, \"learn_time_ms\": 14528.184}", "{\"n\": 5349, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3634.08, \"learn_time_ms\": 14520.706}", "{\"n\": 5350, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3635.83, \"learn_time_ms\": 14515.472}", "{\"n\": 5351, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.42, \"learn_time_ms\": 14515.814}", "{\"n\": 5352, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3649.54, \"learn_time_ms\": 14507.959}", "{\"n\": 5353, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3660.53, \"learn_time_ms\": 14511.764}", "{\"n\": 5354, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3660.53, \"learn_time_ms\": 14503.947}", "{\"n\": 5355, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3667.54, \"learn_time_ms\": 14510.533}", "{\"n\": 5356, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3660.51, \"learn_time_ms\": 14506.462}", "{\"n\": 5357, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3676.34, \"learn_time_ms\": 14501.051}", "{\"n\": 5358, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3682.75, \"learn_time_ms\": 14490.425}", "{\"n\": 5359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3681.31, \"learn_time_ms\": 14490.986}", "{\"n\": 5360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3681.31, \"learn_time_ms\": 14486.137}", "{\"n\": 5361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3683.27, \"learn_time_ms\": 14481.493}", "{\"n\": 5362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3671.05, \"learn_time_ms\": 14465.242}", "{\"n\": 5363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3678.94, \"learn_time_ms\": 14463.551}", "{\"n\": 5364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3692.98, \"learn_time_ms\": 14463.759}", "{\"n\": 5365, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3687.43, \"learn_time_ms\": 14460.957}", "{\"n\": 5366, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3685.17, \"learn_time_ms\": 14468.42}", "{\"n\": 5367, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3685.17, \"learn_time_ms\": 14486.954}", "{\"n\": 5368, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3676.09, \"learn_time_ms\": 14506.052}", "{\"n\": 5369, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3661.66, \"learn_time_ms\": 14496.902}", "{\"n\": 5370, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3652.59, \"learn_time_ms\": 14499.808}", "{\"n\": 5371, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3649.48, \"learn_time_ms\": 14504.81}", "{\"n\": 5372, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3639.13, \"learn_time_ms\": 14509.694}", "{\"n\": 5373, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3639.13, \"learn_time_ms\": 14496.399}", "{\"n\": 5374, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3637.34, \"learn_time_ms\": 14497.262}", "{\"n\": 5375, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3640.16, \"learn_time_ms\": 14478.074}", "{\"n\": 5376, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3648.27, \"learn_time_ms\": 14472.424}", "{\"n\": 5377, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3660.78, \"learn_time_ms\": 14461.664}", "{\"n\": 5378, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3660.78, \"learn_time_ms\": 14461.817}", "{\"n\": 5379, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3655.2, \"learn_time_ms\": 14469.958}", "{\"n\": 5380, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3655.2, \"learn_time_ms\": 14484.118}", "{\"n\": 5381, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3664.73, \"learn_time_ms\": 14473.95}", "{\"n\": 5382, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3666.9, \"learn_time_ms\": 14476.201}", "{\"n\": 5383, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3682.18, \"learn_time_ms\": 14494.648}", "{\"n\": 5384, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3678.37, \"learn_time_ms\": 14491.688}", "{\"n\": 5385, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3678.37, \"learn_time_ms\": 14502.351}", "{\"n\": 5386, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3677.42, \"learn_time_ms\": 14485.347}", "{\"n\": 5387, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3677.42, \"learn_time_ms\": 14497.368}", "{\"n\": 5388, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3654.71, \"learn_time_ms\": 14496.55}", "{\"n\": 5389, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3666.16, \"learn_time_ms\": 14505.696}", "{\"n\": 5390, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3659.79, \"learn_time_ms\": 14479.007}", "{\"n\": 5391, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3659.79, \"learn_time_ms\": 14483.019}", "{\"n\": 5392, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.58, \"learn_time_ms\": 14494.763}", "{\"n\": 5393, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3656.01, \"learn_time_ms\": 14476.345}", "{\"n\": 5394, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3642.1, \"learn_time_ms\": 14472.963}", "{\"n\": 5395, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.83, \"learn_time_ms\": 14486.111}", "{\"n\": 5396, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.42, \"learn_time_ms\": 14516.482}", "{\"n\": 5397, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3628.29, \"learn_time_ms\": 14507.392}", "{\"n\": 5398, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3628.29, \"learn_time_ms\": 14498.036}", "{\"n\": 5399, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3615.98, \"learn_time_ms\": 14498.434}", "{\"n\": 5400, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3614.56, \"learn_time_ms\": 14511.116}", "{\"n\": 5401, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3614.56, \"learn_time_ms\": 14519.394}", "{\"n\": 5402, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3614.8, \"learn_time_ms\": 14512.374}", "{\"n\": 5403, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3627.48, \"learn_time_ms\": 14524.61}", "{\"n\": 5404, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3606.42, \"learn_time_ms\": 14515.96}", "{\"n\": 5405, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3609.83, \"learn_time_ms\": 14506.064}", "{\"n\": 5406, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3608.74, \"learn_time_ms\": 14504.323}", "{\"n\": 5407, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3606.57, \"learn_time_ms\": 14493.305}", "{\"n\": 5408, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3606.64, \"learn_time_ms\": 14495.559}", "{\"n\": 5409, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3609.95, \"learn_time_ms\": 14488.231}", "{\"n\": 5410, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3611.91, \"learn_time_ms\": 14475.145}", "{\"n\": 5411, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3628.61, \"learn_time_ms\": 14460.631}", "{\"n\": 5412, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3628.61, \"learn_time_ms\": 14449.544}", "{\"n\": 5413, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3629.17, \"learn_time_ms\": 14439.598}", "{\"n\": 5414, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3615.2, \"learn_time_ms\": 14442.31}", "{\"n\": 5415, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3607.81, \"learn_time_ms\": 14444.545}", "{\"n\": 5416, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3614.65, \"learn_time_ms\": 14421.68}", "{\"n\": 5417, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3614.04, \"learn_time_ms\": 14424.318}", "{\"n\": 5418, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3601.48, \"learn_time_ms\": 14418.164}", "{\"n\": 5419, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3601.48, \"learn_time_ms\": 14412.712}", "{\"n\": 5420, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3598.12, \"learn_time_ms\": 14417.914}", "{\"n\": 5421, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3596.28, \"learn_time_ms\": 14427.213}", "{\"n\": 5422, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.05, \"learn_time_ms\": 14430.047}", "{\"n\": 5423, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3578.42, \"learn_time_ms\": 14442.343}", "{\"n\": 5424, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3580.96, \"learn_time_ms\": 14451.937}", "{\"n\": 5425, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3580.96, \"learn_time_ms\": 14441.329}", "{\"n\": 5426, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3580.96, \"learn_time_ms\": 14449.316}", "{\"n\": 5427, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3573.14, \"learn_time_ms\": 14445.276}", "{\"n\": 5428, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3571.42, \"learn_time_ms\": 14444.476}", "{\"n\": 5429, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3572.55, \"learn_time_ms\": 14445.694}", "{\"n\": 5430, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3587.95, \"learn_time_ms\": 14438.38}", "{\"n\": 5431, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3574.35, \"learn_time_ms\": 14436.956}", "{\"n\": 5432, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3574.35, \"learn_time_ms\": 14438.71}", "{\"n\": 5433, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3582.83, \"learn_time_ms\": 14428.169}", "{\"n\": 5434, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3580.73, \"learn_time_ms\": 14427.664}", "{\"n\": 5435, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3594.85, \"learn_time_ms\": 14435.929}", "{\"n\": 5436, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3592.59, \"learn_time_ms\": 14436.588}", "{\"n\": 5437, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3592.59, \"learn_time_ms\": 14448.593}", "{\"n\": 5438, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3580.27, \"learn_time_ms\": 14449.934}", "{\"n\": 5439, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3584.02, \"learn_time_ms\": 14449.097}", "{\"n\": 5440, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3584.02, \"learn_time_ms\": 14453.04}", "{\"n\": 5441, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3590.73, \"learn_time_ms\": 14455.712}", "{\"n\": 5442, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3599.81, \"learn_time_ms\": 14458.977}", "{\"n\": 5443, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3595.47, \"learn_time_ms\": 14443.197}", "{\"n\": 5444, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3585.95, \"learn_time_ms\": 14451.614}", "{\"n\": 5445, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3577.6, \"learn_time_ms\": 14458.917}", "{\"n\": 5446, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3566.67, \"learn_time_ms\": 14472.312}", "{\"n\": 5447, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3570.55, \"learn_time_ms\": 14469.932}", "{\"n\": 5448, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3578.65, \"learn_time_ms\": 14471.718}", "{\"n\": 5449, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3572.21, \"learn_time_ms\": 14477.886}", "{\"n\": 5450, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3585.93, \"learn_time_ms\": 14487.92}", "{\"n\": 5451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3585.93, \"learn_time_ms\": 14480.33}", "{\"n\": 5452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3583.08, \"learn_time_ms\": 14475.135}", "{\"n\": 5453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3599.67, \"learn_time_ms\": 14502.626}", "{\"n\": 5454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3599.67, \"learn_time_ms\": 14493.486}", "{\"n\": 5455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3591.28, \"learn_time_ms\": 14506.528}", "{\"n\": 5456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3575.3, \"learn_time_ms\": 14491.16}", "{\"n\": 5457, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3575.3, \"learn_time_ms\": 14486.834}", "{\"n\": 5458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3566.18, \"learn_time_ms\": 14495.117}", "{\"n\": 5459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3571.84, \"learn_time_ms\": 14487.694}", "{\"n\": 5460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3556.94, \"learn_time_ms\": 14501.575}", "{\"n\": 5461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3556.94, \"learn_time_ms\": 14502.858}", "{\"n\": 5462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3556.94, \"learn_time_ms\": 14506.651}", "{\"n\": 5463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3556.94, \"learn_time_ms\": 14496.841}", "{\"n\": 5464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3569.59, \"learn_time_ms\": 14497.607}", "{\"n\": 5465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3560.39, \"learn_time_ms\": 14473.936}", "{\"n\": 5466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3550.22, \"learn_time_ms\": 14463.077}", "{\"n\": 5467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3543.16, \"learn_time_ms\": 14467.951}", "{\"n\": 5468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3543.16, \"learn_time_ms\": 14459.615}", "{\"n\": 5469, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3543.16, \"learn_time_ms\": 14462.839}", "{\"n\": 5470, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3541.88, \"learn_time_ms\": 14454.192}", "{\"n\": 5471, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3541.88, \"learn_time_ms\": 14457.227}", "{\"n\": 5472, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3541.88, \"learn_time_ms\": 14471.351}", "{\"n\": 5473, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3563.75, \"learn_time_ms\": 14489.65}", "{\"n\": 5474, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3563.75, \"learn_time_ms\": 14483.944}", "{\"n\": 5475, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3563.75, \"learn_time_ms\": 14486.998}", "{\"n\": 5476, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3551.72, \"learn_time_ms\": 14519.528}", "{\"n\": 5477, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3551.72, \"learn_time_ms\": 14512.124}", "{\"n\": 5478, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3555.45, \"learn_time_ms\": 14516.74}", "{\"n\": 5479, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3567.3, \"learn_time_ms\": 14516.617}", "{\"n\": 5480, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3577.84, \"learn_time_ms\": 14517.015}", "{\"n\": 5481, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3580.37, \"learn_time_ms\": 14516.953}", "{\"n\": 5482, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3580.37, \"learn_time_ms\": 14498.54}", "{\"n\": 5483, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3601.28, \"learn_time_ms\": 14479.997}", "{\"n\": 5484, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3601.28, \"learn_time_ms\": 14485.18}", "{\"n\": 5485, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3594.94, \"learn_time_ms\": 14480.361}", "{\"n\": 5486, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3598.08, \"learn_time_ms\": 14468.051}", "{\"n\": 5487, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3594.32, \"learn_time_ms\": 14471.829}", "{\"n\": 5488, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3604.18, \"learn_time_ms\": 14481.084}", "{\"n\": 5489, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3604.18, \"learn_time_ms\": 14481.903}", "{\"n\": 5490, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3600.14, \"learn_time_ms\": 14470.388}", "{\"n\": 5491, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3609.01, \"learn_time_ms\": 14485.582}", "{\"n\": 5492, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3599.53, \"learn_time_ms\": 14487.365}", "{\"n\": 5493, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3601.71, \"learn_time_ms\": 14501.29}", "{\"n\": 5494, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3612.23, \"learn_time_ms\": 14508.297}", "{\"n\": 5495, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3612.23, \"learn_time_ms\": 14515.304}", "{\"n\": 5496, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3617.72, \"learn_time_ms\": 14517.353}", "{\"n\": 5497, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3616.83, \"learn_time_ms\": 14508.316}", "{\"n\": 5498, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3611.38, \"learn_time_ms\": 14502.78}", "{\"n\": 5499, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3623.12, \"learn_time_ms\": 14512.373}", "{\"n\": 5500, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3631.15, \"learn_time_ms\": 14523.233}", "{\"n\": 5501, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3626.77, \"learn_time_ms\": 14510.627}", "{\"n\": 5502, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.24, \"learn_time_ms\": 14530.238}", "{\"n\": 5503, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3626.86, \"learn_time_ms\": 14519.722}", "{\"n\": 5504, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3626.86, \"learn_time_ms\": 14510.632}", "{\"n\": 5505, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3620.94, \"learn_time_ms\": 14516.781}", "{\"n\": 5506, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.72, \"learn_time_ms\": 14526.514}", "{\"n\": 5507, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3607.66, \"learn_time_ms\": 14550.4}", "{\"n\": 5508, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.58, \"learn_time_ms\": 14546.696}", "{\"n\": 5509, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3604.1, \"learn_time_ms\": 14549.066}", "{\"n\": 5510, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3601.88, \"learn_time_ms\": 14549.085}", "{\"n\": 5511, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.81, \"learn_time_ms\": 14549.821}", "{\"n\": 5512, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.33, \"learn_time_ms\": 14533.198}", "{\"n\": 5513, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3608.23, \"learn_time_ms\": 14529.362}", "{\"n\": 5514, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.67, \"learn_time_ms\": 14526.393}", "{\"n\": 5515, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3605.42, \"learn_time_ms\": 14518.59}", "{\"n\": 5516, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3604.95, \"learn_time_ms\": 14492.006}", "{\"n\": 5517, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.45, \"learn_time_ms\": 14472.454}", "{\"n\": 5518, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3615.12, \"learn_time_ms\": 14471.079}", "{\"n\": 5519, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3615.12, \"learn_time_ms\": 14460.529}", "{\"n\": 5520, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3615.12, \"learn_time_ms\": 14446.772}", "{\"n\": 5521, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3620.72, \"learn_time_ms\": 14448.317}", "{\"n\": 5522, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3606.65, \"learn_time_ms\": 14458.068}", "{\"n\": 5523, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3598.96, \"learn_time_ms\": 14440.411}", "{\"n\": 5524, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.74, \"learn_time_ms\": 14449.11}", "{\"n\": 5525, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.74, \"learn_time_ms\": 14442.394}", "{\"n\": 5526, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3586.01, \"learn_time_ms\": 14444.337}", "{\"n\": 5527, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3586.01, \"learn_time_ms\": 14440.065}", "{\"n\": 5528, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3571.28, \"learn_time_ms\": 14426.946}", "{\"n\": 5529, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3574.83, \"learn_time_ms\": 14426.345}", "{\"n\": 5530, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3584.34, \"learn_time_ms\": 14435.781}", "{\"n\": 5531, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3584.34, \"learn_time_ms\": 14437.62}", "{\"n\": 5532, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.17, \"learn_time_ms\": 14425.711}", "{\"n\": 5533, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.17, \"learn_time_ms\": 14452.405}", "{\"n\": 5534, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.17, \"learn_time_ms\": 14456.704}", "{\"n\": 5535, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3588.35, \"learn_time_ms\": 14464.274}", "{\"n\": 5536, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.4, \"learn_time_ms\": 14476.112}", "{\"n\": 5537, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.4, \"learn_time_ms\": 14489.336}", "{\"n\": 5538, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.4, \"learn_time_ms\": 14504.275}", "{\"n\": 5539, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.4, \"learn_time_ms\": 14503.277}", "{\"n\": 5540, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.14, \"learn_time_ms\": 14500.96}", "{\"n\": 5541, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.14, \"learn_time_ms\": 14495.064}", "{\"n\": 5542, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3660.75, \"learn_time_ms\": 14508.178}", "{\"n\": 5543, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3667.46, \"learn_time_ms\": 14495.345}", "{\"n\": 5544, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3680.87, \"learn_time_ms\": 14468.592}", "{\"n\": 5545, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3681.59, \"learn_time_ms\": 14460.495}", "{\"n\": 5546, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3679.23, \"learn_time_ms\": 14454.827}", "{\"n\": 5547, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3672.35, \"learn_time_ms\": 14447.411}", "{\"n\": 5548, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.31, \"learn_time_ms\": 14450.843}", "{\"n\": 5549, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3661.97, \"learn_time_ms\": 14462.076}", "{\"n\": 5550, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3662.59, \"learn_time_ms\": 14456.862}", "{\"n\": 5551, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3658.76, \"learn_time_ms\": 14460.959}", "{\"n\": 5552, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3649.49, \"learn_time_ms\": 14465.339}", "{\"n\": 5553, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3649.49, \"learn_time_ms\": 14450.99}", "{\"n\": 5554, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3640.41, \"learn_time_ms\": 14456.982}", "{\"n\": 5555, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3642.04, \"learn_time_ms\": 14460.372}", "{\"n\": 5556, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3625.47, \"learn_time_ms\": 14440.58}", "{\"n\": 5557, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3633.28, \"learn_time_ms\": 14442.137}", "{\"n\": 5558, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.58, \"learn_time_ms\": 14432.351}", "{\"n\": 5559, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.58, \"learn_time_ms\": 14430.644}", "{\"n\": 5560, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.11, \"learn_time_ms\": 14439.874}", "{\"n\": 5561, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3619.11, \"learn_time_ms\": 14438.364}", "{\"n\": 5562, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.62, \"learn_time_ms\": 14432.257}", "{\"n\": 5563, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.62, \"learn_time_ms\": 14453.39}", "{\"n\": 5564, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.62, \"learn_time_ms\": 14460.89}", "{\"n\": 5565, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.62, \"learn_time_ms\": 14477.783}", "{\"n\": 5566, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.93, \"learn_time_ms\": 14508.25}", "{\"n\": 5567, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.45, \"learn_time_ms\": 14520.089}", "{\"n\": 5568, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3603.45, \"learn_time_ms\": 14517.544}", "{\"n\": 5569, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3576.43, \"learn_time_ms\": 14503.103}", "{\"n\": 5570, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3576.43, \"learn_time_ms\": 14486.463}", "{\"n\": 5571, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3579.54, \"learn_time_ms\": 14475.156}", "{\"n\": 5572, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3586.14, \"learn_time_ms\": 14463.016}", "{\"n\": 5573, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3582.35, \"learn_time_ms\": 14466.519}", "{\"n\": 5574, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.45, \"learn_time_ms\": 14467.964}", "{\"n\": 5575, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.95, \"learn_time_ms\": 14459.682}", "{\"n\": 5576, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3586.52, \"learn_time_ms\": 14472.33}", "{\"n\": 5577, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3581.01, \"learn_time_ms\": 14455.662}", "{\"n\": 5578, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3564.71, \"learn_time_ms\": 14466.547}", "{\"n\": 5579, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3555.09, \"learn_time_ms\": 14475.828}", "{\"n\": 5580, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3562.63, \"learn_time_ms\": 14485.788}", "{\"n\": 5581, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3565.27, \"learn_time_ms\": 14496.188}", "{\"n\": 5582, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3551.9, \"learn_time_ms\": 14506.126}", "{\"n\": 5583, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3557.4, \"learn_time_ms\": 14497.9}", "{\"n\": 5584, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3557.64, \"learn_time_ms\": 14498.254}", "{\"n\": 5585, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3566.26, \"learn_time_ms\": 14492.059}", "{\"n\": 5586, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3555.98, \"learn_time_ms\": 14467.016}", "{\"n\": 5587, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3555.98, \"learn_time_ms\": 14490.954}", "{\"n\": 5588, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3557.17, \"learn_time_ms\": 14480.759}", "{\"n\": 5589, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3565.78, \"learn_time_ms\": 14480.347}", "{\"n\": 5590, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3568.39, \"learn_time_ms\": 14486.514}", "{\"n\": 5591, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3576.45, \"learn_time_ms\": 14493.15}", "{\"n\": 5592, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3586.18, \"learn_time_ms\": 14487.97}", "{\"n\": 5593, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3598.19, \"learn_time_ms\": 14491.486}", "{\"n\": 5594, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3607.16, \"learn_time_ms\": 14506.168}", "{\"n\": 5595, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3607.16, \"learn_time_ms\": 14513.366}", "{\"n\": 5596, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3607.16, \"learn_time_ms\": 14510.911}", "{\"n\": 5597, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3597.0, \"learn_time_ms\": 14495.973}", "{\"n\": 5598, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3628.78, \"learn_time_ms\": 14488.047}", "{\"n\": 5599, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3646.34, \"learn_time_ms\": 14492.033}", "{\"n\": 5600, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.77, \"learn_time_ms\": 14483.717}", "{\"n\": 5601, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.77, \"learn_time_ms\": 14471.311}", "{\"n\": 5602, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3638.3, \"learn_time_ms\": 14479.311}", "{\"n\": 5603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3642.96, \"learn_time_ms\": 14476.665}", "{\"n\": 5604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3639.0, \"learn_time_ms\": 14459.965}", "{\"n\": 5605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3639.0, \"learn_time_ms\": 14433.604}", "{\"n\": 5606, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3649.19, \"learn_time_ms\": 14429.431}", "{\"n\": 5607, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3629.58, \"learn_time_ms\": 14421.737}", "{\"n\": 5608, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3624.11, \"learn_time_ms\": 14440.827}", "{\"n\": 5609, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3626.21, \"learn_time_ms\": 14433.349}", "{\"n\": 5610, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3626.2, \"learn_time_ms\": 14441.31}", "{\"n\": 5611, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3623.29, \"learn_time_ms\": 14460.534}", "{\"n\": 5612, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3625.74, \"learn_time_ms\": 14447.547}", "{\"n\": 5613, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3616.71, \"learn_time_ms\": 14449.112}", "{\"n\": 5614, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3602.38, \"learn_time_ms\": 14460.766}", "{\"n\": 5615, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3587.87, \"learn_time_ms\": 14487.214}", "{\"n\": 5616, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3587.87, \"learn_time_ms\": 14491.667}", "{\"n\": 5617, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3582.76, \"learn_time_ms\": 14503.465}", "{\"n\": 5618, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3582.76, \"learn_time_ms\": 14509.384}", "{\"n\": 5619, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3569.51, \"learn_time_ms\": 14510.128}", "{\"n\": 5620, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3548.78, \"learn_time_ms\": 14511.141}", "{\"n\": 5621, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3545.96, \"learn_time_ms\": 14490.061}", "{\"n\": 5622, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3545.96, \"learn_time_ms\": 14482.836}", "{\"n\": 5623, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3534.93, \"learn_time_ms\": 14482.734}", "{\"n\": 5624, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3546.46, \"learn_time_ms\": 14481.359}", "{\"n\": 5625, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3566.57, \"learn_time_ms\": 14486.412}", "{\"n\": 5626, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3569.41, \"learn_time_ms\": 14500.472}", "{\"n\": 5627, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3569.41, \"learn_time_ms\": 14487.939}", "{\"n\": 5628, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3576.05, \"learn_time_ms\": 14476.273}", "{\"n\": 5629, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3565.38, \"learn_time_ms\": 14473.047}", "{\"n\": 5630, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3568.53, \"learn_time_ms\": 14469.825}", "{\"n\": 5631, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3562.55, \"learn_time_ms\": 14475.882}", "{\"n\": 5632, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3558.58, \"learn_time_ms\": 14484.004}", "{\"n\": 5633, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3558.58, \"learn_time_ms\": 14483.032}", "{\"n\": 5634, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3570.09, \"learn_time_ms\": 14479.959}", "{\"n\": 5635, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3581.51, \"learn_time_ms\": 14474.11}", "{\"n\": 5636, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3581.51, \"learn_time_ms\": 14473.624}", "{\"n\": 5637, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3578.32, \"learn_time_ms\": 14462.642}", "{\"n\": 5638, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.38, \"learn_time_ms\": 14463.429}", "{\"n\": 5639, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.38, \"learn_time_ms\": 14479.849}", "{\"n\": 5640, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3591.68, \"learn_time_ms\": 14482.032}", "{\"n\": 5641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3613.96, \"learn_time_ms\": 14465.323}", "{\"n\": 5642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3590.0, \"learn_time_ms\": 14463.11}", "{\"n\": 5643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3615.66, \"learn_time_ms\": 14462.544}", "{\"n\": 5644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3621.31, \"learn_time_ms\": 14462.877}", "{\"n\": 5645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3621.31, \"learn_time_ms\": 14443.819}", "{\"n\": 5646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3629.07, \"learn_time_ms\": 14427.087}", "{\"n\": 5647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3623.37, \"learn_time_ms\": 14440.924}", "{\"n\": 5648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3620.02, \"learn_time_ms\": 14442.951}", "{\"n\": 5649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3598.33, \"learn_time_ms\": 14422.396}", "{\"n\": 5650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3601.55, \"learn_time_ms\": 14427.55}", "{\"n\": 5651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3601.15, \"learn_time_ms\": 14450.927}", "{\"n\": 5652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3600.21, \"learn_time_ms\": 14446.371}", "{\"n\": 5653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3616.77, \"learn_time_ms\": 14443.602}", "{\"n\": 5654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3622.39, \"learn_time_ms\": 14434.598}", "{\"n\": 5655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3625.51, \"learn_time_ms\": 14455.7}", "{\"n\": 5656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3631.39, \"learn_time_ms\": 14476.368}", "{\"n\": 5657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3619.61, \"learn_time_ms\": 14475.194}", "{\"n\": 5658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3610.33, \"learn_time_ms\": 14475.664}", "{\"n\": 5659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3606.74, \"learn_time_ms\": 14474.71}", "{\"n\": 5660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3604.68, \"learn_time_ms\": 14476.259}", "{\"n\": 5661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3578.65, \"learn_time_ms\": 14467.185}", "{\"n\": 5662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3567.16, \"learn_time_ms\": 14474.134}", "{\"n\": 5663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3567.16, \"learn_time_ms\": 14487.48}", "{\"n\": 5664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3558.65, \"learn_time_ms\": 14495.511}", "{\"n\": 5665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3539.41, \"learn_time_ms\": 14470.444}", "{\"n\": 5666, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3531.41, \"learn_time_ms\": 14455.357}", "{\"n\": 5667, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3537.65, \"learn_time_ms\": 14467.037}", "{\"n\": 5668, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3537.65, \"learn_time_ms\": 14460.869}", "{\"n\": 5669, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3521.35, \"learn_time_ms\": 14473.034}", "{\"n\": 5670, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3508.51, \"learn_time_ms\": 14467.562}", "{\"n\": 5671, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3484.37, \"learn_time_ms\": 14467.402}", "{\"n\": 5672, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3481.1, \"learn_time_ms\": 14462.244}", "{\"n\": 5673, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3481.1, \"learn_time_ms\": 14459.988}", "{\"n\": 5674, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3481.1, \"learn_time_ms\": 14459.81}", "{\"n\": 5675, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3482.84, \"learn_time_ms\": 14478.308}", "{\"n\": 5676, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3480.2, \"learn_time_ms\": 14485.518}", "{\"n\": 5677, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3471.92, \"learn_time_ms\": 14491.817}", "{\"n\": 5678, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3458.83, \"learn_time_ms\": 14489.889}", "{\"n\": 5679, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3475.45, \"learn_time_ms\": 14472.41}", "{\"n\": 5680, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3475.45, \"learn_time_ms\": 14455.695}", "{\"n\": 5681, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3482.01, \"learn_time_ms\": 14442.846}", "{\"n\": 5682, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3456.1, \"learn_time_ms\": 14439.475}", "{\"n\": 5683, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3467.64, \"learn_time_ms\": 14432.726}", "{\"n\": 5684, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3467.64, \"learn_time_ms\": 14424.399}", "{\"n\": 5685, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3466.22, \"learn_time_ms\": 14414.193}", "{\"n\": 5686, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3466.22, \"learn_time_ms\": 14422.352}", "{\"n\": 5687, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3473.69, \"learn_time_ms\": 14400.18}", "{\"n\": 5688, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3465.85, \"learn_time_ms\": 14397.717}", "{\"n\": 5689, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3474.21, \"learn_time_ms\": 14411.996}", "{\"n\": 5690, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3492.26, \"learn_time_ms\": 14419.83}", "{\"n\": 5691, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3492.26, \"learn_time_ms\": 14437.045}", "{\"n\": 5692, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3502.82, \"learn_time_ms\": 14455.022}", "{\"n\": 5693, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3513.81, \"learn_time_ms\": 14451.101}", "{\"n\": 5694, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3527.12, \"learn_time_ms\": 14454.745}", "{\"n\": 5695, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3527.12, \"learn_time_ms\": 14462.689}", "{\"n\": 5696, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3526.81, \"learn_time_ms\": 14463.564}", "{\"n\": 5697, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3496.53, \"learn_time_ms\": 14458.454}", "{\"n\": 5698, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3496.53, \"learn_time_ms\": 14467.149}", "{\"n\": 5699, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3507.71, \"learn_time_ms\": 14476.305}", "{\"n\": 5700, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3492.12, \"learn_time_ms\": 14467.236}", "{\"n\": 5701, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3495.23, \"learn_time_ms\": 14477.788}", "{\"n\": 5702, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3496.58, \"learn_time_ms\": 14470.755}", "{\"n\": 5703, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3491.6, \"learn_time_ms\": 14474.352}", "{\"n\": 5704, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3499.6, \"learn_time_ms\": 14468.831}", "{\"n\": 5705, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3499.6, \"learn_time_ms\": 14469.082}", "{\"n\": 5706, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3504.25, \"learn_time_ms\": 14452.282}", "{\"n\": 5707, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3494.08, \"learn_time_ms\": 14475.146}", "{\"n\": 5708, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3482.06, \"learn_time_ms\": 14479.438}", "{\"n\": 5709, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3494.97, \"learn_time_ms\": 14470.174}", "{\"n\": 5710, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3494.97, \"learn_time_ms\": 14476.566}", "{\"n\": 5711, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3500.6, \"learn_time_ms\": 14476.219}", "{\"n\": 5712, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3472.24, \"learn_time_ms\": 14493.994}", "{\"n\": 5713, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3473.68, \"learn_time_ms\": 14499.974}", "{\"n\": 5714, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3482.52, \"learn_time_ms\": 14498.245}", "{\"n\": 5715, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3482.52, \"learn_time_ms\": 14503.441}", "{\"n\": 5716, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3467.47, \"learn_time_ms\": 14522.106}", "{\"n\": 5717, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3482.09, \"learn_time_ms\": 14513.379}", "{\"n\": 5718, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3471.25, \"learn_time_ms\": 14502.196}", "{\"n\": 5719, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3464.55, \"learn_time_ms\": 14495.409}", "{\"n\": 5720, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3464.55, \"learn_time_ms\": 14511.815}", "{\"n\": 5721, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3468.82, \"learn_time_ms\": 14506.844}", "{\"n\": 5722, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3468.82, \"learn_time_ms\": 14484.217}", "{\"n\": 5723, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3457.43, \"learn_time_ms\": 14479.605}", "{\"n\": 5724, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3456.69, \"learn_time_ms\": 14488.959}", "{\"n\": 5725, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3447.15, \"learn_time_ms\": 14491.142}", "{\"n\": 5726, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3449.48, \"learn_time_ms\": 14482.452}", "{\"n\": 5727, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3452.81, \"learn_time_ms\": 14467.537}", "{\"n\": 5728, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3456.0, \"learn_time_ms\": 14468.355}", "{\"n\": 5729, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3449.08, \"learn_time_ms\": 14471.973}", "{\"n\": 5730, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3463.15, \"learn_time_ms\": 14458.2}", "{\"n\": 5731, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3475.63, \"learn_time_ms\": 14467.552}", "{\"n\": 5732, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3464.78, \"learn_time_ms\": 14467.968}", "{\"n\": 5733, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3464.78, \"learn_time_ms\": 14466.152}", "{\"n\": 5734, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3474.04, \"learn_time_ms\": 14462.005}", "{\"n\": 5735, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3479.5, \"learn_time_ms\": 14436.166}", "{\"n\": 5736, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3483.78, \"learn_time_ms\": 14434.45}", "{\"n\": 5737, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3490.98, \"learn_time_ms\": 14451.565}", "{\"n\": 5738, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3496.49, \"learn_time_ms\": 14453.882}", "{\"n\": 5739, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3496.49, \"learn_time_ms\": 14462.479}", "{\"n\": 5740, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3510.58, \"learn_time_ms\": 14461.951}", "{\"n\": 5741, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3519.2, \"learn_time_ms\": 14458.534}", "{\"n\": 5742, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3519.2, \"learn_time_ms\": 14473.708}", "{\"n\": 5743, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3508.63, \"learn_time_ms\": 14473.916}", "{\"n\": 5744, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3523.14, \"learn_time_ms\": 14481.737}", "{\"n\": 5745, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3529.13, \"learn_time_ms\": 14500.025}", "{\"n\": 5746, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3539.04, \"learn_time_ms\": 14495.228}", "{\"n\": 5747, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3539.04, \"learn_time_ms\": 14497.096}", "{\"n\": 5748, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3539.36, \"learn_time_ms\": 14507.855}", "{\"n\": 5749, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3528.48, \"learn_time_ms\": 14495.081}", "{\"n\": 5750, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3536.54, \"learn_time_ms\": 14503.124}", "{\"n\": 5751, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3548.89, \"learn_time_ms\": 14485.781}", "{\"n\": 5752, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3548.89, \"learn_time_ms\": 14475.595}", "{\"n\": 5753, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3548.89, \"learn_time_ms\": 14476.819}", "{\"n\": 5754, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3551.89, \"learn_time_ms\": 14465.686}", "{\"n\": 5755, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3548.69, \"learn_time_ms\": 14464.686}", "{\"n\": 5756, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3532.17, \"learn_time_ms\": 14478.666}", "{\"n\": 5757, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3525.26, \"learn_time_ms\": 14472.265}", "{\"n\": 5758, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3507.69, \"learn_time_ms\": 14464.919}", "{\"n\": 5759, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3501.84, \"learn_time_ms\": 14469.591}", "{\"n\": 5760, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3501.07, \"learn_time_ms\": 14479.48}", "{\"n\": 5761, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3495.86, \"learn_time_ms\": 14485.783}", "{\"n\": 5762, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3495.86, \"learn_time_ms\": 14486.332}", "{\"n\": 5763, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3488.7, \"learn_time_ms\": 14488.775}", "{\"n\": 5764, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3467.4, \"learn_time_ms\": 14508.55}", "{\"n\": 5765, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3457.06, \"learn_time_ms\": 14510.866}", "{\"n\": 5766, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3472.67, \"learn_time_ms\": 14492.314}", "{\"n\": 5767, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3472.67, \"learn_time_ms\": 14489.223}", "{\"n\": 5768, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3466.81, \"learn_time_ms\": 14487.84}", "{\"n\": 5769, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3466.81, \"learn_time_ms\": 14503.665}", "{\"n\": 5770, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3466.81, \"learn_time_ms\": 14499.708}", "{\"n\": 5771, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3488.7, \"learn_time_ms\": 14502.253}", "{\"n\": 5772, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3497.24, \"learn_time_ms\": 14492.923}", "{\"n\": 5773, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3497.24, \"learn_time_ms\": 14492.892}", "{\"n\": 5774, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3488.59, \"learn_time_ms\": 14487.779}", "{\"n\": 5775, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3488.59, \"learn_time_ms\": 14482.189}", "{\"n\": 5776, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3488.64, \"learn_time_ms\": 14498.113}", "{\"n\": 5777, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3519.92, \"learn_time_ms\": 14502.143}", "{\"n\": 5778, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3517.88, \"learn_time_ms\": 14492.166}", "{\"n\": 5779, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3524.0, \"learn_time_ms\": 14470.92}", "{\"n\": 5780, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3526.55, \"learn_time_ms\": 14465.551}", "{\"n\": 5781, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3515.07, \"learn_time_ms\": 14465.592}", "{\"n\": 5782, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3506.65, \"learn_time_ms\": 14475.327}", "{\"n\": 5783, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3521.84, \"learn_time_ms\": 14480.827}", "{\"n\": 5784, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3521.84, \"learn_time_ms\": 14477.781}", "{\"n\": 5785, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3521.84, \"learn_time_ms\": 14490.111}", "{\"n\": 5786, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3520.3, \"learn_time_ms\": 14484.545}", "{\"n\": 5787, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3503.14, \"learn_time_ms\": 14499.325}", "{\"n\": 5788, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3494.65, \"learn_time_ms\": 14497.949}", "{\"n\": 5789, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3487.71, \"learn_time_ms\": 14518.858}", "{\"n\": 5790, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3475.58, \"learn_time_ms\": 14513.128}", "{\"n\": 5791, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3491.68, \"learn_time_ms\": 14508.575}", "{\"n\": 5792, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3490.21, \"learn_time_ms\": 14511.9}", "{\"n\": 5793, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3505.15, \"learn_time_ms\": 14502.118}", "{\"n\": 5794, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3514.29, \"learn_time_ms\": 14506.374}", "{\"n\": 5795, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3523.81, \"learn_time_ms\": 14504.217}", "{\"n\": 5796, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3523.81, \"learn_time_ms\": 14504.594}", "{\"n\": 5797, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3523.81, \"learn_time_ms\": 14498.733}", "{\"n\": 5798, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3506.84, \"learn_time_ms\": 14510.341}", "{\"n\": 5799, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3497.93, \"learn_time_ms\": 14496.869}", "{\"n\": 5800, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3502.05, \"learn_time_ms\": 14509.43}", "{\"n\": 5801, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3507.42, \"learn_time_ms\": 14514.923}", "{\"n\": 5802, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3493.22, \"learn_time_ms\": 14493.598}", "{\"n\": 5803, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3480.25, \"learn_time_ms\": 14497.824}", "{\"n\": 5804, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3480.25, \"learn_time_ms\": 14495.229}", "{\"n\": 5805, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3504.83, \"learn_time_ms\": 14489.865}", "{\"n\": 5806, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3505.65, \"learn_time_ms\": 14499.701}", "{\"n\": 5807, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3510.37, \"learn_time_ms\": 14491.113}", "{\"n\": 5808, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3513.7, \"learn_time_ms\": 14487.867}", "{\"n\": 5809, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3519.05, \"learn_time_ms\": 14495.48}", "{\"n\": 5810, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3504.82, \"learn_time_ms\": 14481.238}", "{\"n\": 5811, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3504.82, \"learn_time_ms\": 14478.189}", "{\"n\": 5812, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3494.22, \"learn_time_ms\": 14519.383}", "{\"n\": 5813, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3494.22, \"learn_time_ms\": 14510.338}", "{\"n\": 5814, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3484.79, \"learn_time_ms\": 14508.87}", "{\"n\": 5815, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3490.02, \"learn_time_ms\": 14519.425}", "{\"n\": 5816, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3485.25, \"learn_time_ms\": 14517.042}", "{\"n\": 5817, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3469.87, \"learn_time_ms\": 14517.929}", "{\"n\": 5818, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3470.76, \"learn_time_ms\": 14535.103}", "{\"n\": 5819, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3475.63, \"learn_time_ms\": 14537.578}", "{\"n\": 5820, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3477.31, \"learn_time_ms\": 14532.851}", "{\"n\": 5821, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3461.13, \"learn_time_ms\": 14540.142}", "{\"n\": 5822, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3461.13, \"learn_time_ms\": 14522.895}", "{\"n\": 5823, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3462.17, \"learn_time_ms\": 14526.52}", "{\"n\": 5824, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3457.86, \"learn_time_ms\": 14512.032}", "{\"n\": 5825, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3469.88, \"learn_time_ms\": 14491.615}", "{\"n\": 5826, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3460.65, \"learn_time_ms\": 14490.72}", "{\"n\": 5827, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3451.0, \"learn_time_ms\": 14492.184}", "{\"n\": 5828, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3464.18, \"learn_time_ms\": 14480.366}", "{\"n\": 5829, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3464.18, \"learn_time_ms\": 14474.014}", "{\"n\": 5830, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3464.18, \"learn_time_ms\": 14484.734}", "{\"n\": 5831, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3470.26, \"learn_time_ms\": 14492.286}", "{\"n\": 5832, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3481.95, \"learn_time_ms\": 14480.314}", "{\"n\": 5833, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3491.93, \"learn_time_ms\": 14474.217}", "{\"n\": 5834, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3479.09, \"learn_time_ms\": 14491.749}", "{\"n\": 5835, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3479.09, \"learn_time_ms\": 14495.923}", "{\"n\": 5836, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3477.92, \"learn_time_ms\": 14485.928}", "{\"n\": 5837, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3492.98, \"learn_time_ms\": 14492.32}", "{\"n\": 5838, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3525.36, \"learn_time_ms\": 14484.921}", "{\"n\": 5839, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3527.66, \"learn_time_ms\": 14486.167}", "{\"n\": 5840, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3540.89, \"learn_time_ms\": 14489.144}", "{\"n\": 5841, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3540.89, \"learn_time_ms\": 14474.344}", "{\"n\": 5842, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3534.31, \"learn_time_ms\": 14495.682}", "{\"n\": 5843, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3534.31, \"learn_time_ms\": 14499.58}", "{\"n\": 5844, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3520.12, \"learn_time_ms\": 14492.489}", "{\"n\": 5845, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3516.41, \"learn_time_ms\": 14499.214}", "{\"n\": 5846, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3518.14, \"learn_time_ms\": 14501.338}", "{\"n\": 5847, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3518.14, \"learn_time_ms\": 14495.694}", "{\"n\": 5848, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3531.15, \"learn_time_ms\": 14503.218}", "{\"n\": 5849, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3497.2, \"learn_time_ms\": 14500.114}", "{\"n\": 5850, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3495.46, \"learn_time_ms\": 14500.853}", "{\"n\": 5851, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3495.46, \"learn_time_ms\": 14500.301}", "{\"n\": 5852, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3495.46, \"learn_time_ms\": 14493.167}", "{\"n\": 5853, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3495.46, \"learn_time_ms\": 14495.295}", "{\"n\": 5854, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3497.05, \"learn_time_ms\": 14505.51}", "{\"n\": 5855, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3493.65, \"learn_time_ms\": 14510.51}", "{\"n\": 5856, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3473.49, \"learn_time_ms\": 14523.66}", "{\"n\": 5857, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3473.49, \"learn_time_ms\": 14531.038}", "{\"n\": 5858, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3473.49, \"learn_time_ms\": 14538.952}", "{\"n\": 5859, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3489.0, \"learn_time_ms\": 14555.951}", "{\"n\": 5860, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3490.65, \"learn_time_ms\": 14562.019}", "{\"n\": 5861, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3511.93, \"learn_time_ms\": 14562.918}", "{\"n\": 5862, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3507.19, \"learn_time_ms\": 14560.12}", "{\"n\": 5863, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3507.19, \"learn_time_ms\": 14555.187}", "{\"n\": 5864, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3497.37, \"learn_time_ms\": 14546.794}", "{\"n\": 5865, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3477.2, \"learn_time_ms\": 14548.608}", "{\"n\": 5866, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3469.18, \"learn_time_ms\": 14538.561}", "{\"n\": 5867, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3472.06, \"learn_time_ms\": 14533.185}", "{\"n\": 5868, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3476.57, \"learn_time_ms\": 14525.828}", "{\"n\": 5869, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3475.21, \"learn_time_ms\": 14507.633}", "{\"n\": 5870, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3475.21, \"learn_time_ms\": 14494.132}", "{\"n\": 5871, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3466.26, \"learn_time_ms\": 14502.311}", "{\"n\": 5872, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3453.57, \"learn_time_ms\": 14502.505}", "{\"n\": 5873, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3453.57, \"learn_time_ms\": 14519.565}", "{\"n\": 5874, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3462.02, \"learn_time_ms\": 14517.749}", "{\"n\": 5875, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3453.69, \"learn_time_ms\": 14507.766}", "{\"n\": 5876, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3453.69, \"learn_time_ms\": 14513.445}", "{\"n\": 5877, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3457.56, \"learn_time_ms\": 14517.439}", "{\"n\": 5878, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3454.56, \"learn_time_ms\": 14522.292}", "{\"n\": 5879, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3454.56, \"learn_time_ms\": 14527.139}", "{\"n\": 5880, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3459.55, \"learn_time_ms\": 14543.106}", "{\"n\": 5881, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3452.15, \"learn_time_ms\": 14536.358}", "{\"n\": 5882, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3452.15, \"learn_time_ms\": 14523.25}", "{\"n\": 5883, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3460.72, \"learn_time_ms\": 14509.251}", "{\"n\": 5884, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3468.09, \"learn_time_ms\": 14521.08}", "{\"n\": 5885, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.96, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3470.84, \"learn_time_ms\": 14529.374}", "{\"n\": 5886, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3474.77, \"learn_time_ms\": 14511.694}", "{\"n\": 5887, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3467.9, \"learn_time_ms\": 14505.834}", "{\"n\": 5888, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3467.9, \"learn_time_ms\": 14489.458}", "{\"n\": 5889, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3477.59, \"learn_time_ms\": 14492.796}", "{\"n\": 5890, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3483.11, \"learn_time_ms\": 14482.943}", "{\"n\": 5891, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3479.59, \"learn_time_ms\": 14478.775}", "{\"n\": 5892, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3466.66, \"learn_time_ms\": 14481.792}", "{\"n\": 5893, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3486.79, \"learn_time_ms\": 14492.256}", "{\"n\": 5894, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3487.97, \"learn_time_ms\": 14490.275}", "{\"n\": 5895, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3486.85, \"learn_time_ms\": 14498.376}", "{\"n\": 5896, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3486.85, \"learn_time_ms\": 14520.025}", "{\"n\": 5897, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3471.91, \"learn_time_ms\": 14515.659}", "{\"n\": 5898, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3471.91, \"learn_time_ms\": 14534.055}", "{\"n\": 5899, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3471.59, \"learn_time_ms\": 14534.021}", "{\"n\": 5900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3478.36, \"learn_time_ms\": 14532.731}", "{\"n\": 5901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3461.37, \"learn_time_ms\": 14547.428}", "{\"n\": 5902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3461.37, \"learn_time_ms\": 14557.746}", "{\"n\": 5903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3465.23, \"learn_time_ms\": 14545.665}", "{\"n\": 5904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3470.26, \"learn_time_ms\": 14536.29}", "{\"n\": 5905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3482.28, \"learn_time_ms\": 14516.633}", "{\"n\": 5906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3509.82, \"learn_time_ms\": 14506.548}", "{\"n\": 5907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3518.88, \"learn_time_ms\": 14507.399}", "{\"n\": 5908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3512.76, \"learn_time_ms\": 14496.114}", "{\"n\": 5909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3512.76, \"learn_time_ms\": 14485.874}", "{\"n\": 5910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3486.1, \"learn_time_ms\": 14477.164}", "{\"n\": 5911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3486.1, \"learn_time_ms\": 14464.87}", "{\"n\": 5912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3478.84, \"learn_time_ms\": 14464.582}", "{\"n\": 5913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3487.68, \"learn_time_ms\": 14479.515}", "{\"n\": 5914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3478.45, \"learn_time_ms\": 14475.294}", "{\"n\": 5915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3478.45, \"learn_time_ms\": 14464.036}", "{\"n\": 5916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3484.23, \"learn_time_ms\": 14450.24}", "{\"n\": 5917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3470.77, \"learn_time_ms\": 14440.809}", "{\"n\": 5918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3470.77, \"learn_time_ms\": 14446.931}", "{\"n\": 5919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3470.77, \"learn_time_ms\": 14438.184}", "{\"n\": 5920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3460.3, \"learn_time_ms\": 14448.322}", "{\"n\": 5921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3460.3, \"learn_time_ms\": 14452.258}", "{\"n\": 5922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3460.3, \"learn_time_ms\": 14460.286}", "{\"n\": 5923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3484.28, \"learn_time_ms\": 14461.827}", "{\"n\": 5924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3464.71, \"learn_time_ms\": 14466.273}", "{\"n\": 5925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3464.71, \"learn_time_ms\": 14484.576}", "{\"n\": 5926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3476.04, \"learn_time_ms\": 14501.876}", "{\"n\": 5927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3472.06, \"learn_time_ms\": 14523.861}", "{\"n\": 5928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3486.03, \"learn_time_ms\": 14513.494}", "{\"n\": 5929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3496.0, \"learn_time_ms\": 14545.963}", "{\"n\": 5930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3514.01, \"learn_time_ms\": 14542.795}", "{\"n\": 5931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3526.57, \"learn_time_ms\": 14516.975}", "{\"n\": 5932, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3532.28, \"learn_time_ms\": 14510.237}", "{\"n\": 5933, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3533.61, \"learn_time_ms\": 14515.997}", "{\"n\": 5934, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3529.94, \"learn_time_ms\": 14518.033}", "{\"n\": 5935, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3518.68, \"learn_time_ms\": 14526.531}", "{\"n\": 5936, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3518.01, \"learn_time_ms\": 14530.624}", "{\"n\": 5937, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3520.73, \"learn_time_ms\": 14520.116}", "{\"n\": 5938, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3538.79, \"learn_time_ms\": 14525.754}", "{\"n\": 5939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3538.79, \"learn_time_ms\": 14519.415}", "{\"n\": 5940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3544.05, \"learn_time_ms\": 14515.645}", "{\"n\": 5941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3544.05, \"learn_time_ms\": 14531.575}", "{\"n\": 5942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3559.22, \"learn_time_ms\": 14512.782}", "{\"n\": 5943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3550.72, \"learn_time_ms\": 14495.019}", "{\"n\": 5944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3550.72, \"learn_time_ms\": 14483.162}", "{\"n\": 5945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3572.08, \"learn_time_ms\": 14472.428}", "{\"n\": 5946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3590.3, \"learn_time_ms\": 14450.339}", "{\"n\": 5947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.53, \"learn_time_ms\": 14435.844}", "{\"n\": 5948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.07, \"learn_time_ms\": 14431.402}", "{\"n\": 5949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.07, \"learn_time_ms\": 14421.785}", "{\"n\": 5950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.11, \"learn_time_ms\": 14415.602}", "{\"n\": 5951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.64, \"learn_time_ms\": 14422.541}", "{\"n\": 5952, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3594.13, \"learn_time_ms\": 14436.148}", "{\"n\": 5953, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3587.77, \"learn_time_ms\": 14443.148}", "{\"n\": 5954, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3582.05, \"learn_time_ms\": 14462.023}", "{\"n\": 5955, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3582.05, \"learn_time_ms\": 14469.494}", "{\"n\": 5956, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3570.53, \"learn_time_ms\": 14476.633}", "{\"n\": 5957, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3565.97, \"learn_time_ms\": 14509.836}", "{\"n\": 5958, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3554.07, \"learn_time_ms\": 14524.34}", "{\"n\": 5959, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3566.53, \"learn_time_ms\": 14527.042}", "{\"n\": 5960, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3564.12, \"learn_time_ms\": 14530.401}", "{\"n\": 5961, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3564.12, \"learn_time_ms\": 14522.514}", "{\"n\": 5962, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3564.12, \"learn_time_ms\": 14528.203}", "{\"n\": 5963, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3558.01, \"learn_time_ms\": 14527.903}", "{\"n\": 5964, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3551.74, \"learn_time_ms\": 14540.227}", "{\"n\": 5965, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3558.86, \"learn_time_ms\": 14535.165}", "{\"n\": 5966, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3567.96, \"learn_time_ms\": 14537.948}", "{\"n\": 5967, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3575.9, \"learn_time_ms\": 14524.888}", "{\"n\": 5968, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3575.9, \"learn_time_ms\": 14507.768}", "{\"n\": 5969, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3575.9, \"learn_time_ms\": 14508.454}", "{\"n\": 5970, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3569.24, \"learn_time_ms\": 14511.089}", "{\"n\": 5971, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3579.32, \"learn_time_ms\": 14515.152}", "{\"n\": 5972, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3593.56, \"learn_time_ms\": 14510.847}", "{\"n\": 5973, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3593.56, \"learn_time_ms\": 14507.212}", "{\"n\": 5974, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3593.56, \"learn_time_ms\": 14477.877}", "{\"n\": 5975, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3612.19, \"learn_time_ms\": 14470.493}", "{\"n\": 5976, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3612.19, \"learn_time_ms\": 14468.582}", "{\"n\": 5977, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3636.89, \"learn_time_ms\": 14479.974}", "{\"n\": 5978, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3644.09, \"learn_time_ms\": 14496.578}", "{\"n\": 5979, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3631.18, \"learn_time_ms\": 14503.122}", "{\"n\": 5980, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3631.18, \"learn_time_ms\": 14506.697}", "{\"n\": 5981, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3610.36, \"learn_time_ms\": 14520.144}", "{\"n\": 5982, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3610.36, \"learn_time_ms\": 14517.8}", "{\"n\": 5983, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3586.3, \"learn_time_ms\": 14524.236}", "{\"n\": 5984, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3583.49, \"learn_time_ms\": 14538.899}", "{\"n\": 5985, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3593.9, \"learn_time_ms\": 14567.627}", "{\"n\": 5986, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3599.56, \"learn_time_ms\": 14575.55}", "{\"n\": 5987, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3599.56, \"learn_time_ms\": 14561.677}", "{\"n\": 5988, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3599.56, \"learn_time_ms\": 14553.016}", "{\"n\": 5989, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3634.11, \"learn_time_ms\": 14539.322}", "{\"n\": 5990, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3618.07, \"learn_time_ms\": 14539.17}", "{\"n\": 5991, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3613.92, \"learn_time_ms\": 14530.114}", "{\"n\": 5992, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3630.92, \"learn_time_ms\": 14544.909}", "{\"n\": 5993, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3630.92, \"learn_time_ms\": 14544.665}", "{\"n\": 5994, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3630.92, \"learn_time_ms\": 14546.803}", "{\"n\": 5995, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3635.54, \"learn_time_ms\": 14525.716}", "{\"n\": 5996, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3633.26, \"learn_time_ms\": 14515.775}", "{\"n\": 5997, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3644.13, \"learn_time_ms\": 14504.471}", "{\"n\": 5998, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3650.57, \"learn_time_ms\": 14495.201}", "{\"n\": 5999, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3646.52, \"learn_time_ms\": 14503.281}", "{\"n\": 6000, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3657.45, \"learn_time_ms\": 14511.289}"]["{\"n\": 6001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15746.905}", "{\"n\": 6002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15410.389}", "{\"n\": 6003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15350.192}", "{\"n\": 6004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15297.21}", "{\"n\": 6005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15270.069}", "{\"n\": 6006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15250.722}", "{\"n\": 6007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15226.757}", "{\"n\": 6008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15214.363}", "{\"n\": 6009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15212.44}", "{\"n\": 6010, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2818.0, \"learn_time_ms\": 15200.573}", "{\"n\": 6011, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2798.5, \"learn_time_ms\": 15137.767}", "{\"n\": 6012, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3152.3333333333335, \"learn_time_ms\": 15137.627}", "{\"n\": 6013, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.333333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3615.1666666666665, \"learn_time_ms\": 15129.467}", "{\"n\": 6014, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.428571428571429, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3602.5714285714284, \"learn_time_ms\": 15129.051}", "{\"n\": 6015, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3667.875, \"learn_time_ms\": 15125.506}", "{\"n\": 6016, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3667.875, \"learn_time_ms\": 15121.704}", "{\"n\": 6017, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3600.4, \"learn_time_ms\": 15117.951}", "{\"n\": 6018, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -7.166666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3508.1666666666665, \"learn_time_ms\": 15115.344}", "{\"n\": 6019, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.714285714285714, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3609.0714285714284, \"learn_time_ms\": 15106.811}", "{\"n\": 6020, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.733333333333333, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3596.4666666666667, \"learn_time_ms\": 15104.877}", "{\"n\": 6021, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3663.625, \"learn_time_ms\": 15104.804}", "{\"n\": 6022, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.352941176470588, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3654.764705882353, \"learn_time_ms\": 15109.242}", "{\"n\": 6023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.222222222222222, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3673.0, \"learn_time_ms\": 15095.735}", "{\"n\": 6024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3626.05, \"learn_time_ms\": 15088.694}", "{\"n\": 6025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.318181818181818, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3632.318181818182, \"learn_time_ms\": 15076.847}", "{\"n\": 6026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.304347826086956, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3640.4347826086955, \"learn_time_ms\": 15053.424}", "{\"n\": 6027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3638.5416666666665, \"learn_time_ms\": 15048.559}", "{\"n\": 6028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3638.5416666666665, \"learn_time_ms\": 15015.706}", "{\"n\": 6029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3667.4, \"learn_time_ms\": 14975.908}", "{\"n\": 6030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.321428571428571, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.6428571428573, \"learn_time_ms\": 14946.569}", "{\"n\": 6031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.266666666666667, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3637.633333333333, \"learn_time_ms\": 14902.281}", "{\"n\": 6032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.290322580645161, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3639.7419354838707, \"learn_time_ms\": 14872.024}", "{\"n\": 6033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.290322580645161, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3639.7419354838707, \"learn_time_ms\": 14845.946}", "{\"n\": 6034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3623.03125, \"learn_time_ms\": 14802.706}", "{\"n\": 6035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.444444444444445, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3636.1944444444443, \"learn_time_ms\": 14774.543}", "{\"n\": 6036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.1891891891891895, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3647.3513513513512, \"learn_time_ms\": 14737.113}", "{\"n\": 6037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.2631578947368425, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3638.0263157894738, \"learn_time_ms\": 14695.261}", "{\"n\": 6038, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.17948717948718, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3648.5128205128203, \"learn_time_ms\": 14672.199}", "{\"n\": 6039, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.17948717948718, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3648.5128205128203, \"learn_time_ms\": 14676.427}", "{\"n\": 6040, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.146341463414634, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3654.390243902439, \"learn_time_ms\": 14657.757}", "{\"n\": 6041, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.238095238095238, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3643.309523809524, \"learn_time_ms\": 14670.285}", "{\"n\": 6042, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.555555555555555, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3605.777777777778, \"learn_time_ms\": 14667.854}", "{\"n\": 6043, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3615.695652173913, \"learn_time_ms\": 14671.808}", "{\"n\": 6044, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.574468085106383, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3606.255319148936, \"learn_time_ms\": 14692.628}", "{\"n\": 6045, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.604166666666667, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3600.0208333333335, \"learn_time_ms\": 14691.832}", "{\"n\": 6046, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3609.64, \"learn_time_ms\": 14709.162}", "{\"n\": 6047, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.653846153846154, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3602.326923076923, \"learn_time_ms\": 14721.277}", "{\"n\": 6048, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.653846153846154, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3602.326923076923, \"learn_time_ms\": 14741.006}", "{\"n\": 6049, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.679245283018868, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3608.5283018867926, \"learn_time_ms\": 14729.822}", "{\"n\": 6050, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.767857142857143, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3601.4285714285716, \"learn_time_ms\": 14748.327}", "{\"n\": 6051, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.807017543859649, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3599.035087719298, \"learn_time_ms\": 14724.573}", "{\"n\": 6052, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.932203389830509, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3576.898305084746, \"learn_time_ms\": 14712.428}", "{\"n\": 6053, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.932203389830509, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3576.898305084746, \"learn_time_ms\": 14684.277}", "{\"n\": 6054, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.819672131147541, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3591.9508196721313, \"learn_time_ms\": 14672.565}", "{\"n\": 6055, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.746031746031746, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3597.936507936508, \"learn_time_ms\": 14656.162}", "{\"n\": 6056, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.746031746031746, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3597.936507936508, \"learn_time_ms\": 14670.231}", "{\"n\": 6057, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.8307692307692305, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3587.276923076923, \"learn_time_ms\": 14679.281}", "{\"n\": 6058, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.940298507462686, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3572.3432835820895, \"learn_time_ms\": 14673.49}", "{\"n\": 6059, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.940298507462686, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3572.3432835820895, \"learn_time_ms\": 14682.241}", "{\"n\": 6060, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.782608695652174, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3581.782608695652, \"learn_time_ms\": 14677.708}", "{\"n\": 6061, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.971830985915493, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3553.3521126760565, \"learn_time_ms\": 14692.798}", "{\"n\": 6062, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.971830985915493, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3553.3521126760565, \"learn_time_ms\": 14705.89}", "{\"n\": 6063, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.905405405405405, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3561.175675675676, \"learn_time_ms\": 14727.166}", "{\"n\": 6064, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.933333333333334, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3558.173333333333, \"learn_time_ms\": 14723.902}", "{\"n\": 6065, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.921052631578948, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3563.7631578947367, \"learn_time_ms\": 14710.692}", "{\"n\": 6066, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.8734177215189876, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3566.025316455696, \"learn_time_ms\": 14660.192}", "{\"n\": 6067, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.8734177215189876, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3566.025316455696, \"learn_time_ms\": 14633.172}", "{\"n\": 6068, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.7125, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3567.325, \"learn_time_ms\": 14624.427}", "{\"n\": 6069, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.7125, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3567.325, \"learn_time_ms\": 14590.923}", "{\"n\": 6070, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.819277108433735, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3559.8072289156626, \"learn_time_ms\": 14594.044}", "{\"n\": 6071, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.837209302325581, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3551.7093023255816, \"learn_time_ms\": 14599.672}", "{\"n\": 6072, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.837209302325581, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3551.7093023255816, \"learn_time_ms\": 14572.582}", "{\"n\": 6073, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.724137931034483, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3552.425287356322, \"learn_time_ms\": 14564.663}", "{\"n\": 6074, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.730337078651686, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3549.224719101124, \"learn_time_ms\": 14570.908}", "{\"n\": 6075, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.711111111111111, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3552.366666666667, \"learn_time_ms\": 14576.827}", "{\"n\": 6076, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.78021978021978, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3539.835164835165, \"learn_time_ms\": 14615.179}", "{\"n\": 6077, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.76595744680851, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3547.1382978723404, \"learn_time_ms\": 14646.356}", "{\"n\": 6078, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.76595744680851, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3547.1382978723404, \"learn_time_ms\": 14652.265}", "{\"n\": 6079, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.76595744680851, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3547.1382978723404, \"learn_time_ms\": 14681.152}", "{\"n\": 6080, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.7894736842105265, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3543.557894736842, \"learn_time_ms\": 14643.147}", "{\"n\": 6081, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.708333333333333, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3553.375, \"learn_time_ms\": 14618.168}", "{\"n\": 6082, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.846938775510204, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3537.938775510204, \"learn_time_ms\": 14634.999}", "{\"n\": 6083, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.848484848484849, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3536.7676767676767, \"learn_time_ms\": 14658.077}", "{\"n\": 6084, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3551.79, \"learn_time_ms\": 14654.335}", "{\"n\": 6085, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3563.7, \"learn_time_ms\": 14676.577}", "{\"n\": 6086, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3563.7, \"learn_time_ms\": 14688.178}", "{\"n\": 6087, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3564.71, \"learn_time_ms\": 14682.783}", "{\"n\": 6088, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3564.19, \"learn_time_ms\": 14668.784}", "{\"n\": 6089, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3567.25, \"learn_time_ms\": 14631.985}", "{\"n\": 6090, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3580.83, \"learn_time_ms\": 14645.492}", "{\"n\": 6091, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3591.73, \"learn_time_ms\": 14671.558}", "{\"n\": 6092, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3584.61, \"learn_time_ms\": 14658.358}", "{\"n\": 6093, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3568.72, \"learn_time_ms\": 14640.52}", "{\"n\": 6094, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3545.66, \"learn_time_ms\": 14640.005}", "{\"n\": 6095, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3527.47, \"learn_time_ms\": 14645.812}", "{\"n\": 6096, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3527.47, \"learn_time_ms\": 14649.516}", "{\"n\": 6097, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3537.94, \"learn_time_ms\": 14642.061}", "{\"n\": 6098, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3537.94, \"learn_time_ms\": 14672.505}", "{\"n\": 6099, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.84, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3523.69, \"learn_time_ms\": 14714.196}", "{\"n\": 6100, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3513.32, \"learn_time_ms\": 14724.659}", "{\"n\": 6101, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3518.08, \"learn_time_ms\": 14720.971}", "{\"n\": 6102, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3518.6, \"learn_time_ms\": 14725.79}", "{\"n\": 6103, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3523.16, \"learn_time_ms\": 14736.06}", "{\"n\": 6104, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3523.16, \"learn_time_ms\": 14745.133}", "{\"n\": 6105, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3518.33, \"learn_time_ms\": 14730.413}", "{\"n\": 6106, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3525.64, \"learn_time_ms\": 14701.363}", "{\"n\": 6107, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3538.08, \"learn_time_ms\": 14689.846}", "{\"n\": 6108, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3529.96, \"learn_time_ms\": 14665.753}", "{\"n\": 6109, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3506.71, \"learn_time_ms\": 14657.225}", "{\"n\": 6110, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3507.83, \"learn_time_ms\": 14674.604}", "{\"n\": 6111, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3507.83, \"learn_time_ms\": 14631.155}", "{\"n\": 6112, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3505.54, \"learn_time_ms\": 14627.35}", "{\"n\": 6113, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3507.2, \"learn_time_ms\": 14631.578}", "{\"n\": 6114, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3507.54, \"learn_time_ms\": 14631.753}", "{\"n\": 6115, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3507.54, \"learn_time_ms\": 14645.858}", "{\"n\": 6116, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3510.41, \"learn_time_ms\": 14669.347}", "{\"n\": 6117, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3517.52, \"learn_time_ms\": 14686.075}", "{\"n\": 6118, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3522.49, \"learn_time_ms\": 14712.88}", "{\"n\": 6119, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3529.22, \"learn_time_ms\": 14701.299}", "{\"n\": 6120, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3529.22, \"learn_time_ms\": 14665.102}", "{\"n\": 6121, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3529.22, \"learn_time_ms\": 14694.495}", "{\"n\": 6122, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3536.42, \"learn_time_ms\": 14677.019}", "{\"n\": 6123, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3526.96, \"learn_time_ms\": 14653.462}", "{\"n\": 6124, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3521.08, \"learn_time_ms\": 14646.926}", "{\"n\": 6125, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3516.3, \"learn_time_ms\": 14640.552}", "{\"n\": 6126, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3516.3, \"learn_time_ms\": 14613.702}", "{\"n\": 6127, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3520.53, \"learn_time_ms\": 14625.753}", "{\"n\": 6128, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3530.83, \"learn_time_ms\": 14601.117}", "{\"n\": 6129, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3519.35, \"learn_time_ms\": 14617.118}", "{\"n\": 6130, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3531.39, \"learn_time_ms\": 14659.982}", "{\"n\": 6131, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3541.38, \"learn_time_ms\": 14677.129}", "{\"n\": 6132, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3531.98, \"learn_time_ms\": 14708.686}", "{\"n\": 6133, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3527.39, \"learn_time_ms\": 14700.734}", "{\"n\": 6134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3535.6, \"learn_time_ms\": 14674.136}", "{\"n\": 6135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3540.05, \"learn_time_ms\": 14679.086}", "{\"n\": 6136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3540.71, \"learn_time_ms\": 14691.444}", "{\"n\": 6137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3538.49, \"learn_time_ms\": 14682.575}", "{\"n\": 6138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3548.45, \"learn_time_ms\": 14692.658}", "{\"n\": 6139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3530.74, \"learn_time_ms\": 14701.307}", "{\"n\": 6140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3522.8, \"learn_time_ms\": 14694.526}", "{\"n\": 6141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3519.66, \"learn_time_ms\": 14691.269}", "{\"n\": 6142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3519.66, \"learn_time_ms\": 14694.604}", "{\"n\": 6143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3535.49, \"learn_time_ms\": 14696.565}", "{\"n\": 6144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3535.49, \"learn_time_ms\": 14727.899}", "{\"n\": 6145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3557.94, \"learn_time_ms\": 14732.743}", "{\"n\": 6146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3558.55, \"learn_time_ms\": 14748.422}", "{\"n\": 6147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3558.55, \"learn_time_ms\": 14702.183}", "{\"n\": 6148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3566.39, \"learn_time_ms\": 14703.731}", "{\"n\": 6149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3564.0, \"learn_time_ms\": 14698.246}", "{\"n\": 6150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3564.0, \"learn_time_ms\": 14649.629}", "{\"n\": 6151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3584.33, \"learn_time_ms\": 14643.703}", "{\"n\": 6152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3559.93, \"learn_time_ms\": 14631.311}", "{\"n\": 6153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3559.93, \"learn_time_ms\": 14642.003}", "{\"n\": 6154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3572.95, \"learn_time_ms\": 14615.526}", "{\"n\": 6155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3582.69, \"learn_time_ms\": 14610.565}", "{\"n\": 6156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3588.71, \"learn_time_ms\": 14600.705}", "{\"n\": 6157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3584.35, \"learn_time_ms\": 14633.311}", "{\"n\": 6158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3577.49, \"learn_time_ms\": 14630.667}", "{\"n\": 6159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3568.76, \"learn_time_ms\": 14634.138}", "{\"n\": 6160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3561.75, \"learn_time_ms\": 14679.269}", "{\"n\": 6161, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3545.33, \"learn_time_ms\": 14699.822}", "{\"n\": 6162, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3542.35, \"learn_time_ms\": 14712.748}", "{\"n\": 6163, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3527.5, \"learn_time_ms\": 14714.923}", "{\"n\": 6164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3502.06, \"learn_time_ms\": 14722.747}", "{\"n\": 6165, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3502.06, \"learn_time_ms\": 14725.18}", "{\"n\": 6166, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3520.68, \"learn_time_ms\": 14726.218}", "{\"n\": 6167, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3527.56, \"learn_time_ms\": 14736.212}", "{\"n\": 6168, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3541.52, \"learn_time_ms\": 14743.007}", "{\"n\": 6169, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3539.47, \"learn_time_ms\": 14743.368}", "{\"n\": 6170, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3539.47, \"learn_time_ms\": 14750.822}", "{\"n\": 6171, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3534.7, \"learn_time_ms\": 14732.5}", "{\"n\": 6172, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3565.02, \"learn_time_ms\": 14729.216}", "{\"n\": 6173, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3565.02, \"learn_time_ms\": 14722.799}", "{\"n\": 6174, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3558.27, \"learn_time_ms\": 14743.26}", "{\"n\": 6175, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3539.94, \"learn_time_ms\": 14734.365}", "{\"n\": 6176, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3555.69, \"learn_time_ms\": 14737.482}", "{\"n\": 6177, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3529.72, \"learn_time_ms\": 14737.648}", "{\"n\": 6178, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3529.72, \"learn_time_ms\": 14729.657}", "{\"n\": 6179, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3530.15, \"learn_time_ms\": 14730.099}", "{\"n\": 6180, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3532.48, \"learn_time_ms\": 14723.757}", "{\"n\": 6181, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3523.09, \"learn_time_ms\": 14730.004}", "{\"n\": 6182, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3545.02, \"learn_time_ms\": 14757.658}", "{\"n\": 6183, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3545.02, \"learn_time_ms\": 14786.634}", "{\"n\": 6184, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3545.02, \"learn_time_ms\": 14779.489}", "{\"n\": 6185, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3536.02, \"learn_time_ms\": 14802.905}", "{\"n\": 6186, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3552.35, \"learn_time_ms\": 14774.259}", "{\"n\": 6187, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3551.69, \"learn_time_ms\": 14763.325}", "{\"n\": 6188, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3547.12, \"learn_time_ms\": 14771.521}", "{\"n\": 6189, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3555.38, \"learn_time_ms\": 14758.805}", "{\"n\": 6190, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3555.38, \"learn_time_ms\": 14742.901}", "{\"n\": 6191, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3534.52, \"learn_time_ms\": 14742.75}", "{\"n\": 6192, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3525.81, \"learn_time_ms\": 14713.241}", "{\"n\": 6193, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3525.81, \"learn_time_ms\": 14709.29}", "{\"n\": 6194, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3519.67, \"learn_time_ms\": 14691.343}", "{\"n\": 6195, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3512.8, \"learn_time_ms\": 14671.253}", "{\"n\": 6196, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3525.4, \"learn_time_ms\": 14702.589}", "{\"n\": 6197, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3531.41, \"learn_time_ms\": 14716.172}", "{\"n\": 6198, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3528.41, \"learn_time_ms\": 14713.205}", "{\"n\": 6199, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3531.88, \"learn_time_ms\": 14717.011}", "{\"n\": 6200, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3523.7, \"learn_time_ms\": 14746.883}", "{\"n\": 6201, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3528.74, \"learn_time_ms\": 14746.873}", "{\"n\": 6202, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3528.74, \"learn_time_ms\": 14754.943}", "{\"n\": 6203, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3512.94, \"learn_time_ms\": 14733.506}", "{\"n\": 6204, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3506.31, \"learn_time_ms\": 14746.871}", "{\"n\": 6205, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3524.99, \"learn_time_ms\": 14754.475}", "{\"n\": 6206, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3514.42, \"learn_time_ms\": 14758.731}", "{\"n\": 6207, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3524.08, \"learn_time_ms\": 14753.836}", "{\"n\": 6208, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3524.08, \"learn_time_ms\": 14757.355}", "{\"n\": 6209, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3517.97, \"learn_time_ms\": 14767.228}", "{\"n\": 6210, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3521.09, \"learn_time_ms\": 14737.298}", "{\"n\": 6211, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3515.51, \"learn_time_ms\": 14727.645}", "{\"n\": 6212, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3530.88, \"learn_time_ms\": 14721.437}", "{\"n\": 6213, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3538.97, \"learn_time_ms\": 14733.142}", "{\"n\": 6214, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3553.74, \"learn_time_ms\": 14712.796}", "{\"n\": 6215, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3551.36, \"learn_time_ms\": 14702.48}", "{\"n\": 6216, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3536.9, \"learn_time_ms\": 14704.612}", "{\"n\": 6217, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3535.47, \"learn_time_ms\": 14712.762}", "{\"n\": 6218, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3534.87, \"learn_time_ms\": 14713.058}", "{\"n\": 6219, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3532.48, \"learn_time_ms\": 14708.325}", "{\"n\": 6220, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3522.42, \"learn_time_ms\": 14704.949}", "{\"n\": 6221, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3522.42, \"learn_time_ms\": 14716.454}", "{\"n\": 6222, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3519.98, \"learn_time_ms\": 14717.34}", "{\"n\": 6223, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3503.12, \"learn_time_ms\": 14726.325}", "{\"n\": 6224, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3492.54, \"learn_time_ms\": 14749.184}", "{\"n\": 6225, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3509.11, \"learn_time_ms\": 14767.246}", "{\"n\": 6226, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3519.44, \"learn_time_ms\": 14765.473}", "{\"n\": 6227, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3514.53, \"learn_time_ms\": 14766.62}", "{\"n\": 6228, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3513.36, \"learn_time_ms\": 14777.158}", "{\"n\": 6229, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3521.07, \"learn_time_ms\": 14773.798}", "{\"n\": 6230, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3521.07, \"learn_time_ms\": 14791.27}", "{\"n\": 6231, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3513.43, \"learn_time_ms\": 14771.114}", "{\"n\": 6232, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3520.33, \"learn_time_ms\": 14771.817}", "{\"n\": 6233, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3520.58, \"learn_time_ms\": 14768.075}", "{\"n\": 6234, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3515.89, \"learn_time_ms\": 14768.868}", "{\"n\": 6235, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3515.29, \"learn_time_ms\": 14758.779}", "{\"n\": 6236, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3515.29, \"learn_time_ms\": 14757.904}", "{\"n\": 6237, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3530.46, \"learn_time_ms\": 14761.347}", "{\"n\": 6238, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3530.46, \"learn_time_ms\": 14750.19}", "{\"n\": 6239, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3541.59, \"learn_time_ms\": 14773.039}", "{\"n\": 6240, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3554.31, \"learn_time_ms\": 14775.185}", "{\"n\": 6241, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3547.71, \"learn_time_ms\": 14796.159}", "{\"n\": 6242, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3547.71, \"learn_time_ms\": 14794.21}", "{\"n\": 6243, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3556.23, \"learn_time_ms\": 14780.607}", "{\"n\": 6244, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3556.23, \"learn_time_ms\": 14786.787}", "{\"n\": 6245, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3564.94, \"learn_time_ms\": 14794.769}", "{\"n\": 6246, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3543.71, \"learn_time_ms\": 14788.711}", "{\"n\": 6247, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3555.81, \"learn_time_ms\": 14745.362}", "{\"n\": 6248, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3559.66, \"learn_time_ms\": 14733.973}", "{\"n\": 6249, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3567.71, \"learn_time_ms\": 14716.037}", "{\"n\": 6250, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3567.71, \"learn_time_ms\": 14721.587}", "{\"n\": 6251, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3565.13, \"learn_time_ms\": 14720.742}", "{\"n\": 6252, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3567.95, \"learn_time_ms\": 14734.724}", "{\"n\": 6253, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3578.91, \"learn_time_ms\": 14725.46}", "{\"n\": 6254, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3572.84, \"learn_time_ms\": 14725.199}", "{\"n\": 6255, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3572.84, \"learn_time_ms\": 14717.15}", "{\"n\": 6256, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3571.96, \"learn_time_ms\": 14712.22}", "{\"n\": 6257, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3560.97, \"learn_time_ms\": 14753.227}", "{\"n\": 6258, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3575.81, \"learn_time_ms\": 14777.673}", "{\"n\": 6259, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.3, \"learn_time_ms\": 14784.992}", "{\"n\": 6260, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3556.63, \"learn_time_ms\": 14779.926}", "{\"n\": 6261, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3556.95, \"learn_time_ms\": 14779.694}", "{\"n\": 6262, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3559.71, \"learn_time_ms\": 14744.656}", "{\"n\": 6263, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3563.85, \"learn_time_ms\": 14764.952}", "{\"n\": 6264, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3574.16, \"learn_time_ms\": 14760.571}", "{\"n\": 6265, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3581.44, \"learn_time_ms\": 14763.839}", "{\"n\": 6266, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3583.6, \"learn_time_ms\": 14776.903}", "{\"n\": 6267, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3572.52, \"learn_time_ms\": 14774.172}", "{\"n\": 6268, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3570.89, \"learn_time_ms\": 14753.112}", "{\"n\": 6269, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3567.08, \"learn_time_ms\": 14743.37}", "{\"n\": 6270, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3565.71, \"learn_time_ms\": 14750.473}", "{\"n\": 6271, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3571.06, \"learn_time_ms\": 14751.178}", "{\"n\": 6272, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3577.71, \"learn_time_ms\": 14767.472}", "{\"n\": 6273, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3570.95, \"learn_time_ms\": 14768.354}", "{\"n\": 6274, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3565.28, \"learn_time_ms\": 14766.414}", "{\"n\": 6275, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3573.05, \"learn_time_ms\": 14762.991}", "{\"n\": 6276, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3573.05, \"learn_time_ms\": 14751.794}", "{\"n\": 6277, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3578.11, \"learn_time_ms\": 14754.972}", "{\"n\": 6278, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.37, \"learn_time_ms\": 14759.617}", "{\"n\": 6279, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3597.54, \"learn_time_ms\": 14763.426}", "{\"n\": 6280, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3596.46, \"learn_time_ms\": 14744.485}", "{\"n\": 6281, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3594.4, \"learn_time_ms\": 14744.918}", "{\"n\": 6282, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3603.28, \"learn_time_ms\": 14747.064}", "{\"n\": 6283, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3603.28, \"learn_time_ms\": 14746.268}", "{\"n\": 6284, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3595.02, \"learn_time_ms\": 14764.002}", "{\"n\": 6285, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.83, \"learn_time_ms\": 14752.778}", "{\"n\": 6286, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.83, \"learn_time_ms\": 14736.494}", "{\"n\": 6287, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3591.54, \"learn_time_ms\": 14727.042}", "{\"n\": 6288, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3591.54, \"learn_time_ms\": 14710.578}", "{\"n\": 6289, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3592.95, \"learn_time_ms\": 14706.128}", "{\"n\": 6290, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3586.04, \"learn_time_ms\": 14711.353}", "{\"n\": 6291, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.24, \"learn_time_ms\": 14671.419}", "{\"n\": 6292, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3590.95, \"learn_time_ms\": 14686.366}", "{\"n\": 6293, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3603.85, \"learn_time_ms\": 14681.954}", "{\"n\": 6294, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3603.85, \"learn_time_ms\": 14669.072}", "{\"n\": 6295, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.48, \"learn_time_ms\": 14671.636}", "{\"n\": 6296, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3601.43, \"learn_time_ms\": 14661.639}", "{\"n\": 6297, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3599.15, \"learn_time_ms\": 14657.73}", "{\"n\": 6298, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3607.09, \"learn_time_ms\": 14676.82}", "{\"n\": 6299, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3614.8, \"learn_time_ms\": 14657.003}", "{\"n\": 6300, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3624.32, \"learn_time_ms\": 14643.89}", "{\"n\": 6301, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3624.33, \"learn_time_ms\": 14667.128}", "{\"n\": 6302, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3634.81, \"learn_time_ms\": 14667.648}", "{\"n\": 6303, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3639.48, \"learn_time_ms\": 14670.724}", "{\"n\": 6304, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3639.48, \"learn_time_ms\": 14674.716}", "{\"n\": 6305, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.23, \"learn_time_ms\": 14703.25}", "{\"n\": 6306, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3636.47, \"learn_time_ms\": 14756.843}", "{\"n\": 6307, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3632.14, \"learn_time_ms\": 14766.365}", "{\"n\": 6308, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3638.88, \"learn_time_ms\": 14768.899}", "{\"n\": 6309, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3645.54, \"learn_time_ms\": 14802.191}", "{\"n\": 6310, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3664.0, \"learn_time_ms\": 14816.866}", "{\"n\": 6311, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3670.86, \"learn_time_ms\": 14830.16}", "{\"n\": 6312, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3670.86, \"learn_time_ms\": 14812.623}", "{\"n\": 6313, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3660.62, \"learn_time_ms\": 14810.627}", "{\"n\": 6314, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3655.97, \"learn_time_ms\": 14799.19}", "{\"n\": 6315, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3654.17, \"learn_time_ms\": 14787.036}", "{\"n\": 6316, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3637.76, \"learn_time_ms\": 14753.505}", "{\"n\": 6317, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3630.56, \"learn_time_ms\": 14749.474}", "{\"n\": 6318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3630.56, \"learn_time_ms\": 14729.689}", "{\"n\": 6319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3630.56, \"learn_time_ms\": 14717.423}", "{\"n\": 6320, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3631.86, \"learn_time_ms\": 14721.775}", "{\"n\": 6321, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3627.99, \"learn_time_ms\": 14730.313}", "{\"n\": 6322, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3623.99, \"learn_time_ms\": 14749.832}", "{\"n\": 6323, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3623.99, \"learn_time_ms\": 14742.331}", "{\"n\": 6324, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3623.99, \"learn_time_ms\": 14744.235}", "{\"n\": 6325, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3629.86, \"learn_time_ms\": 14739.894}", "{\"n\": 6326, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3647.87, \"learn_time_ms\": 14742.078}", "{\"n\": 6327, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3647.87, \"learn_time_ms\": 14751.361}", "{\"n\": 6328, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3629.96, \"learn_time_ms\": 14772.769}", "{\"n\": 6329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3629.96, \"learn_time_ms\": 14787.591}", "{\"n\": 6330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3627.52, \"learn_time_ms\": 14802.215}", "{\"n\": 6331, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3628.05, \"learn_time_ms\": 14798.116}", "{\"n\": 6332, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3634.96, \"learn_time_ms\": 14784.775}", "{\"n\": 6333, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3628.18, \"learn_time_ms\": 14798.091}", "{\"n\": 6334, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3626.95, \"learn_time_ms\": 14815.983}", "{\"n\": 6335, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3627.22, \"learn_time_ms\": 14826.478}", "{\"n\": 6336, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3627.22, \"learn_time_ms\": 14850.972}", "{\"n\": 6337, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3622.88, \"learn_time_ms\": 14833.821}", "{\"n\": 6338, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3618.77, \"learn_time_ms\": 14842.186}", "{\"n\": 6339, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3617.18, \"learn_time_ms\": 14844.786}", "{\"n\": 6340, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3611.01, \"learn_time_ms\": 14807.608}", "{\"n\": 6341, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3593.73, \"learn_time_ms\": 14810.913}", "{\"n\": 6342, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3593.73, \"learn_time_ms\": 14819.82}", "{\"n\": 6343, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3605.54, \"learn_time_ms\": 14803.856}", "{\"n\": 6344, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3609.83, \"learn_time_ms\": 14790.468}", "{\"n\": 6345, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3609.83, \"learn_time_ms\": 14781.651}", "{\"n\": 6346, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3616.57, \"learn_time_ms\": 14770.279}", "{\"n\": 6347, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3623.46, \"learn_time_ms\": 14779.927}", "{\"n\": 6348, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3615.45, \"learn_time_ms\": 14771.877}", "{\"n\": 6349, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3615.45, \"learn_time_ms\": 14760.475}", "{\"n\": 6350, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3608.91, \"learn_time_ms\": 14778.339}", "{\"n\": 6351, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3606.87, \"learn_time_ms\": 14781.606}", "{\"n\": 6352, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3596.31, \"learn_time_ms\": 14784.62}", "{\"n\": 6353, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3597.1, \"learn_time_ms\": 14795.465}", "{\"n\": 6354, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3597.1, \"learn_time_ms\": 14809.307}", "{\"n\": 6355, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3597.1, \"learn_time_ms\": 14802.504}", "{\"n\": 6356, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3584.81, \"learn_time_ms\": 14795.713}", "{\"n\": 6357, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3598.13, \"learn_time_ms\": 14796.407}", "{\"n\": 6358, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3597.97, \"learn_time_ms\": 14804.889}", "{\"n\": 6359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3594.25, \"learn_time_ms\": 14784.61}", "{\"n\": 6360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3594.25, \"learn_time_ms\": 14795.522}", "{\"n\": 6361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3594.25, \"learn_time_ms\": 14778.192}", "{\"n\": 6362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3594.38, \"learn_time_ms\": 14756.466}", "{\"n\": 6363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3619.43, \"learn_time_ms\": 14752.065}", "{\"n\": 6364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3625.44, \"learn_time_ms\": 14739.068}", "{\"n\": 6365, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3623.73, \"learn_time_ms\": 14734.004}", "{\"n\": 6366, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3623.73, \"learn_time_ms\": 14723.488}", "{\"n\": 6367, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3614.58, \"learn_time_ms\": 14699.677}", "{\"n\": 6368, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3613.4, \"learn_time_ms\": 14685.444}", "{\"n\": 6369, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3620.52, \"learn_time_ms\": 14699.914}", "{\"n\": 6370, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3621.47, \"learn_time_ms\": 14700.098}", "{\"n\": 6371, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3629.65, \"learn_time_ms\": 14694.021}", "{\"n\": 6372, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3629.65, \"learn_time_ms\": 14704.016}", "{\"n\": 6373, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3613.69, \"learn_time_ms\": 14690.007}", "{\"n\": 6374, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3602.56, \"learn_time_ms\": 14681.8}", "{\"n\": 6375, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3602.56, \"learn_time_ms\": 14695.365}", "{\"n\": 6376, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3579.44, \"learn_time_ms\": 14698.072}", "{\"n\": 6377, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3571.65, \"learn_time_ms\": 14711.626}", "{\"n\": 6378, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3571.65, \"learn_time_ms\": 14709.57}", "{\"n\": 6379, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3568.5, \"learn_time_ms\": 14716.298}", "{\"n\": 6380, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3568.5, \"learn_time_ms\": 14718.415}", "{\"n\": 6381, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3574.06, \"learn_time_ms\": 14720.844}", "{\"n\": 6382, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3591.58, \"learn_time_ms\": 14711.75}", "{\"n\": 6383, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3591.92, \"learn_time_ms\": 14727.255}", "{\"n\": 6384, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3588.27, \"learn_time_ms\": 14711.285}", "{\"n\": 6385, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3588.27, \"learn_time_ms\": 14697.525}", "{\"n\": 6386, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3595.09, \"learn_time_ms\": 14701.035}", "{\"n\": 6387, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3589.23, \"learn_time_ms\": 14710.964}", "{\"n\": 6388, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3585.89, \"learn_time_ms\": 14713.609}", "{\"n\": 6389, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3589.42, \"learn_time_ms\": 14709.78}", "{\"n\": 6390, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3594.91, \"learn_time_ms\": 14710.769}", "{\"n\": 6391, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3607.04, \"learn_time_ms\": 14707.491}", "{\"n\": 6392, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3607.04, \"learn_time_ms\": 14726.785}", "{\"n\": 6393, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3609.38, \"learn_time_ms\": 14703.202}", "{\"n\": 6394, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3607.86, \"learn_time_ms\": 14721.004}", "{\"n\": 6395, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3607.86, \"learn_time_ms\": 14744.803}", "{\"n\": 6396, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3617.5, \"learn_time_ms\": 14742.436}", "{\"n\": 6397, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3631.95, \"learn_time_ms\": 14710.15}", "{\"n\": 6398, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3631.27, \"learn_time_ms\": 14713.048}", "{\"n\": 6399, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3631.27, \"learn_time_ms\": 14686.142}", "{\"n\": 6400, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3619.2, \"learn_time_ms\": 14687.706}", "{\"n\": 6401, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3617.42, \"learn_time_ms\": 14665.502}", "{\"n\": 6402, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3617.8, \"learn_time_ms\": 14666.669}", "{\"n\": 6403, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3629.38, \"learn_time_ms\": 14686.488}", "{\"n\": 6404, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3611.85, \"learn_time_ms\": 14693.975}", "{\"n\": 6405, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3611.85, \"learn_time_ms\": 14680.993}", "{\"n\": 6406, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3625.51, \"learn_time_ms\": 14681.372}", "{\"n\": 6407, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3636.15, \"learn_time_ms\": 14703.663}", "{\"n\": 6408, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3634.7, \"learn_time_ms\": 14697.091}", "{\"n\": 6409, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3655.44, \"learn_time_ms\": 14697.819}", "{\"n\": 6410, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3655.28, \"learn_time_ms\": 14674.636}", "{\"n\": 6411, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3655.13, \"learn_time_ms\": 14711.165}", "{\"n\": 6412, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3655.13, \"learn_time_ms\": 14697.439}", "{\"n\": 6413, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3660.19, \"learn_time_ms\": 14720.004}", "{\"n\": 6414, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3653.46, \"learn_time_ms\": 14727.597}", "{\"n\": 6415, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3662.25, \"learn_time_ms\": 14724.145}", "{\"n\": 6416, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3662.25, \"learn_time_ms\": 14723.665}", "{\"n\": 6417, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3679.75, \"learn_time_ms\": 14723.95}", "{\"n\": 6418, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3693.24, \"learn_time_ms\": 14709.744}", "{\"n\": 6419, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3693.24, \"learn_time_ms\": 14730.55}", "{\"n\": 6420, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3687.93, \"learn_time_ms\": 14744.192}", "{\"n\": 6421, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3687.93, \"learn_time_ms\": 14736.086}", "{\"n\": 6422, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3685.9, \"learn_time_ms\": 14715.544}", "{\"n\": 6423, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3678.01, \"learn_time_ms\": 14707.235}", "{\"n\": 6424, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3681.19, \"learn_time_ms\": 14692.061}", "{\"n\": 6425, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3698.3, \"learn_time_ms\": 14659.626}", "{\"n\": 6426, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3698.3, \"learn_time_ms\": 14645.351}", "{\"n\": 6427, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3708.8, \"learn_time_ms\": 14652.788}", "{\"n\": 6428, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3708.8, \"learn_time_ms\": 14663.001}", "{\"n\": 6429, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3712.65, \"learn_time_ms\": 14666.213}", "{\"n\": 6430, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3725.43, \"learn_time_ms\": 14643.112}", "{\"n\": 6431, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3727.93, \"learn_time_ms\": 14644.088}", "{\"n\": 6432, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3731.16, \"learn_time_ms\": 14672.314}", "{\"n\": 6433, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3729.03, \"learn_time_ms\": 14667.983}", "{\"n\": 6434, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3729.03, \"learn_time_ms\": 14676.662}", "{\"n\": 6435, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3724.82, \"learn_time_ms\": 14714.076}", "{\"n\": 6436, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3744.23, \"learn_time_ms\": 14731.686}", "{\"n\": 6437, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.69, \"learn_time_ms\": 14731.225}", "{\"n\": 6438, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.14, \"learn_time_ms\": 14739.864}", "{\"n\": 6439, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.14, \"learn_time_ms\": 14756.789}", "{\"n\": 6440, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3737.59, \"learn_time_ms\": 14776.871}", "{\"n\": 6441, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3737.59, \"learn_time_ms\": 14795.55}", "{\"n\": 6442, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.41, \"learn_time_ms\": 14789.677}", "{\"n\": 6443, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3717.62, \"learn_time_ms\": 14791.519}", "{\"n\": 6444, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3717.62, \"learn_time_ms\": 14780.385}", "{\"n\": 6445, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3722.55, \"learn_time_ms\": 14776.643}", "{\"n\": 6446, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3722.55, \"learn_time_ms\": 14780.99}", "{\"n\": 6447, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3732.01, \"learn_time_ms\": 14788.532}", "{\"n\": 6448, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.95, \"learn_time_ms\": 14787.942}", "{\"n\": 6449, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.02, \"learn_time_ms\": 14774.436}", "{\"n\": 6450, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.91, \"learn_time_ms\": 14756.357}", "{\"n\": 6451, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3747.74, \"learn_time_ms\": 14744.183}", "{\"n\": 6452, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3747.74, \"learn_time_ms\": 14738.07}", "{\"n\": 6453, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3745.27, \"learn_time_ms\": 14729.203}", "{\"n\": 6454, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3752.2, \"learn_time_ms\": 14714.583}", "{\"n\": 6455, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3750.74, \"learn_time_ms\": 14688.493}", "{\"n\": 6456, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.76, \"learn_time_ms\": 14675.198}", "{\"n\": 6457, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.76, \"learn_time_ms\": 14650.255}", "{\"n\": 6458, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.23, \"learn_time_ms\": 14633.236}", "{\"n\": 6459, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3731.56, \"learn_time_ms\": 14614.916}", "{\"n\": 6460, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.98, \"learn_time_ms\": 14610.474}", "{\"n\": 6461, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3727.24, \"learn_time_ms\": 14617.323}", "{\"n\": 6462, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3725.96, \"learn_time_ms\": 14621.143}", "{\"n\": 6463, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.65, \"learn_time_ms\": 14630.809}", "{\"n\": 6464, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.25, \"learn_time_ms\": 14653.123}", "{\"n\": 6465, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.37, \"learn_time_ms\": 14677.263}", "{\"n\": 6466, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.26, \"learn_time_ms\": 14696.458}", "{\"n\": 6467, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.26, \"learn_time_ms\": 14716.163}", "{\"n\": 6468, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.26, \"learn_time_ms\": 14746.681}", "{\"n\": 6469, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.26, \"learn_time_ms\": 14763.336}", "{\"n\": 6470, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3715.77, \"learn_time_ms\": 14779.183}", "{\"n\": 6471, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3717.94, \"learn_time_ms\": 14788.44}", "{\"n\": 6472, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.41, \"learn_time_ms\": 14791.173}", "{\"n\": 6473, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.84, \"learn_time_ms\": 14779.343}", "{\"n\": 6474, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.84, \"learn_time_ms\": 14770.833}", "{\"n\": 6475, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.84, \"learn_time_ms\": 14781.936}", "{\"n\": 6476, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.53, \"learn_time_ms\": 14774.218}", "{\"n\": 6477, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.17, \"learn_time_ms\": 14729.121}", "{\"n\": 6478, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3713.96, \"learn_time_ms\": 14719.475}", "{\"n\": 6479, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.79, \"learn_time_ms\": 14684.059}", "{\"n\": 6480, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.79, \"learn_time_ms\": 14694.24}", "{\"n\": 6481, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.79, \"learn_time_ms\": 14690.373}", "{\"n\": 6482, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3716.6, \"learn_time_ms\": 14680.116}", "{\"n\": 6483, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.7, \"learn_time_ms\": 14679.368}", "{\"n\": 6484, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.78, \"learn_time_ms\": 14690.848}", "{\"n\": 6485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.78, \"learn_time_ms\": 14681.328}", "{\"n\": 6486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.78, \"learn_time_ms\": 14684.227}", "{\"n\": 6487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.79, \"learn_time_ms\": 14726.936}", "{\"n\": 6488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.03, \"learn_time_ms\": 14713.435}", "{\"n\": 6489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.03, \"learn_time_ms\": 14744.485}", "{\"n\": 6490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.84, \"learn_time_ms\": 14734.789}", "{\"n\": 6491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.16, \"learn_time_ms\": 14689.928}", "{\"n\": 6492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.16, \"learn_time_ms\": 14693.554}", "{\"n\": 6493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.16, \"learn_time_ms\": 14687.596}", "{\"n\": 6494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.93, \"learn_time_ms\": 14681.553}", "{\"n\": 6495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.89, \"learn_time_ms\": 14677.995}", "{\"n\": 6496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.51, \"learn_time_ms\": 14684.334}", "{\"n\": 6497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.44, \"learn_time_ms\": 14665.8}", "{\"n\": 6498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.49, \"learn_time_ms\": 14678.722}", "{\"n\": 6499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.49, \"learn_time_ms\": 14695.448}", "{\"n\": 6500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.57, \"learn_time_ms\": 14701.532}", "{\"n\": 6501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3700.54, \"learn_time_ms\": 14748.326}", "{\"n\": 6502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.07, \"learn_time_ms\": 14755.173}", "{\"n\": 6503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.07, \"learn_time_ms\": 14759.005}", "{\"n\": 6504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.07, \"learn_time_ms\": 14756.914}", "{\"n\": 6505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3709.1, \"learn_time_ms\": 14753.053}", "{\"n\": 6506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.75, \"learn_time_ms\": 14741.04}", "{\"n\": 6507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.75, \"learn_time_ms\": 14762.441}", "{\"n\": 6508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.64, \"learn_time_ms\": 14749.678}", "{\"n\": 6509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.64, \"learn_time_ms\": 14724.356}", "{\"n\": 6510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.69, \"learn_time_ms\": 14719.297}", "{\"n\": 6511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.69, \"learn_time_ms\": 14705.323}", "{\"n\": 6512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.69, \"learn_time_ms\": 14700.663}", "{\"n\": 6513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.58, \"learn_time_ms\": 14706.57}", "{\"n\": 6514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3666.38, \"learn_time_ms\": 14714.606}", "{\"n\": 6515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3660.57, \"learn_time_ms\": 14722.249}", "{\"n\": 6516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3645.19, \"learn_time_ms\": 14722.772}", "{\"n\": 6517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3645.19, \"learn_time_ms\": 14714.464}", "{\"n\": 6518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3645.19, \"learn_time_ms\": 14726.225}", "{\"n\": 6519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3652.58, \"learn_time_ms\": 14739.097}", "{\"n\": 6520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.02, \"learn_time_ms\": 14744.222}", "{\"n\": 6521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.75, \"learn_time_ms\": 14743.081}", "{\"n\": 6522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3684.38, \"learn_time_ms\": 14741.751}", "{\"n\": 6523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3684.38, \"learn_time_ms\": 14746.243}", "{\"n\": 6524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3684.38, \"learn_time_ms\": 14733.163}", "{\"n\": 6525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3682.0, \"learn_time_ms\": 14736.358}", "{\"n\": 6526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3679.34, \"learn_time_ms\": 14733.97}", "{\"n\": 6527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.02, \"learn_time_ms\": 14746.659}", "{\"n\": 6528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3682.13, \"learn_time_ms\": 14751.05}", "{\"n\": 6529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3681.73, \"learn_time_ms\": 14753.445}", "{\"n\": 6530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3690.74, \"learn_time_ms\": 14752.469}", "{\"n\": 6531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3690.74, \"learn_time_ms\": 14757.819}", "{\"n\": 6532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3688.06, \"learn_time_ms\": 14763.932}", "{\"n\": 6533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.35, \"learn_time_ms\": 14721.864}", "{\"n\": 6534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.35, \"learn_time_ms\": 14738.863}", "{\"n\": 6535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.13, \"learn_time_ms\": 14742.544}", "{\"n\": 6536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.96, \"learn_time_ms\": 14743.598}", "{\"n\": 6537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.96, \"learn_time_ms\": 14727.366}", "{\"n\": 6538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3699.13, \"learn_time_ms\": 14731.818}", "{\"n\": 6539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3706.85, \"learn_time_ms\": 14734.477}", "{\"n\": 6540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3730.22, \"learn_time_ms\": 14721.538}", "{\"n\": 6541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.07, \"learn_time_ms\": 14708.034}", "{\"n\": 6542, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3729.41, \"learn_time_ms\": 14709.315}", "{\"n\": 6543, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3733.5, \"learn_time_ms\": 14761.873}", "{\"n\": 6544, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.33, \"learn_time_ms\": 14734.827}", "{\"n\": 6545, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.91, \"learn_time_ms\": 14709.473}", "{\"n\": 6546, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3713.99, \"learn_time_ms\": 14706.362}", "{\"n\": 6547, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3713.32, \"learn_time_ms\": 14730.452}", "{\"n\": 6548, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3710.86, \"learn_time_ms\": 14730.567}", "{\"n\": 6549, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3714.43, \"learn_time_ms\": 14725.201}", "{\"n\": 6550, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3715.22, \"learn_time_ms\": 14750.827}", "{\"n\": 6551, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.1, \"learn_time_ms\": 14774.597}", "{\"n\": 6552, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3719.4, \"learn_time_ms\": 14778.439}", "{\"n\": 6553, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3712.7, \"learn_time_ms\": 14767.711}", "{\"n\": 6554, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3727.28, \"learn_time_ms\": 14777.15}", "{\"n\": 6555, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.0, \"learn_time_ms\": 14800.696}", "{\"n\": 6556, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3736.08, \"learn_time_ms\": 14812.705}", "{\"n\": 6557, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3729.62, \"learn_time_ms\": 14786.981}", "{\"n\": 6558, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.47, \"learn_time_ms\": 14740.084}", "{\"n\": 6559, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.74, \"learn_time_ms\": 14739.351}", "{\"n\": 6560, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.9, \"learn_time_ms\": 14723.761}", "{\"n\": 6561, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.9, \"learn_time_ms\": 14696.361}", "{\"n\": 6562, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3747.53, \"learn_time_ms\": 14695.088}", "{\"n\": 6563, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3744.61, \"learn_time_ms\": 14683.669}", "{\"n\": 6564, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.37, \"learn_time_ms\": 14694.045}", "{\"n\": 6565, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.37, \"learn_time_ms\": 14693.852}", "{\"n\": 6566, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.37, \"learn_time_ms\": 14695.703}", "{\"n\": 6567, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.52, \"learn_time_ms\": 14709.192}", "{\"n\": 6568, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3750.97, \"learn_time_ms\": 14744.59}", "{\"n\": 6569, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3729.82, \"learn_time_ms\": 14761.051}", "{\"n\": 6570, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.27, \"learn_time_ms\": 14745.994}", "{\"n\": 6571, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.27, \"learn_time_ms\": 14756.875}", "{\"n\": 6572, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.27, \"learn_time_ms\": 14755.85}", "{\"n\": 6573, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.27, \"learn_time_ms\": 14731.293}", "{\"n\": 6574, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3736.99, \"learn_time_ms\": 14729.687}", "{\"n\": 6575, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.85, \"learn_time_ms\": 14728.845}", "{\"n\": 6576, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.81, \"learn_time_ms\": 14731.225}", "{\"n\": 6577, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.81, \"learn_time_ms\": 14731.495}", "{\"n\": 6578, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.81, \"learn_time_ms\": 14721.056}", "{\"n\": 6579, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3710.25, \"learn_time_ms\": 14719.506}", "{\"n\": 6580, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3710.25, \"learn_time_ms\": 14736.969}", "{\"n\": 6581, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3710.51, \"learn_time_ms\": 14737.139}", "{\"n\": 6582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3708.99, \"learn_time_ms\": 14723.569}", "{\"n\": 6583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.35, \"learn_time_ms\": 14748.885}", "{\"n\": 6584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.35, \"learn_time_ms\": 14745.044}", "{\"n\": 6585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.35, \"learn_time_ms\": 14744.485}", "{\"n\": 6586, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3716.78, \"learn_time_ms\": 14736.139}", "{\"n\": 6587, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3737.3, \"learn_time_ms\": 14731.436}", "{\"n\": 6588, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3741.33, \"learn_time_ms\": 14746.059}", "{\"n\": 6589, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3741.33, \"learn_time_ms\": 14722.79}", "{\"n\": 6590, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3747.04, \"learn_time_ms\": 14697.901}", "{\"n\": 6591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3747.04, \"learn_time_ms\": 14667.409}", "{\"n\": 6592, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3747.23, \"learn_time_ms\": 14675.019}", "{\"n\": 6593, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3749.51, \"learn_time_ms\": 14662.741}", "{\"n\": 6594, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3767.77, \"learn_time_ms\": 14633.196}", "{\"n\": 6595, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3756.59, \"learn_time_ms\": 14639.859}", "{\"n\": 6596, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3756.59, \"learn_time_ms\": 14637.407}", "{\"n\": 6597, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3751.48, \"learn_time_ms\": 14649.25}", "{\"n\": 6598, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3751.48, \"learn_time_ms\": 14648.579}", "{\"n\": 6599, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3756.43, \"learn_time_ms\": 14652.272}", "{\"n\": 6600, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3747.1, \"learn_time_ms\": 14686.858}", "{\"n\": 6601, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3753.7, \"learn_time_ms\": 14727.535}", "{\"n\": 6602, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3753.7, \"learn_time_ms\": 14738.51}", "{\"n\": 6603, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3767.88, \"learn_time_ms\": 14762.673}", "{\"n\": 6604, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3752.62, \"learn_time_ms\": 14796.331}", "{\"n\": 6605, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3752.62, \"learn_time_ms\": 14789.421}", "{\"n\": 6606, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3749.83, \"learn_time_ms\": 14787.269}", "{\"n\": 6607, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3750.87, \"learn_time_ms\": 14783.34}", "{\"n\": 6608, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3750.87, \"learn_time_ms\": 14778.188}", "{\"n\": 6609, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3745.31, \"learn_time_ms\": 14776.922}", "{\"n\": 6610, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3745.31, \"learn_time_ms\": 14772.729}", "{\"n\": 6611, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3745.31, \"learn_time_ms\": 14762.429}", "{\"n\": 6612, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3745.56, \"learn_time_ms\": 14757.035}", "{\"n\": 6613, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3762.19, \"learn_time_ms\": 14764.854}", "{\"n\": 6614, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3758.52, \"learn_time_ms\": 14771.593}", "{\"n\": 6615, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3758.1, \"learn_time_ms\": 14763.91}", "{\"n\": 6616, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3765.38, \"learn_time_ms\": 14767.832}", "{\"n\": 6617, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3764.6, \"learn_time_ms\": 14759.802}", "{\"n\": 6618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3757.7, \"learn_time_ms\": 14759.257}", "{\"n\": 6619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3753.96, \"learn_time_ms\": 14751.165}", "{\"n\": 6620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3765.67, \"learn_time_ms\": 14753.431}", "{\"n\": 6621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3774.8, \"learn_time_ms\": 14755.038}", "{\"n\": 6622, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3774.8, \"learn_time_ms\": 14748.591}", "{\"n\": 6623, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3774.98, \"learn_time_ms\": 14714.306}", "{\"n\": 6624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3774.98, \"learn_time_ms\": 14719.815}", "{\"n\": 6625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3769.88, \"learn_time_ms\": 14724.912}", "{\"n\": 6626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3758.13, \"learn_time_ms\": 14729.919}", "{\"n\": 6627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3767.58, \"learn_time_ms\": 14721.351}", "{\"n\": 6628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.61, \"learn_time_ms\": 14751.136}", "{\"n\": 6629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.61, \"learn_time_ms\": 14776.557}", "{\"n\": 6630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.61, \"learn_time_ms\": 14774.694}", "{\"n\": 6631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3766.19, \"learn_time_ms\": 14765.108}", "{\"n\": 6632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3774.49, \"learn_time_ms\": 14769.555}", "{\"n\": 6633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3774.56, \"learn_time_ms\": 14793.701}", "{\"n\": 6634, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.97, \"learn_time_ms\": 14782.266}", "{\"n\": 6635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.97, \"learn_time_ms\": 14778.636}", "{\"n\": 6636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.97, \"learn_time_ms\": 14785.342}", "{\"n\": 6637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.97, \"learn_time_ms\": 14787.006}", "{\"n\": 6638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3782.29, \"learn_time_ms\": 14776.574}", "{\"n\": 6639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3786.35, \"learn_time_ms\": 14763.306}", "{\"n\": 6640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.55, \"learn_time_ms\": 14749.527}", "{\"n\": 6641, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3790.36, \"learn_time_ms\": 14758.63}", "{\"n\": 6642, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3790.36, \"learn_time_ms\": 14759.646}", "{\"n\": 6643, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3790.36, \"learn_time_ms\": 14750.023}", "{\"n\": 6644, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.27, \"learn_time_ms\": 14759.49}", "{\"n\": 6645, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.27, \"learn_time_ms\": 14765.419}", "{\"n\": 6646, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3794.49, \"learn_time_ms\": 14727.187}", "{\"n\": 6647, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.74, \"learn_time_ms\": 14726.835}", "{\"n\": 6648, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.74, \"learn_time_ms\": 14697.48}", "{\"n\": 6649, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.74, \"learn_time_ms\": 14689.44}", "{\"n\": 6650, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.74, \"learn_time_ms\": 14696.913}", "{\"n\": 6651, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3819.69, \"learn_time_ms\": 14709.045}", "{\"n\": 6652, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3819.4, \"learn_time_ms\": 14712.941}", "{\"n\": 6653, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3810.78, \"learn_time_ms\": 14728.873}", "{\"n\": 6654, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3810.78, \"learn_time_ms\": 14701.567}", "{\"n\": 6655, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3817.07, \"learn_time_ms\": 14693.269}", "{\"n\": 6656, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3817.07, \"learn_time_ms\": 14717.114}", "{\"n\": 6657, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3819.36, \"learn_time_ms\": 14727.459}", "{\"n\": 6658, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3850.98, \"learn_time_ms\": 14735.532}", "{\"n\": 6659, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3850.98, \"learn_time_ms\": 14735.002}", "{\"n\": 6660, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3855.97, \"learn_time_ms\": 14742.067}", "{\"n\": 6661, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3855.97, \"learn_time_ms\": 14738.253}", "{\"n\": 6662, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.32, \"learn_time_ms\": 14719.071}", "{\"n\": 6663, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.32, \"learn_time_ms\": 14680.579}", "{\"n\": 6664, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3845.99, \"learn_time_ms\": 14700.808}", "{\"n\": 6665, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3843.86, \"learn_time_ms\": 14672.324}", "{\"n\": 6666, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3838.21, \"learn_time_ms\": 14672.183}", "{\"n\": 6667, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3838.21, \"learn_time_ms\": 14671.959}", "{\"n\": 6668, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3845.26, \"learn_time_ms\": 14663.89}", "{\"n\": 6669, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3845.26, \"learn_time_ms\": 14674.985}", "{\"n\": 6670, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3821.06, \"learn_time_ms\": 14667.677}", "{\"n\": 6671, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3832.44, \"learn_time_ms\": 14655.253}", "{\"n\": 6672, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3835.85, \"learn_time_ms\": 14665.271}", "{\"n\": 6673, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3838.53, \"learn_time_ms\": 14677.607}", "{\"n\": 6674, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3838.53, \"learn_time_ms\": 14669.343}", "{\"n\": 6675, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3849.05, \"learn_time_ms\": 14705.849}", "{\"n\": 6676, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3847.61, \"learn_time_ms\": 14712.977}", "{\"n\": 6677, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3830.03, \"learn_time_ms\": 14697.012}", "{\"n\": 6678, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3825.78, \"learn_time_ms\": 14696.201}", "{\"n\": 6679, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.53, \"learn_time_ms\": 14694.618}", "{\"n\": 6680, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.53, \"learn_time_ms\": 14688.942}", "{\"n\": 6681, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3817.25, \"learn_time_ms\": 14692.521}", "{\"n\": 6682, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3817.25, \"learn_time_ms\": 14682.388}", "{\"n\": 6683, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3824.2, \"learn_time_ms\": 14680.811}", "{\"n\": 6684, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.83, \"learn_time_ms\": 14657.403}", "{\"n\": 6685, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3815.36, \"learn_time_ms\": 14612.003}", "{\"n\": 6686, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3815.36, \"learn_time_ms\": 14566.787}", "{\"n\": 6687, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3813.56, \"learn_time_ms\": 14573.918}", "{\"n\": 6688, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3823.5, \"learn_time_ms\": 14585.526}", "{\"n\": 6689, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.21, \"learn_time_ms\": 14594.865}", "{\"n\": 6690, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.21, \"learn_time_ms\": 14615.289}", "{\"n\": 6691, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3817.98, \"learn_time_ms\": 14584.562}", "{\"n\": 6692, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3817.61, \"learn_time_ms\": 14542.906}", "{\"n\": 6693, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3821.43, \"learn_time_ms\": 14538.961}", "{\"n\": 6694, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3821.43, \"learn_time_ms\": 14570.152}", "{\"n\": 6695, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3797.15, \"learn_time_ms\": 14608.676}", "{\"n\": 6696, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3798.31, \"learn_time_ms\": 14648.687}", "{\"n\": 6697, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3793.19, \"learn_time_ms\": 14655.827}", "{\"n\": 6698, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3792.4, \"learn_time_ms\": 14643.789}", "{\"n\": 6699, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3792.4, \"learn_time_ms\": 14634.387}", "{\"n\": 6700, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3773.95, \"learn_time_ms\": 14627.718}", "{\"n\": 6701, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3773.95, \"learn_time_ms\": 14671.845}", "{\"n\": 6702, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3789.86, \"learn_time_ms\": 14735.389}", "{\"n\": 6703, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3787.26, \"learn_time_ms\": 14758.208}", "{\"n\": 6704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3776.45, \"learn_time_ms\": 14760.378}", "{\"n\": 6705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3771.6, \"learn_time_ms\": 14773.633}", "{\"n\": 6706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3771.6, \"learn_time_ms\": 14781.998}", "{\"n\": 6707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3778.28, \"learn_time_ms\": 14792.3}", "{\"n\": 6708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3768.95, \"learn_time_ms\": 14793.924}", "{\"n\": 6709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3768.95, \"learn_time_ms\": 14789.757}", "{\"n\": 6710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3770.67, \"learn_time_ms\": 14795.47}", "{\"n\": 6711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3772.33, \"learn_time_ms\": 14779.846}", "{\"n\": 6712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3751.61, \"learn_time_ms\": 14782.001}", "{\"n\": 6713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3731.97, \"learn_time_ms\": 14772.472}", "{\"n\": 6714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3731.97, \"learn_time_ms\": 14767.278}", "{\"n\": 6715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3731.97, \"learn_time_ms\": 14749.778}", "{\"n\": 6716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3726.56, \"learn_time_ms\": 14724.936}", "{\"n\": 6717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3727.93, \"learn_time_ms\": 14724.428}", "{\"n\": 6718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3714.86, \"learn_time_ms\": 14694.753}", "{\"n\": 6719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3717.08, \"learn_time_ms\": 14681.585}", "{\"n\": 6720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3715.83, \"learn_time_ms\": 14651.562}", "{\"n\": 6721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3715.83, \"learn_time_ms\": 14656.289}", "{\"n\": 6722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.03, \"learn_time_ms\": 14645.525}", "{\"n\": 6723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3714.99, \"learn_time_ms\": 14661.561}", "{\"n\": 6724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3718.73, \"learn_time_ms\": 14650.537}", "{\"n\": 6725, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.83, \"learn_time_ms\": 14640.915}", "{\"n\": 6726, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.83, \"learn_time_ms\": 14660.706}", "{\"n\": 6727, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.58, \"learn_time_ms\": 14639.28}", "{\"n\": 6728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.58, \"learn_time_ms\": 14659.819}", "{\"n\": 6729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3723.52, \"learn_time_ms\": 14673.32}", "{\"n\": 6730, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3719.4, \"learn_time_ms\": 14647.904}", "{\"n\": 6731, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3721.38, \"learn_time_ms\": 14664.237}", "{\"n\": 6732, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3721.38, \"learn_time_ms\": 14652.673}", "{\"n\": 6733, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3721.38, \"learn_time_ms\": 14605.346}", "{\"n\": 6734, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3721.17, \"learn_time_ms\": 14601.948}", "{\"n\": 6735, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3715.03, \"learn_time_ms\": 14609.16}", "{\"n\": 6736, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3712.75, \"learn_time_ms\": 14604.088}", "{\"n\": 6737, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3709.54, \"learn_time_ms\": 14622.042}", "{\"n\": 6738, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3709.54, \"learn_time_ms\": 14650.053}", "{\"n\": 6739, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3709.54, \"learn_time_ms\": 14645.554}", "{\"n\": 6740, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3719.04, \"learn_time_ms\": 14679.468}", "{\"n\": 6741, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3704.66, \"learn_time_ms\": 14667.749}", "{\"n\": 6742, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3704.66, \"learn_time_ms\": 14684.985}", "{\"n\": 6743, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3695.93, \"learn_time_ms\": 14724.702}", "{\"n\": 6744, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3695.93, \"learn_time_ms\": 14719.935}", "{\"n\": 6745, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3695.49, \"learn_time_ms\": 14731.187}", "{\"n\": 6746, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3695.49, \"learn_time_ms\": 14734.642}", "{\"n\": 6747, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3708.03, \"learn_time_ms\": 14732.776}", "{\"n\": 6748, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3682.03, \"learn_time_ms\": 14728.728}", "{\"n\": 6749, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3682.03, \"learn_time_ms\": 14728.318}", "{\"n\": 6750, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3677.27, \"learn_time_ms\": 14742.939}", "{\"n\": 6751, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3679.34, \"learn_time_ms\": 14743.116}", "{\"n\": 6752, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3679.34, \"learn_time_ms\": 14739.347}", "{\"n\": 6753, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3678.43, \"learn_time_ms\": 14757.707}", "{\"n\": 6754, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3681.97, \"learn_time_ms\": 14761.763}", "{\"n\": 6755, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3687.38, \"learn_time_ms\": 14758.365}", "{\"n\": 6756, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3684.92, \"learn_time_ms\": 14751.035}", "{\"n\": 6757, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3692.54, \"learn_time_ms\": 14749.236}", "{\"n\": 6758, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3692.92, \"learn_time_ms\": 14731.931}", "{\"n\": 6759, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3686.59, \"learn_time_ms\": 14728.373}", "{\"n\": 6760, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3682.78, \"learn_time_ms\": 14677.507}", "{\"n\": 6761, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3690.69, \"learn_time_ms\": 14679.325}", "{\"n\": 6762, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3690.69, \"learn_time_ms\": 14680.234}", "{\"n\": 6763, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3701.52, \"learn_time_ms\": 14666.482}", "{\"n\": 6764, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3714.8, \"learn_time_ms\": 14680.203}", "{\"n\": 6765, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3709.53, \"learn_time_ms\": 14681.923}", "{\"n\": 6766, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3701.3, \"learn_time_ms\": 14667.122}", "{\"n\": 6767, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3701.3, \"learn_time_ms\": 14663.759}", "{\"n\": 6768, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3704.06, \"learn_time_ms\": 14676.562}", "{\"n\": 6769, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3708.16, \"learn_time_ms\": 14696.767}", "{\"n\": 6770, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3706.91, \"learn_time_ms\": 14705.547}", "{\"n\": 6771, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3706.91, \"learn_time_ms\": 14686.235}", "{\"n\": 6772, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3716.55, \"learn_time_ms\": 14690.449}", "{\"n\": 6773, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3722.29, \"learn_time_ms\": 14680.638}", "{\"n\": 6774, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3722.29, \"learn_time_ms\": 14691.009}", "{\"n\": 6775, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3735.98, \"learn_time_ms\": 14660.535}", "{\"n\": 6776, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3737.04, \"learn_time_ms\": 14677.526}", "{\"n\": 6777, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3739.15, \"learn_time_ms\": 14682.067}", "{\"n\": 6778, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3741.71, \"learn_time_ms\": 14688.595}", "{\"n\": 6779, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3741.71, \"learn_time_ms\": 14693.385}", "{\"n\": 6780, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3741.71, \"learn_time_ms\": 14738.628}", "{\"n\": 6781, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3736.39, \"learn_time_ms\": 14737.279}", "{\"n\": 6782, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3751.0, \"learn_time_ms\": 14708.591}", "{\"n\": 6783, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3757.46, \"learn_time_ms\": 14691.823}", "{\"n\": 6784, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3757.46, \"learn_time_ms\": 14676.412}", "{\"n\": 6785, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3757.46, \"learn_time_ms\": 14706.996}", "{\"n\": 6786, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3757.46, \"learn_time_ms\": 14725.872}", "{\"n\": 6787, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3759.79, \"learn_time_ms\": 14718.546}", "{\"n\": 6788, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3759.68, \"learn_time_ms\": 14714.692}", "{\"n\": 6789, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3759.68, \"learn_time_ms\": 14702.788}", "{\"n\": 6790, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3760.38, \"learn_time_ms\": 14637.552}", "{\"n\": 6791, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3760.38, \"learn_time_ms\": 14632.809}", "{\"n\": 6792, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3759.59, \"learn_time_ms\": 14660.029}", "{\"n\": 6793, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3758.61, \"learn_time_ms\": 14691.222}", "{\"n\": 6794, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3769.18, \"learn_time_ms\": 14686.212}", "{\"n\": 6795, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3773.75, \"learn_time_ms\": 14683.721}", "{\"n\": 6796, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3779.84, \"learn_time_ms\": 14664.525}", "{\"n\": 6797, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3776.17, \"learn_time_ms\": 14677.543}", "{\"n\": 6798, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3776.17, \"learn_time_ms\": 14684.104}", "{\"n\": 6799, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3770.44, \"learn_time_ms\": 14682.847}", "{\"n\": 6800, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3770.44, \"learn_time_ms\": 14741.971}", "{\"n\": 6801, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3788.81, \"learn_time_ms\": 14764.186}", "{\"n\": 6802, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3778.54, \"learn_time_ms\": 14762.929}", "{\"n\": 6803, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3772.29, \"learn_time_ms\": 14727.05}", "{\"n\": 6804, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3776.33, \"learn_time_ms\": 14727.165}", "{\"n\": 6805, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3776.33, \"learn_time_ms\": 14673.229}", "{\"n\": 6806, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3776.33, \"learn_time_ms\": 14674.651}", "{\"n\": 6807, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3776.95, \"learn_time_ms\": 14667.1}", "{\"n\": 6808, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3776.95, \"learn_time_ms\": 14667.236}", "{\"n\": 6809, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3776.95, \"learn_time_ms\": 14669.214}", "{\"n\": 6810, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3776.95, \"learn_time_ms\": 14672.037}", "{\"n\": 6811, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3750.52, \"learn_time_ms\": 14665.076}", "{\"n\": 6812, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3750.52, \"learn_time_ms\": 14643.356}", "{\"n\": 6813, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3743.51, \"learn_time_ms\": 14684.932}", "{\"n\": 6814, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3732.99, \"learn_time_ms\": 14706.482}", "{\"n\": 6815, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.77, \"learn_time_ms\": 14764.494}", "{\"n\": 6816, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.77, \"learn_time_ms\": 14764.404}", "{\"n\": 6817, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3739.7, \"learn_time_ms\": 14769.863}", "{\"n\": 6818, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3734.58, \"learn_time_ms\": 14763.845}", "{\"n\": 6819, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3753.93, \"learn_time_ms\": 14752.495}", "{\"n\": 6820, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3747.17, \"learn_time_ms\": 14743.767}", "{\"n\": 6821, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3760.19, \"learn_time_ms\": 14755.719}", "{\"n\": 6822, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3760.19, \"learn_time_ms\": 14789.732}", "{\"n\": 6823, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3751.55, \"learn_time_ms\": 14774.239}", "{\"n\": 6824, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3751.55, \"learn_time_ms\": 14758.904}", "{\"n\": 6825, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3762.43, \"learn_time_ms\": 14765.328}", "{\"n\": 6826, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3758.04, \"learn_time_ms\": 14773.43}", "{\"n\": 6827, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3744.35, \"learn_time_ms\": 14760.577}", "{\"n\": 6828, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3744.35, \"learn_time_ms\": 14742.628}", "{\"n\": 6829, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3742.38, \"learn_time_ms\": 14764.58}", "{\"n\": 6830, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3735.33, \"learn_time_ms\": 14780.325}", "{\"n\": 6831, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3725.6, \"learn_time_ms\": 14762.468}", "{\"n\": 6832, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3714.74, \"learn_time_ms\": 14715.301}", "{\"n\": 6833, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.45, \"learn_time_ms\": 14732.784}", "{\"n\": 6834, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.45, \"learn_time_ms\": 14735.937}", "{\"n\": 6835, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3696.24, \"learn_time_ms\": 14734.565}", "{\"n\": 6836, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.06, \"learn_time_ms\": 14722.997}", "{\"n\": 6837, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.06, \"learn_time_ms\": 14720.635}", "{\"n\": 6838, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.67, \"learn_time_ms\": 14724.982}", "{\"n\": 6839, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3682.92, \"learn_time_ms\": 14713.469}", "{\"n\": 6840, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3685.28, \"learn_time_ms\": 14700.245}", "{\"n\": 6841, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3687.67, \"learn_time_ms\": 14707.968}", "{\"n\": 6842, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3693.8, \"learn_time_ms\": 14741.375}", "{\"n\": 6843, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3693.8, \"learn_time_ms\": 14721.838}", "{\"n\": 6844, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3687.64, \"learn_time_ms\": 14725.941}", "{\"n\": 6845, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3685.28, \"learn_time_ms\": 14716.81}", "{\"n\": 6846, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3686.56, \"learn_time_ms\": 14723.428}", "{\"n\": 6847, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3676.64, \"learn_time_ms\": 14738.068}", "{\"n\": 6848, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3674.85, \"learn_time_ms\": 14728.257}", "{\"n\": 6849, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3660.2, \"learn_time_ms\": 14701.539}", "{\"n\": 6850, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3669.26, \"learn_time_ms\": 14677.323}", "{\"n\": 6851, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3674.29, \"learn_time_ms\": 14684.327}", "{\"n\": 6852, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3674.29, \"learn_time_ms\": 14682.298}", "{\"n\": 6853, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3681.68, \"learn_time_ms\": 14628.492}", "{\"n\": 6854, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3660.75, \"learn_time_ms\": 14621.236}", "{\"n\": 6855, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3660.75, \"learn_time_ms\": 14622.726}", "{\"n\": 6856, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3654.11, \"learn_time_ms\": 14623.861}", "{\"n\": 6857, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3651.67, \"learn_time_ms\": 14623.813}", "{\"n\": 6858, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3651.67, \"learn_time_ms\": 14653.478}", "{\"n\": 6859, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3651.67, \"learn_time_ms\": 14676.912}", "{\"n\": 6860, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3642.52, \"learn_time_ms\": 14685.531}", "{\"n\": 6861, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3637.56, \"learn_time_ms\": 14696.289}", "{\"n\": 6862, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3639.97, \"learn_time_ms\": 14714.365}", "{\"n\": 6863, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3620.51, \"learn_time_ms\": 14780.038}", "{\"n\": 6864, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3627.7, \"learn_time_ms\": 14769.429}", "{\"n\": 6865, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3627.7, \"learn_time_ms\": 14789.667}", "{\"n\": 6866, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3630.0, \"learn_time_ms\": 14803.907}", "{\"n\": 6867, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3665.16, \"learn_time_ms\": 14790.177}", "{\"n\": 6868, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3665.16, \"learn_time_ms\": 14785.991}", "{\"n\": 6869, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3660.14, \"learn_time_ms\": 14787.893}", "{\"n\": 6870, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3672.68, \"learn_time_ms\": 14800.497}", "{\"n\": 6871, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3660.71, \"learn_time_ms\": 14785.441}", "{\"n\": 6872, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3650.11, \"learn_time_ms\": 14769.379}", "{\"n\": 6873, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3650.11, \"learn_time_ms\": 14760.618}", "{\"n\": 6874, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3650.11, \"learn_time_ms\": 14771.509}", "{\"n\": 6875, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3654.9, \"learn_time_ms\": 14755.458}", "{\"n\": 6876, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3635.34, \"learn_time_ms\": 14746.975}", "{\"n\": 6877, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3646.27, \"learn_time_ms\": 14761.037}", "{\"n\": 6878, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3646.27, \"learn_time_ms\": 14766.134}", "{\"n\": 6879, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.23, \"learn_time_ms\": 14751.555}", "{\"n\": 6880, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.23, \"learn_time_ms\": 14749.735}", "{\"n\": 6881, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3625.87, \"learn_time_ms\": 14741.833}", "{\"n\": 6882, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3625.87, \"learn_time_ms\": 14739.99}", "{\"n\": 6883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3623.2, \"learn_time_ms\": 14740.2}", "{\"n\": 6884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3623.2, \"learn_time_ms\": 14758.542}", "{\"n\": 6885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.17, \"learn_time_ms\": 14754.186}", "{\"n\": 6886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.17, \"learn_time_ms\": 14742.856}", "{\"n\": 6887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3648.17, \"learn_time_ms\": 14724.208}", "{\"n\": 6888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3663.71, \"learn_time_ms\": 14707.11}", "{\"n\": 6889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3667.16, \"learn_time_ms\": 14731.74}", "{\"n\": 6890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3676.41, \"learn_time_ms\": 14741.686}", "{\"n\": 6891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3671.01, \"learn_time_ms\": 14704.674}", "{\"n\": 6892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3671.01, \"learn_time_ms\": 14694.466}", "{\"n\": 6893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3671.01, \"learn_time_ms\": 14654.189}", "{\"n\": 6894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3676.26, \"learn_time_ms\": 14614.372}", "{\"n\": 6895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3669.33, \"learn_time_ms\": 14596.715}", "{\"n\": 6896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3668.08, \"learn_time_ms\": 14608.309}", "{\"n\": 6897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3671.09, \"learn_time_ms\": 14610.353}", "{\"n\": 6898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3678.2, \"learn_time_ms\": 14627.96}", "{\"n\": 6899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3678.2, \"learn_time_ms\": 14624.001}", "{\"n\": 6900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3672.36, \"learn_time_ms\": 14605.0}", "{\"n\": 6901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3675.78, \"learn_time_ms\": 14607.301}", "{\"n\": 6902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3667.9, \"learn_time_ms\": 14608.188}", "{\"n\": 6903, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3667.9, \"learn_time_ms\": 14648.037}", "{\"n\": 6904, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3660.66, \"learn_time_ms\": 14676.048}", "{\"n\": 6905, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3671.64, \"learn_time_ms\": 14688.94}", "{\"n\": 6906, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3671.64, \"learn_time_ms\": 14655.211}", "{\"n\": 6907, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3674.86, \"learn_time_ms\": 14646.434}", "{\"n\": 6908, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3686.61, \"learn_time_ms\": 14628.427}", "{\"n\": 6909, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3703.2, \"learn_time_ms\": 14630.781}", "{\"n\": 6910, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3703.2, \"learn_time_ms\": 14639.284}", "{\"n\": 6911, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3728.63, \"learn_time_ms\": 14687.892}", "{\"n\": 6912, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3728.63, \"learn_time_ms\": 14688.057}", "{\"n\": 6913, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3728.63, \"learn_time_ms\": 14659.954}", "{\"n\": 6914, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3739.29, \"learn_time_ms\": 14647.174}", "{\"n\": 6915, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3740.91, \"learn_time_ms\": 14655.721}", "{\"n\": 6916, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3737.92, \"learn_time_ms\": 14683.867}", "{\"n\": 6917, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3737.92, \"learn_time_ms\": 14692.352}", "{\"n\": 6918, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3737.92, \"learn_time_ms\": 14693.342}", "{\"n\": 6919, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3738.11, \"learn_time_ms\": 14681.284}", "{\"n\": 6920, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3738.11, \"learn_time_ms\": 14691.965}", "{\"n\": 6921, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3744.72, \"learn_time_ms\": 14680.582}", "{\"n\": 6922, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3743.89, \"learn_time_ms\": 14688.17}", "{\"n\": 6923, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3743.83, \"learn_time_ms\": 14715.703}", "{\"n\": 6924, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3731.03, \"learn_time_ms\": 14721.506}", "{\"n\": 6925, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3746.77, \"learn_time_ms\": 14717.943}", "{\"n\": 6926, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3747.26, \"learn_time_ms\": 14684.23}", "{\"n\": 6927, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3747.26, \"learn_time_ms\": 14685.653}", "{\"n\": 6928, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3767.43, \"learn_time_ms\": 14713.395}", "{\"n\": 6929, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3775.58, \"learn_time_ms\": 14700.601}", "{\"n\": 6930, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3775.58, \"learn_time_ms\": 14681.415}", "{\"n\": 6931, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3775.58, \"learn_time_ms\": 14671.458}", "{\"n\": 6932, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3763.52, \"learn_time_ms\": 14661.149}", "{\"n\": 6933, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3779.43, \"learn_time_ms\": 14664.657}", "{\"n\": 6934, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3779.43, \"learn_time_ms\": 14673.211}", "{\"n\": 6935, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3776.58, \"learn_time_ms\": 14657.548}", "{\"n\": 6936, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3785.86, \"learn_time_ms\": 14687.814}", "{\"n\": 6937, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3785.86, \"learn_time_ms\": 14697.039}", "{\"n\": 6938, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.24, \"learn_time_ms\": 14666.366}", "{\"n\": 6939, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3793.72, \"learn_time_ms\": 14677.787}", "{\"n\": 6940, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3786.54, \"learn_time_ms\": 14689.527}", "{\"n\": 6941, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3793.01, \"learn_time_ms\": 14681.076}", "{\"n\": 6942, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3805.39, \"learn_time_ms\": 14696.205}", "{\"n\": 6943, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3805.29, \"learn_time_ms\": 14697.824}", "{\"n\": 6944, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3805.29, \"learn_time_ms\": 14682.2}", "{\"n\": 6945, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3788.2, \"learn_time_ms\": 14701.135}", "{\"n\": 6946, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3791.98, \"learn_time_ms\": 14702.619}", "{\"n\": 6947, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3784.88, \"learn_time_ms\": 14692.927}", "{\"n\": 6948, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3784.88, \"learn_time_ms\": 14712.438}", "{\"n\": 6949, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3773.04, \"learn_time_ms\": 14731.232}", "{\"n\": 6950, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3767.67, \"learn_time_ms\": 14722.58}", "{\"n\": 6951, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3764.88, \"learn_time_ms\": 14721.425}", "{\"n\": 6952, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3773.01, \"learn_time_ms\": 14715.04}", "{\"n\": 6953, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3776.52, \"learn_time_ms\": 14689.026}", "{\"n\": 6954, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3791.0, \"learn_time_ms\": 14715.671}", "{\"n\": 6955, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3790.97, \"learn_time_ms\": 14712.586}", "{\"n\": 6956, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3773.81, \"learn_time_ms\": 14731.201}", "{\"n\": 6957, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3775.08, \"learn_time_ms\": 14742.983}", "{\"n\": 6958, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.82, \"learn_time_ms\": 14739.125}", "{\"n\": 6959, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.82, \"learn_time_ms\": 14714.388}", "{\"n\": 6960, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3779.71, \"learn_time_ms\": 14713.761}", "{\"n\": 6961, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3770.71, \"learn_time_ms\": 14701.695}", "{\"n\": 6962, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3770.71, \"learn_time_ms\": 14688.548}", "{\"n\": 6963, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3772.9, \"learn_time_ms\": 14714.177}", "{\"n\": 6964, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3777.95, \"learn_time_ms\": 14702.318}", "{\"n\": 6965, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3777.29, \"learn_time_ms\": 14703.397}", "{\"n\": 6966, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3778.67, \"learn_time_ms\": 14683.69}", "{\"n\": 6967, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3774.67, \"learn_time_ms\": 14691.788}", "{\"n\": 6968, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3772.03, \"learn_time_ms\": 14691.142}", "{\"n\": 6969, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3773.81, \"learn_time_ms\": 14685.257}", "{\"n\": 6970, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3773.81, \"learn_time_ms\": 14710.043}", "{\"n\": 6971, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3760.86, \"learn_time_ms\": 14729.153}", "{\"n\": 6972, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3756.46, \"learn_time_ms\": 14754.847}", "{\"n\": 6973, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3756.46, \"learn_time_ms\": 14756.251}", "{\"n\": 6974, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3756.12, \"learn_time_ms\": 14762.836}", "{\"n\": 6975, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3741.1, \"learn_time_ms\": 14763.009}", "{\"n\": 6976, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3739.58, \"learn_time_ms\": 14768.863}", "{\"n\": 6977, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3723.94, \"learn_time_ms\": 14771.036}", "{\"n\": 6978, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3723.31, \"learn_time_ms\": 14759.23}", "{\"n\": 6979, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3721.39, \"learn_time_ms\": 14788.619}", "{\"n\": 6980, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3712.53, \"learn_time_ms\": 14771.561}", "{\"n\": 6981, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3692.55, \"learn_time_ms\": 14784.903}", "{\"n\": 6982, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3702.12, \"learn_time_ms\": 14760.339}", "{\"n\": 6983, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3697.66, \"learn_time_ms\": 14741.415}", "{\"n\": 6984, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3695.03, \"learn_time_ms\": 14720.438}", "{\"n\": 6985, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3682.48, \"learn_time_ms\": 14726.183}", "{\"n\": 6986, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3681.54, \"learn_time_ms\": 14731.898}", "{\"n\": 6987, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3668.2, \"learn_time_ms\": 14716.719}", "{\"n\": 6988, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3668.2, \"learn_time_ms\": 14710.335}", "{\"n\": 6989, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3650.27, \"learn_time_ms\": 14691.912}", "{\"n\": 6990, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3643.08, \"learn_time_ms\": 14676.472}", "{\"n\": 6991, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3631.11, \"learn_time_ms\": 14673.197}", "{\"n\": 6992, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3631.11, \"learn_time_ms\": 14690.324}", "{\"n\": 6993, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3649.62, \"learn_time_ms\": 14708.245}", "{\"n\": 6994, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3633.74, \"learn_time_ms\": 14692.992}", "{\"n\": 6995, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3633.74, \"learn_time_ms\": 14686.286}", "{\"n\": 6996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3640.76, \"learn_time_ms\": 14664.463}", "{\"n\": 6997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3651.09, \"learn_time_ms\": 14671.924}", "{\"n\": 6998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3637.79, \"learn_time_ms\": 14669.545}", "{\"n\": 6999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3637.79, \"learn_time_ms\": 14662.591}", "{\"n\": 7000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3640.98, \"learn_time_ms\": 14688.774}"]["{\"n\": 7001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15198.722}", "{\"n\": 7002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14929.186}", "{\"n\": 7003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14855.422}", "{\"n\": 7004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14823.925}", "{\"n\": 7005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14798.568}", "{\"n\": 7006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14764.502}", "{\"n\": 7007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14758.428}", "{\"n\": 7008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14747.879}", "{\"n\": 7009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14746.1}", "{\"n\": 7010, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2905.0, \"learn_time_ms\": 14741.445}", "{\"n\": 7011, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3284.5, \"learn_time_ms\": 14693.198}", "{\"n\": 7012, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3469.6, \"learn_time_ms\": 14688.283}", "{\"n\": 7013, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.333333333333333, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3631.3333333333335, \"learn_time_ms\": 14695.986}", "{\"n\": 7014, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.125, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3648.125, \"learn_time_ms\": 14690.638}", "{\"n\": 7015, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.125, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3648.125, \"learn_time_ms\": 14689.028}", "{\"n\": 7016, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.125, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3648.125, \"learn_time_ms\": 14708.902}", "{\"n\": 7017, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3558.4, \"learn_time_ms\": 14703.54}", "{\"n\": 7018, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.916666666666667, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3548.3333333333335, \"learn_time_ms\": 14716.068}", "{\"n\": 7019, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.142857142857143, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3537.714285714286, \"learn_time_ms\": 14721.68}", "{\"n\": 7020, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.8125, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3556.5625, \"learn_time_ms\": 14723.897}", "{\"n\": 7021, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.8125, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3556.5625, \"learn_time_ms\": 14733.522}", "{\"n\": 7022, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.8125, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3556.5625, \"learn_time_ms\": 14755.265}", "{\"n\": 7023, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.888888888888889, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3595.9444444444443, \"learn_time_ms\": 14752.989}", "{\"n\": 7024, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3553.3, \"learn_time_ms\": 14763.905}", "{\"n\": 7025, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3553.3, \"learn_time_ms\": 14772.783}", "{\"n\": 7026, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.190476190476191, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3561.0476190476193, \"learn_time_ms\": 14774.665}", "{\"n\": 7027, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.2272727272727275, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3574.2272727272725, \"learn_time_ms\": 14781.801}", "{\"n\": 7028, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.958333333333333, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3638.5833333333335, \"learn_time_ms\": 14776.391}", "{\"n\": 7029, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.958333333333333, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3638.5833333333335, \"learn_time_ms\": 14779.493}", "{\"n\": 7030, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.481481481481482, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3595.3703703703704, \"learn_time_ms\": 14780.709}", "{\"n\": 7031, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.321428571428571, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3614.6071428571427, \"learn_time_ms\": 14778.648}", "{\"n\": 7032, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.741935483870968, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3699.8064516129034, \"learn_time_ms\": 14766.618}", "{\"n\": 7033, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.741935483870968, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3699.8064516129034, \"learn_time_ms\": 14763.996}", "{\"n\": 7034, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.625, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3725.78125, \"learn_time_ms\": 14743.359}", "{\"n\": 7035, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.625, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3725.78125, \"learn_time_ms\": 14742.223}", "{\"n\": 7036, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.588235294117647, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3747.294117647059, \"learn_time_ms\": 14741.96}", "{\"n\": 7037, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.594594594594595, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3749.0810810810813, \"learn_time_ms\": 14740.904}", "{\"n\": 7038, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.594594594594595, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3749.0810810810813, \"learn_time_ms\": 14743.734}", "{\"n\": 7039, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.6923076923076925, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3732.3333333333335, \"learn_time_ms\": 14741.072}", "{\"n\": 7040, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.775, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3726.975, \"learn_time_ms\": 14748.782}", "{\"n\": 7041, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.775, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3726.975, \"learn_time_ms\": 14742.486}", "{\"n\": 7042, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.809523809523809, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3718.1190476190477, \"learn_time_ms\": 14745.816}", "{\"n\": 7043, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.809523809523809, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3718.1190476190477, \"learn_time_ms\": 14749.148}", "{\"n\": 7044, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.613636363636363, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3714.2272727272725, \"learn_time_ms\": 14764.004}", "{\"n\": 7045, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.739130434782608, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3709.8260869565215, \"learn_time_ms\": 14757.066}", "{\"n\": 7046, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.375, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3727.2083333333335, \"learn_time_ms\": 14755.933}", "{\"n\": 7047, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.375, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3727.2083333333335, \"learn_time_ms\": 14765.309}", "{\"n\": 7048, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.469387755102041, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3725.061224489796, \"learn_time_ms\": 14765.286}", "{\"n\": 7049, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.490196078431373, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3731.6666666666665, \"learn_time_ms\": 14768.797}", "{\"n\": 7050, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.490196078431373, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3731.6666666666665, \"learn_time_ms\": 14761.43}", "{\"n\": 7051, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.37037037037037, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3755.8703703703704, \"learn_time_ms\": 14767.5}", "{\"n\": 7052, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.4363636363636365, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3749.2545454545457, \"learn_time_ms\": 14765.231}", "{\"n\": 7053, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.375, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3758.839285714286, \"learn_time_ms\": 14765.16}", "{\"n\": 7054, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.456140350877193, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3753.4210526315787, \"learn_time_ms\": 14757.201}", "{\"n\": 7055, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.456140350877193, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3753.4210526315787, \"learn_time_ms\": 14763.957}", "{\"n\": 7056, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.396551724137931, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.3275862068967, \"learn_time_ms\": 14763.697}", "{\"n\": 7057, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.311475409836065, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.754098360656, \"learn_time_ms\": 14747.368}", "{\"n\": 7058, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.380952380952381, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.4603174603176, \"learn_time_ms\": 14734.854}", "{\"n\": 7059, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.484375, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.171875, \"learn_time_ms\": 14726.757}", "{\"n\": 7060, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.3076923076923075, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3780.8, \"learn_time_ms\": 14732.661}", "{\"n\": 7061, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.3076923076923075, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3780.8, \"learn_time_ms\": 14727.123}", "{\"n\": 7062, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.257575757575758, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3784.1969696969695, \"learn_time_ms\": 14729.379}", "{\"n\": 7063, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.257575757575758, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3784.1969696969695, \"learn_time_ms\": 14740.658}", "{\"n\": 7064, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.171428571428572, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3786.842857142857, \"learn_time_ms\": 14751.603}", "{\"n\": 7065, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.253521126760563, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.4225352112676, \"learn_time_ms\": 14753.091}", "{\"n\": 7066, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.208333333333333, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3786.8611111111113, \"learn_time_ms\": 14742.538}", "{\"n\": 7067, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.208333333333333, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3786.8611111111113, \"learn_time_ms\": 14747.032}", "{\"n\": 7068, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.219178082191781, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3783.1917808219177, \"learn_time_ms\": 14757.195}", "{\"n\": 7069, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.276315789473684, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3783.7763157894738, \"learn_time_ms\": 14748.454}", "{\"n\": 7070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2727272727272725, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3788.7662337662337, \"learn_time_ms\": 14746.735}", "{\"n\": 7071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2784810126582276, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3799.0759493670885, \"learn_time_ms\": 14744.168}", "{\"n\": 7072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2625, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.9375, \"learn_time_ms\": 14743.789}", "{\"n\": 7073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2625, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.9375, \"learn_time_ms\": 14733.988}", "{\"n\": 7074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.296296296296297, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.222222222222, \"learn_time_ms\": 14734.132}", "{\"n\": 7075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2073170731707314, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3810.378048780488, \"learn_time_ms\": 14728.691}", "{\"n\": 7076, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.235294117647059, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3815.0470588235294, \"learn_time_ms\": 14729.644}", "{\"n\": 7077, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.390804597701149, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3796.344827586207, \"learn_time_ms\": 14727.347}", "{\"n\": 7078, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.390804597701149, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3796.344827586207, \"learn_time_ms\": 14726.41}", "{\"n\": 7079, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.454545454545454, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3789.875, \"learn_time_ms\": 14737.404}", "{\"n\": 7080, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.573033707865169, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3775.8426966292136, \"learn_time_ms\": 14737.106}", "{\"n\": 7081, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.573033707865169, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3775.8426966292136, \"learn_time_ms\": 14747.522}", "{\"n\": 7082, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.521739130434782, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.967391304348, \"learn_time_ms\": 14749.895}", "{\"n\": 7083, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.526881720430108, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3782.1935483870966, \"learn_time_ms\": 14748.822}", "{\"n\": 7084, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48936170212766, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3795.3829787234044, \"learn_time_ms\": 14752.511}", "{\"n\": 7085, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.458333333333333, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3799.4166666666665, \"learn_time_ms\": 14762.69}", "{\"n\": 7086, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.494845360824742, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3794.226804123711, \"learn_time_ms\": 14773.103}", "{\"n\": 7087, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.479591836734694, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3797.581632653061, \"learn_time_ms\": 14779.654}", "{\"n\": 7088, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3803.77, \"learn_time_ms\": 14774.02}", "{\"n\": 7089, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3815.17, \"learn_time_ms\": 14766.018}", "{\"n\": 7090, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3821.3, \"learn_time_ms\": 14751.384}", "{\"n\": 7091, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3835.03, \"learn_time_ms\": 14729.96}", "{\"n\": 7092, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3835.03, \"learn_time_ms\": 14717.916}", "{\"n\": 7093, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3808.37, \"learn_time_ms\": 14711.478}", "{\"n\": 7094, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3813.73, \"learn_time_ms\": 14708.878}", "{\"n\": 7095, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3813.73, \"learn_time_ms\": 14703.188}", "{\"n\": 7096, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3821.34, \"learn_time_ms\": 14695.797}", "{\"n\": 7097, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3820.08, \"learn_time_ms\": 14695.105}", "{\"n\": 7098, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3827.07, \"learn_time_ms\": 14699.556}", "{\"n\": 7099, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3837.61, \"learn_time_ms\": 14712.657}", "{\"n\": 7100, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3833.96, \"learn_time_ms\": 14720.912}", "{\"n\": 7101, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3831.18, \"learn_time_ms\": 14728.578}", "{\"n\": 7102, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3840.98, \"learn_time_ms\": 14735.25}", "{\"n\": 7103, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3840.98, \"learn_time_ms\": 14734.655}", "{\"n\": 7104, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3856.22, \"learn_time_ms\": 14731.117}", "{\"n\": 7105, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3860.14, \"learn_time_ms\": 14725.159}", "{\"n\": 7106, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3860.14, \"learn_time_ms\": 14723.234}", "{\"n\": 7107, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3860.14, \"learn_time_ms\": 14719.013}", "{\"n\": 7108, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3861.09, \"learn_time_ms\": 14724.558}", "{\"n\": 7109, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3869.02, \"learn_time_ms\": 14715.014}", "{\"n\": 7110, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3872.72, \"learn_time_ms\": 14717.575}", "{\"n\": 7111, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3858.1, \"learn_time_ms\": 14730.422}", "{\"n\": 7112, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3858.1, \"learn_time_ms\": 14731.285}", "{\"n\": 7113, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3858.1, \"learn_time_ms\": 14736.499}", "{\"n\": 7114, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3858.1, \"learn_time_ms\": 14748.208}", "{\"n\": 7115, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3846.53, \"learn_time_ms\": 14750.006}", "{\"n\": 7116, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3834.14, \"learn_time_ms\": 14749.716}", "{\"n\": 7117, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3844.98, \"learn_time_ms\": 14762.517}", "{\"n\": 7118, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3843.39, \"learn_time_ms\": 14766.212}", "{\"n\": 7119, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3847.38, \"learn_time_ms\": 14759.729}", "{\"n\": 7120, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3847.38, \"learn_time_ms\": 14763.609}", "{\"n\": 7121, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3847.38, \"learn_time_ms\": 14769.937}", "{\"n\": 7122, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3865.27, \"learn_time_ms\": 14772.322}", "{\"n\": 7123, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3874.37, \"learn_time_ms\": 14769.025}", "{\"n\": 7124, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3903.84, \"learn_time_ms\": 14755.262}", "{\"n\": 7125, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3909.49, \"learn_time_ms\": 14765.769}", "{\"n\": 7126, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3913.46, \"learn_time_ms\": 14771.066}", "{\"n\": 7127, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3913.46, \"learn_time_ms\": 14760.373}", "{\"n\": 7128, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3913.46, \"learn_time_ms\": 14749.409}", "{\"n\": 7129, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3914.49, \"learn_time_ms\": 14754.165}", "{\"n\": 7130, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3920.45, \"learn_time_ms\": 14758.487}", "{\"n\": 7131, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3930.96, \"learn_time_ms\": 14753.174}", "{\"n\": 7132, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3931.41, \"learn_time_ms\": 14762.439}", "{\"n\": 7133, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3931.41, \"learn_time_ms\": 14762.294}", "{\"n\": 7134, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3931.41, \"learn_time_ms\": 14765.07}", "{\"n\": 7135, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3938.96, \"learn_time_ms\": 14757.096}", "{\"n\": 7136, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3937.13, \"learn_time_ms\": 14755.255}", "{\"n\": 7137, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3916.48, \"learn_time_ms\": 14763.906}", "{\"n\": 7138, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3924.37, \"learn_time_ms\": 14766.49}", "{\"n\": 7139, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3924.37, \"learn_time_ms\": 14770.221}", "{\"n\": 7140, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3922.98, \"learn_time_ms\": 14760.703}", "{\"n\": 7141, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3928.74, \"learn_time_ms\": 14744.569}", "{\"n\": 7142, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.7, \"learn_time_ms\": 14733.219}", "{\"n\": 7143, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.31, \"learn_time_ms\": 14725.848}", "{\"n\": 7144, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.31, \"learn_time_ms\": 14731.814}", "{\"n\": 7145, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3923.85, \"learn_time_ms\": 14722.536}", "{\"n\": 7146, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3920.25, \"learn_time_ms\": 14719.943}", "{\"n\": 7147, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3936.02, \"learn_time_ms\": 14711.62}", "{\"n\": 7148, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.68, \"learn_time_ms\": 14712.654}", "{\"n\": 7149, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.68, \"learn_time_ms\": 14716.615}", "{\"n\": 7150, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3926.68, \"learn_time_ms\": 14710.707}", "{\"n\": 7151, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3926.68, \"learn_time_ms\": 14717.976}", "{\"n\": 7152, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3926.68, \"learn_time_ms\": 14713.605}", "{\"n\": 7153, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3911.77, \"learn_time_ms\": 14719.902}", "{\"n\": 7154, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3911.77, \"learn_time_ms\": 14711.566}", "{\"n\": 7155, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3911.27, \"learn_time_ms\": 14729.346}", "{\"n\": 7156, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3918.68, \"learn_time_ms\": 14739.157}", "{\"n\": 7157, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.07, \"learn_time_ms\": 14734.305}", "{\"n\": 7158, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.07, \"learn_time_ms\": 14720.058}", "{\"n\": 7159, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.07, \"learn_time_ms\": 14720.274}", "{\"n\": 7160, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.07, \"learn_time_ms\": 14717.803}", "{\"n\": 7161, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3939.75, \"learn_time_ms\": 14715.167}", "{\"n\": 7162, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3957.61, \"learn_time_ms\": 14724.571}", "{\"n\": 7163, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3958.18, \"learn_time_ms\": 14728.826}", "{\"n\": 7164, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3958.18, \"learn_time_ms\": 14730.824}", "{\"n\": 7165, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3958.18, \"learn_time_ms\": 14715.06}", "{\"n\": 7166, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3954.3, \"learn_time_ms\": 14711.821}", "{\"n\": 7167, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3954.3, \"learn_time_ms\": 14721.551}", "{\"n\": 7168, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3949.85, \"learn_time_ms\": 14735.787}", "{\"n\": 7169, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3946.3, \"learn_time_ms\": 14731.418}", "{\"n\": 7170, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3952.18, \"learn_time_ms\": 14738.922}", "{\"n\": 7171, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3952.29, \"learn_time_ms\": 14741.39}", "{\"n\": 7172, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3952.29, \"learn_time_ms\": 14741.104}", "{\"n\": 7173, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3937.1, \"learn_time_ms\": 14733.183}", "{\"n\": 7174, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3931.77, \"learn_time_ms\": 14733.71}", "{\"n\": 7175, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3949.48, \"learn_time_ms\": 14743.104}", "{\"n\": 7176, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3966.05, \"learn_time_ms\": 14737.955}", "{\"n\": 7177, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3968.45, \"learn_time_ms\": 14734.47}", "{\"n\": 7178, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3974.96, \"learn_time_ms\": 14734.153}", "{\"n\": 7179, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3971.74, \"learn_time_ms\": 14734.485}", "{\"n\": 7180, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3971.74, \"learn_time_ms\": 14741.643}", "{\"n\": 7181, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3977.0, \"learn_time_ms\": 14748.645}", "{\"n\": 7182, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3971.25, \"learn_time_ms\": 14750.542}", "{\"n\": 7183, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3967.72, \"learn_time_ms\": 14751.738}", "{\"n\": 7184, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3972.49, \"learn_time_ms\": 14748.641}", "{\"n\": 7185, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3967.86, \"learn_time_ms\": 14751.584}", "{\"n\": 7186, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3972.76, \"learn_time_ms\": 14753.241}", "{\"n\": 7187, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3972.76, \"learn_time_ms\": 14754.475}", "{\"n\": 7188, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3956.88, \"learn_time_ms\": 14744.742}", "{\"n\": 7189, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3945.45, \"learn_time_ms\": 14742.805}", "{\"n\": 7190, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3949.36, \"learn_time_ms\": 14736.019}", "{\"n\": 7191, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3955.69, \"learn_time_ms\": 14743.486}", "{\"n\": 7192, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3955.69, \"learn_time_ms\": 14750.842}", "{\"n\": 7193, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3962.76, \"learn_time_ms\": 14757.747}", "{\"n\": 7194, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3962.76, \"learn_time_ms\": 14748.55}", "{\"n\": 7195, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3956.7, \"learn_time_ms\": 14728.052}", "{\"n\": 7196, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3960.58, \"learn_time_ms\": 14729.298}", "{\"n\": 7197, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3960.58, \"learn_time_ms\": 14734.282}", "{\"n\": 7198, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3960.58, \"learn_time_ms\": 14741.732}", "{\"n\": 7199, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3950.35, \"learn_time_ms\": 14746.738}", "{\"n\": 7200, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3944.98, \"learn_time_ms\": 14746.679}", "{\"n\": 7201, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3944.98, \"learn_time_ms\": 14722.507}", "{\"n\": 7202, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3924.26, \"learn_time_ms\": 14715.37}", "{\"n\": 7203, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3914.05, \"learn_time_ms\": 14721.718}", "{\"n\": 7204, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3914.05, \"learn_time_ms\": 14731.304}", "{\"n\": 7205, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3914.05, \"learn_time_ms\": 14736.203}", "{\"n\": 7206, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3905.65, \"learn_time_ms\": 14726.86}", "{\"n\": 7207, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3881.42, \"learn_time_ms\": 14717.535}", "{\"n\": 7208, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3881.42, \"learn_time_ms\": 14716.062}", "{\"n\": 7209, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3889.06, \"learn_time_ms\": 14715.261}", "{\"n\": 7210, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3892.99, \"learn_time_ms\": 14696.833}", "{\"n\": 7211, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3892.99, \"learn_time_ms\": 14705.925}", "{\"n\": 7212, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3892.99, \"learn_time_ms\": 14697.008}", "{\"n\": 7213, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3886.3, \"learn_time_ms\": 14686.534}", "{\"n\": 7214, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3881.95, \"learn_time_ms\": 14689.384}", "{\"n\": 7215, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3887.3, \"learn_time_ms\": 14697.364}", "{\"n\": 7216, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3895.37, \"learn_time_ms\": 14708.936}", "{\"n\": 7217, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3895.37, \"learn_time_ms\": 14715.967}", "{\"n\": 7218, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3894.27, \"learn_time_ms\": 14721.81}", "{\"n\": 7219, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3905.68, \"learn_time_ms\": 14719.725}", "{\"n\": 7220, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3902.34, \"learn_time_ms\": 14727.678}", "{\"n\": 7221, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3908.83, \"learn_time_ms\": 14729.778}", "{\"n\": 7222, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3895.59, \"learn_time_ms\": 14728.353}", "{\"n\": 7223, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3897.39, \"learn_time_ms\": 14741.461}", "{\"n\": 7224, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3896.89, \"learn_time_ms\": 14744.559}", "{\"n\": 7225, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3896.16, \"learn_time_ms\": 14742.508}", "{\"n\": 7226, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3896.16, \"learn_time_ms\": 14739.044}", "{\"n\": 7227, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3899.52, \"learn_time_ms\": 14734.067}", "{\"n\": 7228, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3893.64, \"learn_time_ms\": 14732.022}", "{\"n\": 7229, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3901.0, \"learn_time_ms\": 14733.673}", "{\"n\": 7230, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3894.24, \"learn_time_ms\": 14748.756}", "{\"n\": 7231, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3899.51, \"learn_time_ms\": 14750.823}", "{\"n\": 7232, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3889.36, \"learn_time_ms\": 14748.42}", "{\"n\": 7233, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3889.36, \"learn_time_ms\": 14724.556}", "{\"n\": 7234, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3882.78, \"learn_time_ms\": 14718.025}", "{\"n\": 7235, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3890.25, \"learn_time_ms\": 14726.152}", "{\"n\": 7236, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3898.98, \"learn_time_ms\": 14719.774}", "{\"n\": 7237, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3895.3, \"learn_time_ms\": 14721.299}", "{\"n\": 7238, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3883.41, \"learn_time_ms\": 14711.591}", "{\"n\": 7239, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3883.41, \"learn_time_ms\": 14713.624}", "{\"n\": 7240, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3883.41, \"learn_time_ms\": 14716.971}", "{\"n\": 7241, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3885.09, \"learn_time_ms\": 14707.792}", "{\"n\": 7242, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3877.04, \"learn_time_ms\": 14717.006}", "{\"n\": 7243, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3877.04, \"learn_time_ms\": 14723.649}", "{\"n\": 7244, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3865.3, \"learn_time_ms\": 14710.151}", "{\"n\": 7245, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3870.58, \"learn_time_ms\": 14709.696}", "{\"n\": 7246, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3854.05, \"learn_time_ms\": 14724.425}", "{\"n\": 7247, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3849.13, \"learn_time_ms\": 14721.191}", "{\"n\": 7248, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3856.63, \"learn_time_ms\": 14728.037}", "{\"n\": 7249, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3852.26, \"learn_time_ms\": 14721.204}", "{\"n\": 7250, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3852.26, \"learn_time_ms\": 14717.593}", "{\"n\": 7251, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3848.29, \"learn_time_ms\": 14727.77}", "{\"n\": 7252, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3848.29, \"learn_time_ms\": 14716.486}", "{\"n\": 7253, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3841.81, \"learn_time_ms\": 14726.433}", "{\"n\": 7254, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3833.83, \"learn_time_ms\": 14755.253}", "{\"n\": 7255, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3833.83, \"learn_time_ms\": 14756.754}", "{\"n\": 7256, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3797.13, \"learn_time_ms\": 14742.009}", "{\"n\": 7257, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3797.13, \"learn_time_ms\": 14756.144}", "{\"n\": 7258, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3797.13, \"learn_time_ms\": 14767.205}", "{\"n\": 7259, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3793.09, \"learn_time_ms\": 14748.09}", "{\"n\": 7260, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3793.09, \"learn_time_ms\": 14730.156}", "{\"n\": 7261, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3773.46, \"learn_time_ms\": 14719.433}", "{\"n\": 7262, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.41, \"learn_time_ms\": 14720.431}", "{\"n\": 7263, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3772.98, \"learn_time_ms\": 14716.586}", "{\"n\": 7264, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3772.98, \"learn_time_ms\": 14710.618}", "{\"n\": 7265, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3774.36, \"learn_time_ms\": 14702.358}", "{\"n\": 7266, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.89, \"learn_time_ms\": 14711.681}", "{\"n\": 7267, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.89, \"learn_time_ms\": 14686.952}", "{\"n\": 7268, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3766.62, \"learn_time_ms\": 14670.068}", "{\"n\": 7269, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3760.81, \"learn_time_ms\": 14699.592}", "{\"n\": 7270, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3760.81, \"learn_time_ms\": 14713.293}", "{\"n\": 7271, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3760.81, \"learn_time_ms\": 14720.855}", "{\"n\": 7272, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3760.81, \"learn_time_ms\": 14727.431}", "{\"n\": 7273, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3757.82, \"learn_time_ms\": 14725.442}", "{\"n\": 7274, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3749.85, \"learn_time_ms\": 14722.738}", "{\"n\": 7275, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3758.84, \"learn_time_ms\": 14727.838}", "{\"n\": 7276, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3764.79, \"learn_time_ms\": 14719.288}", "{\"n\": 7277, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3764.79, \"learn_time_ms\": 14721.514}", "{\"n\": 7278, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3734.43, \"learn_time_ms\": 14728.772}", "{\"n\": 7279, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3745.02, \"learn_time_ms\": 14710.459}", "{\"n\": 7280, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3737.33, \"learn_time_ms\": 14709.6}", "{\"n\": 7281, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3735.46, \"learn_time_ms\": 14717.506}", "{\"n\": 7282, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3741.18, \"learn_time_ms\": 14720.373}", "{\"n\": 7283, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3743.67, \"learn_time_ms\": 14712.393}", "{\"n\": 7284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3743.67, \"learn_time_ms\": 14709.067}", "{\"n\": 7285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3734.1, \"learn_time_ms\": 14712.978}", "{\"n\": 7286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3736.83, \"learn_time_ms\": 14713.568}", "{\"n\": 7287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3736.35, \"learn_time_ms\": 14719.395}", "{\"n\": 7288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3736.84, \"learn_time_ms\": 14722.521}", "{\"n\": 7289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3737.7, \"learn_time_ms\": 14730.869}", "{\"n\": 7290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3741.52, \"learn_time_ms\": 14725.626}", "{\"n\": 7291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3741.52, \"learn_time_ms\": 14726.048}", "{\"n\": 7292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3732.97, \"learn_time_ms\": 14730.612}", "{\"n\": 7293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.7, \"learn_time_ms\": 14748.687}", "{\"n\": 7294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3727.43, \"learn_time_ms\": 14759.762}", "{\"n\": 7295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3720.9, \"learn_time_ms\": 14755.186}", "{\"n\": 7296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3723.09, \"learn_time_ms\": 14756.206}", "{\"n\": 7297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3723.52, \"learn_time_ms\": 14755.038}", "{\"n\": 7298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3718.5, \"learn_time_ms\": 14732.926}", "{\"n\": 7299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3732.91, \"learn_time_ms\": 14728.461}", "{\"n\": 7300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3737.97, \"learn_time_ms\": 14741.275}", "{\"n\": 7301, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3737.97, \"learn_time_ms\": 14735.561}", "{\"n\": 7302, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3737.97, \"learn_time_ms\": 14731.002}", "{\"n\": 7303, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3750.96, \"learn_time_ms\": 14731.552}", "{\"n\": 7304, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3750.96, \"learn_time_ms\": 14721.373}", "{\"n\": 7305, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3749.18, \"learn_time_ms\": 14711.072}", "{\"n\": 7306, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.72, \"learn_time_ms\": 14720.189}", "{\"n\": 7307, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.18, \"learn_time_ms\": 14731.433}", "{\"n\": 7308, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.18, \"learn_time_ms\": 14735.745}", "{\"n\": 7309, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.18, \"learn_time_ms\": 14737.022}", "{\"n\": 7310, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.03, \"learn_time_ms\": 14731.122}", "{\"n\": 7311, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.03, \"learn_time_ms\": 14737.902}", "{\"n\": 7312, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3754.94, \"learn_time_ms\": 14743.133}", "{\"n\": 7313, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3750.7, \"learn_time_ms\": 14736.059}", "{\"n\": 7314, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3747.87, \"learn_time_ms\": 14744.287}", "{\"n\": 7315, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3754.46, \"learn_time_ms\": 14752.122}", "{\"n\": 7316, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3754.46, \"learn_time_ms\": 14747.177}", "{\"n\": 7317, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3763.92, \"learn_time_ms\": 14755.337}", "{\"n\": 7318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3771.63, \"learn_time_ms\": 14771.788}", "{\"n\": 7319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3771.63, \"learn_time_ms\": 14775.636}", "{\"n\": 7320, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3785.42, \"learn_time_ms\": 14785.845}", "{\"n\": 7321, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3785.42, \"learn_time_ms\": 14786.855}", "{\"n\": 7322, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3781.59, \"learn_time_ms\": 14783.74}", "{\"n\": 7323, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3774.14, \"learn_time_ms\": 14786.443}", "{\"n\": 7324, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3779.11, \"learn_time_ms\": 14778.067}", "{\"n\": 7325, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3779.11, \"learn_time_ms\": 14773.875}", "{\"n\": 7326, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3784.9, \"learn_time_ms\": 14775.592}", "{\"n\": 7327, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3784.27, \"learn_time_ms\": 14778.657}", "{\"n\": 7328, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3779.03, \"learn_time_ms\": 14764.149}", "{\"n\": 7329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3769.27, \"learn_time_ms\": 14770.065}", "{\"n\": 7330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3769.27, \"learn_time_ms\": 14762.115}", "{\"n\": 7331, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3773.85, \"learn_time_ms\": 14752.977}", "{\"n\": 7332, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3770.72, \"learn_time_ms\": 14746.848}", "{\"n\": 7333, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3770.72, \"learn_time_ms\": 14739.855}", "{\"n\": 7334, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3768.6, \"learn_time_ms\": 14743.494}", "{\"n\": 7335, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3768.6, \"learn_time_ms\": 14747.559}", "{\"n\": 7336, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3786.34, \"learn_time_ms\": 14746.346}", "{\"n\": 7337, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3788.46, \"learn_time_ms\": 14730.15}", "{\"n\": 7338, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3792.93, \"learn_time_ms\": 14742.024}", "{\"n\": 7339, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3802.25, \"learn_time_ms\": 14723.802}", "{\"n\": 7340, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3802.25, \"learn_time_ms\": 14727.078}", "{\"n\": 7341, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3792.71, \"learn_time_ms\": 14728.774}", "{\"n\": 7342, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3806.4, \"learn_time_ms\": 14730.957}", "{\"n\": 7343, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3805.74, \"learn_time_ms\": 14735.445}", "{\"n\": 7344, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3805.74, \"learn_time_ms\": 14736.705}", "{\"n\": 7345, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3783.88, \"learn_time_ms\": 14741.365}", "{\"n\": 7346, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3794.57, \"learn_time_ms\": 14730.778}", "{\"n\": 7347, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3794.57, \"learn_time_ms\": 14721.936}", "{\"n\": 7348, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.51, \"learn_time_ms\": 14714.842}", "{\"n\": 7349, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3806.62, \"learn_time_ms\": 14731.1}", "{\"n\": 7350, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3803.05, \"learn_time_ms\": 14721.912}", "{\"n\": 7351, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3819.89, \"learn_time_ms\": 14727.838}", "{\"n\": 7352, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3819.89, \"learn_time_ms\": 14736.954}", "{\"n\": 7353, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3814.43, \"learn_time_ms\": 14735.993}", "{\"n\": 7354, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3815.14, \"learn_time_ms\": 14736.872}", "{\"n\": 7355, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3827.35, \"learn_time_ms\": 14738.996}", "{\"n\": 7356, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3826.79, \"learn_time_ms\": 14757.181}", "{\"n\": 7357, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3828.33, \"learn_time_ms\": 14767.513}", "{\"n\": 7358, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3831.93, \"learn_time_ms\": 14786.295}", "{\"n\": 7359, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3829.75, \"learn_time_ms\": 14777.762}", "{\"n\": 7360, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3815.96, \"learn_time_ms\": 14782.225}", "{\"n\": 7361, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3815.96, \"learn_time_ms\": 14777.862}", "{\"n\": 7362, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3828.2, \"learn_time_ms\": 14774.607}", "{\"n\": 7363, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3828.2, \"learn_time_ms\": 14779.678}", "{\"n\": 7364, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3841.57, \"learn_time_ms\": 14773.884}", "{\"n\": 7365, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3850.02, \"learn_time_ms\": 14762.566}", "{\"n\": 7366, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3827.79, \"learn_time_ms\": 14759.914}", "{\"n\": 7367, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3833.86, \"learn_time_ms\": 14758.062}", "{\"n\": 7368, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3833.86, \"learn_time_ms\": 14745.598}", "{\"n\": 7369, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3825.18, \"learn_time_ms\": 14754.044}", "{\"n\": 7370, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3825.18, \"learn_time_ms\": 14755.339}", "{\"n\": 7371, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3825.18, \"learn_time_ms\": 14747.735}", "{\"n\": 7372, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3829.64, \"learn_time_ms\": 14733.487}", "{\"n\": 7373, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3831.88, \"learn_time_ms\": 14726.095}", "{\"n\": 7374, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3831.88, \"learn_time_ms\": 14730.332}", "{\"n\": 7375, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3830.17, \"learn_time_ms\": 14752.537}", "{\"n\": 7376, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3827.15, \"learn_time_ms\": 14747.617}", "{\"n\": 7377, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3826.14, \"learn_time_ms\": 14758.502}", "{\"n\": 7378, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3811.89, \"learn_time_ms\": 14770.152}", "{\"n\": 7379, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3804.61, \"learn_time_ms\": 14769.865}", "{\"n\": 7380, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3804.3, \"learn_time_ms\": 14777.377}", "{\"n\": 7381, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3770.36, \"learn_time_ms\": 14786.92}", "{\"n\": 7382, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3768.05, \"learn_time_ms\": 14808.037}", "{\"n\": 7383, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3757.71, \"learn_time_ms\": 14821.523}", "{\"n\": 7384, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3769.82, \"learn_time_ms\": 14819.621}", "{\"n\": 7385, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3774.53, \"learn_time_ms\": 14810.548}", "{\"n\": 7386, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3758.62, \"learn_time_ms\": 14814.842}", "{\"n\": 7387, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3761.46, \"learn_time_ms\": 14807.56}", "{\"n\": 7388, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3756.94, \"learn_time_ms\": 14792.127}", "{\"n\": 7389, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3747.73, \"learn_time_ms\": 14780.419}", "{\"n\": 7390, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3747.73, \"learn_time_ms\": 14764.844}", "{\"n\": 7391, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3740.13, \"learn_time_ms\": 14766.691}", "{\"n\": 7392, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.95, \"learn_time_ms\": 14756.336}", "{\"n\": 7393, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3731.68, \"learn_time_ms\": 14751.841}", "{\"n\": 7394, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3720.62, \"learn_time_ms\": 14747.861}", "{\"n\": 7395, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3703.24, \"learn_time_ms\": 14744.332}", "{\"n\": 7396, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3699.62, \"learn_time_ms\": 14729.032}", "{\"n\": 7397, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3696.28, \"learn_time_ms\": 14728.758}", "{\"n\": 7398, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3709.1, \"learn_time_ms\": 14735.563}", "{\"n\": 7399, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3703.41, \"learn_time_ms\": 14747.134}", "{\"n\": 7400, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3703.41, \"learn_time_ms\": 14745.845}", "{\"n\": 7401, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3689.29, \"learn_time_ms\": 14734.615}", "{\"n\": 7402, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3674.77, \"learn_time_ms\": 14738.165}", "{\"n\": 7403, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3673.17, \"learn_time_ms\": 14742.915}", "{\"n\": 7404, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3657.51, \"learn_time_ms\": 14738.185}", "{\"n\": 7405, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3675.36, \"learn_time_ms\": 14740.501}", "{\"n\": 7406, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3657.48, \"learn_time_ms\": 14747.859}", "{\"n\": 7407, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3657.48, \"learn_time_ms\": 14748.79}", "{\"n\": 7408, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3656.76, \"learn_time_ms\": 14747.326}", "{\"n\": 7409, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3670.36, \"learn_time_ms\": 14742.64}", "{\"n\": 7410, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3670.36, \"learn_time_ms\": 14744.277}", "{\"n\": 7411, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3662.96, \"learn_time_ms\": 14745.22}", "{\"n\": 7412, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3648.9, \"learn_time_ms\": 14742.207}", "{\"n\": 7413, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3648.9, \"learn_time_ms\": 14733.119}", "{\"n\": 7414, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3651.15, \"learn_time_ms\": 14739.901}", "{\"n\": 7415, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3654.85, \"learn_time_ms\": 14725.845}", "{\"n\": 7416, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3654.85, \"learn_time_ms\": 14733.495}", "{\"n\": 7417, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3660.92, \"learn_time_ms\": 14740.996}", "{\"n\": 7418, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3655.89, \"learn_time_ms\": 14746.353}", "{\"n\": 7419, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3655.89, \"learn_time_ms\": 14747.695}", "{\"n\": 7420, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3655.89, \"learn_time_ms\": 14749.637}", "{\"n\": 7421, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3658.86, \"learn_time_ms\": 14755.05}", "{\"n\": 7422, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3663.53, \"learn_time_ms\": 14754.392}", "{\"n\": 7423, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3663.53, \"learn_time_ms\": 14749.568}", "{\"n\": 7424, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3662.72, \"learn_time_ms\": 14750.774}", "{\"n\": 7425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3658.1, \"learn_time_ms\": 14760.423}", "{\"n\": 7426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3658.1, \"learn_time_ms\": 14757.796}", "{\"n\": 7427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3663.44, \"learn_time_ms\": 14740.328}", "{\"n\": 7428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3662.16, \"learn_time_ms\": 14735.964}", "{\"n\": 7429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3662.16, \"learn_time_ms\": 14733.98}", "{\"n\": 7430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3652.66, \"learn_time_ms\": 14736.261}", "{\"n\": 7431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3648.86, \"learn_time_ms\": 14734.898}", "{\"n\": 7432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3658.39, \"learn_time_ms\": 14736.351}", "{\"n\": 7433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3658.39, \"learn_time_ms\": 14746.812}", "{\"n\": 7434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3657.47, \"learn_time_ms\": 14748.879}", "{\"n\": 7435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3658.69, \"learn_time_ms\": 14750.925}", "{\"n\": 7436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3672.4, \"learn_time_ms\": 14759.65}", "{\"n\": 7437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3689.89, \"learn_time_ms\": 14772.758}", "{\"n\": 7438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3688.03, \"learn_time_ms\": 14775.344}", "{\"n\": 7439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3672.13, \"learn_time_ms\": 14771.845}", "{\"n\": 7440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3675.12, \"learn_time_ms\": 14768.076}", "{\"n\": 7441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3683.97, \"learn_time_ms\": 14760.939}", "{\"n\": 7442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3678.99, \"learn_time_ms\": 14751.98}", "{\"n\": 7443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3674.66, \"learn_time_ms\": 14739.231}", "{\"n\": 7444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3675.91, \"learn_time_ms\": 14719.993}", "{\"n\": 7445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3675.89, \"learn_time_ms\": 14715.617}", "{\"n\": 7446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3647.84, \"learn_time_ms\": 14707.209}", "{\"n\": 7447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3633.82, \"learn_time_ms\": 14694.949}", "{\"n\": 7448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3633.82, \"learn_time_ms\": 14686.764}", "{\"n\": 7449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3640.06, \"learn_time_ms\": 14682.39}", "{\"n\": 7450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3639.06, \"learn_time_ms\": 14686.118}", "{\"n\": 7451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3642.47, \"learn_time_ms\": 14705.463}", "{\"n\": 7452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3631.81, \"learn_time_ms\": 14712.561}", "{\"n\": 7453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3629.35, \"learn_time_ms\": 14713.466}", "{\"n\": 7454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3640.35, \"learn_time_ms\": 14721.593}", "{\"n\": 7455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3627.12, \"learn_time_ms\": 14724.968}", "{\"n\": 7456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3631.44, \"learn_time_ms\": 14719.031}", "{\"n\": 7457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3637.37, \"learn_time_ms\": 14729.697}", "{\"n\": 7458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.31, \"learn_time_ms\": 14739.057}", "{\"n\": 7459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3657.05, \"learn_time_ms\": 14750.289}", "{\"n\": 7460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3656.14, \"learn_time_ms\": 14759.756}", "{\"n\": 7461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3648.81, \"learn_time_ms\": 14746.485}", "{\"n\": 7462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3661.75, \"learn_time_ms\": 14752.631}", "{\"n\": 7463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3661.75, \"learn_time_ms\": 14759.19}", "{\"n\": 7464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3657.08, \"learn_time_ms\": 14770.453}", "{\"n\": 7465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3678.68, \"learn_time_ms\": 14772.461}", "{\"n\": 7466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3664.98, \"learn_time_ms\": 14779.482}", "{\"n\": 7467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3664.98, \"learn_time_ms\": 14762.78}", "{\"n\": 7468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3664.98, \"learn_time_ms\": 14760.917}", "{\"n\": 7469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3662.68, \"learn_time_ms\": 14764.15}", "{\"n\": 7470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3661.58, \"learn_time_ms\": 14766.165}", "{\"n\": 7471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3667.37, \"learn_time_ms\": 14756.842}", "{\"n\": 7472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3679.15, \"learn_time_ms\": 14741.569}", "{\"n\": 7473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3687.76, \"learn_time_ms\": 14742.985}", "{\"n\": 7474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3687.76, \"learn_time_ms\": 14752.207}", "{\"n\": 7475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3684.52, \"learn_time_ms\": 14744.076}", "{\"n\": 7476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3687.67, \"learn_time_ms\": 14751.201}", "{\"n\": 7477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3684.42, \"learn_time_ms\": 14758.317}", "{\"n\": 7478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3700.45, \"learn_time_ms\": 14764.258}", "{\"n\": 7479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3712.81, \"learn_time_ms\": 14753.794}", "{\"n\": 7480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3712.81, \"learn_time_ms\": 14741.053}", "{\"n\": 7481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3712.81, \"learn_time_ms\": 14748.716}", "{\"n\": 7482, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.98, \"learn_time_ms\": 14756.889}", "{\"n\": 7483, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3729.9, \"learn_time_ms\": 14751.613}", "{\"n\": 7484, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3729.9, \"learn_time_ms\": 14737.07}", "{\"n\": 7485, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3752.32, \"learn_time_ms\": 14742.849}", "{\"n\": 7486, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3752.56, \"learn_time_ms\": 14730.32}", "{\"n\": 7487, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3752.56, \"learn_time_ms\": 14734.373}", "{\"n\": 7488, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3752.62, \"learn_time_ms\": 14723.462}", "{\"n\": 7489, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3756.05, \"learn_time_ms\": 14728.79}", "{\"n\": 7490, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3756.05, \"learn_time_ms\": 14730.751}", "{\"n\": 7491, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3767.54, \"learn_time_ms\": 14725.366}", "{\"n\": 7492, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.01, \"learn_time_ms\": 14721.679}", "{\"n\": 7493, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.01, \"learn_time_ms\": 14727.017}", "{\"n\": 7494, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3772.87, \"learn_time_ms\": 14728.756}", "{\"n\": 7495, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3766.94, \"learn_time_ms\": 14720.395}", "{\"n\": 7496, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.03, \"learn_time_ms\": 14730.633}", "{\"n\": 7497, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.03, \"learn_time_ms\": 14735.381}", "{\"n\": 7498, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3766.44, \"learn_time_ms\": 14746.576}", "{\"n\": 7499, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3766.44, \"learn_time_ms\": 14753.427}", "{\"n\": 7500, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3763.32, \"learn_time_ms\": 14757.789}", "{\"n\": 7501, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.94, \"learn_time_ms\": 14762.871}", "{\"n\": 7502, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.94, \"learn_time_ms\": 14775.917}", "{\"n\": 7503, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3785.28, \"learn_time_ms\": 14768.392}", "{\"n\": 7504, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3782.63, \"learn_time_ms\": 14772.133}", "{\"n\": 7505, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.24, \"learn_time_ms\": 14772.346}", "{\"n\": 7506, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.24, \"learn_time_ms\": 14768.831}", "{\"n\": 7507, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3782.88, \"learn_time_ms\": 14775.476}", "{\"n\": 7508, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3782.88, \"learn_time_ms\": 14770.155}", "{\"n\": 7509, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.63, \"learn_time_ms\": 14762.616}", "{\"n\": 7510, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.77, \"learn_time_ms\": 14755.505}", "{\"n\": 7511, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3782.7, \"learn_time_ms\": 14763.491}", "{\"n\": 7512, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3791.06, \"learn_time_ms\": 14748.734}", "{\"n\": 7513, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3795.14, \"learn_time_ms\": 14742.114}", "{\"n\": 7514, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.4, \"learn_time_ms\": 14736.961}", "{\"n\": 7515, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.93, \"learn_time_ms\": 14738.862}", "{\"n\": 7516, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.51, \"learn_time_ms\": 14740.2}", "{\"n\": 7517, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.51, \"learn_time_ms\": 14743.586}", "{\"n\": 7518, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.51, \"learn_time_ms\": 14743.324}", "{\"n\": 7519, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.1, \"learn_time_ms\": 14752.167}", "{\"n\": 7520, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.95, \"learn_time_ms\": 14765.036}", "{\"n\": 7521, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.95, \"learn_time_ms\": 14756.262}", "{\"n\": 7522, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.95, \"learn_time_ms\": 14760.351}", "{\"n\": 7523, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3753.53, \"learn_time_ms\": 14778.301}", "{\"n\": 7524, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3753.53, \"learn_time_ms\": 14778.894}", "{\"n\": 7525, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.34, \"learn_time_ms\": 14789.821}", "{\"n\": 7526, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.34, \"learn_time_ms\": 14790.668}", "{\"n\": 7527, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.36, \"learn_time_ms\": 14756.021}", "{\"n\": 7528, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3779.95, \"learn_time_ms\": 14755.109}", "{\"n\": 7529, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3779.95, \"learn_time_ms\": 14760.271}", "{\"n\": 7530, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3780.75, \"learn_time_ms\": 14762.154}", "{\"n\": 7531, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.84, \"learn_time_ms\": 14770.341}", "{\"n\": 7532, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.84, \"learn_time_ms\": 14783.197}", "{\"n\": 7533, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.84, \"learn_time_ms\": 14777.451}", "{\"n\": 7534, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3812.89, \"learn_time_ms\": 14780.518}", "{\"n\": 7535, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3817.65, \"learn_time_ms\": 14766.427}", "{\"n\": 7536, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3819.77, \"learn_time_ms\": 14770.207}", "{\"n\": 7537, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3819.77, \"learn_time_ms\": 14787.506}", "{\"n\": 7538, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3810.9, \"learn_time_ms\": 14782.309}", "{\"n\": 7539, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3818.13, \"learn_time_ms\": 14777.655}", "{\"n\": 7540, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3823.56, \"learn_time_ms\": 14774.984}", "{\"n\": 7541, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3821.75, \"learn_time_ms\": 14770.974}", "{\"n\": 7542, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3832.33, \"learn_time_ms\": 14759.728}", "{\"n\": 7543, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3832.33, \"learn_time_ms\": 14759.356}", "{\"n\": 7544, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3818.22, \"learn_time_ms\": 14750.884}", "{\"n\": 7545, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3825.32, \"learn_time_ms\": 14753.654}", "{\"n\": 7546, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3819.13, \"learn_time_ms\": 14725.73}", "{\"n\": 7547, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3819.06, \"learn_time_ms\": 14737.519}", "{\"n\": 7548, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3824.33, \"learn_time_ms\": 14736.408}", "{\"n\": 7549, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3818.03, \"learn_time_ms\": 14731.852}", "{\"n\": 7550, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3808.04, \"learn_time_ms\": 14726.486}", "{\"n\": 7551, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3803.39, \"learn_time_ms\": 14717.982}", "{\"n\": 7552, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3803.39, \"learn_time_ms\": 14727.006}", "{\"n\": 7553, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3809.2, \"learn_time_ms\": 14726.172}", "{\"n\": 7554, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3809.04, \"learn_time_ms\": 14724.605}", "{\"n\": 7555, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3814.64, \"learn_time_ms\": 14732.619}", "{\"n\": 7556, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3808.73, \"learn_time_ms\": 14744.73}", "{\"n\": 7557, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3804.34, \"learn_time_ms\": 14732.487}", "{\"n\": 7558, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3810.27, \"learn_time_ms\": 14735.212}", "{\"n\": 7559, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3815.97, \"learn_time_ms\": 14720.389}", "{\"n\": 7560, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3815.97, \"learn_time_ms\": 14718.42}", "{\"n\": 7561, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3820.04, \"learn_time_ms\": 14730.879}", "{\"n\": 7562, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3818.24, \"learn_time_ms\": 14711.404}", "{\"n\": 7563, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3831.88, \"learn_time_ms\": 14708.378}", "{\"n\": 7564, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3831.88, \"learn_time_ms\": 14725.346}", "{\"n\": 7565, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3823.85, \"learn_time_ms\": 14727.519}", "{\"n\": 7566, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3798.44, \"learn_time_ms\": 14735.921}", "{\"n\": 7567, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3803.12, \"learn_time_ms\": 14748.543}", "{\"n\": 7568, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.51, \"learn_time_ms\": 14758.879}", "{\"n\": 7569, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3808.35, \"learn_time_ms\": 14765.222}", "{\"n\": 7570, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3814.7, \"learn_time_ms\": 14758.948}", "{\"n\": 7571, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3814.88, \"learn_time_ms\": 14764.555}", "{\"n\": 7572, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3807.11, \"learn_time_ms\": 14776.931}", "{\"n\": 7573, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3802.78, \"learn_time_ms\": 14780.53}", "{\"n\": 7574, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3802.78, \"learn_time_ms\": 14769.788}", "{\"n\": 7575, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3804.72, \"learn_time_ms\": 14771.237}", "{\"n\": 7576, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.17, \"learn_time_ms\": 14768.553}", "{\"n\": 7577, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.17, \"learn_time_ms\": 14755.992}", "{\"n\": 7578, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.17, \"learn_time_ms\": 14748.728}", "{\"n\": 7579, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3815.1, \"learn_time_ms\": 14752.522}", "{\"n\": 7580, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3815.1, \"learn_time_ms\": 14762.985}", "{\"n\": 7581, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3817.36, \"learn_time_ms\": 14744.892}", "{\"n\": 7582, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3800.27, \"learn_time_ms\": 14749.888}", "{\"n\": 7583, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3806.28, \"learn_time_ms\": 14755.988}", "{\"n\": 7584, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3806.28, \"learn_time_ms\": 14765.498}", "{\"n\": 7585, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3809.32, \"learn_time_ms\": 14756.675}", "{\"n\": 7586, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3806.59, \"learn_time_ms\": 14758.95}", "{\"n\": 7587, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3809.45, \"learn_time_ms\": 14774.926}", "{\"n\": 7588, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3808.32, \"learn_time_ms\": 14775.328}", "{\"n\": 7589, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3801.36, \"learn_time_ms\": 14781.089}", "{\"n\": 7590, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3801.36, \"learn_time_ms\": 14780.773}", "{\"n\": 7591, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3801.36, \"learn_time_ms\": 14783.683}", "{\"n\": 7592, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3780.61, \"learn_time_ms\": 14779.334}", "{\"n\": 7593, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3784.58, \"learn_time_ms\": 14772.23}", "{\"n\": 7594, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3784.7, \"learn_time_ms\": 14759.582}", "{\"n\": 7595, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.48, \"learn_time_ms\": 14768.909}", "{\"n\": 7596, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.48, \"learn_time_ms\": 14759.422}", "{\"n\": 7597, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3760.22, \"learn_time_ms\": 14749.732}", "{\"n\": 7598, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.11, \"learn_time_ms\": 14749.201}", "{\"n\": 7599, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.64, \"learn_time_ms\": 14750.381}", "{\"n\": 7600, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.64, \"learn_time_ms\": 14745.338}", "{\"n\": 7601, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3803.03, \"learn_time_ms\": 14746.597}", "{\"n\": 7602, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3803.03, \"learn_time_ms\": 14745.507}", "{\"n\": 7603, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3803.03, \"learn_time_ms\": 14741.209}", "{\"n\": 7604, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3792.37, \"learn_time_ms\": 14732.285}", "{\"n\": 7605, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3796.98, \"learn_time_ms\": 14729.765}", "{\"n\": 7606, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.09, \"learn_time_ms\": 14740.625}", "{\"n\": 7607, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.09, \"learn_time_ms\": 14735.881}", "{\"n\": 7608, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3772.98, \"learn_time_ms\": 14733.096}", "{\"n\": 7609, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3772.98, \"learn_time_ms\": 14715.681}", "{\"n\": 7610, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3776.68, \"learn_time_ms\": 14717.451}", "{\"n\": 7611, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3779.39, \"learn_time_ms\": 14722.75}", "{\"n\": 7612, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3773.3, \"learn_time_ms\": 14718.257}", "{\"n\": 7613, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3773.3, \"learn_time_ms\": 14722.893}", "{\"n\": 7614, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3775.46, \"learn_time_ms\": 14735.164}", "{\"n\": 7615, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3775.46, \"learn_time_ms\": 14723.778}", "{\"n\": 7616, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3760.94, \"learn_time_ms\": 14713.256}", "{\"n\": 7617, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.27, \"learn_time_ms\": 14710.272}", "{\"n\": 7618, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.91, \"learn_time_ms\": 14712.903}", "{\"n\": 7619, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.91, \"learn_time_ms\": 14725.011}", "{\"n\": 7620, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.91, \"learn_time_ms\": 14717.242}", "{\"n\": 7621, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.44, \"learn_time_ms\": 14711.286}", "{\"n\": 7622, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3743.61, \"learn_time_ms\": 14715.687}", "{\"n\": 7623, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3746.2, \"learn_time_ms\": 14711.757}", "{\"n\": 7624, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3730.59, \"learn_time_ms\": 14714.156}", "{\"n\": 7625, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.01, \"learn_time_ms\": 14720.014}", "{\"n\": 7626, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.01, \"learn_time_ms\": 14718.728}", "{\"n\": 7627, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.01, \"learn_time_ms\": 14713.877}", "{\"n\": 7628, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3748.2, \"learn_time_ms\": 14715.006}", "{\"n\": 7629, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3733.33, \"learn_time_ms\": 14710.168}", "{\"n\": 7630, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3735.29, \"learn_time_ms\": 14711.645}", "{\"n\": 7631, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3737.22, \"learn_time_ms\": 14717.385}", "{\"n\": 7632, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3737.22, \"learn_time_ms\": 14712.418}", "{\"n\": 7633, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3737.91, \"learn_time_ms\": 14717.194}", "{\"n\": 7634, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3737.91, \"learn_time_ms\": 14720.255}", "{\"n\": 7635, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3742.58, \"learn_time_ms\": 14726.754}", "{\"n\": 7636, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3742.21, \"learn_time_ms\": 14737.865}", "{\"n\": 7637, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3734.42, \"learn_time_ms\": 14739.417}", "{\"n\": 7638, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.91, \"learn_time_ms\": 14741.609}", "{\"n\": 7639, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3727.4, \"learn_time_ms\": 14745.875}", "{\"n\": 7640, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3727.4, \"learn_time_ms\": 14745.607}", "{\"n\": 7641, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3706.98, \"learn_time_ms\": 14741.658}", "{\"n\": 7642, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3712.91, \"learn_time_ms\": 14745.025}", "{\"n\": 7643, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3742.52, \"learn_time_ms\": 14745.775}", "{\"n\": 7644, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3746.0, \"learn_time_ms\": 14740.095}", "{\"n\": 7645, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.8, \"learn_time_ms\": 14728.528}", "{\"n\": 7646, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.8, \"learn_time_ms\": 14714.928}", "{\"n\": 7647, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3721.14, \"learn_time_ms\": 14722.87}", "{\"n\": 7648, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.14, \"learn_time_ms\": 14714.281}", "{\"n\": 7649, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.14, \"learn_time_ms\": 14714.806}", "{\"n\": 7650, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3726.08, \"learn_time_ms\": 14720.897}", "{\"n\": 7651, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.82, \"learn_time_ms\": 14719.168}", "{\"n\": 7652, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.82, \"learn_time_ms\": 14719.112}", "{\"n\": 7653, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3742.27, \"learn_time_ms\": 14717.491}", "{\"n\": 7654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.88, \"learn_time_ms\": 14721.187}", "{\"n\": 7655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.88, \"learn_time_ms\": 14732.207}", "{\"n\": 7656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3713.83, \"learn_time_ms\": 14735.064}", "{\"n\": 7657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3713.83, \"learn_time_ms\": 14731.064}", "{\"n\": 7658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.5, \"learn_time_ms\": 14750.93}", "{\"n\": 7659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.5, \"learn_time_ms\": 14752.997}", "{\"n\": 7660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3718.83, \"learn_time_ms\": 14754.003}", "{\"n\": 7661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3710.47, \"learn_time_ms\": 14751.935}", "{\"n\": 7662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.01, \"learn_time_ms\": 14747.896}", "{\"n\": 7663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3716.56, \"learn_time_ms\": 14738.75}", "{\"n\": 7664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3716.56, \"learn_time_ms\": 14736.261}", "{\"n\": 7665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3716.56, \"learn_time_ms\": 14739.383}", "{\"n\": 7666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3717.5, \"learn_time_ms\": 14742.566}", "{\"n\": 7667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3717.5, \"learn_time_ms\": 14742.273}", "{\"n\": 7668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3710.12, \"learn_time_ms\": 14722.988}", "{\"n\": 7669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3726.54, \"learn_time_ms\": 14720.241}", "{\"n\": 7670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3726.54, \"learn_time_ms\": 14713.883}", "{\"n\": 7671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3726.54, \"learn_time_ms\": 14724.639}", "{\"n\": 7672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.72, \"learn_time_ms\": 14734.69}", "{\"n\": 7673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3727.66, \"learn_time_ms\": 14740.334}", "{\"n\": 7674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3745.32, \"learn_time_ms\": 14734.873}", "{\"n\": 7675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.4, \"learn_time_ms\": 14725.16}", "{\"n\": 7676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3727.31, \"learn_time_ms\": 14726.937}", "{\"n\": 7677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3727.31, \"learn_time_ms\": 14728.441}", "{\"n\": 7678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3727.31, \"learn_time_ms\": 14721.1}", "{\"n\": 7679, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.8, \"learn_time_ms\": 14707.195}", "{\"n\": 7680, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3707.0, \"learn_time_ms\": 14709.606}", "{\"n\": 7681, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3715.16, \"learn_time_ms\": 14699.208}", "{\"n\": 7682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.25, \"learn_time_ms\": 14691.188}", "{\"n\": 7683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.91, \"learn_time_ms\": 14683.228}", "{\"n\": 7684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3723.49, \"learn_time_ms\": 14694.699}", "{\"n\": 7685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3708.33, \"learn_time_ms\": 14699.942}", "{\"n\": 7686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3710.67, \"learn_time_ms\": 14691.034}", "{\"n\": 7687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3710.67, \"learn_time_ms\": 14684.382}", "{\"n\": 7688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3710.67, \"learn_time_ms\": 14696.013}", "{\"n\": 7689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3710.67, \"learn_time_ms\": 14695.977}", "{\"n\": 7690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3714.68, \"learn_time_ms\": 14688.997}", "{\"n\": 7691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3714.68, \"learn_time_ms\": 14706.995}", "{\"n\": 7692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3686.43, \"learn_time_ms\": 14706.297}", "{\"n\": 7693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3686.43, \"learn_time_ms\": 14710.588}", "{\"n\": 7694, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.23, \"learn_time_ms\": 14703.631}", "{\"n\": 7695, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.72, \"learn_time_ms\": 14687.92}", "{\"n\": 7696, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3703.64, \"learn_time_ms\": 14705.903}", "{\"n\": 7697, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3708.89, \"learn_time_ms\": 14722.236}", "{\"n\": 7698, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3714.54, \"learn_time_ms\": 14728.126}", "{\"n\": 7699, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.75, \"learn_time_ms\": 14743.869}", "{\"n\": 7700, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3729.1, \"learn_time_ms\": 14753.782}", "{\"n\": 7701, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3729.1, \"learn_time_ms\": 14745.778}", "{\"n\": 7702, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3726.92, \"learn_time_ms\": 14756.033}", "{\"n\": 7703, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3728.87, \"learn_time_ms\": 14763.579}", "{\"n\": 7704, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3728.98, \"learn_time_ms\": 14759.696}", "{\"n\": 7705, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3731.79, \"learn_time_ms\": 14769.499}", "{\"n\": 7706, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3752.62, \"learn_time_ms\": 14763.222}", "{\"n\": 7707, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3752.62, \"learn_time_ms\": 14755.192}", "{\"n\": 7708, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3754.31, \"learn_time_ms\": 14744.099}", "{\"n\": 7709, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3748.53, \"learn_time_ms\": 14747.08}", "{\"n\": 7710, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3749.24, \"learn_time_ms\": 14752.743}", "{\"n\": 7711, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3749.88, \"learn_time_ms\": 14747.664}", "{\"n\": 7712, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3749.88, \"learn_time_ms\": 14747.801}", "{\"n\": 7713, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3739.85, \"learn_time_ms\": 14736.791}", "{\"n\": 7714, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3727.07, \"learn_time_ms\": 14732.043}", "{\"n\": 7715, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3727.07, \"learn_time_ms\": 14724.62}", "{\"n\": 7716, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3730.8, \"learn_time_ms\": 14713.957}", "{\"n\": 7717, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3742.1, \"learn_time_ms\": 14721.506}", "{\"n\": 7718, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3745.27, \"learn_time_ms\": 14730.6}", "{\"n\": 7719, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3745.27, \"learn_time_ms\": 14725.706}", "{\"n\": 7720, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3758.8, \"learn_time_ms\": 14724.813}", "{\"n\": 7721, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3732.45, \"learn_time_ms\": 14729.904}", "{\"n\": 7722, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3732.45, \"learn_time_ms\": 14722.014}", "{\"n\": 7723, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3738.53, \"learn_time_ms\": 14732.232}", "{\"n\": 7724, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3745.17, \"learn_time_ms\": 14739.494}", "{\"n\": 7725, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3745.92, \"learn_time_ms\": 14757.035}", "{\"n\": 7726, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3763.38, \"learn_time_ms\": 14774.882}", "{\"n\": 7727, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3753.77, \"learn_time_ms\": 14764.675}", "{\"n\": 7728, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3755.33, \"learn_time_ms\": 14765.342}", "{\"n\": 7729, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3753.29, \"learn_time_ms\": 14760.158}", "{\"n\": 7730, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3753.29, \"learn_time_ms\": 14758.84}", "{\"n\": 7731, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3766.93, \"learn_time_ms\": 14755.276}", "{\"n\": 7732, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3746.25, \"learn_time_ms\": 14756.035}", "{\"n\": 7733, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3736.95, \"learn_time_ms\": 14759.744}", "{\"n\": 7734, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3743.2, \"learn_time_ms\": 14766.745}", "{\"n\": 7735, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3730.53, \"learn_time_ms\": 14759.862}", "{\"n\": 7736, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3730.53, \"learn_time_ms\": 14752.923}", "{\"n\": 7737, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3728.69, \"learn_time_ms\": 14759.571}", "{\"n\": 7738, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3721.59, \"learn_time_ms\": 14755.065}", "{\"n\": 7739, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3721.59, \"learn_time_ms\": 14762.533}", "{\"n\": 7740, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3704.35, \"learn_time_ms\": 14755.007}", "{\"n\": 7741, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3704.35, \"learn_time_ms\": 14746.254}", "{\"n\": 7742, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3704.18, \"learn_time_ms\": 14758.664}", "{\"n\": 7743, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3711.82, \"learn_time_ms\": 14752.572}", "{\"n\": 7744, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3716.24, \"learn_time_ms\": 14735.748}", "{\"n\": 7745, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3716.24, \"learn_time_ms\": 14735.266}", "{\"n\": 7746, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3716.24, \"learn_time_ms\": 14738.785}", "{\"n\": 7747, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3701.24, \"learn_time_ms\": 14733.743}", "{\"n\": 7748, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3708.45, \"learn_time_ms\": 14735.194}", "{\"n\": 7749, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3690.18, \"learn_time_ms\": 14736.317}", "{\"n\": 7750, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3684.99, \"learn_time_ms\": 14733.702}", "{\"n\": 7751, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3678.03, \"learn_time_ms\": 14741.066}", "{\"n\": 7752, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3678.03, \"learn_time_ms\": 14725.348}", "{\"n\": 7753, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3679.7, \"learn_time_ms\": 14733.587}", "{\"n\": 7754, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3685.17, \"learn_time_ms\": 14739.987}", "{\"n\": 7755, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3691.87, \"learn_time_ms\": 14742.79}", "{\"n\": 7756, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3691.87, \"learn_time_ms\": 14742.192}", "{\"n\": 7757, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3692.7, \"learn_time_ms\": 14750.079}", "{\"n\": 7758, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3685.63, \"learn_time_ms\": 14750.911}", "{\"n\": 7759, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3685.63, \"learn_time_ms\": 14742.436}", "{\"n\": 7760, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3683.78, \"learn_time_ms\": 14760.133}", "{\"n\": 7761, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3688.66, \"learn_time_ms\": 14759.073}", "{\"n\": 7762, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3697.85, \"learn_time_ms\": 14761.792}", "{\"n\": 7763, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3697.85, \"learn_time_ms\": 14760.533}", "{\"n\": 7764, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3691.79, \"learn_time_ms\": 14773.342}", "{\"n\": 7765, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3681.76, \"learn_time_ms\": 14773.277}", "{\"n\": 7766, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3681.76, \"learn_time_ms\": 14773.073}", "{\"n\": 7767, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3678.03, \"learn_time_ms\": 14772.174}", "{\"n\": 7768, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3692.18, \"learn_time_ms\": 14771.206}", "{\"n\": 7769, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3703.19, \"learn_time_ms\": 14776.807}", "{\"n\": 7770, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3694.05, \"learn_time_ms\": 14766.565}", "{\"n\": 7771, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3692.59, \"learn_time_ms\": 14764.37}", "{\"n\": 7772, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3683.62, \"learn_time_ms\": 14780.65}", "{\"n\": 7773, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3679.2, \"learn_time_ms\": 14788.414}", "{\"n\": 7774, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3673.92, \"learn_time_ms\": 14777.605}", "{\"n\": 7775, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3676.91, \"learn_time_ms\": 14767.057}", "{\"n\": 7776, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3667.33, \"learn_time_ms\": 14769.041}", "{\"n\": 7777, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3692.68, \"learn_time_ms\": 14766.487}", "{\"n\": 7778, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3682.66, \"learn_time_ms\": 14769.076}", "{\"n\": 7779, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3671.03, \"learn_time_ms\": 14776.301}", "{\"n\": 7780, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3654.25, \"learn_time_ms\": 14772.765}", "{\"n\": 7781, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3654.25, \"learn_time_ms\": 14779.148}", "{\"n\": 7782, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3653.22, \"learn_time_ms\": 14753.954}", "{\"n\": 7783, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3643.82, \"learn_time_ms\": 14737.004}", "{\"n\": 7784, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3637.73, \"learn_time_ms\": 14743.516}", "{\"n\": 7785, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3645.43, \"learn_time_ms\": 14748.329}", "{\"n\": 7786, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3645.13, \"learn_time_ms\": 14737.926}", "{\"n\": 7787, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3650.73, \"learn_time_ms\": 14731.68}", "{\"n\": 7788, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3657.58, \"learn_time_ms\": 14728.8}", "{\"n\": 7789, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3657.41, \"learn_time_ms\": 14718.858}", "{\"n\": 7790, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3662.2, \"learn_time_ms\": 14707.547}", "{\"n\": 7791, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3662.2, \"learn_time_ms\": 14700.107}", "{\"n\": 7792, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3662.76, \"learn_time_ms\": 14705.614}", "{\"n\": 7793, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3662.76, \"learn_time_ms\": 14711.222}", "{\"n\": 7794, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3647.76, \"learn_time_ms\": 14704.407}", "{\"n\": 7795, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3642.53, \"learn_time_ms\": 14696.559}", "{\"n\": 7796, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3642.53, \"learn_time_ms\": 14691.517}", "{\"n\": 7797, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3652.6, \"learn_time_ms\": 14698.569}", "{\"n\": 7798, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3651.6, \"learn_time_ms\": 14687.896}", "{\"n\": 7799, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3651.6, \"learn_time_ms\": 14691.438}", "{\"n\": 7800, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3641.03, \"learn_time_ms\": 14702.499}", "{\"n\": 7801, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3638.37, \"learn_time_ms\": 14702.206}", "{\"n\": 7802, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3633.46, \"learn_time_ms\": 14708.11}", "{\"n\": 7803, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3635.36, \"learn_time_ms\": 14706.459}", "{\"n\": 7804, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3646.35, \"learn_time_ms\": 14715.025}", "{\"n\": 7805, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3639.27, \"learn_time_ms\": 14720.817}", "{\"n\": 7806, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3639.27, \"learn_time_ms\": 14735.534}", "{\"n\": 7807, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3660.99, \"learn_time_ms\": 14732.884}", "{\"n\": 7808, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3663.58, \"learn_time_ms\": 14737.729}", "{\"n\": 7809, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3663.58, \"learn_time_ms\": 14743.624}", "{\"n\": 7810, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3676.79, \"learn_time_ms\": 14742.436}", "{\"n\": 7811, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3676.79, \"learn_time_ms\": 14740.755}", "{\"n\": 7812, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3685.1, \"learn_time_ms\": 14737.138}", "{\"n\": 7813, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3681.29, \"learn_time_ms\": 14735.127}", "{\"n\": 7814, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3680.27, \"learn_time_ms\": 14731.929}", "{\"n\": 7815, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3681.55, \"learn_time_ms\": 14738.121}", "{\"n\": 7816, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3681.55, \"learn_time_ms\": 14721.608}", "{\"n\": 7817, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3681.55, \"learn_time_ms\": 14717.556}", "{\"n\": 7818, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3674.47, \"learn_time_ms\": 14726.513}", "{\"n\": 7819, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3679.37, \"learn_time_ms\": 14719.247}", "{\"n\": 7820, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3681.41, \"learn_time_ms\": 14714.646}", "{\"n\": 7821, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3684.27, \"learn_time_ms\": 14726.004}", "{\"n\": 7822, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3691.53, \"learn_time_ms\": 14730.117}", "{\"n\": 7823, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3691.53, \"learn_time_ms\": 14723.278}", "{\"n\": 7824, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3691.53, \"learn_time_ms\": 14721.364}", "{\"n\": 7825, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3688.66, \"learn_time_ms\": 14718.829}", "{\"n\": 7826, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3689.84, \"learn_time_ms\": 14733.544}", "{\"n\": 7827, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3721.58, \"learn_time_ms\": 14730.947}", "{\"n\": 7828, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.04, \"learn_time_ms\": 14725.263}", "{\"n\": 7829, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.04, \"learn_time_ms\": 14725.065}", "{\"n\": 7830, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.04, \"learn_time_ms\": 14727.538}", "{\"n\": 7831, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3726.25, \"learn_time_ms\": 14723.199}", "{\"n\": 7832, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3735.06, \"learn_time_ms\": 14719.356}", "{\"n\": 7833, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.63, \"learn_time_ms\": 14727.827}", "{\"n\": 7834, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.63, \"learn_time_ms\": 14731.037}", "{\"n\": 7835, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.63, \"learn_time_ms\": 14745.01}", "{\"n\": 7836, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.63, \"learn_time_ms\": 14740.582}", "{\"n\": 7837, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3724.39, \"learn_time_ms\": 14740.191}", "{\"n\": 7838, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3721.1, \"learn_time_ms\": 14726.108}", "{\"n\": 7839, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3719.61, \"learn_time_ms\": 14719.425}", "{\"n\": 7840, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3719.61, \"learn_time_ms\": 14720.947}", "{\"n\": 7841, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3719.09, \"learn_time_ms\": 14723.067}", "{\"n\": 7842, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3719.09, \"learn_time_ms\": 14720.185}", "{\"n\": 7843, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3721.11, \"learn_time_ms\": 14715.264}", "{\"n\": 7844, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3718.73, \"learn_time_ms\": 14709.635}", "{\"n\": 7845, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.98, \"learn_time_ms\": 14695.288}", "{\"n\": 7846, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3727.95, \"learn_time_ms\": 14700.998}", "{\"n\": 7847, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3741.91, \"learn_time_ms\": 14706.869}", "{\"n\": 7848, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3741.91, \"learn_time_ms\": 14732.677}", "{\"n\": 7849, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3742.1, \"learn_time_ms\": 14740.013}", "{\"n\": 7850, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3738.38, \"learn_time_ms\": 14747.561}", "{\"n\": 7851, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.1, \"learn_time_ms\": 14746.948}", "{\"n\": 7852, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3727.94, \"learn_time_ms\": 14758.29}", "{\"n\": 7853, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.74, \"learn_time_ms\": 14774.689}", "{\"n\": 7854, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.74, \"learn_time_ms\": 14774.552}", "{\"n\": 7855, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.74, \"learn_time_ms\": 14766.347}", "{\"n\": 7856, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3720.9, \"learn_time_ms\": 14758.006}", "{\"n\": 7857, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.72, \"learn_time_ms\": 14760.996}", "{\"n\": 7858, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3770.73, \"learn_time_ms\": 14750.762}", "{\"n\": 7859, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3773.66, \"learn_time_ms\": 14751.902}", "{\"n\": 7860, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3773.66, \"learn_time_ms\": 14753.636}", "{\"n\": 7861, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3773.66, \"learn_time_ms\": 14738.54}", "{\"n\": 7862, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3773.66, \"learn_time_ms\": 14732.035}", "{\"n\": 7863, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3779.12, \"learn_time_ms\": 14719.836}", "{\"n\": 7864, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3770.59, \"learn_time_ms\": 14719.559}", "{\"n\": 7865, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3771.31, \"learn_time_ms\": 14732.287}", "{\"n\": 7866, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3771.31, \"learn_time_ms\": 14726.964}", "{\"n\": 7867, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3771.31, \"learn_time_ms\": 14728.018}", "{\"n\": 7868, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3777.33, \"learn_time_ms\": 14736.48}", "{\"n\": 7869, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3774.64, \"learn_time_ms\": 14750.335}", "{\"n\": 7870, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3763.21, \"learn_time_ms\": 14748.158}", "{\"n\": 7871, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3781.09, \"learn_time_ms\": 14763.358}", "{\"n\": 7872, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3782.58, \"learn_time_ms\": 14758.513}", "{\"n\": 7873, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3782.58, \"learn_time_ms\": 14756.607}", "{\"n\": 7874, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3775.32, \"learn_time_ms\": 14758.492}", "{\"n\": 7875, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3775.32, \"learn_time_ms\": 14745.852}", "{\"n\": 7876, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3774.39, \"learn_time_ms\": 14757.795}", "{\"n\": 7877, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3778.68, \"learn_time_ms\": 14753.143}", "{\"n\": 7878, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3804.27, \"learn_time_ms\": 14737.641}", "{\"n\": 7879, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3811.79, \"learn_time_ms\": 14718.079}", "{\"n\": 7880, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3811.79, \"learn_time_ms\": 14714.514}", "{\"n\": 7881, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3810.94, \"learn_time_ms\": 14714.003}", "{\"n\": 7882, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3802.63, \"learn_time_ms\": 14723.036}", "{\"n\": 7883, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3803.34, \"learn_time_ms\": 14729.737}", "{\"n\": 7884, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3808.26, \"learn_time_ms\": 14727.452}", "{\"n\": 7885, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3807.1, \"learn_time_ms\": 14729.177}", "{\"n\": 7886, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3814.05, \"learn_time_ms\": 14717.548}", "{\"n\": 7887, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3814.05, \"learn_time_ms\": 14717.662}", "{\"n\": 7888, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3809.88, \"learn_time_ms\": 14719.819}", "{\"n\": 7889, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.75, \"learn_time_ms\": 14720.012}", "{\"n\": 7890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.75, \"learn_time_ms\": 14716.992}", "{\"n\": 7891, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3792.13, \"learn_time_ms\": 14713.011}", "{\"n\": 7892, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3807.59, \"learn_time_ms\": 14699.969}", "{\"n\": 7893, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3816.54, \"learn_time_ms\": 14686.701}", "{\"n\": 7894, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3814.14, \"learn_time_ms\": 14685.411}", "{\"n\": 7895, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3831.68, \"learn_time_ms\": 14683.63}", "{\"n\": 7896, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3831.68, \"learn_time_ms\": 14693.061}", "{\"n\": 7897, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3831.68, \"learn_time_ms\": 14684.916}", "{\"n\": 7898, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3826.7, \"learn_time_ms\": 14686.394}", "{\"n\": 7899, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3831.92, \"learn_time_ms\": 14682.028}", "{\"n\": 7900, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3831.92, \"learn_time_ms\": 14685.26}", "{\"n\": 7901, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3819.26, \"learn_time_ms\": 14688.71}", "{\"n\": 7902, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3819.26, \"learn_time_ms\": 14704.624}", "{\"n\": 7903, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3809.84, \"learn_time_ms\": 14714.337}", "{\"n\": 7904, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3802.33, \"learn_time_ms\": 14715.984}", "{\"n\": 7905, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3795.17, \"learn_time_ms\": 14734.863}", "{\"n\": 7906, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3799.67, \"learn_time_ms\": 14738.476}", "{\"n\": 7907, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.53, \"learn_time_ms\": 14753.381}", "{\"n\": 7908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.53, \"learn_time_ms\": 14753.701}", "{\"n\": 7909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3798.62, \"learn_time_ms\": 14761.354}", "{\"n\": 7910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3796.61, \"learn_time_ms\": 14756.126}", "{\"n\": 7911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3790.04, \"learn_time_ms\": 14749.651}", "{\"n\": 7912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3796.47, \"learn_time_ms\": 14732.397}", "{\"n\": 7913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3796.47, \"learn_time_ms\": 14728.741}", "{\"n\": 7914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3792.15, \"learn_time_ms\": 14733.281}", "{\"n\": 7915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3807.84, \"learn_time_ms\": 14720.363}", "{\"n\": 7916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3809.79, \"learn_time_ms\": 14707.635}", "{\"n\": 7917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3818.47, \"learn_time_ms\": 14705.928}", "{\"n\": 7918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3811.87, \"learn_time_ms\": 14701.06}", "{\"n\": 7919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3811.87, \"learn_time_ms\": 14691.942}", "{\"n\": 7920, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3801.99, \"learn_time_ms\": 14679.821}", "{\"n\": 7921, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3805.46, \"learn_time_ms\": 14686.323}", "{\"n\": 7922, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3809.92, \"learn_time_ms\": 14696.218}", "{\"n\": 7923, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3820.87, \"learn_time_ms\": 14703.365}", "{\"n\": 7924, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3815.92, \"learn_time_ms\": 14709.475}", "{\"n\": 7925, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3809.94, \"learn_time_ms\": 14710.627}", "{\"n\": 7926, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3809.94, \"learn_time_ms\": 14721.731}", "{\"n\": 7927, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3793.66, \"learn_time_ms\": 14719.873}", "{\"n\": 7928, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3793.66, \"learn_time_ms\": 14723.012}", "{\"n\": 7929, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.65, \"learn_time_ms\": 14743.443}", "{\"n\": 7930, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3791.9, \"learn_time_ms\": 14754.325}", "{\"n\": 7931, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3792.16, \"learn_time_ms\": 14747.203}", "{\"n\": 7932, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3792.16, \"learn_time_ms\": 14735.527}", "{\"n\": 7933, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3796.01, \"learn_time_ms\": 14728.645}", "{\"n\": 7934, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3799.19, \"learn_time_ms\": 14727.777}", "{\"n\": 7935, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3798.17, \"learn_time_ms\": 14728.553}", "{\"n\": 7936, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3799.38, \"learn_time_ms\": 14737.316}", "{\"n\": 7937, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3799.38, \"learn_time_ms\": 14727.653}", "{\"n\": 7938, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3792.49, \"learn_time_ms\": 14732.614}", "{\"n\": 7939, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3788.02, \"learn_time_ms\": 14715.893}", "{\"n\": 7940, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.85, \"learn_time_ms\": 14717.995}", "{\"n\": 7941, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.85, \"learn_time_ms\": 14723.363}", "{\"n\": 7942, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.85, \"learn_time_ms\": 14731.221}", "{\"n\": 7943, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3791.51, \"learn_time_ms\": 14730.375}", "{\"n\": 7944, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3787.5, \"learn_time_ms\": 14720.198}", "{\"n\": 7945, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3783.51, \"learn_time_ms\": 14716.98}", "{\"n\": 7946, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3775.02, \"learn_time_ms\": 14705.011}", "{\"n\": 7947, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.46, \"learn_time_ms\": 14712.571}", "{\"n\": 7948, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.46, \"learn_time_ms\": 14708.777}", "{\"n\": 7949, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3773.95, \"learn_time_ms\": 14733.697}", "{\"n\": 7950, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.76, \"learn_time_ms\": 14743.611}", "{\"n\": 7951, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.76, \"learn_time_ms\": 14742.968}", "{\"n\": 7952, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3782.17, \"learn_time_ms\": 14743.805}", "{\"n\": 7953, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3793.13, \"learn_time_ms\": 14746.601}", "{\"n\": 7954, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3790.16, \"learn_time_ms\": 14763.062}", "{\"n\": 7955, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.68, \"learn_time_ms\": 14773.782}", "{\"n\": 7956, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.04, \"learn_time_ms\": 14775.233}", "{\"n\": 7957, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.7, \"learn_time_ms\": 14769.596}", "{\"n\": 7958, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.7, \"learn_time_ms\": 14769.816}", "{\"n\": 7959, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.35, \"learn_time_ms\": 14736.294}", "{\"n\": 7960, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.35, \"learn_time_ms\": 14721.295}", "{\"n\": 7961, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.35, \"learn_time_ms\": 14716.747}", "{\"n\": 7962, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.97, \"learn_time_ms\": 14703.929}", "{\"n\": 7963, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.21, \"learn_time_ms\": 14695.176}", "{\"n\": 7964, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.21, \"learn_time_ms\": 14677.576}", "{\"n\": 7965, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3736.6, \"learn_time_ms\": 14660.617}", "{\"n\": 7966, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3754.88, \"learn_time_ms\": 14662.692}", "{\"n\": 7967, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3756.28, \"learn_time_ms\": 14655.447}", "{\"n\": 7968, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3751.8, \"learn_time_ms\": 14656.648}", "{\"n\": 7969, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3728.18, \"learn_time_ms\": 14667.005}", "{\"n\": 7970, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3726.19, \"learn_time_ms\": 14682.683}", "{\"n\": 7971, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3726.19, \"learn_time_ms\": 14677.434}", "{\"n\": 7972, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3726.19, \"learn_time_ms\": 14688.265}", "{\"n\": 7973, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.11, \"learn_time_ms\": 14703.905}", "{\"n\": 7974, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3736.21, \"learn_time_ms\": 14713.089}", "{\"n\": 7975, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3732.78, \"learn_time_ms\": 14726.408}", "{\"n\": 7976, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3732.52, \"learn_time_ms\": 14724.109}", "{\"n\": 7977, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3732.52, \"learn_time_ms\": 14736.465}", "{\"n\": 7978, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3737.27, \"learn_time_ms\": 14737.22}", "{\"n\": 7979, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3737.27, \"learn_time_ms\": 14725.676}", "{\"n\": 7980, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3762.45, \"learn_time_ms\": 14724.734}", "{\"n\": 7981, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3761.11, \"learn_time_ms\": 14734.59}", "{\"n\": 7982, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3763.93, \"learn_time_ms\": 14743.011}", "{\"n\": 7983, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.16, \"learn_time_ms\": 14734.156}", "{\"n\": 7984, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.16, \"learn_time_ms\": 14723.228}", "{\"n\": 7985, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3767.74, \"learn_time_ms\": 14725.957}", "{\"n\": 7986, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3767.74, \"learn_time_ms\": 14718.337}", "{\"n\": 7987, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3762.52, \"learn_time_ms\": 14719.958}", "{\"n\": 7988, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3762.52, \"learn_time_ms\": 14714.687}", "{\"n\": 7989, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.08, \"learn_time_ms\": 14726.002}", "{\"n\": 7990, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.92, \"learn_time_ms\": 14725.735}", "{\"n\": 7991, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.92, \"learn_time_ms\": 14729.337}", "{\"n\": 7992, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.0, \"learn_time_ms\": 14717.124}", "{\"n\": 7993, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3759.94, \"learn_time_ms\": 14722.723}", "{\"n\": 7994, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3752.5, \"learn_time_ms\": 14738.735}", "{\"n\": 7995, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3775.44, \"learn_time_ms\": 14730.791}", "{\"n\": 7996, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.32, \"learn_time_ms\": 14737.774}", "{\"n\": 7997, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.32, \"learn_time_ms\": 14727.21}", "{\"n\": 7998, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.32, \"learn_time_ms\": 14742.463}", "{\"n\": 7999, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.63, \"learn_time_ms\": 14737.741}", "{\"n\": 8000, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3767.87, \"learn_time_ms\": 14733.237}"]["{\"n\": 8001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15455.333}", "{\"n\": 8002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15169.161}", "{\"n\": 8003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15053.938}", "{\"n\": 8004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14984.495}", "{\"n\": 8005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14905.086}", "{\"n\": 8006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14910.175}", "{\"n\": 8007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14908.312}", "{\"n\": 8008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14925.161}", "{\"n\": 8009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14902.889}", "{\"n\": 8010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14908.484}", "{\"n\": 8011, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -17.0, \"episode_len_mean\": 2156.0, \"learn_time_ms\": 14849.382}", "{\"n\": 8012, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2766.5, \"learn_time_ms\": 14836.175}", "{\"n\": 8013, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.285714285714286, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3672.0, \"learn_time_ms\": 14844.676}", "{\"n\": 8014, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3809.625, \"learn_time_ms\": 14852.966}", "{\"n\": 8015, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3809.625, \"learn_time_ms\": 14894.539}", "{\"n\": 8016, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3809.625, \"learn_time_ms\": 14885.617}", "{\"n\": 8017, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3809.625, \"learn_time_ms\": 14903.651}", "{\"n\": 8018, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.7272727272727275, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3764.909090909091, \"learn_time_ms\": 14888.607}", "{\"n\": 8019, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.666666666666667, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3748.4166666666665, \"learn_time_ms\": 14910.175}", "{\"n\": 8020, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.642857142857143, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3721.214285714286, \"learn_time_ms\": 14915.933}", "{\"n\": 8021, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.5625, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3740.1875, \"learn_time_ms\": 14921.632}", "{\"n\": 8022, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.823529411764706, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3725.6470588235293, \"learn_time_ms\": 14941.264}", "{\"n\": 8023, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.823529411764706, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3725.6470588235293, \"learn_time_ms\": 14933.74}", "{\"n\": 8024, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.611111111111111, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3745.8333333333335, \"learn_time_ms\": 14936.598}", "{\"n\": 8025, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3696.0476190476193, \"learn_time_ms\": 14923.131}", "{\"n\": 8026, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.7727272727272725, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3713.0454545454545, \"learn_time_ms\": 14938.982}", "{\"n\": 8027, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.304347826086956, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3737.782608695652, \"learn_time_ms\": 14916.916}", "{\"n\": 8028, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3708.56, \"learn_time_ms\": 14923.97}", "{\"n\": 8029, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3708.56, \"learn_time_ms\": 14913.635}", "{\"n\": 8030, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.62962962962963, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3689.4074074074074, \"learn_time_ms\": 14904.235}", "{\"n\": 8031, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.310344827586207, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3706.4827586206898, \"learn_time_ms\": 14913.55}", "{\"n\": 8032, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.310344827586207, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3706.4827586206898, \"learn_time_ms\": 14922.149}", "{\"n\": 8033, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.375, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3703.84375, \"learn_time_ms\": 14935.945}", "{\"n\": 8034, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.121212121212121, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3715.3939393939395, \"learn_time_ms\": 14907.384}", "{\"n\": 8035, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.121212121212121, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3715.3939393939395, \"learn_time_ms\": 14897.422}", "{\"n\": 8036, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.121212121212121, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3715.3939393939395, \"learn_time_ms\": 14885.658}", "{\"n\": 8037, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3690.114285714286, \"learn_time_ms\": 14895.187}", "{\"n\": 8038, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.486486486486487, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3696.4594594594596, \"learn_time_ms\": 14895.731}", "{\"n\": 8039, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.475, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3689.95, \"learn_time_ms\": 14910.205}", "{\"n\": 8040, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.487804878048781, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3695.439024390244, \"learn_time_ms\": 14914.92}", "{\"n\": 8041, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.487804878048781, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3695.439024390244, \"learn_time_ms\": 14905.988}", "{\"n\": 8042, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.476190476190476, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3696.690476190476, \"learn_time_ms\": 14873.757}", "{\"n\": 8043, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.441860465116279, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3706.1162790697676, \"learn_time_ms\": 14853.621}", "{\"n\": 8044, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.2444444444444445, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3712.1111111111113, \"learn_time_ms\": 14885.428}", "{\"n\": 8045, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.041666666666667, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3723.0208333333335, \"learn_time_ms\": 14895.475}", "{\"n\": 8046, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.1020408163265305, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3724.326530612245, \"learn_time_ms\": 14905.029}", "{\"n\": 8047, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.1020408163265305, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3724.326530612245, \"learn_time_ms\": 14884.787}", "{\"n\": 8048, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3716.54, \"learn_time_ms\": 14873.859}", "{\"n\": 8049, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.215686274509804, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3713.392156862745, \"learn_time_ms\": 14871.822}", "{\"n\": 8050, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.096153846153846, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3725.6153846153848, \"learn_time_ms\": 14885.757}", "{\"n\": 8051, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.925925925925926, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3732.1111111111113, \"learn_time_ms\": 14889.46}", "{\"n\": 8052, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.9655172413793105, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3708.4655172413795, \"learn_time_ms\": 14916.02}", "{\"n\": 8053, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.9655172413793105, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3708.4655172413795, \"learn_time_ms\": 14929.674}", "{\"n\": 8054, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.9655172413793105, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3708.4655172413795, \"learn_time_ms\": 14920.432}", "{\"n\": 8055, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.983050847457627, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3709.0338983050847, \"learn_time_ms\": 14915.158}", "{\"n\": 8056, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3698.116666666667, \"learn_time_ms\": 14901.252}", "{\"n\": 8057, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.245901639344262, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3676.7377049180327, \"learn_time_ms\": 14923.938}", "{\"n\": 8058, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.190476190476191, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3680.4444444444443, \"learn_time_ms\": 14938.199}", "{\"n\": 8059, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.8636363636363638, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3702.6969696969695, \"learn_time_ms\": 14938.057}", "{\"n\": 8060, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.8636363636363638, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3702.6969696969695, \"learn_time_ms\": 14905.066}", "{\"n\": 8061, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.8636363636363638, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3702.6969696969695, \"learn_time_ms\": 14903.648}", "{\"n\": 8062, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.898550724637681, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3703.927536231884, \"learn_time_ms\": 14905.561}", "{\"n\": 8063, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.898550724637681, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3703.927536231884, \"learn_time_ms\": 14909.741}", "{\"n\": 8064, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.8142857142857145, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3711.3714285714286, \"learn_time_ms\": 14900.04}", "{\"n\": 8065, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.671232876712329, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3724.8082191780823, \"learn_time_ms\": 14900.437}", "{\"n\": 8066, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.635135135135135, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3730.4594594594596, \"learn_time_ms\": 14901.786}", "{\"n\": 8067, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.635135135135135, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3730.4594594594596, \"learn_time_ms\": 14885.507}", "{\"n\": 8068, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.7333333333333334, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3721.68, \"learn_time_ms\": 14873.645}", "{\"n\": 8069, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.923076923076923, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3702.4615384615386, \"learn_time_ms\": 14878.468}", "{\"n\": 8070, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.8375, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3713.675, \"learn_time_ms\": 14895.021}", "{\"n\": 8071, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.8375, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3713.675, \"learn_time_ms\": 14891.632}", "{\"n\": 8072, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.753086419753086, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3721.1728395061727, \"learn_time_ms\": 14893.201}", "{\"n\": 8073, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.682926829268293, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3723.4634146341464, \"learn_time_ms\": 14882.753}", "{\"n\": 8074, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.4352941176470586, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3737.211764705882, \"learn_time_ms\": 14901.493}", "{\"n\": 8075, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5402298850574714, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.919540229885, \"learn_time_ms\": 14918.485}", "{\"n\": 8076, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5402298850574714, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.919540229885, \"learn_time_ms\": 14931.826}", "{\"n\": 8077, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6136363636363638, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3717.159090909091, \"learn_time_ms\": 14947.329}", "{\"n\": 8078, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6136363636363638, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3717.159090909091, \"learn_time_ms\": 14960.099}", "{\"n\": 8079, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5604395604395602, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3719.4505494505493, \"learn_time_ms\": 14953.41}", "{\"n\": 8080, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.630434782608696, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3710.9891304347825, \"learn_time_ms\": 14958.846}", "{\"n\": 8081, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6774193548387095, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3709.494623655914, \"learn_time_ms\": 14971.121}", "{\"n\": 8082, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.7083333333333335, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3707.4895833333335, \"learn_time_ms\": 14964.654}", "{\"n\": 8083, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.7083333333333335, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3707.4895833333335, \"learn_time_ms\": 14972.535}", "{\"n\": 8084, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.7083333333333335, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3707.4895833333335, \"learn_time_ms\": 14973.274}", "{\"n\": 8085, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.489795918367347, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3707.285714285714, \"learn_time_ms\": 14963.498}", "{\"n\": 8086, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3705.02, \"learn_time_ms\": 14968.0}", "{\"n\": 8087, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3728.54, \"learn_time_ms\": 14950.619}", "{\"n\": 8088, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3719.94, \"learn_time_ms\": 14945.096}", "{\"n\": 8089, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3719.94, \"learn_time_ms\": 14926.594}", "{\"n\": 8090, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3715.34, \"learn_time_ms\": 14926.447}", "{\"n\": 8091, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3715.34, \"learn_time_ms\": 14928.312}", "{\"n\": 8092, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3703.75, \"learn_time_ms\": 14926.775}", "{\"n\": 8093, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3692.71, \"learn_time_ms\": 14933.645}", "{\"n\": 8094, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3700.16, \"learn_time_ms\": 14929.897}", "{\"n\": 8095, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3694.36, \"learn_time_ms\": 14910.772}", "{\"n\": 8096, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3694.36, \"learn_time_ms\": 14898.59}", "{\"n\": 8097, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3694.36, \"learn_time_ms\": 14919.127}", "{\"n\": 8098, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3694.82, \"learn_time_ms\": 14918.922}", "{\"n\": 8099, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3694.82, \"learn_time_ms\": 14904.197}", "{\"n\": 8100, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3695.87, \"learn_time_ms\": 14900.086}", "{\"n\": 8101, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3698.96, \"learn_time_ms\": 14892.153}", "{\"n\": 8102, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3697.01, \"learn_time_ms\": 14894.133}", "{\"n\": 8103, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3690.06, \"learn_time_ms\": 14889.354}", "{\"n\": 8104, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3690.06, \"learn_time_ms\": 14905.934}", "{\"n\": 8105, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3699.84, \"learn_time_ms\": 14933.623}", "{\"n\": 8106, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3710.7, \"learn_time_ms\": 14909.02}", "{\"n\": 8107, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3712.17, \"learn_time_ms\": 14906.784}", "{\"n\": 8108, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3711.76, \"learn_time_ms\": 14914.954}", "{\"n\": 8109, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3698.08, \"learn_time_ms\": 14948.886}", "{\"n\": 8110, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3693.18, \"learn_time_ms\": 14945.236}", "{\"n\": 8111, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3693.18, \"learn_time_ms\": 14946.719}", "{\"n\": 8112, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3692.23, \"learn_time_ms\": 14955.965}", "{\"n\": 8113, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3692.71, \"learn_time_ms\": 14948.25}", "{\"n\": 8114, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3702.08, \"learn_time_ms\": 14910.461}", "{\"n\": 8115, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3702.08, \"learn_time_ms\": 14896.313}", "{\"n\": 8116, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3712.17, \"learn_time_ms\": 14931.712}", "{\"n\": 8117, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3716.02, \"learn_time_ms\": 14923.715}", "{\"n\": 8118, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3715.29, \"learn_time_ms\": 14912.512}", "{\"n\": 8119, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3699.21, \"learn_time_ms\": 14921.995}", "{\"n\": 8120, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3702.6, \"learn_time_ms\": 14929.267}", "{\"n\": 8121, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3702.6, \"learn_time_ms\": 14927.267}", "{\"n\": 8122, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3702.6, \"learn_time_ms\": 14887.362}", "{\"n\": 8123, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3685.91, \"learn_time_ms\": 14902.873}", "{\"n\": 8124, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3694.6, \"learn_time_ms\": 14916.513}", "{\"n\": 8125, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3673.04, \"learn_time_ms\": 14924.829}", "{\"n\": 8126, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3660.76, \"learn_time_ms\": 14916.315}", "{\"n\": 8127, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3660.76, \"learn_time_ms\": 14921.142}", "{\"n\": 8128, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3660.76, \"learn_time_ms\": 14932.924}", "{\"n\": 8129, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3666.15, \"learn_time_ms\": 14932.123}", "{\"n\": 8130, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3649.78, \"learn_time_ms\": 14934.301}", "{\"n\": 8131, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3655.03, \"learn_time_ms\": 14931.26}", "{\"n\": 8132, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3676.71, \"learn_time_ms\": 14962.948}", "{\"n\": 8133, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3671.09, \"learn_time_ms\": 14951.07}", "{\"n\": 8134, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3669.37, \"learn_time_ms\": 14959.776}", "{\"n\": 8135, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3669.37, \"learn_time_ms\": 14961.591}", "{\"n\": 8136, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3669.37, \"learn_time_ms\": 14965.428}", "{\"n\": 8137, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3665.5, \"learn_time_ms\": 14968.473}", "{\"n\": 8138, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3670.27, \"learn_time_ms\": 14945.187}", "{\"n\": 8139, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.24, \"learn_time_ms\": 14925.03}", "{\"n\": 8140, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.24, \"learn_time_ms\": 14920.452}", "{\"n\": 8141, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3643.24, \"learn_time_ms\": 14926.459}", "{\"n\": 8142, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.83, \"learn_time_ms\": 14933.492}", "{\"n\": 8143, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.83, \"learn_time_ms\": 14919.887}", "{\"n\": 8144, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3667.53, \"learn_time_ms\": 14928.016}", "{\"n\": 8145, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3663.78, \"learn_time_ms\": 14913.317}", "{\"n\": 8146, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.78, \"learn_time_ms\": 14932.463}", "{\"n\": 8147, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.71, \"learn_time_ms\": 14935.999}", "{\"n\": 8148, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.71, \"learn_time_ms\": 14955.824}", "{\"n\": 8149, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3636.71, \"learn_time_ms\": 14977.15}", "{\"n\": 8150, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3631.91, \"learn_time_ms\": 14983.708}", "{\"n\": 8151, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.78, \"learn_time_ms\": 14972.772}", "{\"n\": 8152, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3637.87, \"learn_time_ms\": 14961.328}", "{\"n\": 8153, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3656.8, \"learn_time_ms\": 14976.554}", "{\"n\": 8154, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3658.1, \"learn_time_ms\": 14955.309}", "{\"n\": 8155, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3658.1, \"learn_time_ms\": 14978.079}", "{\"n\": 8156, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3662.73, \"learn_time_ms\": 14968.378}", "{\"n\": 8157, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3663.4, \"learn_time_ms\": 14951.903}", "{\"n\": 8158, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3669.96, \"learn_time_ms\": 14947.87}", "{\"n\": 8159, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3680.54, \"learn_time_ms\": 14928.439}", "{\"n\": 8160, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.32, \"learn_time_ms\": 14924.921}", "{\"n\": 8161, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.32, \"learn_time_ms\": 14940.637}", "{\"n\": 8162, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.32, \"learn_time_ms\": 14946.621}", "{\"n\": 8163, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3692.57, \"learn_time_ms\": 14938.597}", "{\"n\": 8164, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.04, \"learn_time_ms\": 14949.852}", "{\"n\": 8165, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3702.22, \"learn_time_ms\": 14949.234}", "{\"n\": 8166, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.29, \"learn_time_ms\": 14933.864}", "{\"n\": 8167, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.29, \"learn_time_ms\": 14932.946}", "{\"n\": 8168, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.29, \"learn_time_ms\": 14933.77}", "{\"n\": 8169, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3723.32, \"learn_time_ms\": 14938.59}", "{\"n\": 8170, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3723.75, \"learn_time_ms\": 14940.283}", "{\"n\": 8171, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3706.21, \"learn_time_ms\": 14932.934}", "{\"n\": 8172, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3706.21, \"learn_time_ms\": 14937.729}", "{\"n\": 8173, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3706.42, \"learn_time_ms\": 14957.917}", "{\"n\": 8174, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3704.93, \"learn_time_ms\": 14971.997}", "{\"n\": 8175, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3704.93, \"learn_time_ms\": 14959.599}", "{\"n\": 8176, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3698.83, \"learn_time_ms\": 14961.222}", "{\"n\": 8177, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.86, \"learn_time_ms\": 14983.335}", "{\"n\": 8178, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3709.67, \"learn_time_ms\": 14985.293}", "{\"n\": 8179, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3722.01, \"learn_time_ms\": 14982.089}", "{\"n\": 8180, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3708.71, \"learn_time_ms\": 14967.744}", "{\"n\": 8181, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3708.71, \"learn_time_ms\": 14967.029}", "{\"n\": 8182, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3707.88, \"learn_time_ms\": 14941.968}", "{\"n\": 8183, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3698.6, \"learn_time_ms\": 14913.732}", "{\"n\": 8184, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3700.37, \"learn_time_ms\": 14902.87}", "{\"n\": 8185, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3700.37, \"learn_time_ms\": 14914.795}", "{\"n\": 8186, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3716.12, \"learn_time_ms\": 14910.992}", "{\"n\": 8187, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3716.88, \"learn_time_ms\": 14901.787}", "{\"n\": 8188, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3717.3, \"learn_time_ms\": 14879.833}", "{\"n\": 8189, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3718.46, \"learn_time_ms\": 14886.553}", "{\"n\": 8190, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.19, \"learn_time_ms\": 14898.191}", "{\"n\": 8191, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.19, \"learn_time_ms\": 14900.107}", "{\"n\": 8192, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3709.96, \"learn_time_ms\": 14919.55}", "{\"n\": 8193, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3695.36, \"learn_time_ms\": 14911.98}", "{\"n\": 8194, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.5, \"learn_time_ms\": 14895.815}", "{\"n\": 8195, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.78, \"learn_time_ms\": 14890.425}", "{\"n\": 8196, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.78, \"learn_time_ms\": 14892.139}", "{\"n\": 8197, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.21, \"learn_time_ms\": 14899.03}", "{\"n\": 8198, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.52, \"learn_time_ms\": 14894.332}", "{\"n\": 8199, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.64, \"learn_time_ms\": 14891.267}", "{\"n\": 8200, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.96, \"learn_time_ms\": 14899.849}", "{\"n\": 8201, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.41, \"learn_time_ms\": 14903.537}", "{\"n\": 8202, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.41, \"learn_time_ms\": 14910.673}", "{\"n\": 8203, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3718.09, \"learn_time_ms\": 14931.874}", "{\"n\": 8204, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3724.22, \"learn_time_ms\": 14948.716}", "{\"n\": 8205, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3749.21, \"learn_time_ms\": 14951.084}", "{\"n\": 8206, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3744.33, \"learn_time_ms\": 14952.315}", "{\"n\": 8207, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3745.92, \"learn_time_ms\": 14952.286}", "{\"n\": 8208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.22, \"learn_time_ms\": 14976.939}", "{\"n\": 8209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.22, \"learn_time_ms\": 14991.614}", "{\"n\": 8210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3791.26, \"learn_time_ms\": 14989.853}", "{\"n\": 8211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3781.83, \"learn_time_ms\": 14985.658}", "{\"n\": 8212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.67, \"learn_time_ms\": 14994.829}", "{\"n\": 8213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.67, \"learn_time_ms\": 14997.145}", "{\"n\": 8214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3787.61, \"learn_time_ms\": 15000.368}", "{\"n\": 8215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3791.94, \"learn_time_ms\": 14992.133}", "{\"n\": 8216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3779.33, \"learn_time_ms\": 15008.627}", "{\"n\": 8217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3779.33, \"learn_time_ms\": 15001.511}", "{\"n\": 8218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.47, \"learn_time_ms\": 14989.379}", "{\"n\": 8219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3790.78, \"learn_time_ms\": 14990.085}", "{\"n\": 8220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3790.78, \"learn_time_ms\": 14995.755}", "{\"n\": 8221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3783.17, \"learn_time_ms\": 14988.594}", "{\"n\": 8222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3783.17, \"learn_time_ms\": 14977.092}", "{\"n\": 8223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3778.58, \"learn_time_ms\": 14982.133}", "{\"n\": 8224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.44, \"learn_time_ms\": 14982.033}", "{\"n\": 8225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3789.29, \"learn_time_ms\": 15008.033}", "{\"n\": 8226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3795.85, \"learn_time_ms\": 15004.634}", "{\"n\": 8227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3803.78, \"learn_time_ms\": 15014.468}", "{\"n\": 8228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3798.32, \"learn_time_ms\": 15004.14}", "{\"n\": 8229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3798.32, \"learn_time_ms\": 14994.186}", "{\"n\": 8230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3797.77, \"learn_time_ms\": 14989.014}", "{\"n\": 8231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3804.33, \"learn_time_ms\": 14998.708}", "{\"n\": 8232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3798.87, \"learn_time_ms\": 15006.588}", "{\"n\": 8233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3786.43, \"learn_time_ms\": 15008.591}", "{\"n\": 8234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3786.43, \"learn_time_ms\": 15014.174}", "{\"n\": 8235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3795.99, \"learn_time_ms\": 14991.363}", "{\"n\": 8236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3790.38, \"learn_time_ms\": 14987.845}", "{\"n\": 8237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3791.26, \"learn_time_ms\": 14982.003}", "{\"n\": 8238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3788.12, \"learn_time_ms\": 15005.463}", "{\"n\": 8239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3787.82, \"learn_time_ms\": 14999.101}", "{\"n\": 8240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3787.82, \"learn_time_ms\": 14993.148}", "{\"n\": 8241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3789.82, \"learn_time_ms\": 15001.857}", "{\"n\": 8242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3795.77, \"learn_time_ms\": 14999.106}", "{\"n\": 8243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3783.92, \"learn_time_ms\": 15000.528}", "{\"n\": 8244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3763.0, \"learn_time_ms\": 14998.847}", "{\"n\": 8245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3761.36, \"learn_time_ms\": 15009.882}", "{\"n\": 8246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3761.36, \"learn_time_ms\": 15021.597}", "{\"n\": 8247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3750.09, \"learn_time_ms\": 15015.907}", "{\"n\": 8248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3756.69, \"learn_time_ms\": 15011.881}", "{\"n\": 8249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3774.11, \"learn_time_ms\": 15004.901}", "{\"n\": 8250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3776.68, \"learn_time_ms\": 14998.743}", "{\"n\": 8251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3788.73, \"learn_time_ms\": 14979.715}", "{\"n\": 8252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3788.73, \"learn_time_ms\": 14966.89}", "{\"n\": 8253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3788.73, \"learn_time_ms\": 14965.521}", "{\"n\": 8254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3788.16, \"learn_time_ms\": 14960.704}", "{\"n\": 8255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3780.6, \"learn_time_ms\": 14947.981}", "{\"n\": 8256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3770.03, \"learn_time_ms\": 14942.786}", "{\"n\": 8257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3763.92, \"learn_time_ms\": 14943.482}", "{\"n\": 8258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3769.05, \"learn_time_ms\": 14947.189}", "{\"n\": 8259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3774.79, \"learn_time_ms\": 14954.563}", "{\"n\": 8260, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3785.74, \"learn_time_ms\": 14962.13}", "{\"n\": 8261, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3785.74, \"learn_time_ms\": 14958.428}", "{\"n\": 8262, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3775.2, \"learn_time_ms\": 14956.744}", "{\"n\": 8263, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3775.2, \"learn_time_ms\": 14959.601}", "{\"n\": 8264, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3779.51, \"learn_time_ms\": 14973.194}", "{\"n\": 8265, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3781.53, \"learn_time_ms\": 14972.212}", "{\"n\": 8266, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3776.91, \"learn_time_ms\": 14969.24}", "{\"n\": 8267, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3754.79, \"learn_time_ms\": 14984.205}", "{\"n\": 8268, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3757.5, \"learn_time_ms\": 14988.668}", "{\"n\": 8269, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3754.67, \"learn_time_ms\": 14993.765}", "{\"n\": 8270, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3741.75, \"learn_time_ms\": 14992.105}", "{\"n\": 8271, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3748.18, \"learn_time_ms\": 15017.378}", "{\"n\": 8272, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3748.18, \"learn_time_ms\": 15017.391}", "{\"n\": 8273, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3747.42, \"learn_time_ms\": 15002.212}", "{\"n\": 8274, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3747.07, \"learn_time_ms\": 14975.906}", "{\"n\": 8275, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3738.26, \"learn_time_ms\": 14985.82}", "{\"n\": 8276, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3725.77, \"learn_time_ms\": 14976.658}", "{\"n\": 8277, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3725.77, \"learn_time_ms\": 14946.616}", "{\"n\": 8278, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3725.77, \"learn_time_ms\": 14944.702}", "{\"n\": 8279, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3738.32, \"learn_time_ms\": 14957.143}", "{\"n\": 8280, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3731.96, \"learn_time_ms\": 14953.157}", "{\"n\": 8281, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3731.96, \"learn_time_ms\": 14936.732}", "{\"n\": 8282, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3725.9, \"learn_time_ms\": 14921.15}", "{\"n\": 8283, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3729.4, \"learn_time_ms\": 14931.416}", "{\"n\": 8284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3729.4, \"learn_time_ms\": 14941.259}", "{\"n\": 8285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3729.4, \"learn_time_ms\": 14935.874}", "{\"n\": 8286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3709.97, \"learn_time_ms\": 14946.679}", "{\"n\": 8287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3703.79, \"learn_time_ms\": 14967.369}", "{\"n\": 8288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3699.42, \"learn_time_ms\": 14970.594}", "{\"n\": 8289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3695.86, \"learn_time_ms\": 14963.783}", "{\"n\": 8290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3695.86, \"learn_time_ms\": 14933.069}", "{\"n\": 8291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3695.86, \"learn_time_ms\": 14923.717}", "{\"n\": 8292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3713.19, \"learn_time_ms\": 14939.28}", "{\"n\": 8293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3714.75, \"learn_time_ms\": 14941.891}", "{\"n\": 8294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3712.98, \"learn_time_ms\": 14944.597}", "{\"n\": 8295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3716.27, \"learn_time_ms\": 14955.23}", "{\"n\": 8296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3716.27, \"learn_time_ms\": 14959.701}", "{\"n\": 8297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3716.27, \"learn_time_ms\": 14970.698}", "{\"n\": 8298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3718.52, \"learn_time_ms\": 14961.598}", "{\"n\": 8299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3704.77, \"learn_time_ms\": 14964.123}", "{\"n\": 8300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3713.54, \"learn_time_ms\": 14993.281}", "{\"n\": 8301, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3710.46, \"learn_time_ms\": 14998.903}", "{\"n\": 8302, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3710.46, \"learn_time_ms\": 14994.901}", "{\"n\": 8303, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3710.46, \"learn_time_ms\": 14994.132}", "{\"n\": 8304, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3712.7, \"learn_time_ms\": 14990.161}", "{\"n\": 8305, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.41, \"learn_time_ms\": 14947.863}", "{\"n\": 8306, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.45, \"learn_time_ms\": 14925.921}", "{\"n\": 8307, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.33, \"learn_time_ms\": 14901.546}", "{\"n\": 8308, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3694.97, \"learn_time_ms\": 14906.448}", "{\"n\": 8309, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3694.97, \"learn_time_ms\": 14892.01}", "{\"n\": 8310, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3693.54, \"learn_time_ms\": 14906.769}", "{\"n\": 8311, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3689.05, \"learn_time_ms\": 14906.978}", "{\"n\": 8312, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.01, \"learn_time_ms\": 14920.86}", "{\"n\": 8313, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.36, \"learn_time_ms\": 14922.174}", "{\"n\": 8314, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3679.03, \"learn_time_ms\": 14924.598}", "{\"n\": 8315, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3674.97, \"learn_time_ms\": 14942.401}", "{\"n\": 8316, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3669.49, \"learn_time_ms\": 14946.296}", "{\"n\": 8317, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3669.49, \"learn_time_ms\": 14943.424}", "{\"n\": 8318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.99, \"learn_time_ms\": 14926.748}", "{\"n\": 8319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3673.84, \"learn_time_ms\": 14935.279}", "{\"n\": 8320, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.11, \"learn_time_ms\": 14922.771}", "{\"n\": 8321, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3690.07, \"learn_time_ms\": 14943.101}", "{\"n\": 8322, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3690.8, \"learn_time_ms\": 14948.801}", "{\"n\": 8323, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3681.4, \"learn_time_ms\": 14948.717}", "{\"n\": 8324, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3681.4, \"learn_time_ms\": 14954.918}", "{\"n\": 8325, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3692.39, \"learn_time_ms\": 14965.43}", "{\"n\": 8326, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3685.26, \"learn_time_ms\": 14975.72}", "{\"n\": 8327, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.47, \"learn_time_ms\": 15007.572}", "{\"n\": 8328, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.47, \"learn_time_ms\": 15036.273}", "{\"n\": 8329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3687.84, \"learn_time_ms\": 15050.357}", "{\"n\": 8330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3676.92, \"learn_time_ms\": 15049.627}", "{\"n\": 8331, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3678.25, \"learn_time_ms\": 15020.927}", "{\"n\": 8332, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3686.99, \"learn_time_ms\": 15007.86}", "{\"n\": 8333, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3695.26, \"learn_time_ms\": 15003.767}", "{\"n\": 8334, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3702.73, \"learn_time_ms\": 14996.869}", "{\"n\": 8335, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3702.73, \"learn_time_ms\": 14989.652}", "{\"n\": 8336, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3692.6, \"learn_time_ms\": 15001.848}", "{\"n\": 8337, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3702.85, \"learn_time_ms\": 14980.377}", "{\"n\": 8338, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3701.54, \"learn_time_ms\": 14969.633}", "{\"n\": 8339, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3701.22, \"learn_time_ms\": 14960.165}", "{\"n\": 8340, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3701.22, \"learn_time_ms\": 14958.947}", "{\"n\": 8341, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3707.64, \"learn_time_ms\": 14969.43}", "{\"n\": 8342, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3707.41, \"learn_time_ms\": 14977.19}", "{\"n\": 8343, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3707.41, \"learn_time_ms\": 14968.062}", "{\"n\": 8344, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3736.86, \"learn_time_ms\": 14982.882}", "{\"n\": 8345, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3752.94, \"learn_time_ms\": 15003.472}", "{\"n\": 8346, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3747.97, \"learn_time_ms\": 14980.332}", "{\"n\": 8347, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3751.34, \"learn_time_ms\": 14990.569}", "{\"n\": 8348, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3753.98, \"learn_time_ms\": 14982.107}", "{\"n\": 8349, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3761.04, \"learn_time_ms\": 14964.709}", "{\"n\": 8350, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.37, \"learn_time_ms\": 14966.151}", "{\"n\": 8351, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3750.74, \"learn_time_ms\": 14968.725}", "{\"n\": 8352, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3759.62, \"learn_time_ms\": 14961.545}", "{\"n\": 8353, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3759.62, \"learn_time_ms\": 14972.402}", "{\"n\": 8354, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3772.53, \"learn_time_ms\": 14972.452}", "{\"n\": 8355, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.14, \"learn_time_ms\": 14968.327}", "{\"n\": 8356, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3751.57, \"learn_time_ms\": 14986.303}", "{\"n\": 8357, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3751.57, \"learn_time_ms\": 14999.891}", "{\"n\": 8358, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3746.86, \"learn_time_ms\": 15016.959}", "{\"n\": 8359, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3746.86, \"learn_time_ms\": 15038.184}", "{\"n\": 8360, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3749.06, \"learn_time_ms\": 15043.47}", "{\"n\": 8361, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3749.06, \"learn_time_ms\": 15053.977}", "{\"n\": 8362, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3734.36, \"learn_time_ms\": 15051.588}", "{\"n\": 8363, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.67, \"learn_time_ms\": 15057.434}", "{\"n\": 8364, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.67, \"learn_time_ms\": 15048.039}", "{\"n\": 8365, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.46, \"learn_time_ms\": 15045.954}", "{\"n\": 8366, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3736.48, \"learn_time_ms\": 15039.599}", "{\"n\": 8367, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3735.99, \"learn_time_ms\": 15031.86}", "{\"n\": 8368, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3726.21, \"learn_time_ms\": 15020.961}", "{\"n\": 8369, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3707.7, \"learn_time_ms\": 15013.19}", "{\"n\": 8370, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3710.62, \"learn_time_ms\": 15015.395}", "{\"n\": 8371, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3709.83, \"learn_time_ms\": 15005.023}", "{\"n\": 8372, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3715.31, \"learn_time_ms\": 14996.846}", "{\"n\": 8373, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3715.01, \"learn_time_ms\": 14994.763}", "{\"n\": 8374, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3715.52, \"learn_time_ms\": 14986.188}", "{\"n\": 8375, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3715.52, \"learn_time_ms\": 14973.9}", "{\"n\": 8376, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3736.75, \"learn_time_ms\": 14968.982}", "{\"n\": 8377, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.43, \"learn_time_ms\": 14962.886}", "{\"n\": 8378, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3719.36, \"learn_time_ms\": 14967.133}", "{\"n\": 8379, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3719.36, \"learn_time_ms\": 14965.89}", "{\"n\": 8380, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3719.36, \"learn_time_ms\": 14950.128}", "{\"n\": 8381, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3721.38, \"learn_time_ms\": 14963.707}", "{\"n\": 8382, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3723.13, \"learn_time_ms\": 14978.962}", "{\"n\": 8383, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3718.02, \"learn_time_ms\": 14975.092}", "{\"n\": 8384, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3718.02, \"learn_time_ms\": 14984.181}", "{\"n\": 8385, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3717.61, \"learn_time_ms\": 15006.321}", "{\"n\": 8386, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3717.61, \"learn_time_ms\": 15006.351}", "{\"n\": 8387, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3714.23, \"learn_time_ms\": 14999.939}", "{\"n\": 8388, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3703.02, \"learn_time_ms\": 14993.674}", "{\"n\": 8389, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3701.6, \"learn_time_ms\": 14992.066}", "{\"n\": 8390, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3709.26, \"learn_time_ms\": 15006.617}", "{\"n\": 8391, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3709.26, \"learn_time_ms\": 15009.617}", "{\"n\": 8392, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3720.03, \"learn_time_ms\": 15016.998}", "{\"n\": 8393, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3713.87, \"learn_time_ms\": 15017.479}", "{\"n\": 8394, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3704.43, \"learn_time_ms\": 15028.03}", "{\"n\": 8395, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3708.84, \"learn_time_ms\": 15009.638}", "{\"n\": 8396, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3705.37, \"learn_time_ms\": 15005.814}", "{\"n\": 8397, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3712.33, \"learn_time_ms\": 15002.226}", "{\"n\": 8398, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3712.33, \"learn_time_ms\": 14995.209}", "{\"n\": 8399, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3699.73, \"learn_time_ms\": 15012.353}", "{\"n\": 8400, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3695.64, \"learn_time_ms\": 15007.361}", "{\"n\": 8401, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3702.14, \"learn_time_ms\": 14995.625}", "{\"n\": 8402, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3698.47, \"learn_time_ms\": 14983.883}", "{\"n\": 8403, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3698.11, \"learn_time_ms\": 14988.675}", "{\"n\": 8404, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3699.62, \"learn_time_ms\": 14975.658}", "{\"n\": 8405, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3699.62, \"learn_time_ms\": 14985.122}", "{\"n\": 8406, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3699.62, \"learn_time_ms\": 14985.158}", "{\"n\": 8407, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3719.98, \"learn_time_ms\": 14985.363}", "{\"n\": 8408, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3727.38, \"learn_time_ms\": 14989.689}", "{\"n\": 8409, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3719.38, \"learn_time_ms\": 14950.431}", "{\"n\": 8410, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3718.37, \"learn_time_ms\": 14955.882}", "{\"n\": 8411, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3702.31, \"learn_time_ms\": 14960.934}", "{\"n\": 8412, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3702.31, \"learn_time_ms\": 14972.094}", "{\"n\": 8413, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3702.31, \"learn_time_ms\": 14973.803}", "{\"n\": 8414, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3710.79, \"learn_time_ms\": 14976.01}", "{\"n\": 8415, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3709.55, \"learn_time_ms\": 14962.92}", "{\"n\": 8416, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3692.25, \"learn_time_ms\": 14957.296}", "{\"n\": 8417, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3688.1, \"learn_time_ms\": 14967.191}", "{\"n\": 8418, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3688.1, \"learn_time_ms\": 14954.721}", "{\"n\": 8419, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3688.1, \"learn_time_ms\": 14986.203}", "{\"n\": 8420, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3697.83, \"learn_time_ms\": 14990.379}", "{\"n\": 8421, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3697.83, \"learn_time_ms\": 14983.424}", "{\"n\": 8422, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3700.88, \"learn_time_ms\": 14976.281}", "{\"n\": 8423, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.37, \"learn_time_ms\": 14953.595}", "{\"n\": 8424, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3699.74, \"learn_time_ms\": 14947.603}", "{\"n\": 8425, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3699.74, \"learn_time_ms\": 14944.465}", "{\"n\": 8426, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3699.74, \"learn_time_ms\": 14943.123}", "{\"n\": 8427, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.58, \"learn_time_ms\": 14939.325}", "{\"n\": 8428, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3718.13, \"learn_time_ms\": 14959.95}", "{\"n\": 8429, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3713.37, \"learn_time_ms\": 14955.856}", "{\"n\": 8430, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3719.07, \"learn_time_ms\": 14953.618}", "{\"n\": 8431, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3715.26, \"learn_time_ms\": 14961.485}", "{\"n\": 8432, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3715.26, \"learn_time_ms\": 14965.221}", "{\"n\": 8433, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.31, \"learn_time_ms\": 14985.634}", "{\"n\": 8434, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.96, \"learn_time_ms\": 14993.153}", "{\"n\": 8435, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3739.62, \"learn_time_ms\": 14992.933}", "{\"n\": 8436, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.87, \"learn_time_ms\": 14990.14}", "{\"n\": 8437, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.87, \"learn_time_ms\": 14971.991}", "{\"n\": 8438, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.87, \"learn_time_ms\": 14923.967}", "{\"n\": 8439, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.45, \"learn_time_ms\": 14916.727}", "{\"n\": 8440, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3735.22, \"learn_time_ms\": 14915.308}", "{\"n\": 8441, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3734.17, \"learn_time_ms\": 14913.191}", "{\"n\": 8442, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3734.17, \"learn_time_ms\": 14925.545}", "{\"n\": 8443, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.77, \"learn_time_ms\": 14925.291}", "{\"n\": 8444, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.77, \"learn_time_ms\": 14914.883}", "{\"n\": 8445, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3731.57, \"learn_time_ms\": 14895.321}", "{\"n\": 8446, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.86, \"learn_time_ms\": 14873.538}", "{\"n\": 8447, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3744.1, \"learn_time_ms\": 14892.054}", "{\"n\": 8448, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3754.97, \"learn_time_ms\": 14939.868}", "{\"n\": 8449, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3754.42, \"learn_time_ms\": 14952.792}", "{\"n\": 8450, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3754.42, \"learn_time_ms\": 14945.75}", "{\"n\": 8451, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3745.48, \"learn_time_ms\": 14931.193}", "{\"n\": 8452, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3750.63, \"learn_time_ms\": 14915.095}", "{\"n\": 8453, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.59, \"learn_time_ms\": 14912.926}", "{\"n\": 8454, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3748.93, \"learn_time_ms\": 14932.428}", "{\"n\": 8455, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3755.61, \"learn_time_ms\": 14969.252}", "{\"n\": 8456, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3755.61, \"learn_time_ms\": 15001.159}", "{\"n\": 8457, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3752.29, \"learn_time_ms\": 15001.099}", "{\"n\": 8458, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3761.75, \"learn_time_ms\": 15000.356}", "{\"n\": 8459, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3765.15, \"learn_time_ms\": 14993.892}", "{\"n\": 8460, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3766.25, \"learn_time_ms\": 14995.144}", "{\"n\": 8461, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3766.25, \"learn_time_ms\": 15002.66}", "{\"n\": 8462, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3766.25, \"learn_time_ms\": 15020.474}", "{\"n\": 8463, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3767.05, \"learn_time_ms\": 15021.589}", "{\"n\": 8464, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3772.3, \"learn_time_ms\": 15010.094}", "{\"n\": 8465, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3778.28, \"learn_time_ms\": 15006.438}", "{\"n\": 8466, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.99, \"learn_time_ms\": 15017.5}", "{\"n\": 8467, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.48, \"learn_time_ms\": 14995.782}", "{\"n\": 8468, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.48, \"learn_time_ms\": 14989.715}", "{\"n\": 8469, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3758.78, \"learn_time_ms\": 14985.673}", "{\"n\": 8470, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3742.98, \"learn_time_ms\": 14987.297}", "{\"n\": 8471, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3744.8, \"learn_time_ms\": 15005.457}", "{\"n\": 8472, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3760.4, \"learn_time_ms\": 14991.485}", "{\"n\": 8473, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3764.02, \"learn_time_ms\": 15002.746}", "{\"n\": 8474, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3764.02, \"learn_time_ms\": 15010.896}", "{\"n\": 8475, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3754.26, \"learn_time_ms\": 15014.994}", "{\"n\": 8476, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3763.58, \"learn_time_ms\": 15003.468}", "{\"n\": 8477, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3763.58, \"learn_time_ms\": 15002.276}", "{\"n\": 8478, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3765.13, \"learn_time_ms\": 15009.872}", "{\"n\": 8479, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.28, \"learn_time_ms\": 15021.963}", "{\"n\": 8480, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3767.25, \"learn_time_ms\": 15027.831}", "{\"n\": 8481, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3767.25, \"learn_time_ms\": 15025.136}", "{\"n\": 8482, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3761.73, \"learn_time_ms\": 15027.568}", "{\"n\": 8483, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3752.13, \"learn_time_ms\": 15016.294}", "{\"n\": 8484, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.22, \"learn_time_ms\": 15005.648}", "{\"n\": 8485, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.66, \"learn_time_ms\": 14987.145}", "{\"n\": 8486, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.66, \"learn_time_ms\": 14997.643}", "{\"n\": 8487, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3749.14, \"learn_time_ms\": 15026.32}", "{\"n\": 8488, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3752.58, \"learn_time_ms\": 15023.775}", "{\"n\": 8489, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3752.58, \"learn_time_ms\": 15010.23}", "{\"n\": 8490, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3753.88, \"learn_time_ms\": 15001.035}", "{\"n\": 8491, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3761.85, \"learn_time_ms\": 14960.008}", "{\"n\": 8492, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.14, \"learn_time_ms\": 14960.503}", "{\"n\": 8493, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.14, \"learn_time_ms\": 14968.11}", "{\"n\": 8494, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.14, \"learn_time_ms\": 14964.793}", "{\"n\": 8495, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3778.28, \"learn_time_ms\": 14983.804}", "{\"n\": 8496, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.62, \"learn_time_ms\": 14980.76}", "{\"n\": 8497, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3783.64, \"learn_time_ms\": 14965.554}", "{\"n\": 8498, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3788.07, \"learn_time_ms\": 14956.89}", "{\"n\": 8499, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3777.85, \"learn_time_ms\": 14972.038}", "{\"n\": 8500, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3777.85, \"learn_time_ms\": 14974.236}", "{\"n\": 8501, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3777.85, \"learn_time_ms\": 15011.008}", "{\"n\": 8502, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.41, \"learn_time_ms\": 15012.776}", "{\"n\": 8503, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.41, \"learn_time_ms\": 14978.903}", "{\"n\": 8504, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3786.51, \"learn_time_ms\": 14980.691}", "{\"n\": 8505, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3788.28, \"learn_time_ms\": 14982.99}", "{\"n\": 8506, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3789.86, \"learn_time_ms\": 15000.163}", "{\"n\": 8507, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.06, \"learn_time_ms\": 15015.715}", "{\"n\": 8508, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.06, \"learn_time_ms\": 15036.497}", "{\"n\": 8509, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3787.87, \"learn_time_ms\": 15025.761}", "{\"n\": 8510, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3787.87, \"learn_time_ms\": 15026.444}", "{\"n\": 8511, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.64, \"learn_time_ms\": 15014.948}", "{\"n\": 8512, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3794.53, \"learn_time_ms\": 14996.904}", "{\"n\": 8513, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3806.31, \"learn_time_ms\": 15024.374}", "{\"n\": 8514, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3799.3, \"learn_time_ms\": 15028.397}", "{\"n\": 8515, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3799.3, \"learn_time_ms\": 15021.713}", "{\"n\": 8516, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.57, \"learn_time_ms\": 14986.484}", "{\"n\": 8517, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3790.52, \"learn_time_ms\": 14985.953}", "{\"n\": 8518, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3823.51, \"learn_time_ms\": 14972.334}", "{\"n\": 8519, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3831.8, \"learn_time_ms\": 14983.597}", "{\"n\": 8520, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3831.8, \"learn_time_ms\": 14993.353}", "{\"n\": 8521, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3830.17, \"learn_time_ms\": 15009.721}", "{\"n\": 8522, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3830.17, \"learn_time_ms\": 15018.11}", "{\"n\": 8523, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3842.37, \"learn_time_ms\": 15022.05}", "{\"n\": 8524, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3841.93, \"learn_time_ms\": 15020.011}", "{\"n\": 8525, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.11, \"learn_time_ms\": 15029.801}", "{\"n\": 8526, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.11, \"learn_time_ms\": 15044.427}", "{\"n\": 8527, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.11, \"learn_time_ms\": 15037.652}", "{\"n\": 8528, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3857.21, \"learn_time_ms\": 15015.532}", "{\"n\": 8529, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.38, \"learn_time_ms\": 14998.199}", "{\"n\": 8530, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3856.22, \"learn_time_ms\": 14979.371}", "{\"n\": 8531, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3852.99, \"learn_time_ms\": 14971.592}", "{\"n\": 8532, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3849.15, \"learn_time_ms\": 14970.189}", "{\"n\": 8533, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3849.15, \"learn_time_ms\": 14967.275}", "{\"n\": 8534, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3849.15, \"learn_time_ms\": 14971.671}", "{\"n\": 8535, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3856.18, \"learn_time_ms\": 14962.763}", "{\"n\": 8536, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3857.37, \"learn_time_ms\": 14951.53}", "{\"n\": 8537, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3857.76, \"learn_time_ms\": 14925.258}", "{\"n\": 8538, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3859.29, \"learn_time_ms\": 14937.679}", "{\"n\": 8539, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3859.29, \"learn_time_ms\": 14940.195}", "{\"n\": 8540, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3859.29, \"learn_time_ms\": 14937.221}", "{\"n\": 8541, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3862.4, \"learn_time_ms\": 14937.193}", "{\"n\": 8542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3873.19, \"learn_time_ms\": 14941.479}", "{\"n\": 8543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3871.51, \"learn_time_ms\": 14932.236}", "{\"n\": 8544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3868.06, \"learn_time_ms\": 14925.327}", "{\"n\": 8545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3868.06, \"learn_time_ms\": 14920.903}", "{\"n\": 8546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3860.32, \"learn_time_ms\": 14945.664}", "{\"n\": 8547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3860.32, \"learn_time_ms\": 14985.534}", "{\"n\": 8548, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3872.83, \"learn_time_ms\": 14996.065}", "{\"n\": 8549, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3885.8, \"learn_time_ms\": 14997.846}", "{\"n\": 8550, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3896.89, \"learn_time_ms\": 15005.101}", "{\"n\": 8551, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3909.03, \"learn_time_ms\": 14999.869}", "{\"n\": 8552, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3909.03, \"learn_time_ms\": 14988.142}", "{\"n\": 8553, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3899.68, \"learn_time_ms\": 15007.182}", "{\"n\": 8554, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3898.47, \"learn_time_ms\": 15020.945}", "{\"n\": 8555, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3886.04, \"learn_time_ms\": 15024.167}", "{\"n\": 8556, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3893.12, \"learn_time_ms\": 14996.457}", "{\"n\": 8557, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3897.57, \"learn_time_ms\": 14980.701}", "{\"n\": 8558, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3897.57, \"learn_time_ms\": 14971.387}", "{\"n\": 8559, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3885.75, \"learn_time_ms\": 14971.139}", "{\"n\": 8560, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3885.75, \"learn_time_ms\": 14984.571}", "{\"n\": 8561, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3897.89, \"learn_time_ms\": 14986.215}", "{\"n\": 8562, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3902.89, \"learn_time_ms\": 14999.224}", "{\"n\": 8563, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3902.67, \"learn_time_ms\": 15006.67}", "{\"n\": 8564, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3913.24, \"learn_time_ms\": 15013.704}", "{\"n\": 8565, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3913.24, \"learn_time_ms\": 15019.111}", "{\"n\": 8566, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3901.05, \"learn_time_ms\": 15051.076}", "{\"n\": 8567, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3898.4, \"learn_time_ms\": 15058.999}", "{\"n\": 8568, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3898.4, \"learn_time_ms\": 15057.158}", "{\"n\": 8569, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3891.58, \"learn_time_ms\": 15050.343}", "{\"n\": 8570, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3903.86, \"learn_time_ms\": 15044.849}", "{\"n\": 8571, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3903.86, \"learn_time_ms\": 15040.483}", "{\"n\": 8572, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3903.86, \"learn_time_ms\": 15044.449}", "{\"n\": 8573, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3909.46, \"learn_time_ms\": 15031.286}", "{\"n\": 8574, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3888.92, \"learn_time_ms\": 15021.464}", "{\"n\": 8575, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3895.19, \"learn_time_ms\": 14988.335}", "{\"n\": 8576, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3883.35, \"learn_time_ms\": 14986.353}", "{\"n\": 8577, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3882.6, \"learn_time_ms\": 14990.575}", "{\"n\": 8578, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3878.96, \"learn_time_ms\": 15004.884}", "{\"n\": 8579, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3878.68, \"learn_time_ms\": 15018.358}", "{\"n\": 8580, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3873.64, \"learn_time_ms\": 15007.107}", "{\"n\": 8581, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3873.64, \"learn_time_ms\": 15003.746}", "{\"n\": 8582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3867.93, \"learn_time_ms\": 14991.746}", "{\"n\": 8583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3867.8, \"learn_time_ms\": 14980.358}", "{\"n\": 8584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3867.8, \"learn_time_ms\": 14980.507}", "{\"n\": 8585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3862.11, \"learn_time_ms\": 15009.022}", "{\"n\": 8586, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3861.04, \"learn_time_ms\": 14980.065}", "{\"n\": 8587, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3854.79, \"learn_time_ms\": 14974.106}", "{\"n\": 8588, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3856.58, \"learn_time_ms\": 14960.432}", "{\"n\": 8589, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3856.58, \"learn_time_ms\": 14962.476}", "{\"n\": 8590, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3850.94, \"learn_time_ms\": 14971.426}", "{\"n\": 8591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3849.78, \"learn_time_ms\": 14968.738}", "{\"n\": 8592, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3844.63, \"learn_time_ms\": 14978.152}", "{\"n\": 8593, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3849.04, \"learn_time_ms\": 14993.995}", "{\"n\": 8594, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3856.99, \"learn_time_ms\": 14996.742}", "{\"n\": 8595, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3856.99, \"learn_time_ms\": 15005.005}", "{\"n\": 8596, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3865.77, \"learn_time_ms\": 15014.341}", "{\"n\": 8597, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3839.81, \"learn_time_ms\": 15027.684}", "{\"n\": 8598, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3818.21, \"learn_time_ms\": 15035.768}", "{\"n\": 8599, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3818.21, \"learn_time_ms\": 15019.425}", "{\"n\": 8600, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3813.34, \"learn_time_ms\": 15023.614}", "{\"n\": 8601, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3807.02, \"learn_time_ms\": 15027.109}", "{\"n\": 8602, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.54, \"learn_time_ms\": 15007.489}", "{\"n\": 8603, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.12, \"learn_time_ms\": 14995.026}", "{\"n\": 8604, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3785.61, \"learn_time_ms\": 14993.562}", "{\"n\": 8605, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3784.15, \"learn_time_ms\": 14991.56}", "{\"n\": 8606, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.8, \"learn_time_ms\": 15008.405}", "{\"n\": 8607, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3794.57, \"learn_time_ms\": 14992.623}", "{\"n\": 8608, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3786.05, \"learn_time_ms\": 15007.414}", "{\"n\": 8609, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3786.05, \"learn_time_ms\": 14996.775}", "{\"n\": 8610, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3786.6, \"learn_time_ms\": 15002.102}", "{\"n\": 8611, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3782.26, \"learn_time_ms\": 15000.33}", "{\"n\": 8612, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3782.26, \"learn_time_ms\": 15014.696}", "{\"n\": 8613, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3785.17, \"learn_time_ms\": 15022.968}", "{\"n\": 8614, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3785.17, \"learn_time_ms\": 15017.642}", "{\"n\": 8615, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3773.43, \"learn_time_ms\": 15030.566}", "{\"n\": 8616, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3763.18, \"learn_time_ms\": 15011.291}", "{\"n\": 8617, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3742.0, \"learn_time_ms\": 15005.773}", "{\"n\": 8618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3745.05, \"learn_time_ms\": 14992.504}", "{\"n\": 8619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3745.05, \"learn_time_ms\": 15019.529}", "{\"n\": 8620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3737.6, \"learn_time_ms\": 15011.8}", "{\"n\": 8621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3753.8, \"learn_time_ms\": 15028.445}", "{\"n\": 8622, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3753.8, \"learn_time_ms\": 15034.281}", "{\"n\": 8623, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3764.8, \"learn_time_ms\": 15041.541}", "{\"n\": 8624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3774.0, \"learn_time_ms\": 15042.455}", "{\"n\": 8625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3780.26, \"learn_time_ms\": 15025.979}", "{\"n\": 8626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3780.26, \"learn_time_ms\": 15036.57}", "{\"n\": 8627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3780.26, \"learn_time_ms\": 15037.333}", "{\"n\": 8628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3767.61, \"learn_time_ms\": 15042.426}", "{\"n\": 8629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3770.93, \"learn_time_ms\": 15037.526}", "{\"n\": 8630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3770.93, \"learn_time_ms\": 15035.132}", "{\"n\": 8631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3774.8, \"learn_time_ms\": 15028.472}", "{\"n\": 8632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3774.8, \"learn_time_ms\": 15017.975}", "{\"n\": 8633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3779.01, \"learn_time_ms\": 15013.545}", "{\"n\": 8634, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3777.05, \"learn_time_ms\": 15010.087}", "{\"n\": 8635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3761.1, \"learn_time_ms\": 15012.307}", "{\"n\": 8636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3761.49, \"learn_time_ms\": 14979.42}", "{\"n\": 8637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3751.76, \"learn_time_ms\": 14958.17}", "{\"n\": 8638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3751.76, \"learn_time_ms\": 14944.957}", "{\"n\": 8639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3742.99, \"learn_time_ms\": 14941.188}", "{\"n\": 8640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3743.88, \"learn_time_ms\": 14932.215}", "{\"n\": 8641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3729.17, \"learn_time_ms\": 14939.239}", "{\"n\": 8642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3729.17, \"learn_time_ms\": 14940.937}", "{\"n\": 8643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3735.73, \"learn_time_ms\": 14929.244}", "{\"n\": 8644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3734.89, \"learn_time_ms\": 14927.291}", "{\"n\": 8645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3728.94, \"learn_time_ms\": 14916.554}", "{\"n\": 8646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3716.86, \"learn_time_ms\": 14930.142}", "{\"n\": 8647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3708.45, \"learn_time_ms\": 14945.843}", "{\"n\": 8648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3706.26, \"learn_time_ms\": 14960.822}", "{\"n\": 8649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3711.37, \"learn_time_ms\": 14967.078}", "{\"n\": 8650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3711.37, \"learn_time_ms\": 14980.596}", "{\"n\": 8651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3698.99, \"learn_time_ms\": 14973.422}", "{\"n\": 8652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3699.81, \"learn_time_ms\": 14970.673}", "{\"n\": 8653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3705.84, \"learn_time_ms\": 14976.845}", "{\"n\": 8654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3703.12, \"learn_time_ms\": 14963.774}", "{\"n\": 8655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3703.12, \"learn_time_ms\": 14968.443}", "{\"n\": 8656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3697.46, \"learn_time_ms\": 14983.665}", "{\"n\": 8657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3698.9, \"learn_time_ms\": 14990.452}", "{\"n\": 8658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3698.9, \"learn_time_ms\": 14992.488}", "{\"n\": 8659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3695.46, \"learn_time_ms\": 14996.819}", "{\"n\": 8660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3685.36, \"learn_time_ms\": 14992.66}", "{\"n\": 8661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3694.14, \"learn_time_ms\": 14952.566}", "{\"n\": 8662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3695.88, \"learn_time_ms\": 14959.467}", "{\"n\": 8663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3686.59, \"learn_time_ms\": 14964.088}", "{\"n\": 8664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3680.9, \"learn_time_ms\": 14986.458}", "{\"n\": 8665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3688.38, \"learn_time_ms\": 14986.688}", "{\"n\": 8666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3689.81, \"learn_time_ms\": 14985.842}", "{\"n\": 8667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3689.81, \"learn_time_ms\": 14966.49}", "{\"n\": 8668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3690.14, \"learn_time_ms\": 14956.338}", "{\"n\": 8669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3687.96, \"learn_time_ms\": 14924.561}", "{\"n\": 8670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3694.04, \"learn_time_ms\": 14932.294}", "{\"n\": 8671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3689.87, \"learn_time_ms\": 14961.058}", "{\"n\": 8672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3679.79, \"learn_time_ms\": 14958.036}", "{\"n\": 8673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3681.44, \"learn_time_ms\": 14957.637}", "{\"n\": 8674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3698.09, \"learn_time_ms\": 14952.319}", "{\"n\": 8675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3744.44, \"learn_time_ms\": 14953.971}", "{\"n\": 8676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3744.27, \"learn_time_ms\": 14964.263}", "{\"n\": 8677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3746.38, \"learn_time_ms\": 14988.376}", "{\"n\": 8678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3746.38, \"learn_time_ms\": 14981.849}", "{\"n\": 8679, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3758.36, \"learn_time_ms\": 15020.879}", "{\"n\": 8680, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3758.83, \"learn_time_ms\": 15020.517}", "{\"n\": 8681, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3753.53, \"learn_time_ms\": 15020.098}", "{\"n\": 8682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3750.19, \"learn_time_ms\": 15037.752}", "{\"n\": 8683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3738.41, \"learn_time_ms\": 15000.992}", "{\"n\": 8684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.66, \"learn_time_ms\": 15017.584}", "{\"n\": 8685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3733.74, \"learn_time_ms\": 15018.339}", "{\"n\": 8686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3734.64, \"learn_time_ms\": 14990.864}", "{\"n\": 8687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3734.64, \"learn_time_ms\": 14991.232}", "{\"n\": 8688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3736.68, \"learn_time_ms\": 14975.515}", "{\"n\": 8689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3730.06, \"learn_time_ms\": 14968.82}", "{\"n\": 8690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3730.06, \"learn_time_ms\": 14968.544}", "{\"n\": 8691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3732.49, \"learn_time_ms\": 14980.949}", "{\"n\": 8692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3741.98, \"learn_time_ms\": 14964.156}", "{\"n\": 8693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3741.98, \"learn_time_ms\": 14985.58}", "{\"n\": 8694, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3760.04, \"learn_time_ms\": 14971.588}", "{\"n\": 8695, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3774.17, \"learn_time_ms\": 14974.378}", "{\"n\": 8696, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3770.82, \"learn_time_ms\": 15000.319}", "{\"n\": 8697, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3767.63, \"learn_time_ms\": 15005.746}", "{\"n\": 8698, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3757.2, \"learn_time_ms\": 15008.755}", "{\"n\": 8699, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3757.2, \"learn_time_ms\": 15002.971}", "{\"n\": 8700, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3757.2, \"learn_time_ms\": 14991.459}", "{\"n\": 8701, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3725.62, \"learn_time_ms\": 14992.368}", "{\"n\": 8702, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3723.23, \"learn_time_ms\": 14998.635}", "{\"n\": 8703, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.6, \"learn_time_ms\": 15007.433}", "{\"n\": 8704, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.6, \"learn_time_ms\": 14989.951}", "{\"n\": 8705, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3730.14, \"learn_time_ms\": 14985.83}", "{\"n\": 8706, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3724.09, \"learn_time_ms\": 14981.076}", "{\"n\": 8707, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3724.09, \"learn_time_ms\": 14963.203}", "{\"n\": 8708, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3737.75, \"learn_time_ms\": 14992.075}", "{\"n\": 8709, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3723.54, \"learn_time_ms\": 14990.027}", "{\"n\": 8710, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3723.54, \"learn_time_ms\": 14997.389}", "{\"n\": 8711, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3722.72, \"learn_time_ms\": 15003.102}", "{\"n\": 8712, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.3, \"learn_time_ms\": 14998.191}", "{\"n\": 8713, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.3, \"learn_time_ms\": 15006.675}", "{\"n\": 8714, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3721.39, \"learn_time_ms\": 15027.319}", "{\"n\": 8715, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3747.78, \"learn_time_ms\": 15035.053}", "{\"n\": 8716, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3747.78, \"learn_time_ms\": 15026.15}", "{\"n\": 8717, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3748.87, \"learn_time_ms\": 15040.203}", "{\"n\": 8718, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3745.27, \"learn_time_ms\": 15037.054}", "{\"n\": 8719, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3748.95, \"learn_time_ms\": 15032.764}", "{\"n\": 8720, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3772.9, \"learn_time_ms\": 15022.676}", "{\"n\": 8721, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3762.82, \"learn_time_ms\": 15001.325}", "{\"n\": 8722, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3766.07, \"learn_time_ms\": 15008.969}", "{\"n\": 8723, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3781.35, \"learn_time_ms\": 14992.612}", "{\"n\": 8724, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3781.35, \"learn_time_ms\": 14991.15}", "{\"n\": 8725, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3776.71, \"learn_time_ms\": 15001.828}", "{\"n\": 8726, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3757.63, \"learn_time_ms\": 15001.65}", "{\"n\": 8727, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.31, \"learn_time_ms\": 14983.824}", "{\"n\": 8728, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.31, \"learn_time_ms\": 14994.204}", "{\"n\": 8729, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.06, \"learn_time_ms\": 15001.477}", "{\"n\": 8730, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.06, \"learn_time_ms\": 15006.437}", "{\"n\": 8731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.75, \"learn_time_ms\": 15009.664}", "{\"n\": 8732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3773.72, \"learn_time_ms\": 15008.972}", "{\"n\": 8733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3776.74, \"learn_time_ms\": 15018.249}", "{\"n\": 8734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3776.74, \"learn_time_ms\": 15017.989}", "{\"n\": 8735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3791.37, \"learn_time_ms\": 15010.844}", "{\"n\": 8736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3785.79, \"learn_time_ms\": 15004.893}", "{\"n\": 8737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3785.79, \"learn_time_ms\": 15015.55}", "{\"n\": 8738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.46, \"learn_time_ms\": 15009.303}", "{\"n\": 8739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.46, \"learn_time_ms\": 15004.591}", "{\"n\": 8740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.48, \"learn_time_ms\": 15008.513}", "{\"n\": 8741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.48, \"learn_time_ms\": 15024.338}", "{\"n\": 8742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.48, \"learn_time_ms\": 15021.14}", "{\"n\": 8743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.48, \"learn_time_ms\": 15024.784}", "{\"n\": 8744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3780.55, \"learn_time_ms\": 15024.071}", "{\"n\": 8745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.48, \"learn_time_ms\": 15026.171}", "{\"n\": 8746, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3776.13, \"learn_time_ms\": 15041.641}", "{\"n\": 8747, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.27, \"learn_time_ms\": 15046.186}", "{\"n\": 8748, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.27, \"learn_time_ms\": 15036.185}", "{\"n\": 8749, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.27, \"learn_time_ms\": 15041.85}", "{\"n\": 8750, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.27, \"learn_time_ms\": 15008.736}", "{\"n\": 8751, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.17, \"learn_time_ms\": 14997.834}", "{\"n\": 8752, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3764.81, \"learn_time_ms\": 14996.852}", "{\"n\": 8753, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3765.2, \"learn_time_ms\": 14989.577}", "{\"n\": 8754, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3765.2, \"learn_time_ms\": 14991.361}", "{\"n\": 8755, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3763.34, \"learn_time_ms\": 14991.905}", "{\"n\": 8756, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3762.62, \"learn_time_ms\": 14991.357}", "{\"n\": 8757, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.59, \"learn_time_ms\": 14986.915}", "{\"n\": 8758, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3772.33, \"learn_time_ms\": 14991.396}", "{\"n\": 8759, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.8, \"learn_time_ms\": 14984.108}", "{\"n\": 8760, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.8, \"learn_time_ms\": 14999.801}", "{\"n\": 8761, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.8, \"learn_time_ms\": 15010.0}", "{\"n\": 8762, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.8, \"learn_time_ms\": 15004.891}", "{\"n\": 8763, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.8, \"learn_time_ms\": 15007.344}", "{\"n\": 8764, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3794.42, \"learn_time_ms\": 14982.934}", "{\"n\": 8765, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.97, \"learn_time_ms\": 14968.072}", "{\"n\": 8766, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.84, \"learn_time_ms\": 14961.115}", "{\"n\": 8767, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.84, \"learn_time_ms\": 14964.069}", "{\"n\": 8768, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.84, \"learn_time_ms\": 14963.237}", "{\"n\": 8769, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.84, \"learn_time_ms\": 14966.631}", "{\"n\": 8770, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3795.14, \"learn_time_ms\": 14992.957}", "{\"n\": 8771, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3797.7, \"learn_time_ms\": 14990.514}", "{\"n\": 8772, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3795.24, \"learn_time_ms\": 14995.043}", "{\"n\": 8773, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3794.57, \"learn_time_ms\": 14994.616}", "{\"n\": 8774, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3794.57, \"learn_time_ms\": 15013.692}", "{\"n\": 8775, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3796.02, \"learn_time_ms\": 15014.996}", "{\"n\": 8776, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3794.38, \"learn_time_ms\": 15022.581}", "{\"n\": 8777, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3794.56, \"learn_time_ms\": 15024.366}", "{\"n\": 8778, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3794.56, \"learn_time_ms\": 15029.06}", "{\"n\": 8779, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3810.4, \"learn_time_ms\": 15014.988}", "{\"n\": 8780, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3831.87, \"learn_time_ms\": 15001.743}", "{\"n\": 8781, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3831.87, \"learn_time_ms\": 14984.51}", "{\"n\": 8782, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3824.26, \"learn_time_ms\": 14978.674}", "{\"n\": 8783, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3822.35, \"learn_time_ms\": 14984.801}", "{\"n\": 8784, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3822.35, \"learn_time_ms\": 14993.887}", "{\"n\": 8785, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3828.96, \"learn_time_ms\": 15003.526}", "{\"n\": 8786, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3828.47, \"learn_time_ms\": 15003.712}", "{\"n\": 8787, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3828.47, \"learn_time_ms\": 15004.541}", "{\"n\": 8788, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3823.59, \"learn_time_ms\": 14995.329}", "{\"n\": 8789, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3823.59, \"learn_time_ms\": 15022.315}", "{\"n\": 8790, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3824.28, \"learn_time_ms\": 15027.465}", "{\"n\": 8791, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3826.69, \"learn_time_ms\": 15038.741}", "{\"n\": 8792, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3835.07, \"learn_time_ms\": 15048.359}", "{\"n\": 8793, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3826.26, \"learn_time_ms\": 15038.722}", "{\"n\": 8794, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3826.26, \"learn_time_ms\": 15029.105}", "{\"n\": 8795, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3825.22, \"learn_time_ms\": 15036.575}", "{\"n\": 8796, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3831.18, \"learn_time_ms\": 15032.025}", "{\"n\": 8797, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3807.12, \"learn_time_ms\": 14984.752}", "{\"n\": 8798, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3807.79, \"learn_time_ms\": 14981.456}", "{\"n\": 8799, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3807.79, \"learn_time_ms\": 14950.211}", "{\"n\": 8800, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3800.2, \"learn_time_ms\": 14949.621}", "{\"n\": 8801, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3807.23, \"learn_time_ms\": 14926.555}", "{\"n\": 8802, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3807.23, \"learn_time_ms\": 14919.607}", "{\"n\": 8803, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3798.47, \"learn_time_ms\": 14897.643}", "{\"n\": 8804, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3796.35, \"learn_time_ms\": 14882.107}", "{\"n\": 8805, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3805.89, \"learn_time_ms\": 14871.32}", "{\"n\": 8806, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3805.89, \"learn_time_ms\": 14870.475}", "{\"n\": 8807, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3809.68, \"learn_time_ms\": 14921.105}", "{\"n\": 8808, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3809.68, \"learn_time_ms\": 14915.327}", "{\"n\": 8809, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.99, \"learn_time_ms\": 14941.073}", "{\"n\": 8810, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3793.01, \"learn_time_ms\": 14945.209}", "{\"n\": 8811, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.3, \"learn_time_ms\": 14966.05}", "{\"n\": 8812, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.3, \"learn_time_ms\": 14958.804}", "{\"n\": 8813, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3797.18, \"learn_time_ms\": 14982.061}", "{\"n\": 8814, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3797.18, \"learn_time_ms\": 14995.787}", "{\"n\": 8815, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3793.28, \"learn_time_ms\": 14987.569}", "{\"n\": 8816, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3810.98, \"learn_time_ms\": 14976.862}", "{\"n\": 8817, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3814.02, \"learn_time_ms\": 14968.495}", "{\"n\": 8818, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3814.02, \"learn_time_ms\": 14958.233}", "{\"n\": 8819, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3820.22, \"learn_time_ms\": 14953.31}", "{\"n\": 8820, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3820.71, \"learn_time_ms\": 14945.363}", "{\"n\": 8821, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3820.71, \"learn_time_ms\": 14941.756}", "{\"n\": 8822, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3822.77, \"learn_time_ms\": 14954.82}", "{\"n\": 8823, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3818.05, \"learn_time_ms\": 14944.916}", "{\"n\": 8824, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3831.8, \"learn_time_ms\": 14952.178}", "{\"n\": 8825, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3831.8, \"learn_time_ms\": 14958.84}", "{\"n\": 8826, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3822.35, \"learn_time_ms\": 14962.749}", "{\"n\": 8827, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3822.35, \"learn_time_ms\": 14959.716}", "{\"n\": 8828, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3822.42, \"learn_time_ms\": 14982.231}", "{\"n\": 8829, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3830.28, \"learn_time_ms\": 14975.033}", "{\"n\": 8830, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3821.49, \"learn_time_ms\": 14980.606}", "{\"n\": 8831, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3825.67, \"learn_time_ms\": 14983.164}", "{\"n\": 8832, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3825.67, \"learn_time_ms\": 14978.469}", "{\"n\": 8833, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3823.5, \"learn_time_ms\": 14993.088}", "{\"n\": 8834, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3827.46, \"learn_time_ms\": 14998.237}", "{\"n\": 8835, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3821.95, \"learn_time_ms\": 15014.371}", "{\"n\": 8836, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3810.25, \"learn_time_ms\": 15028.559}", "{\"n\": 8837, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3810.75, \"learn_time_ms\": 15038.473}", "{\"n\": 8838, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3813.49, \"learn_time_ms\": 15011.554}", "{\"n\": 8839, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3813.49, \"learn_time_ms\": 15013.349}", "{\"n\": 8840, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3823.55, \"learn_time_ms\": 15016.304}", "{\"n\": 8841, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3823.59, \"learn_time_ms\": 15016.033}", "{\"n\": 8842, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3832.84, \"learn_time_ms\": 15018.031}", "{\"n\": 8843, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3832.84, \"learn_time_ms\": 15015.221}", "{\"n\": 8844, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3832.84, \"learn_time_ms\": 15009.74}", "{\"n\": 8845, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3832.9, \"learn_time_ms\": 14999.468}", "{\"n\": 8846, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3821.56, \"learn_time_ms\": 14996.083}", "{\"n\": 8847, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3815.51, \"learn_time_ms\": 14984.369}", "{\"n\": 8848, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.01, \"learn_time_ms\": 15012.626}", "{\"n\": 8849, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.08, \"learn_time_ms\": 15013.819}", "{\"n\": 8850, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3827.57, \"learn_time_ms\": 15014.045}", "{\"n\": 8851, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3827.57, \"learn_time_ms\": 15031.41}", "{\"n\": 8852, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3827.57, \"learn_time_ms\": 15028.729}", "{\"n\": 8853, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3821.81, \"learn_time_ms\": 15028.516}", "{\"n\": 8854, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3827.29, \"learn_time_ms\": 15001.302}", "{\"n\": 8855, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3827.29, \"learn_time_ms\": 14990.747}", "{\"n\": 8856, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3831.07, \"learn_time_ms\": 14985.266}", "{\"n\": 8857, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3833.2, \"learn_time_ms\": 14987.673}", "{\"n\": 8858, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3813.77, \"learn_time_ms\": 14997.982}", "{\"n\": 8859, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3813.77, \"learn_time_ms\": 15008.459}", "{\"n\": 8860, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3803.69, \"learn_time_ms\": 15006.48}", "{\"n\": 8861, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3827.77, \"learn_time_ms\": 15005.825}", "{\"n\": 8862, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3827.77, \"learn_time_ms\": 15004.873}", "{\"n\": 8863, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3797.47, \"learn_time_ms\": 15012.761}", "{\"n\": 8864, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3791.38, \"learn_time_ms\": 15041.02}", "{\"n\": 8865, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3791.38, \"learn_time_ms\": 15040.11}", "{\"n\": 8866, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.07, \"learn_time_ms\": 15045.11}", "{\"n\": 8867, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3797.07, \"learn_time_ms\": 15044.408}", "{\"n\": 8868, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3796.28, \"learn_time_ms\": 15021.88}", "{\"n\": 8869, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3793.8, \"learn_time_ms\": 15002.464}", "{\"n\": 8870, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.54, \"learn_time_ms\": 14991.884}", "{\"n\": 8871, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3776.37, \"learn_time_ms\": 14979.25}", "{\"n\": 8872, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.42, \"learn_time_ms\": 14982.165}", "{\"n\": 8873, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.89, \"learn_time_ms\": 14961.446}", "{\"n\": 8874, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.89, \"learn_time_ms\": 14958.166}", "{\"n\": 8875, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.89, \"learn_time_ms\": 14959.335}", "{\"n\": 8876, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3792.86, \"learn_time_ms\": 14929.225}", "{\"n\": 8877, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3805.41, \"learn_time_ms\": 14924.013}", "{\"n\": 8878, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3795.11, \"learn_time_ms\": 14944.065}", "{\"n\": 8879, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3781.92, \"learn_time_ms\": 14957.759}", "{\"n\": 8880, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3781.92, \"learn_time_ms\": 14944.961}", "{\"n\": 8881, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3781.92, \"learn_time_ms\": 14939.478}", "{\"n\": 8882, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3781.92, \"learn_time_ms\": 14940.664}", "{\"n\": 8883, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.05, \"learn_time_ms\": 14956.542}", "{\"n\": 8884, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3798.42, \"learn_time_ms\": 14954.327}", "{\"n\": 8885, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.99, \"learn_time_ms\": 14952.532}", "{\"n\": 8886, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.99, \"learn_time_ms\": 14941.929}", "{\"n\": 8887, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.99, \"learn_time_ms\": 14955.756}", "{\"n\": 8888, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3823.04, \"learn_time_ms\": 14938.113}", "{\"n\": 8889, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3815.83, \"learn_time_ms\": 14930.566}", "{\"n\": 8890, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3821.35, \"learn_time_ms\": 14956.528}", "{\"n\": 8891, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3818.94, \"learn_time_ms\": 14969.773}", "{\"n\": 8892, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3820.4, \"learn_time_ms\": 14969.819}", "{\"n\": 8893, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3820.4, \"learn_time_ms\": 14950.628}", "{\"n\": 8894, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3820.4, \"learn_time_ms\": 14953.183}", "{\"n\": 8895, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.74, \"learn_time_ms\": 14953.246}", "{\"n\": 8896, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3797.7, \"learn_time_ms\": 15006.233}", "{\"n\": 8897, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3796.17, \"learn_time_ms\": 15009.233}", "{\"n\": 8898, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3798.81, \"learn_time_ms\": 15012.481}", "{\"n\": 8899, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3801.16, \"learn_time_ms\": 15005.69}", "{\"n\": 8900, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3801.16, \"learn_time_ms\": 14986.168}", "{\"n\": 8901, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3795.96, \"learn_time_ms\": 14974.998}", "{\"n\": 8902, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3797.11, \"learn_time_ms\": 14971.438}", "{\"n\": 8903, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3806.1, \"learn_time_ms\": 14972.758}", "{\"n\": 8904, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3803.08, \"learn_time_ms\": 14977.492}", "{\"n\": 8905, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3803.08, \"learn_time_ms\": 14981.23}", "{\"n\": 8906, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3800.29, \"learn_time_ms\": 14976.945}", "{\"n\": 8907, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3800.29, \"learn_time_ms\": 14965.732}", "{\"n\": 8908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3798.06, \"learn_time_ms\": 14976.002}", "{\"n\": 8909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.05, \"learn_time_ms\": 14985.745}", "{\"n\": 8910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.05, \"learn_time_ms\": 14999.12}", "{\"n\": 8911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3801.66, \"learn_time_ms\": 15006.556}", "{\"n\": 8912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3801.66, \"learn_time_ms\": 15003.637}", "{\"n\": 8913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.6, \"learn_time_ms\": 15017.506}", "{\"n\": 8914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.6, \"learn_time_ms\": 15025.067}", "{\"n\": 8915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.6, \"learn_time_ms\": 15026.208}", "{\"n\": 8916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.04, \"learn_time_ms\": 15014.309}", "{\"n\": 8917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.43, \"learn_time_ms\": 15027.606}", "{\"n\": 8918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.92, \"learn_time_ms\": 15011.174}", "{\"n\": 8919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.92, \"learn_time_ms\": 15015.838}", "{\"n\": 8920, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3773.5, \"learn_time_ms\": 15004.873}", "{\"n\": 8921, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.68, \"learn_time_ms\": 15007.207}", "{\"n\": 8922, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3782.57, \"learn_time_ms\": 14999.568}", "{\"n\": 8923, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3786.57, \"learn_time_ms\": 14993.432}", "{\"n\": 8924, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3780.86, \"learn_time_ms\": 14965.877}", "{\"n\": 8925, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3780.86, \"learn_time_ms\": 14961.907}", "{\"n\": 8926, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3780.86, \"learn_time_ms\": 14953.789}", "{\"n\": 8927, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3779.52, \"learn_time_ms\": 14947.995}", "{\"n\": 8928, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3771.99, \"learn_time_ms\": 14954.816}", "{\"n\": 8929, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3771.99, \"learn_time_ms\": 14934.14}", "{\"n\": 8930, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3767.56, \"learn_time_ms\": 14907.402}", "{\"n\": 8931, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3748.01, \"learn_time_ms\": 14852.509}", "{\"n\": 8932, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3741.7, \"learn_time_ms\": 14851.823}", "{\"n\": 8933, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3741.7, \"learn_time_ms\": 14850.516}", "{\"n\": 8934, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3748.38, \"learn_time_ms\": 14865.431}", "{\"n\": 8935, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3743.45, \"learn_time_ms\": 14866.651}", "{\"n\": 8936, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3753.83, \"learn_time_ms\": 14862.459}", "{\"n\": 8937, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3758.15, \"learn_time_ms\": 14864.793}", "{\"n\": 8938, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3757.23, \"learn_time_ms\": 14888.084}", "{\"n\": 8939, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3761.68, \"learn_time_ms\": 14901.788}", "{\"n\": 8940, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3761.68, \"learn_time_ms\": 14931.486}", "{\"n\": 8941, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3769.46, \"learn_time_ms\": 14958.509}", "{\"n\": 8942, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3769.46, \"learn_time_ms\": 14954.375}", "{\"n\": 8943, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3796.26, \"learn_time_ms\": 14954.363}", "{\"n\": 8944, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3796.26, \"learn_time_ms\": 14966.335}", "{\"n\": 8945, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3797.86, \"learn_time_ms\": 14975.975}", "{\"n\": 8946, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3797.86, \"learn_time_ms\": 14990.21}", "{\"n\": 8947, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3805.05, \"learn_time_ms\": 14985.9}", "{\"n\": 8948, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3815.08, \"learn_time_ms\": 14967.958}", "{\"n\": 8949, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3813.5, \"learn_time_ms\": 14973.139}", "{\"n\": 8950, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3829.61, \"learn_time_ms\": 14991.023}", "{\"n\": 8951, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3829.61, \"learn_time_ms\": 15006.711}", "{\"n\": 8952, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3824.61, \"learn_time_ms\": 15015.885}", "{\"n\": 8953, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3833.29, \"learn_time_ms\": 15028.976}", "{\"n\": 8954, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3833.29, \"learn_time_ms\": 15033.036}", "{\"n\": 8955, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3836.6, \"learn_time_ms\": 15031.945}", "{\"n\": 8956, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3834.37, \"learn_time_ms\": 15003.675}", "{\"n\": 8957, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3834.67, \"learn_time_ms\": 15001.642}", "{\"n\": 8958, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3834.67, \"learn_time_ms\": 15017.572}", "{\"n\": 8959, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3840.26, \"learn_time_ms\": 15021.228}", "{\"n\": 8960, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.0, \"learn_time_ms\": 15012.379}", "{\"n\": 8961, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.0, \"learn_time_ms\": 15014.932}", "{\"n\": 8962, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3841.31, \"learn_time_ms\": 15024.51}", "{\"n\": 8963, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3847.78, \"learn_time_ms\": 15026.076}", "{\"n\": 8964, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3842.19, \"learn_time_ms\": 15019.595}", "{\"n\": 8965, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3842.19, \"learn_time_ms\": 15013.1}", "{\"n\": 8966, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.27, \"learn_time_ms\": 15042.435}", "{\"n\": 8967, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3842.54, \"learn_time_ms\": 15046.662}", "{\"n\": 8968, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3828.79, \"learn_time_ms\": 15036.724}", "{\"n\": 8969, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3819.7, \"learn_time_ms\": 15035.647}", "{\"n\": 8970, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3823.66, \"learn_time_ms\": 15042.041}", "{\"n\": 8971, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3823.03, \"learn_time_ms\": 15063.795}", "{\"n\": 8972, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3823.03, \"learn_time_ms\": 15054.06}", "{\"n\": 8973, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3825.76, \"learn_time_ms\": 15050.021}", "{\"n\": 8974, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3825.76, \"learn_time_ms\": 15040.337}", "{\"n\": 8975, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3851.32, \"learn_time_ms\": 15045.224}", "{\"n\": 8976, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3855.27, \"learn_time_ms\": 15041.676}", "{\"n\": 8977, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3843.61, \"learn_time_ms\": 15034.044}", "{\"n\": 8978, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3843.61, \"learn_time_ms\": 15013.246}", "{\"n\": 8979, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3834.68, \"learn_time_ms\": 14983.214}", "{\"n\": 8980, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3834.68, \"learn_time_ms\": 14975.771}", "{\"n\": 8981, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3823.14, \"learn_time_ms\": 14962.697}", "{\"n\": 8982, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3819.88, \"learn_time_ms\": 14960.723}", "{\"n\": 8983, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3817.04, \"learn_time_ms\": 14956.647}", "{\"n\": 8984, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3831.46, \"learn_time_ms\": 14963.204}", "{\"n\": 8985, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3831.46, \"learn_time_ms\": 14964.394}", "{\"n\": 8986, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3831.46, \"learn_time_ms\": 14969.899}", "{\"n\": 8987, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3831.46, \"learn_time_ms\": 14984.533}", "{\"n\": 8988, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3830.62, \"learn_time_ms\": 14997.548}", "{\"n\": 8989, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3821.21, \"learn_time_ms\": 15033.038}", "{\"n\": 8990, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3823.4, \"learn_time_ms\": 15035.427}", "{\"n\": 8991, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3823.4, \"learn_time_ms\": 15031.234}", "{\"n\": 8992, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3823.4, \"learn_time_ms\": 15042.977}", "{\"n\": 8993, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3830.92, \"learn_time_ms\": 15052.055}", "{\"n\": 8994, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3845.18, \"learn_time_ms\": 15046.818}", "{\"n\": 8995, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3850.34, \"learn_time_ms\": 15054.291}", "{\"n\": 8996, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3851.01, \"learn_time_ms\": 15040.267}", "{\"n\": 8997, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3847.65, \"learn_time_ms\": 15030.339}", "{\"n\": 8998, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3841.74, \"learn_time_ms\": 15039.44}", "{\"n\": 8999, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3831.04, \"learn_time_ms\": 15040.104}", "{\"n\": 9000, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3831.04, \"learn_time_ms\": 15033.125}"]["{\"n\": 9001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15382.101}", "{\"n\": 9002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15058.887}", "{\"n\": 9003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14949.9}", "{\"n\": 9004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14887.351}", "{\"n\": 9005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14850.943}", "{\"n\": 9006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14819.168}", "{\"n\": 9007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14813.355}", "{\"n\": 9008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14793.906}", "{\"n\": 9009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14782.375}", "{\"n\": 9010, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2717.0, \"learn_time_ms\": 14776.361}", "{\"n\": 9011, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2601.0, \"learn_time_ms\": 14701.824}", "{\"n\": 9012, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.666666666666667, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3089.3333333333335, \"learn_time_ms\": 14707.012}", "{\"n\": 9013, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3172.1428571428573, \"learn_time_ms\": 14710.84}", "{\"n\": 9014, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3172.1428571428573, \"learn_time_ms\": 14705.812}", "{\"n\": 9015, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.875, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.25, \"learn_time_ms\": 14709.345}", "{\"n\": 9016, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.777777777777778, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.3333333333335, \"learn_time_ms\": 14717.513}", "{\"n\": 9017, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3427.2, \"learn_time_ms\": 14722.504}", "{\"n\": 9018, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.9166666666666665, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3471.8333333333335, \"learn_time_ms\": 14724.527}", "{\"n\": 9019, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.428571428571429, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3437.714285714286, \"learn_time_ms\": 14732.018}", "{\"n\": 9020, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.266666666666667, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3477.5333333333333, \"learn_time_ms\": 14728.658}", "{\"n\": 9021, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.875, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3541.0625, \"learn_time_ms\": 14737.901}", "{\"n\": 9022, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.611111111111111, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3451.0555555555557, \"learn_time_ms\": 14733.762}", "{\"n\": 9023, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.421052631578948, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3500.0, \"learn_time_ms\": 14735.033}", "{\"n\": 9024, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3525.85, \"learn_time_ms\": 14739.053}", "{\"n\": 9025, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3568.2727272727275, \"learn_time_ms\": 14733.693}", "{\"n\": 9026, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.391304347826087, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3607.782608695652, \"learn_time_ms\": 14726.884}", "{\"n\": 9027, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.391304347826087, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3607.782608695652, \"learn_time_ms\": 14708.605}", "{\"n\": 9028, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.888888888888889, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3566.4444444444443, \"learn_time_ms\": 14705.695}", "{\"n\": 9029, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.9285714285714284, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3563.3214285714284, \"learn_time_ms\": 14698.868}", "{\"n\": 9030, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5172413793103448, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3559.9310344827586, \"learn_time_ms\": 14694.834}", "{\"n\": 9031, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3560.8333333333335, \"learn_time_ms\": 14703.433}", "{\"n\": 9032, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3560.8333333333335, \"learn_time_ms\": 14690.802}", "{\"n\": 9033, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3560.8333333333335, \"learn_time_ms\": 14676.195}", "{\"n\": 9034, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.03125, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3568.3125, \"learn_time_ms\": 14672.807}", "{\"n\": 9035, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.085714285714286, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3578.4857142857145, \"learn_time_ms\": 14673.615}", "{\"n\": 9036, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3783783783783785, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3554.135135135135, \"learn_time_ms\": 14678.95}", "{\"n\": 9037, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4210526315789473, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3561.2368421052633, \"learn_time_ms\": 14681.893}", "{\"n\": 9038, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4210526315789473, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3561.2368421052633, \"learn_time_ms\": 14691.426}", "{\"n\": 9039, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.358974358974359, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3582.769230769231, \"learn_time_ms\": 14674.009}", "{\"n\": 9040, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.325, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3590.35, \"learn_time_ms\": 14676.369}", "{\"n\": 9041, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3095238095238093, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3619.0714285714284, \"learn_time_ms\": 14673.783}", "{\"n\": 9042, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2093023255813953, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3626.9302325581393, \"learn_time_ms\": 14678.627}", "{\"n\": 9043, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.282608695652174, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3637.413043478261, \"learn_time_ms\": 14681.922}", "{\"n\": 9044, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.282608695652174, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3637.413043478261, \"learn_time_ms\": 14691.496}", "{\"n\": 9045, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.282608695652174, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3637.413043478261, \"learn_time_ms\": 14685.689}", "{\"n\": 9046, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4166666666666665, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3626.9375, \"learn_time_ms\": 14679.58}", "{\"n\": 9047, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3137254901960786, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3653.549019607843, \"learn_time_ms\": 14689.039}", "{\"n\": 9048, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3137254901960786, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3653.549019607843, \"learn_time_ms\": 14678.273}", "{\"n\": 9049, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2641509433962264, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3672.622641509434, \"learn_time_ms\": 14699.022}", "{\"n\": 9050, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.074074074074074, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3679.574074074074, \"learn_time_ms\": 14690.378}", "{\"n\": 9051, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.074074074074074, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3679.574074074074, \"learn_time_ms\": 14686.706}", "{\"n\": 9052, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.074074074074074, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3679.574074074074, \"learn_time_ms\": 14684.955}", "{\"n\": 9053, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.263157894736842, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3670.9298245614036, \"learn_time_ms\": 14690.631}", "{\"n\": 9054, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3559322033898304, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3668.5254237288136, \"learn_time_ms\": 14694.197}", "{\"n\": 9055, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4166666666666665, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3662.516666666667, \"learn_time_ms\": 14702.379}", "{\"n\": 9056, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4754098360655736, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3658.3934426229507, \"learn_time_ms\": 14688.146}", "{\"n\": 9057, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3225806451612905, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3661.5967741935483, \"learn_time_ms\": 14685.426}", "{\"n\": 9058, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15625, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3673.203125, \"learn_time_ms\": 14689.692}", "{\"n\": 9059, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.1846153846153844, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3669.3384615384616, \"learn_time_ms\": 14681.52}", "{\"n\": 9060, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.1515151515151514, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3678.181818181818, \"learn_time_ms\": 14685.345}", "{\"n\": 9061, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.1641791044776117, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3682.223880597015, \"learn_time_ms\": 14678.119}", "{\"n\": 9062, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2058823529411766, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3680.3382352941176, \"learn_time_ms\": 14676.067}", "{\"n\": 9063, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.142857142857143, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3698.885714285714, \"learn_time_ms\": 14678.468}", "{\"n\": 9064, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9722222222222223, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3691.0, \"learn_time_ms\": 14662.971}", "{\"n\": 9065, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0273972602739727, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3686.4794520547944, \"learn_time_ms\": 14663.025}", "{\"n\": 9066, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.054054054054054, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3684.3513513513512, \"learn_time_ms\": 14684.376}", "{\"n\": 9067, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9466666666666668, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.28, \"learn_time_ms\": 14677.034}", "{\"n\": 9068, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.8684210526315788, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3692.7368421052633, \"learn_time_ms\": 14677.405}", "{\"n\": 9069, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.7564102564102564, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.653846153846, \"learn_time_ms\": 14689.42}", "{\"n\": 9070, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6455696202531644, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.9367088607596, \"learn_time_ms\": 14704.781}", "{\"n\": 9071, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6296296296296298, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.543209876543, \"learn_time_ms\": 14703.687}", "{\"n\": 9072, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.548780487804878, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.548780487805, \"learn_time_ms\": 14702.931}", "{\"n\": 9073, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.548780487804878, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.548780487805, \"learn_time_ms\": 14705.211}", "{\"n\": 9074, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.607142857142857, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3705.690476190476, \"learn_time_ms\": 14712.377}", "{\"n\": 9075, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.9882352941177, \"learn_time_ms\": 14711.48}", "{\"n\": 9076, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3709.9882352941177, \"learn_time_ms\": 14708.344}", "{\"n\": 9077, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.752808988764045, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3706.3370786516853, \"learn_time_ms\": 14707.838}", "{\"n\": 9078, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6555555555555554, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3708.588888888889, \"learn_time_ms\": 14698.551}", "{\"n\": 9079, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.7032967032967035, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3707.5164835164837, \"learn_time_ms\": 14685.537}", "{\"n\": 9080, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6956521739130435, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.445652173913, \"learn_time_ms\": 14680.181}", "{\"n\": 9081, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6956521739130435, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.445652173913, \"learn_time_ms\": 14682.462}", "{\"n\": 9082, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6956521739130435, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3714.445652173913, \"learn_time_ms\": 14691.803}", "{\"n\": 9083, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6288659793814433, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3726.2061855670104, \"learn_time_ms\": 14683.599}", "{\"n\": 9084, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6288659793814433, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3726.2061855670104, \"learn_time_ms\": 14682.587}", "{\"n\": 9085, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.6122448979591835, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3730.9897959183672, \"learn_time_ms\": 14691.791}", "{\"n\": 9086, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.707070707070707, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3720.5757575757575, \"learn_time_ms\": 14699.538}", "{\"n\": 9087, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3716.17, \"learn_time_ms\": 14698.656}", "{\"n\": 9088, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3716.17, \"learn_time_ms\": 14710.021}", "{\"n\": 9089, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3723.89, \"learn_time_ms\": 14727.094}", "{\"n\": 9090, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3750.03, \"learn_time_ms\": 14725.151}", "{\"n\": 9091, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3768.22, \"learn_time_ms\": 14726.635}", "{\"n\": 9092, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3768.22, \"learn_time_ms\": 14730.133}", "{\"n\": 9093, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3765.54, \"learn_time_ms\": 14724.589}", "{\"n\": 9094, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3765.54, \"learn_time_ms\": 14729.744}", "{\"n\": 9095, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3760.62, \"learn_time_ms\": 14716.724}", "{\"n\": 9096, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3767.53, \"learn_time_ms\": 14707.288}", "{\"n\": 9097, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3781.93, \"learn_time_ms\": 14704.129}", "{\"n\": 9098, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3778.66, \"learn_time_ms\": 14703.699}", "{\"n\": 9099, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3772.17, \"learn_time_ms\": 14695.09}", "{\"n\": 9100, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3772.17, \"learn_time_ms\": 14689.303}", "{\"n\": 9101, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3782.4, \"learn_time_ms\": 14683.933}", "{\"n\": 9102, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3789.46, \"learn_time_ms\": 14685.789}", "{\"n\": 9103, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3781.04, \"learn_time_ms\": 14691.996}", "{\"n\": 9104, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3781.04, \"learn_time_ms\": 14687.268}", "{\"n\": 9105, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3780.26, \"learn_time_ms\": 14680.555}", "{\"n\": 9106, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3780.26, \"learn_time_ms\": 14679.816}", "{\"n\": 9107, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3788.28, \"learn_time_ms\": 14676.76}", "{\"n\": 9108, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3788.28, \"learn_time_ms\": 14677.147}", "{\"n\": 9109, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3802.27, \"learn_time_ms\": 14679.183}", "{\"n\": 9110, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3816.59, \"learn_time_ms\": 14686.177}", "{\"n\": 9111, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3817.74, \"learn_time_ms\": 14687.304}", "{\"n\": 9112, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3816.87, \"learn_time_ms\": 14674.09}", "{\"n\": 9113, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3816.87, \"learn_time_ms\": 14664.625}", "{\"n\": 9114, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3818.88, \"learn_time_ms\": 14659.968}", "{\"n\": 9115, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3818.88, \"learn_time_ms\": 14671.339}", "{\"n\": 9116, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3828.59, \"learn_time_ms\": 14682.518}", "{\"n\": 9117, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3831.5, \"learn_time_ms\": 14690.69}", "{\"n\": 9118, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3824.97, \"learn_time_ms\": 14691.871}", "{\"n\": 9119, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3815.29, \"learn_time_ms\": 14687.265}", "{\"n\": 9120, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3811.15, \"learn_time_ms\": 14687.066}", "{\"n\": 9121, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3801.18, \"learn_time_ms\": 14693.946}", "{\"n\": 9122, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3799.92, \"learn_time_ms\": 14695.994}", "{\"n\": 9123, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3811.23, \"learn_time_ms\": 14712.281}", "{\"n\": 9124, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3819.85, \"learn_time_ms\": 14711.717}", "{\"n\": 9125, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3819.85, \"learn_time_ms\": 14718.35}", "{\"n\": 9126, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3808.46, \"learn_time_ms\": 14717.288}", "{\"n\": 9127, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3809.87, \"learn_time_ms\": 14708.877}", "{\"n\": 9128, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3798.39, \"learn_time_ms\": 14712.003}", "{\"n\": 9129, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3800.71, \"learn_time_ms\": 14716.58}", "{\"n\": 9130, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3800.51, \"learn_time_ms\": 14714.57}", "{\"n\": 9131, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3808.14, \"learn_time_ms\": 14717.885}", "{\"n\": 9132, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3814.72, \"learn_time_ms\": 14725.933}", "{\"n\": 9133, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3814.83, \"learn_time_ms\": 14730.506}", "{\"n\": 9134, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3814.83, \"learn_time_ms\": 14741.577}", "{\"n\": 9135, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3813.2, \"learn_time_ms\": 14728.417}", "{\"n\": 9136, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3801.37, \"learn_time_ms\": 14708.571}", "{\"n\": 9137, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3799.96, \"learn_time_ms\": 14725.249}", "{\"n\": 9138, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3799.96, \"learn_time_ms\": 14712.087}", "{\"n\": 9139, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3782.25, \"learn_time_ms\": 14722.513}", "{\"n\": 9140, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3782.25, \"learn_time_ms\": 14723.951}", "{\"n\": 9141, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3770.93, \"learn_time_ms\": 14721.837}", "{\"n\": 9142, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3774.52, \"learn_time_ms\": 14721.402}", "{\"n\": 9143, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3774.52, \"learn_time_ms\": 14709.532}", "{\"n\": 9144, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.25, \"learn_time_ms\": 14701.195}", "{\"n\": 9145, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.25, \"learn_time_ms\": 14696.27}", "{\"n\": 9146, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.77, \"learn_time_ms\": 14715.8}", "{\"n\": 9147, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3791.43, \"learn_time_ms\": 14691.044}", "{\"n\": 9148, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.01, \"learn_time_ms\": 14698.691}", "{\"n\": 9149, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3778.01, \"learn_time_ms\": 14683.033}", "{\"n\": 9150, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3786.37, \"learn_time_ms\": 14689.304}", "{\"n\": 9151, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3794.97, \"learn_time_ms\": 14680.619}", "{\"n\": 9152, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3800.7, \"learn_time_ms\": 14679.65}", "{\"n\": 9153, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3800.7, \"learn_time_ms\": 14677.714}", "{\"n\": 9154, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3800.7, \"learn_time_ms\": 14684.933}", "{\"n\": 9155, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3806.2, \"learn_time_ms\": 14698.102}", "{\"n\": 9156, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3819.4, \"learn_time_ms\": 14703.538}", "{\"n\": 9157, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3825.23, \"learn_time_ms\": 14721.04}", "{\"n\": 9158, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3819.11, \"learn_time_ms\": 14725.434}", "{\"n\": 9159, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3819.11, \"learn_time_ms\": 14730.341}", "{\"n\": 9160, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3819.11, \"learn_time_ms\": 14718.563}", "{\"n\": 9161, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3814.07, \"learn_time_ms\": 14718.811}", "{\"n\": 9162, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3803.66, \"learn_time_ms\": 14720.936}", "{\"n\": 9163, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3799.16, \"learn_time_ms\": 14734.395}", "{\"n\": 9164, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3811.57, \"learn_time_ms\": 14737.301}", "{\"n\": 9165, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3811.57, \"learn_time_ms\": 14742.443}", "{\"n\": 9166, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3812.07, \"learn_time_ms\": 14740.587}", "{\"n\": 9167, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3798.4, \"learn_time_ms\": 14747.315}", "{\"n\": 9168, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3798.82, \"learn_time_ms\": 14751.315}", "{\"n\": 9169, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3799.2, \"learn_time_ms\": 14750.494}", "{\"n\": 9170, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.87, \"learn_time_ms\": 14755.931}", "{\"n\": 9171, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3779.75, \"learn_time_ms\": 14760.644}", "{\"n\": 9172, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3779.75, \"learn_time_ms\": 14760.931}", "{\"n\": 9173, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3768.28, \"learn_time_ms\": 14746.152}", "{\"n\": 9174, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3759.63, \"learn_time_ms\": 14741.65}", "{\"n\": 9175, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3759.63, \"learn_time_ms\": 14732.603}", "{\"n\": 9176, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3759.63, \"learn_time_ms\": 14716.894}", "{\"n\": 9177, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3748.04, \"learn_time_ms\": 14718.606}", "{\"n\": 9178, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3749.01, \"learn_time_ms\": 14725.689}", "{\"n\": 9179, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3747.42, \"learn_time_ms\": 14728.864}", "{\"n\": 9180, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3748.61, \"learn_time_ms\": 14731.275}", "{\"n\": 9181, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3743.14, \"learn_time_ms\": 14714.812}", "{\"n\": 9182, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3742.3, \"learn_time_ms\": 14724.459}", "{\"n\": 9183, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3737.94, \"learn_time_ms\": 14737.283}", "{\"n\": 9184, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3735.88, \"learn_time_ms\": 14741.679}", "{\"n\": 9185, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3723.84, \"learn_time_ms\": 14742.037}", "{\"n\": 9186, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3725.09, \"learn_time_ms\": 14753.688}", "{\"n\": 9187, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.98, \"learn_time_ms\": 14755.373}", "{\"n\": 9188, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.98, \"learn_time_ms\": 14737.721}", "{\"n\": 9189, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.26, \"learn_time_ms\": 14734.44}", "{\"n\": 9190, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.26, \"learn_time_ms\": 14724.204}", "{\"n\": 9191, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3699.9, \"learn_time_ms\": 14737.731}", "{\"n\": 9192, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3707.25, \"learn_time_ms\": 14729.113}", "{\"n\": 9193, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3707.25, \"learn_time_ms\": 14721.211}", "{\"n\": 9194, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3709.04, \"learn_time_ms\": 14707.459}", "{\"n\": 9195, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3709.04, \"learn_time_ms\": 14699.466}", "{\"n\": 9196, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3709.57, \"learn_time_ms\": 14692.967}", "{\"n\": 9197, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3705.59, \"learn_time_ms\": 14683.321}", "{\"n\": 9198, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3705.59, \"learn_time_ms\": 14688.84}", "{\"n\": 9199, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.69, \"learn_time_ms\": 14672.652}", "{\"n\": 9200, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3686.5, \"learn_time_ms\": 14684.113}", "{\"n\": 9201, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3686.5, \"learn_time_ms\": 14686.615}", "{\"n\": 9202, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3693.17, \"learn_time_ms\": 14677.251}", "{\"n\": 9203, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3686.69, \"learn_time_ms\": 14671.478}", "{\"n\": 9204, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3698.0, \"learn_time_ms\": 14687.721}", "{\"n\": 9205, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.34, \"learn_time_ms\": 14696.165}", "{\"n\": 9206, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.34, \"learn_time_ms\": 14698.491}", "{\"n\": 9207, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3694.75, \"learn_time_ms\": 14697.526}", "{\"n\": 9208, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3694.75, \"learn_time_ms\": 14695.44}", "{\"n\": 9209, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.46, \"learn_time_ms\": 14711.388}", "{\"n\": 9210, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3684.03, \"learn_time_ms\": 14710.15}", "{\"n\": 9211, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.61, \"learn_time_ms\": 14708.582}", "{\"n\": 9212, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3695.74, \"learn_time_ms\": 14713.945}", "{\"n\": 9213, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3698.84, \"learn_time_ms\": 14716.912}", "{\"n\": 9214, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.03, \"learn_time_ms\": 14710.664}", "{\"n\": 9215, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.03, \"learn_time_ms\": 14712.401}", "{\"n\": 9216, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.14, \"learn_time_ms\": 14708.057}", "{\"n\": 9217, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3693.88, \"learn_time_ms\": 14700.08}", "{\"n\": 9218, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3693.88, \"learn_time_ms\": 14708.568}", "{\"n\": 9219, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.77, \"learn_time_ms\": 14693.579}", "{\"n\": 9220, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.77, \"learn_time_ms\": 14690.106}", "{\"n\": 9221, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3680.2, \"learn_time_ms\": 14698.156}", "{\"n\": 9222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3656.1, \"learn_time_ms\": 14709.389}", "{\"n\": 9223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3656.1, \"learn_time_ms\": 14703.892}", "{\"n\": 9224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3658.94, \"learn_time_ms\": 14697.189}", "{\"n\": 9225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3666.13, \"learn_time_ms\": 14689.566}", "{\"n\": 9226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3662.29, \"learn_time_ms\": 14682.012}", "{\"n\": 9227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.4, \"learn_time_ms\": 14694.149}", "{\"n\": 9228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3644.05, \"learn_time_ms\": 14687.856}", "{\"n\": 9229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3644.05, \"learn_time_ms\": 14712.638}", "{\"n\": 9230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3639.69, \"learn_time_ms\": 14719.537}", "{\"n\": 9231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3629.96, \"learn_time_ms\": 14714.614}", "{\"n\": 9232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.39, \"learn_time_ms\": 14700.779}", "{\"n\": 9233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.09, \"learn_time_ms\": 14708.969}", "{\"n\": 9234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.09, \"learn_time_ms\": 14718.008}", "{\"n\": 9235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3615.01, \"learn_time_ms\": 14732.444}", "{\"n\": 9236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3615.01, \"learn_time_ms\": 14752.371}", "{\"n\": 9237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.53, \"learn_time_ms\": 14754.448}", "{\"n\": 9238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3604.85, \"learn_time_ms\": 14761.074}", "{\"n\": 9239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.01, \"learn_time_ms\": 14752.918}", "{\"n\": 9240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.01, \"learn_time_ms\": 14756.064}", "{\"n\": 9241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.93, \"learn_time_ms\": 14764.847}", "{\"n\": 9242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3599.77, \"learn_time_ms\": 14773.299}", "{\"n\": 9243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3599.77, \"learn_time_ms\": 14773.724}", "{\"n\": 9244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3609.51, \"learn_time_ms\": 14759.891}", "{\"n\": 9245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3609.51, \"learn_time_ms\": 14756.529}", "{\"n\": 9246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3609.51, \"learn_time_ms\": 14755.188}", "{\"n\": 9247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3629.21, \"learn_time_ms\": 14756.843}", "{\"n\": 9248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3637.64, \"learn_time_ms\": 14747.947}", "{\"n\": 9249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3631.05, \"learn_time_ms\": 14748.106}", "{\"n\": 9250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3631.05, \"learn_time_ms\": 14748.02}", "{\"n\": 9251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3632.58, \"learn_time_ms\": 14730.052}", "{\"n\": 9252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3628.25, \"learn_time_ms\": 14735.696}", "{\"n\": 9253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3633.18, \"learn_time_ms\": 14728.459}", "{\"n\": 9254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3615.39, \"learn_time_ms\": 14747.79}", "{\"n\": 9255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3610.39, \"learn_time_ms\": 14753.052}", "{\"n\": 9256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3610.39, \"learn_time_ms\": 14747.576}", "{\"n\": 9257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3618.34, \"learn_time_ms\": 14752.196}", "{\"n\": 9258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3598.58, \"learn_time_ms\": 14758.337}", "{\"n\": 9259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3601.92, \"learn_time_ms\": 14751.885}", "{\"n\": 9260, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3601.92, \"learn_time_ms\": 14744.712}", "{\"n\": 9261, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3601.72, \"learn_time_ms\": 14761.594}", "{\"n\": 9262, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3597.01, \"learn_time_ms\": 14753.061}", "{\"n\": 9263, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3599.59, \"learn_time_ms\": 14759.712}", "{\"n\": 9264, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.32, \"learn_time_ms\": 14757.684}", "{\"n\": 9265, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3595.2, \"learn_time_ms\": 14745.741}", "{\"n\": 9266, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3595.2, \"learn_time_ms\": 14749.299}", "{\"n\": 9267, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3592.72, \"learn_time_ms\": 14745.654}", "{\"n\": 9268, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3586.55, \"learn_time_ms\": 14745.113}", "{\"n\": 9269, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 14741.833}", "{\"n\": 9270, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3561.27, \"learn_time_ms\": 14738.297}", "{\"n\": 9271, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3561.27, \"learn_time_ms\": 14736.658}", "{\"n\": 9272, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3561.14, \"learn_time_ms\": 14729.987}", "{\"n\": 9273, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3561.14, \"learn_time_ms\": 14736.634}", "{\"n\": 9274, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3557.91, \"learn_time_ms\": 14726.506}", "{\"n\": 9275, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3559.83, \"learn_time_ms\": 14727.253}", "{\"n\": 9276, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3559.83, \"learn_time_ms\": 14725.639}", "{\"n\": 9277, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3544.14, \"learn_time_ms\": 14727.766}", "{\"n\": 9278, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3543.95, \"learn_time_ms\": 14725.305}", "{\"n\": 9279, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3543.95, \"learn_time_ms\": 14731.491}", "{\"n\": 9280, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3540.09, \"learn_time_ms\": 14729.589}", "{\"n\": 9281, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3531.68, \"learn_time_ms\": 14730.77}", "{\"n\": 9282, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3531.68, \"learn_time_ms\": 14737.637}", "{\"n\": 9283, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3540.55, \"learn_time_ms\": 14740.225}", "{\"n\": 9284, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3546.16, \"learn_time_ms\": 14743.817}", "{\"n\": 9285, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3554.25, \"learn_time_ms\": 14746.357}", "{\"n\": 9286, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3554.25, \"learn_time_ms\": 14748.917}", "{\"n\": 9287, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3550.71, \"learn_time_ms\": 14740.833}", "{\"n\": 9288, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3541.25, \"learn_time_ms\": 14740.027}", "{\"n\": 9289, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3555.49, \"learn_time_ms\": 14742.365}", "{\"n\": 9290, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3551.75, \"learn_time_ms\": 14747.134}", "{\"n\": 9291, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3551.75, \"learn_time_ms\": 14741.613}", "{\"n\": 9292, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3548.7, \"learn_time_ms\": 14744.348}", "{\"n\": 9293, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3544.75, \"learn_time_ms\": 14740.065}", "{\"n\": 9294, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3544.66, \"learn_time_ms\": 14745.919}", "{\"n\": 9295, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3544.66, \"learn_time_ms\": 14746.044}", "{\"n\": 9296, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3555.74, \"learn_time_ms\": 14736.856}", "{\"n\": 9297, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3555.74, \"learn_time_ms\": 14743.382}", "{\"n\": 9298, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3555.74, \"learn_time_ms\": 14744.56}", "{\"n\": 9299, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3547.04, \"learn_time_ms\": 14749.106}", "{\"n\": 9300, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3530.46, \"learn_time_ms\": 14751.11}", "{\"n\": 9301, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3535.46, \"learn_time_ms\": 14750.668}", "{\"n\": 9302, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3535.54, \"learn_time_ms\": 14738.611}", "{\"n\": 9303, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3535.54, \"learn_time_ms\": 14737.337}", "{\"n\": 9304, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3550.44, \"learn_time_ms\": 14735.731}", "{\"n\": 9305, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3550.44, \"learn_time_ms\": 14749.381}", "{\"n\": 9306, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3569.0, \"learn_time_ms\": 14749.171}", "{\"n\": 9307, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3571.77, \"learn_time_ms\": 14739.218}", "{\"n\": 9308, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3585.03, \"learn_time_ms\": 14744.531}", "{\"n\": 9309, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3585.03, \"learn_time_ms\": 14743.217}", "{\"n\": 9310, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3569.76, \"learn_time_ms\": 14757.498}", "{\"n\": 9311, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3569.76, \"learn_time_ms\": 14755.55}", "{\"n\": 9312, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3566.25, \"learn_time_ms\": 14757.944}", "{\"n\": 9313, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3587.12, \"learn_time_ms\": 14753.64}", "{\"n\": 9314, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3587.12, \"learn_time_ms\": 14755.347}", "{\"n\": 9315, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3592.27, \"learn_time_ms\": 14740.27}", "{\"n\": 9316, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3612.86, \"learn_time_ms\": 14737.913}", "{\"n\": 9317, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3612.86, \"learn_time_ms\": 14744.907}", "{\"n\": 9318, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3612.86, \"learn_time_ms\": 14732.769}", "{\"n\": 9319, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3616.82, \"learn_time_ms\": 14730.757}", "{\"n\": 9320, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3623.27, \"learn_time_ms\": 14717.814}", "{\"n\": 9321, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3619.98, \"learn_time_ms\": 14726.972}", "{\"n\": 9322, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.84, \"learn_time_ms\": 14733.811}", "{\"n\": 9323, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.84, \"learn_time_ms\": 14736.157}", "{\"n\": 9324, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.84, \"learn_time_ms\": 14725.737}", "{\"n\": 9325, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.81, \"learn_time_ms\": 14722.465}", "{\"n\": 9326, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.08, \"learn_time_ms\": 14716.799}", "{\"n\": 9327, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.87, \"learn_time_ms\": 14710.842}", "{\"n\": 9328, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.48, \"learn_time_ms\": 14716.891}", "{\"n\": 9329, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.34, \"learn_time_ms\": 14708.331}", "{\"n\": 9330, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.34, \"learn_time_ms\": 14709.45}", "{\"n\": 9331, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.34, \"learn_time_ms\": 14699.583}", "{\"n\": 9332, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3636.22, \"learn_time_ms\": 14690.097}", "{\"n\": 9333, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.76, \"learn_time_ms\": 14702.338}", "{\"n\": 9334, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.76, \"learn_time_ms\": 14702.761}", "{\"n\": 9335, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3675.7, \"learn_time_ms\": 14698.042}", "{\"n\": 9336, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3677.49, \"learn_time_ms\": 14699.311}", "{\"n\": 9337, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3677.49, \"learn_time_ms\": 14705.161}", "{\"n\": 9338, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3677.7, \"learn_time_ms\": 14696.615}", "{\"n\": 9339, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3694.35, \"learn_time_ms\": 14698.643}", "{\"n\": 9340, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3704.06, \"learn_time_ms\": 14689.525}", "{\"n\": 9341, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3704.06, \"learn_time_ms\": 14688.796}", "{\"n\": 9342, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3704.06, \"learn_time_ms\": 14699.221}", "{\"n\": 9343, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3704.06, \"learn_time_ms\": 14694.338}", "{\"n\": 9344, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3718.55, \"learn_time_ms\": 14689.394}", "{\"n\": 9345, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3729.89, \"learn_time_ms\": 14698.295}", "{\"n\": 9346, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3743.7, \"learn_time_ms\": 14719.067}", "{\"n\": 9347, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3743.7, \"learn_time_ms\": 14725.709}", "{\"n\": 9348, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3743.7, \"learn_time_ms\": 14741.744}", "{\"n\": 9349, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3743.7, \"learn_time_ms\": 14740.52}", "{\"n\": 9350, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3737.3, \"learn_time_ms\": 14753.583}", "{\"n\": 9351, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3737.3, \"learn_time_ms\": 14752.008}", "{\"n\": 9352, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3756.95, \"learn_time_ms\": 14752.12}", "{\"n\": 9353, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.86, \"learn_time_ms\": 14727.046}", "{\"n\": 9354, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3770.4, \"learn_time_ms\": 14742.505}", "{\"n\": 9355, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3765.95, \"learn_time_ms\": 14730.831}", "{\"n\": 9356, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3766.98, \"learn_time_ms\": 14717.985}", "{\"n\": 9357, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3751.73, \"learn_time_ms\": 14715.948}", "{\"n\": 9358, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3767.22, \"learn_time_ms\": 14704.61}", "{\"n\": 9359, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3778.47, \"learn_time_ms\": 14705.514}", "{\"n\": 9360, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3777.71, \"learn_time_ms\": 14693.74}", "{\"n\": 9361, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.81, \"learn_time_ms\": 14692.017}", "{\"n\": 9362, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3783.28, \"learn_time_ms\": 14685.583}", "{\"n\": 9363, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3779.2, \"learn_time_ms\": 14698.724}", "{\"n\": 9364, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3773.07, \"learn_time_ms\": 14684.532}", "{\"n\": 9365, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3768.9, \"learn_time_ms\": 14697.426}", "{\"n\": 9366, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3760.84, \"learn_time_ms\": 14700.779}", "{\"n\": 9367, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3768.67, \"learn_time_ms\": 14689.666}", "{\"n\": 9368, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3768.67, \"learn_time_ms\": 14694.054}", "{\"n\": 9369, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3759.32, \"learn_time_ms\": 14695.313}", "{\"n\": 9370, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3794.1, \"learn_time_ms\": 14709.414}", "{\"n\": 9371, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3803.34, \"learn_time_ms\": 14716.108}", "{\"n\": 9372, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3799.12, \"learn_time_ms\": 14716.964}", "{\"n\": 9373, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3788.24, \"learn_time_ms\": 14722.352}", "{\"n\": 9374, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3788.24, \"learn_time_ms\": 14736.699}", "{\"n\": 9375, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3796.03, \"learn_time_ms\": 14736.097}", "{\"n\": 9376, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3792.61, \"learn_time_ms\": 14741.729}", "{\"n\": 9377, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3782.47, \"learn_time_ms\": 14737.427}", "{\"n\": 9378, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3771.34, \"learn_time_ms\": 14728.64}", "{\"n\": 9379, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3771.34, \"learn_time_ms\": 14730.833}", "{\"n\": 9380, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3775.35, \"learn_time_ms\": 14712.799}", "{\"n\": 9381, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3773.08, \"learn_time_ms\": 14713.377}", "{\"n\": 9382, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3747.1, \"learn_time_ms\": 14721.758}", "{\"n\": 9383, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.81, \"learn_time_ms\": 14718.651}", "{\"n\": 9384, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3746.01, \"learn_time_ms\": 14716.239}", "{\"n\": 9385, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.71, \"learn_time_ms\": 14718.71}", "{\"n\": 9386, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.71, \"learn_time_ms\": 14713.316}", "{\"n\": 9387, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3739.71, \"learn_time_ms\": 14720.736}", "{\"n\": 9388, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3747.03, \"learn_time_ms\": 14732.589}", "{\"n\": 9389, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3758.96, \"learn_time_ms\": 14738.549}", "{\"n\": 9390, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3757.44, \"learn_time_ms\": 14739.716}", "{\"n\": 9391, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3757.95, \"learn_time_ms\": 14738.877}", "{\"n\": 9392, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3753.12, \"learn_time_ms\": 14724.252}", "{\"n\": 9393, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3751.77, \"learn_time_ms\": 14725.444}", "{\"n\": 9394, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3741.83, \"learn_time_ms\": 14733.207}", "{\"n\": 9395, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3740.92, \"learn_time_ms\": 14734.577}", "{\"n\": 9396, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3743.61, \"learn_time_ms\": 14739.29}", "{\"n\": 9397, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3750.83, \"learn_time_ms\": 14741.21}", "{\"n\": 9398, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3757.67, \"learn_time_ms\": 14748.936}", "{\"n\": 9399, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3757.67, \"learn_time_ms\": 14729.456}", "{\"n\": 9400, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3748.14, \"learn_time_ms\": 14736.241}", "{\"n\": 9401, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3751.21, \"learn_time_ms\": 14741.364}", "{\"n\": 9402, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.64, \"learn_time_ms\": 14753.436}", "{\"n\": 9403, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3753.21, \"learn_time_ms\": 14744.016}", "{\"n\": 9404, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3753.21, \"learn_time_ms\": 14726.989}", "{\"n\": 9405, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3753.21, \"learn_time_ms\": 14730.748}", "{\"n\": 9406, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.8, \"learn_time_ms\": 14722.264}", "{\"n\": 9407, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.8, \"learn_time_ms\": 14732.973}", "{\"n\": 9408, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3774.67, \"learn_time_ms\": 14726.972}", "{\"n\": 9409, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3767.29, \"learn_time_ms\": 14739.338}", "{\"n\": 9410, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3768.68, \"learn_time_ms\": 14749.035}", "{\"n\": 9411, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3761.42, \"learn_time_ms\": 14735.73}", "{\"n\": 9412, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3736.77, \"learn_time_ms\": 14737.103}", "{\"n\": 9413, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3731.07, \"learn_time_ms\": 14745.955}", "{\"n\": 9414, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3731.07, \"learn_time_ms\": 14744.474}", "{\"n\": 9415, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3732.04, \"learn_time_ms\": 14740.773}", "{\"n\": 9416, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3732.04, \"learn_time_ms\": 14746.566}", "{\"n\": 9417, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3739.97, \"learn_time_ms\": 14741.368}", "{\"n\": 9418, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3741.87, \"learn_time_ms\": 14744.813}", "{\"n\": 9419, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3739.92, \"learn_time_ms\": 14756.383}", "{\"n\": 9420, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3741.83, \"learn_time_ms\": 14746.999}", "{\"n\": 9421, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3733.66, \"learn_time_ms\": 14760.031}", "{\"n\": 9422, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3739.25, \"learn_time_ms\": 14759.587}", "{\"n\": 9423, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3745.01, \"learn_time_ms\": 14769.98}", "{\"n\": 9424, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3737.08, \"learn_time_ms\": 14781.636}", "{\"n\": 9425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3744.91, \"learn_time_ms\": 14781.06}", "{\"n\": 9426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3744.91, \"learn_time_ms\": 14779.538}", "{\"n\": 9427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3751.52, \"learn_time_ms\": 14780.26}", "{\"n\": 9428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3751.52, \"learn_time_ms\": 14773.513}", "{\"n\": 9429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3754.5, \"learn_time_ms\": 14770.664}", "{\"n\": 9430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.32, \"learn_time_ms\": 14775.744}", "{\"n\": 9431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.32, \"learn_time_ms\": 14776.752}", "{\"n\": 9432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3747.81, \"learn_time_ms\": 14757.525}", "{\"n\": 9433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.91, \"learn_time_ms\": 14746.659}", "{\"n\": 9434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3760.64, \"learn_time_ms\": 14745.052}", "{\"n\": 9435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3759.21, \"learn_time_ms\": 14743.481}", "{\"n\": 9436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3775.94, \"learn_time_ms\": 14736.163}", "{\"n\": 9437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3774.3, \"learn_time_ms\": 14737.17}", "{\"n\": 9438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3789.77, \"learn_time_ms\": 14740.482}", "{\"n\": 9439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3780.65, \"learn_time_ms\": 14735.377}", "{\"n\": 9440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3780.9, \"learn_time_ms\": 14732.378}", "{\"n\": 9441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3780.9, \"learn_time_ms\": 14718.686}", "{\"n\": 9442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3792.17, \"learn_time_ms\": 14734.521}", "{\"n\": 9443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3792.17, \"learn_time_ms\": 14735.419}", "{\"n\": 9444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3796.82, \"learn_time_ms\": 14714.101}", "{\"n\": 9445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3788.79, \"learn_time_ms\": 14712.337}", "{\"n\": 9446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3788.79, \"learn_time_ms\": 14716.948}", "{\"n\": 9447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.57, \"learn_time_ms\": 14704.696}", "{\"n\": 9448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3782.34, \"learn_time_ms\": 14707.315}", "{\"n\": 9449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3767.51, \"learn_time_ms\": 14705.448}", "{\"n\": 9450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3767.51, \"learn_time_ms\": 14695.339}", "{\"n\": 9451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.77, \"learn_time_ms\": 14699.708}", "{\"n\": 9452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.67, \"learn_time_ms\": 14693.406}", "{\"n\": 9453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3783.79, \"learn_time_ms\": 14693.75}", "{\"n\": 9454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3783.79, \"learn_time_ms\": 14706.53}", "{\"n\": 9455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3780.91, \"learn_time_ms\": 14716.33}", "{\"n\": 9456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3784.13, \"learn_time_ms\": 14718.302}", "{\"n\": 9457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3791.26, \"learn_time_ms\": 14732.896}", "{\"n\": 9458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3791.26, \"learn_time_ms\": 14720.268}", "{\"n\": 9459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3785.91, \"learn_time_ms\": 14731.743}", "{\"n\": 9460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3780.68, \"learn_time_ms\": 14737.425}", "{\"n\": 9461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3780.68, \"learn_time_ms\": 14737.337}", "{\"n\": 9462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3782.92, \"learn_time_ms\": 14732.911}", "{\"n\": 9463, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3768.1, \"learn_time_ms\": 14725.648}", "{\"n\": 9464, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3768.1, \"learn_time_ms\": 14724.969}", "{\"n\": 9465, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.73, \"learn_time_ms\": 14721.717}", "{\"n\": 9466, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.73, \"learn_time_ms\": 14724.465}", "{\"n\": 9467, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3773.68, \"learn_time_ms\": 14719.546}", "{\"n\": 9468, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3783.6, \"learn_time_ms\": 14732.225}", "{\"n\": 9469, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3784.83, \"learn_time_ms\": 14711.165}", "{\"n\": 9470, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3781.29, \"learn_time_ms\": 14708.516}", "{\"n\": 9471, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3781.47, \"learn_time_ms\": 14704.947}", "{\"n\": 9472, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3781.47, \"learn_time_ms\": 14716.023}", "{\"n\": 9473, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3783.88, \"learn_time_ms\": 14718.036}", "{\"n\": 9474, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3784.7, \"learn_time_ms\": 14718.703}", "{\"n\": 9475, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.27, \"learn_time_ms\": 14702.095}", "{\"n\": 9476, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3741.56, \"learn_time_ms\": 14695.47}", "{\"n\": 9477, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3752.03, \"learn_time_ms\": 14696.969}", "{\"n\": 9478, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3752.03, \"learn_time_ms\": 14689.479}", "{\"n\": 9479, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3752.03, \"learn_time_ms\": 14695.679}", "{\"n\": 9480, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3752.03, \"learn_time_ms\": 14701.758}", "{\"n\": 9481, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.09, \"learn_time_ms\": 14712.407}", "{\"n\": 9482, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.05, \"learn_time_ms\": 14706.589}", "{\"n\": 9483, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3766.25, \"learn_time_ms\": 14712.221}", "{\"n\": 9484, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3775.13, \"learn_time_ms\": 14711.023}", "{\"n\": 9485, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3775.13, \"learn_time_ms\": 14718.084}", "{\"n\": 9486, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3778.04, \"learn_time_ms\": 14724.967}", "{\"n\": 9487, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3778.04, \"learn_time_ms\": 14724.318}", "{\"n\": 9488, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3789.33, \"learn_time_ms\": 14728.41}", "{\"n\": 9489, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3796.95, \"learn_time_ms\": 14728.643}", "{\"n\": 9490, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3816.52, \"learn_time_ms\": 14723.334}", "{\"n\": 9491, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3816.52, \"learn_time_ms\": 14721.239}", "{\"n\": 9492, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3805.84, \"learn_time_ms\": 14726.86}", "{\"n\": 9493, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3805.84, \"learn_time_ms\": 14721.88}", "{\"n\": 9494, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3799.14, \"learn_time_ms\": 14731.641}", "{\"n\": 9495, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3795.25, \"learn_time_ms\": 14733.808}", "{\"n\": 9496, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3790.25, \"learn_time_ms\": 14726.197}", "{\"n\": 9497, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3790.25, \"learn_time_ms\": 14725.744}", "{\"n\": 9498, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3790.25, \"learn_time_ms\": 14722.527}", "{\"n\": 9499, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3790.53, \"learn_time_ms\": 14715.609}", "{\"n\": 9500, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3781.18, \"learn_time_ms\": 14727.967}", "{\"n\": 9501, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3783.2, \"learn_time_ms\": 14740.543}", "{\"n\": 9502, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.04, \"learn_time_ms\": 14738.037}", "{\"n\": 9503, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.04, \"learn_time_ms\": 14750.863}", "{\"n\": 9504, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3788.85, \"learn_time_ms\": 14749.095}", "{\"n\": 9505, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3788.85, \"learn_time_ms\": 14746.296}", "{\"n\": 9506, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3777.28, \"learn_time_ms\": 14753.809}", "{\"n\": 9507, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3761.77, \"learn_time_ms\": 14757.229}", "{\"n\": 9508, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3761.77, \"learn_time_ms\": 14758.373}", "{\"n\": 9509, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3750.62, \"learn_time_ms\": 14779.537}", "{\"n\": 9510, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3730.08, \"learn_time_ms\": 14775.044}", "{\"n\": 9511, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3722.28, \"learn_time_ms\": 14762.552}", "{\"n\": 9512, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3722.28, \"learn_time_ms\": 14764.671}", "{\"n\": 9513, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3710.65, \"learn_time_ms\": 14765.628}", "{\"n\": 9514, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3715.61, \"learn_time_ms\": 14758.155}", "{\"n\": 9515, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3709.79, \"learn_time_ms\": 14751.301}", "{\"n\": 9516, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3709.79, \"learn_time_ms\": 14748.194}", "{\"n\": 9517, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3706.69, \"learn_time_ms\": 14723.617}", "{\"n\": 9518, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3706.69, \"learn_time_ms\": 14718.193}", "{\"n\": 9519, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3698.69, \"learn_time_ms\": 14708.837}", "{\"n\": 9520, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3707.33, \"learn_time_ms\": 14707.773}", "{\"n\": 9521, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3712.92, \"learn_time_ms\": 14722.994}", "{\"n\": 9522, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3710.51, \"learn_time_ms\": 14723.407}", "{\"n\": 9523, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3710.51, \"learn_time_ms\": 14715.771}", "{\"n\": 9524, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3718.05, \"learn_time_ms\": 14717.103}", "{\"n\": 9525, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3707.69, \"learn_time_ms\": 14727.614}", "{\"n\": 9526, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3707.69, \"learn_time_ms\": 14724.539}", "{\"n\": 9527, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.6, \"learn_time_ms\": 14736.703}", "{\"n\": 9528, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.6, \"learn_time_ms\": 14738.611}", "{\"n\": 9529, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3760.33, \"learn_time_ms\": 14739.189}", "{\"n\": 9530, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3760.33, \"learn_time_ms\": 14737.708}", "{\"n\": 9531, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3762.74, \"learn_time_ms\": 14715.885}", "{\"n\": 9532, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3758.48, \"learn_time_ms\": 14729.514}", "{\"n\": 9533, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3790.79, \"learn_time_ms\": 14721.501}", "{\"n\": 9534, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.54, \"learn_time_ms\": 14730.407}", "{\"n\": 9535, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.54, \"learn_time_ms\": 14737.497}", "{\"n\": 9536, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3750.95, \"learn_time_ms\": 14746.158}", "{\"n\": 9537, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3755.51, \"learn_time_ms\": 14743.912}", "{\"n\": 9538, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.84, \"learn_time_ms\": 14744.156}", "{\"n\": 9539, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3756.88, \"learn_time_ms\": 14743.919}", "{\"n\": 9540, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3757.49, \"learn_time_ms\": 14738.537}", "{\"n\": 9541, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3752.52, \"learn_time_ms\": 14738.748}", "{\"n\": 9542, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3771.16, \"learn_time_ms\": 14727.123}", "{\"n\": 9543, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3761.05, \"learn_time_ms\": 14738.23}", "{\"n\": 9544, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3746.07, \"learn_time_ms\": 14736.205}", "{\"n\": 9545, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.71, \"learn_time_ms\": 14722.802}", "{\"n\": 9546, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3732.05, \"learn_time_ms\": 14709.018}", "{\"n\": 9547, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.71, \"learn_time_ms\": 14712.237}", "{\"n\": 9548, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3754.58, \"learn_time_ms\": 14712.569}", "{\"n\": 9549, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3747.72, \"learn_time_ms\": 14717.935}", "{\"n\": 9550, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3740.66, \"learn_time_ms\": 14718.552}", "{\"n\": 9551, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3731.28, \"learn_time_ms\": 14723.758}", "{\"n\": 9552, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3735.63, \"learn_time_ms\": 14715.481}", "{\"n\": 9553, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3734.63, \"learn_time_ms\": 14706.931}", "{\"n\": 9554, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3738.13, \"learn_time_ms\": 14714.297}", "{\"n\": 9555, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3738.13, \"learn_time_ms\": 14711.06}", "{\"n\": 9556, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3734.45, \"learn_time_ms\": 14716.313}", "{\"n\": 9557, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.88, \"learn_time_ms\": 14727.764}", "{\"n\": 9558, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3738.2, \"learn_time_ms\": 14735.137}", "{\"n\": 9559, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.3, \"learn_time_ms\": 14733.616}", "{\"n\": 9560, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3734.24, \"learn_time_ms\": 14744.938}", "{\"n\": 9561, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3727.89, \"learn_time_ms\": 14747.331}", "{\"n\": 9562, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3725.24, \"learn_time_ms\": 14758.903}", "{\"n\": 9563, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3725.24, \"learn_time_ms\": 14775.361}", "{\"n\": 9564, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3731.05, \"learn_time_ms\": 14775.025}", "{\"n\": 9565, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3710.75, \"learn_time_ms\": 14787.36}", "{\"n\": 9566, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3710.75, \"learn_time_ms\": 14783.09}", "{\"n\": 9567, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3714.84, \"learn_time_ms\": 14759.654}", "{\"n\": 9568, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3711.48, \"learn_time_ms\": 14747.271}", "{\"n\": 9569, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3712.67, \"learn_time_ms\": 14747.612}", "{\"n\": 9570, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3729.72, \"learn_time_ms\": 14737.718}", "{\"n\": 9571, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3734.51, \"learn_time_ms\": 14729.566}", "{\"n\": 9572, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3728.23, \"learn_time_ms\": 14730.791}", "{\"n\": 9573, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3718.86, \"learn_time_ms\": 14718.58}", "{\"n\": 9574, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3720.87, \"learn_time_ms\": 14704.371}", "{\"n\": 9575, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3729.08, \"learn_time_ms\": 14702.56}", "{\"n\": 9576, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.42, \"learn_time_ms\": 14692.378}", "{\"n\": 9577, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3719.79, \"learn_time_ms\": 14707.185}", "{\"n\": 9578, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3719.79, \"learn_time_ms\": 14717.508}", "{\"n\": 9579, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3733.56, \"learn_time_ms\": 14695.051}", "{\"n\": 9580, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3733.99, \"learn_time_ms\": 14701.971}", "{\"n\": 9581, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3737.77, \"learn_time_ms\": 14706.751}", "{\"n\": 9582, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.41, \"learn_time_ms\": 14698.055}", "{\"n\": 9583, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.29, \"learn_time_ms\": 14683.416}", "{\"n\": 9584, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.29, \"learn_time_ms\": 14684.936}", "{\"n\": 9585, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3765.72, \"learn_time_ms\": 14683.36}", "{\"n\": 9586, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.18, \"learn_time_ms\": 14707.153}", "{\"n\": 9587, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.1, \"learn_time_ms\": 14709.763}", "{\"n\": 9588, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.1, \"learn_time_ms\": 14708.85}", "{\"n\": 9589, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3805.4, \"learn_time_ms\": 14727.723}", "{\"n\": 9590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3815.24, \"learn_time_ms\": 14733.935}", "{\"n\": 9591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3815.24, \"learn_time_ms\": 14743.425}", "{\"n\": 9592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3815.17, \"learn_time_ms\": 14749.913}", "{\"n\": 9593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3808.28, \"learn_time_ms\": 14768.136}", "{\"n\": 9594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3807.26, \"learn_time_ms\": 14781.567}", "{\"n\": 9595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3807.26, \"learn_time_ms\": 14795.314}", "{\"n\": 9596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3810.32, \"learn_time_ms\": 14790.787}", "{\"n\": 9597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3810.32, \"learn_time_ms\": 14794.566}", "{\"n\": 9598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3806.96, \"learn_time_ms\": 14786.321}", "{\"n\": 9599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3825.2, \"learn_time_ms\": 14785.965}", "{\"n\": 9600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3827.1, \"learn_time_ms\": 14774.327}", "{\"n\": 9601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.1, \"learn_time_ms\": 14766.642}", "{\"n\": 9602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.1, \"learn_time_ms\": 14759.795}", "{\"n\": 9603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3812.53, \"learn_time_ms\": 14757.838}", "{\"n\": 9604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3797.55, \"learn_time_ms\": 14748.024}", "{\"n\": 9605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3797.55, \"learn_time_ms\": 14728.406}", "{\"n\": 9606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.03, \"learn_time_ms\": 14723.367}", "{\"n\": 9607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3812.09, \"learn_time_ms\": 14711.113}", "{\"n\": 9608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3808.51, \"learn_time_ms\": 14719.636}", "{\"n\": 9609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3808.51, \"learn_time_ms\": 14725.019}", "{\"n\": 9610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3808.51, \"learn_time_ms\": 14735.059}", "{\"n\": 9611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3801.53, \"learn_time_ms\": 14743.348}", "{\"n\": 9612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3798.97, \"learn_time_ms\": 14756.535}", "{\"n\": 9613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3798.97, \"learn_time_ms\": 14756.856}", "{\"n\": 9614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3799.68, \"learn_time_ms\": 14763.041}", "{\"n\": 9615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3806.53, \"learn_time_ms\": 14776.258}", "{\"n\": 9616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3806.53, \"learn_time_ms\": 14776.331}", "{\"n\": 9617, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3825.25, \"learn_time_ms\": 14782.646}", "{\"n\": 9618, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3825.25, \"learn_time_ms\": 14781.532}", "{\"n\": 9619, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3837.07, \"learn_time_ms\": 14777.602}", "{\"n\": 9620, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3833.92, \"learn_time_ms\": 14765.995}", "{\"n\": 9621, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3848.67, \"learn_time_ms\": 14755.131}", "{\"n\": 9622, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3854.95, \"learn_time_ms\": 14733.294}", "{\"n\": 9623, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3851.81, \"learn_time_ms\": 14731.221}", "{\"n\": 9624, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3865.17, \"learn_time_ms\": 14723.582}", "{\"n\": 9625, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3882.06, \"learn_time_ms\": 14718.675}", "{\"n\": 9626, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3880.23, \"learn_time_ms\": 14714.588}", "{\"n\": 9627, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3886.2, \"learn_time_ms\": 14709.665}", "{\"n\": 9628, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3880.15, \"learn_time_ms\": 14712.466}", "{\"n\": 9629, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3880.66, \"learn_time_ms\": 14711.415}", "{\"n\": 9630, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3892.52, \"learn_time_ms\": 14716.587}", "{\"n\": 9631, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3892.49, \"learn_time_ms\": 14716.412}", "{\"n\": 9632, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3892.49, \"learn_time_ms\": 14726.917}", "{\"n\": 9633, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3894.46, \"learn_time_ms\": 14725.442}", "{\"n\": 9634, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3902.46, \"learn_time_ms\": 14726.005}", "{\"n\": 9635, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3913.04, \"learn_time_ms\": 14720.185}", "{\"n\": 9636, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3916.51, \"learn_time_ms\": 14730.323}", "{\"n\": 9637, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3920.98, \"learn_time_ms\": 14732.632}", "{\"n\": 9638, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3918.59, \"learn_time_ms\": 14719.576}", "{\"n\": 9639, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3913.96, \"learn_time_ms\": 14712.541}", "{\"n\": 9640, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3907.94, \"learn_time_ms\": 14708.848}", "{\"n\": 9641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3907.94, \"learn_time_ms\": 14708.167}", "{\"n\": 9642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3917.81, \"learn_time_ms\": 14717.104}", "{\"n\": 9643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3922.06, \"learn_time_ms\": 14714.246}", "{\"n\": 9644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3931.99, \"learn_time_ms\": 14709.019}", "{\"n\": 9645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3932.8, \"learn_time_ms\": 14714.532}", "{\"n\": 9646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3930.96, \"learn_time_ms\": 14711.938}", "{\"n\": 9647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3932.91, \"learn_time_ms\": 14712.144}", "{\"n\": 9648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3934.63, \"learn_time_ms\": 14720.785}", "{\"n\": 9649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3934.63, \"learn_time_ms\": 14731.582}", "{\"n\": 9650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3945.16, \"learn_time_ms\": 14727.69}", "{\"n\": 9651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3932.37, \"learn_time_ms\": 14736.305}", "{\"n\": 9652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3932.37, \"learn_time_ms\": 14725.632}", "{\"n\": 9653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3928.2, \"learn_time_ms\": 14732.428}", "{\"n\": 9654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3934.42, \"learn_time_ms\": 14734.549}", "{\"n\": 9655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3917.39, \"learn_time_ms\": 14742.413}", "{\"n\": 9656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3916.91, \"learn_time_ms\": 14747.665}", "{\"n\": 9657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3909.85, \"learn_time_ms\": 14758.961}", "{\"n\": 9658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3915.74, \"learn_time_ms\": 14747.462}", "{\"n\": 9659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3915.74, \"learn_time_ms\": 14746.664}", "{\"n\": 9660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3919.71, \"learn_time_ms\": 14748.28}", "{\"n\": 9661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3924.7, \"learn_time_ms\": 14737.918}", "{\"n\": 9662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3930.15, \"learn_time_ms\": 14740.426}", "{\"n\": 9663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3927.08, \"learn_time_ms\": 14734.393}", "{\"n\": 9664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3927.25, \"learn_time_ms\": 14730.589}", "{\"n\": 9665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3929.98, \"learn_time_ms\": 14707.33}", "{\"n\": 9666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3926.46, \"learn_time_ms\": 14687.426}", "{\"n\": 9667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3923.4, \"learn_time_ms\": 14682.286}", "{\"n\": 9668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3910.32, \"learn_time_ms\": 14701.733}", "{\"n\": 9669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3910.32, \"learn_time_ms\": 14677.961}", "{\"n\": 9670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3919.32, \"learn_time_ms\": 14681.03}", "{\"n\": 9671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3918.58, \"learn_time_ms\": 14675.145}", "{\"n\": 9672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3918.76, \"learn_time_ms\": 14663.98}", "{\"n\": 9673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3927.86, \"learn_time_ms\": 14669.837}", "{\"n\": 9674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3924.36, \"learn_time_ms\": 14680.247}", "{\"n\": 9675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3934.7, \"learn_time_ms\": 14684.761}", "{\"n\": 9676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3934.7, \"learn_time_ms\": 14685.455}", "{\"n\": 9677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3930.42, \"learn_time_ms\": 14677.261}", "{\"n\": 9678, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3933.36, \"learn_time_ms\": 14656.613}", "{\"n\": 9679, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3933.36, \"learn_time_ms\": 14678.937}", "{\"n\": 9680, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3916.95, \"learn_time_ms\": 14681.521}", "{\"n\": 9681, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3912.99, \"learn_time_ms\": 14694.433}", "{\"n\": 9682, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3922.55, \"learn_time_ms\": 14702.543}", "{\"n\": 9683, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3922.55, \"learn_time_ms\": 14698.951}", "{\"n\": 9684, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3922.55, \"learn_time_ms\": 14693.341}", "{\"n\": 9685, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3933.31, \"learn_time_ms\": 14710.824}", "{\"n\": 9686, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3947.61, \"learn_time_ms\": 14728.629}", "{\"n\": 9687, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3954.96, \"learn_time_ms\": 14738.428}", "{\"n\": 9688, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3941.58, \"learn_time_ms\": 14749.848}", "{\"n\": 9689, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3939.37, \"learn_time_ms\": 14744.849}", "{\"n\": 9690, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3939.37, \"learn_time_ms\": 14742.827}", "{\"n\": 9691, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3937.72, \"learn_time_ms\": 14716.108}", "{\"n\": 9692, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3951.15, \"learn_time_ms\": 14711.343}", "{\"n\": 9693, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3950.72, \"learn_time_ms\": 14722.753}", "{\"n\": 9694, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3950.09, \"learn_time_ms\": 14723.288}", "{\"n\": 9695, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3953.9, \"learn_time_ms\": 14709.456}", "{\"n\": 9696, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3973.14, \"learn_time_ms\": 14700.783}", "{\"n\": 9697, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3959.48, \"learn_time_ms\": 14705.373}", "{\"n\": 9698, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3953.39, \"learn_time_ms\": 14706.068}", "{\"n\": 9699, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3954.39, \"learn_time_ms\": 14701.389}", "{\"n\": 9700, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3954.39, \"learn_time_ms\": 14696.025}", "{\"n\": 9701, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3954.39, \"learn_time_ms\": 14731.052}", "{\"n\": 9702, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3956.25, \"learn_time_ms\": 14745.009}", "{\"n\": 9703, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3956.25, \"learn_time_ms\": 14727.089}", "{\"n\": 9704, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3945.39, \"learn_time_ms\": 14734.653}", "{\"n\": 9705, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3928.25, \"learn_time_ms\": 14727.686}", "{\"n\": 9706, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3919.28, \"learn_time_ms\": 14721.325}", "{\"n\": 9707, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3912.12, \"learn_time_ms\": 14716.306}", "{\"n\": 9708, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3912.12, \"learn_time_ms\": 14711.986}", "{\"n\": 9709, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3908.07, \"learn_time_ms\": 14723.597}", "{\"n\": 9710, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3902.53, \"learn_time_ms\": 14719.86}", "{\"n\": 9711, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3889.34, \"learn_time_ms\": 14729.522}", "{\"n\": 9712, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3885.53, \"learn_time_ms\": 14731.407}", "{\"n\": 9713, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3884.32, \"learn_time_ms\": 14749.322}", "{\"n\": 9714, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3862.68, \"learn_time_ms\": 14746.392}", "{\"n\": 9715, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3862.68, \"learn_time_ms\": 14763.795}", "{\"n\": 9716, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3867.76, \"learn_time_ms\": 14763.007}", "{\"n\": 9717, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3860.03, \"learn_time_ms\": 14762.559}", "{\"n\": 9718, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3868.7, \"learn_time_ms\": 14771.084}", "{\"n\": 9719, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3869.68, \"learn_time_ms\": 14768.774}", "{\"n\": 9720, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3867.84, \"learn_time_ms\": 14777.77}", "{\"n\": 9721, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3867.84, \"learn_time_ms\": 14756.62}", "{\"n\": 9722, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3856.83, \"learn_time_ms\": 14730.082}", "{\"n\": 9723, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3838.37, \"learn_time_ms\": 14716.189}", "{\"n\": 9724, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3836.92, \"learn_time_ms\": 14706.899}", "{\"n\": 9725, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3842.02, \"learn_time_ms\": 14706.471}", "{\"n\": 9726, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3842.02, \"learn_time_ms\": 14714.695}", "{\"n\": 9727, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3842.48, \"learn_time_ms\": 14707.343}", "{\"n\": 9728, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3836.72, \"learn_time_ms\": 14702.529}", "{\"n\": 9729, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3818.41, \"learn_time_ms\": 14693.908}", "{\"n\": 9730, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3818.41, \"learn_time_ms\": 14699.939}", "{\"n\": 9731, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3821.18, \"learn_time_ms\": 14702.886}", "{\"n\": 9732, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3815.38, \"learn_time_ms\": 14724.937}", "{\"n\": 9733, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3815.38, \"learn_time_ms\": 14733.162}", "{\"n\": 9734, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3830.48, \"learn_time_ms\": 14739.482}", "{\"n\": 9735, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3830.53, \"learn_time_ms\": 14736.585}", "{\"n\": 9736, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3849.29, \"learn_time_ms\": 14737.529}", "{\"n\": 9737, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3849.13, \"learn_time_ms\": 14737.629}", "{\"n\": 9738, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3849.13, \"learn_time_ms\": 14742.961}", "{\"n\": 9739, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3849.13, \"learn_time_ms\": 14746.065}", "{\"n\": 9740, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3834.65, \"learn_time_ms\": 14742.268}", "{\"n\": 9741, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3792.19, \"learn_time_ms\": 14740.504}", "{\"n\": 9742, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3787.46, \"learn_time_ms\": 14737.289}", "{\"n\": 9743, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3787.46, \"learn_time_ms\": 14735.68}", "{\"n\": 9744, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3797.03, \"learn_time_ms\": 14742.143}", "{\"n\": 9745, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3797.03, \"learn_time_ms\": 14736.016}", "{\"n\": 9746, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3784.77, \"learn_time_ms\": 14726.143}", "{\"n\": 9747, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3784.1, \"learn_time_ms\": 14705.94}", "{\"n\": 9748, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3767.94, \"learn_time_ms\": 14709.371}", "{\"n\": 9749, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3753.26, \"learn_time_ms\": 14707.586}", "{\"n\": 9750, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3753.26, \"learn_time_ms\": 14714.746}", "{\"n\": 9751, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3751.55, \"learn_time_ms\": 14715.105}", "{\"n\": 9752, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3754.8, \"learn_time_ms\": 14715.645}", "{\"n\": 9753, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3735.51, \"learn_time_ms\": 14716.089}", "{\"n\": 9754, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3742.41, \"learn_time_ms\": 14712.975}", "{\"n\": 9755, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3752.51, \"learn_time_ms\": 14722.274}", "{\"n\": 9756, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3756.98, \"learn_time_ms\": 14727.103}", "{\"n\": 9757, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3759.78, \"learn_time_ms\": 14743.797}", "{\"n\": 9758, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3767.76, \"learn_time_ms\": 14740.089}", "{\"n\": 9759, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3766.35, \"learn_time_ms\": 14743.542}", "{\"n\": 9760, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3740.17, \"learn_time_ms\": 14733.201}", "{\"n\": 9761, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3740.17, \"learn_time_ms\": 14729.845}", "{\"n\": 9762, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3729.54, \"learn_time_ms\": 14725.659}", "{\"n\": 9763, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3732.87, \"learn_time_ms\": 14721.453}", "{\"n\": 9764, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3732.87, \"learn_time_ms\": 14724.942}", "{\"n\": 9765, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.74, \"learn_time_ms\": 14725.176}", "{\"n\": 9766, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3737.13, \"learn_time_ms\": 14730.444}", "{\"n\": 9767, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3720.52, \"learn_time_ms\": 14735.656}", "{\"n\": 9768, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3721.46, \"learn_time_ms\": 14724.582}", "{\"n\": 9769, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3716.22, \"learn_time_ms\": 14716.972}", "{\"n\": 9770, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3716.22, \"learn_time_ms\": 14722.275}", "{\"n\": 9771, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.54, \"learn_time_ms\": 14723.431}", "{\"n\": 9772, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.54, \"learn_time_ms\": 14722.433}", "{\"n\": 9773, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.46, \"learn_time_ms\": 14730.439}", "{\"n\": 9774, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.82, \"learn_time_ms\": 14729.358}", "{\"n\": 9775, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3691.36, \"learn_time_ms\": 14727.175}", "{\"n\": 9776, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.86, \"learn_time_ms\": 14742.39}", "{\"n\": 9777, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.32, \"learn_time_ms\": 14745.073}", "{\"n\": 9778, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.1, \"learn_time_ms\": 14743.822}", "{\"n\": 9779, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.1, \"learn_time_ms\": 14753.196}", "{\"n\": 9780, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3672.65, \"learn_time_ms\": 14755.273}", "{\"n\": 9781, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3683.28, \"learn_time_ms\": 14765.842}", "{\"n\": 9782, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.7, \"learn_time_ms\": 14765.92}", "{\"n\": 9783, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.7, \"learn_time_ms\": 14761.611}", "{\"n\": 9784, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.41, \"learn_time_ms\": 14760.922}", "{\"n\": 9785, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.21, \"learn_time_ms\": 14749.849}", "{\"n\": 9786, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3699.86, \"learn_time_ms\": 14727.815}", "{\"n\": 9787, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.32, \"learn_time_ms\": 14724.356}", "{\"n\": 9788, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3708.3, \"learn_time_ms\": 14737.448}", "{\"n\": 9789, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3716.66, \"learn_time_ms\": 14737.232}", "{\"n\": 9790, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3715.52, \"learn_time_ms\": 14733.113}", "{\"n\": 9791, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3715.39, \"learn_time_ms\": 14726.83}", "{\"n\": 9792, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3734.96, \"learn_time_ms\": 14719.121}", "{\"n\": 9793, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3735.5, \"learn_time_ms\": 14723.784}", "{\"n\": 9794, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3735.5, \"learn_time_ms\": 14720.537}", "{\"n\": 9795, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3744.44, \"learn_time_ms\": 14729.294}", "{\"n\": 9796, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.39, \"learn_time_ms\": 14741.387}", "{\"n\": 9797, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.39, \"learn_time_ms\": 14741.03}", "{\"n\": 9798, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.03, \"learn_time_ms\": 14734.484}", "{\"n\": 9799, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3733.44, \"learn_time_ms\": 14743.239}", "{\"n\": 9800, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3732.02, \"learn_time_ms\": 14746.981}", "{\"n\": 9801, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.32, \"learn_time_ms\": 14746.399}", "{\"n\": 9802, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.32, \"learn_time_ms\": 14759.147}", "{\"n\": 9803, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.01, \"learn_time_ms\": 14748.2}", "{\"n\": 9804, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3737.47, \"learn_time_ms\": 14746.181}", "{\"n\": 9805, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.75, \"learn_time_ms\": 14745.758}", "{\"n\": 9806, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3723.11, \"learn_time_ms\": 14733.206}", "{\"n\": 9807, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3723.11, \"learn_time_ms\": 14735.588}", "{\"n\": 9808, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3723.11, \"learn_time_ms\": 14723.543}", "{\"n\": 9809, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3725.77, \"learn_time_ms\": 14711.51}", "{\"n\": 9810, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3725.77, \"learn_time_ms\": 14707.204}", "{\"n\": 9811, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3700.15, \"learn_time_ms\": 14709.056}", "{\"n\": 9812, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3702.33, \"learn_time_ms\": 14707.234}", "{\"n\": 9813, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3702.33, \"learn_time_ms\": 14707.89}", "{\"n\": 9814, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.77, \"learn_time_ms\": 14715.857}", "{\"n\": 9815, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3685.67, \"learn_time_ms\": 14722.373}", "{\"n\": 9816, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.96, \"learn_time_ms\": 14727.384}", "{\"n\": 9817, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.67, \"learn_time_ms\": 14713.35}", "{\"n\": 9818, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3713.46, \"learn_time_ms\": 14732.758}", "{\"n\": 9819, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3713.46, \"learn_time_ms\": 14731.04}", "{\"n\": 9820, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.48, \"learn_time_ms\": 14732.544}", "{\"n\": 9821, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3718.45, \"learn_time_ms\": 14731.648}", "{\"n\": 9822, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3730.06, \"learn_time_ms\": 14722.457}", "{\"n\": 9823, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3730.06, \"learn_time_ms\": 14728.441}", "{\"n\": 9824, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3717.7, \"learn_time_ms\": 14719.315}", "{\"n\": 9825, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3717.98, \"learn_time_ms\": 14710.322}", "{\"n\": 9826, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.91, \"learn_time_ms\": 14715.464}", "{\"n\": 9827, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.91, \"learn_time_ms\": 14728.485}", "{\"n\": 9828, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.69, \"learn_time_ms\": 14723.49}", "{\"n\": 9829, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3731.22, \"learn_time_ms\": 14729.326}", "{\"n\": 9830, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3735.71, \"learn_time_ms\": 14725.994}", "{\"n\": 9831, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3746.56, \"learn_time_ms\": 14713.443}", "{\"n\": 9832, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3755.89, \"learn_time_ms\": 14723.072}", "{\"n\": 9833, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3752.4, \"learn_time_ms\": 14724.521}", "{\"n\": 9834, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3757.03, \"learn_time_ms\": 14714.33}", "{\"n\": 9835, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3763.04, \"learn_time_ms\": 14727.758}", "{\"n\": 9836, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3763.04, \"learn_time_ms\": 14732.095}", "{\"n\": 9837, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.07, \"learn_time_ms\": 14723.947}", "{\"n\": 9838, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.21, \"learn_time_ms\": 14722.627}", "{\"n\": 9839, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.94, \"learn_time_ms\": 14719.555}", "{\"n\": 9840, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.94, \"learn_time_ms\": 14713.831}", "{\"n\": 9841, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.94, \"learn_time_ms\": 14716.895}", "{\"n\": 9842, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.44, \"learn_time_ms\": 14714.494}", "{\"n\": 9843, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3759.54, \"learn_time_ms\": 14718.256}", "{\"n\": 9844, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3761.64, \"learn_time_ms\": 14722.119}", "{\"n\": 9845, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3762.43, \"learn_time_ms\": 14710.064}", "{\"n\": 9846, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3756.9, \"learn_time_ms\": 14692.63}", "{\"n\": 9847, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3756.9, \"learn_time_ms\": 14693.295}", "{\"n\": 9848, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3754.05, \"learn_time_ms\": 14694.172}", "{\"n\": 9849, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3756.59, \"learn_time_ms\": 14690.688}", "{\"n\": 9850, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3756.59, \"learn_time_ms\": 14701.295}", "{\"n\": 9851, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.65, \"learn_time_ms\": 14703.286}", "{\"n\": 9852, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.84, \"learn_time_ms\": 14701.248}", "{\"n\": 9853, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.84, \"learn_time_ms\": 14692.407}", "{\"n\": 9854, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.84, \"learn_time_ms\": 14705.315}", "{\"n\": 9855, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3768.4, \"learn_time_ms\": 14718.874}", "{\"n\": 9856, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3786.15, \"learn_time_ms\": 14721.576}", "{\"n\": 9857, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3792.77, \"learn_time_ms\": 14735.814}", "{\"n\": 9858, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3790.33, \"learn_time_ms\": 14731.59}", "{\"n\": 9859, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3790.33, \"learn_time_ms\": 14743.248}", "{\"n\": 9860, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3790.33, \"learn_time_ms\": 14721.616}", "{\"n\": 9861, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3787.81, \"learn_time_ms\": 14730.572}", "{\"n\": 9862, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.05, \"learn_time_ms\": 14737.489}", "{\"n\": 9863, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3789.34, \"learn_time_ms\": 14744.797}", "{\"n\": 9864, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3798.65, \"learn_time_ms\": 14744.653}", "{\"n\": 9865, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3798.65, \"learn_time_ms\": 14742.603}", "{\"n\": 9866, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3789.43, \"learn_time_ms\": 14746.549}", "{\"n\": 9867, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3781.61, \"learn_time_ms\": 14735.832}", "{\"n\": 9868, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3780.39, \"learn_time_ms\": 14735.42}", "{\"n\": 9869, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3774.52, \"learn_time_ms\": 14728.99}", "{\"n\": 9870, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3771.47, \"learn_time_ms\": 14745.507}", "{\"n\": 9871, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3780.79, \"learn_time_ms\": 14722.989}", "{\"n\": 9872, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3780.79, \"learn_time_ms\": 14717.046}", "{\"n\": 9873, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.75, \"learn_time_ms\": 14710.163}", "{\"n\": 9874, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3786.7, \"learn_time_ms\": 14703.266}", "{\"n\": 9875, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3788.8, \"learn_time_ms\": 14700.743}", "{\"n\": 9876, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3783.65, \"learn_time_ms\": 14703.92}", "{\"n\": 9877, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3783.65, \"learn_time_ms\": 14719.866}", "{\"n\": 9878, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.74, \"learn_time_ms\": 14722.24}", "{\"n\": 9879, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3776.51, \"learn_time_ms\": 14719.715}", "{\"n\": 9880, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3765.82, \"learn_time_ms\": 14729.638}", "{\"n\": 9881, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3760.16, \"learn_time_ms\": 14748.635}", "{\"n\": 9882, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3760.16, \"learn_time_ms\": 14750.647}", "{\"n\": 9883, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3758.08, \"learn_time_ms\": 14758.787}", "{\"n\": 9884, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3744.31, \"learn_time_ms\": 14756.08}", "{\"n\": 9885, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3752.66, \"learn_time_ms\": 14755.25}", "{\"n\": 9886, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3753.79, \"learn_time_ms\": 14761.697}", "{\"n\": 9887, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3757.23, \"learn_time_ms\": 14755.786}", "{\"n\": 9888, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.97, \"learn_time_ms\": 14773.961}", "{\"n\": 9889, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.97, \"learn_time_ms\": 14780.883}", "{\"n\": 9890, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.81, \"learn_time_ms\": 14765.825}", "{\"n\": 9891, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3764.92, \"learn_time_ms\": 14779.643}", "{\"n\": 9892, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.59, \"learn_time_ms\": 14789.196}", "{\"n\": 9893, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3773.98, \"learn_time_ms\": 14796.876}", "{\"n\": 9894, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3779.35, \"learn_time_ms\": 14807.252}", "{\"n\": 9895, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.54, \"learn_time_ms\": 14806.351}", "{\"n\": 9896, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.54, \"learn_time_ms\": 14806.349}", "{\"n\": 9897, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.11, \"learn_time_ms\": 14800.408}", "{\"n\": 9898, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3784.89, \"learn_time_ms\": 14782.444}", "{\"n\": 9899, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3790.22, \"learn_time_ms\": 14776.06}", "{\"n\": 9900, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3781.79, \"learn_time_ms\": 14779.316}", "{\"n\": 9901, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.84, \"learn_time_ms\": 14765.175}", "{\"n\": 9902, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3783.33, \"learn_time_ms\": 14769.432}", "{\"n\": 9903, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3783.33, \"learn_time_ms\": 14756.128}", "{\"n\": 9904, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.72, \"learn_time_ms\": 14753.852}", "{\"n\": 9905, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3785.9, \"learn_time_ms\": 14743.036}", "{\"n\": 9906, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.23, \"learn_time_ms\": 14741.053}", "{\"n\": 9907, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3804.78, \"learn_time_ms\": 14742.235}", "{\"n\": 9908, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3804.78, \"learn_time_ms\": 14731.251}", "{\"n\": 9909, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3804.78, \"learn_time_ms\": 14737.996}", "{\"n\": 9910, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3792.85, \"learn_time_ms\": 14748.111}", "{\"n\": 9911, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3772.68, \"learn_time_ms\": 14746.069}", "{\"n\": 9912, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3769.46, \"learn_time_ms\": 14731.526}", "{\"n\": 9913, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3769.46, \"learn_time_ms\": 14728.222}", "{\"n\": 9914, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3762.32, \"learn_time_ms\": 14720.063}", "{\"n\": 9915, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3762.32, \"learn_time_ms\": 14723.313}", "{\"n\": 9916, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3769.91, \"learn_time_ms\": 14721.084}", "{\"n\": 9917, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3757.3, \"learn_time_ms\": 14711.539}", "{\"n\": 9918, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3772.91, \"learn_time_ms\": 14715.143}", "{\"n\": 9919, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3772.91, \"learn_time_ms\": 14705.445}", "{\"n\": 9920, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.27, \"learn_time_ms\": 14699.759}", "{\"n\": 9921, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.27, \"learn_time_ms\": 14702.42}", "{\"n\": 9922, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3772.57, \"learn_time_ms\": 14700.123}", "{\"n\": 9923, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.42, \"learn_time_ms\": 14701.258}", "{\"n\": 9924, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3791.74, \"learn_time_ms\": 14721.772}", "{\"n\": 9925, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.79, \"learn_time_ms\": 14724.511}", "{\"n\": 9926, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3787.55, \"learn_time_ms\": 14724.269}", "{\"n\": 9927, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3787.55, \"learn_time_ms\": 14723.902}", "{\"n\": 9928, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3781.56, \"learn_time_ms\": 14733.262}", "{\"n\": 9929, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.14, \"learn_time_ms\": 14732.617}", "{\"n\": 9930, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3773.3, \"learn_time_ms\": 14718.279}", "{\"n\": 9931, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.6, \"learn_time_ms\": 14719.378}", "{\"n\": 9932, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.6, \"learn_time_ms\": 14726.964}", "{\"n\": 9933, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.65, \"learn_time_ms\": 14727.908}", "{\"n\": 9934, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.65, \"learn_time_ms\": 14707.65}", "{\"n\": 9935, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.77, \"learn_time_ms\": 14711.09}", "{\"n\": 9936, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3767.75, \"learn_time_ms\": 14703.428}", "{\"n\": 9937, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3767.75, \"learn_time_ms\": 14711.905}", "{\"n\": 9938, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3764.0, \"learn_time_ms\": 14714.137}", "{\"n\": 9939, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3764.0, \"learn_time_ms\": 14713.771}", "{\"n\": 9940, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3773.35, \"learn_time_ms\": 14715.64}", "{\"n\": 9941, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3773.35, \"learn_time_ms\": 14710.652}", "{\"n\": 9942, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.5, \"learn_time_ms\": 14693.6}", "{\"n\": 9943, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3772.18, \"learn_time_ms\": 14701.126}", "{\"n\": 9944, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3787.73, \"learn_time_ms\": 14706.079}", "{\"n\": 9945, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3787.73, \"learn_time_ms\": 14715.817}", "{\"n\": 9946, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3794.03, \"learn_time_ms\": 14724.553}", "{\"n\": 9947, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3794.03, \"learn_time_ms\": 14741.092}", "{\"n\": 9948, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3791.36, \"learn_time_ms\": 14739.272}", "{\"n\": 9949, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3811.84, \"learn_time_ms\": 14755.653}", "{\"n\": 9950, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3810.74, \"learn_time_ms\": 14766.653}", "{\"n\": 9951, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3815.04, \"learn_time_ms\": 14765.664}", "{\"n\": 9952, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3815.04, \"learn_time_ms\": 14784.56}", "{\"n\": 9953, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3826.39, \"learn_time_ms\": 14777.116}", "{\"n\": 9954, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3833.44, \"learn_time_ms\": 14781.186}", "{\"n\": 9955, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3825.78, \"learn_time_ms\": 14756.009}", "{\"n\": 9956, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3823.98, \"learn_time_ms\": 14760.415}", "{\"n\": 9957, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3823.98, \"learn_time_ms\": 14745.698}", "{\"n\": 9958, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3835.65, \"learn_time_ms\": 14744.817}", "{\"n\": 9959, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3835.65, \"learn_time_ms\": 14728.971}", "{\"n\": 9960, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3834.97, \"learn_time_ms\": 14732.492}", "{\"n\": 9961, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3830.38, \"learn_time_ms\": 14737.292}", "{\"n\": 9962, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3837.95, \"learn_time_ms\": 14724.383}", "{\"n\": 9963, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3847.12, \"learn_time_ms\": 14722.446}", "{\"n\": 9964, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3858.27, \"learn_time_ms\": 14723.059}", "{\"n\": 9965, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3858.27, \"learn_time_ms\": 14738.266}", "{\"n\": 9966, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3863.75, \"learn_time_ms\": 14737.928}", "{\"n\": 9967, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3862.62, \"learn_time_ms\": 14732.033}", "{\"n\": 9968, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3861.71, \"learn_time_ms\": 14724.322}", "{\"n\": 9969, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3854.98, \"learn_time_ms\": 14732.781}", "{\"n\": 9970, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3857.93, \"learn_time_ms\": 14727.309}", "{\"n\": 9971, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3874.86, \"learn_time_ms\": 14723.844}", "{\"n\": 9972, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3874.86, \"learn_time_ms\": 14732.607}", "{\"n\": 9973, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3870.27, \"learn_time_ms\": 14734.109}", "{\"n\": 9974, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3865.47, \"learn_time_ms\": 14729.802}", "{\"n\": 9975, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3865.47, \"learn_time_ms\": 14716.801}", "{\"n\": 9976, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3857.66, \"learn_time_ms\": 14708.501}", "{\"n\": 9977, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3850.19, \"learn_time_ms\": 14711.299}", "{\"n\": 9978, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3850.19, \"learn_time_ms\": 14721.674}", "{\"n\": 9979, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3844.89, \"learn_time_ms\": 14735.52}", "{\"n\": 9980, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3854.14, \"learn_time_ms\": 14735.225}", "{\"n\": 9981, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3859.29, \"learn_time_ms\": 14729.824}", "{\"n\": 9982, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3859.29, \"learn_time_ms\": 14725.822}", "{\"n\": 9983, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3859.29, \"learn_time_ms\": 14717.312}", "{\"n\": 9984, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3863.45, \"learn_time_ms\": 14717.887}", "{\"n\": 9985, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3863.39, \"learn_time_ms\": 14722.327}", "{\"n\": 9986, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3863.39, \"learn_time_ms\": 14728.361}", "{\"n\": 9987, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3853.65, \"learn_time_ms\": 14719.308}", "{\"n\": 9988, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3847.55, \"learn_time_ms\": 14714.557}", "{\"n\": 9989, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3846.16, \"learn_time_ms\": 14692.916}", "{\"n\": 9990, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3846.16, \"learn_time_ms\": 14696.979}", "{\"n\": 9991, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3857.19, \"learn_time_ms\": 14700.803}", "{\"n\": 9992, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3854.41, \"learn_time_ms\": 14711.03}", "{\"n\": 9993, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3863.47, \"learn_time_ms\": 14727.994}", "{\"n\": 9994, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3875.05, \"learn_time_ms\": 14728.73}", "{\"n\": 9995, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3879.79, \"learn_time_ms\": 14733.388}", "{\"n\": 9996, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3879.79, \"learn_time_ms\": 14730.076}", "{\"n\": 9997, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3878.96, \"learn_time_ms\": 14738.202}", "{\"n\": 9998, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3882.57, \"learn_time_ms\": 14735.692}", "{\"n\": 9999, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3878.86, \"learn_time_ms\": 14741.666}", "{\"n\": 10000, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3878.86, \"learn_time_ms\": 14738.782}"]["{\"n\": 10001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15450.716}", "{\"n\": 10002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15078.071}", "{\"n\": 10003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14953.927}", "{\"n\": 10004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14896.023}", "{\"n\": 10005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14867.223}", "{\"n\": 10006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14857.747}", "{\"n\": 10007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14854.694}", "{\"n\": 10008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14828.532}", "{\"n\": 10009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14818.05}", "{\"n\": 10010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14812.758}", "{\"n\": 10011, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2647.0, \"learn_time_ms\": 14746.505}", "{\"n\": 10012, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -8.666666666666666, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3128.3333333333335, \"learn_time_ms\": 14750.764}", "{\"n\": 10013, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.333333333333333, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3485.5, \"learn_time_ms\": 14732.758}", "{\"n\": 10014, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.375, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3570.0, \"learn_time_ms\": 14735.705}", "{\"n\": 10015, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.375, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3570.0, \"learn_time_ms\": 14742.53}", "{\"n\": 10016, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.375, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3570.0, \"learn_time_ms\": 14738.577}", "{\"n\": 10017, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.5555555555557, \"learn_time_ms\": 14712.478}", "{\"n\": 10018, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3609.1, \"learn_time_ms\": 14730.615}", "{\"n\": 10019, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.571428571428571, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3582.4285714285716, \"learn_time_ms\": 14737.378}", "{\"n\": 10020, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3601.9333333333334, \"learn_time_ms\": 14740.873}", "{\"n\": 10021, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.8125, \"learn_time_ms\": 14735.266}", "{\"n\": 10022, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.8125, \"learn_time_ms\": 14744.631}", "{\"n\": 10023, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.9411764705882355, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.705882352941, \"learn_time_ms\": 14773.967}", "{\"n\": 10024, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.9411764705882355, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3641.705882352941, \"learn_time_ms\": 14790.38}", "{\"n\": 10025, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.111111111111111, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3626.1111111111113, \"learn_time_ms\": 14789.19}", "{\"n\": 10026, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.0952380952380953, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3691.809523809524, \"learn_time_ms\": 14791.474}", "{\"n\": 10027, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.6666666666665, \"learn_time_ms\": 14814.056}", "{\"n\": 10028, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.6666666666665, \"learn_time_ms\": 14808.5}", "{\"n\": 10029, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3743.6666666666665, \"learn_time_ms\": 14814.542}", "{\"n\": 10030, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.88, \"learn_time_ms\": 14827.763}", "{\"n\": 10031, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.88, \"learn_time_ms\": 14822.859}", "{\"n\": 10032, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5172413793103448, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.310344827586, \"learn_time_ms\": 14836.569}", "{\"n\": 10033, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.2333333333333334, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3768.633333333333, \"learn_time_ms\": 14830.788}", "{\"n\": 10034, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96875, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.65625, \"learn_time_ms\": 14819.617}", "{\"n\": 10035, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96875, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.65625, \"learn_time_ms\": 14824.258}", "{\"n\": 10036, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96875, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.65625, \"learn_time_ms\": 14826.131}", "{\"n\": 10037, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3812.181818181818, \"learn_time_ms\": 14823.199}", "{\"n\": 10038, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6857142857142857, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3817.057142857143, \"learn_time_ms\": 14821.117}", "{\"n\": 10039, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6842105263157894, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3825.5, \"learn_time_ms\": 14815.419}", "{\"n\": 10040, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.7435897435897436, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3823.0, \"learn_time_ms\": 14803.317}", "{\"n\": 10041, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.725, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3831.025, \"learn_time_ms\": 14817.238}", "{\"n\": 10042, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.725, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3831.025, \"learn_time_ms\": 14793.229}", "{\"n\": 10043, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.725, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3831.025, \"learn_time_ms\": 14798.452}", "{\"n\": 10044, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5909090909090908, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3856.25, \"learn_time_ms\": 14803.352}", "{\"n\": 10045, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3850.911111111111, \"learn_time_ms\": 14797.322}", "{\"n\": 10046, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5869565217391304, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3832.804347826087, \"learn_time_ms\": 14793.464}", "{\"n\": 10047, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4375, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3852.7083333333335, \"learn_time_ms\": 14801.944}", "{\"n\": 10048, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4375, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3852.7083333333335, \"learn_time_ms\": 14807.493}", "{\"n\": 10049, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3850.54, \"learn_time_ms\": 14815.495}", "{\"n\": 10050, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.803921568627451, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3830.3137254901962, \"learn_time_ms\": 14826.306}", "{\"n\": 10051, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.8461538461538463, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3824.9615384615386, \"learn_time_ms\": 14833.775}", "{\"n\": 10052, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.8679245283018868, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3832.5283018867926, \"learn_time_ms\": 14849.719}", "{\"n\": 10053, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.7818181818181817, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3851.0363636363636, \"learn_time_ms\": 14840.34}", "{\"n\": 10054, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.875, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3848.464285714286, \"learn_time_ms\": 14835.745}", "{\"n\": 10055, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.912280701754386, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3846.5087719298244, \"learn_time_ms\": 14837.74}", "{\"n\": 10056, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.135593220338983, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3823.186440677966, \"learn_time_ms\": 14831.281}", "{\"n\": 10057, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.183333333333333, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3823.9166666666665, \"learn_time_ms\": 14832.082}", "{\"n\": 10058, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.1774193548387095, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3829.7580645161293, \"learn_time_ms\": 14831.618}", "{\"n\": 10059, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.111111111111111, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3835.063492063492, \"learn_time_ms\": 14815.209}", "{\"n\": 10060, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.203125, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3828.546875, \"learn_time_ms\": 14797.751}", "{\"n\": 10061, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.287878787878788, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3819.742424242424, \"learn_time_ms\": 14788.017}", "{\"n\": 10062, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.287878787878788, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3819.742424242424, \"learn_time_ms\": 14782.35}", "{\"n\": 10063, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.283582089552239, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3825.4626865671644, \"learn_time_ms\": 14786.621}", "{\"n\": 10064, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.2318840579710146, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3817.8260869565215, \"learn_time_ms\": 14775.658}", "{\"n\": 10065, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.0428571428571427, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3818.442857142857, \"learn_time_ms\": 14777.134}", "{\"n\": 10066, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.1666666666666665, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3808.5138888888887, \"learn_time_ms\": 14779.733}", "{\"n\": 10067, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.2054794520547945, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3806.7123287671234, \"learn_time_ms\": 14772.889}", "{\"n\": 10068, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.27027027027027, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.810810810811, \"learn_time_ms\": 14766.706}", "{\"n\": 10069, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.27027027027027, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.810810810811, \"learn_time_ms\": 14779.548}", "{\"n\": 10070, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.210526315789474, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3809.9473684210525, \"learn_time_ms\": 14788.049}", "{\"n\": 10071, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.1538461538461537, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3809.0384615384614, \"learn_time_ms\": 14779.794}", "{\"n\": 10072, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.1625, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.4875, \"learn_time_ms\": 14770.836}", "{\"n\": 10073, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.1625, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.4875, \"learn_time_ms\": 14775.334}", "{\"n\": 10074, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.097560975609756, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3820.3536585365855, \"learn_time_ms\": 14787.693}", "{\"n\": 10075, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.097560975609756, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3820.3536585365855, \"learn_time_ms\": 14787.957}", "{\"n\": 10076, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.144578313253012, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3823.156626506024, \"learn_time_ms\": 14794.727}", "{\"n\": 10077, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.2873563218390807, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.3793103448274, \"learn_time_ms\": 14797.703}", "{\"n\": 10078, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.272727272727273, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3821.715909090909, \"learn_time_ms\": 14804.711}", "{\"n\": 10079, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3817.288888888889, \"learn_time_ms\": 14798.385}", "{\"n\": 10080, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3817.288888888889, \"learn_time_ms\": 14799.692}", "{\"n\": 10081, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3817.288888888889, \"learn_time_ms\": 14805.454}", "{\"n\": 10082, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3817.288888888889, \"learn_time_ms\": 14817.091}", "{\"n\": 10083, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.3333333333333335, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3817.2795698924733, \"learn_time_ms\": 14810.325}", "{\"n\": 10084, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.463157894736842, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3810.5263157894738, \"learn_time_ms\": 14808.191}", "{\"n\": 10085, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5625, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3799.9895833333335, \"learn_time_ms\": 14816.132}", "{\"n\": 10086, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.6288659793814433, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3793.061855670103, \"learn_time_ms\": 14824.99}", "{\"n\": 10087, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.707070707070707, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.5757575757575, \"learn_time_ms\": 14820.293}", "{\"n\": 10088, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.707070707070707, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3786.5757575757575, \"learn_time_ms\": 14817.56}", "{\"n\": 10089, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3793.52, \"learn_time_ms\": 14824.415}", "{\"n\": 10090, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3808.24, \"learn_time_ms\": 14821.773}", "{\"n\": 10091, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3815.39, \"learn_time_ms\": 14822.403}", "{\"n\": 10092, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3802.42, \"learn_time_ms\": 14816.019}", "{\"n\": 10093, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3806.22, \"learn_time_ms\": 14811.163}", "{\"n\": 10094, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3810.85, \"learn_time_ms\": 14814.623}", "{\"n\": 10095, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3815.28, \"learn_time_ms\": 14803.318}", "{\"n\": 10096, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3807.27, \"learn_time_ms\": 14800.303}", "{\"n\": 10097, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3817.36, \"learn_time_ms\": 14795.363}", "{\"n\": 10098, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3826.43, \"learn_time_ms\": 14800.557}", "{\"n\": 10099, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3822.11, \"learn_time_ms\": 14798.189}", "{\"n\": 10100, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3822.11, \"learn_time_ms\": 14805.442}", "{\"n\": 10101, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3822.49, \"learn_time_ms\": 14803.115}", "{\"n\": 10102, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3826.58, \"learn_time_ms\": 14803.913}", "{\"n\": 10103, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3824.91, \"learn_time_ms\": 14818.591}", "{\"n\": 10104, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3817.21, \"learn_time_ms\": 14816.032}", "{\"n\": 10105, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3813.48, \"learn_time_ms\": 14811.681}", "{\"n\": 10106, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3793.61, \"learn_time_ms\": 14796.363}", "{\"n\": 10107, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3790.17, \"learn_time_ms\": 14801.791}", "{\"n\": 10108, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3790.17, \"learn_time_ms\": 14802.706}", "{\"n\": 10109, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3785.75, \"learn_time_ms\": 14790.926}", "{\"n\": 10110, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3792.29, \"learn_time_ms\": 14783.503}", "{\"n\": 10111, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3792.29, \"learn_time_ms\": 14801.251}", "{\"n\": 10112, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3775.11, \"learn_time_ms\": 14814.418}", "{\"n\": 10113, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3775.11, \"learn_time_ms\": 14814.634}", "{\"n\": 10114, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3769.18, \"learn_time_ms\": 14813.579}", "{\"n\": 10115, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3764.79, \"learn_time_ms\": 14837.618}", "{\"n\": 10116, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3761.24, \"learn_time_ms\": 14854.397}", "{\"n\": 10117, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3766.35, \"learn_time_ms\": 14865.282}", "{\"n\": 10118, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3757.46, \"learn_time_ms\": 14859.659}", "{\"n\": 10119, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3757.46, \"learn_time_ms\": 14875.814}", "{\"n\": 10120, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3757.09, \"learn_time_ms\": 14874.312}", "{\"n\": 10121, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3757.09, \"learn_time_ms\": 14858.417}", "{\"n\": 10122, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3745.58, \"learn_time_ms\": 14844.805}", "{\"n\": 10123, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3738.78, \"learn_time_ms\": 14845.773}", "{\"n\": 10124, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3755.12, \"learn_time_ms\": 14847.196}", "{\"n\": 10125, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3753.38, \"learn_time_ms\": 14833.289}", "{\"n\": 10126, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3762.56, \"learn_time_ms\": 14817.872}", "{\"n\": 10127, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3762.56, \"learn_time_ms\": 14812.574}", "{\"n\": 10128, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3774.67, \"learn_time_ms\": 14810.273}", "{\"n\": 10129, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3767.87, \"learn_time_ms\": 14811.447}", "{\"n\": 10130, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3767.87, \"learn_time_ms\": 14806.853}", "{\"n\": 10131, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3761.28, \"learn_time_ms\": 14807.699}", "{\"n\": 10132, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3752.18, \"learn_time_ms\": 14818.144}", "{\"n\": 10133, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3752.18, \"learn_time_ms\": 14822.265}", "{\"n\": 10134, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3752.18, \"learn_time_ms\": 14824.442}", "{\"n\": 10135, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3757.12, \"learn_time_ms\": 14827.671}", "{\"n\": 10136, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3748.83, \"learn_time_ms\": 14835.957}", "{\"n\": 10137, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3747.89, \"learn_time_ms\": 14841.467}", "{\"n\": 10138, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3752.38, \"learn_time_ms\": 14851.59}", "{\"n\": 10139, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3767.2, \"learn_time_ms\": 14841.154}", "{\"n\": 10140, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3767.2, \"learn_time_ms\": 14850.289}", "{\"n\": 10141, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3763.53, \"learn_time_ms\": 14860.942}", "{\"n\": 10142, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3771.43, \"learn_time_ms\": 14853.544}", "{\"n\": 10143, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3771.43, \"learn_time_ms\": 14848.73}", "{\"n\": 10144, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3771.43, \"learn_time_ms\": 14848.864}", "{\"n\": 10145, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3772.57, \"learn_time_ms\": 14852.856}", "{\"n\": 10146, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3766.32, \"learn_time_ms\": 14856.611}", "{\"n\": 10147, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3758.96, \"learn_time_ms\": 14844.396}", "{\"n\": 10148, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3752.0, \"learn_time_ms\": 14829.893}", "{\"n\": 10149, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3745.05, \"learn_time_ms\": 14825.03}", "{\"n\": 10150, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3747.05, \"learn_time_ms\": 14832.379}", "{\"n\": 10151, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3742.48, \"learn_time_ms\": 14816.646}", "{\"n\": 10152, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3743.89, \"learn_time_ms\": 14813.261}", "{\"n\": 10153, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3741.31, \"learn_time_ms\": 14814.021}", "{\"n\": 10154, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3728.83, \"learn_time_ms\": 14815.922}", "{\"n\": 10155, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3728.67, \"learn_time_ms\": 14807.925}", "{\"n\": 10156, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3728.67, \"learn_time_ms\": 14807.665}", "{\"n\": 10157, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3728.67, \"learn_time_ms\": 14825.072}", "{\"n\": 10158, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3728.67, \"learn_time_ms\": 14842.716}", "{\"n\": 10159, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3730.41, \"learn_time_ms\": 14838.742}", "{\"n\": 10160, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3724.98, \"learn_time_ms\": 14825.311}", "{\"n\": 10161, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3722.9, \"learn_time_ms\": 14829.677}", "{\"n\": 10162, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3733.0, \"learn_time_ms\": 14832.029}", "{\"n\": 10163, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3733.0, \"learn_time_ms\": 14831.271}", "{\"n\": 10164, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3752.84, \"learn_time_ms\": 14831.361}", "{\"n\": 10165, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3754.01, \"learn_time_ms\": 14833.944}", "{\"n\": 10166, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3746.99, \"learn_time_ms\": 14836.586}", "{\"n\": 10167, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3753.02, \"learn_time_ms\": 14832.965}", "{\"n\": 10168, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3755.39, \"learn_time_ms\": 14827.632}", "{\"n\": 10169, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3762.08, \"learn_time_ms\": 14838.58}", "{\"n\": 10170, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3735.25, \"learn_time_ms\": 14842.294}", "{\"n\": 10171, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3735.25, \"learn_time_ms\": 14848.956}", "{\"n\": 10172, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3730.18, \"learn_time_ms\": 14840.629}", "{\"n\": 10173, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3736.41, \"learn_time_ms\": 14843.477}", "{\"n\": 10174, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3727.83, \"learn_time_ms\": 14843.811}", "{\"n\": 10175, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3717.61, \"learn_time_ms\": 14851.334}", "{\"n\": 10176, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3723.51, \"learn_time_ms\": 14844.796}", "{\"n\": 10177, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3722.85, \"learn_time_ms\": 14850.232}", "{\"n\": 10178, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3711.22, \"learn_time_ms\": 14848.679}", "{\"n\": 10179, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3710.42, \"learn_time_ms\": 14839.037}", "{\"n\": 10180, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3705.12, \"learn_time_ms\": 14832.273}", "{\"n\": 10181, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.89, \"learn_time_ms\": 14828.89}", "{\"n\": 10182, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.05, \"learn_time_ms\": 14837.996}", "{\"n\": 10183, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.05, \"learn_time_ms\": 14838.581}", "{\"n\": 10184, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.05, \"learn_time_ms\": 14843.917}", "{\"n\": 10185, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3733.21, \"learn_time_ms\": 14830.47}", "{\"n\": 10186, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3733.21, \"learn_time_ms\": 14823.653}", "{\"n\": 10187, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3727.5, \"learn_time_ms\": 14807.997}", "{\"n\": 10188, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.25, \"learn_time_ms\": 14816.674}", "{\"n\": 10189, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3719.95, \"learn_time_ms\": 14830.141}", "{\"n\": 10190, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3719.95, \"learn_time_ms\": 14824.225}", "{\"n\": 10191, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.59, \"learn_time_ms\": 14815.674}", "{\"n\": 10192, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3715.91, \"learn_time_ms\": 14812.014}", "{\"n\": 10193, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.99, \"learn_time_ms\": 14813.017}", "{\"n\": 10194, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3725.66, \"learn_time_ms\": 14803.686}", "{\"n\": 10195, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3725.66, \"learn_time_ms\": 14805.104}", "{\"n\": 10196, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3727.16, \"learn_time_ms\": 14828.402}", "{\"n\": 10197, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3727.16, \"learn_time_ms\": 14825.839}", "{\"n\": 10198, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3731.42, \"learn_time_ms\": 14815.408}", "{\"n\": 10199, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3719.11, \"learn_time_ms\": 14811.045}", "{\"n\": 10200, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3721.67, \"learn_time_ms\": 14823.319}", "{\"n\": 10201, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.66, \"learn_time_ms\": 14840.642}", "{\"n\": 10202, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.66, \"learn_time_ms\": 14849.703}", "{\"n\": 10203, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3706.43, \"learn_time_ms\": 14850.985}", "{\"n\": 10204, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.27, \"learn_time_ms\": 14841.188}", "{\"n\": 10205, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.52, \"learn_time_ms\": 14845.448}", "{\"n\": 10206, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3702.08, \"learn_time_ms\": 14830.202}", "{\"n\": 10207, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3717.26, \"learn_time_ms\": 14833.705}", "{\"n\": 10208, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3709.86, \"learn_time_ms\": 14832.94}", "{\"n\": 10209, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3709.86, \"learn_time_ms\": 14833.014}", "{\"n\": 10210, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3713.84, \"learn_time_ms\": 14837.897}", "{\"n\": 10211, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3731.49, \"learn_time_ms\": 14820.346}", "{\"n\": 10212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3753.75, \"learn_time_ms\": 14808.489}", "{\"n\": 10213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3758.84, \"learn_time_ms\": 14805.713}", "{\"n\": 10214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3761.16, \"learn_time_ms\": 14820.119}", "{\"n\": 10215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3752.88, \"learn_time_ms\": 14819.113}", "{\"n\": 10216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3752.88, \"learn_time_ms\": 14822.249}", "{\"n\": 10217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3758.52, \"learn_time_ms\": 14821.595}", "{\"n\": 10218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3758.8, \"learn_time_ms\": 14825.613}", "{\"n\": 10219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3768.55, \"learn_time_ms\": 14829.578}", "{\"n\": 10220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3764.94, \"learn_time_ms\": 14832.22}", "{\"n\": 10221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3753.21, \"learn_time_ms\": 14845.066}", "{\"n\": 10222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3753.21, \"learn_time_ms\": 14847.979}", "{\"n\": 10223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3752.7, \"learn_time_ms\": 14848.748}", "{\"n\": 10224, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3746.28, \"learn_time_ms\": 14851.116}", "{\"n\": 10225, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3758.87, \"learn_time_ms\": 14835.46}", "{\"n\": 10226, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3754.4, \"learn_time_ms\": 14839.341}", "{\"n\": 10227, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3760.62, \"learn_time_ms\": 14850.477}", "{\"n\": 10228, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3766.85, \"learn_time_ms\": 14856.657}", "{\"n\": 10229, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3761.22, \"learn_time_ms\": 14860.497}", "{\"n\": 10230, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3773.1, \"learn_time_ms\": 14857.095}", "{\"n\": 10231, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3767.59, \"learn_time_ms\": 14845.775}", "{\"n\": 10232, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3774.6, \"learn_time_ms\": 14855.783}", "{\"n\": 10233, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3786.38, \"learn_time_ms\": 14861.616}", "{\"n\": 10234, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.92, \"learn_time_ms\": 14862.373}", "{\"n\": 10235, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3779.17, \"learn_time_ms\": 14886.674}", "{\"n\": 10236, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.73, \"learn_time_ms\": 14880.744}", "{\"n\": 10237, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.27, \"learn_time_ms\": 14871.878}", "{\"n\": 10238, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3779.78, \"learn_time_ms\": 14862.703}", "{\"n\": 10239, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3779.78, \"learn_time_ms\": 14860.135}", "{\"n\": 10240, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3771.61, \"learn_time_ms\": 14858.786}", "{\"n\": 10241, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3777.05, \"learn_time_ms\": 14867.64}", "{\"n\": 10242, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3759.9, \"learn_time_ms\": 14847.58}", "{\"n\": 10243, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3752.59, \"learn_time_ms\": 14824.505}", "{\"n\": 10244, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3747.46, \"learn_time_ms\": 14824.848}", "{\"n\": 10245, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3734.16, \"learn_time_ms\": 14807.576}", "{\"n\": 10246, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3728.76, \"learn_time_ms\": 14806.234}", "{\"n\": 10247, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3722.94, \"learn_time_ms\": 14805.866}", "{\"n\": 10248, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3737.59, \"learn_time_ms\": 14800.899}", "{\"n\": 10249, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3759.13, \"learn_time_ms\": 14796.953}", "{\"n\": 10250, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3759.69, \"learn_time_ms\": 14800.211}", "{\"n\": 10251, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3767.46, \"learn_time_ms\": 14784.494}", "{\"n\": 10252, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3766.7, \"learn_time_ms\": 14795.715}", "{\"n\": 10253, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3759.5, \"learn_time_ms\": 14801.823}", "{\"n\": 10254, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3763.77, \"learn_time_ms\": 14795.571}", "{\"n\": 10255, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3767.98, \"learn_time_ms\": 14795.32}", "{\"n\": 10256, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.55, \"learn_time_ms\": 14795.431}", "{\"n\": 10257, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.55, \"learn_time_ms\": 14790.024}", "{\"n\": 10258, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.53, \"learn_time_ms\": 14798.87}", "{\"n\": 10259, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.53, \"learn_time_ms\": 14803.165}", "{\"n\": 10260, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.53, \"learn_time_ms\": 14812.379}", "{\"n\": 10261, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3788.74, \"learn_time_ms\": 14832.812}", "{\"n\": 10262, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3780.65, \"learn_time_ms\": 14832.887}", "{\"n\": 10263, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.02, \"learn_time_ms\": 14836.062}", "{\"n\": 10264, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.02, \"learn_time_ms\": 14840.113}", "{\"n\": 10265, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3776.02, \"learn_time_ms\": 14838.413}", "{\"n\": 10266, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3774.17, \"learn_time_ms\": 14835.93}", "{\"n\": 10267, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3775.98, \"learn_time_ms\": 14859.956}", "{\"n\": 10268, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3780.52, \"learn_time_ms\": 14866.789}", "{\"n\": 10269, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3770.86, \"learn_time_ms\": 14866.118}", "{\"n\": 10270, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3756.99, \"learn_time_ms\": 14849.206}", "{\"n\": 10271, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3756.99, \"learn_time_ms\": 14839.641}", "{\"n\": 10272, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3744.69, \"learn_time_ms\": 14840.829}", "{\"n\": 10273, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3744.69, \"learn_time_ms\": 14846.137}", "{\"n\": 10274, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3727.42, \"learn_time_ms\": 14837.579}", "{\"n\": 10275, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3743.15, \"learn_time_ms\": 14852.221}", "{\"n\": 10276, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3742.8, \"learn_time_ms\": 14852.576}", "{\"n\": 10277, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3742.8, \"learn_time_ms\": 14830.365}", "{\"n\": 10278, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3745.44, \"learn_time_ms\": 14825.162}", "{\"n\": 10279, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3745.44, \"learn_time_ms\": 14812.245}", "{\"n\": 10280, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3745.64, \"learn_time_ms\": 14818.632}", "{\"n\": 10281, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3746.32, \"learn_time_ms\": 14831.867}", "{\"n\": 10282, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3732.69, \"learn_time_ms\": 14820.901}", "{\"n\": 10283, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3729.2, \"learn_time_ms\": 14807.356}", "{\"n\": 10284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3720.95, \"learn_time_ms\": 14817.543}", "{\"n\": 10285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3720.95, \"learn_time_ms\": 14815.55}", "{\"n\": 10286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3717.7, \"learn_time_ms\": 14816.614}", "{\"n\": 10287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3721.06, \"learn_time_ms\": 14817.162}", "{\"n\": 10288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3718.54, \"learn_time_ms\": 14812.198}", "{\"n\": 10289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3718.54, \"learn_time_ms\": 14816.491}", "{\"n\": 10290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3709.65, \"learn_time_ms\": 14801.32}", "{\"n\": 10291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3701.33, \"learn_time_ms\": 14797.994}", "{\"n\": 10292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3695.81, \"learn_time_ms\": 14806.3}", "{\"n\": 10293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3683.94, \"learn_time_ms\": 14809.933}", "{\"n\": 10294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3677.0, \"learn_time_ms\": 14789.855}", "{\"n\": 10295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3667.96, \"learn_time_ms\": 14788.561}", "{\"n\": 10296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3667.96, \"learn_time_ms\": 14786.722}", "{\"n\": 10297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3664.22, \"learn_time_ms\": 14790.298}", "{\"n\": 10298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.54, \"learn_time_ms\": 14805.023}", "{\"n\": 10299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3675.98, \"learn_time_ms\": 14818.828}", "{\"n\": 10300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3675.98, \"learn_time_ms\": 14825.593}", "{\"n\": 10301, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3672.63, \"learn_time_ms\": 14823.652}", "{\"n\": 10302, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3677.95, \"learn_time_ms\": 14827.664}", "{\"n\": 10303, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3669.66, \"learn_time_ms\": 14835.079}", "{\"n\": 10304, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3657.41, \"learn_time_ms\": 14859.625}", "{\"n\": 10305, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3642.05, \"learn_time_ms\": 14855.856}", "{\"n\": 10306, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3649.57, \"learn_time_ms\": 14845.256}", "{\"n\": 10307, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3644.63, \"learn_time_ms\": 14845.3}", "{\"n\": 10308, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3628.53, \"learn_time_ms\": 14828.736}", "{\"n\": 10309, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.79, \"learn_time_ms\": 14823.456}", "{\"n\": 10310, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3629.38, \"learn_time_ms\": 14825.244}", "{\"n\": 10311, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3626.43, \"learn_time_ms\": 14821.474}", "{\"n\": 10312, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3618.94, \"learn_time_ms\": 14804.375}", "{\"n\": 10313, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3621.21, \"learn_time_ms\": 14786.852}", "{\"n\": 10314, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3625.92, \"learn_time_ms\": 14770.5}", "{\"n\": 10315, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3630.1, \"learn_time_ms\": 14777.901}", "{\"n\": 10316, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3640.71, \"learn_time_ms\": 14801.029}", "{\"n\": 10317, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3634.5, \"learn_time_ms\": 14803.961}", "{\"n\": 10318, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.85, \"learn_time_ms\": 14810.059}", "{\"n\": 10319, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3631.12, \"learn_time_ms\": 14807.616}", "{\"n\": 10320, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3631.12, \"learn_time_ms\": 14792.383}", "{\"n\": 10321, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3634.07, \"learn_time_ms\": 14794.534}", "{\"n\": 10322, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3634.51, \"learn_time_ms\": 14806.325}", "{\"n\": 10323, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3617.82, \"learn_time_ms\": 14824.053}", "{\"n\": 10324, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3615.42, \"learn_time_ms\": 14834.13}", "{\"n\": 10325, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3615.42, \"learn_time_ms\": 14833.274}", "{\"n\": 10326, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3615.19, \"learn_time_ms\": 14830.95}", "{\"n\": 10327, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.05, \"learn_time_ms\": 14831.094}", "{\"n\": 10328, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.42, \"learn_time_ms\": 14827.377}", "{\"n\": 10329, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.82, \"learn_time_ms\": 14821.444}", "{\"n\": 10330, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.82, \"learn_time_ms\": 14834.135}", "{\"n\": 10331, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.42, \"learn_time_ms\": 14846.648}", "{\"n\": 10332, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.13, \"learn_time_ms\": 14862.753}", "{\"n\": 10333, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.13, \"learn_time_ms\": 14865.469}", "{\"n\": 10334, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.23, \"learn_time_ms\": 14871.841}", "{\"n\": 10335, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.83, \"learn_time_ms\": 14867.968}", "{\"n\": 10336, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.64, \"learn_time_ms\": 14871.588}", "{\"n\": 10337, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.06, \"learn_time_ms\": 14881.693}", "{\"n\": 10338, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.4, \"learn_time_ms\": 14879.938}", "{\"n\": 10339, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.4, \"learn_time_ms\": 14891.372}", "{\"n\": 10340, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3592.75, \"learn_time_ms\": 14890.337}", "{\"n\": 10341, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3592.3, \"learn_time_ms\": 14882.282}", "{\"n\": 10342, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3609.13, \"learn_time_ms\": 14863.842}", "{\"n\": 10343, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3612.89, \"learn_time_ms\": 14866.572}", "{\"n\": 10344, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3612.89, \"learn_time_ms\": 14848.736}", "{\"n\": 10345, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3617.6, \"learn_time_ms\": 14837.147}", "{\"n\": 10346, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3637.01, \"learn_time_ms\": 14814.791}", "{\"n\": 10347, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3657.24, \"learn_time_ms\": 14804.619}", "{\"n\": 10348, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3652.98, \"learn_time_ms\": 14819.268}", "{\"n\": 10349, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3656.35, \"learn_time_ms\": 14809.669}", "{\"n\": 10350, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3659.1, \"learn_time_ms\": 14813.059}", "{\"n\": 10351, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3659.1, \"learn_time_ms\": 14805.001}", "{\"n\": 10352, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3642.62, \"learn_time_ms\": 14810.115}", "{\"n\": 10353, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3642.62, \"learn_time_ms\": 14787.421}", "{\"n\": 10354, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3645.46, \"learn_time_ms\": 14786.179}", "{\"n\": 10355, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.56, \"learn_time_ms\": 14782.699}", "{\"n\": 10356, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.56, \"learn_time_ms\": 14801.45}", "{\"n\": 10357, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3660.39, \"learn_time_ms\": 14803.037}", "{\"n\": 10358, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3660.39, \"learn_time_ms\": 14795.519}", "{\"n\": 10359, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3651.14, \"learn_time_ms\": 14795.603}", "{\"n\": 10360, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3657.42, \"learn_time_ms\": 14800.546}", "{\"n\": 10361, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3648.61, \"learn_time_ms\": 14797.823}", "{\"n\": 10362, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3648.61, \"learn_time_ms\": 14800.113}", "{\"n\": 10363, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3648.69, \"learn_time_ms\": 14821.852}", "{\"n\": 10364, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3648.69, \"learn_time_ms\": 14832.336}", "{\"n\": 10365, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3647.48, \"learn_time_ms\": 14849.041}", "{\"n\": 10366, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3660.18, \"learn_time_ms\": 14843.483}", "{\"n\": 10367, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3666.01, \"learn_time_ms\": 14831.782}", "{\"n\": 10368, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3667.17, \"learn_time_ms\": 14816.103}", "{\"n\": 10369, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3667.17, \"learn_time_ms\": 14829.841}", "{\"n\": 10370, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3667.17, \"learn_time_ms\": 14806.614}", "{\"n\": 10371, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3667.17, \"learn_time_ms\": 14806.18}", "{\"n\": 10372, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3667.56, \"learn_time_ms\": 14796.984}", "{\"n\": 10373, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3669.31, \"learn_time_ms\": 14790.711}", "{\"n\": 10374, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3700.79, \"learn_time_ms\": 14791.266}", "{\"n\": 10375, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3700.79, \"learn_time_ms\": 14782.794}", "{\"n\": 10376, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3693.12, \"learn_time_ms\": 14778.052}", "{\"n\": 10377, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3691.56, \"learn_time_ms\": 14779.862}", "{\"n\": 10378, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3691.56, \"learn_time_ms\": 14783.202}", "{\"n\": 10379, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3682.73, \"learn_time_ms\": 14769.328}", "{\"n\": 10380, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3685.5, \"learn_time_ms\": 14783.349}", "{\"n\": 10381, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3711.16, \"learn_time_ms\": 14795.925}", "{\"n\": 10382, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3711.16, \"learn_time_ms\": 14784.758}", "{\"n\": 10383, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3711.16, \"learn_time_ms\": 14776.452}", "{\"n\": 10384, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3713.46, \"learn_time_ms\": 14765.929}", "{\"n\": 10385, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3712.84, \"learn_time_ms\": 14771.848}", "{\"n\": 10386, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3748.4, \"learn_time_ms\": 14768.697}", "{\"n\": 10387, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.73, \"learn_time_ms\": 14773.401}", "{\"n\": 10388, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.73, \"learn_time_ms\": 14777.643}", "{\"n\": 10389, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.73, \"learn_time_ms\": 14766.888}", "{\"n\": 10390, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3748.84, \"learn_time_ms\": 14766.188}", "{\"n\": 10391, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3759.74, \"learn_time_ms\": 14760.334}", "{\"n\": 10392, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.02, \"learn_time_ms\": 14786.918}", "{\"n\": 10393, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.03, \"learn_time_ms\": 14795.958}", "{\"n\": 10394, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3767.55, \"learn_time_ms\": 14804.108}", "{\"n\": 10395, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3767.55, \"learn_time_ms\": 14794.113}", "{\"n\": 10396, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.33, \"learn_time_ms\": 14794.385}", "{\"n\": 10397, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3771.25, \"learn_time_ms\": 14795.851}", "{\"n\": 10398, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3773.27, \"learn_time_ms\": 14795.7}", "{\"n\": 10399, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3772.94, \"learn_time_ms\": 14819.666}", "{\"n\": 10400, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3782.26, \"learn_time_ms\": 14822.632}", "{\"n\": 10401, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3788.46, \"learn_time_ms\": 14829.219}", "{\"n\": 10402, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3788.46, \"learn_time_ms\": 14811.858}", "{\"n\": 10403, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3783.69, \"learn_time_ms\": 14816.59}", "{\"n\": 10404, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3784.55, \"learn_time_ms\": 14816.395}", "{\"n\": 10405, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3784.55, \"learn_time_ms\": 14809.112}", "{\"n\": 10406, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3789.19, \"learn_time_ms\": 14806.957}", "{\"n\": 10407, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3797.91, \"learn_time_ms\": 14801.981}", "{\"n\": 10408, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3797.91, \"learn_time_ms\": 14800.199}", "{\"n\": 10409, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3790.12, \"learn_time_ms\": 14791.436}", "{\"n\": 10410, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3791.55, \"learn_time_ms\": 14793.607}", "{\"n\": 10411, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3791.55, \"learn_time_ms\": 14776.468}", "{\"n\": 10412, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.94, \"learn_time_ms\": 14773.511}", "{\"n\": 10413, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3820.6, \"learn_time_ms\": 14762.25}", "{\"n\": 10414, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3798.58, \"learn_time_ms\": 14750.337}", "{\"n\": 10415, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3803.01, \"learn_time_ms\": 14758.223}", "{\"n\": 10416, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3803.01, \"learn_time_ms\": 14770.675}", "{\"n\": 10417, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3812.89, \"learn_time_ms\": 14770.602}", "{\"n\": 10418, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3804.47, \"learn_time_ms\": 14759.575}", "{\"n\": 10419, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.53, \"learn_time_ms\": 14752.516}", "{\"n\": 10420, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.48, \"learn_time_ms\": 14753.191}", "{\"n\": 10421, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3776.48, \"learn_time_ms\": 14759.335}", "{\"n\": 10422, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3773.17, \"learn_time_ms\": 14766.496}", "{\"n\": 10423, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3773.18, \"learn_time_ms\": 14776.545}", "{\"n\": 10424, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3773.18, \"learn_time_ms\": 14779.574}", "{\"n\": 10425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3760.56, \"learn_time_ms\": 14780.735}", "{\"n\": 10426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3764.09, \"learn_time_ms\": 14773.869}", "{\"n\": 10427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.38, \"learn_time_ms\": 14768.298}", "{\"n\": 10428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.38, \"learn_time_ms\": 14784.634}", "{\"n\": 10429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3771.25, \"learn_time_ms\": 14782.094}", "{\"n\": 10430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.15, \"learn_time_ms\": 14781.849}", "{\"n\": 10431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3763.83, \"learn_time_ms\": 14769.08}", "{\"n\": 10432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3759.25, \"learn_time_ms\": 14769.053}", "{\"n\": 10433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3762.69, \"learn_time_ms\": 14766.95}", "{\"n\": 10434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3762.69, \"learn_time_ms\": 14763.288}", "{\"n\": 10435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3756.59, \"learn_time_ms\": 14769.555}", "{\"n\": 10436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3759.14, \"learn_time_ms\": 14769.942}", "{\"n\": 10437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3755.13, \"learn_time_ms\": 14771.721}", "{\"n\": 10438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3754.67, \"learn_time_ms\": 14771.67}", "{\"n\": 10439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3760.1, \"learn_time_ms\": 14782.882}", "{\"n\": 10440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3765.5, \"learn_time_ms\": 14775.181}", "{\"n\": 10441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3758.29, \"learn_time_ms\": 14785.554}", "{\"n\": 10442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3752.75, \"learn_time_ms\": 14786.61}", "{\"n\": 10443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.7, \"learn_time_ms\": 14789.709}", "{\"n\": 10444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3739.01, \"learn_time_ms\": 14805.578}", "{\"n\": 10445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3748.55, \"learn_time_ms\": 14791.813}", "{\"n\": 10446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3748.55, \"learn_time_ms\": 14793.863}", "{\"n\": 10447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.07, \"learn_time_ms\": 14786.525}", "{\"n\": 10448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3740.62, \"learn_time_ms\": 14790.551}", "{\"n\": 10449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3740.62, \"learn_time_ms\": 14792.714}", "{\"n\": 10450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.57, \"learn_time_ms\": 14797.638}", "{\"n\": 10451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3728.17, \"learn_time_ms\": 14784.973}", "{\"n\": 10452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3718.46, \"learn_time_ms\": 14778.754}", "{\"n\": 10453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3719.9, \"learn_time_ms\": 14755.568}", "{\"n\": 10454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3725.39, \"learn_time_ms\": 14748.306}", "{\"n\": 10455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3728.77, \"learn_time_ms\": 14754.411}", "{\"n\": 10456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3728.81, \"learn_time_ms\": 14746.566}", "{\"n\": 10457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3728.81, \"learn_time_ms\": 14754.024}", "{\"n\": 10458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3719.41, \"learn_time_ms\": 14745.755}", "{\"n\": 10459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3719.41, \"learn_time_ms\": 14737.367}", "{\"n\": 10460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.3, \"learn_time_ms\": 14738.267}", "{\"n\": 10461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3724.3, \"learn_time_ms\": 14752.763}", "{\"n\": 10462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3709.03, \"learn_time_ms\": 14750.266}", "{\"n\": 10463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.87, \"learn_time_ms\": 14770.133}", "{\"n\": 10464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3692.38, \"learn_time_ms\": 14765.143}", "{\"n\": 10465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3694.74, \"learn_time_ms\": 14767.282}", "{\"n\": 10466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.31, \"learn_time_ms\": 14775.258}", "{\"n\": 10467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3695.35, \"learn_time_ms\": 14775.044}", "{\"n\": 10468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3692.4, \"learn_time_ms\": 14770.052}", "{\"n\": 10469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3700.14, \"learn_time_ms\": 14775.534}", "{\"n\": 10470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.54, \"learn_time_ms\": 14785.142}", "{\"n\": 10471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.23, \"learn_time_ms\": 14784.705}", "{\"n\": 10472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.23, \"learn_time_ms\": 14799.694}", "{\"n\": 10473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.23, \"learn_time_ms\": 14794.262}", "{\"n\": 10474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.9, \"learn_time_ms\": 14801.906}", "{\"n\": 10475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.34, \"learn_time_ms\": 14809.194}", "{\"n\": 10476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.19, \"learn_time_ms\": 14793.517}", "{\"n\": 10477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.19, \"learn_time_ms\": 14796.95}", "{\"n\": 10478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3673.62, \"learn_time_ms\": 14802.029}", "{\"n\": 10479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3670.35, \"learn_time_ms\": 14800.793}", "{\"n\": 10480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3670.35, \"learn_time_ms\": 14792.558}", "{\"n\": 10481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.4, \"learn_time_ms\": 14804.226}", "{\"n\": 10482, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.61, \"learn_time_ms\": 14806.028}", "{\"n\": 10483, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3654.28, \"learn_time_ms\": 14806.177}", "{\"n\": 10484, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3654.28, \"learn_time_ms\": 14800.83}", "{\"n\": 10485, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3658.33, \"learn_time_ms\": 14796.224}", "{\"n\": 10486, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3645.12, \"learn_time_ms\": 14807.224}", "{\"n\": 10487, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3636.17, \"learn_time_ms\": 14805.123}", "{\"n\": 10488, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3645.35, \"learn_time_ms\": 14800.973}", "{\"n\": 10489, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.06, \"learn_time_ms\": 14796.375}", "{\"n\": 10490, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.48, \"learn_time_ms\": 14780.995}", "{\"n\": 10491, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.48, \"learn_time_ms\": 14766.321}", "{\"n\": 10492, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3658.81, \"learn_time_ms\": 14764.521}", "{\"n\": 10493, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3671.79, \"learn_time_ms\": 14776.919}", "{\"n\": 10494, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3671.79, \"learn_time_ms\": 14781.291}", "{\"n\": 10495, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3678.7, \"learn_time_ms\": 14776.99}", "{\"n\": 10496, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.92, \"learn_time_ms\": 14776.507}", "{\"n\": 10497, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.92, \"learn_time_ms\": 14774.867}", "{\"n\": 10498, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3693.07, \"learn_time_ms\": 14759.793}", "{\"n\": 10499, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3693.07, \"learn_time_ms\": 14750.179}", "{\"n\": 10500, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3676.2, \"learn_time_ms\": 14779.989}", "{\"n\": 10501, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3680.84, \"learn_time_ms\": 14784.572}", "{\"n\": 10502, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3680.84, \"learn_time_ms\": 14778.354}", "{\"n\": 10503, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.36, \"learn_time_ms\": 14757.53}", "{\"n\": 10504, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3689.11, \"learn_time_ms\": 14757.169}", "{\"n\": 10505, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3689.11, \"learn_time_ms\": 14754.366}", "{\"n\": 10506, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3696.21, \"learn_time_ms\": 14760.024}", "{\"n\": 10507, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3693.47, \"learn_time_ms\": 14774.271}", "{\"n\": 10508, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3693.47, \"learn_time_ms\": 14795.929}", "{\"n\": 10509, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3682.88, \"learn_time_ms\": 14816.98}", "{\"n\": 10510, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3690.98, \"learn_time_ms\": 14804.414}", "{\"n\": 10511, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3682.9, \"learn_time_ms\": 14809.386}", "{\"n\": 10512, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3681.93, \"learn_time_ms\": 14798.637}", "{\"n\": 10513, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.92, \"learn_time_ms\": 14812.589}", "{\"n\": 10514, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3689.43, \"learn_time_ms\": 14826.054}", "{\"n\": 10515, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3689.43, \"learn_time_ms\": 14838.118}", "{\"n\": 10516, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3685.44, \"learn_time_ms\": 14829.534}", "{\"n\": 10517, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3685.44, \"learn_time_ms\": 14824.865}", "{\"n\": 10518, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3678.0, \"learn_time_ms\": 14819.353}", "{\"n\": 10519, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3666.35, \"learn_time_ms\": 14811.531}", "{\"n\": 10520, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3685.29, \"learn_time_ms\": 14812.418}", "{\"n\": 10521, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3679.44, \"learn_time_ms\": 14790.491}", "{\"n\": 10522, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3677.22, \"learn_time_ms\": 14802.694}", "{\"n\": 10523, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3678.68, \"learn_time_ms\": 14797.411}", "{\"n\": 10524, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3674.22, \"learn_time_ms\": 14782.223}", "{\"n\": 10525, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3669.27, \"learn_time_ms\": 14775.599}", "{\"n\": 10526, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3669.27, \"learn_time_ms\": 14766.715}", "{\"n\": 10527, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.08, \"learn_time_ms\": 14759.103}", "{\"n\": 10528, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3668.53, \"learn_time_ms\": 14756.832}", "{\"n\": 10529, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3671.4, \"learn_time_ms\": 14755.611}", "{\"n\": 10530, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3649.44, \"learn_time_ms\": 14752.328}", "{\"n\": 10531, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3646.66, \"learn_time_ms\": 14773.28}", "{\"n\": 10532, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3646.66, \"learn_time_ms\": 14777.257}", "{\"n\": 10533, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3644.06, \"learn_time_ms\": 14771.751}", "{\"n\": 10534, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3640.89, \"learn_time_ms\": 14774.117}", "{\"n\": 10535, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.98, \"learn_time_ms\": 14776.82}", "{\"n\": 10536, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.98, \"learn_time_ms\": 14804.085}", "{\"n\": 10537, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.2, \"learn_time_ms\": 14801.935}", "{\"n\": 10538, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.55, \"learn_time_ms\": 14804.065}", "{\"n\": 10539, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.9, \"learn_time_ms\": 14813.331}", "{\"n\": 10540, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.9, \"learn_time_ms\": 14808.144}", "{\"n\": 10541, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.95, \"learn_time_ms\": 14788.854}", "{\"n\": 10542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3643.7, \"learn_time_ms\": 14784.665}", "{\"n\": 10543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3643.0, \"learn_time_ms\": 14789.453}", "{\"n\": 10544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3633.62, \"learn_time_ms\": 14786.52}", "{\"n\": 10545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3635.54, \"learn_time_ms\": 14782.195}", "{\"n\": 10546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3635.54, \"learn_time_ms\": 14767.6}", "{\"n\": 10547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3636.5, \"learn_time_ms\": 14765.697}", "{\"n\": 10548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.56, \"learn_time_ms\": 14773.761}", "{\"n\": 10549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.56, \"learn_time_ms\": 14760.013}", "{\"n\": 10550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3641.65, \"learn_time_ms\": 14758.186}", "{\"n\": 10551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3641.65, \"learn_time_ms\": 14763.307}", "{\"n\": 10552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3641.65, \"learn_time_ms\": 14761.221}", "{\"n\": 10553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3631.98, \"learn_time_ms\": 14768.452}", "{\"n\": 10554, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3650.16, \"learn_time_ms\": 14777.026}", "{\"n\": 10555, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3653.36, \"learn_time_ms\": 14778.263}", "{\"n\": 10556, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.38, \"learn_time_ms\": 14770.89}", "{\"n\": 10557, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3638.52, \"learn_time_ms\": 14797.456}", "{\"n\": 10558, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3636.8, \"learn_time_ms\": 14791.152}", "{\"n\": 10559, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3636.8, \"learn_time_ms\": 14800.643}", "{\"n\": 10560, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3631.92, \"learn_time_ms\": 14813.82}", "{\"n\": 10561, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.78, \"learn_time_ms\": 14838.295}", "{\"n\": 10562, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3643.07, \"learn_time_ms\": 14844.908}", "{\"n\": 10563, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3646.44, \"learn_time_ms\": 14833.638}", "{\"n\": 10564, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3646.44, \"learn_time_ms\": 14822.16}", "{\"n\": 10565, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3646.44, \"learn_time_ms\": 14835.502}", "{\"n\": 10566, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3626.95, \"learn_time_ms\": 14839.356}", "{\"n\": 10567, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3621.81, \"learn_time_ms\": 14819.43}", "{\"n\": 10568, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.31, \"learn_time_ms\": 14823.29}", "{\"n\": 10569, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.31, \"learn_time_ms\": 14824.29}", "{\"n\": 10570, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3598.84, \"learn_time_ms\": 14823.202}", "{\"n\": 10571, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3598.84, \"learn_time_ms\": 14808.249}", "{\"n\": 10572, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.05, \"learn_time_ms\": 14795.643}", "{\"n\": 10573, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.82, \"learn_time_ms\": 14802.034}", "{\"n\": 10574, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3606.78, \"learn_time_ms\": 14801.723}", "{\"n\": 10575, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3606.78, \"learn_time_ms\": 14787.792}", "{\"n\": 10576, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3608.15, \"learn_time_ms\": 14795.858}", "{\"n\": 10577, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3608.15, \"learn_time_ms\": 14792.92}", "{\"n\": 10578, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3606.37, \"learn_time_ms\": 14795.719}", "{\"n\": 10579, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3590.03, \"learn_time_ms\": 14781.684}", "{\"n\": 10580, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3589.13, \"learn_time_ms\": 14766.677}", "{\"n\": 10581, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3588.11, \"learn_time_ms\": 14769.828}", "{\"n\": 10582, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3584.74, \"learn_time_ms\": 14773.783}", "{\"n\": 10583, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3584.74, \"learn_time_ms\": 14765.465}", "{\"n\": 10584, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3586.52, \"learn_time_ms\": 14767.101}", "{\"n\": 10585, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.9, \"learn_time_ms\": 14771.567}", "{\"n\": 10586, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3592.76, \"learn_time_ms\": 14771.093}", "{\"n\": 10587, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3598.44, \"learn_time_ms\": 14784.659}", "{\"n\": 10588, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3598.44, \"learn_time_ms\": 14771.123}", "{\"n\": 10589, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3587.72, \"learn_time_ms\": 14775.29}", "{\"n\": 10590, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3581.31, \"learn_time_ms\": 14772.352}", "{\"n\": 10591, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3573.03, \"learn_time_ms\": 14763.685}", "{\"n\": 10592, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3556.33, \"learn_time_ms\": 14768.17}", "{\"n\": 10593, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3560.61, \"learn_time_ms\": 14778.641}", "{\"n\": 10594, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3558.91, \"learn_time_ms\": 14769.446}", "{\"n\": 10595, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3558.91, \"learn_time_ms\": 14771.973}", "{\"n\": 10596, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3572.25, \"learn_time_ms\": 14769.505}", "{\"n\": 10597, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3581.53, \"learn_time_ms\": 14749.225}", "{\"n\": 10598, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3581.53, \"learn_time_ms\": 14759.077}", "{\"n\": 10599, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3598.49, \"learn_time_ms\": 14769.139}", "{\"n\": 10600, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.85, \"learn_time_ms\": 14783.799}", "{\"n\": 10601, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.85, \"learn_time_ms\": 14791.043}", "{\"n\": 10602, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3581.89, \"learn_time_ms\": 14787.654}", "{\"n\": 10603, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3574.74, \"learn_time_ms\": 14786.349}", "{\"n\": 10604, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3567.72, \"learn_time_ms\": 14796.575}", "{\"n\": 10605, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3567.72, \"learn_time_ms\": 14794.522}", "{\"n\": 10606, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3586.56, \"learn_time_ms\": 14803.412}", "{\"n\": 10607, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.53, \"learn_time_ms\": 14812.177}", "{\"n\": 10608, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3586.66, \"learn_time_ms\": 14810.033}", "{\"n\": 10609, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3588.02, \"learn_time_ms\": 14811.767}", "{\"n\": 10610, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.68, \"learn_time_ms\": 14819.448}", "{\"n\": 10611, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3592.18, \"learn_time_ms\": 14824.831}", "{\"n\": 10612, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3605.28, \"learn_time_ms\": 14828.481}", "{\"n\": 10613, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3605.28, \"learn_time_ms\": 14818.639}", "{\"n\": 10614, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3596.54, \"learn_time_ms\": 14810.735}", "{\"n\": 10615, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3596.54, \"learn_time_ms\": 14811.422}", "{\"n\": 10616, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3600.36, \"learn_time_ms\": 14800.338}", "{\"n\": 10617, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3591.69, \"learn_time_ms\": 14800.47}", "{\"n\": 10618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3582.18, \"learn_time_ms\": 14811.356}", "{\"n\": 10619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3582.18, \"learn_time_ms\": 14805.474}", "{\"n\": 10620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3578.25, \"learn_time_ms\": 14799.291}", "{\"n\": 10621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3593.48, \"learn_time_ms\": 14791.058}", "{\"n\": 10622, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3613.26, \"learn_time_ms\": 14787.787}", "{\"n\": 10623, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.92, \"learn_time_ms\": 14795.578}", "{\"n\": 10624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.92, \"learn_time_ms\": 14803.703}", "{\"n\": 10625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.92, \"learn_time_ms\": 14798.432}", "{\"n\": 10626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.92, \"learn_time_ms\": 14797.376}", "{\"n\": 10627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3613.39, \"learn_time_ms\": 14792.227}", "{\"n\": 10628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.96, \"learn_time_ms\": 14795.582}", "{\"n\": 10629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.96, \"learn_time_ms\": 14796.014}", "{\"n\": 10630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.38, \"learn_time_ms\": 14787.42}", "{\"n\": 10631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.38, \"learn_time_ms\": 14784.791}", "{\"n\": 10632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.38, \"learn_time_ms\": 14790.72}", "{\"n\": 10633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.54, \"learn_time_ms\": 14785.551}", "{\"n\": 10634, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.85, \"learn_time_ms\": 14782.154}", "{\"n\": 10635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.71, \"learn_time_ms\": 14784.519}", "{\"n\": 10636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.71, \"learn_time_ms\": 14793.828}", "{\"n\": 10637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.33, \"learn_time_ms\": 14788.263}", "{\"n\": 10638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.33, \"learn_time_ms\": 14771.106}", "{\"n\": 10639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3646.82, \"learn_time_ms\": 14768.241}", "{\"n\": 10640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.4, \"learn_time_ms\": 14784.344}", "{\"n\": 10641, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3669.43, \"learn_time_ms\": 14785.519}", "{\"n\": 10642, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3660.96, \"learn_time_ms\": 14780.152}", "{\"n\": 10643, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.64, \"learn_time_ms\": 14779.127}", "{\"n\": 10644, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3656.18, \"learn_time_ms\": 14773.839}", "{\"n\": 10645, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.04, \"learn_time_ms\": 14782.188}", "{\"n\": 10646, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.52, \"learn_time_ms\": 14775.881}", "{\"n\": 10647, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3686.78, \"learn_time_ms\": 14793.461}", "{\"n\": 10648, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.7, \"learn_time_ms\": 14798.133}", "{\"n\": 10649, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3675.85, \"learn_time_ms\": 14798.537}", "{\"n\": 10650, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3677.73, \"learn_time_ms\": 14797.313}", "{\"n\": 10651, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3668.68, \"learn_time_ms\": 14802.429}", "{\"n\": 10652, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3663.77, \"learn_time_ms\": 14803.254}", "{\"n\": 10653, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3663.4, \"learn_time_ms\": 14808.272}", "{\"n\": 10654, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3663.4, \"learn_time_ms\": 14819.568}", "{\"n\": 10655, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3656.99, \"learn_time_ms\": 14817.127}", "{\"n\": 10656, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3656.99, \"learn_time_ms\": 14815.154}", "{\"n\": 10657, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3674.24, \"learn_time_ms\": 14808.889}", "{\"n\": 10658, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3665.97, \"learn_time_ms\": 14805.354}", "{\"n\": 10659, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.48, \"learn_time_ms\": 14805.906}", "{\"n\": 10660, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3658.11, \"learn_time_ms\": 14795.904}", "{\"n\": 10661, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3669.85, \"learn_time_ms\": 14789.708}", "{\"n\": 10662, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3669.85, \"learn_time_ms\": 14791.957}", "{\"n\": 10663, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.99, \"learn_time_ms\": 14789.611}", "{\"n\": 10664, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3663.34, \"learn_time_ms\": 14793.948}", "{\"n\": 10665, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.72, \"learn_time_ms\": 14780.756}", "{\"n\": 10666, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3672.62, \"learn_time_ms\": 14791.486}", "{\"n\": 10667, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3666.21, \"learn_time_ms\": 14802.172}", "{\"n\": 10668, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3666.21, \"learn_time_ms\": 14813.706}", "{\"n\": 10669, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.62, \"learn_time_ms\": 14812.963}", "{\"n\": 10670, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.68, \"learn_time_ms\": 14816.602}", "{\"n\": 10671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3682.48, \"learn_time_ms\": 14825.421}", "{\"n\": 10672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3686.51, \"learn_time_ms\": 14835.606}", "{\"n\": 10673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.27, \"learn_time_ms\": 14844.243}", "{\"n\": 10674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.62, \"learn_time_ms\": 14837.52}", "{\"n\": 10675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.95, \"learn_time_ms\": 14839.047}", "{\"n\": 10676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.95, \"learn_time_ms\": 14842.08}", "{\"n\": 10677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3658.6, \"learn_time_ms\": 14838.331}", "{\"n\": 10678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3660.86, \"learn_time_ms\": 14836.798}", "{\"n\": 10679, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.24, \"learn_time_ms\": 14834.146}", "{\"n\": 10680, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.17, \"learn_time_ms\": 14826.43}", "{\"n\": 10681, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.65, \"learn_time_ms\": 14827.053}", "{\"n\": 10682, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3666.25, \"learn_time_ms\": 14822.773}", "{\"n\": 10683, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.33, \"learn_time_ms\": 14824.866}", "{\"n\": 10684, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.74, \"learn_time_ms\": 14827.149}", "{\"n\": 10685, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.56, \"learn_time_ms\": 14842.744}", "{\"n\": 10686, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.99, \"learn_time_ms\": 14849.913}", "{\"n\": 10687, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.23, \"learn_time_ms\": 14852.612}", "{\"n\": 10688, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3695.01, \"learn_time_ms\": 14851.286}", "{\"n\": 10689, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.93, \"learn_time_ms\": 14851.466}", "{\"n\": 10690, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3690.93, \"learn_time_ms\": 14859.555}", "{\"n\": 10691, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.31, \"learn_time_ms\": 14859.62}", "{\"n\": 10692, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3710.55, \"learn_time_ms\": 14858.524}", "{\"n\": 10693, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.63, \"learn_time_ms\": 14849.437}", "{\"n\": 10694, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.63, \"learn_time_ms\": 14856.427}", "{\"n\": 10695, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3716.62, \"learn_time_ms\": 14850.716}", "{\"n\": 10696, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3716.62, \"learn_time_ms\": 14842.577}", "{\"n\": 10697, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.96, \"learn_time_ms\": 14835.862}", "{\"n\": 10698, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.03, \"learn_time_ms\": 14831.115}", "{\"n\": 10699, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3700.94, \"learn_time_ms\": 14843.414}", "{\"n\": 10700, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.57, \"learn_time_ms\": 14832.156}", "{\"n\": 10701, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3704.37, \"learn_time_ms\": 14827.067}", "{\"n\": 10702, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.44, \"learn_time_ms\": 14831.832}", "{\"n\": 10703, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.44, \"learn_time_ms\": 14850.09}", "{\"n\": 10704, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3719.75, \"learn_time_ms\": 14851.865}", "{\"n\": 10705, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3718.09, \"learn_time_ms\": 14851.691}", "{\"n\": 10706, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3718.09, \"learn_time_ms\": 14851.422}", "{\"n\": 10707, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3721.0, \"learn_time_ms\": 14860.116}", "{\"n\": 10708, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.06, \"learn_time_ms\": 14851.176}", "{\"n\": 10709, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3730.03, \"learn_time_ms\": 14837.796}", "{\"n\": 10710, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3733.73, \"learn_time_ms\": 14857.427}", "{\"n\": 10711, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.36, \"learn_time_ms\": 14867.408}", "{\"n\": 10712, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3744.95, \"learn_time_ms\": 14859.006}", "{\"n\": 10713, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.78, \"learn_time_ms\": 14843.132}", "{\"n\": 10714, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.78, \"learn_time_ms\": 14833.767}", "{\"n\": 10715, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3749.26, \"learn_time_ms\": 14830.792}", "{\"n\": 10716, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.54, \"learn_time_ms\": 14821.534}", "{\"n\": 10717, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.54, \"learn_time_ms\": 14819.942}", "{\"n\": 10718, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3739.59, \"learn_time_ms\": 14830.58}", "{\"n\": 10719, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3734.04, \"learn_time_ms\": 14844.25}", "{\"n\": 10720, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3726.38, \"learn_time_ms\": 14834.819}", "{\"n\": 10721, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3733.67, \"learn_time_ms\": 14829.518}", "{\"n\": 10722, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3732.86, \"learn_time_ms\": 14823.19}", "{\"n\": 10723, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.57, \"learn_time_ms\": 14832.894}", "{\"n\": 10724, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.57, \"learn_time_ms\": 14834.832}", "{\"n\": 10725, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3733.32, \"learn_time_ms\": 14837.704}", "{\"n\": 10726, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.44, \"learn_time_ms\": 14841.512}", "{\"n\": 10727, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.0, \"learn_time_ms\": 14845.172}", "{\"n\": 10728, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3753.8, \"learn_time_ms\": 14821.686}", "{\"n\": 10729, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3766.1, \"learn_time_ms\": 14820.974}", "{\"n\": 10730, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3766.1, \"learn_time_ms\": 14834.344}", "{\"n\": 10731, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3766.1, \"learn_time_ms\": 14832.835}", "{\"n\": 10732, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3766.55, \"learn_time_ms\": 14841.322}", "{\"n\": 10733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3790.05, \"learn_time_ms\": 14837.49}", "{\"n\": 10734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.44, \"learn_time_ms\": 14842.557}", "{\"n\": 10735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.44, \"learn_time_ms\": 14835.469}", "{\"n\": 10736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.44, \"learn_time_ms\": 14826.431}", "{\"n\": 10737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.44, \"learn_time_ms\": 14813.7}", "{\"n\": 10738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3770.47, \"learn_time_ms\": 14842.399}", "{\"n\": 10739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3768.05, \"learn_time_ms\": 14827.551}", "{\"n\": 10740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3769.07, \"learn_time_ms\": 14814.964}", "{\"n\": 10741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3763.26, \"learn_time_ms\": 14817.706}", "{\"n\": 10742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3763.26, \"learn_time_ms\": 14813.131}", "{\"n\": 10743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3769.59, \"learn_time_ms\": 14812.427}", "{\"n\": 10744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3769.59, \"learn_time_ms\": 14809.13}", "{\"n\": 10745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.71, \"learn_time_ms\": 14818.457}", "{\"n\": 10746, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3779.02, \"learn_time_ms\": 14831.55}", "{\"n\": 10747, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3798.58, \"learn_time_ms\": 14841.286}", "{\"n\": 10748, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3806.82, \"learn_time_ms\": 14840.806}", "{\"n\": 10749, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3806.82, \"learn_time_ms\": 14856.871}", "{\"n\": 10750, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3788.12, \"learn_time_ms\": 14844.008}", "{\"n\": 10751, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3796.13, \"learn_time_ms\": 14833.393}", "{\"n\": 10752, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3803.05, \"learn_time_ms\": 14847.862}", "{\"n\": 10753, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3818.78, \"learn_time_ms\": 14848.916}", "{\"n\": 10754, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3828.8, \"learn_time_ms\": 14856.285}", "{\"n\": 10755, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3828.35, \"learn_time_ms\": 14860.619}", "{\"n\": 10756, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3837.5, \"learn_time_ms\": 14868.498}", "{\"n\": 10757, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3835.38, \"learn_time_ms\": 14862.309}", "{\"n\": 10758, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3827.23, \"learn_time_ms\": 14855.093}", "{\"n\": 10759, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3824.14, \"learn_time_ms\": 14850.415}", "{\"n\": 10760, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3838.09, \"learn_time_ms\": 14884.667}", "{\"n\": 10761, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3831.82, \"learn_time_ms\": 14898.412}", "{\"n\": 10762, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3830.61, \"learn_time_ms\": 14877.295}", "{\"n\": 10763, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3830.61, \"learn_time_ms\": 14869.754}", "{\"n\": 10764, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3823.51, \"learn_time_ms\": 14867.087}", "{\"n\": 10765, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3812.45, \"learn_time_ms\": 14854.598}", "{\"n\": 10766, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3812.45, \"learn_time_ms\": 14833.144}", "{\"n\": 10767, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3810.85, \"learn_time_ms\": 14816.19}", "{\"n\": 10768, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3800.32, \"learn_time_ms\": 14804.777}", "{\"n\": 10769, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.17, \"learn_time_ms\": 14797.353}", "{\"n\": 10770, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.27, \"learn_time_ms\": 14771.146}", "{\"n\": 10771, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.67, \"learn_time_ms\": 14766.405}", "{\"n\": 10772, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.67, \"learn_time_ms\": 14779.063}", "{\"n\": 10773, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3781.67, \"learn_time_ms\": 14777.866}", "{\"n\": 10774, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3778.06, \"learn_time_ms\": 14782.311}", "{\"n\": 10775, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3779.66, \"learn_time_ms\": 14785.663}", "{\"n\": 10776, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3769.58, \"learn_time_ms\": 14789.31}", "{\"n\": 10777, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3770.51, \"learn_time_ms\": 14799.325}", "{\"n\": 10778, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3770.51, \"learn_time_ms\": 14823.778}", "{\"n\": 10779, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3770.51, \"learn_time_ms\": 14831.589}", "{\"n\": 10780, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3770.51, \"learn_time_ms\": 14838.097}", "{\"n\": 10781, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3765.71, \"learn_time_ms\": 14843.463}", "{\"n\": 10782, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3769.15, \"learn_time_ms\": 14839.223}", "{\"n\": 10783, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3762.09, \"learn_time_ms\": 14845.167}", "{\"n\": 10784, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3761.61, \"learn_time_ms\": 14847.325}", "{\"n\": 10785, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3761.61, \"learn_time_ms\": 14850.984}", "{\"n\": 10786, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3767.44, \"learn_time_ms\": 14868.703}", "{\"n\": 10787, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3767.31, \"learn_time_ms\": 14875.391}", "{\"n\": 10788, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3768.67, \"learn_time_ms\": 14863.654}", "{\"n\": 10789, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3764.61, \"learn_time_ms\": 14871.486}", "{\"n\": 10790, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.36, \"learn_time_ms\": 14869.83}", "{\"n\": 10791, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3753.84, \"learn_time_ms\": 14875.293}", "{\"n\": 10792, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3742.63, \"learn_time_ms\": 14876.0}", "{\"n\": 10793, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3744.6, \"learn_time_ms\": 14875.207}", "{\"n\": 10794, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3744.7, \"learn_time_ms\": 14866.551}", "{\"n\": 10795, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3746.77, \"learn_time_ms\": 14865.48}", "{\"n\": 10796, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3754.3, \"learn_time_ms\": 14844.151}", "{\"n\": 10797, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3763.98, \"learn_time_ms\": 14846.833}", "{\"n\": 10798, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3771.66, \"learn_time_ms\": 14846.124}", "{\"n\": 10799, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3770.41, \"learn_time_ms\": 14826.68}", "{\"n\": 10800, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3770.41, \"learn_time_ms\": 14825.108}", "{\"n\": 10801, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3767.27, \"learn_time_ms\": 14817.379}", "{\"n\": 10802, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3777.83, \"learn_time_ms\": 14819.883}", "{\"n\": 10803, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3771.65, \"learn_time_ms\": 14818.082}", "{\"n\": 10804, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3766.27, \"learn_time_ms\": 14822.226}", "{\"n\": 10805, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3766.27, \"learn_time_ms\": 14822.585}", "{\"n\": 10806, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3756.33, \"learn_time_ms\": 14831.315}", "{\"n\": 10807, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3756.82, \"learn_time_ms\": 14827.862}", "{\"n\": 10808, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3752.54, \"learn_time_ms\": 14830.247}", "{\"n\": 10809, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3758.98, \"learn_time_ms\": 14852.625}", "{\"n\": 10810, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3756.78, \"learn_time_ms\": 14859.396}", "{\"n\": 10811, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3766.82, \"learn_time_ms\": 14852.732}", "{\"n\": 10812, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3766.34, \"learn_time_ms\": 14852.842}", "{\"n\": 10813, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3766.34, \"learn_time_ms\": 14853.562}", "{\"n\": 10814, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3773.56, \"learn_time_ms\": 14836.949}", "{\"n\": 10815, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3782.16, \"learn_time_ms\": 14841.826}", "{\"n\": 10816, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3795.97, \"learn_time_ms\": 14852.224}", "{\"n\": 10817, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3784.32, \"learn_time_ms\": 14856.399}", "{\"n\": 10818, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3767.54, \"learn_time_ms\": 14853.206}", "{\"n\": 10819, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3767.54, \"learn_time_ms\": 14838.521}", "{\"n\": 10820, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3767.54, \"learn_time_ms\": 14835.221}", "{\"n\": 10821, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.75, \"learn_time_ms\": 14824.122}", "{\"n\": 10822, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.84, \"learn_time_ms\": 14807.665}", "{\"n\": 10823, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3771.43, \"learn_time_ms\": 14818.136}", "{\"n\": 10824, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3771.43, \"learn_time_ms\": 14834.461}", "{\"n\": 10825, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.31, \"learn_time_ms\": 14826.132}", "{\"n\": 10826, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3771.12, \"learn_time_ms\": 14816.665}", "{\"n\": 10827, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3768.68, \"learn_time_ms\": 14805.937}", "{\"n\": 10828, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3780.56, \"learn_time_ms\": 14807.712}", "{\"n\": 10829, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3772.71, \"learn_time_ms\": 14806.18}", "{\"n\": 10830, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.25, \"learn_time_ms\": 14808.359}", "{\"n\": 10831, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.25, \"learn_time_ms\": 14828.433}", "{\"n\": 10832, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3763.25, \"learn_time_ms\": 14845.859}", "{\"n\": 10833, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3757.96, \"learn_time_ms\": 14841.576}", "{\"n\": 10834, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3756.44, \"learn_time_ms\": 14828.347}", "{\"n\": 10835, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3756.44, \"learn_time_ms\": 14826.966}", "{\"n\": 10836, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3751.75, \"learn_time_ms\": 14835.16}", "{\"n\": 10837, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3750.57, \"learn_time_ms\": 14834.213}", "{\"n\": 10838, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3748.34, \"learn_time_ms\": 14829.808}", "{\"n\": 10839, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3748.34, \"learn_time_ms\": 14829.463}", "{\"n\": 10840, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3754.06, \"learn_time_ms\": 14839.046}", "{\"n\": 10841, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3761.87, \"learn_time_ms\": 14822.306}", "{\"n\": 10842, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.97, \"learn_time_ms\": 14808.519}", "{\"n\": 10843, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3760.12, \"learn_time_ms\": 14804.054}", "{\"n\": 10844, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3760.12, \"learn_time_ms\": 14811.909}", "{\"n\": 10845, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3752.87, \"learn_time_ms\": 14817.598}", "{\"n\": 10846, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3756.48, \"learn_time_ms\": 14813.285}", "{\"n\": 10847, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.82, \"learn_time_ms\": 14828.909}", "{\"n\": 10848, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3768.77, \"learn_time_ms\": 14826.594}", "{\"n\": 10849, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.42, \"learn_time_ms\": 14833.532}", "{\"n\": 10850, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.42, \"learn_time_ms\": 14819.289}", "{\"n\": 10851, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.42, \"learn_time_ms\": 14835.94}", "{\"n\": 10852, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3769.0, \"learn_time_ms\": 14851.491}", "{\"n\": 10853, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3774.08, \"learn_time_ms\": 14855.044}", "{\"n\": 10854, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3774.4, \"learn_time_ms\": 14854.624}", "{\"n\": 10855, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3785.88, \"learn_time_ms\": 14860.456}", "{\"n\": 10856, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3785.88, \"learn_time_ms\": 14853.201}", "{\"n\": 10857, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3785.88, \"learn_time_ms\": 14837.653}", "{\"n\": 10858, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3794.04, \"learn_time_ms\": 14851.702}", "{\"n\": 10859, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3794.04, \"learn_time_ms\": 14848.528}", "{\"n\": 10860, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3792.07, \"learn_time_ms\": 14857.381}", "{\"n\": 10861, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3808.91, \"learn_time_ms\": 14841.811}", "{\"n\": 10862, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3811.12, \"learn_time_ms\": 14827.8}", "{\"n\": 10863, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3811.12, \"learn_time_ms\": 14818.655}", "{\"n\": 10864, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3811.12, \"learn_time_ms\": 14811.968}", "{\"n\": 10865, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3807.36, \"learn_time_ms\": 14807.931}", "{\"n\": 10866, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3811.06, \"learn_time_ms\": 14814.613}", "{\"n\": 10867, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3800.84, \"learn_time_ms\": 14819.915}", "{\"n\": 10868, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3808.75, \"learn_time_ms\": 14818.04}", "{\"n\": 10869, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3807.93, \"learn_time_ms\": 14812.334}", "{\"n\": 10870, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3807.93, \"learn_time_ms\": 14814.641}", "{\"n\": 10871, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3807.93, \"learn_time_ms\": 14822.161}", "{\"n\": 10872, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3819.8, \"learn_time_ms\": 14827.263}", "{\"n\": 10873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3820.5, \"learn_time_ms\": 14822.475}", "{\"n\": 10874, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3816.9, \"learn_time_ms\": 14831.633}", "{\"n\": 10875, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3820.23, \"learn_time_ms\": 14811.532}", "{\"n\": 10876, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3820.23, \"learn_time_ms\": 14808.137}", "{\"n\": 10877, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3813.62, \"learn_time_ms\": 14816.954}", "{\"n\": 10878, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3818.02, \"learn_time_ms\": 14804.394}", "{\"n\": 10879, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3818.02, \"learn_time_ms\": 14804.985}", "{\"n\": 10880, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3822.21, \"learn_time_ms\": 14797.231}", "{\"n\": 10881, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3814.08, \"learn_time_ms\": 14790.867}", "{\"n\": 10882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3818.93, \"learn_time_ms\": 14779.991}", "{\"n\": 10883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3818.93, \"learn_time_ms\": 14783.186}", "{\"n\": 10884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3818.93, \"learn_time_ms\": 14779.752}", "{\"n\": 10885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3815.75, \"learn_time_ms\": 14799.017}", "{\"n\": 10886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3825.71, \"learn_time_ms\": 14805.148}", "{\"n\": 10887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3830.28, \"learn_time_ms\": 14793.688}", "{\"n\": 10888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3826.2, \"learn_time_ms\": 14803.045}", "{\"n\": 10889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3830.61, \"learn_time_ms\": 14807.044}", "{\"n\": 10890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3830.61, \"learn_time_ms\": 14811.055}", "{\"n\": 10891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3823.55, \"learn_time_ms\": 14815.772}", "{\"n\": 10892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3817.92, \"learn_time_ms\": 14827.398}", "{\"n\": 10893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3829.24, \"learn_time_ms\": 14832.826}", "{\"n\": 10894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3840.38, \"learn_time_ms\": 14829.817}", "{\"n\": 10895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3840.38, \"learn_time_ms\": 14811.41}", "{\"n\": 10896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3843.71, \"learn_time_ms\": 14806.109}", "{\"n\": 10897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3843.71, \"learn_time_ms\": 14793.628}", "{\"n\": 10898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3849.61, \"learn_time_ms\": 14781.432}", "{\"n\": 10899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3871.91, \"learn_time_ms\": 14782.534}", "{\"n\": 10900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3871.91, \"learn_time_ms\": 14780.772}", "{\"n\": 10901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3873.99, \"learn_time_ms\": 14788.021}", "{\"n\": 10902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3873.99, \"learn_time_ms\": 14797.835}", "{\"n\": 10903, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3890.19, \"learn_time_ms\": 14809.791}", "{\"n\": 10904, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3890.19, \"learn_time_ms\": 14816.517}", "{\"n\": 10905, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3863.18, \"learn_time_ms\": 14828.138}", "{\"n\": 10906, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3866.16, \"learn_time_ms\": 14823.367}", "{\"n\": 10907, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3864.83, \"learn_time_ms\": 14844.714}", "{\"n\": 10908, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3870.34, \"learn_time_ms\": 14846.896}", "{\"n\": 10909, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3872.28, \"learn_time_ms\": 14832.564}", "{\"n\": 10910, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3872.28, \"learn_time_ms\": 14827.855}", "{\"n\": 10911, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3872.93, \"learn_time_ms\": 14815.678}", "{\"n\": 10912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3882.82, \"learn_time_ms\": 14803.498}", "{\"n\": 10913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3882.82, \"learn_time_ms\": 14787.785}", "{\"n\": 10914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3885.29, \"learn_time_ms\": 14782.62}", "{\"n\": 10915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3893.19, \"learn_time_ms\": 14791.323}", "{\"n\": 10916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3888.47, \"learn_time_ms\": 14793.448}", "{\"n\": 10917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3888.47, \"learn_time_ms\": 14797.645}", "{\"n\": 10918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3891.52, \"learn_time_ms\": 14798.993}", "{\"n\": 10919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3902.05, \"learn_time_ms\": 14813.888}", "{\"n\": 10920, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3902.05, \"learn_time_ms\": 14810.044}", "{\"n\": 10921, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3902.05, \"learn_time_ms\": 14808.767}", "{\"n\": 10922, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3908.95, \"learn_time_ms\": 14806.273}", "{\"n\": 10923, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3914.66, \"learn_time_ms\": 14809.84}", "{\"n\": 10924, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3914.9, \"learn_time_ms\": 14807.228}", "{\"n\": 10925, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3919.23, \"learn_time_ms\": 14797.6}", "{\"n\": 10926, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3919.23, \"learn_time_ms\": 14763.062}", "{\"n\": 10927, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3918.39, \"learn_time_ms\": 14747.198}", "{\"n\": 10928, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3918.39, \"learn_time_ms\": 14748.242}", "{\"n\": 10929, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3911.72, \"learn_time_ms\": 14748.881}", "{\"n\": 10930, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3910.13, \"learn_time_ms\": 14754.387}", "{\"n\": 10931, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3910.13, \"learn_time_ms\": 14760.438}", "{\"n\": 10932, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3910.13, \"learn_time_ms\": 14751.104}", "{\"n\": 10933, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3910.13, \"learn_time_ms\": 14753.239}", "{\"n\": 10934, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3914.02, \"learn_time_ms\": 14754.576}", "{\"n\": 10935, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3915.38, \"learn_time_ms\": 14755.861}", "{\"n\": 10936, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3904.66, \"learn_time_ms\": 14785.343}", "{\"n\": 10937, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3903.51, \"learn_time_ms\": 14791.293}", "{\"n\": 10938, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3895.41, \"learn_time_ms\": 14805.005}", "{\"n\": 10939, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3895.41, \"learn_time_ms\": 14794.913}", "{\"n\": 10940, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3891.91, \"learn_time_ms\": 14781.718}", "{\"n\": 10941, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3895.75, \"learn_time_ms\": 14788.316}", "{\"n\": 10942, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3894.24, \"learn_time_ms\": 14793.705}", "{\"n\": 10943, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3895.33, \"learn_time_ms\": 14785.223}", "{\"n\": 10944, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3897.74, \"learn_time_ms\": 14787.752}", "{\"n\": 10945, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3884.39, \"learn_time_ms\": 14793.231}", "{\"n\": 10946, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3884.39, \"learn_time_ms\": 14798.96}", "{\"n\": 10947, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3872.83, \"learn_time_ms\": 14797.743}", "{\"n\": 10948, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3866.14, \"learn_time_ms\": 14788.722}", "{\"n\": 10949, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3863.78, \"learn_time_ms\": 14799.341}", "{\"n\": 10950, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3862.13, \"learn_time_ms\": 14797.662}", "{\"n\": 10951, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3862.13, \"learn_time_ms\": 14790.551}", "{\"n\": 10952, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3862.13, \"learn_time_ms\": 14802.886}", "{\"n\": 10953, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3864.23, \"learn_time_ms\": 14812.167}", "{\"n\": 10954, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3864.66, \"learn_time_ms\": 14819.355}", "{\"n\": 10955, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3864.19, \"learn_time_ms\": 14814.404}", "{\"n\": 10956, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3856.36, \"learn_time_ms\": 14818.337}", "{\"n\": 10957, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3856.36, \"learn_time_ms\": 14826.109}", "{\"n\": 10958, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3858.96, \"learn_time_ms\": 14825.629}", "{\"n\": 10959, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3858.96, \"learn_time_ms\": 14826.843}", "{\"n\": 10960, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3864.53, \"learn_time_ms\": 14843.403}", "{\"n\": 10961, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3849.24, \"learn_time_ms\": 14844.747}", "{\"n\": 10962, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3840.14, \"learn_time_ms\": 14852.189}", "{\"n\": 10963, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3840.14, \"learn_time_ms\": 14853.96}", "{\"n\": 10964, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3843.79, \"learn_time_ms\": 14847.744}", "{\"n\": 10965, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3843.79, \"learn_time_ms\": 14856.34}", "{\"n\": 10966, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3843.79, \"learn_time_ms\": 14850.003}", "{\"n\": 10967, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3830.14, \"learn_time_ms\": 14845.521}", "{\"n\": 10968, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3825.97, \"learn_time_ms\": 14848.627}", "{\"n\": 10969, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3825.97, \"learn_time_ms\": 14852.797}", "{\"n\": 10970, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3834.61, \"learn_time_ms\": 14848.148}", "{\"n\": 10971, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3834.61, \"learn_time_ms\": 14848.444}", "{\"n\": 10972, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3834.61, \"learn_time_ms\": 14847.889}", "{\"n\": 10973, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3833.07, \"learn_time_ms\": 14842.006}", "{\"n\": 10974, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3819.18, \"learn_time_ms\": 14830.166}", "{\"n\": 10975, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3819.71, \"learn_time_ms\": 14826.088}", "{\"n\": 10976, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3819.71, \"learn_time_ms\": 14824.701}", "{\"n\": 10977, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3816.2, \"learn_time_ms\": 14812.81}", "{\"n\": 10978, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3816.2, \"learn_time_ms\": 14811.123}", "{\"n\": 10979, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3813.29, \"learn_time_ms\": 14789.412}", "{\"n\": 10980, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3804.07, \"learn_time_ms\": 14789.398}", "{\"n\": 10981, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3804.52, \"learn_time_ms\": 14775.903}", "{\"n\": 10982, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3804.52, \"learn_time_ms\": 14761.72}", "{\"n\": 10983, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3804.52, \"learn_time_ms\": 14761.51}", "{\"n\": 10984, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3814.23, \"learn_time_ms\": 14770.914}", "{\"n\": 10985, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3822.65, \"learn_time_ms\": 14771.788}", "{\"n\": 10986, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3809.41, \"learn_time_ms\": 14779.183}", "{\"n\": 10987, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3796.12, \"learn_time_ms\": 14795.297}", "{\"n\": 10988, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3796.12, \"learn_time_ms\": 14796.695}", "{\"n\": 10989, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3798.64, \"learn_time_ms\": 14814.359}", "{\"n\": 10990, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.78, \"learn_time_ms\": 14824.528}", "{\"n\": 10991, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.14, \"learn_time_ms\": 14833.492}", "{\"n\": 10992, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.14, \"learn_time_ms\": 14840.123}", "{\"n\": 10993, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.72, \"learn_time_ms\": 14853.545}", "{\"n\": 10994, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3790.69, \"learn_time_ms\": 14849.821}", "{\"n\": 10995, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.2, \"learn_time_ms\": 14844.213}", "{\"n\": 10996, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3795.0, \"learn_time_ms\": 14843.41}", "{\"n\": 10997, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3796.77, \"learn_time_ms\": 14842.106}", "{\"n\": 10998, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3783.31, \"learn_time_ms\": 14830.308}", "{\"n\": 10999, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3783.31, \"learn_time_ms\": 14832.625}", "{\"n\": 11000, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3790.39, \"learn_time_ms\": 14824.097}"]["{\"n\": 11001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15399.363}", "{\"n\": 11002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15103.027}", "{\"n\": 11003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 15011.365}", "{\"n\": 11004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14953.471}", "{\"n\": 11005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14927.829}", "{\"n\": 11006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14906.631}", "{\"n\": 11007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14900.732}", "{\"n\": 11008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14887.24}", "{\"n\": 11009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14884.478}", "{\"n\": 11010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 14882.896}", "{\"n\": 11011, \"episode_reward_min\": 3.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3660.0, \"learn_time_ms\": 14825.885}", "{\"n\": 11012, \"episode_reward_min\": 3.0, \"episode_reward_mean\": 3.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3660.0, \"learn_time_ms\": 14844.87}", "{\"n\": 11013, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -0.16666666666666666, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3921.3333333333335, \"learn_time_ms\": 14857.001}", "{\"n\": 11014, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3980.25, \"learn_time_ms\": 14867.93}", "{\"n\": 11015, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3980.25, \"learn_time_ms\": 14865.432}", "{\"n\": 11016, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3980.25, \"learn_time_ms\": 14861.189}", "{\"n\": 11017, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3980.25, \"learn_time_ms\": 14863.46}", "{\"n\": 11018, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3774.9, \"learn_time_ms\": 14880.954}", "{\"n\": 11019, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.384615384615385, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3677.5384615384614, \"learn_time_ms\": 14896.023}", "{\"n\": 11020, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3750.875, \"learn_time_ms\": 14900.928}", "{\"n\": 11021, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3750.875, \"learn_time_ms\": 14900.068}", "{\"n\": 11022, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3750.875, \"learn_time_ms\": 14894.526}", "{\"n\": 11023, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3750.875, \"learn_time_ms\": 14903.207}", "{\"n\": 11024, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.222222222222222, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3743.8333333333335, \"learn_time_ms\": 14917.29}", "{\"n\": 11025, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.238095238095238, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3704.2380952380954, \"learn_time_ms\": 14917.684}", "{\"n\": 11026, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.181818181818182, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3718.7272727272725, \"learn_time_ms\": 14933.433}", "{\"n\": 11027, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3739.6666666666665, \"learn_time_ms\": 14933.335}", "{\"n\": 11028, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3739.6666666666665, \"learn_time_ms\": 14909.045}", "{\"n\": 11029, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3716.76, \"learn_time_ms\": 14885.22}", "{\"n\": 11030, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3716.76, \"learn_time_ms\": 14878.031}", "{\"n\": 11031, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.8518518518518516, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3729.8888888888887, \"learn_time_ms\": 14891.623}", "{\"n\": 11032, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.8620689655172415, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3732.793103448276, \"learn_time_ms\": 14896.517}", "{\"n\": 11033, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.6129032258064515, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3758.935483870968, \"learn_time_ms\": 14882.965}", "{\"n\": 11034, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.625, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3766.46875, \"learn_time_ms\": 14867.439}", "{\"n\": 11035, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.787878787878788, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3750.939393939394, \"learn_time_ms\": 14877.759}", "{\"n\": 11036, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.9411764705882355, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3747.6176470588234, \"learn_time_ms\": 14889.281}", "{\"n\": 11037, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0285714285714285, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3750.4, \"learn_time_ms\": 14893.3}", "{\"n\": 11038, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.081081081081081, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3746.5945945945946, \"learn_time_ms\": 14913.838}", "{\"n\": 11039, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.871794871794872, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3753.6666666666665, \"learn_time_ms\": 14919.074}", "{\"n\": 11040, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.871794871794872, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3753.6666666666665, \"learn_time_ms\": 14919.654}", "{\"n\": 11041, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.8536585365853657, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3761.878048780488, \"learn_time_ms\": 14920.789}", "{\"n\": 11042, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.023809523809524, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3739.5476190476193, \"learn_time_ms\": 14921.727}", "{\"n\": 11043, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.177777777777778, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3720.1555555555556, \"learn_time_ms\": 14918.392}", "{\"n\": 11044, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.177777777777778, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3720.1555555555556, \"learn_time_ms\": 14934.485}", "{\"n\": 11045, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.9574468085106385, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3740.8297872340427, \"learn_time_ms\": 14931.602}", "{\"n\": 11046, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.9574468085106385, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3740.8297872340427, \"learn_time_ms\": 14921.649}", "{\"n\": 11047, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3746.0833333333335, \"learn_time_ms\": 14923.223}", "{\"n\": 11048, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3746.0833333333335, \"learn_time_ms\": 14922.022}", "{\"n\": 11049, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.9423076923076925, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3733.6923076923076, \"learn_time_ms\": 14928.701}", "{\"n\": 11050, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3730.735849056604, \"learn_time_ms\": 14930.241}", "{\"n\": 11051, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.074074074074074, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3722.6666666666665, \"learn_time_ms\": 14914.529}", "{\"n\": 11052, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.054545454545455, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3724.4545454545455, \"learn_time_ms\": 14901.137}", "{\"n\": 11053, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.071428571428571, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3718.0714285714284, \"learn_time_ms\": 14909.406}", "{\"n\": 11054, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.071428571428571, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3718.0714285714284, \"learn_time_ms\": 14887.783}", "{\"n\": 11055, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.017241379310345, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3722.7241379310344, \"learn_time_ms\": 14888.216}", "{\"n\": 11056, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.9166666666666665, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3732.0333333333333, \"learn_time_ms\": 14883.371}", "{\"n\": 11057, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.761904761904762, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3740.5396825396824, \"learn_time_ms\": 14880.044}", "{\"n\": 11058, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.65625, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3746.15625, \"learn_time_ms\": 14865.58}", "{\"n\": 11059, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.65625, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3746.15625, \"learn_time_ms\": 14848.967}", "{\"n\": 11060, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5076923076923077, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3747.892307692308, \"learn_time_ms\": 14859.715}", "{\"n\": 11061, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.5076923076923077, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3747.892307692308, \"learn_time_ms\": 14863.578}", "{\"n\": 11062, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.2238805970149254, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3751.6567164179105, \"learn_time_ms\": 14866.385}", "{\"n\": 11063, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2857142857142856, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3735.3, \"learn_time_ms\": 14858.682}", "{\"n\": 11064, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.267605633802817, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3736.6197183098593, \"learn_time_ms\": 14861.727}", "{\"n\": 11065, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3194444444444446, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3737.152777777778, \"learn_time_ms\": 14871.795}", "{\"n\": 11066, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3972602739726026, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.6164383561645, \"learn_time_ms\": 14875.703}", "{\"n\": 11067, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3972602739726026, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.6164383561645, \"learn_time_ms\": 14861.074}", "{\"n\": 11068, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2666666666666666, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3739.306666666667, \"learn_time_ms\": 14864.956}", "{\"n\": 11069, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2337662337662336, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3748.909090909091, \"learn_time_ms\": 14875.085}", "{\"n\": 11070, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.151898734177215, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3757.1772151898736, \"learn_time_ms\": 14850.06}", "{\"n\": 11071, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1375, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3758.1375, \"learn_time_ms\": 14840.149}", "{\"n\": 11072, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.123456790123457, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3757.58024691358, \"learn_time_ms\": 14833.183}", "{\"n\": 11073, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.123456790123457, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3757.58024691358, \"learn_time_ms\": 14834.596}", "{\"n\": 11074, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.072289156626506, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3747.1807228915663, \"learn_time_ms\": 14851.191}", "{\"n\": 11075, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.1176470588235294, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3753.564705882353, \"learn_time_ms\": 14831.446}", "{\"n\": 11076, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.227272727272727, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.9886363636365, \"learn_time_ms\": 14842.993}", "{\"n\": 11077, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.227272727272727, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3741.9886363636365, \"learn_time_ms\": 14850.49}", "{\"n\": 11078, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.202247191011236, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.887640449438, \"learn_time_ms\": 14845.71}", "{\"n\": 11079, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.202247191011236, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.887640449438, \"learn_time_ms\": 14846.41}", "{\"n\": 11080, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.202247191011236, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.887640449438, \"learn_time_ms\": 14851.709}", "{\"n\": 11081, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.161290322580645, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3742.935483870968, \"learn_time_ms\": 14870.016}", "{\"n\": 11082, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.263157894736842, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.463157894737, \"learn_time_ms\": 14866.157}", "{\"n\": 11083, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28125, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3731.84375, \"learn_time_ms\": 14864.766}", "{\"n\": 11084, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28125, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3731.84375, \"learn_time_ms\": 14839.819}", "{\"n\": 11085, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2577319587628866, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3735.4742268041236, \"learn_time_ms\": 14848.138}", "{\"n\": 11086, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.2551020408163267, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3736.061224489796, \"learn_time_ms\": 14835.431}", "{\"n\": 11087, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3732.1, \"learn_time_ms\": 14844.776}", "{\"n\": 11088, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3733.86, \"learn_time_ms\": 14849.246}", "{\"n\": 11089, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3735.92, \"learn_time_ms\": 14844.071}", "{\"n\": 11090, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.49, \"learn_time_ms\": 14857.699}", "{\"n\": 11091, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3739.78, \"learn_time_ms\": 14840.929}", "{\"n\": 11092, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3732.04, \"learn_time_ms\": 14853.515}", "{\"n\": 11093, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3729.16, \"learn_time_ms\": 14828.516}", "{\"n\": 11094, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3728.63, \"learn_time_ms\": 14838.125}", "{\"n\": 11095, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3748.05, \"learn_time_ms\": 14836.847}", "{\"n\": 11096, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3748.05, \"learn_time_ms\": 14841.016}", "{\"n\": 11097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3759.62, \"learn_time_ms\": 14834.564}", "{\"n\": 11098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3743.15, \"learn_time_ms\": 14840.733}", "{\"n\": 11099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.24, \"learn_time_ms\": 14856.325}", "{\"n\": 11100, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.24, \"learn_time_ms\": 14855.096}", "{\"n\": 11101, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3746.23, \"learn_time_ms\": 14861.724}", "{\"n\": 11102, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.33, \"learn_time_ms\": 14863.598}", "{\"n\": 11103, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3763.89, \"learn_time_ms\": 14885.466}", "{\"n\": 11104, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3744.66, \"learn_time_ms\": 14897.198}", "{\"n\": 11105, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.03, \"learn_time_ms\": 14902.465}", "{\"n\": 11106, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.03, \"learn_time_ms\": 14906.074}", "{\"n\": 11107, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3750.22, \"learn_time_ms\": 14903.317}", "{\"n\": 11108, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3730.03, \"learn_time_ms\": 14912.664}", "{\"n\": 11109, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3742.22, \"learn_time_ms\": 14912.802}", "{\"n\": 11110, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3739.9, \"learn_time_ms\": 14906.472}", "{\"n\": 11111, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.27, \"learn_time_ms\": 14914.168}", "{\"n\": 11112, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.27, \"learn_time_ms\": 14910.51}", "{\"n\": 11113, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3732.83, \"learn_time_ms\": 14916.516}", "{\"n\": 11114, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3732.83, \"learn_time_ms\": 14919.667}", "{\"n\": 11115, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.59, \"learn_time_ms\": 14907.887}", "{\"n\": 11116, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3732.53, \"learn_time_ms\": 14895.644}", "{\"n\": 11117, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.36, \"learn_time_ms\": 14908.927}", "{\"n\": 11118, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.36, \"learn_time_ms\": 14894.783}", "{\"n\": 11119, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3741.36, \"learn_time_ms\": 14896.539}", "{\"n\": 11120, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.04, \"learn_time_ms\": 14903.24}", "{\"n\": 11121, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.04, \"learn_time_ms\": 14907.966}", "{\"n\": 11122, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.39, \"learn_time_ms\": 14905.048}", "{\"n\": 11123, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3738.39, \"learn_time_ms\": 14895.221}", "{\"n\": 11124, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3736.25, \"learn_time_ms\": 14907.497}", "{\"n\": 11125, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3734.68, \"learn_time_ms\": 14926.199}", "{\"n\": 11126, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3734.68, \"learn_time_ms\": 14937.322}", "{\"n\": 11127, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3749.87, \"learn_time_ms\": 14930.648}", "{\"n\": 11128, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3758.28, \"learn_time_ms\": 14944.486}", "{\"n\": 11129, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3753.34, \"learn_time_ms\": 14941.236}", "{\"n\": 11130, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3753.34, \"learn_time_ms\": 14930.959}", "{\"n\": 11131, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3763.78, \"learn_time_ms\": 14912.054}", "{\"n\": 11132, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3752.37, \"learn_time_ms\": 14902.678}", "{\"n\": 11133, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3762.03, \"learn_time_ms\": 14913.768}", "{\"n\": 11134, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.61, \"learn_time_ms\": 14891.834}", "{\"n\": 11135, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3750.46, \"learn_time_ms\": 14875.34}", "{\"n\": 11136, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3756.15, \"learn_time_ms\": 14862.408}", "{\"n\": 11137, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3756.41, \"learn_time_ms\": 14842.635}", "{\"n\": 11138, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3756.4, \"learn_time_ms\": 14833.917}", "{\"n\": 11139, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3750.44, \"learn_time_ms\": 14841.096}", "{\"n\": 11140, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3763.47, \"learn_time_ms\": 14854.937}", "{\"n\": 11141, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.3, \"learn_time_ms\": 14894.107}", "{\"n\": 11142, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.3, \"learn_time_ms\": 14912.282}", "{\"n\": 11143, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3781.23, \"learn_time_ms\": 14916.153}", "{\"n\": 11144, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3780.24, \"learn_time_ms\": 14923.241}", "{\"n\": 11145, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3778.03, \"learn_time_ms\": 14939.571}", "{\"n\": 11146, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3777.39, \"learn_time_ms\": 14956.677}", "{\"n\": 11147, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.86, \"learn_time_ms\": 14967.427}", "{\"n\": 11148, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3771.65, \"learn_time_ms\": 14966.13}", "{\"n\": 11149, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3755.21, \"learn_time_ms\": 14964.946}", "{\"n\": 11150, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3757.08, \"learn_time_ms\": 14951.579}", "{\"n\": 11151, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3757.08, \"learn_time_ms\": 14929.832}", "{\"n\": 11152, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3775.54, \"learn_time_ms\": 14925.779}", "{\"n\": 11153, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3772.9, \"learn_time_ms\": 14917.696}", "{\"n\": 11154, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.2, \"learn_time_ms\": 14903.403}", "{\"n\": 11155, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3782.2, \"learn_time_ms\": 14891.939}", "{\"n\": 11156, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3776.94, \"learn_time_ms\": 14870.955}", "{\"n\": 11157, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3787.47, \"learn_time_ms\": 14877.743}", "{\"n\": 11158, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3789.74, \"learn_time_ms\": 14884.891}", "{\"n\": 11159, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3784.51, \"learn_time_ms\": 14868.49}", "{\"n\": 11160, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3803.36, \"learn_time_ms\": 14881.425}", "{\"n\": 11161, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3803.36, \"learn_time_ms\": 14862.993}", "{\"n\": 11162, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3803.36, \"learn_time_ms\": 14842.763}", "{\"n\": 11163, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3814.04, \"learn_time_ms\": 14838.311}", "{\"n\": 11164, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3814.04, \"learn_time_ms\": 14840.338}", "{\"n\": 11165, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.29, \"learn_time_ms\": 14833.196}", "{\"n\": 11166, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3819.61, \"learn_time_ms\": 14843.017}", "{\"n\": 11167, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3813.7, \"learn_time_ms\": 14865.32}", "{\"n\": 11168, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3810.54, \"learn_time_ms\": 14857.807}", "{\"n\": 11169, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3810.54, \"learn_time_ms\": 14859.128}", "{\"n\": 11170, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3806.94, \"learn_time_ms\": 14848.293}", "{\"n\": 11171, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3804.45, \"learn_time_ms\": 14866.357}", "{\"n\": 11172, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3795.19, \"learn_time_ms\": 14893.313}", "{\"n\": 11173, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3781.05, \"learn_time_ms\": 14897.104}", "{\"n\": 11174, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3782.1, \"learn_time_ms\": 14893.264}", "{\"n\": 11175, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3782.1, \"learn_time_ms\": 14894.723}", "{\"n\": 11176, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3782.1, \"learn_time_ms\": 14898.106}", "{\"n\": 11177, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3778.32, \"learn_time_ms\": 14879.257}", "{\"n\": 11178, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3791.62, \"learn_time_ms\": 14884.527}", "{\"n\": 11179, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3788.07, \"learn_time_ms\": 14896.213}", "{\"n\": 11180, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3775.01, \"learn_time_ms\": 14898.429}", "{\"n\": 11181, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3775.01, \"learn_time_ms\": 14897.218}", "{\"n\": 11182, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3779.24, \"learn_time_ms\": 14893.045}", "{\"n\": 11183, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3779.24, \"learn_time_ms\": 14896.872}", "{\"n\": 11184, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3786.08, \"learn_time_ms\": 14897.471}", "{\"n\": 11185, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3799.82, \"learn_time_ms\": 14896.044}", "{\"n\": 11186, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3819.69, \"learn_time_ms\": 14885.185}", "{\"n\": 11187, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3819.69, \"learn_time_ms\": 14892.957}", "{\"n\": 11188, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3799.18, \"learn_time_ms\": 14886.828}", "{\"n\": 11189, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3793.97, \"learn_time_ms\": 14892.715}", "{\"n\": 11190, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3793.97, \"learn_time_ms\": 14903.013}", "{\"n\": 11191, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3796.08, \"learn_time_ms\": 14908.849}", "{\"n\": 11192, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3804.79, \"learn_time_ms\": 14908.384}", "{\"n\": 11193, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3807.65, \"learn_time_ms\": 14908.557}", "{\"n\": 11194, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3801.75, \"learn_time_ms\": 14923.059}", "{\"n\": 11195, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3813.74, \"learn_time_ms\": 14927.068}", "{\"n\": 11196, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3804.18, \"learn_time_ms\": 14929.412}", "{\"n\": 11197, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3804.18, \"learn_time_ms\": 14939.759}", "{\"n\": 11198, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3796.12, \"learn_time_ms\": 14947.817}", "{\"n\": 11199, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3818.83, \"learn_time_ms\": 14923.303}", "{\"n\": 11200, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3818.8, \"learn_time_ms\": 14910.337}", "{\"n\": 11201, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3818.8, \"learn_time_ms\": 14900.091}", "{\"n\": 11202, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3823.5, \"learn_time_ms\": 14902.961}", "{\"n\": 11203, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3823.5, \"learn_time_ms\": 14903.054}", "{\"n\": 11204, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3830.44, \"learn_time_ms\": 14897.951}", "{\"n\": 11205, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3837.91, \"learn_time_ms\": 14910.3}", "{\"n\": 11206, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3837.91, \"learn_time_ms\": 14916.494}", "{\"n\": 11207, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3846.23, \"learn_time_ms\": 14895.567}", "{\"n\": 11208, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3846.23, \"learn_time_ms\": 14892.013}", "{\"n\": 11209, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3861.38, \"learn_time_ms\": 14906.262}", "{\"n\": 11210, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3867.65, \"learn_time_ms\": 14903.049}", "{\"n\": 11211, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3853.99, \"learn_time_ms\": 14905.731}", "{\"n\": 11212, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3859.12, \"learn_time_ms\": 14889.411}", "{\"n\": 11213, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3859.12, \"learn_time_ms\": 14890.372}", "{\"n\": 11214, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3852.38, \"learn_time_ms\": 14884.943}", "{\"n\": 11215, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3852.38, \"learn_time_ms\": 14880.263}", "{\"n\": 11216, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3842.28, \"learn_time_ms\": 14873.066}", "{\"n\": 11217, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3825.49, \"learn_time_ms\": 14861.37}", "{\"n\": 11218, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3825.45, \"learn_time_ms\": 14874.035}", "{\"n\": 11219, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3837.95, \"learn_time_ms\": 14867.477}", "{\"n\": 11220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3837.95, \"learn_time_ms\": 14853.634}", "{\"n\": 11221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3820.38, \"learn_time_ms\": 14842.837}", "{\"n\": 11222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3814.49, \"learn_time_ms\": 14840.111}", "{\"n\": 11223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3810.61, \"learn_time_ms\": 14841.453}", "{\"n\": 11224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.0, \"learn_time_ms\": 14846.091}", "{\"n\": 11225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.34, \"learn_time_ms\": 14840.11}", "{\"n\": 11226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.18, \"learn_time_ms\": 14849.275}", "{\"n\": 11227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.18, \"learn_time_ms\": 14862.626}", "{\"n\": 11228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3815.49, \"learn_time_ms\": 14835.97}", "{\"n\": 11229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.26, \"learn_time_ms\": 14840.452}", "{\"n\": 11230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3806.21, \"learn_time_ms\": 14865.924}", "{\"n\": 11231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3809.01, \"learn_time_ms\": 14877.856}", "{\"n\": 11232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3814.85, \"learn_time_ms\": 14907.987}", "{\"n\": 11233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3814.85, \"learn_time_ms\": 14912.245}", "{\"n\": 11234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3810.3, \"learn_time_ms\": 14911.603}", "{\"n\": 11235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3822.46, \"learn_time_ms\": 14926.926}", "{\"n\": 11236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3815.39, \"learn_time_ms\": 14916.545}", "{\"n\": 11237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3820.87, \"learn_time_ms\": 14899.705}", "{\"n\": 11238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3820.87, \"learn_time_ms\": 14903.022}", "{\"n\": 11239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3814.85, \"learn_time_ms\": 14911.772}", "{\"n\": 11240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.17, \"learn_time_ms\": 14915.744}", "{\"n\": 11241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3809.33, \"learn_time_ms\": 14911.112}", "{\"n\": 11242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3809.17, \"learn_time_ms\": 14889.062}", "{\"n\": 11243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3800.47, \"learn_time_ms\": 14892.7}", "{\"n\": 11244, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3809.11, \"learn_time_ms\": 14901.41}", "{\"n\": 11245, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3809.11, \"learn_time_ms\": 14889.794}", "{\"n\": 11246, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3808.14, \"learn_time_ms\": 14901.194}", "{\"n\": 11247, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3805.79, \"learn_time_ms\": 14914.576}", "{\"n\": 11248, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.69, \"learn_time_ms\": 14910.842}", "{\"n\": 11249, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3811.03, \"learn_time_ms\": 14902.392}", "{\"n\": 11250, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3820.12, \"learn_time_ms\": 14895.628}", "{\"n\": 11251, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3828.17, \"learn_time_ms\": 14893.365}", "{\"n\": 11252, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3840.05, \"learn_time_ms\": 14888.577}", "{\"n\": 11253, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3839.56, \"learn_time_ms\": 14877.895}", "{\"n\": 11254, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3837.32, \"learn_time_ms\": 14873.133}", "{\"n\": 11255, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3843.47, \"learn_time_ms\": 14874.36}", "{\"n\": 11256, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3849.49, \"learn_time_ms\": 14875.496}", "{\"n\": 11257, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3848.68, \"learn_time_ms\": 14877.526}", "{\"n\": 11258, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3848.68, \"learn_time_ms\": 14910.164}", "{\"n\": 11259, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3848.68, \"learn_time_ms\": 14912.958}", "{\"n\": 11260, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3854.74, \"learn_time_ms\": 14919.642}", "{\"n\": 11261, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3858.5, \"learn_time_ms\": 14914.301}", "{\"n\": 11262, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3865.84, \"learn_time_ms\": 14930.593}", "{\"n\": 11263, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3870.37, \"learn_time_ms\": 14921.684}", "{\"n\": 11264, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3852.53, \"learn_time_ms\": 14919.192}", "{\"n\": 11265, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3852.53, \"learn_time_ms\": 14919.945}", "{\"n\": 11266, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3844.0, \"learn_time_ms\": 14900.035}", "{\"n\": 11267, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3848.19, \"learn_time_ms\": 14907.801}", "{\"n\": 11268, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3845.73, \"learn_time_ms\": 14894.563}", "{\"n\": 11269, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3867.53, \"learn_time_ms\": 14892.767}", "{\"n\": 11270, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3870.0, \"learn_time_ms\": 14891.12}", "{\"n\": 11271, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3868.84, \"learn_time_ms\": 14919.148}", "{\"n\": 11272, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3868.84, \"learn_time_ms\": 14908.189}", "{\"n\": 11273, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3875.46, \"learn_time_ms\": 14914.613}", "{\"n\": 11274, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3875.46, \"learn_time_ms\": 14911.545}", "{\"n\": 11275, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3879.25, \"learn_time_ms\": 14911.253}", "{\"n\": 11276, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3881.22, \"learn_time_ms\": 14935.992}", "{\"n\": 11277, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3881.22, \"learn_time_ms\": 14931.819}", "{\"n\": 11278, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3881.34, \"learn_time_ms\": 14916.785}", "{\"n\": 11279, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3868.06, \"learn_time_ms\": 14909.185}", "{\"n\": 11280, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3863.25, \"learn_time_ms\": 14915.858}", "{\"n\": 11281, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3863.25, \"learn_time_ms\": 14881.494}", "{\"n\": 11282, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3871.06, \"learn_time_ms\": 14886.589}", "{\"n\": 11283, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3868.48, \"learn_time_ms\": 14887.277}", "{\"n\": 11284, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3868.48, \"learn_time_ms\": 14893.514}", "{\"n\": 11285, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.87, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3868.4, \"learn_time_ms\": 14886.618}", "{\"n\": 11286, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3867.87, \"learn_time_ms\": 14868.693}", "{\"n\": 11287, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3869.2, \"learn_time_ms\": 14860.08}", "{\"n\": 11288, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3863.36, \"learn_time_ms\": 14868.908}", "{\"n\": 11289, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3850.17, \"learn_time_ms\": 14887.443}", "{\"n\": 11290, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3850.17, \"learn_time_ms\": 14878.447}", "{\"n\": 11291, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3855.8, \"learn_time_ms\": 14886.764}", "{\"n\": 11292, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3852.36, \"learn_time_ms\": 14893.551}", "{\"n\": 11293, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3861.91, \"learn_time_ms\": 14890.197}", "{\"n\": 11294, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3865.82, \"learn_time_ms\": 14873.511}", "{\"n\": 11295, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3883.16, \"learn_time_ms\": 14879.377}", "{\"n\": 11296, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3891.28, \"learn_time_ms\": 14885.3}", "{\"n\": 11297, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3891.28, \"learn_time_ms\": 14887.054}", "{\"n\": 11298, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3891.26, \"learn_time_ms\": 14893.829}", "{\"n\": 11299, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3896.55, \"learn_time_ms\": 14877.195}", "{\"n\": 11300, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3899.38, \"learn_time_ms\": 14882.6}", "{\"n\": 11301, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3896.55, \"learn_time_ms\": 14888.999}", "{\"n\": 11302, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3904.83, \"learn_time_ms\": 14876.981}", "{\"n\": 11303, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3898.7, \"learn_time_ms\": 14865.248}", "{\"n\": 11304, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3901.07, \"learn_time_ms\": 14883.527}", "{\"n\": 11305, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3901.07, \"learn_time_ms\": 14882.785}", "{\"n\": 11306, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3898.84, \"learn_time_ms\": 14879.368}", "{\"n\": 11307, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3903.46, \"learn_time_ms\": 14877.573}", "{\"n\": 11308, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3905.28, \"learn_time_ms\": 14857.762}", "{\"n\": 11309, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3916.78, \"learn_time_ms\": 14868.021}", "{\"n\": 11310, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3916.78, \"learn_time_ms\": 14863.257}", "{\"n\": 11311, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3916.78, \"learn_time_ms\": 14872.218}", "{\"n\": 11312, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3908.86, \"learn_time_ms\": 14884.156}", "{\"n\": 11313, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3902.3, \"learn_time_ms\": 14883.072}", "{\"n\": 11314, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3900.87, \"learn_time_ms\": 14895.112}", "{\"n\": 11315, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3901.86, \"learn_time_ms\": 14885.78}", "{\"n\": 11316, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3901.86, \"learn_time_ms\": 14884.56}", "{\"n\": 11317, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3906.06, \"learn_time_ms\": 14877.858}", "{\"n\": 11318, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3906.06, \"learn_time_ms\": 14890.938}", "{\"n\": 11319, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3916.62, \"learn_time_ms\": 14888.974}", "{\"n\": 11320, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3904.04, \"learn_time_ms\": 14885.647}", "{\"n\": 11321, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3899.95, \"learn_time_ms\": 14893.488}", "{\"n\": 11322, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3891.9, \"learn_time_ms\": 14885.279}", "{\"n\": 11323, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3889.57, \"learn_time_ms\": 14899.618}", "{\"n\": 11324, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3889.57, \"learn_time_ms\": 14873.689}", "{\"n\": 11325, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3889.57, \"learn_time_ms\": 14888.85}", "{\"n\": 11326, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3888.05, \"learn_time_ms\": 14892.955}", "{\"n\": 11327, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3886.55, \"learn_time_ms\": 14898.251}", "{\"n\": 11328, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3888.15, \"learn_time_ms\": 14902.371}", "{\"n\": 11329, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3888.15, \"learn_time_ms\": 14897.298}", "{\"n\": 11330, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3888.15, \"learn_time_ms\": 14904.702}", "{\"n\": 11331, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3870.74, \"learn_time_ms\": 14880.535}", "{\"n\": 11332, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3867.47, \"learn_time_ms\": 14876.078}", "{\"n\": 11333, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3870.83, \"learn_time_ms\": 14860.522}", "{\"n\": 11334, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3861.66, \"learn_time_ms\": 14861.254}", "{\"n\": 11335, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3862.46, \"learn_time_ms\": 14861.466}", "{\"n\": 11336, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3862.46, \"learn_time_ms\": 14862.307}", "{\"n\": 11337, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3861.01, \"learn_time_ms\": 14873.681}", "{\"n\": 11338, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3850.04, \"learn_time_ms\": 14854.239}", "{\"n\": 11339, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3851.41, \"learn_time_ms\": 14839.731}", "{\"n\": 11340, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3849.73, \"learn_time_ms\": 14835.511}", "{\"n\": 11341, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3837.96, \"learn_time_ms\": 14813.788}", "{\"n\": 11342, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3831.13, \"learn_time_ms\": 14810.862}", "{\"n\": 11343, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3831.13, \"learn_time_ms\": 14827.059}", "{\"n\": 11344, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3841.88, \"learn_time_ms\": 14835.332}", "{\"n\": 11345, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3853.0, \"learn_time_ms\": 14823.101}", "{\"n\": 11346, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3840.8, \"learn_time_ms\": 14812.344}", "{\"n\": 11347, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3845.75, \"learn_time_ms\": 14808.22}", "{\"n\": 11348, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3843.55, \"learn_time_ms\": 14839.599}", "{\"n\": 11349, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3832.17, \"learn_time_ms\": 14853.166}", "{\"n\": 11350, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3818.68, \"learn_time_ms\": 14858.932}", "{\"n\": 11351, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3816.5, \"learn_time_ms\": 14893.698}", "{\"n\": 11352, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3819.14, \"learn_time_ms\": 14900.203}", "{\"n\": 11353, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3819.14, \"learn_time_ms\": 14901.976}", "{\"n\": 11354, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3819.28, \"learn_time_ms\": 14903.144}", "{\"n\": 11355, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3825.5, \"learn_time_ms\": 14901.652}", "{\"n\": 11356, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3814.14, \"learn_time_ms\": 14922.382}", "{\"n\": 11357, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3804.84, \"learn_time_ms\": 14928.21}", "{\"n\": 11358, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3804.84, \"learn_time_ms\": 14921.428}", "{\"n\": 11359, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3804.84, \"learn_time_ms\": 14919.819}", "{\"n\": 11360, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3778.76, \"learn_time_ms\": 14895.297}", "{\"n\": 11361, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3778.76, \"learn_time_ms\": 14895.854}", "{\"n\": 11362, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3769.92, \"learn_time_ms\": 14899.409}", "{\"n\": 11363, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3751.21, \"learn_time_ms\": 14913.356}", "{\"n\": 11364, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3747.25, \"learn_time_ms\": 14904.439}", "{\"n\": 11365, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3753.11, \"learn_time_ms\": 14914.814}", "{\"n\": 11366, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3744.85, \"learn_time_ms\": 14899.594}", "{\"n\": 11367, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3744.85, \"learn_time_ms\": 14888.151}", "{\"n\": 11368, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3741.09, \"learn_time_ms\": 14874.84}", "{\"n\": 11369, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3756.48, \"learn_time_ms\": 14899.569}", "{\"n\": 11370, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3744.13, \"learn_time_ms\": 14928.007}", "{\"n\": 11371, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3744.13, \"learn_time_ms\": 14929.677}", "{\"n\": 11372, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3735.52, \"learn_time_ms\": 14920.551}", "{\"n\": 11373, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3733.41, \"learn_time_ms\": 14914.533}", "{\"n\": 11374, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.33, \"learn_time_ms\": 14915.312}", "{\"n\": 11375, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.33, \"learn_time_ms\": 14914.004}", "{\"n\": 11376, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3714.98, \"learn_time_ms\": 14907.686}", "{\"n\": 11377, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3720.43, \"learn_time_ms\": 14912.619}", "{\"n\": 11378, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3720.43, \"learn_time_ms\": 14923.094}", "{\"n\": 11379, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3722.09, \"learn_time_ms\": 14908.818}", "{\"n\": 11380, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3722.09, \"learn_time_ms\": 14907.112}", "{\"n\": 11381, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.09, \"learn_time_ms\": 14904.365}", "{\"n\": 11382, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3726.09, \"learn_time_ms\": 14917.176}", "{\"n\": 11383, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3716.75, \"learn_time_ms\": 14914.238}", "{\"n\": 11384, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3716.75, \"learn_time_ms\": 14937.496}", "{\"n\": 11385, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3721.91, \"learn_time_ms\": 14940.946}", "{\"n\": 11386, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3721.91, \"learn_time_ms\": 14959.097}", "{\"n\": 11387, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3721.91, \"learn_time_ms\": 14966.57}", "{\"n\": 11388, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3724.84, \"learn_time_ms\": 14960.439}", "{\"n\": 11389, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3730.69, \"learn_time_ms\": 14963.765}", "{\"n\": 11390, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3739.22, \"learn_time_ms\": 14957.197}", "{\"n\": 11391, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3729.82, \"learn_time_ms\": 14954.243}", "{\"n\": 11392, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3729.82, \"learn_time_ms\": 14955.544}", "{\"n\": 11393, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3717.5, \"learn_time_ms\": 14954.717}", "{\"n\": 11394, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3720.86, \"learn_time_ms\": 14949.243}", "{\"n\": 11395, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3705.16, \"learn_time_ms\": 14948.243}", "{\"n\": 11396, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3719.91, \"learn_time_ms\": 14960.203}", "{\"n\": 11397, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3713.79, \"learn_time_ms\": 14968.428}", "{\"n\": 11398, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3713.79, \"learn_time_ms\": 14981.468}", "{\"n\": 11399, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3702.39, \"learn_time_ms\": 14975.45}", "{\"n\": 11400, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3694.6, \"learn_time_ms\": 14972.816}", "{\"n\": 11401, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3703.5, \"learn_time_ms\": 14969.431}", "{\"n\": 11402, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3704.03, \"learn_time_ms\": 14962.554}", "{\"n\": 11403, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3704.03, \"learn_time_ms\": 14959.156}", "{\"n\": 11404, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3706.68, \"learn_time_ms\": 14938.283}", "{\"n\": 11405, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3706.68, \"learn_time_ms\": 14930.455}", "{\"n\": 11406, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3683.07, \"learn_time_ms\": 14913.079}", "{\"n\": 11407, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3683.07, \"learn_time_ms\": 14906.179}", "{\"n\": 11408, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.03, \"learn_time_ms\": 14892.526}", "{\"n\": 11409, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3671.09, \"learn_time_ms\": 14883.76}", "{\"n\": 11410, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3681.22, \"learn_time_ms\": 14881.098}", "{\"n\": 11411, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3670.43, \"learn_time_ms\": 14884.863}", "{\"n\": 11412, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3651.85, \"learn_time_ms\": 14883.337}", "{\"n\": 11413, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3677.8, \"learn_time_ms\": 14881.878}", "{\"n\": 11414, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3677.8, \"learn_time_ms\": 14903.535}", "{\"n\": 11415, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3682.29, \"learn_time_ms\": 14916.796}", "{\"n\": 11416, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3676.95, \"learn_time_ms\": 14923.646}", "{\"n\": 11417, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3670.87, \"learn_time_ms\": 14926.464}", "{\"n\": 11418, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3676.61, \"learn_time_ms\": 14929.686}", "{\"n\": 11419, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3668.96, \"learn_time_ms\": 14935.071}", "{\"n\": 11420, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3668.96, \"learn_time_ms\": 14941.84}", "{\"n\": 11421, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3668.96, \"learn_time_ms\": 14942.578}", "{\"n\": 11422, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3669.16, \"learn_time_ms\": 14940.744}", "{\"n\": 11423, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3660.03, \"learn_time_ms\": 14934.457}", "{\"n\": 11424, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3660.03, \"learn_time_ms\": 14906.502}", "{\"n\": 11425, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3676.53, \"learn_time_ms\": 14910.334}", "{\"n\": 11426, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3684.63, \"learn_time_ms\": 14897.289}", "{\"n\": 11427, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3685.72, \"learn_time_ms\": 14890.147}", "{\"n\": 11428, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3684.57, \"learn_time_ms\": 14885.382}", "{\"n\": 11429, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3684.57, \"learn_time_ms\": 14913.19}", "{\"n\": 11430, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3674.79, \"learn_time_ms\": 14937.119}", "{\"n\": 11431, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3684.8, \"learn_time_ms\": 14933.953}", "{\"n\": 11432, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3684.84, \"learn_time_ms\": 14951.205}", "{\"n\": 11433, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3703.61, \"learn_time_ms\": 14977.621}", "{\"n\": 11434, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3699.71, \"learn_time_ms\": 14996.14}", "{\"n\": 11435, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3699.71, \"learn_time_ms\": 15001.074}", "{\"n\": 11436, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3711.22, \"learn_time_ms\": 15017.085}", "{\"n\": 11437, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3703.82, \"learn_time_ms\": 15027.718}", "{\"n\": 11438, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3709.81, \"learn_time_ms\": 15040.293}", "{\"n\": 11439, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3737.67, \"learn_time_ms\": 15012.696}", "{\"n\": 11440, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3728.39, \"learn_time_ms\": 14993.883}", "{\"n\": 11441, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3740.58, \"learn_time_ms\": 15010.671}", "{\"n\": 11442, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3732.4, \"learn_time_ms\": 15004.064}", "{\"n\": 11443, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3732.4, \"learn_time_ms\": 15004.076}", "{\"n\": 11444, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3728.78, \"learn_time_ms\": 15006.563}", "{\"n\": 11445, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3734.88, \"learn_time_ms\": 14992.723}", "{\"n\": 11446, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3730.55, \"learn_time_ms\": 14992.254}", "{\"n\": 11447, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3736.8, \"learn_time_ms\": 14978.694}", "{\"n\": 11448, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3736.8, \"learn_time_ms\": 14962.399}", "{\"n\": 11449, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3741.91, \"learn_time_ms\": 14965.521}", "{\"n\": 11450, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3748.74, \"learn_time_ms\": 14962.516}", "{\"n\": 11451, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3751.22, \"learn_time_ms\": 14958.279}", "{\"n\": 11452, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3741.16, \"learn_time_ms\": 14941.407}", "{\"n\": 11453, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3741.06, \"learn_time_ms\": 14922.062}", "{\"n\": 11454, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3741.06, \"learn_time_ms\": 14918.285}", "{\"n\": 11455, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3741.06, \"learn_time_ms\": 14923.075}", "{\"n\": 11456, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3734.14, \"learn_time_ms\": 14913.571}", "{\"n\": 11457, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3723.37, \"learn_time_ms\": 14915.488}", "{\"n\": 11458, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3730.69, \"learn_time_ms\": 14924.178}", "{\"n\": 11459, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3730.69, \"learn_time_ms\": 14919.666}", "{\"n\": 11460, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3730.69, \"learn_time_ms\": 14911.991}", "{\"n\": 11461, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3735.56, \"learn_time_ms\": 14919.938}", "{\"n\": 11462, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3723.16, \"learn_time_ms\": 14946.297}", "{\"n\": 11463, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3714.18, \"learn_time_ms\": 14950.54}", "{\"n\": 11464, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3700.05, \"learn_time_ms\": 14960.314}", "{\"n\": 11465, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3701.38, \"learn_time_ms\": 14950.567}", "{\"n\": 11466, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3692.78, \"learn_time_ms\": 14958.808}", "{\"n\": 11467, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3692.78, \"learn_time_ms\": 14970.068}", "{\"n\": 11468, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3690.77, \"learn_time_ms\": 14968.836}", "{\"n\": 11469, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3681.57, \"learn_time_ms\": 14962.012}", "{\"n\": 11470, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3691.3, \"learn_time_ms\": 14967.851}", "{\"n\": 11471, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3703.62, \"learn_time_ms\": 14958.264}", "{\"n\": 11472, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3694.22, \"learn_time_ms\": 14946.836}", "{\"n\": 11473, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3694.22, \"learn_time_ms\": 14942.003}", "{\"n\": 11474, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3695.3, \"learn_time_ms\": 14937.254}", "{\"n\": 11475, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3703.92, \"learn_time_ms\": 14949.443}", "{\"n\": 11476, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3725.11, \"learn_time_ms\": 14945.776}", "{\"n\": 11477, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3737.59, \"learn_time_ms\": 14937.096}", "{\"n\": 11478, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3741.01, \"learn_time_ms\": 14942.442}", "{\"n\": 11479, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3738.69, \"learn_time_ms\": 14947.943}", "{\"n\": 11480, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3738.25, \"learn_time_ms\": 14946.22}", "{\"n\": 11481, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3738.25, \"learn_time_ms\": 14935.437}", "{\"n\": 11482, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3732.98, \"learn_time_ms\": 14920.828}", "{\"n\": 11483, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3743.69, \"learn_time_ms\": 14920.815}", "{\"n\": 11484, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3743.69, \"learn_time_ms\": 14906.154}", "{\"n\": 11485, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3756.59, \"learn_time_ms\": 14883.702}", "{\"n\": 11486, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3761.84, \"learn_time_ms\": 14883.899}", "{\"n\": 11487, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3753.32, \"learn_time_ms\": 14878.235}", "{\"n\": 11488, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3775.02, \"learn_time_ms\": 14864.307}", "{\"n\": 11489, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3787.31, \"learn_time_ms\": 14867.73}", "{\"n\": 11490, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3787.31, \"learn_time_ms\": 14866.961}", "{\"n\": 11491, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3772.63, \"learn_time_ms\": 14863.97}", "{\"n\": 11492, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3757.56, \"learn_time_ms\": 14883.815}", "{\"n\": 11493, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3752.18, \"learn_time_ms\": 14876.371}", "{\"n\": 11494, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3752.18, \"learn_time_ms\": 14884.858}", "{\"n\": 11495, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3751.48, \"learn_time_ms\": 14890.829}", "{\"n\": 11496, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3754.37, \"learn_time_ms\": 14897.394}", "{\"n\": 11497, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3754.37, \"learn_time_ms\": 14903.983}", "{\"n\": 11498, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3760.71, \"learn_time_ms\": 14912.923}", "{\"n\": 11499, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3760.71, \"learn_time_ms\": 14915.555}", "{\"n\": 11500, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3761.79, \"learn_time_ms\": 14900.628}", "{\"n\": 11501, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3776.79, \"learn_time_ms\": 14905.755}", "{\"n\": 11502, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3787.77, \"learn_time_ms\": 14915.983}", "{\"n\": 11503, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3780.86, \"learn_time_ms\": 14931.423}", "{\"n\": 11504, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3780.86, \"learn_time_ms\": 14936.461}", "{\"n\": 11505, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3780.5, \"learn_time_ms\": 14950.482}", "{\"n\": 11506, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3778.99, \"learn_time_ms\": 14938.933}", "{\"n\": 11507, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.82, \"learn_time_ms\": 14929.137}", "{\"n\": 11508, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3784.06, \"learn_time_ms\": 14930.176}", "{\"n\": 11509, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3780.92, \"learn_time_ms\": 14934.062}", "{\"n\": 11510, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3778.38, \"learn_time_ms\": 14945.676}", "{\"n\": 11511, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3778.38, \"learn_time_ms\": 14943.591}", "{\"n\": 11512, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3778.03, \"learn_time_ms\": 14925.453}", "{\"n\": 11513, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3778.03, \"learn_time_ms\": 14925.63}", "{\"n\": 11514, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.18, \"learn_time_ms\": 14917.705}", "{\"n\": 11515, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.18, \"learn_time_ms\": 14908.301}", "{\"n\": 11516, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.01, \"learn_time_ms\": 14911.582}", "{\"n\": 11517, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.01, \"learn_time_ms\": 14918.053}", "{\"n\": 11518, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3769.76, \"learn_time_ms\": 14915.285}", "{\"n\": 11519, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3774.76, \"learn_time_ms\": 14896.967}", "{\"n\": 11520, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3777.98, \"learn_time_ms\": 14890.853}", "{\"n\": 11521, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3789.68, \"learn_time_ms\": 14892.387}", "{\"n\": 11522, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3789.68, \"learn_time_ms\": 14890.74}", "{\"n\": 11523, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3789.68, \"learn_time_ms\": 14881.834}", "{\"n\": 11524, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3787.83, \"learn_time_ms\": 14877.927}", "{\"n\": 11525, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3788.54, \"learn_time_ms\": 14894.409}", "{\"n\": 11526, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3788.54, \"learn_time_ms\": 14896.24}", "{\"n\": 11527, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3775.12, \"learn_time_ms\": 14897.53}", "{\"n\": 11528, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3783.96, \"learn_time_ms\": 14899.443}", "{\"n\": 11529, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3783.96, \"learn_time_ms\": 14894.789}", "{\"n\": 11530, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3780.47, \"learn_time_ms\": 14896.923}", "{\"n\": 11531, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3787.24, \"learn_time_ms\": 14908.18}", "{\"n\": 11532, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3787.57, \"learn_time_ms\": 14905.118}", "{\"n\": 11533, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3787.57, \"learn_time_ms\": 14914.411}", "{\"n\": 11534, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3784.55, \"learn_time_ms\": 14927.42}", "{\"n\": 11535, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3783.9, \"learn_time_ms\": 14917.133}", "{\"n\": 11536, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3801.1, \"learn_time_ms\": 14911.859}", "{\"n\": 11537, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3808.03, \"learn_time_ms\": 14916.401}", "{\"n\": 11538, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3802.47, \"learn_time_ms\": 14927.229}", "{\"n\": 11539, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3803.32, \"learn_time_ms\": 14942.308}", "{\"n\": 11540, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3806.18, \"learn_time_ms\": 14951.436}", "{\"n\": 11541, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3806.18, \"learn_time_ms\": 14946.33}", "{\"n\": 11542, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3816.15, \"learn_time_ms\": 14947.291}", "{\"n\": 11543, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3825.03, \"learn_time_ms\": 14924.877}", "{\"n\": 11544, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3825.03, \"learn_time_ms\": 14912.811}", "{\"n\": 11545, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3846.94, \"learn_time_ms\": 14906.478}", "{\"n\": 11546, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3856.38, \"learn_time_ms\": 14920.236}", "{\"n\": 11547, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3856.64, \"learn_time_ms\": 14918.001}", "{\"n\": 11548, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3868.3, \"learn_time_ms\": 14905.213}", "{\"n\": 11549, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3864.36, \"learn_time_ms\": 14917.235}", "{\"n\": 11550, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3864.36, \"learn_time_ms\": 14919.013}", "{\"n\": 11551, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3864.36, \"learn_time_ms\": 14909.091}", "{\"n\": 11552, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3850.04, \"learn_time_ms\": 14910.524}", "{\"n\": 11553, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3864.79, \"learn_time_ms\": 14925.43}", "{\"n\": 11554, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3868.9, \"learn_time_ms\": 14926.034}", "{\"n\": 11555, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3856.47, \"learn_time_ms\": 14946.948}", "{\"n\": 11556, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3842.18, \"learn_time_ms\": 14948.133}", "{\"n\": 11557, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3842.18, \"learn_time_ms\": 14946.748}", "{\"n\": 11558, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3842.18, \"learn_time_ms\": 14949.121}", "{\"n\": 11559, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3843.73, \"learn_time_ms\": 14938.977}", "{\"n\": 11560, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3849.97, \"learn_time_ms\": 14929.573}", "{\"n\": 11561, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3867.85, \"learn_time_ms\": 14913.332}", "{\"n\": 11562, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3869.59, \"learn_time_ms\": 14926.618}", "{\"n\": 11563, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3869.59, \"learn_time_ms\": 14931.433}", "{\"n\": 11564, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3864.53, \"learn_time_ms\": 14939.425}", "{\"n\": 11565, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3866.9, \"learn_time_ms\": 14915.306}", "{\"n\": 11566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3872.64, \"learn_time_ms\": 14906.054}", "{\"n\": 11567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3879.45, \"learn_time_ms\": 14905.684}", "{\"n\": 11568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3874.04, \"learn_time_ms\": 14894.866}", "{\"n\": 11569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3870.87, \"learn_time_ms\": 14898.021}", "{\"n\": 11570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3870.87, \"learn_time_ms\": 14897.847}", "{\"n\": 11571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3875.15, \"learn_time_ms\": 14903.811}", "{\"n\": 11572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3881.15, \"learn_time_ms\": 14880.703}", "{\"n\": 11573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3893.06, \"learn_time_ms\": 14886.947}", "{\"n\": 11574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3891.87, \"learn_time_ms\": 14881.0}", "{\"n\": 11575, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3906.91, \"learn_time_ms\": 14886.065}", "{\"n\": 11576, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3911.44, \"learn_time_ms\": 14880.566}", "{\"n\": 11577, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3911.44, \"learn_time_ms\": 14869.527}", "{\"n\": 11578, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3916.88, \"learn_time_ms\": 14887.33}", "{\"n\": 11579, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3917.36, \"learn_time_ms\": 14882.858}", "{\"n\": 11580, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3917.36, \"learn_time_ms\": 14889.054}", "{\"n\": 11581, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3906.03, \"learn_time_ms\": 14897.236}", "{\"n\": 11582, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3903.28, \"learn_time_ms\": 14901.392}", "{\"n\": 11583, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3903.28, \"learn_time_ms\": 14894.227}", "{\"n\": 11584, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3903.28, \"learn_time_ms\": 14900.417}", "{\"n\": 11585, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3899.84, \"learn_time_ms\": 14900.818}", "{\"n\": 11586, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3897.33, \"learn_time_ms\": 14902.752}", "{\"n\": 11587, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3891.13, \"learn_time_ms\": 14905.524}", "{\"n\": 11588, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3891.13, \"learn_time_ms\": 14898.307}", "{\"n\": 11589, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3891.66, \"learn_time_ms\": 14903.418}", "{\"n\": 11590, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3891.66, \"learn_time_ms\": 14911.763}", "{\"n\": 11591, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3891.66, \"learn_time_ms\": 14910.047}", "{\"n\": 11592, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3899.87, \"learn_time_ms\": 14913.739}", "{\"n\": 11593, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3890.82, \"learn_time_ms\": 14930.225}", "{\"n\": 11594, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3900.23, \"learn_time_ms\": 14915.469}", "{\"n\": 11595, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3900.23, \"learn_time_ms\": 14903.089}", "{\"n\": 11596, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3900.23, \"learn_time_ms\": 14910.016}", "{\"n\": 11597, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3898.14, \"learn_time_ms\": 14911.54}", "{\"n\": 11598, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3898.14, \"learn_time_ms\": 14911.264}", "{\"n\": 11599, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3909.13, \"learn_time_ms\": 14917.292}", "{\"n\": 11600, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3910.08, \"learn_time_ms\": 14920.037}", "{\"n\": 11601, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3912.1, \"learn_time_ms\": 14925.706}", "{\"n\": 11602, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3912.1, \"learn_time_ms\": 14926.146}", "{\"n\": 11603, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.2, \"learn_time_ms\": 14901.657}", "{\"n\": 11604, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.2, \"learn_time_ms\": 14937.652}", "{\"n\": 11605, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3911.82, \"learn_time_ms\": 14949.697}", "{\"n\": 11606, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3924.52, \"learn_time_ms\": 14948.134}", "{\"n\": 11607, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3924.52, \"learn_time_ms\": 14948.779}", "{\"n\": 11608, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3937.13, \"learn_time_ms\": 14943.71}", "{\"n\": 11609, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3931.73, \"learn_time_ms\": 14927.77}", "{\"n\": 11610, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3918.89, \"learn_time_ms\": 14915.38}", "{\"n\": 11611, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3924.28, \"learn_time_ms\": 14933.409}", "{\"n\": 11612, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3922.66, \"learn_time_ms\": 14946.415}", "{\"n\": 11613, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3935.25, \"learn_time_ms\": 14944.427}", "{\"n\": 11614, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3934.55, \"learn_time_ms\": 14922.061}", "{\"n\": 11615, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3934.09, \"learn_time_ms\": 14929.232}", "{\"n\": 11616, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3934.09, \"learn_time_ms\": 14917.35}", "{\"n\": 11617, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3934.09, \"learn_time_ms\": 14922.578}", "{\"n\": 11618, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3912.54, \"learn_time_ms\": 14909.229}", "{\"n\": 11619, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3921.4, \"learn_time_ms\": 14927.948}", "{\"n\": 11620, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3921.4, \"learn_time_ms\": 14924.618}", "{\"n\": 11621, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3919.51, \"learn_time_ms\": 14913.72}", "{\"n\": 11622, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3926.22, \"learn_time_ms\": 14902.655}", "{\"n\": 11623, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3926.22, \"learn_time_ms\": 14902.013}", "{\"n\": 11624, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3914.95, \"learn_time_ms\": 14903.552}", "{\"n\": 11625, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3909.59, \"learn_time_ms\": 14907.336}", "{\"n\": 11626, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3911.95, \"learn_time_ms\": 14914.211}", "{\"n\": 11627, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3914.53, \"learn_time_ms\": 14915.098}", "{\"n\": 11628, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3921.04, \"learn_time_ms\": 14941.367}", "{\"n\": 11629, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3921.04, \"learn_time_ms\": 14941.364}", "{\"n\": 11630, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3918.73, \"learn_time_ms\": 14965.527}", "{\"n\": 11631, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3924.64, \"learn_time_ms\": 14967.648}", "{\"n\": 11632, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3916.9, \"learn_time_ms\": 14969.239}", "{\"n\": 11633, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3916.9, \"learn_time_ms\": 14981.973}", "{\"n\": 11634, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3906.34, \"learn_time_ms\": 14979.818}", "{\"n\": 11635, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3906.34, \"learn_time_ms\": 14964.866}", "{\"n\": 11636, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3906.34, \"learn_time_ms\": 14967.732}", "{\"n\": 11637, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3915.25, \"learn_time_ms\": 14966.719}", "{\"n\": 11638, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3918.43, \"learn_time_ms\": 14962.326}", "{\"n\": 11639, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3898.88, \"learn_time_ms\": 14944.346}", "{\"n\": 11640, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3898.88, \"learn_time_ms\": 14912.113}", "{\"n\": 11641, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3898.88, \"learn_time_ms\": 14903.708}", "{\"n\": 11642, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3897.99, \"learn_time_ms\": 14912.695}", "{\"n\": 11643, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3883.52, \"learn_time_ms\": 14913.8}", "{\"n\": 11644, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3898.71, \"learn_time_ms\": 14920.244}", "{\"n\": 11645, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3896.46, \"learn_time_ms\": 14924.907}", "{\"n\": 11646, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3896.46, \"learn_time_ms\": 14918.178}", "{\"n\": 11647, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3896.46, \"learn_time_ms\": 14923.063}", "{\"n\": 11648, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3909.25, \"learn_time_ms\": 14920.424}", "{\"n\": 11649, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3897.68, \"learn_time_ms\": 14911.842}", "{\"n\": 11650, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3883.61, \"learn_time_ms\": 14933.858}", "{\"n\": 11651, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3885.05, \"learn_time_ms\": 14930.338}", "{\"n\": 11652, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3885.05, \"learn_time_ms\": 14922.583}", "{\"n\": 11653, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3885.05, \"learn_time_ms\": 14919.052}", "{\"n\": 11654, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3884.9, \"learn_time_ms\": 14917.675}", "{\"n\": 11655, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3890.35, \"learn_time_ms\": 14914.521}", "{\"n\": 11656, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3886.61, \"learn_time_ms\": 14916.35}", "{\"n\": 11657, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3874.43, \"learn_time_ms\": 14903.013}", "{\"n\": 11658, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3877.68, \"learn_time_ms\": 14903.693}", "{\"n\": 11659, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3877.68, \"learn_time_ms\": 14913.112}", "{\"n\": 11660, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3877.68, \"learn_time_ms\": 14903.668}", "{\"n\": 11661, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3871.53, \"learn_time_ms\": 14914.561}", "{\"n\": 11662, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3850.64, \"learn_time_ms\": 14902.003}", "{\"n\": 11663, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3850.64, \"learn_time_ms\": 14897.856}", "{\"n\": 11664, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3854.44, \"learn_time_ms\": 14890.703}", "{\"n\": 11665, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3854.44, \"learn_time_ms\": 14904.604}", "{\"n\": 11666, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3852.79, \"learn_time_ms\": 14902.395}", "{\"n\": 11667, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3859.11, \"learn_time_ms\": 14911.573}", "{\"n\": 11668, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3867.34, \"learn_time_ms\": 14914.294}", "{\"n\": 11669, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3859.76, \"learn_time_ms\": 14927.152}", "{\"n\": 11670, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3844.14, \"learn_time_ms\": 14939.293}", "{\"n\": 11671, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3854.5, \"learn_time_ms\": 14934.211}", "{\"n\": 11672, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3855.67, \"learn_time_ms\": 14939.442}", "{\"n\": 11673, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3842.13, \"learn_time_ms\": 14940.922}", "{\"n\": 11674, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3842.13, \"learn_time_ms\": 14943.9}", "{\"n\": 11675, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3849.97, \"learn_time_ms\": 14933.418}", "{\"n\": 11676, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3849.95, \"learn_time_ms\": 14932.37}", "{\"n\": 11677, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3845.83, \"learn_time_ms\": 14930.07}", "{\"n\": 11678, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3844.28, \"learn_time_ms\": 14926.7}", "{\"n\": 11679, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3832.27, \"learn_time_ms\": 14917.425}", "{\"n\": 11680, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3832.27, \"learn_time_ms\": 14894.803}", "{\"n\": 11681, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.32, \"learn_time_ms\": 14902.35}", "{\"n\": 11682, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.32, \"learn_time_ms\": 14913.617}", "{\"n\": 11683, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.1, \"learn_time_ms\": 14912.632}", "{\"n\": 11684, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.1, \"learn_time_ms\": 14911.535}", "{\"n\": 11685, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3802.86, \"learn_time_ms\": 14911.619}", "{\"n\": 11686, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3812.03, \"learn_time_ms\": 14918.707}", "{\"n\": 11687, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3799.8, \"learn_time_ms\": 14922.552}", "{\"n\": 11688, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3800.1, \"learn_time_ms\": 14914.849}", "{\"n\": 11689, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3796.44, \"learn_time_ms\": 14919.613}", "{\"n\": 11690, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3801.8, \"learn_time_ms\": 14923.917}", "{\"n\": 11691, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3801.8, \"learn_time_ms\": 14898.08}", "{\"n\": 11692, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3809.43, \"learn_time_ms\": 14897.217}", "{\"n\": 11693, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3809.43, \"learn_time_ms\": 14909.534}", "{\"n\": 11694, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3802.41, \"learn_time_ms\": 14900.291}", "{\"n\": 11695, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3822.83, \"learn_time_ms\": 14907.109}", "{\"n\": 11696, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3821.76, \"learn_time_ms\": 14904.807}", "{\"n\": 11697, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3823.28, \"learn_time_ms\": 14902.989}", "{\"n\": 11698, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.59, \"learn_time_ms\": 14921.818}", "{\"n\": 11699, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3804.59, \"learn_time_ms\": 14917.97}", "{\"n\": 11700, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3798.99, \"learn_time_ms\": 14925.245}", "{\"n\": 11701, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3791.28, \"learn_time_ms\": 14958.268}", "{\"n\": 11702, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3789.34, \"learn_time_ms\": 14953.402}", "{\"n\": 11703, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.81, \"learn_time_ms\": 14944.602}", "{\"n\": 11704, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3785.81, \"learn_time_ms\": 14952.847}", "{\"n\": 11705, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3764.06, \"learn_time_ms\": 14936.517}", "{\"n\": 11706, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3759.92, \"learn_time_ms\": 14942.722}", "{\"n\": 11707, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3764.31, \"learn_time_ms\": 14934.639}", "{\"n\": 11708, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3766.1, \"learn_time_ms\": 14918.729}", "{\"n\": 11709, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3766.1, \"learn_time_ms\": 14925.336}", "{\"n\": 11710, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3774.61, \"learn_time_ms\": 14910.906}", "{\"n\": 11711, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3778.59, \"learn_time_ms\": 14894.999}", "{\"n\": 11712, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3765.4, \"learn_time_ms\": 14892.168}", "{\"n\": 11713, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3764.72, \"learn_time_ms\": 14890.203}", "{\"n\": 11714, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3755.0, \"learn_time_ms\": 14895.4}", "{\"n\": 11715, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3755.0, \"learn_time_ms\": 14914.067}", "{\"n\": 11716, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3772.4, \"learn_time_ms\": 14914.264}", "{\"n\": 11717, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3779.03, \"learn_time_ms\": 14918.405}", "{\"n\": 11718, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3789.82, \"learn_time_ms\": 14934.832}", "{\"n\": 11719, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3789.82, \"learn_time_ms\": 14924.284}", "{\"n\": 11720, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3789.82, \"learn_time_ms\": 14940.002}", "{\"n\": 11721, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3800.53, \"learn_time_ms\": 14949.602}", "{\"n\": 11722, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3800.53, \"learn_time_ms\": 14951.035}", "{\"n\": 11723, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3806.34, \"learn_time_ms\": 14956.179}", "{\"n\": 11724, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3797.66, \"learn_time_ms\": 14960.488}", "{\"n\": 11725, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3772.92, \"learn_time_ms\": 14954.661}", "{\"n\": 11726, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3772.92, \"learn_time_ms\": 14952.756}", "{\"n\": 11727, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.85, \"learn_time_ms\": 14955.6}", "{\"n\": 11728, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.85, \"learn_time_ms\": 14951.155}", "{\"n\": 11729, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3775.86, \"learn_time_ms\": 14942.407}", "{\"n\": 11730, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3788.83, \"learn_time_ms\": 14930.568}", "{\"n\": 11731, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3792.92, \"learn_time_ms\": 14920.272}", "{\"n\": 11732, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3794.08, \"learn_time_ms\": 14907.589}", "{\"n\": 11733, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3794.08, \"learn_time_ms\": 14895.807}", "{\"n\": 11734, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3796.11, \"learn_time_ms\": 14888.793}", "{\"n\": 11735, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3796.11, \"learn_time_ms\": 14884.831}", "{\"n\": 11736, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3782.26, \"learn_time_ms\": 14888.596}", "{\"n\": 11737, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3785.94, \"learn_time_ms\": 14888.51}", "{\"n\": 11738, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3798.5, \"learn_time_ms\": 14878.951}", "{\"n\": 11739, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.31, \"learn_time_ms\": 14894.864}", "{\"n\": 11740, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.31, \"learn_time_ms\": 14901.787}", "{\"n\": 11741, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3797.45, \"learn_time_ms\": 14896.597}", "{\"n\": 11742, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3802.81, \"learn_time_ms\": 14909.916}", "{\"n\": 11743, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3805.69, \"learn_time_ms\": 14914.855}", "{\"n\": 11744, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3799.38, \"learn_time_ms\": 14920.069}", "{\"n\": 11745, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.51, \"learn_time_ms\": 14909.784}", "{\"n\": 11746, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.51, \"learn_time_ms\": 14896.825}", "{\"n\": 11747, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3801.51, \"learn_time_ms\": 14900.424}", "{\"n\": 11748, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3799.71, \"learn_time_ms\": 14902.426}", "{\"n\": 11749, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3817.65, \"learn_time_ms\": 14894.449}", "{\"n\": 11750, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3817.65, \"learn_time_ms\": 14886.949}", "{\"n\": 11751, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3810.98, \"learn_time_ms\": 14894.659}", "{\"n\": 11752, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3810.98, \"learn_time_ms\": 14904.177}", "{\"n\": 11753, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3808.96, \"learn_time_ms\": 14904.762}", "{\"n\": 11754, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3807.09, \"learn_time_ms\": 14892.945}", "{\"n\": 11755, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3807.09, \"learn_time_ms\": 14911.433}", "{\"n\": 11756, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3798.38, \"learn_time_ms\": 14914.766}", "{\"n\": 11757, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3802.29, \"learn_time_ms\": 14913.145}", "{\"n\": 11758, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3809.79, \"learn_time_ms\": 14912.07}", "{\"n\": 11759, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3801.53, \"learn_time_ms\": 14915.249}", "{\"n\": 11760, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3812.46, \"learn_time_ms\": 14924.326}", "{\"n\": 11761, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3809.53, \"learn_time_ms\": 14923.753}", "{\"n\": 11762, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.95, \"learn_time_ms\": 14921.795}", "{\"n\": 11763, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.95, \"learn_time_ms\": 14938.456}", "{\"n\": 11764, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3818.67, \"learn_time_ms\": 14935.836}", "{\"n\": 11765, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3816.37, \"learn_time_ms\": 14927.048}", "{\"n\": 11766, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3828.55, \"learn_time_ms\": 14921.239}", "{\"n\": 11767, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3828.55, \"learn_time_ms\": 14923.796}", "{\"n\": 11768, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3829.91, \"learn_time_ms\": 14930.208}", "{\"n\": 11769, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3834.52, \"learn_time_ms\": 14944.689}", "{\"n\": 11770, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3836.64, \"learn_time_ms\": 14950.607}", "{\"n\": 11771, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3825.33, \"learn_time_ms\": 14946.388}", "{\"n\": 11772, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3822.71, \"learn_time_ms\": 14944.205}", "{\"n\": 11773, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3833.46, \"learn_time_ms\": 14937.614}", "{\"n\": 11774, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3833.46, \"learn_time_ms\": 14951.413}", "{\"n\": 11775, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3834.62, \"learn_time_ms\": 14959.829}", "{\"n\": 11776, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3834.62, \"learn_time_ms\": 14968.476}", "{\"n\": 11777, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3829.36, \"learn_time_ms\": 14955.798}", "{\"n\": 11778, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3841.15, \"learn_time_ms\": 14954.329}", "{\"n\": 11779, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3839.64, \"learn_time_ms\": 14956.969}", "{\"n\": 11780, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3839.64, \"learn_time_ms\": 14959.412}", "{\"n\": 11781, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3839.28, \"learn_time_ms\": 14975.816}", "{\"n\": 11782, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3839.28, \"learn_time_ms\": 14957.988}", "{\"n\": 11783, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3839.28, \"learn_time_ms\": 14947.571}", "{\"n\": 11784, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3853.21, \"learn_time_ms\": 14955.039}", "{\"n\": 11785, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3871.0, \"learn_time_ms\": 14956.678}", "{\"n\": 11786, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3858.95, \"learn_time_ms\": 14961.788}", "{\"n\": 11787, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3858.95, \"learn_time_ms\": 14978.055}", "{\"n\": 11788, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3852.62, \"learn_time_ms\": 14971.927}", "{\"n\": 11789, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3843.31, \"learn_time_ms\": 14946.56}", "{\"n\": 11790, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3843.31, \"learn_time_ms\": 14931.597}", "{\"n\": 11791, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3853.93, \"learn_time_ms\": 14920.119}", "{\"n\": 11792, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3848.27, \"learn_time_ms\": 14920.786}", "{\"n\": 11793, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3860.43, \"learn_time_ms\": 14927.937}", "{\"n\": 11794, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3860.43, \"learn_time_ms\": 14897.981}", "{\"n\": 11795, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3845.27, \"learn_time_ms\": 14883.733}", "{\"n\": 11796, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3845.27, \"learn_time_ms\": 14884.88}", "{\"n\": 11797, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3847.33, \"learn_time_ms\": 14870.054}", "{\"n\": 11798, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3843.31, \"learn_time_ms\": 14868.185}", "{\"n\": 11799, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3842.33, \"learn_time_ms\": 14862.819}", "{\"n\": 11800, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3842.33, \"learn_time_ms\": 14859.08}", "{\"n\": 11801, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3850.39, \"learn_time_ms\": 14866.617}", "{\"n\": 11802, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3843.4, \"learn_time_ms\": 14880.428}", "{\"n\": 11803, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3840.58, \"learn_time_ms\": 14880.66}", "{\"n\": 11804, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3840.58, \"learn_time_ms\": 14888.008}", "{\"n\": 11805, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3846.07, \"learn_time_ms\": 14895.864}", "{\"n\": 11806, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3867.65, \"learn_time_ms\": 14893.163}", "{\"n\": 11807, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3867.65, \"learn_time_ms\": 14883.441}", "{\"n\": 11808, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3874.93, \"learn_time_ms\": 14883.205}", "{\"n\": 11809, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3888.82, \"learn_time_ms\": 14912.3}", "{\"n\": 11810, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3888.82, \"learn_time_ms\": 14921.491}", "{\"n\": 11811, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3880.15, \"learn_time_ms\": 14904.289}", "{\"n\": 11812, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3884.67, \"learn_time_ms\": 14893.766}", "{\"n\": 11813, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3873.0, \"learn_time_ms\": 14901.187}", "{\"n\": 11814, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3873.0, \"learn_time_ms\": 14905.759}", "{\"n\": 11815, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3869.46, \"learn_time_ms\": 14898.207}", "{\"n\": 11816, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3869.46, \"learn_time_ms\": 14884.459}", "{\"n\": 11817, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3878.42, \"learn_time_ms\": 14902.146}", "{\"n\": 11818, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3871.98, \"learn_time_ms\": 14929.029}", "{\"n\": 11819, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3875.66, \"learn_time_ms\": 14928.803}", "{\"n\": 11820, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3879.43, \"learn_time_ms\": 14927.296}", "{\"n\": 11821, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3884.83, \"learn_time_ms\": 14935.012}", "{\"n\": 11822, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3881.64, \"learn_time_ms\": 14943.462}", "{\"n\": 11823, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3881.64, \"learn_time_ms\": 14939.747}", "{\"n\": 11824, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3873.35, \"learn_time_ms\": 14942.858}", "{\"n\": 11825, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3880.04, \"learn_time_ms\": 14962.252}", "{\"n\": 11826, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3867.57, \"learn_time_ms\": 14967.967}", "{\"n\": 11827, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3867.57, \"learn_time_ms\": 14965.014}", "{\"n\": 11828, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3879.07, \"learn_time_ms\": 14947.513}", "{\"n\": 11829, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3879.07, \"learn_time_ms\": 14940.989}", "{\"n\": 11830, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3877.94, \"learn_time_ms\": 14958.75}", "{\"n\": 11831, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3872.48, \"learn_time_ms\": 14965.393}", "{\"n\": 11832, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3872.48, \"learn_time_ms\": 14976.386}", "{\"n\": 11833, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3874.85, \"learn_time_ms\": 14959.931}", "{\"n\": 11834, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3871.8, \"learn_time_ms\": 14953.959}", "{\"n\": 11835, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3889.79, \"learn_time_ms\": 14933.477}", "{\"n\": 11836, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3891.71, \"learn_time_ms\": 14939.227}", "{\"n\": 11837, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3890.74, \"learn_time_ms\": 14949.441}", "{\"n\": 11838, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3890.74, \"learn_time_ms\": 14947.849}", "{\"n\": 11839, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3890.74, \"learn_time_ms\": 14951.159}", "{\"n\": 11840, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3893.87, \"learn_time_ms\": 14929.977}", "{\"n\": 11841, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3896.32, \"learn_time_ms\": 14925.311}", "{\"n\": 11842, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3894.9, \"learn_time_ms\": 14922.726}", "{\"n\": 11843, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3884.4, \"learn_time_ms\": 14931.811}", "{\"n\": 11844, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3884.4, \"learn_time_ms\": 14941.56}", "{\"n\": 11845, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3884.4, \"learn_time_ms\": 14954.085}", "{\"n\": 11846, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3880.05, \"learn_time_ms\": 14959.429}", "{\"n\": 11847, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3880.05, \"learn_time_ms\": 14949.707}", "{\"n\": 11848, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3892.32, \"learn_time_ms\": 14940.757}", "{\"n\": 11849, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3888.45, \"learn_time_ms\": 14921.357}", "{\"n\": 11850, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3885.91, \"learn_time_ms\": 14925.469}", "{\"n\": 11851, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3890.94, \"learn_time_ms\": 14914.532}", "{\"n\": 11852, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3889.86, \"learn_time_ms\": 14892.286}", "{\"n\": 11853, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3884.1, \"learn_time_ms\": 14899.715}", "{\"n\": 11854, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3884.1, \"learn_time_ms\": 14888.348}", "{\"n\": 11855, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3872.97, \"learn_time_ms\": 14883.804}", "{\"n\": 11856, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3871.14, \"learn_time_ms\": 14867.765}", "{\"n\": 11857, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3875.75, \"learn_time_ms\": 14862.29}", "{\"n\": 11858, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3874.03, \"learn_time_ms\": 14862.7}", "{\"n\": 11859, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3873.36, \"learn_time_ms\": 14870.006}", "{\"n\": 11860, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3873.36, \"learn_time_ms\": 14866.308}", "{\"n\": 11861, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3873.36, \"learn_time_ms\": 14864.289}", "{\"n\": 11862, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3877.69, \"learn_time_ms\": 14877.954}", "{\"n\": 11863, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3876.52, \"learn_time_ms\": 14875.197}", "{\"n\": 11864, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3865.68, \"learn_time_ms\": 14885.879}", "{\"n\": 11865, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3855.48, \"learn_time_ms\": 14885.557}", "{\"n\": 11866, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3859.85, \"learn_time_ms\": 14899.016}", "{\"n\": 11867, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3859.85, \"learn_time_ms\": 14920.751}", "{\"n\": 11868, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3861.9, \"learn_time_ms\": 14928.409}", "{\"n\": 11869, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3871.94, \"learn_time_ms\": 14933.071}", "{\"n\": 11870, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3870.94, \"learn_time_ms\": 14947.435}", "{\"n\": 11871, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3873.41, \"learn_time_ms\": 14959.44}", "{\"n\": 11872, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3873.41, \"learn_time_ms\": 14950.473}", "{\"n\": 11873, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3850.21, \"learn_time_ms\": 14948.08}", "{\"n\": 11874, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3850.21, \"learn_time_ms\": 14948.169}", "{\"n\": 11875, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3833.01, \"learn_time_ms\": 14942.162}", "{\"n\": 11876, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3835.45, \"learn_time_ms\": 14937.17}", "{\"n\": 11877, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3824.19, \"learn_time_ms\": 14932.781}", "{\"n\": 11878, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3824.19, \"learn_time_ms\": 14932.024}", "{\"n\": 11879, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3820.91, \"learn_time_ms\": 14931.491}", "{\"n\": 11880, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3813.79, \"learn_time_ms\": 14932.733}", "{\"n\": 11881, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3813.65, \"learn_time_ms\": 14924.699}", "{\"n\": 11882, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3816.66, \"learn_time_ms\": 14932.219}", "{\"n\": 11883, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3803.36, \"learn_time_ms\": 14936.926}", "{\"n\": 11884, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3804.64, \"learn_time_ms\": 14938.042}", "{\"n\": 11885, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3804.64, \"learn_time_ms\": 14933.703}", "{\"n\": 11886, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3790.42, \"learn_time_ms\": 14932.491}", "{\"n\": 11887, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3790.42, \"learn_time_ms\": 14911.71}", "{\"n\": 11888, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3796.12, \"learn_time_ms\": 14914.366}", "{\"n\": 11889, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3791.69, \"learn_time_ms\": 14916.572}", "{\"n\": 11890, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3791.69, \"learn_time_ms\": 14897.771}", "{\"n\": 11891, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3791.69, \"learn_time_ms\": 14913.515}", "{\"n\": 11892, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3782.57, \"learn_time_ms\": 14926.599}", "{\"n\": 11893, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3779.52, \"learn_time_ms\": 14924.857}", "{\"n\": 11894, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3787.6, \"learn_time_ms\": 14922.49}", "{\"n\": 11895, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3789.72, \"learn_time_ms\": 14929.157}", "{\"n\": 11896, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3803.06, \"learn_time_ms\": 14935.387}", "{\"n\": 11897, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3789.35, \"learn_time_ms\": 14952.809}", "{\"n\": 11898, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3790.43, \"learn_time_ms\": 14961.646}", "{\"n\": 11899, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3788.22, \"learn_time_ms\": 14956.151}", "{\"n\": 11900, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3785.22, \"learn_time_ms\": 14968.018}", "{\"n\": 11901, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3785.22, \"learn_time_ms\": 14945.585}", "{\"n\": 11902, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3785.22, \"learn_time_ms\": 14926.33}", "{\"n\": 11903, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3795.48, \"learn_time_ms\": 14925.775}", "{\"n\": 11904, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3780.8, \"learn_time_ms\": 14931.367}", "{\"n\": 11905, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3780.6, \"learn_time_ms\": 14944.59}", "{\"n\": 11906, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.64, \"learn_time_ms\": 14956.482}", "{\"n\": 11907, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.64, \"learn_time_ms\": 14950.915}", "{\"n\": 11908, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.64, \"learn_time_ms\": 14938.028}", "{\"n\": 11909, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3784.79, \"learn_time_ms\": 14932.376}", "{\"n\": 11910, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3791.77, \"learn_time_ms\": 14927.804}", "{\"n\": 11911, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3792.02, \"learn_time_ms\": 14962.551}", "{\"n\": 11912, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3775.77, \"learn_time_ms\": 14970.155}", "{\"n\": 11913, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3775.77, \"learn_time_ms\": 14970.612}", "{\"n\": 11914, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3767.57, \"learn_time_ms\": 14951.311}", "{\"n\": 11915, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3767.57, \"learn_time_ms\": 14943.443}", "{\"n\": 11916, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3769.22, \"learn_time_ms\": 14935.089}", "{\"n\": 11917, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3775.85, \"learn_time_ms\": 14932.685}", "{\"n\": 11918, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3776.6, \"learn_time_ms\": 14934.416}", "{\"n\": 11919, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3762.88, \"learn_time_ms\": 14930.405}", "{\"n\": 11920, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3762.88, \"learn_time_ms\": 14943.148}", "{\"n\": 11921, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.69, \"learn_time_ms\": 14923.052}", "{\"n\": 11922, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.69, \"learn_time_ms\": 14920.065}", "{\"n\": 11923, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3773.41, \"learn_time_ms\": 14909.314}", "{\"n\": 11924, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3773.24, \"learn_time_ms\": 14916.519}", "{\"n\": 11925, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3778.9, \"learn_time_ms\": 14912.62}", "{\"n\": 11926, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3768.29, \"learn_time_ms\": 14896.164}", "{\"n\": 11927, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3768.29, \"learn_time_ms\": 14884.628}", "{\"n\": 11928, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3753.65, \"learn_time_ms\": 14894.75}", "{\"n\": 11929, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3753.65, \"learn_time_ms\": 14900.2}", "{\"n\": 11930, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3762.71, \"learn_time_ms\": 14899.004}", "{\"n\": 11931, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3765.4, \"learn_time_ms\": 14894.981}", "{\"n\": 11932, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.99, \"learn_time_ms\": 14884.725}", "{\"n\": 11933, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.99, \"learn_time_ms\": 14882.7}", "{\"n\": 11934, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.99, \"learn_time_ms\": 14866.772}", "{\"n\": 11935, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3738.07, \"learn_time_ms\": 14864.963}", "{\"n\": 11936, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3732.99, \"learn_time_ms\": 14893.115}", "{\"n\": 11937, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3738.69, \"learn_time_ms\": 14894.375}", "{\"n\": 11938, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3729.93, \"learn_time_ms\": 14890.085}", "{\"n\": 11939, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3727.51, \"learn_time_ms\": 14893.639}", "{\"n\": 11940, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3727.51, \"learn_time_ms\": 14884.893}", "{\"n\": 11941, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3727.51, \"learn_time_ms\": 14882.543}", "{\"n\": 11942, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3742.71, \"learn_time_ms\": 14896.967}", "{\"n\": 11943, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3755.37, \"learn_time_ms\": 14905.717}", "{\"n\": 11944, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3760.35, \"learn_time_ms\": 14919.28}", "{\"n\": 11945, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3765.19, \"learn_time_ms\": 14919.677}", "{\"n\": 11946, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3771.41, \"learn_time_ms\": 14910.025}", "{\"n\": 11947, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3771.41, \"learn_time_ms\": 14918.866}", "{\"n\": 11948, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3775.24, \"learn_time_ms\": 14915.15}", "{\"n\": 11949, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3772.72, \"learn_time_ms\": 14919.143}", "{\"n\": 11950, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3772.72, \"learn_time_ms\": 14921.377}", "{\"n\": 11951, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3772.72, \"learn_time_ms\": 14930.965}", "{\"n\": 11952, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3797.49, \"learn_time_ms\": 14935.501}", "{\"n\": 11953, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3805.59, \"learn_time_ms\": 14940.801}", "{\"n\": 11954, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3808.8, \"learn_time_ms\": 14950.639}", "{\"n\": 11955, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3811.07, \"learn_time_ms\": 14956.633}", "{\"n\": 11956, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3811.07, \"learn_time_ms\": 14942.587}", "{\"n\": 11957, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3784.38, \"learn_time_ms\": 14946.082}", "{\"n\": 11958, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3802.27, \"learn_time_ms\": 14943.162}", "{\"n\": 11959, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3802.27, \"learn_time_ms\": 14954.624}", "{\"n\": 11960, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3790.43, \"learn_time_ms\": 14967.066}", "{\"n\": 11961, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3780.79, \"learn_time_ms\": 14968.444}", "{\"n\": 11962, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3786.06, \"learn_time_ms\": 14971.997}", "{\"n\": 11963, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3786.06, \"learn_time_ms\": 14970.527}", "{\"n\": 11964, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3774.84, \"learn_time_ms\": 14968.382}", "{\"n\": 11965, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3761.32, \"learn_time_ms\": 14960.89}", "{\"n\": 11966, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3765.87, \"learn_time_ms\": 14952.277}", "{\"n\": 11967, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.29, \"learn_time_ms\": 14958.493}", "{\"n\": 11968, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3764.29, \"learn_time_ms\": 14955.527}", "{\"n\": 11969, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3768.29, \"learn_time_ms\": 14944.832}", "{\"n\": 11970, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3769.82, \"learn_time_ms\": 14954.283}", "{\"n\": 11971, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3771.28, \"learn_time_ms\": 14956.367}", "{\"n\": 11972, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3771.28, \"learn_time_ms\": 14939.942}", "{\"n\": 11973, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3771.28, \"learn_time_ms\": 14936.149}", "{\"n\": 11974, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3770.47, \"learn_time_ms\": 14922.592}", "{\"n\": 11975, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3768.38, \"learn_time_ms\": 14934.285}", "{\"n\": 11976, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3768.89, \"learn_time_ms\": 14950.138}", "{\"n\": 11977, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3759.46, \"learn_time_ms\": 14938.741}", "{\"n\": 11978, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3754.98, \"learn_time_ms\": 14934.036}", "{\"n\": 11979, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3753.77, \"learn_time_ms\": 14932.958}", "{\"n\": 11980, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3751.53, \"learn_time_ms\": 14920.037}", "{\"n\": 11981, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3751.53, \"learn_time_ms\": 14912.121}", "{\"n\": 11982, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3744.47, \"learn_time_ms\": 14915.222}", "{\"n\": 11983, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3759.06, \"learn_time_ms\": 14903.541}", "{\"n\": 11984, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3775.08, \"learn_time_ms\": 14900.121}", "{\"n\": 11985, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3774.83, \"learn_time_ms\": 14897.651}", "{\"n\": 11986, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3767.84, \"learn_time_ms\": 14879.278}", "{\"n\": 11987, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3767.84, \"learn_time_ms\": 14878.563}", "{\"n\": 11988, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3762.03, \"learn_time_ms\": 14880.333}", "{\"n\": 11989, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3760.62, \"learn_time_ms\": 14878.428}", "{\"n\": 11990, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.35, \"learn_time_ms\": 14870.632}", "{\"n\": 11991, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3770.35, \"learn_time_ms\": 14863.348}", "{\"n\": 11992, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3777.57, \"learn_time_ms\": 14879.987}", "{\"n\": 11993, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.31, \"learn_time_ms\": 14892.031}", "{\"n\": 11994, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3769.31, \"learn_time_ms\": 14919.625}", "{\"n\": 11995, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3740.06, \"learn_time_ms\": 14909.22}", "{\"n\": 11996, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3740.28, \"learn_time_ms\": 14910.986}", "{\"n\": 11997, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3744.12, \"learn_time_ms\": 14906.896}", "{\"n\": 11998, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3749.98, \"learn_time_ms\": 14896.005}", "{\"n\": 11999, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3749.98, \"learn_time_ms\": 14891.899}", "{\"n\": 12000, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3736.27, \"learn_time_ms\": 14888.516}"]