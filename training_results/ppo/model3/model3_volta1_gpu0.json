["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10658.956}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10531.356}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 10485.009}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.666666666666668, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1106.6666666666667, \"learn_time_ms\": 10425.596}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.375, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1207.75, \"learn_time_ms\": 10389.146}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.416666666666668, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1198.0833333333333, \"learn_time_ms\": 10379.975}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3125, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1239.0625, \"learn_time_ms\": 10362.809}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1219.65, \"learn_time_ms\": 10369.61}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.375, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1233.3333333333333, \"learn_time_ms\": 10351.426}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.40740740740741, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1221.5555555555557, \"learn_time_ms\": 10335.171}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4375, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1214.46875, \"learn_time_ms\": 10290.68}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.441176470588236, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1208.9411764705883, \"learn_time_ms\": 10263.951}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28205128205128, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1229.7179487179487, \"learn_time_ms\": 10241.533}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.30952380952381, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1233.2619047619048, \"learn_time_ms\": 10234.896}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.361702127659573, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1238.3191489361702, \"learn_time_ms\": 10226.67}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3265306122449, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1246.591836734694, \"learn_time_ms\": 10205.41}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.32075471698113, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1251.2830188679245, \"learn_time_ms\": 10193.126}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.280701754385966, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1259.3157894736842, \"learn_time_ms\": 10178.203}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.311475409836067, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1257.377049180328, \"learn_time_ms\": 10201.593}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.307692307692307, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1261.7384615384615, \"learn_time_ms\": 10228.459}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.333333333333332, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1264.159420289855, \"learn_time_ms\": 10254.103}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34246575342466, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1261.4246575342465, \"learn_time_ms\": 10282.756}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.307692307692307, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1265.2307692307693, \"learn_time_ms\": 10305.788}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.320987654320987, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1263.2962962962963, \"learn_time_ms\": 10326.75}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.333333333333332, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1260.5119047619048, \"learn_time_ms\": 10343.187}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.329545454545453, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1258.5227272727273, \"learn_time_ms\": 10359.027}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.322222222222223, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1258.5, \"learn_time_ms\": 10351.193}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.263157894736842, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1265.2736842105264, \"learn_time_ms\": 10341.788}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.242424242424242, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1268.4949494949494, \"learn_time_ms\": 10291.746}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1271.85, \"learn_time_ms\": 10245.18}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1268.75, \"learn_time_ms\": 10202.933}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1269.4, \"learn_time_ms\": 10185.108}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1262.88, \"learn_time_ms\": 10175.513}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1264.18, \"learn_time_ms\": 10151.363}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.29, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1261.09, \"learn_time_ms\": 10143.264}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1263.57, \"learn_time_ms\": 10120.218}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.26, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1261.84, \"learn_time_ms\": 10148.716}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1259.5, \"learn_time_ms\": 10190.823}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.32, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1248.96, \"learn_time_ms\": 10237.286}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.33, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1239.37, \"learn_time_ms\": 10287.422}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1235.42, \"learn_time_ms\": 10327.115}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1217.99, \"learn_time_ms\": 10362.351}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1214.36, \"learn_time_ms\": 10384.855}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1208.7, \"learn_time_ms\": 10421.037}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1210.71, \"learn_time_ms\": 10452.845}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1212.96, \"learn_time_ms\": 10500.97}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1216.05, \"learn_time_ms\": 10540.284}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1211.25, \"learn_time_ms\": 10535.401}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1206.88, \"learn_time_ms\": 10545.189}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1210.6, \"learn_time_ms\": 10544.696}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1214.82, \"learn_time_ms\": 10538.996}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1206.32, \"learn_time_ms\": 10515.889}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1209.67, \"learn_time_ms\": 10503.235}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1198.56, \"learn_time_ms\": 10498.375}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1198.29, \"learn_time_ms\": 10486.934}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1197.65, \"learn_time_ms\": 10478.949}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1194.03, \"learn_time_ms\": 10461.397}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1194.26, \"learn_time_ms\": 10453.214}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1187.91, \"learn_time_ms\": 10445.086}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1190.65, \"learn_time_ms\": 10442.615}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1192.81, \"learn_time_ms\": 10446.312}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1194.78, \"learn_time_ms\": 10454.07}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1197.96, \"learn_time_ms\": 10466.396}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1199.65, \"learn_time_ms\": 10472.459}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1207.86, \"learn_time_ms\": 10464.521}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1205.08, \"learn_time_ms\": 10466.253}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1209.96, \"learn_time_ms\": 10456.402}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1210.94, \"learn_time_ms\": 10456.435}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1216.43, \"learn_time_ms\": 10447.612}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1209.35, \"learn_time_ms\": 10442.175}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1207.26, \"learn_time_ms\": 10440.011}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1204.44, \"learn_time_ms\": 10440.659}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1207.02, \"learn_time_ms\": 10418.406}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1206.79, \"learn_time_ms\": 10402.182}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1196.87, \"learn_time_ms\": 10415.52}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1192.72, \"learn_time_ms\": 10409.733}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1187.95, \"learn_time_ms\": 10403.749}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1189.36, \"learn_time_ms\": 10401.158}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1192.24, \"learn_time_ms\": 10408.651}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1191.67, \"learn_time_ms\": 10408.661}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1200.92, \"learn_time_ms\": 10420.782}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1201.39, \"learn_time_ms\": 10430.152}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1202.31, \"learn_time_ms\": 10443.56}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1206.61, \"learn_time_ms\": 10461.195}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1212.22, \"learn_time_ms\": 10454.222}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1210.15, \"learn_time_ms\": 10459.549}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1207.67, \"learn_time_ms\": 10475.676}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1207.62, \"learn_time_ms\": 10484.75}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1208.26, \"learn_time_ms\": 10489.219}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1204.49, \"learn_time_ms\": 10499.27}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1201.82, \"learn_time_ms\": 10511.446}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1195.08, \"learn_time_ms\": 10495.879}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1198.17, \"learn_time_ms\": 10496.584}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1190.32, \"learn_time_ms\": 10495.728}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.19, \"learn_time_ms\": 10500.414}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1180.93, \"learn_time_ms\": 10495.467}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1176.94, \"learn_time_ms\": 10487.783}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1184.42, \"learn_time_ms\": 10478.234}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1187.27, \"learn_time_ms\": 10475.781}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1191.44, \"learn_time_ms\": 10479.426}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1202.03, \"learn_time_ms\": 10463.361}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1198.81, \"learn_time_ms\": 10469.502}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.67, \"learn_time_ms\": 10466.578}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1198.08, \"learn_time_ms\": 10454.059}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1195.74, \"learn_time_ms\": 10444.362}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1195.12, \"learn_time_ms\": 10450.548}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1195.96, \"learn_time_ms\": 10445.209}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.56, \"learn_time_ms\": 10452.992}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1192.82, \"learn_time_ms\": 10449.52}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.65, \"learn_time_ms\": 10450.49}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1181.75, \"learn_time_ms\": 10449.27}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1180.7, \"learn_time_ms\": 10445.799}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1181.39, \"learn_time_ms\": 10446.649}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1192.01, \"learn_time_ms\": 10452.92}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1201.57, \"learn_time_ms\": 10457.424}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1200.82, \"learn_time_ms\": 10446.658}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1207.35, \"learn_time_ms\": 10443.35}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1205.8, \"learn_time_ms\": 10432.276}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1208.75, \"learn_time_ms\": 10432.723}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1221.82, \"learn_time_ms\": 10416.103}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1223.56, \"learn_time_ms\": 10405.497}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1221.99, \"learn_time_ms\": 10402.219}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1217.08, \"learn_time_ms\": 10406.978}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1210.73, \"learn_time_ms\": 10395.303}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1202.16, \"learn_time_ms\": 10394.008}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1199.85, \"learn_time_ms\": 10396.364}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1203.89, \"learn_time_ms\": 10398.536}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1210.57, \"learn_time_ms\": 10398.065}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1210.67, \"learn_time_ms\": 10398.002}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1209.55, \"learn_time_ms\": 10397.586}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1211.02, \"learn_time_ms\": 10404.368}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1212.2, \"learn_time_ms\": 10399.202}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1219.02, \"learn_time_ms\": 10390.029}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1215.86, \"learn_time_ms\": 10385.082}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1217.45, \"learn_time_ms\": 10377.34}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1227.93, \"learn_time_ms\": 10378.424}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1232.44, \"learn_time_ms\": 10372.672}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1233.65, \"learn_time_ms\": 10385.671}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1228.1, \"learn_time_ms\": 10381.02}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1219.31, \"learn_time_ms\": 10384.408}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1221.32, \"learn_time_ms\": 10384.489}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1224.39, \"learn_time_ms\": 10407.024}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1224.8, \"learn_time_ms\": 10418.514}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1216.01, \"learn_time_ms\": 10430.436}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1221.52, \"learn_time_ms\": 10446.731}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1223.49, \"learn_time_ms\": 10444.993}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1225.62, \"learn_time_ms\": 10453.018}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1227.37, \"learn_time_ms\": 10445.657}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1229.27, \"learn_time_ms\": 10445.471}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1239.21, \"learn_time_ms\": 10438.72}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1243.41, \"learn_time_ms\": 10433.531}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1240.74, \"learn_time_ms\": 10422.436}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1237.78, \"learn_time_ms\": 10408.317}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1230.57, \"learn_time_ms\": 10405.363}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1231.33, \"learn_time_ms\": 10406.305}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1225.32, \"learn_time_ms\": 10408.431}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1215.71, \"learn_time_ms\": 10420.548}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1214.98, \"learn_time_ms\": 10421.924}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1205.73, \"learn_time_ms\": 10423.389}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1204.93, \"learn_time_ms\": 10423.134}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1198.68, \"learn_time_ms\": 10425.844}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1199.51, \"learn_time_ms\": 10418.308}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1193.79, \"learn_time_ms\": 10420.755}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1193.79, \"learn_time_ms\": 10418.3}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1196.87, \"learn_time_ms\": 10406.952}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1196.26, \"learn_time_ms\": 10408.056}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1194.97, \"learn_time_ms\": 10396.257}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1202.17, \"learn_time_ms\": 10392.133}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1198.07, \"learn_time_ms\": 10390.66}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1196.88, \"learn_time_ms\": 10398.243}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1188.33, \"learn_time_ms\": 10409.759}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1189.16, \"learn_time_ms\": 10436.319}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1180.48, \"learn_time_ms\": 10440.159}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1180.48, \"learn_time_ms\": 10449.294}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1168.45, \"learn_time_ms\": 10457.828}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1167.29, \"learn_time_ms\": 10458.102}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1177.06, \"learn_time_ms\": 10452.45}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1185.46, \"learn_time_ms\": 10459.827}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1188.34, \"learn_time_ms\": 10458.767}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1186.37, \"learn_time_ms\": 10460.611}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1194.7, \"learn_time_ms\": 10450.084}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1194.58, \"learn_time_ms\": 10426.191}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1208.2, \"learn_time_ms\": 10423.893}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1209.05, \"learn_time_ms\": 10423.951}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1219.45, \"learn_time_ms\": 10417.925}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1217.48, \"learn_time_ms\": 10422.474}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1209.04, \"learn_time_ms\": 10422.129}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1206.79, \"learn_time_ms\": 10413.776}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1210.55, \"learn_time_ms\": 10420.477}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1216.71, \"learn_time_ms\": 10416.855}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1223.4, \"learn_time_ms\": 10417.281}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1223.34, \"learn_time_ms\": 10430.08}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1217.92, \"learn_time_ms\": 10432.469}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1215.26, \"learn_time_ms\": 10432.343}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1224.71, \"learn_time_ms\": 10432.874}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1231.79, \"learn_time_ms\": 10427.438}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1239.93, \"learn_time_ms\": 10431.474}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1232.74, \"learn_time_ms\": 10428.274}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1231.17, \"learn_time_ms\": 10434.02}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1229.26, \"learn_time_ms\": 10435.053}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1238.03, \"learn_time_ms\": 10436.475}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1237.17, \"learn_time_ms\": 10437.508}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1227.42, \"learn_time_ms\": 10442.287}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1226.02, \"learn_time_ms\": 10453.749}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1222.17, \"learn_time_ms\": 10453.911}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1219.34, \"learn_time_ms\": 10453.467}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1214.59, \"learn_time_ms\": 10453.562}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1212.97, \"learn_time_ms\": 10464.603}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1210.87, \"learn_time_ms\": 10452.609}", "{\"n\": 210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1204.92, \"learn_time_ms\": 10464.572}", "{\"n\": 211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1204.0, \"learn_time_ms\": 10453.796}", "{\"n\": 212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1230.98, \"learn_time_ms\": 10450.538}", "{\"n\": 213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1227.66, \"learn_time_ms\": 10447.203}", "{\"n\": 214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1208.28, \"learn_time_ms\": 10433.627}", "{\"n\": 215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1197.13, \"learn_time_ms\": 10431.202}", "{\"n\": 216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1191.01, \"learn_time_ms\": 10437.486}", "{\"n\": 217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.76, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1179.41, \"learn_time_ms\": 10437.794}", "{\"n\": 218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1170.66, \"learn_time_ms\": 10425.255}", "{\"n\": 219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1153.87, \"learn_time_ms\": 10429.698}", "{\"n\": 220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1145.49, \"learn_time_ms\": 10420.251}", "{\"n\": 221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1137.57, \"learn_time_ms\": 10434.637}", "{\"n\": 222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1135.81, \"learn_time_ms\": 10438.71}", "{\"n\": 223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1128.81, \"learn_time_ms\": 10440.074}", "{\"n\": 224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1109.32, \"learn_time_ms\": 10438.698}", "{\"n\": 225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1104.15, \"learn_time_ms\": 10433.05}", "{\"n\": 226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1096.38, \"learn_time_ms\": 10430.345}", "{\"n\": 227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1086.12, \"learn_time_ms\": 10433.511}", "{\"n\": 228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1081.57, \"learn_time_ms\": 10435.704}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1072.03, \"learn_time_ms\": 10441.302}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1063.43, \"learn_time_ms\": 10442.559}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.93, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1057.79, \"learn_time_ms\": 10445.963}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1043.31, \"learn_time_ms\": 10421.844}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.02, \"learn_time_ms\": 10418.661}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.91, \"learn_time_ms\": 10424.956}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.06, \"learn_time_ms\": 10431.799}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.84, \"learn_time_ms\": 10432.325}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 10422.661}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 10429.845}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.09, \"learn_time_ms\": 10428.831}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.31, \"learn_time_ms\": 10424.009}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.98, \"learn_time_ms\": 10409.19}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.85, \"learn_time_ms\": 10419.739}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.88, \"learn_time_ms\": 10419.979}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.64, \"learn_time_ms\": 10412.305}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.85, \"learn_time_ms\": 10414.296}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 10416.711}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.06, \"learn_time_ms\": 10425.312}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.22, \"learn_time_ms\": 10421.432}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 10421.175}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34, \"learn_time_ms\": 10420.496}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.82, \"learn_time_ms\": 10428.7}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.23, \"learn_time_ms\": 10430.235}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.17, \"learn_time_ms\": 10436.989}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.28, \"learn_time_ms\": 10441.219}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.48, \"learn_time_ms\": 10433.437}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.52, \"learn_time_ms\": 10434.276}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.54, \"learn_time_ms\": 10432.819}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.82, \"learn_time_ms\": 10448.81}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.88, \"learn_time_ms\": 10448.47}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.75, \"learn_time_ms\": 10447.655}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.52, \"learn_time_ms\": 10448.014}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.41, \"learn_time_ms\": 10457.249}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.52, \"learn_time_ms\": 10450.748}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1, \"learn_time_ms\": 10456.555}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 10458.334}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.76, \"learn_time_ms\": 10453.259}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.25, \"learn_time_ms\": 10447.415}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.87, \"learn_time_ms\": 10433.967}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.06, \"learn_time_ms\": 10425.606}", "{\"n\": 270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.74, \"learn_time_ms\": 10436.682}", "{\"n\": 271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.97, \"learn_time_ms\": 10430.878}", "{\"n\": 272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 10411.295}", "{\"n\": 273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.18, \"learn_time_ms\": 10417.283}", "{\"n\": 274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.58, \"learn_time_ms\": 10407.938}", "{\"n\": 275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.43, \"learn_time_ms\": 10407.842}", "{\"n\": 276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.06, \"learn_time_ms\": 10408.86}", "{\"n\": 277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 10416.435}", "{\"n\": 278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.66, \"learn_time_ms\": 10416.284}", "{\"n\": 279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.78, \"learn_time_ms\": 10417.549}", "{\"n\": 280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.76, \"learn_time_ms\": 10408.437}", "{\"n\": 281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.65, \"learn_time_ms\": 10417.165}", "{\"n\": 282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 10423.17}", "{\"n\": 283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.82, \"learn_time_ms\": 10413.998}", "{\"n\": 284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.36, \"learn_time_ms\": 10419.309}", "{\"n\": 285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.46, \"learn_time_ms\": 10421.591}", "{\"n\": 286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 10419.129}", "{\"n\": 287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.49, \"learn_time_ms\": 10410.148}", "{\"n\": 288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.43, \"learn_time_ms\": 10401.188}", "{\"n\": 289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.28, \"learn_time_ms\": 10405.66}", "{\"n\": 290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.25, \"learn_time_ms\": 10405.222}", "{\"n\": 291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.36, \"learn_time_ms\": 10395.472}", "{\"n\": 292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.22, \"learn_time_ms\": 10402.779}", "{\"n\": 293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.34, \"learn_time_ms\": 10401.165}", "{\"n\": 294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.29, \"learn_time_ms\": 10393.461}", "{\"n\": 295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.95, \"learn_time_ms\": 10393.532}", "{\"n\": 296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.22, \"learn_time_ms\": 10397.439}", "{\"n\": 297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.41, \"learn_time_ms\": 10403.084}", "{\"n\": 298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.33, \"learn_time_ms\": 10407.411}", "{\"n\": 299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.42, \"learn_time_ms\": 10412.778}", "{\"n\": 300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.72, \"learn_time_ms\": 10418.666}", "{\"n\": 301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.67, \"learn_time_ms\": 10415.606}", "{\"n\": 302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 10417.721}", "{\"n\": 303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.26, \"learn_time_ms\": 10427.547}", "{\"n\": 304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 10426.064}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 10428.19}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 10429.349}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 10425.685}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 10428.214}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 10426.586}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.45, \"learn_time_ms\": 10418.289}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.41, \"learn_time_ms\": 10427.931}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.46, \"learn_time_ms\": 10423.088}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 10409.68}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 10415.82}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.9, \"learn_time_ms\": 10416.386}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 10406.46}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.72, \"learn_time_ms\": 10407.535}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 10407.305}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.15, \"learn_time_ms\": 10405.639}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 10409.324}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.75, \"learn_time_ms\": 10406.348}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.08, \"learn_time_ms\": 10400.995}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.11, \"learn_time_ms\": 10409.64}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.64, \"learn_time_ms\": 10403.902}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.68, \"learn_time_ms\": 10411.524}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.56, \"learn_time_ms\": 10412.669}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.23, \"learn_time_ms\": 10416.273}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.29, \"learn_time_ms\": 10410.123}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.18, \"learn_time_ms\": 10402.986}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.09, \"learn_time_ms\": 10399.018}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.86, \"learn_time_ms\": 10394.257}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.91, \"learn_time_ms\": 10399.4}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.94, \"learn_time_ms\": 10389.047}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.53, \"learn_time_ms\": 10394.748}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.65, \"learn_time_ms\": 10388.491}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 10386.254}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.91, \"learn_time_ms\": 10383.265}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.73, \"learn_time_ms\": 10390.186}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 10386.5}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.36, \"learn_time_ms\": 10384.467}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.03, \"learn_time_ms\": 10386.266}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 10386.535}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 10397.25}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 10385.392}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 10382.651}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.39, \"learn_time_ms\": 10386.907}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 10382.927}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.46, \"learn_time_ms\": 10386.217}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 10400.655}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.2, \"learn_time_ms\": 10398.156}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.62, \"learn_time_ms\": 10399.14}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 10392.447}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 10395.316}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.06, \"learn_time_ms\": 10401.442}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.42, \"learn_time_ms\": 10393.405}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.83, \"learn_time_ms\": 10394.607}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.31, \"learn_time_ms\": 10392.339}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 10393.155}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 10389.176}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 10391.159}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.26, \"learn_time_ms\": 10397.838}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.17, \"learn_time_ms\": 10407.941}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.67, \"learn_time_ms\": 10405.774}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.32, \"learn_time_ms\": 10406.581}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.28, \"learn_time_ms\": 10413.911}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.61, \"learn_time_ms\": 10418.131}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.98, \"learn_time_ms\": 10428.447}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.24, \"learn_time_ms\": 10415.273}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.51, \"learn_time_ms\": 10411.142}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.28, \"learn_time_ms\": 10435.188}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.78, \"learn_time_ms\": 10431.256}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.78, \"learn_time_ms\": 10428.324}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.67, \"learn_time_ms\": 10425.365}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.82, \"learn_time_ms\": 10431.882}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.7, \"learn_time_ms\": 10438.053}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.57, \"learn_time_ms\": 10433.089}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.54, \"learn_time_ms\": 10431.048}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.98, \"learn_time_ms\": 10440.312}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.47, \"learn_time_ms\": 10443.394}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.55, \"learn_time_ms\": 10423.358}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 10426.579}", "{\"n\": 382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 10414.879}", "{\"n\": 383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.21, \"learn_time_ms\": 10419.814}", "{\"n\": 384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.56, \"learn_time_ms\": 10417.067}", "{\"n\": 385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.56, \"learn_time_ms\": 10410.346}", "{\"n\": 386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.31, \"learn_time_ms\": 10405.293}", "{\"n\": 387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 10407.915}", "{\"n\": 388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 10405.141}", "{\"n\": 389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 10404.798}", "{\"n\": 390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.6, \"learn_time_ms\": 10402.371}", "{\"n\": 391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.18, \"learn_time_ms\": 10397.522}", "{\"n\": 392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.55, \"learn_time_ms\": 10397.915}", "{\"n\": 393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.53, \"learn_time_ms\": 10404.875}", "{\"n\": 394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.23, \"learn_time_ms\": 10405.831}", "{\"n\": 395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 10418.826}", "{\"n\": 396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.84, \"learn_time_ms\": 10427.476}", "{\"n\": 397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 10424.919}", "{\"n\": 398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.56, \"learn_time_ms\": 10420.113}", "{\"n\": 399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 10427.259}", "{\"n\": 400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.03, \"learn_time_ms\": 10422.345}", "{\"n\": 401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 10428.832}", "{\"n\": 402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.86, \"learn_time_ms\": 10461.783}", "{\"n\": 403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 10453.854}", "{\"n\": 404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.81, \"learn_time_ms\": 10449.676}", "{\"n\": 405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.76, \"learn_time_ms\": 10438.907}", "{\"n\": 406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 10435.158}", "{\"n\": 407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.45, \"learn_time_ms\": 10432.032}", "{\"n\": 408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.65, \"learn_time_ms\": 10433.638}", "{\"n\": 409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.84, \"learn_time_ms\": 10430.232}", "{\"n\": 410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 10443.178}", "{\"n\": 411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 10439.903}", "{\"n\": 412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 10415.653}", "{\"n\": 413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.7, \"learn_time_ms\": 10409.582}", "{\"n\": 414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.84, \"learn_time_ms\": 10414.475}", "{\"n\": 415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 10409.618}", "{\"n\": 416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.85, \"learn_time_ms\": 10414.865}", "{\"n\": 417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.39, \"learn_time_ms\": 10414.012}", "{\"n\": 418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.14, \"learn_time_ms\": 10415.361}", "{\"n\": 419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.81, \"learn_time_ms\": 10408.713}", "{\"n\": 420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 10407.291}", "{\"n\": 421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 10402.708}", "{\"n\": 422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 10411.619}", "{\"n\": 423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 10423.537}", "{\"n\": 424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.67, \"learn_time_ms\": 10421.114}", "{\"n\": 425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.83, \"learn_time_ms\": 10431.121}", "{\"n\": 426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 10430.537}", "{\"n\": 427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 10448.063}", "{\"n\": 428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 10454.403}", "{\"n\": 429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 10462.618}", "{\"n\": 430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.94, \"learn_time_ms\": 10464.065}", "{\"n\": 431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 10469.191}", "{\"n\": 432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 10455.502}", "{\"n\": 433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.41, \"learn_time_ms\": 10449.044}", "{\"n\": 434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 10442.561}", "{\"n\": 435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.09, \"learn_time_ms\": 10437.27}", "{\"n\": 436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 10431.127}", "{\"n\": 437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 10416.846}", "{\"n\": 438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 10409.641}", "{\"n\": 439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.45, \"learn_time_ms\": 10406.108}", "{\"n\": 440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 10397.881}", "{\"n\": 441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 10395.96}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 10403.009}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.83, \"learn_time_ms\": 10410.829}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 10413.583}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.45, \"learn_time_ms\": 10438.392}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 10439.6}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 10441.786}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 10456.248}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 10454.748}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.57, \"learn_time_ms\": 10460.442}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.84, \"learn_time_ms\": 10465.754}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.27, \"learn_time_ms\": 10468.67}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.06, \"learn_time_ms\": 10454.479}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.98, \"learn_time_ms\": 10464.295}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 10439.979}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.03, \"learn_time_ms\": 10438.773}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 10437.255}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5, \"learn_time_ms\": 10424.865}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 10423.515}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 10421.737}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.45, \"learn_time_ms\": 10422.763}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 10415.983}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.83, \"learn_time_ms\": 10427.135}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 10423.038}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.17, \"learn_time_ms\": 10419.72}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 10418.771}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 10420.105}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.21, \"learn_time_ms\": 10413.584}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 10412.067}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 10414.978}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.43, \"learn_time_ms\": 10403.354}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.23, \"learn_time_ms\": 10407.66}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.56, \"learn_time_ms\": 10403.44}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 10416.544}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 10418.904}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 10428.953}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.21, \"learn_time_ms\": 10420.535}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.19, \"learn_time_ms\": 10426.91}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 10436.778}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 10432.731}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.03, \"learn_time_ms\": 10436.418}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.17, \"learn_time_ms\": 10432.145}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 10431.698}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.63, \"learn_time_ms\": 10411.118}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.31, \"learn_time_ms\": 10418.384}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.7, \"learn_time_ms\": 10407.909}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 10430.248}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 10431.289}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.22, \"learn_time_ms\": 10421.042}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 10430.902}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.92, \"learn_time_ms\": 10434.749}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.85, \"learn_time_ms\": 10437.969}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 10436.724}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.17, \"learn_time_ms\": 10437.301}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 10434.273}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 10436.706}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.15, \"learn_time_ms\": 10420.834}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 10421.399}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.64, \"learn_time_ms\": 10428.954}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 10418.805}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.92, \"learn_time_ms\": 10419.696}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 10418.96}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 10416.079}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.59, \"learn_time_ms\": 10421.367}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.53, \"learn_time_ms\": 10420.906}", "{\"n\": 506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.94, \"learn_time_ms\": 10422.744}", "{\"n\": 507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 10429.103}", "{\"n\": 508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4, \"learn_time_ms\": 10429.239}", "{\"n\": 509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 10430.654}", "{\"n\": 510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 10432.844}", "{\"n\": 511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.68, \"learn_time_ms\": 10439.213}", "{\"n\": 512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 10440.17}", "{\"n\": 513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 10443.524}", "{\"n\": 514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.98, \"learn_time_ms\": 10444.102}", "{\"n\": 515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.98, \"learn_time_ms\": 10447.054}", "{\"n\": 516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.46, \"learn_time_ms\": 10448.225}", "{\"n\": 517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 10443.854}", "{\"n\": 518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 10440.637}", "{\"n\": 519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 10430.711}", "{\"n\": 520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 10430.049}", "{\"n\": 521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 10411.015}", "{\"n\": 522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.82, \"learn_time_ms\": 10409.529}", "{\"n\": 523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.96, \"learn_time_ms\": 10408.505}", "{\"n\": 524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0, \"learn_time_ms\": 10408.036}", "{\"n\": 525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 10399.362}", "{\"n\": 526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.36, \"learn_time_ms\": 10403.796}", "{\"n\": 527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 10403.429}", "{\"n\": 528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.92, \"learn_time_ms\": 10411.237}", "{\"n\": 529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.57, \"learn_time_ms\": 10413.886}", "{\"n\": 530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.68, \"learn_time_ms\": 10413.488}", "{\"n\": 531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 10423.565}", "{\"n\": 532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 10429.641}", "{\"n\": 533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 10431.568}", "{\"n\": 534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.54, \"learn_time_ms\": 10427.938}", "{\"n\": 535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.53, \"learn_time_ms\": 10437.182}", "{\"n\": 536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.66, \"learn_time_ms\": 10432.379}", "{\"n\": 537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.73, \"learn_time_ms\": 10426.29}", "{\"n\": 538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.71, \"learn_time_ms\": 10453.286}", "{\"n\": 539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.66, \"learn_time_ms\": 10459.6}", "{\"n\": 540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.74, \"learn_time_ms\": 10463.194}", "{\"n\": 541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 10460.963}", "{\"n\": 542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.58, \"learn_time_ms\": 10459.571}", "{\"n\": 543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 10456.401}", "{\"n\": 544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 10470.34}", "{\"n\": 545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.41, \"learn_time_ms\": 10472.018}", "{\"n\": 546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.92, \"learn_time_ms\": 10472.835}", "{\"n\": 547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.23, \"learn_time_ms\": 10482.675}", "{\"n\": 548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.33, \"learn_time_ms\": 10446.901}", "{\"n\": 549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.42, \"learn_time_ms\": 10446.917}", "{\"n\": 550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.66, \"learn_time_ms\": 10439.315}", "{\"n\": 551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.24, \"learn_time_ms\": 10432.933}", "{\"n\": 552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.15, \"learn_time_ms\": 10422.587}", "{\"n\": 553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.83, \"learn_time_ms\": 10417.042}", "{\"n\": 554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.97, \"learn_time_ms\": 10406.513}", "{\"n\": 555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.79, \"learn_time_ms\": 10393.102}", "{\"n\": 556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.95, \"learn_time_ms\": 10386.556}", "{\"n\": 557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.87, \"learn_time_ms\": 10375.722}", "{\"n\": 558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.83, \"learn_time_ms\": 10380.378}", "{\"n\": 559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.63, \"learn_time_ms\": 10386.214}", "{\"n\": 560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.87, \"learn_time_ms\": 10387.864}", "{\"n\": 561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.46, \"learn_time_ms\": 10397.964}", "{\"n\": 562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.68, \"learn_time_ms\": 10392.344}", "{\"n\": 563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 10399.05}", "{\"n\": 564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 10398.235}", "{\"n\": 565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.22, \"learn_time_ms\": 10401.471}", "{\"n\": 566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 10399.271}", "{\"n\": 567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.41, \"learn_time_ms\": 10405.178}", "{\"n\": 568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.49, \"learn_time_ms\": 10404.518}", "{\"n\": 569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.23, \"learn_time_ms\": 10392.701}", "{\"n\": 570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.3, \"learn_time_ms\": 10401.932}", "{\"n\": 571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 10395.901}", "{\"n\": 572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.3, \"learn_time_ms\": 10420.99}", "{\"n\": 573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.42, \"learn_time_ms\": 10414.102}", "{\"n\": 574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.42, \"learn_time_ms\": 10409.867}", "{\"n\": 575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 10407.639}", "{\"n\": 576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 10408.919}", "{\"n\": 577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.09, \"learn_time_ms\": 10408.67}", "{\"n\": 578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.27, \"learn_time_ms\": 10401.685}", "{\"n\": 579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.58, \"learn_time_ms\": 10405.794}", "{\"n\": 580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.22, \"learn_time_ms\": 10400.397}", "{\"n\": 581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7, \"learn_time_ms\": 10404.267}", "{\"n\": 582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.9, \"learn_time_ms\": 10389.356}", "{\"n\": 583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.97, \"learn_time_ms\": 10396.703}", "{\"n\": 584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.25, \"learn_time_ms\": 10399.538}", "{\"n\": 585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.19, \"learn_time_ms\": 10412.144}", "{\"n\": 586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.02, \"learn_time_ms\": 10416.355}", "{\"n\": 587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.38, \"learn_time_ms\": 10420.733}", "{\"n\": 588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.88, \"learn_time_ms\": 10420.247}", "{\"n\": 589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.66, \"learn_time_ms\": 10420.868}", "{\"n\": 590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 10420.241}", "{\"n\": 591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.82, \"learn_time_ms\": 10418.79}", "{\"n\": 592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.01, \"learn_time_ms\": 10420.446}", "{\"n\": 593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.08, \"learn_time_ms\": 10428.847}", "{\"n\": 594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.75, \"learn_time_ms\": 10427.564}", "{\"n\": 595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.53, \"learn_time_ms\": 10415.671}", "{\"n\": 596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 10417.479}", "{\"n\": 597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.23, \"learn_time_ms\": 10413.634}", "{\"n\": 598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 10423.644}", "{\"n\": 599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.37, \"learn_time_ms\": 10430.853}", "{\"n\": 600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 10423.709}", "{\"n\": 601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5, \"learn_time_ms\": 10424.562}", "{\"n\": 602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5, \"learn_time_ms\": 10426.332}", "{\"n\": 603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.74, \"learn_time_ms\": 10425.768}", "{\"n\": 604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.53, \"learn_time_ms\": 10422.467}", "{\"n\": 605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.79, \"learn_time_ms\": 10416.532}", "{\"n\": 606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.56, \"learn_time_ms\": 10415.971}", "{\"n\": 607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.26, \"learn_time_ms\": 10418.978}", "{\"n\": 608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.24, \"learn_time_ms\": 10412.066}", "{\"n\": 609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.06, \"learn_time_ms\": 10408.594}", "{\"n\": 610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.87, \"learn_time_ms\": 10412.932}", "{\"n\": 611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.95, \"learn_time_ms\": 10415.265}", "{\"n\": 612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.04, \"learn_time_ms\": 10417.183}", "{\"n\": 613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.21, \"learn_time_ms\": 10410.167}", "{\"n\": 614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.96, \"learn_time_ms\": 10417.495}", "{\"n\": 615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.45, \"learn_time_ms\": 10424.889}", "{\"n\": 616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.84, \"learn_time_ms\": 10421.646}", "{\"n\": 617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.55, \"learn_time_ms\": 10422.301}", "{\"n\": 618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.34, \"learn_time_ms\": 10420.754}", "{\"n\": 619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.21, \"learn_time_ms\": 10425.369}", "{\"n\": 620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.35, \"learn_time_ms\": 10429.517}", "{\"n\": 621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9, \"learn_time_ms\": 10419.479}", "{\"n\": 622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.37, \"learn_time_ms\": 10411.793}", "{\"n\": 623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.57, \"learn_time_ms\": 10408.695}", "{\"n\": 624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.54, \"learn_time_ms\": 10402.218}", "{\"n\": 625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.78, \"learn_time_ms\": 10394.571}", "{\"n\": 626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.24, \"learn_time_ms\": 10394.035}", "{\"n\": 627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 10401.286}", "{\"n\": 628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.81, \"learn_time_ms\": 10398.228}", "{\"n\": 629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 10395.0}", "{\"n\": 630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 10391.792}", "{\"n\": 631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.63, \"learn_time_ms\": 10409.401}", "{\"n\": 632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 10406.829}", "{\"n\": 633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.31, \"learn_time_ms\": 10403.871}", "{\"n\": 634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.22, \"learn_time_ms\": 10411.352}", "{\"n\": 635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.57, \"learn_time_ms\": 10416.902}", "{\"n\": 636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.12, \"learn_time_ms\": 10414.87}", "{\"n\": 637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 10397.345}", "{\"n\": 638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.62, \"learn_time_ms\": 10409.442}", "{\"n\": 639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 10394.256}", "{\"n\": 640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.43, \"learn_time_ms\": 10391.43}", "{\"n\": 641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 10386.233}", "{\"n\": 642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 10390.798}", "{\"n\": 643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.52, \"learn_time_ms\": 10398.947}", "{\"n\": 644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 10397.211}", "{\"n\": 645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.85, \"learn_time_ms\": 10402.636}", "{\"n\": 646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 10404.51}", "{\"n\": 647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 10410.574}", "{\"n\": 648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.42, \"learn_time_ms\": 10404.096}", "{\"n\": 649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.43, \"learn_time_ms\": 10411.941}", "{\"n\": 650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 10415.5}", "{\"n\": 651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.86, \"learn_time_ms\": 10416.528}", "{\"n\": 652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.85, \"learn_time_ms\": 10428.734}", "{\"n\": 653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 10425.095}", "{\"n\": 654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 10420.924}", "{\"n\": 655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 10415.568}", "{\"n\": 656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.91, \"learn_time_ms\": 10412.093}", "{\"n\": 657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 10431.014}", "{\"n\": 658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.39, \"learn_time_ms\": 10433.042}", "{\"n\": 659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.25, \"learn_time_ms\": 10433.952}", "{\"n\": 660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.69, \"learn_time_ms\": 10432.795}", "{\"n\": 661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.32, \"learn_time_ms\": 10426.068}", "{\"n\": 662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.26, \"learn_time_ms\": 10414.794}", "{\"n\": 663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.47, \"learn_time_ms\": 10412.65}", "{\"n\": 664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.46, \"learn_time_ms\": 10404.575}", "{\"n\": 665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.11, \"learn_time_ms\": 10413.171}", "{\"n\": 666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.93, \"learn_time_ms\": 10419.827}", "{\"n\": 667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.9, \"learn_time_ms\": 10402.78}", "{\"n\": 668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.94, \"learn_time_ms\": 10406.052}", "{\"n\": 669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.63, \"learn_time_ms\": 10406.975}", "{\"n\": 670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.3, \"learn_time_ms\": 10406.841}", "{\"n\": 671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.67, \"learn_time_ms\": 10411.328}", "{\"n\": 672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.46, \"learn_time_ms\": 10411.595}", "{\"n\": 673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.9, \"learn_time_ms\": 10418.003}", "{\"n\": 674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.92, \"learn_time_ms\": 10424.692}", "{\"n\": 675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.52, \"learn_time_ms\": 10414.626}", "{\"n\": 676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.86, \"learn_time_ms\": 10413.966}", "{\"n\": 677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.8, \"learn_time_ms\": 10419.436}", "{\"n\": 678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.09, \"learn_time_ms\": 10420.771}", "{\"n\": 679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.15, \"learn_time_ms\": 10407.605}", "{\"n\": 680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.36, \"learn_time_ms\": 10407.402}", "{\"n\": 681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.75, \"learn_time_ms\": 10404.319}", "{\"n\": 682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.11, \"learn_time_ms\": 10402.701}", "{\"n\": 683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.37, \"learn_time_ms\": 10399.072}", "{\"n\": 684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.47, \"learn_time_ms\": 10408.172}", "{\"n\": 685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.03, \"learn_time_ms\": 10426.877}", "{\"n\": 686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 10426.107}", "{\"n\": 687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 10414.173}", "{\"n\": 688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.62, \"learn_time_ms\": 10415.642}", "{\"n\": 689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 10422.852}", "{\"n\": 690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.53, \"learn_time_ms\": 10431.664}", "{\"n\": 691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.71, \"learn_time_ms\": 10431.975}", "{\"n\": 692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.43, \"learn_time_ms\": 10435.214}", "{\"n\": 693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.56, \"learn_time_ms\": 10437.38}", "{\"n\": 694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 10437.736}", "{\"n\": 695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 10419.786}", "{\"n\": 696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.41, \"learn_time_ms\": 10431.374}", "{\"n\": 697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.45, \"learn_time_ms\": 10433.334}", "{\"n\": 698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 10426.407}", "{\"n\": 699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.55, \"learn_time_ms\": 10425.217}", "{\"n\": 700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 10421.422}", "{\"n\": 701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.49, \"learn_time_ms\": 10419.63}", "{\"n\": 702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.46, \"learn_time_ms\": 10430.533}", "{\"n\": 703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 10425.377}", "{\"n\": 704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.14, \"learn_time_ms\": 10408.048}", "{\"n\": 705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.95, \"learn_time_ms\": 10402.554}", "{\"n\": 706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.67, \"learn_time_ms\": 10388.346}", "{\"n\": 707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.71, \"learn_time_ms\": 10385.383}", "{\"n\": 708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.22, \"learn_time_ms\": 10386.018}", "{\"n\": 709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.44, \"learn_time_ms\": 10394.444}", "{\"n\": 710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.33, \"learn_time_ms\": 10407.445}", "{\"n\": 711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34, \"learn_time_ms\": 10404.708}", "{\"n\": 712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.62, \"learn_time_ms\": 10396.297}", "{\"n\": 713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.62, \"learn_time_ms\": 10415.715}", "{\"n\": 714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.84, \"learn_time_ms\": 10426.013}", "{\"n\": 715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 10450.814}", "{\"n\": 716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 10461.505}", "{\"n\": 717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.51, \"learn_time_ms\": 10469.1}", "{\"n\": 718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.21, \"learn_time_ms\": 10469.343}", "{\"n\": 719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 10466.29}", "{\"n\": 720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 10476.394}", "{\"n\": 721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.84, \"learn_time_ms\": 10478.456}", "{\"n\": 722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 10497.596}", "{\"n\": 723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.85, \"learn_time_ms\": 10478.379}", "{\"n\": 724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 10479.53}", "{\"n\": 725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.42, \"learn_time_ms\": 10472.133}", "{\"n\": 726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.55, \"learn_time_ms\": 10472.152}", "{\"n\": 727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.39, \"learn_time_ms\": 10474.74}", "{\"n\": 728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 10477.696}", "{\"n\": 729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.7, \"learn_time_ms\": 10482.624}", "{\"n\": 730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.57, \"learn_time_ms\": 10445.417}", "{\"n\": 731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 10456.776}", "{\"n\": 732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 10432.817}", "{\"n\": 733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 10441.288}", "{\"n\": 734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 10451.876}", "{\"n\": 735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 10439.247}", "{\"n\": 736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 10441.085}", "{\"n\": 737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 10438.79}", "{\"n\": 738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 10446.419}", "{\"n\": 739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.3, \"learn_time_ms\": 10452.62}", "{\"n\": 740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.08, \"learn_time_ms\": 10459.404}", "{\"n\": 741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.54, \"learn_time_ms\": 10453.362}", "{\"n\": 742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 10475.372}", "{\"n\": 743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.62, \"learn_time_ms\": 10478.92}", "{\"n\": 744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.23, \"learn_time_ms\": 10483.396}", "{\"n\": 745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 10483.711}", "{\"n\": 746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 10485.248}", "{\"n\": 747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 10482.577}", "{\"n\": 748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 10475.046}", "{\"n\": 749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.73, \"learn_time_ms\": 10462.362}", "{\"n\": 750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.78, \"learn_time_ms\": 10464.386}", "{\"n\": 751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.06, \"learn_time_ms\": 10457.764}", "{\"n\": 752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.52, \"learn_time_ms\": 10438.988}", "{\"n\": 753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.12, \"learn_time_ms\": 10432.917}", "{\"n\": 754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.36, \"learn_time_ms\": 10426.913}", "{\"n\": 755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.11, \"learn_time_ms\": 10429.783}", "{\"n\": 756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.92, \"learn_time_ms\": 10431.927}", "{\"n\": 757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.79, \"learn_time_ms\": 10429.179}", "{\"n\": 758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.82, \"learn_time_ms\": 10427.263}", "{\"n\": 759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.99, \"learn_time_ms\": 10425.512}", "{\"n\": 760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 10433.856}", "{\"n\": 761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 10436.699}", "{\"n\": 762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.17, \"learn_time_ms\": 10435.795}", "{\"n\": 763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.37, \"learn_time_ms\": 10430.214}", "{\"n\": 764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.16, \"learn_time_ms\": 10424.063}", "{\"n\": 765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.32, \"learn_time_ms\": 10429.506}", "{\"n\": 766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.33, \"learn_time_ms\": 10422.459}", "{\"n\": 767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.6, \"learn_time_ms\": 10426.368}", "{\"n\": 768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.36, \"learn_time_ms\": 10424.711}", "{\"n\": 769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.43, \"learn_time_ms\": 10425.069}", "{\"n\": 770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.49, \"learn_time_ms\": 10410.885}", "{\"n\": 771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 10413.111}", "{\"n\": 772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 10406.631}", "{\"n\": 773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.19, \"learn_time_ms\": 10405.337}", "{\"n\": 774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 10403.521}", "{\"n\": 775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.55, \"learn_time_ms\": 10400.09}", "{\"n\": 776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.66, \"learn_time_ms\": 10397.31}", "{\"n\": 777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 10398.39}", "{\"n\": 778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 10406.844}", "{\"n\": 779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 10414.431}", "{\"n\": 780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.15, \"learn_time_ms\": 10423.812}", "{\"n\": 781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.86, \"learn_time_ms\": 10434.189}", "{\"n\": 782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.81, \"learn_time_ms\": 10440.597}", "{\"n\": 783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.77, \"learn_time_ms\": 10447.848}", "{\"n\": 784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.76, \"learn_time_ms\": 10446.942}", "{\"n\": 785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.06, \"learn_time_ms\": 10445.748}", "{\"n\": 786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.31, \"learn_time_ms\": 10446.714}", "{\"n\": 787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.96, \"learn_time_ms\": 10442.849}", "{\"n\": 788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.09, \"learn_time_ms\": 10427.362}", "{\"n\": 789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.22, \"learn_time_ms\": 10415.701}", "{\"n\": 790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.12, \"learn_time_ms\": 10410.221}", "{\"n\": 791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.84, \"learn_time_ms\": 10391.634}", "{\"n\": 792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.42, \"learn_time_ms\": 10387.007}", "{\"n\": 793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.19, \"learn_time_ms\": 10380.736}", "{\"n\": 794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.18, \"learn_time_ms\": 10373.293}", "{\"n\": 795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.71, \"learn_time_ms\": 10375.277}", "{\"n\": 796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.05, \"learn_time_ms\": 10366.945}", "{\"n\": 797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5, \"learn_time_ms\": 10361.957}", "{\"n\": 798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.57, \"learn_time_ms\": 10369.545}", "{\"n\": 799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.59, \"learn_time_ms\": 10377.922}", "{\"n\": 800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 10383.854}", "{\"n\": 801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.45, \"learn_time_ms\": 10392.115}", "{\"n\": 802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.87, \"learn_time_ms\": 10391.762}", "{\"n\": 803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.57, \"learn_time_ms\": 10396.006}", "{\"n\": 804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 10404.644}", "{\"n\": 805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 10400.732}", "{\"n\": 806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.73, \"learn_time_ms\": 10405.321}", "{\"n\": 807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 10409.763}", "{\"n\": 808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.14, \"learn_time_ms\": 10407.122}", "{\"n\": 809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.26, \"learn_time_ms\": 10410.53}", "{\"n\": 810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.63, \"learn_time_ms\": 10406.888}", "{\"n\": 811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.61, \"learn_time_ms\": 10408.009}", "{\"n\": 812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.76, \"learn_time_ms\": 10408.947}", "{\"n\": 813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.77, \"learn_time_ms\": 10404.831}", "{\"n\": 814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.19, \"learn_time_ms\": 10402.323}", "{\"n\": 815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.06, \"learn_time_ms\": 10396.554}", "{\"n\": 816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.89, \"learn_time_ms\": 10390.814}", "{\"n\": 817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.93, \"learn_time_ms\": 10388.64}", "{\"n\": 818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.39, \"learn_time_ms\": 10392.274}", "{\"n\": 819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.51, \"learn_time_ms\": 10381.79}", "{\"n\": 820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.08, \"learn_time_ms\": 10382.191}", "{\"n\": 821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 10382.814}", "{\"n\": 822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 10392.77}", "{\"n\": 823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 10397.007}", "{\"n\": 824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 10417.41}", "{\"n\": 825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7, \"learn_time_ms\": 10422.459}", "{\"n\": 826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.79, \"learn_time_ms\": 10429.962}", "{\"n\": 827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 10433.412}", "{\"n\": 828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 10429.902}", "{\"n\": 829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 10433.236}", "{\"n\": 830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 10431.407}", "{\"n\": 831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 10431.0}", "{\"n\": 832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.3, \"learn_time_ms\": 10437.776}", "{\"n\": 833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.12, \"learn_time_ms\": 10435.132}", "{\"n\": 834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 10416.751}", "{\"n\": 835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.18, \"learn_time_ms\": 10416.866}", "{\"n\": 836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.37, \"learn_time_ms\": 10420.299}", "{\"n\": 837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 10416.085}", "{\"n\": 838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.46, \"learn_time_ms\": 10417.438}", "{\"n\": 839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 10422.784}", "{\"n\": 840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 10428.913}", "{\"n\": 841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.06, \"learn_time_ms\": 10423.62}", "{\"n\": 842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0, \"learn_time_ms\": 10405.375}", "{\"n\": 843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.12, \"learn_time_ms\": 10410.535}", "{\"n\": 844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.13, \"learn_time_ms\": 10410.181}", "{\"n\": 845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.74, \"learn_time_ms\": 10416.666}", "{\"n\": 846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 10413.384}", "{\"n\": 847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.03, \"learn_time_ms\": 10426.063}", "{\"n\": 848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.65, \"learn_time_ms\": 10431.081}", "{\"n\": 849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.54, \"learn_time_ms\": 10430.912}", "{\"n\": 850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 10426.741}", "{\"n\": 851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 10422.455}", "{\"n\": 852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.88, \"learn_time_ms\": 10439.058}", "{\"n\": 853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.78, \"learn_time_ms\": 10434.89}", "{\"n\": 854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.73, \"learn_time_ms\": 10433.783}", "{\"n\": 855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.92, \"learn_time_ms\": 10436.532}", "{\"n\": 856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 10438.094}", "{\"n\": 857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.56, \"learn_time_ms\": 10439.057}", "{\"n\": 858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 10435.572}", "{\"n\": 859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.82, \"learn_time_ms\": 10435.605}", "{\"n\": 860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.07, \"learn_time_ms\": 10443.41}", "{\"n\": 861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 10453.749}", "{\"n\": 862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.31, \"learn_time_ms\": 10440.689}", "{\"n\": 863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.59, \"learn_time_ms\": 10452.693}", "{\"n\": 864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.67, \"learn_time_ms\": 10457.401}", "{\"n\": 865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34, \"learn_time_ms\": 10458.752}", "{\"n\": 866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 10451.519}", "{\"n\": 867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.56, \"learn_time_ms\": 10441.559}", "{\"n\": 868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 10439.107}", "{\"n\": 869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 10426.334}", "{\"n\": 870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.12, \"learn_time_ms\": 10425.942}", "{\"n\": 871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.56, \"learn_time_ms\": 10418.606}", "{\"n\": 872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.82, \"learn_time_ms\": 10416.821}", "{\"n\": 873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.08, \"learn_time_ms\": 10406.422}", "{\"n\": 874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.28, \"learn_time_ms\": 10404.966}", "{\"n\": 875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.85, \"learn_time_ms\": 10311.039}", "{\"n\": 876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.92, \"learn_time_ms\": 10317.049}", "{\"n\": 877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.16, \"learn_time_ms\": 10312.898}", "{\"n\": 878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.42, \"learn_time_ms\": 10310.172}", "{\"n\": 879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.12, \"learn_time_ms\": 10313.408}", "{\"n\": 880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 10324.985}", "{\"n\": 881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.73, \"learn_time_ms\": 10325.516}", "{\"n\": 882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1, \"learn_time_ms\": 10329.094}", "{\"n\": 883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.07, \"learn_time_ms\": 10332.3}", "{\"n\": 884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.04, \"learn_time_ms\": 10335.543}", "{\"n\": 885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.83, \"learn_time_ms\": 10425.631}", "{\"n\": 886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 10425.942}", "{\"n\": 887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.1, \"learn_time_ms\": 10432.28}", "{\"n\": 888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.88, \"learn_time_ms\": 10437.156}", "{\"n\": 889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.78, \"learn_time_ms\": 10451.151}", "{\"n\": 890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.99, \"learn_time_ms\": 10439.598}", "{\"n\": 891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.67, \"learn_time_ms\": 10437.677}", "{\"n\": 892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 10435.373}", "{\"n\": 893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.22, \"learn_time_ms\": 10427.708}", "{\"n\": 894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 10420.789}", "{\"n\": 895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 10413.165}", "{\"n\": 896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 10411.593}", "{\"n\": 897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.12, \"learn_time_ms\": 10410.433}", "{\"n\": 898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.58, \"learn_time_ms\": 10403.214}", "{\"n\": 899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 10390.941}", "{\"n\": 900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.77, \"learn_time_ms\": 10378.617}", "{\"n\": 901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 10524.677}", "{\"n\": 902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 10515.211}", "{\"n\": 903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 10515.514}", "{\"n\": 904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.86, \"learn_time_ms\": 10512.158}", "{\"n\": 905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.94, \"learn_time_ms\": 10517.129}", "{\"n\": 906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 10525.368}", "{\"n\": 907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 10547.091}", "{\"n\": 908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 10550.974}", "{\"n\": 909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.98, \"learn_time_ms\": 10557.715}", "{\"n\": 910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 10563.406}", "{\"n\": 911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 10416.877}", "{\"n\": 912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.72, \"learn_time_ms\": 10427.004}", "{\"n\": 913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 10427.794}", "{\"n\": 914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.81, \"learn_time_ms\": 10430.122}", "{\"n\": 915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 10426.808}", "{\"n\": 916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.92, \"learn_time_ms\": 10410.076}", "{\"n\": 917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.88, \"learn_time_ms\": 10385.49}", "{\"n\": 918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 10390.005}", "{\"n\": 919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 10387.44}", "{\"n\": 920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 10383.553}", "{\"n\": 921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.23, \"learn_time_ms\": 10380.112}", "{\"n\": 922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 10379.486}", "{\"n\": 923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.58, \"learn_time_ms\": 10388.486}", "{\"n\": 924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 10393.317}", "{\"n\": 925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.34, \"learn_time_ms\": 10389.344}", "{\"n\": 926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.13, \"learn_time_ms\": 10391.742}", "{\"n\": 927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 10396.995}", "{\"n\": 928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.52, \"learn_time_ms\": 10398.197}", "{\"n\": 929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.21, \"learn_time_ms\": 10396.032}", "{\"n\": 930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.39, \"learn_time_ms\": 10409.966}", "{\"n\": 931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.73, \"learn_time_ms\": 10410.228}", "{\"n\": 932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.35, \"learn_time_ms\": 10408.443}", "{\"n\": 933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.27, \"learn_time_ms\": 10399.089}", "{\"n\": 934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.51, \"learn_time_ms\": 10392.052}", "{\"n\": 935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 10414.056}", "{\"n\": 936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.81, \"learn_time_ms\": 10413.765}", "{\"n\": 937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.16, \"learn_time_ms\": 10412.068}", "{\"n\": 938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 10406.465}", "{\"n\": 939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 10418.894}", "{\"n\": 940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.98, \"learn_time_ms\": 10406.626}", "{\"n\": 941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.9, \"learn_time_ms\": 10433.732}", "{\"n\": 942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.71, \"learn_time_ms\": 10441.259}", "{\"n\": 943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 10446.001}", "{\"n\": 944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.47, \"learn_time_ms\": 10445.616}", "{\"n\": 945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.88, \"learn_time_ms\": 10442.858}", "{\"n\": 946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.85, \"learn_time_ms\": 10451.519}", "{\"n\": 947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 10463.4}", "{\"n\": 948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.03, \"learn_time_ms\": 10471.466}", "{\"n\": 949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.12, \"learn_time_ms\": 10461.863}", "{\"n\": 950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 10478.415}", "{\"n\": 951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 10460.698}", "{\"n\": 952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.02, \"learn_time_ms\": 10459.98}", "{\"n\": 953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 10461.357}", "{\"n\": 954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.12, \"learn_time_ms\": 10467.842}", "{\"n\": 955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.83, \"learn_time_ms\": 10452.563}", "{\"n\": 956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.97, \"learn_time_ms\": 10454.752}", "{\"n\": 957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.92, \"learn_time_ms\": 10447.614}", "{\"n\": 958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.59, \"learn_time_ms\": 10445.641}", "{\"n\": 959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.43, \"learn_time_ms\": 10472.376}", "{\"n\": 960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 10480.96}", "{\"n\": 961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.63, \"learn_time_ms\": 10494.923}", "{\"n\": 962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.37, \"learn_time_ms\": 10528.015}", "{\"n\": 963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.39, \"learn_time_ms\": 10535.611}", "{\"n\": 964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 10561.954}", "{\"n\": 965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 10582.207}", "{\"n\": 966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.42, \"learn_time_ms\": 10581.568}", "{\"n\": 967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.48, \"learn_time_ms\": 10597.1}", "{\"n\": 968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.3, \"learn_time_ms\": 10599.604}", "{\"n\": 969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.17, \"learn_time_ms\": 10581.165}", "{\"n\": 970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.99, \"learn_time_ms\": 10570.312}", "{\"n\": 971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.31, \"learn_time_ms\": 10560.515}", "{\"n\": 972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.23, \"learn_time_ms\": 10521.068}", "{\"n\": 973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.88, \"learn_time_ms\": 10502.939}", "{\"n\": 974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.13, \"learn_time_ms\": 10475.663}", "{\"n\": 975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.12, \"learn_time_ms\": 10463.591}", "{\"n\": 976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.8, \"learn_time_ms\": 10455.151}", "{\"n\": 977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.08, \"learn_time_ms\": 10424.735}", "{\"n\": 978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.14, \"learn_time_ms\": 10414.638}", "{\"n\": 979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.71, \"learn_time_ms\": 10406.213}", "{\"n\": 980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.6, \"learn_time_ms\": 10402.19}", "{\"n\": 981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.79, \"learn_time_ms\": 10389.317}", "{\"n\": 982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 10396.228}", "{\"n\": 983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.95, \"learn_time_ms\": 10412.844}", "{\"n\": 984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 10405.747}", "{\"n\": 985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 10403.553}", "{\"n\": 986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 10419.388}", "{\"n\": 987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.19, \"learn_time_ms\": 10438.843}", "{\"n\": 988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 10439.897}", "{\"n\": 989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 10460.913}", "{\"n\": 990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 10470.967}", "{\"n\": 991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 10477.577}", "{\"n\": 992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 10482.596}", "{\"n\": 993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2, \"learn_time_ms\": 10477.52}", "{\"n\": 994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 10485.547}", "{\"n\": 995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.56, \"learn_time_ms\": 10490.412}", "{\"n\": 996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 10477.027}", "{\"n\": 997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 10479.917}", "{\"n\": 998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7, \"learn_time_ms\": 10483.529}", "{\"n\": 999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.54, \"learn_time_ms\": 10462.616}", "{\"n\": 1000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.19, \"learn_time_ms\": 10466.727}"]["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 48755.117}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 37089.61}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 33050.813}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1036.75, \"learn_time_ms\": 31145.671}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1036.75, \"learn_time_ms\": 30005.702}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1077.9375, \"learn_time_ms\": 29250.353}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88235294117647, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1074.1764705882354, \"learn_time_ms\": 28711.569}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.833333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1087.2083333333333, \"learn_time_ms\": 28296.561}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.862068965517242, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1086.6206896551723, \"learn_time_ms\": 27986.886}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8125, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1088.15625, \"learn_time_ms\": 27731.331}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.789473684210527, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1090.8947368421052, \"learn_time_ms\": 25396.927}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1098.55, \"learn_time_ms\": 25402.698}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.80851063829787, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1100.659574468085, \"learn_time_ms\": 25402.815}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.816326530612244, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1100.6938775510205, \"learn_time_ms\": 25406.66}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1101.2181818181818, \"learn_time_ms\": 25409.916}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79310344827586, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1102.2413793103449, \"learn_time_ms\": 25407.4}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77777777777778, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1104.904761904762, \"learn_time_ms\": 25405.715}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.776119402985074, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1104.8955223880596, \"learn_time_ms\": 25416.806}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.746478873239436, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1107.3098591549297, \"learn_time_ms\": 25411.925}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1106.6184210526317, \"learn_time_ms\": 25415.857}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1107.8125, \"learn_time_ms\": 25418.912}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75581395348837, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1106.6744186046512, \"learn_time_ms\": 25418.696}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.761363636363637, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1105.9886363636363, \"learn_time_ms\": 25466.382}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.768421052631577, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1105.778947368421, \"learn_time_ms\": 25467.809}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.755102040816325, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1105.9795918367347, \"learn_time_ms\": 25464.545}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1109.12, \"learn_time_ms\": 25468.415}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1112.0, \"learn_time_ms\": 25452.737}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1112.29, \"learn_time_ms\": 25455.22}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.72, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1112.34, \"learn_time_ms\": 25462.199}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1115.61, \"learn_time_ms\": 25460.724}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1115.92, \"learn_time_ms\": 25466.91}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.76, \"learn_time_ms\": 25465.245}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.35, \"learn_time_ms\": 25470.828}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.33, \"learn_time_ms\": 25468.896}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1114.97, \"learn_time_ms\": 25468.784}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.45, \"learn_time_ms\": 25468.302}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.28, \"learn_time_ms\": 25485.414}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1123.09, \"learn_time_ms\": 25480.128}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.05, \"learn_time_ms\": 25469.719}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.95, \"learn_time_ms\": 25469.858}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.16, \"learn_time_ms\": 25470.552}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.38, \"learn_time_ms\": 25474.094}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.61, \"learn_time_ms\": 25473.091}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.42, \"learn_time_ms\": 25477.704}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1122.06, \"learn_time_ms\": 25483.206}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.4, \"learn_time_ms\": 25485.819}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1123.53, \"learn_time_ms\": 25479.509}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.9, \"learn_time_ms\": 25474.727}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.34, \"learn_time_ms\": 25480.5}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.3, \"learn_time_ms\": 25482.282}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1122.41, \"learn_time_ms\": 25480.304}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1123.95, \"learn_time_ms\": 25472.488}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.93, \"learn_time_ms\": 25461.227}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.69, \"learn_time_ms\": 25455.805}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.28, \"learn_time_ms\": 25459.311}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.37, \"learn_time_ms\": 25456.457}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.52, \"learn_time_ms\": 25461.416}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.01, \"learn_time_ms\": 25466.331}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1115.03, \"learn_time_ms\": 25469.743}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1115.22, \"learn_time_ms\": 25476.122}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1113.9, \"learn_time_ms\": 25477.408}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1116.01, \"learn_time_ms\": 25480.147}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.44, \"learn_time_ms\": 25482.52}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1117.29, \"learn_time_ms\": 25476.367}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.18, \"learn_time_ms\": 25468.352}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.95, \"learn_time_ms\": 25466.423}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.02, \"learn_time_ms\": 25461.2}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.51, \"learn_time_ms\": 25455.347}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.89, \"learn_time_ms\": 25454.608}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.6, \"learn_time_ms\": 25450.554}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.12, \"learn_time_ms\": 25447.219}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.72, \"learn_time_ms\": 25427.944}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1122.05, \"learn_time_ms\": 25439.747}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.89, \"learn_time_ms\": 25336.848}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.72, \"learn_time_ms\": 25340.512}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1123.36, \"learn_time_ms\": 25333.712}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1126.05, \"learn_time_ms\": 25342.438}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1124.42, \"learn_time_ms\": 25348.277}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1124.74, \"learn_time_ms\": 25347.227}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1126.7, \"learn_time_ms\": 25345.528}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1126.48, \"learn_time_ms\": 25344.736}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1126.08, \"learn_time_ms\": 25369.964}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1126.81, \"learn_time_ms\": 25366.912}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1127.81, \"learn_time_ms\": 25479.974}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1126.57, \"learn_time_ms\": 25483.04}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1126.93, \"learn_time_ms\": 25496.494}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1126.67, \"learn_time_ms\": 25494.952}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1123.68, \"learn_time_ms\": 25495.779}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.54, \"learn_time_ms\": 25495.903}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.8, \"learn_time_ms\": 25499.602}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.78, \"learn_time_ms\": 25460.267}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.57, \"learn_time_ms\": 25330.686}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1122.28, \"learn_time_ms\": 25319.205}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1123.18, \"learn_time_ms\": 25317.761}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.56, \"learn_time_ms\": 25315.056}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.06, \"learn_time_ms\": 25321.314}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.12, \"learn_time_ms\": 25324.013}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1116.23, \"learn_time_ms\": 25328.052}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1116.52, \"learn_time_ms\": 25329.997}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.13, \"learn_time_ms\": 25330.119}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.51, \"learn_time_ms\": 25370.989}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.67, \"learn_time_ms\": 25510.42}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.3, \"learn_time_ms\": 25531.866}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.99, \"learn_time_ms\": 25537.605}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.04, \"learn_time_ms\": 25537.766}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1118.93, \"learn_time_ms\": 25523.323}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.84, \"learn_time_ms\": 25451.067}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1122.16, \"learn_time_ms\": 25367.997}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.22, \"learn_time_ms\": 25362.679}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.4, \"learn_time_ms\": 25358.061}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.01, \"learn_time_ms\": 25343.01}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1119.97, \"learn_time_ms\": 25331.808}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.74, \"learn_time_ms\": 25321.307}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1121.79, \"learn_time_ms\": 25312.925}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1120.46, \"learn_time_ms\": 25324.247}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1122.02, \"learn_time_ms\": 25329.669}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1123.22, \"learn_time_ms\": 25400.662}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1125.34, \"learn_time_ms\": 25491.752}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1126.72, \"learn_time_ms\": 25487.679}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1128.66, \"learn_time_ms\": 25493.123}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1129.56, \"learn_time_ms\": 25510.682}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1131.32, \"learn_time_ms\": 25499.215}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1127.6, \"learn_time_ms\": 25503.737}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1129.55, \"learn_time_ms\": 25504.95}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1129.61, \"learn_time_ms\": 25492.277}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1129.51, \"learn_time_ms\": 25483.451}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1128.67, \"learn_time_ms\": 25476.2}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1130.97, \"learn_time_ms\": 25462.004}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1129.76, \"learn_time_ms\": 25467.574}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1131.18, \"learn_time_ms\": 25465.693}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1130.08, \"learn_time_ms\": 25461.632}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1128.35, \"learn_time_ms\": 25467.801}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1133.5, \"learn_time_ms\": 25460.777}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1137.55, \"learn_time_ms\": 25464.3}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1138.5, \"learn_time_ms\": 25455.973}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1136.72, \"learn_time_ms\": 25453.567}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1136.33, \"learn_time_ms\": 25455.448}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1136.44, \"learn_time_ms\": 25467.323}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1136.05, \"learn_time_ms\": 25478.843}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1135.48, \"learn_time_ms\": 25481.155}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1137.28, \"learn_time_ms\": 25481.368}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1136.8, \"learn_time_ms\": 25479.274}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1135.8, \"learn_time_ms\": 25478.066}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1137.17, \"learn_time_ms\": 25477.842}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1133.62, \"learn_time_ms\": 25486.477}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1135.56, \"learn_time_ms\": 25493.38}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1134.96, \"learn_time_ms\": 25508.013}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1137.53, \"learn_time_ms\": 25498.426}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1142.75, \"learn_time_ms\": 25482.989}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1144.19, \"learn_time_ms\": 25483.491}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1143.54, \"learn_time_ms\": 25485.846}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1143.54, \"learn_time_ms\": 25489.153}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1145.75, \"learn_time_ms\": 25370.745}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1143.89, \"learn_time_ms\": 25368.189}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1144.59, \"learn_time_ms\": 25249.89}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1145.99, \"learn_time_ms\": 25247.717}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1142.54, \"learn_time_ms\": 25238.199}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1142.23, \"learn_time_ms\": 25222.395}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1142.1, \"learn_time_ms\": 25234.229}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1145.36, \"learn_time_ms\": 25221.806}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1146.27, \"learn_time_ms\": 25226.151}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1146.86, \"learn_time_ms\": 25234.483}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1149.51, \"learn_time_ms\": 25355.793}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1149.24, \"learn_time_ms\": 25359.595}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1147.76, \"learn_time_ms\": 25476.164}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1153.24, \"learn_time_ms\": 25474.408}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1149.55, \"learn_time_ms\": 25475.907}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1153.74, \"learn_time_ms\": 25505.174}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.46, \"learn_time_ms\": 25488.235}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.44, \"learn_time_ms\": 25498.73}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1158.53, \"learn_time_ms\": 25500.254}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1155.81, \"learn_time_ms\": 25489.719}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1153.4, \"learn_time_ms\": 25431.022}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1152.06, \"learn_time_ms\": 25371.4}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1152.79, \"learn_time_ms\": 25378.238}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1154.32, \"learn_time_ms\": 25388.874}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1154.64, \"learn_time_ms\": 25367.508}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1157.78, \"learn_time_ms\": 25355.285}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.48, \"learn_time_ms\": 25371.489}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1156.38, \"learn_time_ms\": 25353.72}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1159.48, \"learn_time_ms\": 25255.991}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1162.64, \"learn_time_ms\": 25265.29}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1163.93, \"learn_time_ms\": 25327.451}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1165.22, \"learn_time_ms\": 25381.217}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1164.71, \"learn_time_ms\": 25369.016}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1166.39, \"learn_time_ms\": 25366.825}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1167.13, \"learn_time_ms\": 25359.941}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1167.03, \"learn_time_ms\": 25363.209}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1170.16, \"learn_time_ms\": 25359.583}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1171.83, \"learn_time_ms\": 25380.625}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1172.28, \"learn_time_ms\": 25474.072}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1174.26, \"learn_time_ms\": 25467.312}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1171.26, \"learn_time_ms\": 25473.313}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1170.45, \"learn_time_ms\": 25482.759}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1168.63, \"learn_time_ms\": 25486.722}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1169.56, \"learn_time_ms\": 25490.305}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1167.71, \"learn_time_ms\": 25520.595}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1172.13, \"learn_time_ms\": 25525.396}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1176.29, \"learn_time_ms\": 25520.544}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1176.21, \"learn_time_ms\": 25518.205}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1178.16, \"learn_time_ms\": 25510.243}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1175.68, \"learn_time_ms\": 25502.725}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1178.99, \"learn_time_ms\": 25487.537}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1183.61, \"learn_time_ms\": 25482.718}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1182.59, \"learn_time_ms\": 25485.491}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1178.04, \"learn_time_ms\": 25485.775}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1179.93, \"learn_time_ms\": 25491.014}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1179.04, \"learn_time_ms\": 25490.845}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1177.54, \"learn_time_ms\": 25458.409}", "{\"n\": 210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1181.88, \"learn_time_ms\": 25440.495}", "{\"n\": 211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1181.65, \"learn_time_ms\": 25278.191}", "{\"n\": 212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1184.96, \"learn_time_ms\": 25282.023}", "{\"n\": 213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1187.74, \"learn_time_ms\": 25292.246}", "{\"n\": 214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1184.6, \"learn_time_ms\": 25289.063}", "{\"n\": 215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.35, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1188.51, \"learn_time_ms\": 25290.101}", "{\"n\": 216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.35, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1191.08, \"learn_time_ms\": 25289.732}", "{\"n\": 217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.35, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1188.61, \"learn_time_ms\": 25255.975}", "{\"n\": 218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.31, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1194.34, \"learn_time_ms\": 25212.94}", "{\"n\": 219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.31, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1194.33, \"learn_time_ms\": 25122.494}", "{\"n\": 220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1202.45, \"learn_time_ms\": 25078.934}", "{\"n\": 221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1206.09, \"learn_time_ms\": 25207.579}", "{\"n\": 222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.26, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1205.15, \"learn_time_ms\": 25188.458}", "{\"n\": 223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1203.98, \"learn_time_ms\": 25156.316}", "{\"n\": 224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1201.38, \"learn_time_ms\": 25092.962}", "{\"n\": 225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1209.31, \"learn_time_ms\": 25088.54}", "{\"n\": 226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1213.19, \"learn_time_ms\": 25055.154}", "{\"n\": 227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1213.52, \"learn_time_ms\": 25018.711}", "{\"n\": 228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1213.55, \"learn_time_ms\": 25030.344}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1212.14, \"learn_time_ms\": 25139.48}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.21, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1211.65, \"learn_time_ms\": 25184.997}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1215.83, \"learn_time_ms\": 25213.851}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1218.13, \"learn_time_ms\": 25222.797}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1223.18, \"learn_time_ms\": 25217.64}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1225.5, \"learn_time_ms\": 25262.111}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1235.84, \"learn_time_ms\": 25246.386}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1239.04, \"learn_time_ms\": 25259.777}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.18, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1244.26, \"learn_time_ms\": 25301.503}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.18, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1242.37, \"learn_time_ms\": 25298.981}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1242.43, \"learn_time_ms\": 25304.788}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1245.32, \"learn_time_ms\": 25255.137}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1250.6, \"learn_time_ms\": 25229.271}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1249.79, \"learn_time_ms\": 25207.104}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1254.43, \"learn_time_ms\": 25185.669}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1253.03, \"learn_time_ms\": 25207.319}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1252.1, \"learn_time_ms\": 25228.911}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1253.58, \"learn_time_ms\": 25246.992}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1254.36, \"learn_time_ms\": 25257.25}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1253.5, \"learn_time_ms\": 25281.383}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.09, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1256.73, \"learn_time_ms\": 25289.781}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1265.97, \"learn_time_ms\": 25349.529}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1262.3, \"learn_time_ms\": 25388.987}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1261.42, \"learn_time_ms\": 25426.879}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.04, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1265.46, \"learn_time_ms\": 25480.351}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.02, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1271.48, \"learn_time_ms\": 25477.018}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1274.25, \"learn_time_ms\": 25452.144}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.06, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1279.73, \"learn_time_ms\": 25451.362}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.06, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1278.12, \"learn_time_ms\": 25455.518}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.04, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1282.5, \"learn_time_ms\": 25444.525}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.04, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1282.58, \"learn_time_ms\": 25448.854}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.02, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1285.17, \"learn_time_ms\": 25455.342}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.98, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1290.2, \"learn_time_ms\": 25457.407}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.97, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1289.42, \"learn_time_ms\": 25440.169}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.94, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1293.98, \"learn_time_ms\": 25446.255}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1295.96, \"learn_time_ms\": 25457.197}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1302.93, \"learn_time_ms\": 25486.01}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.83, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1304.96, \"learn_time_ms\": 25486.435}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.85, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1308.79, \"learn_time_ms\": 25482.437}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1307.99, \"learn_time_ms\": 25492.329}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1310.88, \"learn_time_ms\": 25472.924}", "{\"n\": 270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1316.83, \"learn_time_ms\": 25469.007}", "{\"n\": 271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1326.0, \"learn_time_ms\": 25466.574}", "{\"n\": 272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1329.45, \"learn_time_ms\": 25486.001}", "{\"n\": 273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1331.71, \"learn_time_ms\": 25477.7}", "{\"n\": 274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1346.56, \"learn_time_ms\": 25442.684}", "{\"n\": 275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1349.86, \"learn_time_ms\": 25436.879}", "{\"n\": 276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1362.16, \"learn_time_ms\": 25446.038}", "{\"n\": 277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1362.07, \"learn_time_ms\": 25462.443}", "{\"n\": 278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1363.23, \"learn_time_ms\": 25470.677}", "{\"n\": 279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1357.86, \"learn_time_ms\": 25462.936}", "{\"n\": 280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1357.47, \"learn_time_ms\": 25470.893}", "{\"n\": 281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.65, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1362.1, \"learn_time_ms\": 25474.192}", "{\"n\": 282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.61, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1368.24, \"learn_time_ms\": 25477.333}", "{\"n\": 283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.57, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1373.46, \"learn_time_ms\": 25485.783}", "{\"n\": 284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.52, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1379.13, \"learn_time_ms\": 25516.296}", "{\"n\": 285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1382.64, \"learn_time_ms\": 25513.808}", "{\"n\": 286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1386.51, \"learn_time_ms\": 25510.145}", "{\"n\": 287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1395.59, \"learn_time_ms\": 25479.577}", "{\"n\": 288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.38, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1398.31, \"learn_time_ms\": 25477.374}", "{\"n\": 289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.36, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1401.2, \"learn_time_ms\": 25499.524}", "{\"n\": 290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.37, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1403.69, \"learn_time_ms\": 25496.441}", "{\"n\": 291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.36, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1410.64, \"learn_time_ms\": 25500.402}", "{\"n\": 292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.37, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1409.76, \"learn_time_ms\": 25494.825}", "{\"n\": 293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1422.42, \"learn_time_ms\": 25492.366}", "{\"n\": 294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.32, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1420.66, \"learn_time_ms\": 25492.208}", "{\"n\": 295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1422.21, \"learn_time_ms\": 25502.269}", "{\"n\": 296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1433.53, \"learn_time_ms\": 25502.47}", "{\"n\": 297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1443.32, \"learn_time_ms\": 25531.399}", "{\"n\": 298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.09, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1458.88, \"learn_time_ms\": 25530.579}", "{\"n\": 299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.06, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1462.82, \"learn_time_ms\": 25539.36}", "{\"n\": 300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1469.07, \"learn_time_ms\": 25544.193}", "{\"n\": 301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1469.99, \"learn_time_ms\": 25542.62}", "{\"n\": 302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.06, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1472.21, \"learn_time_ms\": 25546.613}", "{\"n\": 303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1481.28, \"learn_time_ms\": 25551.52}", "{\"n\": 304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1489.03, \"learn_time_ms\": 25553.632}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1490.56, \"learn_time_ms\": 25546.968}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.92, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1491.53, \"learn_time_ms\": 25545.15}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1494.95, \"learn_time_ms\": 25548.641}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.89, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1496.69, \"learn_time_ms\": 25548.564}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.89, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1501.53, \"learn_time_ms\": 25541.189}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1504.5, \"learn_time_ms\": 25493.907}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1527.02, \"learn_time_ms\": 25404.782}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1528.89, \"learn_time_ms\": 25367.514}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.79, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1538.16, \"learn_time_ms\": 25309.316}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.79, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1543.43, \"learn_time_ms\": 25309.031}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1543.17, \"learn_time_ms\": 25324.458}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1553.11, \"learn_time_ms\": 25325.133}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1557.89, \"learn_time_ms\": 25316.913}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1560.81, \"learn_time_ms\": 25319.337}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1561.03, \"learn_time_ms\": 25327.804}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1562.13, \"learn_time_ms\": 25380.616}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1567.34, \"learn_time_ms\": 25464.391}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1575.42, \"learn_time_ms\": 25507.164}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1578.18, \"learn_time_ms\": 25560.677}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1583.67, \"learn_time_ms\": 25565.112}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1583.1, \"learn_time_ms\": 25558.262}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1587.45, \"learn_time_ms\": 25560.926}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1588.19, \"learn_time_ms\": 25565.772}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1588.19, \"learn_time_ms\": 25565.504}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1592.38, \"learn_time_ms\": 25523.72}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1597.13, \"learn_time_ms\": 25514.057}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1596.29, \"learn_time_ms\": 25520.312}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1600.12, \"learn_time_ms\": 25516.186}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1602.11, \"learn_time_ms\": 25512.672}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.89, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1598.53, \"learn_time_ms\": 25506.879}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1596.73, \"learn_time_ms\": 25500.854}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.88, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1602.98, \"learn_time_ms\": 25499.361}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.88, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1604.55, \"learn_time_ms\": 25501.67}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1607.79, \"learn_time_ms\": 25498.215}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1612.84, \"learn_time_ms\": 25536.094}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1614.83, \"learn_time_ms\": 25539.414}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1621.62, \"learn_time_ms\": 25534.151}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1621.46, \"learn_time_ms\": 25539.769}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1625.4, \"learn_time_ms\": 25550.57}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1627.44, \"learn_time_ms\": 25551.967}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1628.01, \"learn_time_ms\": 25530.109}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.83, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1627.35, \"learn_time_ms\": 25529.772}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1624.23, \"learn_time_ms\": 25531.682}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.8, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1634.84, \"learn_time_ms\": 25527.715}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1629.27, \"learn_time_ms\": 25527.414}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.75, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1635.38, \"learn_time_ms\": 25515.625}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1635.36, \"learn_time_ms\": 25522.415}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1651.78, \"learn_time_ms\": 25522.235}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1650.9, \"learn_time_ms\": 25520.031}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1654.54, \"learn_time_ms\": 25524.622}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1654.78, \"learn_time_ms\": 25553.494}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1658.99, \"learn_time_ms\": 25550.557}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1658.35, \"learn_time_ms\": 25540.096}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1663.25, \"learn_time_ms\": 25557.969}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1660.79, \"learn_time_ms\": 25564.35}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1662.4, \"learn_time_ms\": 25580.713}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1659.82, \"learn_time_ms\": 25581.373}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1662.21, \"learn_time_ms\": 25575.052}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.79, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1661.04, \"learn_time_ms\": 25546.547}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1663.05, \"learn_time_ms\": 25546.219}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.82, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1662.04, \"learn_time_ms\": 25538.356}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1670.03, \"learn_time_ms\": 25543.689}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1674.41, \"learn_time_ms\": 25528.49}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1675.79, \"learn_time_ms\": 25512.475}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1675.43, \"learn_time_ms\": 25509.451}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1686.66, \"learn_time_ms\": 25503.446}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.8, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1680.59, \"learn_time_ms\": 25500.156}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.75, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1689.28, \"learn_time_ms\": 25503.002}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1693.69, \"learn_time_ms\": 25524.573}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1689.46, \"learn_time_ms\": 25523.495}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1687.27, \"learn_time_ms\": 25527.062}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.75, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1688.41, \"learn_time_ms\": 25524.425}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1688.97, \"learn_time_ms\": 25544.664}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1700.04, \"learn_time_ms\": 25513.683}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1700.04, \"learn_time_ms\": 25511.124}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.75, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1705.66, \"learn_time_ms\": 25504.421}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1706.31, \"learn_time_ms\": 25502.779}", "{\"n\": 382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1706.61, \"learn_time_ms\": 25507.572}", "{\"n\": 383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1712.03, \"learn_time_ms\": 25493.58}", "{\"n\": 384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1712.53, \"learn_time_ms\": 25493.22}", "{\"n\": 385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1721.3, \"learn_time_ms\": 25492.356}", "{\"n\": 386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1718.58, \"learn_time_ms\": 25493.424}", "{\"n\": 387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1723.48, \"learn_time_ms\": 25496.774}", "{\"n\": 388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1723.03, \"learn_time_ms\": 25535.279}", "{\"n\": 389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.64, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1726.65, \"learn_time_ms\": 25534.35}", "{\"n\": 390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.61, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1738.46, \"learn_time_ms\": 25528.934}", "{\"n\": 391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1743.18, \"learn_time_ms\": 25537.535}", "{\"n\": 392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1740.86, \"learn_time_ms\": 25413.663}", "{\"n\": 393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.54, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1743.79, \"learn_time_ms\": 25425.245}", "{\"n\": 394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.54, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1743.59, \"learn_time_ms\": 25349.871}", "{\"n\": 395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1743.45, \"learn_time_ms\": 25331.09}", "{\"n\": 396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1750.13, \"learn_time_ms\": 25313.072}", "{\"n\": 397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1763.8, \"learn_time_ms\": 25275.511}", "{\"n\": 398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.46, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1764.74, \"learn_time_ms\": 25277.199}", "{\"n\": 399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.49, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1765.31, \"learn_time_ms\": 25280.043}", "{\"n\": 400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1766.38, \"learn_time_ms\": 25291.792}", "{\"n\": 401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1765.42, \"learn_time_ms\": 25274.312}", "{\"n\": 402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1778.16, \"learn_time_ms\": 25394.004}", "{\"n\": 403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1776.21, \"learn_time_ms\": 25363.459}", "{\"n\": 404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.48, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1772.41, \"learn_time_ms\": 25435.806}", "{\"n\": 405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1781.74, \"learn_time_ms\": 25454.644}", "{\"n\": 406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1790.25, \"learn_time_ms\": 25469.994}", "{\"n\": 407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1798.24, \"learn_time_ms\": 25499.208}", "{\"n\": 408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1812.03, \"learn_time_ms\": 25494.337}", "{\"n\": 409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1820.45, \"learn_time_ms\": 25496.67}", "{\"n\": 410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1820.45, \"learn_time_ms\": 25497.763}", "{\"n\": 411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1823.14, \"learn_time_ms\": 25503.582}", "{\"n\": 412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1826.33, \"learn_time_ms\": 25500.132}", "{\"n\": 413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.29, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1829.83, \"learn_time_ms\": 25542.661}", "{\"n\": 414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1836.68, \"learn_time_ms\": 25541.139}", "{\"n\": 415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1841.26, \"learn_time_ms\": 25543.61}", "{\"n\": 416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1840.14, \"learn_time_ms\": 25543.894}", "{\"n\": 417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1838.09, \"learn_time_ms\": 25554.189}", "{\"n\": 418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.25, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1847.79, \"learn_time_ms\": 25557.788}", "{\"n\": 419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1844.74, \"learn_time_ms\": 25548.058}", "{\"n\": 420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1845.19, \"learn_time_ms\": 25536.12}", "{\"n\": 421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.32, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1837.45, \"learn_time_ms\": 25538.852}", "{\"n\": 422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.32, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1838.53, \"learn_time_ms\": 25546.092}", "{\"n\": 423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1834.63, \"learn_time_ms\": 25543.535}", "{\"n\": 424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1841.49, \"learn_time_ms\": 25535.578}", "{\"n\": 425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1839.51, \"learn_time_ms\": 25531.339}", "{\"n\": 426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1835.58, \"learn_time_ms\": 25531.495}", "{\"n\": 427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1832.36, \"learn_time_ms\": 25527.954}", "{\"n\": 428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.45, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1832.93, \"learn_time_ms\": 25524.423}", "{\"n\": 429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.46, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1832.09, \"learn_time_ms\": 25533.409}", "{\"n\": 430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1831.36, \"learn_time_ms\": 25546.28}", "{\"n\": 431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1831.1, \"learn_time_ms\": 25551.521}", "{\"n\": 432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.46, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1832.32, \"learn_time_ms\": 25536.575}", "{\"n\": 433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.42, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1838.9, \"learn_time_ms\": 25537.471}", "{\"n\": 434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1833.4, \"learn_time_ms\": 25554.756}", "{\"n\": 435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1827.91, \"learn_time_ms\": 25556.08}", "{\"n\": 436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1826.84, \"learn_time_ms\": 25553.222}", "{\"n\": 437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1834.5, \"learn_time_ms\": 25543.69}", "{\"n\": 438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1834.7, \"learn_time_ms\": 25545.636}", "{\"n\": 439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1843.23, \"learn_time_ms\": 25533.222}", "{\"n\": 440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1845.27, \"learn_time_ms\": 25529.633}", "{\"n\": 441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1845.27, \"learn_time_ms\": 25517.178}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1833.01, \"learn_time_ms\": 25526.446}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.45, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1831.78, \"learn_time_ms\": 25523.731}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.45, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1831.63, \"learn_time_ms\": 25516.623}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.49, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1821.96, \"learn_time_ms\": 25525.696}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.52, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1819.38, \"learn_time_ms\": 25526.836}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1816.75, \"learn_time_ms\": 25542.389}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.54, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1816.65, \"learn_time_ms\": 25550.745}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1814.04, \"learn_time_ms\": 25560.166}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1815.23, \"learn_time_ms\": 25558.682}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.63, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1816.9, \"learn_time_ms\": 25566.362}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1821.8, \"learn_time_ms\": 25549.313}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1826.61, \"learn_time_ms\": 25550.873}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1827.41, \"learn_time_ms\": 25547.263}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.54, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1831.22, \"learn_time_ms\": 25543.398}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1830.79, \"learn_time_ms\": 25551.524}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1834.52, \"learn_time_ms\": 25536.454}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1836.66, \"learn_time_ms\": 25529.535}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1843.37, \"learn_time_ms\": 25526.909}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1849.98, \"learn_time_ms\": 25530.401}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1853.59, \"learn_time_ms\": 25536.306}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1862.91, \"learn_time_ms\": 25532.358}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.32, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1861.45, \"learn_time_ms\": 25514.604}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1864.41, \"learn_time_ms\": 25502.734}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1870.45, \"learn_time_ms\": 25503.832}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1874.56, \"learn_time_ms\": 25497.556}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1873.66, \"learn_time_ms\": 25501.697}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1875.05, \"learn_time_ms\": 25499.077}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1875.69, \"learn_time_ms\": 25318.045}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1889.83, \"learn_time_ms\": 25312.534}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1894.83, \"learn_time_ms\": 25295.25}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1895.5, \"learn_time_ms\": 25310.636}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1899.45, \"learn_time_ms\": 25325.917}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.14, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1913.43, \"learn_time_ms\": 25335.102}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1911.36, \"learn_time_ms\": 25303.725}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1909.19, \"learn_time_ms\": 25304.468}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1911.47, \"learn_time_ms\": 25312.497}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1915.29, \"learn_time_ms\": 25311.422}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1916.33, \"learn_time_ms\": 25501.743}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1915.85, \"learn_time_ms\": 25506.609}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1915.85, \"learn_time_ms\": 25521.125}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1920.53, \"learn_time_ms\": 25531.859}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.04, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1936.09, \"learn_time_ms\": 25527.083}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.06, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1935.5, \"learn_time_ms\": 25533.194}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.04, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1940.76, \"learn_time_ms\": 25566.817}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1942.62, \"learn_time_ms\": 25571.321}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1947.68, \"learn_time_ms\": 25570.759}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1948.39, \"learn_time_ms\": 25573.76}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1955.9, \"learn_time_ms\": 25571.25}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1962.04, \"learn_time_ms\": 25484.683}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1974.1, \"learn_time_ms\": 25470.795}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1971.48, \"learn_time_ms\": 25457.139}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1966.17, \"learn_time_ms\": 25458.149}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1970.61, \"learn_time_ms\": 25456.013}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1972.18, \"learn_time_ms\": 25451.308}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1980.45, \"learn_time_ms\": 25448.731}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1973.39, \"learn_time_ms\": 25436.872}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1972.27, \"learn_time_ms\": 25435.205}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1982.94, \"learn_time_ms\": 25440.905}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.92, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1986.11, \"learn_time_ms\": 25527.801}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.89, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1986.66, \"learn_time_ms\": 25538.619}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1978.58, \"learn_time_ms\": 25542.993}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1981.45, \"learn_time_ms\": 25514.355}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1975.31, \"learn_time_ms\": 25499.608}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1972.02, \"learn_time_ms\": 25478.758}", "{\"n\": 506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1974.54, \"learn_time_ms\": 25459.974}", "{\"n\": 507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1977.1, \"learn_time_ms\": 25478.35}", "{\"n\": 508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1979.65, \"learn_time_ms\": 25475.588}", "{\"n\": 509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1979.65, \"learn_time_ms\": 25447.865}", "{\"n\": 510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1993.07, \"learn_time_ms\": 25448.751}", "{\"n\": 511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1988.8, \"learn_time_ms\": 25452.519}", "{\"n\": 512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1995.64, \"learn_time_ms\": 25460.768}", "{\"n\": 513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1997.42, \"learn_time_ms\": 25492.509}", "{\"n\": 514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1994.13, \"learn_time_ms\": 25507.522}", "{\"n\": 515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1985.56, \"learn_time_ms\": 25531.353}", "{\"n\": 516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1985.04, \"learn_time_ms\": 25551.048}", "{\"n\": 517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1989.12, \"learn_time_ms\": 25530.264}", "{\"n\": 518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1997.3, \"learn_time_ms\": 25530.146}", "{\"n\": 519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.92, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1989.82, \"learn_time_ms\": 25557.705}", "{\"n\": 520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1984.96, \"learn_time_ms\": 25557.283}", "{\"n\": 521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.84, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1991.41, \"learn_time_ms\": 25556.9}", "{\"n\": 522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.84, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1994.53, \"learn_time_ms\": 25556.223}", "{\"n\": 523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.86, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1996.07, \"learn_time_ms\": 25562.694}", "{\"n\": 524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.87, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1989.59, \"learn_time_ms\": 25536.396}", "{\"n\": 525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.86, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1993.54, \"learn_time_ms\": 25535.161}", "{\"n\": 526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.88, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1996.03, \"learn_time_ms\": 25540.171}", "{\"n\": 527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1998.34, \"learn_time_ms\": 25534.027}", "{\"n\": 528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.89, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1997.5, \"learn_time_ms\": 25535.949}", "{\"n\": 529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.89, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1998.2, \"learn_time_ms\": 25519.961}", "{\"n\": 530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.84, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2004.38, \"learn_time_ms\": 25521.173}", "{\"n\": 531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.87, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2002.25, \"learn_time_ms\": 25517.578}", "{\"n\": 532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.86, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1997.92, \"learn_time_ms\": 25490.303}", "{\"n\": 533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.89, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1996.41, \"learn_time_ms\": 25491.53}", "{\"n\": 534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.84, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1999.8, \"learn_time_ms\": 25524.928}", "{\"n\": 535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.84, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2001.78, \"learn_time_ms\": 25521.892}", "{\"n\": 536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.81, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2002.16, \"learn_time_ms\": 25518.029}", "{\"n\": 537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.82, \"episode_reward_max\": -13.0, \"episode_len_mean\": 1997.69, \"learn_time_ms\": 25523.05}", "{\"n\": 538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2002.28, \"learn_time_ms\": 25527.976}", "{\"n\": 539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.83, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2009.66, \"learn_time_ms\": 25537.294}", "{\"n\": 540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2008.36, \"learn_time_ms\": 25536.466}", "{\"n\": 541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.82, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2008.87, \"learn_time_ms\": 25524.992}", "{\"n\": 542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.81, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2019.29, \"learn_time_ms\": 25550.932}", "{\"n\": 543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.82, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2022.5, \"learn_time_ms\": 25503.121}", "{\"n\": 544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.76, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2031.75, \"learn_time_ms\": 25500.641}", "{\"n\": 545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2046.12, \"learn_time_ms\": 25500.145}", "{\"n\": 546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2048.32, \"learn_time_ms\": 25502.631}", "{\"n\": 547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.72, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2051.26, \"learn_time_ms\": 25515.299}", "{\"n\": 548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.73, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2057.87, \"learn_time_ms\": 25514.676}", "{\"n\": 549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.69, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2062.17, \"learn_time_ms\": 25508.559}", "{\"n\": 550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.69, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2063.75, \"learn_time_ms\": 25508.453}", "{\"n\": 551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.69, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2063.75, \"learn_time_ms\": 25518.635}", "{\"n\": 552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2066.14, \"learn_time_ms\": 25513.071}", "{\"n\": 553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2065.81, \"learn_time_ms\": 25559.86}", "{\"n\": 554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2072.48, \"learn_time_ms\": 25561.538}", "{\"n\": 555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2076.81, \"learn_time_ms\": 25568.092}", "{\"n\": 556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2081.31, \"learn_time_ms\": 25515.924}", "{\"n\": 557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2086.13, \"learn_time_ms\": 25523.596}", "{\"n\": 558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2091.71, \"learn_time_ms\": 25528.466}", "{\"n\": 559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2097.0, \"learn_time_ms\": 25532.533}", "{\"n\": 560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2108.64, \"learn_time_ms\": 25535.084}", "{\"n\": 561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2104.72, \"learn_time_ms\": 25521.23}", "{\"n\": 562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2111.42, \"learn_time_ms\": 25530.522}", "{\"n\": 563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2125.14, \"learn_time_ms\": 25532.892}", "{\"n\": 564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2125.38, \"learn_time_ms\": 25539.072}", "{\"n\": 565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2131.49, \"learn_time_ms\": 25528.716}", "{\"n\": 566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2120.06, \"learn_time_ms\": 25577.094}", "{\"n\": 567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2122.43, \"learn_time_ms\": 25579.886}", "{\"n\": 568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2123.86, \"learn_time_ms\": 25577.344}", "{\"n\": 569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2124.68, \"learn_time_ms\": 25580.988}", "{\"n\": 570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2124.6, \"learn_time_ms\": 25579.633}", "{\"n\": 571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2125.08, \"learn_time_ms\": 25589.036}", "{\"n\": 572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2127.71, \"learn_time_ms\": 25587.624}", "{\"n\": 573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.51, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2129.23, \"learn_time_ms\": 25586.318}", "{\"n\": 574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2131.59, \"learn_time_ms\": 25576.382}", "{\"n\": 575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.5, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2131.59, \"learn_time_ms\": 25586.333}", "{\"n\": 576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.51, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2140.76, \"learn_time_ms\": 25590.314}", "{\"n\": 577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2144.46, \"learn_time_ms\": 25578.444}", "{\"n\": 578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.44, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2153.29, \"learn_time_ms\": 25580.482}", "{\"n\": 579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2152.86, \"learn_time_ms\": 25575.048}", "{\"n\": 580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2143.87, \"learn_time_ms\": 25570.954}", "{\"n\": 581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2149.56, \"learn_time_ms\": 25574.379}", "{\"n\": 582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2149.91, \"learn_time_ms\": 25574.266}", "{\"n\": 583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2145.61, \"learn_time_ms\": 25567.907}", "{\"n\": 584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2143.02, \"learn_time_ms\": 25565.049}", "{\"n\": 585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2144.21, \"learn_time_ms\": 25540.886}", "{\"n\": 586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2142.08, \"learn_time_ms\": 25518.989}", "{\"n\": 587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2142.08, \"learn_time_ms\": 25527.237}", "{\"n\": 588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2142.7, \"learn_time_ms\": 25530.139}", "{\"n\": 589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2142.18, \"learn_time_ms\": 25465.574}", "{\"n\": 590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.68, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2139.86, \"learn_time_ms\": 25472.73}", "{\"n\": 591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2147.6, \"learn_time_ms\": 25474.449}", "{\"n\": 592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2146.09, \"learn_time_ms\": 25460.175}", "{\"n\": 593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2144.02, \"learn_time_ms\": 25460.453}", "{\"n\": 594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2145.78, \"learn_time_ms\": 25435.853}", "{\"n\": 595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2147.45, \"learn_time_ms\": 25447.862}", "{\"n\": 596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2143.48, \"learn_time_ms\": 25464.555}", "{\"n\": 597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2143.48, \"learn_time_ms\": 25464.054}", "{\"n\": 598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2152.64, \"learn_time_ms\": 25451.504}", "{\"n\": 599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.64, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2147.97, \"learn_time_ms\": 25511.808}", "{\"n\": 600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2154.64, \"learn_time_ms\": 25510.795}", "{\"n\": 601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2154.64, \"learn_time_ms\": 25509.947}", "{\"n\": 602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.62, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2153.57, \"learn_time_ms\": 25525.509}", "{\"n\": 603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2156.67, \"learn_time_ms\": 25502.053}", "{\"n\": 604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.63, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2156.67, \"learn_time_ms\": 25492.727}", "{\"n\": 605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2153.18, \"learn_time_ms\": 25496.144}", "{\"n\": 606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2160.5, \"learn_time_ms\": 25490.208}", "{\"n\": 607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2156.93, \"learn_time_ms\": 25474.456}", "{\"n\": 608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2156.93, \"learn_time_ms\": 25451.215}", "{\"n\": 609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.52, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2158.92, \"learn_time_ms\": 25444.398}", "{\"n\": 610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2162.66, \"learn_time_ms\": 25443.033}", "{\"n\": 611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2162.66, \"learn_time_ms\": 25423.424}", "{\"n\": 612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2166.21, \"learn_time_ms\": 25421.282}", "{\"n\": 613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2168.28, \"learn_time_ms\": 25445.946}", "{\"n\": 614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2180.87, \"learn_time_ms\": 25469.123}", "{\"n\": 615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.51, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2176.75, \"learn_time_ms\": 25469.771}", "{\"n\": 616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.48, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2179.52, \"learn_time_ms\": 25465.24}", "{\"n\": 617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.45, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2179.08, \"learn_time_ms\": 25475.913}", "{\"n\": 618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.41, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2183.97, \"learn_time_ms\": 25495.295}", "{\"n\": 619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2177.01, \"learn_time_ms\": 25505.324}", "{\"n\": 620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.45, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2172.33, \"learn_time_ms\": 25498.666}", "{\"n\": 621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2175.9, \"learn_time_ms\": 25514.0}", "{\"n\": 622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2173.77, \"learn_time_ms\": 25500.356}", "{\"n\": 623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2164.47, \"learn_time_ms\": 25498.612}", "{\"n\": 624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2166.97, \"learn_time_ms\": 25498.761}", "{\"n\": 625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.44, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2165.01, \"learn_time_ms\": 25500.038}", "{\"n\": 626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2156.42, \"learn_time_ms\": 25503.252}", "{\"n\": 627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2155.0, \"learn_time_ms\": 25487.694}", "{\"n\": 628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.38, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2159.95, \"learn_time_ms\": 25492.71}", "{\"n\": 629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2156.42, \"learn_time_ms\": 25491.624}", "{\"n\": 630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.38, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2156.3, \"learn_time_ms\": 25493.849}", "{\"n\": 631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.35, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2154.15, \"learn_time_ms\": 25490.988}", "{\"n\": 632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.36, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2150.91, \"learn_time_ms\": 25503.101}", "{\"n\": 633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.34, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2151.06, \"learn_time_ms\": 25496.25}", "{\"n\": 634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.34, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2151.06, \"learn_time_ms\": 25505.848}", "{\"n\": 635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.33, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2156.2, \"learn_time_ms\": 25504.662}", "{\"n\": 636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.33, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2156.2, \"learn_time_ms\": 25507.856}", "{\"n\": 637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2171.35, \"learn_time_ms\": 25518.143}", "{\"n\": 638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2178.7, \"learn_time_ms\": 25519.071}", "{\"n\": 639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2180.69, \"learn_time_ms\": 25521.998}", "{\"n\": 640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2176.56, \"learn_time_ms\": 25522.802}", "{\"n\": 641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2173.63, \"learn_time_ms\": 25526.293}", "{\"n\": 642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2176.07, \"learn_time_ms\": 25523.28}", "{\"n\": 643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2171.41, \"learn_time_ms\": 25531.34}", "{\"n\": 644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2168.19, \"learn_time_ms\": 25535.6}", "{\"n\": 645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2169.71, \"learn_time_ms\": 25535.84}", "{\"n\": 646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2166.44, \"learn_time_ms\": 25534.27}", "{\"n\": 647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2164.14, \"learn_time_ms\": 25532.548}", "{\"n\": 648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2162.17, \"learn_time_ms\": 25529.744}", "{\"n\": 649, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2163.6, \"learn_time_ms\": 25527.571}", "{\"n\": 650, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2163.6, \"learn_time_ms\": 25525.581}", "{\"n\": 651, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2169.52, \"learn_time_ms\": 25534.994}", "{\"n\": 652, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2166.84, \"learn_time_ms\": 25537.382}", "{\"n\": 653, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2163.07, \"learn_time_ms\": 25536.129}", "{\"n\": 654, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2162.14, \"learn_time_ms\": 25531.066}", "{\"n\": 655, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.12, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2164.22, \"learn_time_ms\": 25530.918}", "{\"n\": 656, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2166.91, \"learn_time_ms\": 25528.316}", "{\"n\": 657, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2171.39, \"learn_time_ms\": 25533.421}", "{\"n\": 658, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2171.39, \"learn_time_ms\": 25536.034}", "{\"n\": 659, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2173.22, \"learn_time_ms\": 25539.595}", "{\"n\": 660, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2166.95, \"learn_time_ms\": 25538.787}", "{\"n\": 661, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2162.5, \"learn_time_ms\": 25532.429}", "{\"n\": 662, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2168.54, \"learn_time_ms\": 25529.371}", "{\"n\": 663, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2165.35, \"learn_time_ms\": 25525.096}", "{\"n\": 664, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2164.69, \"learn_time_ms\": 25524.712}", "{\"n\": 665, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2174.4, \"learn_time_ms\": 25532.561}", "{\"n\": 666, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2175.6, \"learn_time_ms\": 25533.865}", "{\"n\": 667, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2175.36, \"learn_time_ms\": 25528.5}", "{\"n\": 668, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2184.52, \"learn_time_ms\": 25530.927}", "{\"n\": 669, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2205.04, \"learn_time_ms\": 25536.574}", "{\"n\": 670, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2204.57, \"learn_time_ms\": 25538.813}", "{\"n\": 671, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2205.87, \"learn_time_ms\": 25538.291}", "{\"n\": 672, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2210.48, \"learn_time_ms\": 25543.687}", "{\"n\": 673, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2221.42, \"learn_time_ms\": 25546.938}", "{\"n\": 674, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2223.14, \"learn_time_ms\": 25546.742}", "{\"n\": 675, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2238.77, \"learn_time_ms\": 25540.353}", "{\"n\": 676, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2238.77, \"learn_time_ms\": 25537.368}", "{\"n\": 677, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2239.5, \"learn_time_ms\": 25537.654}", "{\"n\": 678, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2246.31, \"learn_time_ms\": 25531.852}", "{\"n\": 679, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2244.66, \"learn_time_ms\": 25524.394}", "{\"n\": 680, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2239.6, \"learn_time_ms\": 25519.638}", "{\"n\": 681, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2239.07, \"learn_time_ms\": 25522.406}", "{\"n\": 682, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2239.3, \"learn_time_ms\": 25520.912}", "{\"n\": 683, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.72, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2232.5, \"learn_time_ms\": 25517.043}", "{\"n\": 684, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.72, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2232.5, \"learn_time_ms\": 25504.601}", "{\"n\": 685, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2230.06, \"learn_time_ms\": 25506.857}", "{\"n\": 686, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2233.54, \"learn_time_ms\": 25504.917}", "{\"n\": 687, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2231.61, \"learn_time_ms\": 25509.478}", "{\"n\": 688, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2244.26, \"learn_time_ms\": 25483.012}", "{\"n\": 689, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2240.13, \"learn_time_ms\": 25482.662}", "{\"n\": 690, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2255.83, \"learn_time_ms\": 25486.856}", "{\"n\": 691, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2255.92, \"learn_time_ms\": 25487.114}", "{\"n\": 692, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2253.37, \"learn_time_ms\": 25481.324}", "{\"n\": 693, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2253.37, \"learn_time_ms\": 25444.931}", "{\"n\": 694, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2246.2, \"learn_time_ms\": 25460.188}", "{\"n\": 695, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2250.83, \"learn_time_ms\": 25456.596}", "{\"n\": 696, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2250.41, \"learn_time_ms\": 25462.592}", "{\"n\": 697, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2249.25, \"learn_time_ms\": 25445.022}", "{\"n\": 698, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2254.47, \"learn_time_ms\": 25476.456}", "{\"n\": 699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2265.22, \"learn_time_ms\": 25478.626}", "{\"n\": 700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2274.26, \"learn_time_ms\": 25477.789}", "{\"n\": 701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2265.54, \"learn_time_ms\": 25476.78}", "{\"n\": 702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2266.12, \"learn_time_ms\": 25479.233}", "{\"n\": 703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2268.23, \"learn_time_ms\": 25519.123}", "{\"n\": 704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.65, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2272.08, \"learn_time_ms\": 25519.098}", "{\"n\": 705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2275.31, \"learn_time_ms\": 25516.461}", "{\"n\": 706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2275.31, \"learn_time_ms\": 25518.027}", "{\"n\": 707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2282.22, \"learn_time_ms\": 25533.327}", "{\"n\": 708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.72, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2284.01, \"learn_time_ms\": 25529.586}", "{\"n\": 709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2282.99, \"learn_time_ms\": 25529.506}", "{\"n\": 710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.77, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2290.05, \"learn_time_ms\": 25530.76}", "{\"n\": 711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2279.43, \"learn_time_ms\": 25527.387}", "{\"n\": 712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2280.52, \"learn_time_ms\": 25525.503}", "{\"n\": 713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2274.03, \"learn_time_ms\": 25520.442}", "{\"n\": 714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2273.13, \"learn_time_ms\": 25519.311}", "{\"n\": 715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2269.63, \"learn_time_ms\": 25520.151}", "{\"n\": 716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2259.67, \"learn_time_ms\": 25522.834}", "{\"n\": 717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2265.27, \"learn_time_ms\": 25521.264}", "{\"n\": 718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2268.94, \"learn_time_ms\": 25526.933}", "{\"n\": 719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2273.35, \"learn_time_ms\": 25524.988}", "{\"n\": 720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2272.1, \"learn_time_ms\": 25525.064}", "{\"n\": 721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2271.74, \"learn_time_ms\": 25530.612}", "{\"n\": 722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2272.36, \"learn_time_ms\": 25527.875}", "{\"n\": 723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2279.59, \"learn_time_ms\": 25464.579}", "{\"n\": 724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2276.14, \"learn_time_ms\": 25467.721}", "{\"n\": 725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2275.78, \"learn_time_ms\": 25470.159}", "{\"n\": 726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2278.98, \"learn_time_ms\": 25468.059}", "{\"n\": 727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2286.9, \"learn_time_ms\": 25466.629}", "{\"n\": 728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2275.28, \"learn_time_ms\": 25465.701}", "{\"n\": 729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2277.94, \"learn_time_ms\": 25465.143}", "{\"n\": 730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2274.19, \"learn_time_ms\": 25456.89}", "{\"n\": 731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2282.9, \"learn_time_ms\": 25453.788}", "{\"n\": 732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2284.31, \"learn_time_ms\": 25458.708}", "{\"n\": 733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2284.74, \"learn_time_ms\": 25523.59}", "{\"n\": 734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2284.46, \"learn_time_ms\": 25522.45}", "{\"n\": 735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2289.5, \"learn_time_ms\": 25521.511}", "{\"n\": 736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2288.55, \"learn_time_ms\": 25518.163}", "{\"n\": 737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2274.47, \"learn_time_ms\": 25524.97}", "{\"n\": 738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2270.73, \"learn_time_ms\": 25523.006}", "{\"n\": 739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2270.82, \"learn_time_ms\": 25512.086}", "{\"n\": 740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2270.99, \"learn_time_ms\": 25517.533}", "{\"n\": 741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.8, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2272.73, \"learn_time_ms\": 25518.675}", "{\"n\": 742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2267.04, \"learn_time_ms\": 25514.452}", "{\"n\": 743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2262.39, \"learn_time_ms\": 25520.752}", "{\"n\": 744, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2251.99, \"learn_time_ms\": 25513.158}", "{\"n\": 745, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2245.27, \"learn_time_ms\": 25510.549}", "{\"n\": 746, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2240.54, \"learn_time_ms\": 25497.131}", "{\"n\": 747, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2242.66, \"learn_time_ms\": 25498.164}", "{\"n\": 748, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2237.63, \"learn_time_ms\": 25499.39}", "{\"n\": 749, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2222.74, \"learn_time_ms\": 25512.112}", "{\"n\": 750, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2219.25, \"learn_time_ms\": 25516.26}", "{\"n\": 751, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2216.87, \"learn_time_ms\": 25515.521}", "{\"n\": 752, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2209.97, \"learn_time_ms\": 25522.367}", "{\"n\": 753, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2206.82, \"learn_time_ms\": 25518.555}", "{\"n\": 754, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2202.7, \"learn_time_ms\": 25522.701}", "{\"n\": 755, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2207.71, \"learn_time_ms\": 25524.406}", "{\"n\": 756, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2203.74, \"learn_time_ms\": 25483.509}", "{\"n\": 757, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.02, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2209.19, \"learn_time_ms\": 25478.299}", "{\"n\": 758, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2208.6, \"learn_time_ms\": 25443.468}", "{\"n\": 759, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2205.9, \"learn_time_ms\": 25440.245}", "{\"n\": 760, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2203.31, \"learn_time_ms\": 25433.977}", "{\"n\": 761, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2204.19, \"learn_time_ms\": 25433.913}", "{\"n\": 762, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2215.0, \"learn_time_ms\": 25433.839}", "{\"n\": 763, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2210.74, \"learn_time_ms\": 25432.919}", "{\"n\": 764, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2208.09, \"learn_time_ms\": 25437.678}", "{\"n\": 765, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2204.22, \"learn_time_ms\": 25436.832}", "{\"n\": 766, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2204.22, \"learn_time_ms\": 25497.777}", "{\"n\": 767, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2199.28, \"learn_time_ms\": 25503.257}", "{\"n\": 768, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2187.84, \"learn_time_ms\": 25532.338}", "{\"n\": 769, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2187.53, \"learn_time_ms\": 25533.124}", "{\"n\": 770, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2186.27, \"learn_time_ms\": 25540.374}", "{\"n\": 771, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2194.6, \"learn_time_ms\": 25542.985}", "{\"n\": 772, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.81, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2191.09, \"learn_time_ms\": 25536.124}", "{\"n\": 773, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2191.57, \"learn_time_ms\": 25539.303}", "{\"n\": 774, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2186.44, \"learn_time_ms\": 25535.525}", "{\"n\": 775, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2183.39, \"learn_time_ms\": 25537.779}", "{\"n\": 776, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2188.56, \"learn_time_ms\": 25527.733}", "{\"n\": 777, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2189.76, \"learn_time_ms\": 25522.541}", "{\"n\": 778, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2181.4, \"learn_time_ms\": 25521.992}", "{\"n\": 779, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2185.06, \"learn_time_ms\": 25524.122}", "{\"n\": 780, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.77, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2185.46, \"learn_time_ms\": 25515.532}", "{\"n\": 781, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2186.49, \"learn_time_ms\": 25514.968}", "{\"n\": 782, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2185.52, \"learn_time_ms\": 25515.015}", "{\"n\": 783, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2193.18, \"learn_time_ms\": 25518.383}", "{\"n\": 784, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.62, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2200.4, \"learn_time_ms\": 25513.85}", "{\"n\": 785, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2210.03, \"learn_time_ms\": 25512.044}", "{\"n\": 786, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2210.03, \"learn_time_ms\": 25509.514}", "{\"n\": 787, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2221.75, \"learn_time_ms\": 25509.177}", "{\"n\": 788, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2226.5, \"learn_time_ms\": 25512.137}", "{\"n\": 789, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2238.69, \"learn_time_ms\": 25512.126}", "{\"n\": 790, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2238.69, \"learn_time_ms\": 25518.555}", "{\"n\": 791, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2246.29, \"learn_time_ms\": 25517.409}", "{\"n\": 792, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2261.53, \"learn_time_ms\": 25521.098}", "{\"n\": 793, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2266.46, \"learn_time_ms\": 25509.825}", "{\"n\": 794, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2265.64, \"learn_time_ms\": 25518.554}", "{\"n\": 795, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2275.12, \"learn_time_ms\": 25519.42}", "{\"n\": 796, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2293.67, \"learn_time_ms\": 25526.726}", "{\"n\": 797, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2293.48, \"learn_time_ms\": 25529.115}", "{\"n\": 798, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.22, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2302.01, \"learn_time_ms\": 25530.39}", "{\"n\": 799, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2301.94, \"learn_time_ms\": 25531.967}", "{\"n\": 800, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2305.76, \"learn_time_ms\": 25523.726}", "{\"n\": 801, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2305.76, \"learn_time_ms\": 25518.443}", "{\"n\": 802, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2314.75, \"learn_time_ms\": 25518.432}", "{\"n\": 803, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2323.46, \"learn_time_ms\": 25523.303}", "{\"n\": 804, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2332.86, \"learn_time_ms\": 25518.543}", "{\"n\": 805, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2332.29, \"learn_time_ms\": 25520.672}", "{\"n\": 806, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2333.67, \"learn_time_ms\": 25524.544}", "{\"n\": 807, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.38, \"learn_time_ms\": 25525.104}", "{\"n\": 808, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.38, \"learn_time_ms\": 25514.112}", "{\"n\": 809, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2340.87, \"learn_time_ms\": 25511.797}", "{\"n\": 810, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.04, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.94, \"learn_time_ms\": 25517.645}", "{\"n\": 811, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.06, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.09, \"learn_time_ms\": 25519.533}", "{\"n\": 812, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.09, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.06, \"learn_time_ms\": 25523.301}", "{\"n\": 813, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.61, \"learn_time_ms\": 25524.061}", "{\"n\": 814, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2341.38, \"learn_time_ms\": 25527.166}", "{\"n\": 815, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2343.17, \"learn_time_ms\": 25525.172}", "{\"n\": 816, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2351.38, \"learn_time_ms\": 25522.163}", "{\"n\": 817, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.01, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2357.51, \"learn_time_ms\": 25526.394}", "{\"n\": 818, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.88, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2373.17, \"learn_time_ms\": 25536.346}", "{\"n\": 819, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2370.01, \"learn_time_ms\": 25530.982}", "{\"n\": 820, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2370.01, \"learn_time_ms\": 25534.09}", "{\"n\": 821, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2373.94, \"learn_time_ms\": 25539.296}", "{\"n\": 822, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2379.0, \"learn_time_ms\": 25537.008}", "{\"n\": 823, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2383.88, \"learn_time_ms\": 25530.848}", "{\"n\": 824, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2381.78, \"learn_time_ms\": 25528.25}", "{\"n\": 825, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2380.06, \"learn_time_ms\": 25532.063}", "{\"n\": 826, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2366.28, \"learn_time_ms\": 25532.716}", "{\"n\": 827, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2366.28, \"learn_time_ms\": 25526.002}", "{\"n\": 828, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2366.28, \"learn_time_ms\": 25526.024}", "{\"n\": 829, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2364.18, \"learn_time_ms\": 25536.841}", "{\"n\": 830, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.62, \"learn_time_ms\": 25541.995}", "{\"n\": 831, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.62, \"learn_time_ms\": 25540.739}", "{\"n\": 832, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.62, \"learn_time_ms\": 25538.794}", "{\"n\": 833, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2358.56, \"learn_time_ms\": 25550.004}", "{\"n\": 834, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2360.82, \"learn_time_ms\": 25549.189}", "{\"n\": 835, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2360.06, \"learn_time_ms\": 25539.664}", "{\"n\": 836, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.94, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2360.06, \"learn_time_ms\": 25535.441}", "{\"n\": 837, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.96, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2357.01, \"learn_time_ms\": 25529.913}", "{\"n\": 838, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.15, \"learn_time_ms\": 25533.666}", "{\"n\": 839, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2343.53, \"learn_time_ms\": 25532.129}", "{\"n\": 840, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2343.53, \"learn_time_ms\": 25526.175}", "{\"n\": 841, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2341.5, \"learn_time_ms\": 25522.07}", "{\"n\": 842, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.99, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2347.31, \"learn_time_ms\": 25524.217}", "{\"n\": 843, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.99, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2343.21, \"learn_time_ms\": 25519.848}", "{\"n\": 844, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2337.41, \"learn_time_ms\": 25522.573}", "{\"n\": 845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2330.51, \"learn_time_ms\": 25530.115}", "{\"n\": 846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2326.18, \"learn_time_ms\": 25533.609}", "{\"n\": 847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.92, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2333.06, \"learn_time_ms\": 25542.17}", "{\"n\": 848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.89, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2334.46, \"learn_time_ms\": 25540.171}", "{\"n\": 849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2328.8, \"learn_time_ms\": 25537.295}", "{\"n\": 850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2328.8, \"learn_time_ms\": 25531.309}", "{\"n\": 851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2330.09, \"learn_time_ms\": 25530.132}", "{\"n\": 852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2329.48, \"learn_time_ms\": 25527.307}", "{\"n\": 853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.92, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2319.98, \"learn_time_ms\": 25527.57}", "{\"n\": 854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.96, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2318.6, \"learn_time_ms\": 25527.836}", "{\"n\": 855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2316.25, \"learn_time_ms\": 25523.444}", "{\"n\": 856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2319.02, \"learn_time_ms\": 25523.609}", "{\"n\": 857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2327.28, \"learn_time_ms\": 25524.636}", "{\"n\": 858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2329.12, \"learn_time_ms\": 25518.077}", "{\"n\": 859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2328.48, \"learn_time_ms\": 25516.695}", "{\"n\": 860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2330.28, \"learn_time_ms\": 25512.014}", "{\"n\": 861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2326.91, \"learn_time_ms\": 25515.242}", "{\"n\": 862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2326.91, \"learn_time_ms\": 25514.035}", "{\"n\": 863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2329.62, \"learn_time_ms\": 25494.886}", "{\"n\": 864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2329.62, \"learn_time_ms\": 25497.635}", "{\"n\": 865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.02, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2304.42, \"learn_time_ms\": 25501.646}", "{\"n\": 866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2306.77, \"learn_time_ms\": 25505.904}", "{\"n\": 867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2311.06, \"learn_time_ms\": 25502.848}", "{\"n\": 868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2307.38, \"learn_time_ms\": 25506.436}", "{\"n\": 869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2323.47, \"learn_time_ms\": 25511.322}", "{\"n\": 870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2326.05, \"learn_time_ms\": 25515.349}", "{\"n\": 871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2326.38, \"learn_time_ms\": 25515.174}", "{\"n\": 872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2321.52, \"learn_time_ms\": 25516.499}", "{\"n\": 873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2324.19, \"learn_time_ms\": 25537.23}", "{\"n\": 874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2328.32, \"learn_time_ms\": 25528.009}", "{\"n\": 875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2333.14, \"learn_time_ms\": 25534.298}", "{\"n\": 876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2334.27, \"learn_time_ms\": 25522.688}", "{\"n\": 877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2342.29, \"learn_time_ms\": 25531.947}", "{\"n\": 878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.99, \"learn_time_ms\": 25536.063}", "{\"n\": 879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2345.83, \"learn_time_ms\": 25531.272}", "{\"n\": 880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2346.63, \"learn_time_ms\": 25529.454}", "{\"n\": 881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2343.73, \"learn_time_ms\": 25529.675}", "{\"n\": 882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2347.48, \"learn_time_ms\": 25529.031}", "{\"n\": 883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2346.16, \"learn_time_ms\": 25522.404}", "{\"n\": 884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2349.25, \"learn_time_ms\": 25532.122}", "{\"n\": 885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2351.36, \"learn_time_ms\": 25516.649}", "{\"n\": 886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.68, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2358.55, \"learn_time_ms\": 25523.561}", "{\"n\": 887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2352.63, \"learn_time_ms\": 25514.128}", "{\"n\": 888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2350.29, \"learn_time_ms\": 25505.839}", "{\"n\": 889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2349.21, \"learn_time_ms\": 25504.697}", "{\"n\": 890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2350.74, \"learn_time_ms\": 25505.341}", "{\"n\": 891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2339.7, \"learn_time_ms\": 25508.489}", "{\"n\": 892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.81, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2341.91, \"learn_time_ms\": 25431.763}", "{\"n\": 893, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2346.1, \"learn_time_ms\": 25329.141}", "{\"n\": 894, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.88, \"learn_time_ms\": 25296.347}", "{\"n\": 895, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2326.52, \"learn_time_ms\": 25233.092}", "{\"n\": 896, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2330.4, \"learn_time_ms\": 25186.776}", "{\"n\": 897, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2330.4, \"learn_time_ms\": 25175.475}", "{\"n\": 898, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2312.39, \"learn_time_ms\": 25105.989}", "{\"n\": 899, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2314.73, \"learn_time_ms\": 25056.541}", "{\"n\": 900, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2314.18, \"learn_time_ms\": 25062.735}", "{\"n\": 901, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2314.18, \"learn_time_ms\": 25066.589}", "{\"n\": 902, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2306.55, \"learn_time_ms\": 24913.196}", "{\"n\": 903, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2307.18, \"learn_time_ms\": 25017.308}", "{\"n\": 904, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2313.71, \"learn_time_ms\": 25055.046}", "{\"n\": 905, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2319.07, \"learn_time_ms\": 25117.205}", "{\"n\": 906, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2309.45, \"learn_time_ms\": 25169.336}", "{\"n\": 907, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2313.35, \"learn_time_ms\": 25180.671}", "{\"n\": 908, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2325.92, \"learn_time_ms\": 25256.417}", "{\"n\": 909, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2320.91, \"learn_time_ms\": 25305.222}", "{\"n\": 910, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.62, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2321.52, \"learn_time_ms\": 25307.732}", "{\"n\": 911, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.62, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2325.92, \"learn_time_ms\": 25301.271}", "{\"n\": 912, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2320.55, \"learn_time_ms\": 25534.826}", "{\"n\": 913, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.66, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2320.17, \"learn_time_ms\": 25539.165}", "{\"n\": 914, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.62, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2332.14, \"learn_time_ms\": 25531.391}", "{\"n\": 915, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.61, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2330.58, \"learn_time_ms\": 25539.461}", "{\"n\": 916, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.65, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.34, \"learn_time_ms\": 25536.592}", "{\"n\": 917, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.67, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2332.41, \"learn_time_ms\": 25517.417}", "{\"n\": 918, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2321.7, \"learn_time_ms\": 25510.673}", "{\"n\": 919, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2320.35, \"learn_time_ms\": 25512.798}", "{\"n\": 920, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.68, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2333.71, \"learn_time_ms\": 25512.136}", "{\"n\": 921, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.67, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2332.82, \"learn_time_ms\": 25510.952}", "{\"n\": 922, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.65, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2337.2, \"learn_time_ms\": 25506.467}", "{\"n\": 923, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.65, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2337.2, \"learn_time_ms\": 25485.855}", "{\"n\": 924, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.63, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2347.67, \"learn_time_ms\": 25487.002}", "{\"n\": 925, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.6, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2346.1, \"learn_time_ms\": 25488.802}", "{\"n\": 926, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.6, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2345.08, \"learn_time_ms\": 25490.545}", "{\"n\": 927, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.6, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2342.51, \"learn_time_ms\": 25510.586}", "{\"n\": 928, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.59, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2342.21, \"learn_time_ms\": 25516.278}", "{\"n\": 929, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2348.19, \"learn_time_ms\": 25514.1}", "{\"n\": 930, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.57, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2349.47, \"learn_time_ms\": 25512.458}", "{\"n\": 931, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.62, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2343.64, \"learn_time_ms\": 25503.115}", "{\"n\": 932, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2338.75, \"learn_time_ms\": 25503.131}", "{\"n\": 933, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.68, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2337.22, \"learn_time_ms\": 25525.501}", "{\"n\": 934, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2341.06, \"learn_time_ms\": 25523.718}", "{\"n\": 935, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.61, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2344.38, \"learn_time_ms\": 25521.107}", "{\"n\": 936, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.61, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2344.38, \"learn_time_ms\": 25517.751}", "{\"n\": 937, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2365.1, \"learn_time_ms\": 25513.626}", "{\"n\": 938, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2365.89, \"learn_time_ms\": 25516.181}", "{\"n\": 939, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2361.73, \"learn_time_ms\": 25513.661}", "{\"n\": 940, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.54, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2359.63, \"learn_time_ms\": 25514.98}", "{\"n\": 941, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2370.6, \"learn_time_ms\": 25516.452}", "{\"n\": 942, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2370.6, \"learn_time_ms\": 25521.935}", "{\"n\": 943, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2375.32, \"learn_time_ms\": 25518.788}", "{\"n\": 944, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2392.08, \"learn_time_ms\": 25517.257}", "{\"n\": 945, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2409.35, \"learn_time_ms\": 25518.042}", "{\"n\": 946, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2410.49, \"learn_time_ms\": 25519.561}", "{\"n\": 947, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2410.49, \"learn_time_ms\": 25520.274}", "{\"n\": 948, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.19, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2421.25, \"learn_time_ms\": 25516.55}", "{\"n\": 949, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.15, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2428.03, \"learn_time_ms\": 25522.444}", "{\"n\": 950, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2427.72, \"learn_time_ms\": 25519.98}", "{\"n\": 951, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.19, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2433.59, \"learn_time_ms\": 25524.72}", "{\"n\": 952, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.15, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2439.71, \"learn_time_ms\": 25522.449}", "{\"n\": 953, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2449.49, \"learn_time_ms\": 25459.507}", "{\"n\": 954, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2460.42, \"learn_time_ms\": 25460.945}", "{\"n\": 955, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.05, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2456.88, \"learn_time_ms\": 25459.071}", "{\"n\": 956, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2464.36, \"learn_time_ms\": 25457.798}", "{\"n\": 957, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2469.19, \"learn_time_ms\": 25458.117}", "{\"n\": 958, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2459.76, \"learn_time_ms\": 25456.942}", "{\"n\": 959, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2459.76, \"learn_time_ms\": 25459.764}", "{\"n\": 960, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.01, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2465.07, \"learn_time_ms\": 25461.909}", "{\"n\": 961, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2468.63, \"learn_time_ms\": 25446.799}", "{\"n\": 962, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2466.38, \"learn_time_ms\": 25435.806}", "{\"n\": 963, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2468.53, \"learn_time_ms\": 25499.735}", "{\"n\": 964, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2467.86, \"learn_time_ms\": 25501.679}", "{\"n\": 965, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2469.65, \"learn_time_ms\": 25503.201}", "{\"n\": 966, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2468.23, \"learn_time_ms\": 25501.717}", "{\"n\": 967, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2462.87, \"learn_time_ms\": 25505.996}", "{\"n\": 968, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2463.54, \"learn_time_ms\": 25512.746}", "{\"n\": 969, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2463.54, \"learn_time_ms\": 25505.472}", "{\"n\": 970, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2473.75, \"learn_time_ms\": 25482.331}", "{\"n\": 971, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2465.19, \"learn_time_ms\": 25479.55}", "{\"n\": 972, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2461.49, \"learn_time_ms\": 25497.003}", "{\"n\": 973, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2461.49, \"learn_time_ms\": 25494.721}", "{\"n\": 974, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2467.28, \"learn_time_ms\": 25493.483}", "{\"n\": 975, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2472.95, \"learn_time_ms\": 25497.843}", "{\"n\": 976, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2477.51, \"learn_time_ms\": 25500.714}", "{\"n\": 977, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2477.51, \"learn_time_ms\": 25488.69}", "{\"n\": 978, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2480.88, \"learn_time_ms\": 25488.334}", "{\"n\": 979, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2479.84, \"learn_time_ms\": 25488.921}", "{\"n\": 980, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2486.0, \"learn_time_ms\": 25516.49}", "{\"n\": 981, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2486.0, \"learn_time_ms\": 25537.715}", "{\"n\": 982, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2480.23, \"learn_time_ms\": 25534.182}", "{\"n\": 983, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2491.3, \"learn_time_ms\": 25532.061}", "{\"n\": 984, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2493.03, \"learn_time_ms\": 25510.022}", "{\"n\": 985, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2493.03, \"learn_time_ms\": 25505.726}", "{\"n\": 986, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2482.05, \"learn_time_ms\": 25507.592}", "{\"n\": 987, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2473.25, \"learn_time_ms\": 25519.938}", "{\"n\": 988, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2467.3, \"learn_time_ms\": 25518.683}", "{\"n\": 989, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2462.67, \"learn_time_ms\": 25518.871}", "{\"n\": 990, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2462.67, \"learn_time_ms\": 25509.102}", "{\"n\": 991, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2463.49, \"learn_time_ms\": 25478.65}", "{\"n\": 992, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2468.63, \"learn_time_ms\": 25479.237}", "{\"n\": 993, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2469.75, \"learn_time_ms\": 25488.508}", "{\"n\": 994, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2462.39, \"learn_time_ms\": 25514.334}", "{\"n\": 995, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2468.16, \"learn_time_ms\": 25513.025}", "{\"n\": 996, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2471.72, \"learn_time_ms\": 25500.805}", "{\"n\": 997, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2471.44, \"learn_time_ms\": 25507.535}", "{\"n\": 998, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2470.95, \"learn_time_ms\": 25511.288}", "{\"n\": 999, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2475.77, \"learn_time_ms\": 25508.764}", "{\"n\": 1000, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2466.01, \"learn_time_ms\": 25517.533}"]