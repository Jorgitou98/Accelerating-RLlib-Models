["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 46941.9, \"total_train_time_s\": 61.701956272125244}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 35304.224, \"total_train_time_s\": 30.77364444732666}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 31578.189, \"total_train_time_s\": 31.394474983215332}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.375, \"learn_time_ms\": 29720.815, \"total_train_time_s\": 31.391449689865112}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.3076923076923, \"learn_time_ms\": 28609.802, \"total_train_time_s\": 31.397565364837646}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.4375, \"learn_time_ms\": 27872.968, \"total_train_time_s\": 31.47658610343933}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.4166666666666, \"learn_time_ms\": 27345.774, \"total_train_time_s\": 31.41561484336853}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.4166666666666, \"learn_time_ms\": 26947.993, \"total_train_time_s\": 31.384403705596924}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.125, \"learn_time_ms\": 26644.257, \"total_train_time_s\": 31.355235815048218}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.3055555555555, \"learn_time_ms\": 26400.42, \"total_train_time_s\": 31.59892988204956}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1016.725, \"learn_time_ms\": 24124.548, \"total_train_time_s\": 31.42048192024231}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.5, \"learn_time_ms\": 24176.319, \"total_train_time_s\": 31.37594747543335}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.5, \"learn_time_ms\": 24071.261, \"total_train_time_s\": 30.29151487350464}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.0535714285714, \"learn_time_ms\": 24040.08, \"total_train_time_s\": 31.14274024963379}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9322033898305, \"learn_time_ms\": 23977.394, \"total_train_time_s\": 30.849998950958252}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.46875, \"learn_time_ms\": 23941.971, \"total_train_time_s\": 31.09962248802185}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.0, \"learn_time_ms\": 23906.746, \"total_train_time_s\": 31.050079822540283}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.0, \"learn_time_ms\": 23872.093, \"total_train_time_s\": 30.926316738128662}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.1375, \"learn_time_ms\": 23833.197, \"total_train_time_s\": 30.93605613708496}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.277108433735, \"learn_time_ms\": 23784.048, \"total_train_time_s\": 30.884719371795654}"]