["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 48154.02, \"total_train_time_s\": 67.40896224975586}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 35357.448, \"total_train_time_s\": 34.18730640411377}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 31666.458, \"total_train_time_s\": 33.384056091308594}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.25, \"learn_time_ms\": 29750.893, \"total_train_time_s\": 33.120092153549194}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.3076923076923, \"learn_time_ms\": 28619.037, \"total_train_time_s\": 33.01957821846008}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.875, \"learn_time_ms\": 27870.952, \"total_train_time_s\": 33.22589707374573}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9166666666666, \"learn_time_ms\": 27307.448, \"total_train_time_s\": 32.82371711730957}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.9166666666666, \"learn_time_ms\": 26866.271, \"total_train_time_s\": 32.62292194366455}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.0, \"learn_time_ms\": 26502.27, \"total_train_time_s\": 32.684329986572266}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.0285714285715, \"learn_time_ms\": 26242.51, \"total_train_time_s\": 32.780073165893555}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.475, \"learn_time_ms\": 23810.707, \"total_train_time_s\": 32.90535283088684}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.1458333333334, \"learn_time_ms\": 23878.962, \"total_train_time_s\": 32.29621410369873}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.1458333333334, \"learn_time_ms\": 23829.553, \"total_train_time_s\": 32.806265115737915}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4107142857143, \"learn_time_ms\": 23841.429, \"total_train_time_s\": 33.02927041053772}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7457627118644, \"learn_time_ms\": 23825.941, \"total_train_time_s\": 32.84824776649475}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.671875, \"learn_time_ms\": 23779.821, \"total_train_time_s\": 32.691606760025024}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8888888888889, \"learn_time_ms\": 23768.642, \"total_train_time_s\": 32.67613649368286}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8888888888889, \"learn_time_ms\": 23803.83, \"total_train_time_s\": 32.97210335731506}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 23818.748, \"total_train_time_s\": 32.5938503742218}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0365853658536, \"learn_time_ms\": 23811.41, \"total_train_time_s\": 32.724316120147705}"]["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 50512.471, \"total_train_time_s\": 67.29392385482788}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 37293.16, \"total_train_time_s\": 32.834126710891724}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 32861.542, \"total_train_time_s\": 32.74317264556885}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.0, \"learn_time_ms\": 30626.408, \"total_train_time_s\": 32.66998219490051}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.3, \"learn_time_ms\": 29212.396, \"total_train_time_s\": 32.31699204444885}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.125, \"learn_time_ms\": 28332.832, \"total_train_time_s\": 32.729753494262695}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.875, \"learn_time_ms\": 27700.669, \"total_train_time_s\": 32.68134617805481}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.875, \"learn_time_ms\": 27225.899, \"total_train_time_s\": 32.68340730667114}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.4375, \"learn_time_ms\": 26861.6, \"total_train_time_s\": 32.67397356033325}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.5882352941177, \"learn_time_ms\": 26543.374, \"total_train_time_s\": 32.419042110443115}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1031.0, \"learn_time_ms\": 23850.699, \"total_train_time_s\": 32.32828497886658}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.8222222222223, \"learn_time_ms\": 23834.948, \"total_train_time_s\": 32.675936460494995}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.958333333333332, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.6041666666667, \"learn_time_ms\": 23827.485, \"total_train_time_s\": 32.66995191574097}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.962962962962962, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1040.5555555555557, \"learn_time_ms\": 23826.663, \"total_train_time_s\": 32.6584312915802}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.964285714285715, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1043.6785714285713, \"learn_time_ms\": 23859.643, \"total_train_time_s\": 32.640294313430786}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.967741935483872, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1047.5806451612902, \"learn_time_ms\": 23858.899, \"total_train_time_s\": 32.64698886871338}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.907692307692308, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1055.6615384615384, \"learn_time_ms\": 23859.04, \"total_train_time_s\": 32.5866277217865}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.91176470588235, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1055.0588235294117, \"learn_time_ms\": 23859.163, \"total_train_time_s\": 32.563775062561035}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.916666666666668, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1057.0972222222222, \"learn_time_ms\": 23857.325, \"total_train_time_s\": 32.63334393501282}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87012987012987, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1073.7532467532467, \"learn_time_ms\": 23883.087, \"total_train_time_s\": 32.62569975852966}"]