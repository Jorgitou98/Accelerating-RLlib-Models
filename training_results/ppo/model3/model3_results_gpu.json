["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 44176.947}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43054.534}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42529.27}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.875, \"learn_time_ms\": 42125.415}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 41966.86}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.9375, \"learn_time_ms\": 41865.091}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0416666666666, \"learn_time_ms\": 41760.004}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0416666666666, \"learn_time_ms\": 41659.685}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.5, \"learn_time_ms\": 41674.809}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8888888888889, \"learn_time_ms\": 41586.823}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.2, \"learn_time_ms\": 41276.249}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.8958333333334, \"learn_time_ms\": 41212.048}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.8958333333334, \"learn_time_ms\": 41203.94}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6607142857143, \"learn_time_ms\": 41251.495}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.4915254237288, \"learn_time_ms\": 41245.696}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.640625, \"learn_time_ms\": 41215.048}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0277777777778, \"learn_time_ms\": 41262.547}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0277777777778, \"learn_time_ms\": 41327.982}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0625, \"learn_time_ms\": 41256.067}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0975609756098, \"learn_time_ms\": 41268.341}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.7272727272727, \"learn_time_ms\": 41365.483}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.8229166666666, \"learn_time_ms\": 41396.105}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.8229166666666, \"learn_time_ms\": 41387.999}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.72, \"learn_time_ms\": 41358.541}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.79, \"learn_time_ms\": 41425.405}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.93, \"learn_time_ms\": 41562.651}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 41563.988}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 41501.502}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.92, \"learn_time_ms\": 41566.959}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.89, \"learn_time_ms\": 41614.349}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 41610.856}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.36, \"learn_time_ms\": 41576.018}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.36, \"learn_time_ms\": 41596.104}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.91, \"learn_time_ms\": 41652.723}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.91, \"learn_time_ms\": 41541.756}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 41442.994}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 41399.06}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 41439.368}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.74, \"learn_time_ms\": 41391.905}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.59, \"learn_time_ms\": 41479.114}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.91, \"learn_time_ms\": 41454.991}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 41560.763}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 41530.305}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.15, \"learn_time_ms\": 41630.344}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.29, \"learn_time_ms\": 41674.647}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.3, \"learn_time_ms\": 41680.007}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.19, \"learn_time_ms\": 41694.354}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.19, \"learn_time_ms\": 41670.792}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 41678.793}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 41544.616}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 41454.067}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.18, \"learn_time_ms\": 41415.049}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.18, \"learn_time_ms\": 41448.332}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.33, \"learn_time_ms\": 41245.515}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.21, \"learn_time_ms\": 41188.448}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.57, \"learn_time_ms\": 41208.999}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 41166.654}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.76, \"learn_time_ms\": 41182.067}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 41150.28}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.47, \"learn_time_ms\": 41197.445}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.74, \"learn_time_ms\": 41264.76}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 41216.933}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 41230.998}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.68, \"learn_time_ms\": 41249.025}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.78, \"learn_time_ms\": 41307.225}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.6, \"learn_time_ms\": 41274.252}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 41307.536}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 41314.603}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.42, \"learn_time_ms\": 41327.267}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.43, \"learn_time_ms\": 41408.664}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 41298.888}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.27, \"learn_time_ms\": 41285.018}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.27, \"learn_time_ms\": 41257.342}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 41296.525}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 41260.327}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.33, \"learn_time_ms\": 41245.733}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 41312.453}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 41286.042}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.84, \"learn_time_ms\": 41351.063}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.84, \"learn_time_ms\": 41298.911}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 41342.878}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 41392.043}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 41378.885}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.88, \"learn_time_ms\": 41373.127}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.88, \"learn_time_ms\": 41386.513}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.73, \"learn_time_ms\": 41429.477}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.79, \"learn_time_ms\": 41428.265}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.79, \"learn_time_ms\": 41418.925}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.37, \"learn_time_ms\": 41353.949}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.37, \"learn_time_ms\": 41362.363}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.31, \"learn_time_ms\": 41488.001}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.31, \"learn_time_ms\": 41470.989}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.31, \"learn_time_ms\": 41482.968}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.73, \"learn_time_ms\": 41526.894}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.73, \"learn_time_ms\": 41554.014}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.11, \"learn_time_ms\": 41559.116}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.81, \"learn_time_ms\": 41542.311}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.81, \"learn_time_ms\": 41597.602}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.37, \"learn_time_ms\": 41659.583}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.37, \"learn_time_ms\": 41656.874}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.23, \"learn_time_ms\": 41629.549}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.69, \"learn_time_ms\": 41585.457}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.75, \"learn_time_ms\": 41569.611}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.93, \"learn_time_ms\": 41612.717}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.93, \"learn_time_ms\": 41614.571}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.71, \"learn_time_ms\": 41656.289}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.92, \"learn_time_ms\": 41646.56}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.92, \"learn_time_ms\": 41635.827}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.72, \"learn_time_ms\": 41602.023}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.72, \"learn_time_ms\": 41585.045}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.45, \"learn_time_ms\": 41607.613}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 41636.931}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.96, \"learn_time_ms\": 41678.964}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 41526.93}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 41572.617}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.98, \"learn_time_ms\": 41462.406}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 41403.844}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 41344.527}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.98, \"learn_time_ms\": 41381.511}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 41390.992}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.35, \"learn_time_ms\": 41281.941}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.62, \"learn_time_ms\": 41248.197}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.62, \"learn_time_ms\": 41245.414}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.88, \"learn_time_ms\": 41299.274}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.95, \"learn_time_ms\": 41272.6}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 41287.726}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.68, \"learn_time_ms\": 41285.689}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.81, \"learn_time_ms\": 41408.023}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.86, \"learn_time_ms\": 41352.641}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.9, \"learn_time_ms\": 41363.271}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.01, \"learn_time_ms\": 41403.325}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.89, \"learn_time_ms\": 41414.762}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.03, \"learn_time_ms\": 41363.334}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.04, \"learn_time_ms\": 41354.768}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.08, \"learn_time_ms\": 41419.815}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.35, \"learn_time_ms\": 41444.33}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.51, \"learn_time_ms\": 41499.927}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.61, \"learn_time_ms\": 41441.842}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.49, \"learn_time_ms\": 41455.965}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.18, \"learn_time_ms\": 41359.366}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.4, \"learn_time_ms\": 41308.627}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.34, \"learn_time_ms\": 41329.332}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.46, \"learn_time_ms\": 41470.297}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.1, \"learn_time_ms\": 41474.656}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.23, \"learn_time_ms\": 41458.043}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.26, \"learn_time_ms\": 41456.249}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.46, \"learn_time_ms\": 41406.768}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.62, \"learn_time_ms\": 41356.585}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.66, \"learn_time_ms\": 41281.535}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.83, \"learn_time_ms\": 41393.708}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.41, \"learn_time_ms\": 41462.444}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.71, \"learn_time_ms\": 41465.011}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.33, \"learn_time_ms\": 41356.136}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.27, \"learn_time_ms\": 41577.371}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.5, \"learn_time_ms\": 41558.072}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.4, \"learn_time_ms\": 41630.488}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.08, \"learn_time_ms\": 41584.443}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.91, \"learn_time_ms\": 41693.994}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.66, \"learn_time_ms\": 41734.336}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.65, \"learn_time_ms\": 41696.466}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.0, \"learn_time_ms\": 41669.009}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.73, \"learn_time_ms\": 41655.436}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.52, \"learn_time_ms\": 41625.49}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.3, \"learn_time_ms\": 41415.765}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.06, \"learn_time_ms\": 41354.222}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.26, \"learn_time_ms\": 41257.438}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.32, \"learn_time_ms\": 41281.458}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.04, \"learn_time_ms\": 41289.0}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.78, \"learn_time_ms\": 41288.611}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.74, \"learn_time_ms\": 41302.684}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.68, \"learn_time_ms\": 41314.487}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.83, \"learn_time_ms\": 41272.229}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.08, \"learn_time_ms\": 41290.384}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.98, \"learn_time_ms\": 41409.584}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.68, \"learn_time_ms\": 41397.704}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.14, \"learn_time_ms\": 41472.256}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0, \"learn_time_ms\": 41530.044}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.26, \"learn_time_ms\": 41412.161}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.93, \"learn_time_ms\": 41410.38}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.83, \"learn_time_ms\": 41413.148}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 41429.946}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 41540.312}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.56, \"learn_time_ms\": 41590.619}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.87, \"learn_time_ms\": 41488.93}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.04, \"learn_time_ms\": 41650.806}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8, \"learn_time_ms\": 41586.701}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.07, \"learn_time_ms\": 41655.453}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.69, \"learn_time_ms\": 41784.165}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.6, \"learn_time_ms\": 41883.542}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.61, \"learn_time_ms\": 41825.261}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.89, \"learn_time_ms\": 41833.62}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.8, \"learn_time_ms\": 41774.456}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.22, \"learn_time_ms\": 41744.025}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.91, \"learn_time_ms\": 41731.702}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.85, \"learn_time_ms\": 41572.521}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.37, \"learn_time_ms\": 41589.49}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.5, \"learn_time_ms\": 41588.85}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.73, \"learn_time_ms\": 41536.254}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.21, \"learn_time_ms\": 41463.283}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 41533.536}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.28, \"learn_time_ms\": 41497.169}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.39, \"learn_time_ms\": 41594.445}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.91, \"learn_time_ms\": 41607.107}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.54, \"learn_time_ms\": 41669.846}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.99, \"learn_time_ms\": 41770.918}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.49, \"learn_time_ms\": 41845.575}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.85, \"learn_time_ms\": 41796.851}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.64, \"learn_time_ms\": 41845.496}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.88, \"learn_time_ms\": 41822.05}", "{\"n\": 210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.09, \"learn_time_ms\": 41842.258}", "{\"n\": 211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.9, \"learn_time_ms\": 41842.129}", "{\"n\": 212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.77, \"learn_time_ms\": 41789.358}", "{\"n\": 213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.16, \"learn_time_ms\": 41797.62}", "{\"n\": 214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.52, \"learn_time_ms\": 41735.297}", "{\"n\": 215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.38, \"learn_time_ms\": 41610.333}", "{\"n\": 216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.55, \"learn_time_ms\": 41547.22}", "{\"n\": 217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.59, \"learn_time_ms\": 41466.858}", "{\"n\": 218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.62, \"learn_time_ms\": 41358.339}", "{\"n\": 219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.0, \"learn_time_ms\": 41374.331}", "{\"n\": 220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.86, \"learn_time_ms\": 41301.121}", "{\"n\": 221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.69, \"learn_time_ms\": 41292.24}", "{\"n\": 222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.79, \"learn_time_ms\": 41282.74}", "{\"n\": 223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.07, \"learn_time_ms\": 41247.421}", "{\"n\": 224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.44, \"learn_time_ms\": 41214.027}", "{\"n\": 225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.31, \"learn_time_ms\": 41253.553}", "{\"n\": 226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.04, \"learn_time_ms\": 41264.167}", "{\"n\": 227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.56, \"learn_time_ms\": 41361.984}", "{\"n\": 228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.53, \"learn_time_ms\": 41362.537}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.89, \"learn_time_ms\": 41399.008}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.21, \"learn_time_ms\": 41377.587}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.25, \"learn_time_ms\": 41354.651}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.35, \"learn_time_ms\": 41384.232}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.28, \"learn_time_ms\": 41403.95}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.31, \"learn_time_ms\": 41430.859}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.2, \"learn_time_ms\": 41382.646}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.34, \"learn_time_ms\": 41341.893}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.5, \"learn_time_ms\": 41297.002}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.46, \"learn_time_ms\": 41411.559}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.03, \"learn_time_ms\": 41416.218}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.01, \"learn_time_ms\": 41368.235}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.11, \"learn_time_ms\": 41384.315}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.48, \"learn_time_ms\": 41299.243}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.49, \"learn_time_ms\": 41352.097}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.17, \"learn_time_ms\": 41421.485}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.24, \"learn_time_ms\": 41521.436}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.01, \"learn_time_ms\": 41626.141}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.32, \"learn_time_ms\": 41640.468}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.11, \"learn_time_ms\": 41583.156}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.1, \"learn_time_ms\": 41514.413}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.05, \"learn_time_ms\": 41618.48}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.86, \"learn_time_ms\": 41610.131}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.99, \"learn_time_ms\": 41598.168}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.48, \"learn_time_ms\": 41509.194}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.65, \"learn_time_ms\": 41468.577}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.63, \"learn_time_ms\": 41532.27}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.21, \"learn_time_ms\": 41393.932}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.29, \"learn_time_ms\": 41435.844}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.62, \"learn_time_ms\": 41470.917}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.6, \"learn_time_ms\": 41504.019}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.68, \"learn_time_ms\": 41526.236}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.29, \"learn_time_ms\": 41570.313}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.14, \"learn_time_ms\": 41589.646}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.75, \"learn_time_ms\": 41594.889}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.17, \"learn_time_ms\": 41580.601}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.15, \"learn_time_ms\": 41487.352}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.12, \"learn_time_ms\": 41557.689}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.2, \"learn_time_ms\": 41512.578}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.45, \"learn_time_ms\": 41423.501}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.57, \"learn_time_ms\": 41425.788}", "{\"n\": 270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.31, \"learn_time_ms\": 41391.753}", "{\"n\": 271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.63, \"learn_time_ms\": 41437.171}", "{\"n\": 272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.44, \"learn_time_ms\": 41491.247}", "{\"n\": 273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.4, \"learn_time_ms\": 41481.854}", "{\"n\": 274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.58, \"learn_time_ms\": 41518.312}", "{\"n\": 275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.4, \"learn_time_ms\": 41544.793}", "{\"n\": 276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.62, \"learn_time_ms\": 41550.655}", "{\"n\": 277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.65, \"learn_time_ms\": 41560.422}", "{\"n\": 278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.87, \"learn_time_ms\": 41528.675}", "{\"n\": 279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.55, \"learn_time_ms\": 41523.69}", "{\"n\": 280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.1, \"learn_time_ms\": 41487.512}", "{\"n\": 281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.77, \"learn_time_ms\": 41465.074}", "{\"n\": 282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.51, \"learn_time_ms\": 41394.606}", "{\"n\": 283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.61, \"learn_time_ms\": 41326.977}", "{\"n\": 284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.63, \"learn_time_ms\": 41329.078}", "{\"n\": 285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.42, \"learn_time_ms\": 41275.974}", "{\"n\": 286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.39, \"learn_time_ms\": 41276.098}", "{\"n\": 287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.09, \"learn_time_ms\": 41203.579}", "{\"n\": 288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.26, \"learn_time_ms\": 41233.591}", "{\"n\": 289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1020.31, \"learn_time_ms\": 41301.809}", "{\"n\": 290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1019.94, \"learn_time_ms\": 41283.396}", "{\"n\": 291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 41169.739}", "{\"n\": 292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1019.15, \"learn_time_ms\": 41192.977}", "{\"n\": 293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.45, \"learn_time_ms\": 41243.561}", "{\"n\": 294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.58, \"learn_time_ms\": 41250.101}", "{\"n\": 295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.37, \"learn_time_ms\": 41300.809}", "{\"n\": 296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.29, \"learn_time_ms\": 41314.027}", "{\"n\": 297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.54, \"learn_time_ms\": 41341.401}", "{\"n\": 298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.0, \"learn_time_ms\": 41339.028}", "{\"n\": 299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1020.79, \"learn_time_ms\": 41289.917}", "{\"n\": 300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.43, \"learn_time_ms\": 41336.749}", "{\"n\": 301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.19, \"learn_time_ms\": 41407.033}", "{\"n\": 302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.48, \"learn_time_ms\": 41460.522}", "{\"n\": 303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.85, \"learn_time_ms\": 41512.312}", "{\"n\": 304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.16, \"learn_time_ms\": 41486.56}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.95, \"learn_time_ms\": 41474.98}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.75, \"learn_time_ms\": 41443.458}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.63, \"learn_time_ms\": 41445.893}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.11, \"learn_time_ms\": 41484.345}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.3, \"learn_time_ms\": 41580.488}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.88, \"learn_time_ms\": 41694.767}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.34, \"learn_time_ms\": 41752.649}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.32, \"learn_time_ms\": 41649.872}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.0, \"learn_time_ms\": 41660.289}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1022.31, \"learn_time_ms\": 41687.876}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.24, \"learn_time_ms\": 41658.966}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1021.05, \"learn_time_ms\": 41665.05}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.77, \"learn_time_ms\": 41744.64}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1023.99, \"learn_time_ms\": 41752.618}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.07, \"learn_time_ms\": 41697.325}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.02, \"learn_time_ms\": 41512.434}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.92, \"learn_time_ms\": 41534.651}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.23, \"learn_time_ms\": 41591.523}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.32, \"learn_time_ms\": 41601.223}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.3, \"learn_time_ms\": 41524.421}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.89, \"learn_time_ms\": 41493.04}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.98, \"learn_time_ms\": 41451.788}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.74, \"learn_time_ms\": 41394.203}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.9, \"learn_time_ms\": 41383.857}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.17, \"learn_time_ms\": 41310.409}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.29, \"learn_time_ms\": 41372.249}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.13, \"learn_time_ms\": 41288.74}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.75, \"learn_time_ms\": 41303.002}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1027.26, \"learn_time_ms\": 41266.085}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.88, \"learn_time_ms\": 41275.806}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.83, \"learn_time_ms\": 41337.778}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.52, \"learn_time_ms\": 41311.078}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.33, \"learn_time_ms\": 41393.343}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.51, \"learn_time_ms\": 41399.548}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.23, \"learn_time_ms\": 41420.919}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.25, \"learn_time_ms\": 41468.652}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.29, \"learn_time_ms\": 41466.017}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1026.0, \"learn_time_ms\": 41485.684}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1026.14, \"learn_time_ms\": 41557.188}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1025.8, \"learn_time_ms\": 41514.188}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1025.77, \"learn_time_ms\": 41511.197}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1025.5, \"learn_time_ms\": 41571.423}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.62, \"learn_time_ms\": 41446.884}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.38, \"learn_time_ms\": 41416.091}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.05, \"learn_time_ms\": 41427.627}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1023.25, \"learn_time_ms\": 41342.837}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1023.11, \"learn_time_ms\": 41357.537}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.6, \"learn_time_ms\": 41334.528}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1024.74, \"learn_time_ms\": 41278.089}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1025.01, \"learn_time_ms\": 41345.351}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.62, \"learn_time_ms\": 41295.463}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1024.74, \"learn_time_ms\": 41252.08}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1025.15, \"learn_time_ms\": 41250.336}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1026.79, \"learn_time_ms\": 41253.296}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1026.76, \"learn_time_ms\": 41184.519}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.78, \"learn_time_ms\": 41138.382}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1027.93, \"learn_time_ms\": 41181.862}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.38, \"learn_time_ms\": 41312.254}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.35, \"learn_time_ms\": 41292.399}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.47, \"learn_time_ms\": 41314.128}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.72, \"learn_time_ms\": 41362.772}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1029.7, \"learn_time_ms\": 41395.708}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1030.87, \"learn_time_ms\": 41472.83}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.67, \"learn_time_ms\": 41422.421}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1031.64, \"learn_time_ms\": 41482.882}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.36, \"learn_time_ms\": 41612.489}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.53, \"learn_time_ms\": 41611.317}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.53, \"learn_time_ms\": 41452.681}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.7, \"learn_time_ms\": 41470.135}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.48, \"learn_time_ms\": 41509.964}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.66, \"learn_time_ms\": 41504.928}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1034.91, \"learn_time_ms\": 41533.444}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.98, \"learn_time_ms\": 41500.716}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1033.99, \"learn_time_ms\": 41560.101}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.33, \"learn_time_ms\": 41594.554}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.99, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1030.09, \"learn_time_ms\": 41486.724}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1032.63, \"learn_time_ms\": 41549.91}", "{\"n\": 382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.57, \"learn_time_ms\": 41608.131}", "{\"n\": 383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.48, \"learn_time_ms\": 41632.216}", "{\"n\": 384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.83, \"learn_time_ms\": 41582.305}", "{\"n\": 385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.61, \"learn_time_ms\": 41602.006}", "{\"n\": 386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.35, \"learn_time_ms\": 41630.456}", "{\"n\": 387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.83, \"learn_time_ms\": 41715.922}", "{\"n\": 388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.61, \"learn_time_ms\": 41698.332}", "{\"n\": 389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.2, \"learn_time_ms\": 41631.875}", "{\"n\": 390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.22, \"learn_time_ms\": 41684.982}", "{\"n\": 391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.27, \"learn_time_ms\": 41646.788}", "{\"n\": 392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.14, \"learn_time_ms\": 41585.364}", "{\"n\": 393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.47, \"learn_time_ms\": 41539.558}", "{\"n\": 394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.57, \"learn_time_ms\": 41513.861}", "{\"n\": 395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.56, \"learn_time_ms\": 41439.923}", "{\"n\": 396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.01, \"learn_time_ms\": 41355.273}", "{\"n\": 397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.11, \"learn_time_ms\": 41245.658}", "{\"n\": 398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.13, \"learn_time_ms\": 41411.33}", "{\"n\": 399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.39, \"learn_time_ms\": 41444.127}", "{\"n\": 400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1037.85, \"learn_time_ms\": 41463.935}", "{\"n\": 401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1038.1, \"learn_time_ms\": 41363.214}", "{\"n\": 402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1036.1, \"learn_time_ms\": 41384.851}", "{\"n\": 403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1035.96, \"learn_time_ms\": 41385.719}", "{\"n\": 404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.3, \"learn_time_ms\": 41396.137}", "{\"n\": 405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.52, \"learn_time_ms\": 41387.46}", "{\"n\": 406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.01, \"learn_time_ms\": 41372.868}", "{\"n\": 407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.01, \"learn_time_ms\": 41346.416}", "{\"n\": 408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1034.05, \"learn_time_ms\": 41133.678}", "{\"n\": 409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.98, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.57, \"learn_time_ms\": 41168.204}", "{\"n\": 410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.28, \"learn_time_ms\": 41120.267}", "{\"n\": 411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1037.41, \"learn_time_ms\": 41160.994}", "{\"n\": 412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1038.14, \"learn_time_ms\": 41240.628}", "{\"n\": 413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.9, \"learn_time_ms\": 41227.174}", "{\"n\": 414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1040.28, \"learn_time_ms\": 41313.522}", "{\"n\": 415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.91, \"learn_time_ms\": 41410.316}", "{\"n\": 416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.14, \"learn_time_ms\": 41505.785}", "{\"n\": 417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.97, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.64, \"learn_time_ms\": 41589.074}", "{\"n\": 418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.72, \"learn_time_ms\": 41687.447}", "{\"n\": 419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1047.79, \"learn_time_ms\": 41672.89}", "{\"n\": 420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1046.29, \"learn_time_ms\": 41714.872}", "{\"n\": 421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1046.96, \"learn_time_ms\": 41774.495}", "{\"n\": 422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1045.26, \"learn_time_ms\": 41706.001}", "{\"n\": 423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1047.66, \"learn_time_ms\": 41712.453}", "{\"n\": 424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.35, \"learn_time_ms\": 41583.129}", "{\"n\": 425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.79, \"learn_time_ms\": 41512.939}", "{\"n\": 426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1051.24, \"learn_time_ms\": 41458.542}", "{\"n\": 427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.92, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1050.86, \"learn_time_ms\": 41441.119}", "{\"n\": 428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.46, \"learn_time_ms\": 41371.322}", "{\"n\": 429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.48, \"learn_time_ms\": 41429.381}", "{\"n\": 430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1060.38, \"learn_time_ms\": 41373.251}", "{\"n\": 431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1059.66, \"learn_time_ms\": 41409.78}", "{\"n\": 432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1056.87, \"learn_time_ms\": 41357.843}", "{\"n\": 433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.9, \"learn_time_ms\": 41461.797}", "{\"n\": 434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1057.08, \"learn_time_ms\": 41502.705}", "{\"n\": 435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.19, \"learn_time_ms\": 41571.928}", "{\"n\": 436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1061.87, \"learn_time_ms\": 41497.491}", "{\"n\": 437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1062.99, \"learn_time_ms\": 41483.367}", "{\"n\": 438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1070.22, \"learn_time_ms\": 41566.74}", "{\"n\": 439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1070.04, \"learn_time_ms\": 41453.066}", "{\"n\": 440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1067.89, \"learn_time_ms\": 41486.028}", "{\"n\": 441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1067.16, \"learn_time_ms\": 41437.334}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1066.51, \"learn_time_ms\": 41463.289}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1065.93, \"learn_time_ms\": 41420.177}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1066.92, \"learn_time_ms\": 41463.76}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1068.78, \"learn_time_ms\": 41377.686}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1069.43, \"learn_time_ms\": 41459.766}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1069.78, \"learn_time_ms\": 41417.048}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1067.44, \"learn_time_ms\": 41368.66}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.85, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1070.78, \"learn_time_ms\": 41422.148}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1064.26, \"learn_time_ms\": 41379.613}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1067.42, \"learn_time_ms\": 41441.833}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1068.03, \"learn_time_ms\": 41468.635}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1067.38, \"learn_time_ms\": 41394.872}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1076.12, \"learn_time_ms\": 41310.145}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.86, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1075.37, \"learn_time_ms\": 41366.884}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1080.1, \"learn_time_ms\": 41331.648}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1080.95, \"learn_time_ms\": 41330.126}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1083.29, \"learn_time_ms\": 41344.328}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1086.66, \"learn_time_ms\": 41301.537}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1085.07, \"learn_time_ms\": 41356.437}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.81, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1086.32, \"learn_time_ms\": 41166.461}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.74, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1097.33, \"learn_time_ms\": 41185.849}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.73, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1100.82, \"learn_time_ms\": 41151.934}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1106.65, \"learn_time_ms\": 41247.764}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1108.66, \"learn_time_ms\": 41186.576}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1112.44, \"learn_time_ms\": 41189.863}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1111.33, \"learn_time_ms\": 41230.031}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1112.79, \"learn_time_ms\": 41203.049}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1113.53, \"learn_time_ms\": 41329.616}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.64, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1117.58, \"learn_time_ms\": 41259.854}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1123.19, \"learn_time_ms\": 41346.75}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1127.52, \"learn_time_ms\": 41337.275}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1130.93, \"learn_time_ms\": 41413.77}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1131.68, \"learn_time_ms\": 41383.482}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1133.88, \"learn_time_ms\": 41471.85}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1142.85, \"learn_time_ms\": 41545.613}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1139.49, \"learn_time_ms\": 41644.682}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1142.07, \"learn_time_ms\": 41749.246}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1151.08, \"learn_time_ms\": 41717.712}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1152.39, \"learn_time_ms\": 41827.715}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1151.39, \"learn_time_ms\": 41800.488}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1151.32, \"learn_time_ms\": 41767.987}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1150.99, \"learn_time_ms\": 41790.395}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1152.78, \"learn_time_ms\": 41777.498}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1142.14, \"learn_time_ms\": 41732.769}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1149.03, \"learn_time_ms\": 41642.536}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1152.72, \"learn_time_ms\": 41530.843}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1146.64, \"learn_time_ms\": 41398.699}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1147.38, \"learn_time_ms\": 41403.28}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1150.53, \"learn_time_ms\": 41361.638}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1148.53, \"learn_time_ms\": 41440.843}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.69, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1150.21, \"learn_time_ms\": 41545.764}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1153.31, \"learn_time_ms\": 41562.022}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1162.59, \"learn_time_ms\": 41606.851}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1170.11, \"learn_time_ms\": 41596.722}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1170.36, \"learn_time_ms\": 41599.736}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1172.0, \"learn_time_ms\": 41654.313}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1172.14, \"learn_time_ms\": 41842.545}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1179.47, \"learn_time_ms\": 41767.946}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1174.91, \"learn_time_ms\": 41752.17}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1175.96, \"learn_time_ms\": 41705.054}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1174.94, \"learn_time_ms\": 41587.697}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.61, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1171.3, \"learn_time_ms\": 41526.982}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1175.28, \"learn_time_ms\": 41586.525}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1173.69, \"learn_time_ms\": 41566.229}", "{\"n\": 506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1175.34, \"learn_time_ms\": 41572.321}", "{\"n\": 507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1175.75, \"learn_time_ms\": 41482.279}", "{\"n\": 508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1179.64, \"learn_time_ms\": 41297.644}", "{\"n\": 509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1183.19, \"learn_time_ms\": 41274.996}", "{\"n\": 510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1182.57, \"learn_time_ms\": 41360.932}", "{\"n\": 511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1179.99, \"learn_time_ms\": 41306.535}", "{\"n\": 512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1178.27, \"learn_time_ms\": 41358.707}", "{\"n\": 513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1179.72, \"learn_time_ms\": 41477.165}", "{\"n\": 514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1182.02, \"learn_time_ms\": 41336.811}", "{\"n\": 515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1184.4, \"learn_time_ms\": 41403.336}", "{\"n\": 516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1187.02, \"learn_time_ms\": 41451.09}", "{\"n\": 517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1185.14, \"learn_time_ms\": 41553.206}", "{\"n\": 518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1183.56, \"learn_time_ms\": 41549.244}", "{\"n\": 519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1179.05, \"learn_time_ms\": 41569.78}", "{\"n\": 520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.18, \"learn_time_ms\": 41506.624}", "{\"n\": 521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1179.95, \"learn_time_ms\": 41483.955}", "{\"n\": 522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1179.85, \"learn_time_ms\": 41514.671}", "{\"n\": 523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1175.44, \"learn_time_ms\": 41386.639}", "{\"n\": 524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.11, \"learn_time_ms\": 41436.623}", "{\"n\": 525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1188.2, \"learn_time_ms\": 41364.943}", "{\"n\": 526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1190.9, \"learn_time_ms\": 41388.794}", "{\"n\": 527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.01, \"learn_time_ms\": 41357.667}", "{\"n\": 528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.81, \"learn_time_ms\": 41440.84}", "{\"n\": 529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1184.73, \"learn_time_ms\": 41479.936}", "{\"n\": 530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1188.06, \"learn_time_ms\": 41485.643}", "{\"n\": 531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1187.92, \"learn_time_ms\": 41511.331}", "{\"n\": 532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1183.88, \"learn_time_ms\": 41404.055}", "{\"n\": 533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1185.8, \"learn_time_ms\": 41423.884}", "{\"n\": 534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1184.4, \"learn_time_ms\": 41430.379}", "{\"n\": 535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1181.76, \"learn_time_ms\": 41475.351}", "{\"n\": 536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1184.91, \"learn_time_ms\": 41453.266}", "{\"n\": 537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1192.15, \"learn_time_ms\": 41444.008}", "{\"n\": 538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1196.9, \"learn_time_ms\": 41419.972}", "{\"n\": 539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1193.28, \"learn_time_ms\": 41382.537}", "{\"n\": 540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1192.57, \"learn_time_ms\": 41403.083}", "{\"n\": 541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1194.59, \"learn_time_ms\": 41392.801}", "{\"n\": 542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1196.19, \"learn_time_ms\": 41398.103}", "{\"n\": 543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1180.37, \"learn_time_ms\": 41426.09}", "{\"n\": 544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1177.86, \"learn_time_ms\": 41449.21}", "{\"n\": 545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1180.85, \"learn_time_ms\": 41594.753}", "{\"n\": 546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1183.15, \"learn_time_ms\": 41623.243}", "{\"n\": 547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1189.38, \"learn_time_ms\": 41663.753}", "{\"n\": 548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1180.01, \"learn_time_ms\": 41641.625}", "{\"n\": 549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.59, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1173.36, \"learn_time_ms\": 41644.176}", "{\"n\": 550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.62, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1170.11, \"learn_time_ms\": 41673.031}", "{\"n\": 551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1174.12, \"learn_time_ms\": 41692.46}", "{\"n\": 552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1173.74, \"learn_time_ms\": 41664.142}", "{\"n\": 553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1181.62, \"learn_time_ms\": 41682.838}", "{\"n\": 554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1178.33, \"learn_time_ms\": 41740.264}", "{\"n\": 555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1177.36, \"learn_time_ms\": 41619.163}", "{\"n\": 556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1181.12, \"learn_time_ms\": 41612.223}", "{\"n\": 557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1182.28, \"learn_time_ms\": 41566.484}", "{\"n\": 558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1184.3, \"learn_time_ms\": 41536.525}", "{\"n\": 559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1182.21, \"learn_time_ms\": 41509.741}", "{\"n\": 560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.28, \"learn_time_ms\": 41405.133}", "{\"n\": 561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1185.98, \"learn_time_ms\": 41414.921}", "{\"n\": 562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1181.65, \"learn_time_ms\": 41467.422}", "{\"n\": 563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1182.92, \"learn_time_ms\": 41447.543}", "{\"n\": 564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1183.35, \"learn_time_ms\": 41296.42}", "{\"n\": 565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1188.68, \"learn_time_ms\": 41215.198}", "{\"n\": 566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1187.43, \"learn_time_ms\": 41221.874}", "{\"n\": 567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1191.61, \"learn_time_ms\": 41272.033}", "{\"n\": 568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1192.25, \"learn_time_ms\": 41261.02}", "{\"n\": 569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1188.46, \"learn_time_ms\": 41375.402}", "{\"n\": 570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1185.92, \"learn_time_ms\": 41509.73}", "{\"n\": 571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1186.86, \"learn_time_ms\": 41523.906}", "{\"n\": 572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1187.0, \"learn_time_ms\": 41579.071}", "{\"n\": 573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1198.92, \"learn_time_ms\": 41542.385}", "{\"n\": 574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.31, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1201.42, \"learn_time_ms\": 41635.951}", "{\"n\": 575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1207.69, \"learn_time_ms\": 41696.349}", "{\"n\": 576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1208.27, \"learn_time_ms\": 41591.511}", "{\"n\": 577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1215.77, \"learn_time_ms\": 41469.74}", "{\"n\": 578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1218.97, \"learn_time_ms\": 41533.955}", "{\"n\": 579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.29, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1215.9, \"learn_time_ms\": 41465.581}", "{\"n\": 580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1219.07, \"learn_time_ms\": 41384.857}", "{\"n\": 581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1220.22, \"learn_time_ms\": 41409.584}", "{\"n\": 582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.26, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1225.5, \"learn_time_ms\": 41400.635}", "{\"n\": 583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.23, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1235.6, \"learn_time_ms\": 41421.98}", "{\"n\": 584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1241.46, \"learn_time_ms\": 41320.751}", "{\"n\": 585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1240.35, \"learn_time_ms\": 41295.486}", "{\"n\": 586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1245.29, \"learn_time_ms\": 41348.542}", "{\"n\": 587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1250.77, \"learn_time_ms\": 41374.451}", "{\"n\": 588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1253.52, \"learn_time_ms\": 41384.555}", "{\"n\": 589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1253.47, \"learn_time_ms\": 41423.966}", "{\"n\": 590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1258.41, \"learn_time_ms\": 41399.387}", "{\"n\": 591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1255.24, \"learn_time_ms\": 41341.749}", "{\"n\": 592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.18, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1251.2, \"learn_time_ms\": 41285.648}", "{\"n\": 593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1249.47, \"learn_time_ms\": 41232.562}", "{\"n\": 594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1248.61, \"learn_time_ms\": 41223.445}", "{\"n\": 595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1256.55, \"learn_time_ms\": 41187.23}", "{\"n\": 596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.19, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1250.46, \"learn_time_ms\": 41160.975}", "{\"n\": 597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1251.65, \"learn_time_ms\": 41193.59}", "{\"n\": 598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.23, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1251.23, \"learn_time_ms\": 41167.734}", "{\"n\": 599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1251.21, \"learn_time_ms\": 41096.468}", "{\"n\": 600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1245.56, \"learn_time_ms\": 41112.983}", "{\"n\": 601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1243.98, \"learn_time_ms\": 41067.91}", "{\"n\": 602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1239.64, \"learn_time_ms\": 41104.619}", "{\"n\": 603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.33, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1227.37, \"learn_time_ms\": 41064.649}", "{\"n\": 604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.31, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1232.28, \"learn_time_ms\": 41154.004}", "{\"n\": 605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1230.18, \"learn_time_ms\": 41173.755}", "{\"n\": 606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.32, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1227.74, \"learn_time_ms\": 41260.956}", "{\"n\": 607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1220.69, \"learn_time_ms\": 41209.329}", "{\"n\": 608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1212.83, \"learn_time_ms\": 41181.348}", "{\"n\": 609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1206.89, \"learn_time_ms\": 41299.786}", "{\"n\": 610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1204.89, \"learn_time_ms\": 41310.218}", "{\"n\": 611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1205.16, \"learn_time_ms\": 41303.426}", "{\"n\": 612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1204.62, \"learn_time_ms\": 41358.752}", "{\"n\": 613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1216.51, \"learn_time_ms\": 41495.256}", "{\"n\": 614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1215.47, \"learn_time_ms\": 41465.182}", "{\"n\": 615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1205.78, \"learn_time_ms\": 41456.496}", "{\"n\": 616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1204.61, \"learn_time_ms\": 41408.139}", "{\"n\": 617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1207.32, \"learn_time_ms\": 41479.19}", "{\"n\": 618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1213.24, \"learn_time_ms\": 41510.475}", "{\"n\": 619, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1213.9, \"learn_time_ms\": 41387.868}", "{\"n\": 620, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1206.46, \"learn_time_ms\": 41351.592}", "{\"n\": 621, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1208.65, \"learn_time_ms\": 41415.46}", "{\"n\": 622, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1203.05, \"learn_time_ms\": 41334.875}", "{\"n\": 623, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1199.13, \"learn_time_ms\": 41270.285}", "{\"n\": 624, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1201.42, \"learn_time_ms\": 41325.325}", "{\"n\": 625, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1211.24, \"learn_time_ms\": 41336.494}", "{\"n\": 626, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1214.63, \"learn_time_ms\": 41370.505}", "{\"n\": 627, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1218.17, \"learn_time_ms\": 41429.207}", "{\"n\": 628, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1221.91, \"learn_time_ms\": 41383.982}", "{\"n\": 629, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1220.69, \"learn_time_ms\": 41343.691}", "{\"n\": 630, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1231.09, \"learn_time_ms\": 41396.36}", "{\"n\": 631, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1230.19, \"learn_time_ms\": 41460.289}", "{\"n\": 632, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1233.91, \"learn_time_ms\": 41424.1}", "{\"n\": 633, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1240.88, \"learn_time_ms\": 41492.529}", "{\"n\": 634, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.38, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1237.92, \"learn_time_ms\": 41422.618}", "{\"n\": 635, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.34, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1241.53, \"learn_time_ms\": 41377.527}", "{\"n\": 636, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.33, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1244.58, \"learn_time_ms\": 41305.604}", "{\"n\": 637, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.33, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1242.03, \"learn_time_ms\": 41253.776}", "{\"n\": 638, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1239.45, \"learn_time_ms\": 41228.435}", "{\"n\": 639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1239.45, \"learn_time_ms\": 41262.755}", "{\"n\": 640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1241.54, \"learn_time_ms\": 41289.43}", "{\"n\": 641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1242.7, \"learn_time_ms\": 41310.386}", "{\"n\": 642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1257.98, \"learn_time_ms\": 41396.914}", "{\"n\": 643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1261.18, \"learn_time_ms\": 41446.048}", "{\"n\": 644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1267.99, \"learn_time_ms\": 41540.048}", "{\"n\": 645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1267.68, \"learn_time_ms\": 41589.642}", "{\"n\": 646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1266.91, \"learn_time_ms\": 41615.448}", "{\"n\": 647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.23, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1270.98, \"learn_time_ms\": 41566.455}", "{\"n\": 648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1272.07, \"learn_time_ms\": 41661.46}", "{\"n\": 649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1283.02, \"learn_time_ms\": 41644.799}", "{\"n\": 650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1278.71, \"learn_time_ms\": 41600.717}", "{\"n\": 651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1274.56, \"learn_time_ms\": 41464.101}", "{\"n\": 652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1276.74, \"learn_time_ms\": 41401.574}", "{\"n\": 653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.19, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1276.27, \"learn_time_ms\": 41277.448}", "{\"n\": 654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.18, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1279.94, \"learn_time_ms\": 41139.552}", "{\"n\": 655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1278.78, \"learn_time_ms\": 41136.659}", "{\"n\": 656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.15, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1280.14, \"learn_time_ms\": 41177.112}", "{\"n\": 657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1279.77, \"learn_time_ms\": 41231.863}", "{\"n\": 658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1287.56, \"learn_time_ms\": 41300.482}", "{\"n\": 659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1284.43, \"learn_time_ms\": 41345.885}", "{\"n\": 660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1294.8, \"learn_time_ms\": 41309.831}", "{\"n\": 661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1294.75, \"learn_time_ms\": 41409.403}", "{\"n\": 662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1292.67, \"learn_time_ms\": 41442.986}", "{\"n\": 663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1293.79, \"learn_time_ms\": 41388.343}", "{\"n\": 664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1291.07, \"learn_time_ms\": 41437.332}", "{\"n\": 665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1287.79, \"learn_time_ms\": 41521.211}", "{\"n\": 666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1287.99, \"learn_time_ms\": 41596.437}", "{\"n\": 667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1292.61, \"learn_time_ms\": 41582.022}", "{\"n\": 668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1289.07, \"learn_time_ms\": 41484.35}", "{\"n\": 669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1290.82, \"learn_time_ms\": 41497.153}", "{\"n\": 670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1290.82, \"learn_time_ms\": 41627.943}", "{\"n\": 671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1289.28, \"learn_time_ms\": 41561.141}", "{\"n\": 672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1292.26, \"learn_time_ms\": 41658.068}", "{\"n\": 673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1300.71, \"learn_time_ms\": 41677.915}", "{\"n\": 674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1308.84, \"learn_time_ms\": 41755.999}", "{\"n\": 675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1306.21, \"learn_time_ms\": 41729.089}", "{\"n\": 676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1305.96, \"learn_time_ms\": 41544.916}", "{\"n\": 677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1311.63, \"learn_time_ms\": 41550.31}", "{\"n\": 678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1310.11, \"learn_time_ms\": 41661.805}", "{\"n\": 679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.09, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1309.05, \"learn_time_ms\": 41693.69}", "{\"n\": 680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1317.16, \"learn_time_ms\": 41543.981}", "{\"n\": 681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1310.17, \"learn_time_ms\": 41681.704}", "{\"n\": 682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.09, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1315.18, \"learn_time_ms\": 41584.608}", "{\"n\": 683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1313.68, \"learn_time_ms\": 41676.342}", "{\"n\": 684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1309.08, \"learn_time_ms\": 41562.575}", "{\"n\": 685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1303.4, \"learn_time_ms\": 41486.684}", "{\"n\": 686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.14, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1302.34, \"learn_time_ms\": 41678.259}", "{\"n\": 687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1299.13, \"learn_time_ms\": 41667.414}", "{\"n\": 688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1309.84, \"learn_time_ms\": 41532.037}", "{\"n\": 689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1312.51, \"learn_time_ms\": 41496.684}", "{\"n\": 690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1315.6, \"learn_time_ms\": 41622.121}", "{\"n\": 691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1318.26, \"learn_time_ms\": 41574.501}", "{\"n\": 692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1316.94, \"learn_time_ms\": 41631.901}", "{\"n\": 693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1320.04, \"learn_time_ms\": 41614.414}", "{\"n\": 694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.11, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1326.2, \"learn_time_ms\": 41654.383}", "{\"n\": 695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.1, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1329.3, \"learn_time_ms\": 41664.778}", "{\"n\": 696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.07, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1330.02, \"learn_time_ms\": 41519.282}", "{\"n\": 697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.05, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1333.82, \"learn_time_ms\": 41538.794}", "{\"n\": 698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.02, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1342.74, \"learn_time_ms\": 41567.936}", "{\"n\": 699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.99, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1350.63, \"learn_time_ms\": 41526.744}", "{\"n\": 700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.02, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1345.03, \"learn_time_ms\": 41380.948}", "{\"n\": 701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.03, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1346.69, \"learn_time_ms\": 41301.575}", "{\"n\": 702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.01, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1340.26, \"learn_time_ms\": 41265.732}", "{\"n\": 703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1341.56, \"learn_time_ms\": 41201.9}", "{\"n\": 704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1350.56, \"learn_time_ms\": 41210.011}", "{\"n\": 705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1356.63, \"learn_time_ms\": 41251.746}", "{\"n\": 706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1355.68, \"learn_time_ms\": 41318.332}", "{\"n\": 707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1359.99, \"learn_time_ms\": 41296.436}", "{\"n\": 708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.92, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1358.91, \"learn_time_ms\": 41346.82}", "{\"n\": 709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.88, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1371.5, \"learn_time_ms\": 41332.739}", "{\"n\": 710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.9, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1370.99, \"learn_time_ms\": 41343.098}", "{\"n\": 711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1378.22, \"learn_time_ms\": 41363.075}", "{\"n\": 712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1375.94, \"learn_time_ms\": 41254.454}", "{\"n\": 713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1380.5, \"learn_time_ms\": 41265.929}", "{\"n\": 714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.79, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1397.0, \"learn_time_ms\": 41303.878}", "{\"n\": 715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.81, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1397.84, \"learn_time_ms\": 41223.17}", "{\"n\": 716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1407.47, \"learn_time_ms\": 41260.633}", "{\"n\": 717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.79, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1402.9, \"learn_time_ms\": 41186.177}", "{\"n\": 718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1401.48, \"learn_time_ms\": 41101.242}", "{\"n\": 719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.82, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1399.1, \"learn_time_ms\": 41114.755}", "{\"n\": 720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.79, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1405.05, \"learn_time_ms\": 41224.77}", "{\"n\": 721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1414.35, \"learn_time_ms\": 41248.209}", "{\"n\": 722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1412.07, \"learn_time_ms\": 41386.545}", "{\"n\": 723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.79, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1404.92, \"learn_time_ms\": 41358.17}", "{\"n\": 724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.79, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1404.67, \"learn_time_ms\": 41276.601}", "{\"n\": 725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1400.67, \"learn_time_ms\": 41410.503}", "{\"n\": 726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1397.1, \"learn_time_ms\": 41374.17}", "{\"n\": 727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1394.93, \"learn_time_ms\": 41412.328}", "{\"n\": 728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1394.44, \"learn_time_ms\": 41492.522}", "{\"n\": 729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.9, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1393.6, \"learn_time_ms\": 41547.345}", "{\"n\": 730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.88, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1395.1, \"learn_time_ms\": 41465.528}", "{\"n\": 731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1402.31, \"learn_time_ms\": 41453.304}", "{\"n\": 732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.9, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1407.81, \"learn_time_ms\": 41400.798}", "{\"n\": 733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.88, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1417.9, \"learn_time_ms\": 41455.388}", "{\"n\": 734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.88, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1424.65, \"learn_time_ms\": 41457.131}", "{\"n\": 735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1431.97, \"learn_time_ms\": 41384.496}", "{\"n\": 736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1434.16, \"learn_time_ms\": 41316.069}", "{\"n\": 737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1440.45, \"learn_time_ms\": 41409.661}", "{\"n\": 738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1440.45, \"learn_time_ms\": 41364.058}", "{\"n\": 739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.97, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1428.95, \"learn_time_ms\": 41281.688}", "{\"n\": 740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1435.94, \"learn_time_ms\": 41261.344}", "{\"n\": 741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1442.46, \"learn_time_ms\": 41274.846}", "{\"n\": 742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1449.43, \"learn_time_ms\": 41194.942}", "{\"n\": 743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1449.43, \"learn_time_ms\": 41244.456}", "{\"n\": 744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.98, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1439.79, \"learn_time_ms\": 41347.84}", "{\"n\": 745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.99, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1445.78, \"learn_time_ms\": 41402.934}", "{\"n\": 746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.98, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1447.41, \"learn_time_ms\": 41498.554}", "{\"n\": 747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.98, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1459.68, \"learn_time_ms\": 41472.138}", "{\"n\": 748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.95, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1466.64, \"learn_time_ms\": 41438.637}", "{\"n\": 749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.98, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1466.01, \"learn_time_ms\": 41396.386}", "{\"n\": 750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1477.15, \"learn_time_ms\": 41388.464}", "{\"n\": 751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.95, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1473.22, \"learn_time_ms\": 41377.24}", "{\"n\": 752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1472.85, \"learn_time_ms\": 41445.099}", "{\"n\": 753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.95, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1484.62, \"learn_time_ms\": 41412.056}", "{\"n\": 754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.95, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1484.62, \"learn_time_ms\": 41336.279}", "{\"n\": 755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1502.99, \"learn_time_ms\": 41254.331}", "{\"n\": 756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1502.45, \"learn_time_ms\": 41134.069}", "{\"n\": 757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.91, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1506.45, \"learn_time_ms\": 41045.676}", "{\"n\": 758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1516.67, \"learn_time_ms\": 41036.291}", "{\"n\": 759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1519.46, \"learn_time_ms\": 41098.334}", "{\"n\": 760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.87, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1523.61, \"learn_time_ms\": 41147.113}", "{\"n\": 761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.85, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1530.81, \"learn_time_ms\": 41196.122}", "{\"n\": 762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.85, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1530.72, \"learn_time_ms\": 41219.773}", "{\"n\": 763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.85, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1526.23, \"learn_time_ms\": 41177.132}", "{\"n\": 764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.88, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1519.56, \"learn_time_ms\": 41148.19}", "{\"n\": 765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.89, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1523.6, \"learn_time_ms\": 41114.877}", "{\"n\": 766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.94, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1513.87, \"learn_time_ms\": 41145.391}", "{\"n\": 767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.94, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1517.77, \"learn_time_ms\": 41205.161}", "{\"n\": 768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.93, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1523.9, \"learn_time_ms\": 41223.123}", "{\"n\": 769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.86, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1527.73, \"learn_time_ms\": 41252.985}", "{\"n\": 770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.85, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1529.54, \"learn_time_ms\": 41285.092}", "{\"n\": 771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1544.47, \"learn_time_ms\": 41257.368}", "{\"n\": 772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.78, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1552.15, \"learn_time_ms\": 41294.82}", "{\"n\": 773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.77, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1554.66, \"learn_time_ms\": 41323.243}", "{\"n\": 774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.75, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1563.9, \"learn_time_ms\": 41389.873}", "{\"n\": 775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.71, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1568.79, \"learn_time_ms\": 41522.59}", "{\"n\": 776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1574.24, \"learn_time_ms\": 41567.271}", "{\"n\": 777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.65, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1590.3, \"learn_time_ms\": 41567.883}", "{\"n\": 778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.63, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1591.42, \"learn_time_ms\": 41567.445}", "{\"n\": 779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1603.47, \"learn_time_ms\": 41622.585}", "{\"n\": 780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.52, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1604.12, \"learn_time_ms\": 41574.946}", "{\"n\": 781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.53, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1603.67, \"learn_time_ms\": 41548.398}", "{\"n\": 782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1614.87, \"learn_time_ms\": 41420.764}", "{\"n\": 783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.51, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1617.33, \"learn_time_ms\": 41455.795}", "{\"n\": 784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1628.55, \"learn_time_ms\": 41460.914}", "{\"n\": 785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1639.22, \"learn_time_ms\": 41322.274}", "{\"n\": 786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.43, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1642.88, \"learn_time_ms\": 41349.612}", "{\"n\": 787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.42, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1643.82, \"learn_time_ms\": 41337.035}", "{\"n\": 788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.43, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1643.02, \"learn_time_ms\": 41303.775}", "{\"n\": 789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.39, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1650.58, \"learn_time_ms\": 41244.434}", "{\"n\": 790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1650.21, \"learn_time_ms\": 41287.655}", "{\"n\": 791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1674.48, \"learn_time_ms\": 41327.615}", "{\"n\": 792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1673.23, \"learn_time_ms\": 41356.003}", "{\"n\": 793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1675.33, \"learn_time_ms\": 41416.545}", "{\"n\": 794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1675.45, \"learn_time_ms\": 41426.917}", "{\"n\": 795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1677.12, \"learn_time_ms\": 41513.382}", "{\"n\": 796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1677.42, \"learn_time_ms\": 41510.573}", "{\"n\": 797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1689.52, \"learn_time_ms\": 41521.602}", "{\"n\": 798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1695.52, \"learn_time_ms\": 41633.966}", "{\"n\": 799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1697.85, \"learn_time_ms\": 41592.86}", "{\"n\": 800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1707.08, \"learn_time_ms\": 41633.101}", "{\"n\": 801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.1, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1719.31, \"learn_time_ms\": 41579.655}", "{\"n\": 802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1731.34, \"learn_time_ms\": 41622.213}", "{\"n\": 803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1731.34, \"learn_time_ms\": 41565.254}", "{\"n\": 804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.96, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1754.47, \"learn_time_ms\": 41581.008}", "{\"n\": 805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1764.71, \"learn_time_ms\": 41576.228}", "{\"n\": 806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1764.71, \"learn_time_ms\": 41539.652}", "{\"n\": 807, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1769.16, \"learn_time_ms\": 41609.364}", "{\"n\": 808, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.02, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1771.99, \"learn_time_ms\": 41569.171}", "{\"n\": 809, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1765.8, \"learn_time_ms\": 41646.604}", "{\"n\": 810, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1770.09, \"learn_time_ms\": 41543.901}", "{\"n\": 811, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1776.45, \"learn_time_ms\": 41503.946}", "{\"n\": 812, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1782.97, \"learn_time_ms\": 41487.383}", "{\"n\": 813, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.06, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1780.56, \"learn_time_ms\": 41465.255}", "{\"n\": 814, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1780.78, \"learn_time_ms\": 41490.498}", "{\"n\": 815, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1772.23, \"learn_time_ms\": 41421.529}", "{\"n\": 816, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1779.4, \"learn_time_ms\": 41411.567}", "{\"n\": 817, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1786.04, \"learn_time_ms\": 41314.701}", "{\"n\": 818, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1793.17, \"learn_time_ms\": 41263.76}", "{\"n\": 819, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.01, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1798.29, \"learn_time_ms\": 41306.62}", "{\"n\": 820, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1793.05, \"learn_time_ms\": 41332.161}", "{\"n\": 821, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1788.89, \"learn_time_ms\": 41378.377}", "{\"n\": 822, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.05, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1788.89, \"learn_time_ms\": 41442.011}", "{\"n\": 823, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1802.43, \"learn_time_ms\": 41396.619}", "{\"n\": 824, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1805.68, \"learn_time_ms\": 41339.943}", "{\"n\": 825, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1803.54, \"learn_time_ms\": 41359.459}", "{\"n\": 826, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1824.42, \"learn_time_ms\": 41516.649}", "{\"n\": 827, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1829.92, \"learn_time_ms\": 41543.775}", "{\"n\": 828, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1832.17, \"learn_time_ms\": 41596.036}", "{\"n\": 829, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1822.07, \"learn_time_ms\": 41561.465}", "{\"n\": 830, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1822.07, \"learn_time_ms\": 41609.643}", "{\"n\": 831, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1835.79, \"learn_time_ms\": 41676.104}", "{\"n\": 832, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1837.89, \"learn_time_ms\": 41633.769}", "{\"n\": 833, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1841.7, \"learn_time_ms\": 41664.667}", "{\"n\": 834, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1851.31, \"learn_time_ms\": 41708.283}", "{\"n\": 835, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1856.03, \"learn_time_ms\": 41817.308}", "{\"n\": 836, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1850.07, \"learn_time_ms\": 41733.011}", "{\"n\": 837, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1852.59, \"learn_time_ms\": 41778.617}", "{\"n\": 838, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1847.84, \"learn_time_ms\": 41761.364}", "{\"n\": 839, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1841.62, \"learn_time_ms\": 41738.999}", "{\"n\": 840, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1842.09, \"learn_time_ms\": 41694.975}", "{\"n\": 841, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1852.87, \"learn_time_ms\": 41659.468}", "{\"n\": 842, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1836.7, \"learn_time_ms\": 41647.977}", "{\"n\": 843, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1841.45, \"learn_time_ms\": 41597.497}", "{\"n\": 844, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1841.7, \"learn_time_ms\": 41534.19}", "{\"n\": 845, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.95, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1847.46, \"learn_time_ms\": 41435.812}", "{\"n\": 846, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1851.98, \"learn_time_ms\": 41419.051}", "{\"n\": 847, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1851.17, \"learn_time_ms\": 41444.97}", "{\"n\": 848, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1854.63, \"learn_time_ms\": 41486.11}", "{\"n\": 849, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.8, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1852.15, \"learn_time_ms\": 41498.594}", "{\"n\": 850, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.8, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1851.08, \"learn_time_ms\": 41552.202}", "{\"n\": 851, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1845.3, \"learn_time_ms\": 41520.806}", "{\"n\": 852, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1858.96, \"learn_time_ms\": 41546.878}", "{\"n\": 853, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1858.96, \"learn_time_ms\": 41676.582}", "{\"n\": 854, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1873.67, \"learn_time_ms\": 41672.963}", "{\"n\": 855, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1866.55, \"learn_time_ms\": 41734.164}", "{\"n\": 856, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1866.55, \"learn_time_ms\": 41703.928}", "{\"n\": 857, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1868.32, \"learn_time_ms\": 41588.101}", "{\"n\": 858, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1873.42, \"learn_time_ms\": 41530.119}", "{\"n\": 859, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1873.42, \"learn_time_ms\": 41529.347}", "{\"n\": 860, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1873.94, \"learn_time_ms\": 41523.457}", "{\"n\": 861, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1859.98, \"learn_time_ms\": 41534.359}", "{\"n\": 862, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1869.4, \"learn_time_ms\": 41460.039}", "{\"n\": 863, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1878.15, \"learn_time_ms\": 41427.099}", "{\"n\": 864, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1868.09, \"learn_time_ms\": 41531.543}", "{\"n\": 865, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1869.68, \"learn_time_ms\": 41555.409}", "{\"n\": 866, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1856.18, \"learn_time_ms\": 41518.296}", "{\"n\": 867, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.79, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1855.5, \"learn_time_ms\": 41633.026}", "{\"n\": 868, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1864.01, \"learn_time_ms\": 41661.589}", "{\"n\": 869, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1860.23, \"learn_time_ms\": 41604.272}", "{\"n\": 870, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1859.56, \"learn_time_ms\": 41538.193}", "{\"n\": 871, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1863.72, \"learn_time_ms\": 41524.817}", "{\"n\": 872, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1868.71, \"learn_time_ms\": 41767.104}", "{\"n\": 873, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1871.94, \"learn_time_ms\": 41656.991}", "{\"n\": 874, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1871.54, \"learn_time_ms\": 41512.565}", "{\"n\": 875, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1887.59, \"learn_time_ms\": 41468.988}", "{\"n\": 876, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.62, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1886.88, \"learn_time_ms\": 41521.673}", "{\"n\": 877, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.61, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1884.66, \"learn_time_ms\": 41508.149}", "{\"n\": 878, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.62, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1891.68, \"learn_time_ms\": 41443.513}", "{\"n\": 879, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1897.1, \"learn_time_ms\": 41443.624}", "{\"n\": 880, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1886.41, \"learn_time_ms\": 41491.701}", "{\"n\": 881, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1888.6, \"learn_time_ms\": 41524.146}", "{\"n\": 882, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1894.66, \"learn_time_ms\": 41333.991}", "{\"n\": 883, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1897.64, \"learn_time_ms\": 41431.405}", "{\"n\": 884, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1900.01, \"learn_time_ms\": 41405.669}", "{\"n\": 885, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.52, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1902.16, \"learn_time_ms\": 41370.428}", "{\"n\": 886, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1904.82, \"learn_time_ms\": 41296.261}", "{\"n\": 887, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.53, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1911.92, \"learn_time_ms\": 41236.22}", "{\"n\": 888, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.49, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1924.44, \"learn_time_ms\": 41261.611}", "{\"n\": 889, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1926.33, \"learn_time_ms\": 41292.115}", "{\"n\": 890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.42, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1941.01, \"learn_time_ms\": 41285.114}", "{\"n\": 891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.41, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1943.23, \"learn_time_ms\": 41183.831}", "{\"n\": 892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1943.68, \"learn_time_ms\": 41164.431}", "{\"n\": 893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.38, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1946.13, \"learn_time_ms\": 41145.285}", "{\"n\": 894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.4, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1946.05, \"learn_time_ms\": 41321.067}", "{\"n\": 895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1941.73, \"learn_time_ms\": 41437.684}", "{\"n\": 896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1943.77, \"learn_time_ms\": 41463.068}", "{\"n\": 897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.45, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1946.12, \"learn_time_ms\": 41477.548}", "{\"n\": 898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.42, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1943.59, \"learn_time_ms\": 41517.194}", "{\"n\": 899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1949.64, \"learn_time_ms\": 41562.29}", "{\"n\": 900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1956.06, \"learn_time_ms\": 41623.618}", "{\"n\": 901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1964.72, \"learn_time_ms\": 41703.58}", "{\"n\": 902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.36, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1959.12, \"learn_time_ms\": 41738.886}", "{\"n\": 903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1966.46, \"learn_time_ms\": 41781.756}", "{\"n\": 904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.29, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1966.87, \"learn_time_ms\": 41663.943}", "{\"n\": 905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.29, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1965.1, \"learn_time_ms\": 41534.786}", "{\"n\": 906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1967.85, \"learn_time_ms\": 41518.995}", "{\"n\": 907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1982.19, \"learn_time_ms\": 41560.719}", "{\"n\": 908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1994.64, \"learn_time_ms\": 41556.452}", "{\"n\": 909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1991.8, \"learn_time_ms\": 41494.798}", "{\"n\": 910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1997.17, \"learn_time_ms\": 41451.723}", "{\"n\": 911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2006.16, \"learn_time_ms\": 41391.602}", "{\"n\": 912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.07, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2017.65, \"learn_time_ms\": 41325.072}", "{\"n\": 913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2024.59, \"learn_time_ms\": 41283.758}", "{\"n\": 914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2032.74, \"learn_time_ms\": 41333.747}", "{\"n\": 915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2027.14, \"learn_time_ms\": 41398.405}", "{\"n\": 916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2025.76, \"learn_time_ms\": 41467.334}", "{\"n\": 917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2025.76, \"learn_time_ms\": 41508.107}", "{\"n\": 918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2025.99, \"learn_time_ms\": 41560.411}", "{\"n\": 919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2031.72, \"learn_time_ms\": 41552.957}", "{\"n\": 920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2025.81, \"learn_time_ms\": 41557.373}", "{\"n\": 921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2028.26, \"learn_time_ms\": 41570.927}", "{\"n\": 922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2039.8, \"learn_time_ms\": 41693.468}", "{\"n\": 923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2041.29, \"learn_time_ms\": 41599.63}", "{\"n\": 924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2039.37, \"learn_time_ms\": 41554.401}", "{\"n\": 925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2036.43, \"learn_time_ms\": 41589.82}", "{\"n\": 926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2040.85, \"learn_time_ms\": 41560.412}", "{\"n\": 927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2039.69, \"learn_time_ms\": 41435.51}", "{\"n\": 928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2039.66, \"learn_time_ms\": 41386.06}", "{\"n\": 929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2040.05, \"learn_time_ms\": 41396.061}", "{\"n\": 930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2047.45, \"learn_time_ms\": 41431.011}", "{\"n\": 931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.09, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2034.04, \"learn_time_ms\": 41560.111}", "{\"n\": 932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2018.68, \"learn_time_ms\": 41473.193}", "{\"n\": 933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2015.63, \"learn_time_ms\": 41619.948}", "{\"n\": 934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2021.11, \"learn_time_ms\": 41615.34}", "{\"n\": 935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.25, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2012.2, \"learn_time_ms\": 41529.113}", "{\"n\": 936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2022.7, \"learn_time_ms\": 41539.92}", "{\"n\": 937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2026.86, \"learn_time_ms\": 41633.483}", "{\"n\": 938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2032.46, \"learn_time_ms\": 41656.854}", "{\"n\": 939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2035.39, \"learn_time_ms\": 41786.464}", "{\"n\": 940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2035.39, \"learn_time_ms\": 41702.579}", "{\"n\": 941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2038.13, \"learn_time_ms\": 41638.977}", "{\"n\": 942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2038.3, \"learn_time_ms\": 41696.826}", "{\"n\": 943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2038.57, \"learn_time_ms\": 41548.705}", "{\"n\": 944, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2036.56, \"learn_time_ms\": 41593.925}", "{\"n\": 945, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2043.89, \"learn_time_ms\": 41604.818}", "{\"n\": 946, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2052.76, \"learn_time_ms\": 41562.517}", "{\"n\": 947, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2055.84, \"learn_time_ms\": 41468.543}", "{\"n\": 948, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2057.03, \"learn_time_ms\": 41423.771}", "{\"n\": 949, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2053.64, \"learn_time_ms\": 41313.873}", "{\"n\": 950, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2052.55, \"learn_time_ms\": 41319.907}", "{\"n\": 951, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2055.42, \"learn_time_ms\": 41313.535}", "{\"n\": 952, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2052.4, \"learn_time_ms\": 41264.316}", "{\"n\": 953, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2046.18, \"learn_time_ms\": 41356.123}", "{\"n\": 954, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2046.18, \"learn_time_ms\": 41363.067}", "{\"n\": 955, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2034.63, \"learn_time_ms\": 41401.618}", "{\"n\": 956, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2033.63, \"learn_time_ms\": 41397.571}", "{\"n\": 957, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2033.63, \"learn_time_ms\": 41414.134}", "{\"n\": 958, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.29, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2031.73, \"learn_time_ms\": 41391.419}", "{\"n\": 959, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2028.36, \"learn_time_ms\": 41489.767}", "{\"n\": 960, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2030.17, \"learn_time_ms\": 41567.598}", "{\"n\": 961, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.28, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2032.32, \"learn_time_ms\": 41600.772}", "{\"n\": 962, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2038.97, \"learn_time_ms\": 41593.638}", "{\"n\": 963, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2041.82, \"learn_time_ms\": 41643.932}", "{\"n\": 964, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2041.82, \"learn_time_ms\": 41736.441}", "{\"n\": 965, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2048.85, \"learn_time_ms\": 41760.942}", "{\"n\": 966, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2047.68, \"learn_time_ms\": 41868.326}", "{\"n\": 967, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2051.59, \"learn_time_ms\": 42014.187}", "{\"n\": 968, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2052.03, \"learn_time_ms\": 42069.313}", "{\"n\": 969, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2053.14, \"learn_time_ms\": 42043.693}", "{\"n\": 970, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2053.68, \"learn_time_ms\": 42055.136}", "{\"n\": 971, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2058.02, \"learn_time_ms\": 42010.769}", "{\"n\": 972, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2053.7, \"learn_time_ms\": 41995.957}", "{\"n\": 973, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.1, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2055.0, \"learn_time_ms\": 41919.088}", "{\"n\": 974, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.07, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2058.22, \"learn_time_ms\": 41816.414}", "{\"n\": 975, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2061.97, \"learn_time_ms\": 41771.572}", "{\"n\": 976, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2057.73, \"learn_time_ms\": 41750.83}", "{\"n\": 977, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2060.39, \"learn_time_ms\": 41578.251}", "{\"n\": 978, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2067.75, \"learn_time_ms\": 41532.902}", "{\"n\": 979, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2062.38, \"learn_time_ms\": 41488.42}", "{\"n\": 980, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2062.06, \"learn_time_ms\": 41406.006}", "{\"n\": 981, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2060.0, \"learn_time_ms\": 41355.703}", "{\"n\": 982, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2060.16, \"learn_time_ms\": 41484.688}", "{\"n\": 983, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2061.16, \"learn_time_ms\": 41468.239}", "{\"n\": 984, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2062.47, \"learn_time_ms\": 41430.297}", "{\"n\": 985, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2065.94, \"learn_time_ms\": 41509.617}", "{\"n\": 986, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2068.47, \"learn_time_ms\": 41434.885}", "{\"n\": 987, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2072.5, \"learn_time_ms\": 41489.107}", "{\"n\": 988, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2067.43, \"learn_time_ms\": 41508.826}", "{\"n\": 989, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2058.85, \"learn_time_ms\": 41546.283}", "{\"n\": 990, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2051.53, \"learn_time_ms\": 41543.343}", "{\"n\": 991, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2045.43, \"learn_time_ms\": 41719.467}", "{\"n\": 992, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2055.68, \"learn_time_ms\": 41619.008}", "{\"n\": 993, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2055.45, \"learn_time_ms\": 41746.854}", "{\"n\": 994, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2061.81, \"learn_time_ms\": 41761.878}", "{\"n\": 995, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2061.74, \"learn_time_ms\": 41781.974}", "{\"n\": 996, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2061.5, \"learn_time_ms\": 41778.466}", "{\"n\": 997, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.92, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2059.17, \"learn_time_ms\": 41745.53}", "{\"n\": 998, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2060.69, \"learn_time_ms\": 41818.245}", "{\"n\": 999, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.91, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2061.49, \"learn_time_ms\": 41791.396}", "{\"n\": 1000, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.87, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2069.31, \"learn_time_ms\": 41770.838}"]["{\"n\": 1001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 63276.795}", "{\"n\": 1002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 61051.194}", "{\"n\": 1003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 60291.33}", "{\"n\": 1004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 59826.696}", "{\"n\": 1005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 59559.669}", "{\"n\": 1006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 59368.502}", "{\"n\": 1007, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1987.6666666666667, \"learn_time_ms\": 59245.721}", "{\"n\": 1008, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.625, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2109.25, \"learn_time_ms\": 59001.461}", "{\"n\": 1009, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.625, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2109.25, \"learn_time_ms\": 58864.489}", "{\"n\": 1010, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77777777777778, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2066.0, \"learn_time_ms\": 58735.922}", "{\"n\": 1011, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.333333333333332, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2119.866666666667, \"learn_time_ms\": 58127.73}", "{\"n\": 1012, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.375, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2114.0, \"learn_time_ms\": 57996.812}", "{\"n\": 1013, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.375, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2114.0, \"learn_time_ms\": 57717.97}", "{\"n\": 1014, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57894736842105, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2106.8947368421054, \"learn_time_ms\": 57579.433}", "{\"n\": 1015, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.291666666666668, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2105.4583333333335, \"learn_time_ms\": 57346.645}", "{\"n\": 1016, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.291666666666668, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2105.4583333333335, \"learn_time_ms\": 57223.945}", "{\"n\": 1017, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.115384615384617, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2117.3846153846152, \"learn_time_ms\": 57002.509}", "{\"n\": 1018, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.107142857142858, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2130.1071428571427, \"learn_time_ms\": 56975.685}", "{\"n\": 1019, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2140.96875, \"learn_time_ms\": 56820.161}", "{\"n\": 1020, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2140.96875, \"learn_time_ms\": 56855.833}", "{\"n\": 1021, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02857142857143, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2126.342857142857, \"learn_time_ms\": 56800.574}", "{\"n\": 1022, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.871794871794872, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2156.102564102564, \"learn_time_ms\": 56785.546}", "{\"n\": 1023, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2165.175, \"learn_time_ms\": 56831.29}", "{\"n\": 1024, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.926829268292682, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2158.8536585365855, \"learn_time_ms\": 56867.176}", "{\"n\": 1025, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.90909090909091, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2153.7727272727275, \"learn_time_ms\": 56871.794}", "{\"n\": 1026, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8125, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2167.1666666666665, \"learn_time_ms\": 56880.215}", "{\"n\": 1027, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8125, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2167.1666666666665, \"learn_time_ms\": 56827.64}", "{\"n\": 1028, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.88, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2153.26, \"learn_time_ms\": 56850.501}", "{\"n\": 1029, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75925925925926, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2154.6481481481483, \"learn_time_ms\": 56881.469}", "{\"n\": 1030, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.767857142857142, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2156.375, \"learn_time_ms\": 56735.732}", "{\"n\": 1031, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.767857142857142, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2156.375, \"learn_time_ms\": 56671.157}", "{\"n\": 1032, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.838709677419356, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2147.6129032258063, \"learn_time_ms\": 56652.595}", "{\"n\": 1033, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.825396825396826, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2149.126984126984, \"learn_time_ms\": 56652.922}", "{\"n\": 1034, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.828125, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2147.671875, \"learn_time_ms\": 56587.776}", "{\"n\": 1035, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.808823529411764, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2146.6617647058824, \"learn_time_ms\": 56706.526}", "{\"n\": 1036, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.830985915492956, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2136.1830985915494, \"learn_time_ms\": 56713.497}", "{\"n\": 1037, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.819444444444443, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2142.4166666666665, \"learn_time_ms\": 56865.689}", "{\"n\": 1038, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.83783783783784, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2137.864864864865, \"learn_time_ms\": 56920.976}", "{\"n\": 1039, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.82051282051282, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2133.346153846154, \"learn_time_ms\": 56875.451}", "{\"n\": 1040, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.79746835443038, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2136.3924050632913, \"learn_time_ms\": 56824.824}", "{\"n\": 1041, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8125, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2136.175, \"learn_time_ms\": 56921.161}", "{\"n\": 1042, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.783132530120483, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2129.6746987951806, \"learn_time_ms\": 56887.135}", "{\"n\": 1043, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.770114942528735, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2127.2758620689656, \"learn_time_ms\": 56947.292}", "{\"n\": 1044, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.770114942528735, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2127.2758620689656, \"learn_time_ms\": 56933.727}", "{\"n\": 1045, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.797752808988765, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2126.7640449438204, \"learn_time_ms\": 56856.893}", "{\"n\": 1046, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.829787234042552, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2127.2659574468084, \"learn_time_ms\": 56782.52}", "{\"n\": 1047, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.810526315789474, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2133.0315789473684, \"learn_time_ms\": 56735.585}", "{\"n\": 1048, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.810526315789474, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2133.0315789473684, \"learn_time_ms\": 56630.031}", "{\"n\": 1049, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.806122448979593, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2136.081632653061, \"learn_time_ms\": 56657.172}", "{\"n\": 1050, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.8, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2132.05, \"learn_time_ms\": 56721.419}", "{\"n\": 1051, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2137.65, \"learn_time_ms\": 56747.058}", "{\"n\": 1052, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.75, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2137.98, \"learn_time_ms\": 56702.425}", "{\"n\": 1053, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2145.26, \"learn_time_ms\": 56663.54}", "{\"n\": 1054, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.73, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2148.9, \"learn_time_ms\": 56658.842}", "{\"n\": 1055, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.7, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2151.81, \"learn_time_ms\": 56610.662}", "{\"n\": 1056, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.71, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2141.29, \"learn_time_ms\": 56556.091}", "{\"n\": 1057, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.66, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2147.21, \"learn_time_ms\": 56548.53}", "{\"n\": 1058, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2158.34, \"learn_time_ms\": 56533.948}", "{\"n\": 1059, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2160.33, \"learn_time_ms\": 56593.64}", "{\"n\": 1060, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2163.42, \"learn_time_ms\": 56593.284}", "{\"n\": 1061, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2164.93, \"learn_time_ms\": 56542.717}", "{\"n\": 1062, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2170.39, \"learn_time_ms\": 56521.402}", "{\"n\": 1063, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2166.99, \"learn_time_ms\": 56444.252}", "{\"n\": 1064, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2161.28, \"learn_time_ms\": 56466.321}", "{\"n\": 1065, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2161.28, \"learn_time_ms\": 56544.102}", "{\"n\": 1066, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2167.19, \"learn_time_ms\": 56576.048}", "{\"n\": 1067, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.67, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2159.83, \"learn_time_ms\": 56504.869}", "{\"n\": 1068, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.65, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2157.37, \"learn_time_ms\": 56557.663}", "{\"n\": 1069, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.65, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2157.37, \"learn_time_ms\": 56520.555}", "{\"n\": 1070, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2167.67, \"learn_time_ms\": 56584.264}", "{\"n\": 1071, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2161.74, \"learn_time_ms\": 56587.676}", "{\"n\": 1072, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2164.71, \"learn_time_ms\": 56710.321}", "{\"n\": 1073, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2168.48, \"learn_time_ms\": 56871.214}", "{\"n\": 1074, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.69, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2159.43, \"learn_time_ms\": 56807.514}", "{\"n\": 1075, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.68, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2160.06, \"learn_time_ms\": 56850.141}", "{\"n\": 1076, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.65, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2166.48, \"learn_time_ms\": 56818.51}", "{\"n\": 1077, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2171.07, \"learn_time_ms\": 56916.447}", "{\"n\": 1078, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2166.5, \"learn_time_ms\": 56801.202}", "{\"n\": 1079, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2166.5, \"learn_time_ms\": 56804.353}", "{\"n\": 1080, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2169.94, \"learn_time_ms\": 56717.902}", "{\"n\": 1081, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2173.8, \"learn_time_ms\": 56759.419}", "{\"n\": 1082, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2173.5, \"learn_time_ms\": 56622.914}", "{\"n\": 1083, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2171.8, \"learn_time_ms\": 56594.961}", "{\"n\": 1084, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2176.34, \"learn_time_ms\": 56615.793}", "{\"n\": 1085, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2173.05, \"learn_time_ms\": 56623.316}", "{\"n\": 1086, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2176.42, \"learn_time_ms\": 56692.941}", "{\"n\": 1087, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.53, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2178.24, \"learn_time_ms\": 56642.739}", "{\"n\": 1088, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.54, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2190.54, \"learn_time_ms\": 56693.348}", "{\"n\": 1089, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.56, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2188.2, \"learn_time_ms\": 56694.355}", "{\"n\": 1090, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.53, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2189.98, \"learn_time_ms\": 56735.818}", "{\"n\": 1091, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.5, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2193.19, \"learn_time_ms\": 56725.492}", "{\"n\": 1092, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2197.39, \"learn_time_ms\": 56678.241}", "{\"n\": 1093, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.48, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2192.17, \"learn_time_ms\": 56555.883}", "{\"n\": 1094, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2192.43, \"learn_time_ms\": 56585.59}", "{\"n\": 1095, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.5, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2188.91, \"learn_time_ms\": 56507.753}", "{\"n\": 1096, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.49, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2193.89, \"learn_time_ms\": 56443.28}", "{\"n\": 1097, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.51, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2193.86, \"learn_time_ms\": 56475.356}", "{\"n\": 1098, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.46, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2193.75, \"learn_time_ms\": 56517.899}", "{\"n\": 1099, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2188.07, \"learn_time_ms\": 56504.342}", "{\"n\": 1100, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2188.23, \"learn_time_ms\": 56528.368}", "{\"n\": 1101, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2188.23, \"learn_time_ms\": 56585.404}", "{\"n\": 1102, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.35, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2204.92, \"learn_time_ms\": 56739.522}", "{\"n\": 1103, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.39, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2200.9, \"learn_time_ms\": 56885.391}", "{\"n\": 1104, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2197.1, \"learn_time_ms\": 56958.754}", "{\"n\": 1105, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2197.37, \"learn_time_ms\": 57049.831}", "{\"n\": 1106, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2195.16, \"learn_time_ms\": 57083.937}", "{\"n\": 1107, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.45, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2188.63, \"learn_time_ms\": 56989.68}", "{\"n\": 1108, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.44, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2190.58, \"learn_time_ms\": 57054.867}", "{\"n\": 1109, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2196.68, \"learn_time_ms\": 57098.773}", "{\"n\": 1110, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.4, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2202.59, \"learn_time_ms\": 57054.413}", "{\"n\": 1111, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.37, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2205.16, \"learn_time_ms\": 56991.262}", "{\"n\": 1112, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.33, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2207.8, \"learn_time_ms\": 56993.806}", "{\"n\": 1113, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.3, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2210.16, \"learn_time_ms\": 56859.561}", "{\"n\": 1114, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.28, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2210.1, \"learn_time_ms\": 56884.071}", "{\"n\": 1115, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.28, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2210.1, \"learn_time_ms\": 56845.844}", "{\"n\": 1116, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.34, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2203.33, \"learn_time_ms\": 56925.631}", "{\"n\": 1117, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2204.74, \"learn_time_ms\": 56942.716}", "{\"n\": 1118, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2207.81, \"learn_time_ms\": 56822.858}", "{\"n\": 1119, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.29, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2215.81, \"learn_time_ms\": 56826.824}", "{\"n\": 1120, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.22, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2223.39, \"learn_time_ms\": 56840.311}", "{\"n\": 1121, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2221.08, \"learn_time_ms\": 56845.92}", "{\"n\": 1122, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2225.44, \"learn_time_ms\": 56794.421}", "{\"n\": 1123, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -17.19, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2224.41, \"learn_time_ms\": 56800.607}", "{\"n\": 1124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2232.32, \"learn_time_ms\": 56703.393}", "{\"n\": 1125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2232.32, \"learn_time_ms\": 56649.217}", "{\"n\": 1126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2220.29, \"learn_time_ms\": 56640.617}", "{\"n\": 1127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2212.77, \"learn_time_ms\": 56748.966}", "{\"n\": 1128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2212.77, \"learn_time_ms\": 56914.897}", "{\"n\": 1129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2221.65, \"learn_time_ms\": 56864.688}", "{\"n\": 1130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2219.42, \"learn_time_ms\": 56850.303}", "{\"n\": 1131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.22, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2222.92, \"learn_time_ms\": 56866.508}", "{\"n\": 1132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2219.25, \"learn_time_ms\": 56933.865}", "{\"n\": 1133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2219.25, \"learn_time_ms\": 56952.184}", "{\"n\": 1134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2216.92, \"learn_time_ms\": 57042.361}", "{\"n\": 1135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.21, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2224.5, \"learn_time_ms\": 57027.69}", "{\"n\": 1136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.16, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2233.11, \"learn_time_ms\": 56994.035}", "{\"n\": 1137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2229.5, \"learn_time_ms\": 56931.08}", "{\"n\": 1138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2227.31, \"learn_time_ms\": 56736.986}", "{\"n\": 1139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2230.7, \"learn_time_ms\": 56806.026}", "{\"n\": 1140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2235.9, \"learn_time_ms\": 56773.942}", "{\"n\": 1141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2242.38, \"learn_time_ms\": 56785.777}", "{\"n\": 1142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2242.96, \"learn_time_ms\": 56784.669}", "{\"n\": 1143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2238.8, \"learn_time_ms\": 56729.63}", "{\"n\": 1144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2239.9, \"learn_time_ms\": 56715.537}", "{\"n\": 1145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2242.74, \"learn_time_ms\": 56701.985}", "{\"n\": 1146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2242.74, \"learn_time_ms\": 56730.859}", "{\"n\": 1147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2239.51, \"learn_time_ms\": 56681.925}", "{\"n\": 1148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2225.5, \"learn_time_ms\": 56796.241}", "{\"n\": 1149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.06, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2225.64, \"learn_time_ms\": 56761.885}", "{\"n\": 1150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.06, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2225.64, \"learn_time_ms\": 56816.378}", "{\"n\": 1151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2231.51, \"learn_time_ms\": 56710.98}", "{\"n\": 1152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2225.82, \"learn_time_ms\": 56717.105}", "{\"n\": 1153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2225.82, \"learn_time_ms\": 56713.483}", "{\"n\": 1154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2225.82, \"learn_time_ms\": 56656.765}", "{\"n\": 1155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2227.13, \"learn_time_ms\": 56695.037}", "{\"n\": 1156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2211.66, \"learn_time_ms\": 56760.52}", "{\"n\": 1157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2211.66, \"learn_time_ms\": 56872.206}", "{\"n\": 1158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2215.22, \"learn_time_ms\": 56851.255}", "{\"n\": 1159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2218.04, \"learn_time_ms\": 56840.565}", "{\"n\": 1160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2227.32, \"learn_time_ms\": 56789.024}", "{\"n\": 1161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2227.32, \"learn_time_ms\": 56835.974}", "{\"n\": 1162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2214.49, \"learn_time_ms\": 56783.374}", "{\"n\": 1163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2213.6, \"learn_time_ms\": 56868.75}", "{\"n\": 1164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2213.6, \"learn_time_ms\": 56824.761}", "{\"n\": 1165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2204.62, \"learn_time_ms\": 56818.316}", "{\"n\": 1166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2209.0, \"learn_time_ms\": 56695.887}", "{\"n\": 1167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2199.93, \"learn_time_ms\": 56654.976}", "{\"n\": 1168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2199.93, \"learn_time_ms\": 56580.558}", "{\"n\": 1169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.04, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2183.28, \"learn_time_ms\": 56575.449}", "{\"n\": 1170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2184.72, \"learn_time_ms\": 56575.376}", "{\"n\": 1171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.98, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2193.63, \"learn_time_ms\": 56487.774}", "{\"n\": 1172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2199.58, \"learn_time_ms\": 56576.266}", "{\"n\": 1173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2197.58, \"learn_time_ms\": 56569.646}", "{\"n\": 1174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2199.37, \"learn_time_ms\": 56627.913}", "{\"n\": 1175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2203.91, \"learn_time_ms\": 56622.207}", "{\"n\": 1176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2209.97, \"learn_time_ms\": 56711.481}", "{\"n\": 1177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2211.04, \"learn_time_ms\": 56688.728}", "{\"n\": 1178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2206.89, \"learn_time_ms\": 56755.965}", "{\"n\": 1179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2197.76, \"learn_time_ms\": 56767.401}", "{\"n\": 1180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.81, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2208.93, \"learn_time_ms\": 56878.27}", "{\"n\": 1181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2199.52, \"learn_time_ms\": 56902.306}", "{\"n\": 1182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2198.97, \"learn_time_ms\": 56884.213}", "{\"n\": 1183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2202.99, \"learn_time_ms\": 56891.921}", "{\"n\": 1184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2199.58, \"learn_time_ms\": 56894.53}", "{\"n\": 1185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2195.23, \"learn_time_ms\": 56950.084}", "{\"n\": 1186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2197.33, \"learn_time_ms\": 56847.83}", "{\"n\": 1187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2189.3, \"learn_time_ms\": 56920.384}", "{\"n\": 1188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2192.89, \"learn_time_ms\": 56947.97}", "{\"n\": 1189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2191.84, \"learn_time_ms\": 57055.707}", "{\"n\": 1190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2191.84, \"learn_time_ms\": 56904.257}", "{\"n\": 1191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2195.29, \"learn_time_ms\": 56978.969}", "{\"n\": 1192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.93, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2201.59, \"learn_time_ms\": 56896.094}", "{\"n\": 1193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2204.4, \"learn_time_ms\": 56924.246}", "{\"n\": 1194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2206.71, \"learn_time_ms\": 56909.199}", "{\"n\": 1195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2204.37, \"learn_time_ms\": 56873.93}", "{\"n\": 1196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2204.71, \"learn_time_ms\": 56916.38}", "{\"n\": 1197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2202.57, \"learn_time_ms\": 56853.288}", "{\"n\": 1198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2201.1, \"learn_time_ms\": 56769.558}", "{\"n\": 1199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2211.81, \"learn_time_ms\": 56706.956}", "{\"n\": 1200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2209.89, \"learn_time_ms\": 56798.893}", "{\"n\": 1201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.92, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2208.09, \"learn_time_ms\": 56752.877}", "{\"n\": 1202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2203.13, \"learn_time_ms\": 56755.92}", "{\"n\": 1203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2196.47, \"learn_time_ms\": 56771.312}", "{\"n\": 1204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2194.09, \"learn_time_ms\": 56726.256}", "{\"n\": 1205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2191.88, \"learn_time_ms\": 56723.969}", "{\"n\": 1206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2179.98, \"learn_time_ms\": 56618.765}", "{\"n\": 1207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2188.67, \"learn_time_ms\": 56658.858}", "{\"n\": 1208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2180.19, \"learn_time_ms\": 56676.592}", "{\"n\": 1209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2181.58, \"learn_time_ms\": 56615.008}", "{\"n\": 1210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2186.52, \"learn_time_ms\": 56619.398}", "{\"n\": 1211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2186.52, \"learn_time_ms\": 56599.203}", "{\"n\": 1212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2184.84, \"learn_time_ms\": 56643.124}", "{\"n\": 1213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2185.46, \"learn_time_ms\": 56567.596}", "{\"n\": 1214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2186.81, \"learn_time_ms\": 56602.554}", "{\"n\": 1215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2190.06, \"learn_time_ms\": 56620.017}", "{\"n\": 1216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2182.85, \"learn_time_ms\": 56692.767}", "{\"n\": 1217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2181.79, \"learn_time_ms\": 56560.777}", "{\"n\": 1218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2183.48, \"learn_time_ms\": 56547.466}", "{\"n\": 1219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2174.9, \"learn_time_ms\": 56588.269}", "{\"n\": 1220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2174.9, \"learn_time_ms\": 56537.563}", "{\"n\": 1221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2166.11, \"learn_time_ms\": 56604.127}", "{\"n\": 1222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2159.2, \"learn_time_ms\": 56642.323}", "{\"n\": 1223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2163.87, \"learn_time_ms\": 56680.935}", "{\"n\": 1224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2163.87, \"learn_time_ms\": 56705.824}", "{\"n\": 1225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2160.42, \"learn_time_ms\": 56707.458}", "{\"n\": 1226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2154.45, \"learn_time_ms\": 56700.988}", "{\"n\": 1227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2154.51, \"learn_time_ms\": 56855.255}", "{\"n\": 1228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.02, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2156.34, \"learn_time_ms\": 56996.626}", "{\"n\": 1229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.01, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2156.2, \"learn_time_ms\": 56972.061}", "{\"n\": 1230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2161.77, \"learn_time_ms\": 57100.781}", "{\"n\": 1231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2161.77, \"learn_time_ms\": 57120.254}", "{\"n\": 1232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2152.94, \"learn_time_ms\": 57059.873}", "{\"n\": 1233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2155.78, \"learn_time_ms\": 57056.02}", "{\"n\": 1234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.97, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2146.07, \"learn_time_ms\": 57010.371}", "{\"n\": 1235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.94, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2143.17, \"learn_time_ms\": 57068.291}", "{\"n\": 1236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2140.46, \"learn_time_ms\": 57128.335}", "{\"n\": 1237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2134.72, \"learn_time_ms\": 57104.363}", "{\"n\": 1238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2147.92, \"learn_time_ms\": 56934.286}", "{\"n\": 1239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.81, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2145.56, \"learn_time_ms\": 56919.27}", "{\"n\": 1240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2143.11, \"learn_time_ms\": 56829.544}", "{\"n\": 1241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2143.6, \"learn_time_ms\": 56753.244}", "{\"n\": 1242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2151.94, \"learn_time_ms\": 56760.941}", "{\"n\": 1243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2146.49, \"learn_time_ms\": 56808.636}", "{\"n\": 1244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2148.57, \"learn_time_ms\": 56890.214}", "{\"n\": 1245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2153.16, \"learn_time_ms\": 56789.545}", "{\"n\": 1246, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2160.51, \"learn_time_ms\": 56738.563}", "{\"n\": 1247, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.72, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2163.48, \"learn_time_ms\": 56749.461}", "{\"n\": 1248, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2164.84, \"learn_time_ms\": 56892.419}", "{\"n\": 1249, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2167.34, \"learn_time_ms\": 56925.165}", "{\"n\": 1250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.8, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2175.02, \"learn_time_ms\": 56971.592}", "{\"n\": 1251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.8, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2175.02, \"learn_time_ms\": 57008.886}", "{\"n\": 1252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.8, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2183.8, \"learn_time_ms\": 57001.804}", "{\"n\": 1253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2174.42, \"learn_time_ms\": 56951.876}", "{\"n\": 1254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2176.06, \"learn_time_ms\": 56992.611}", "{\"n\": 1255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.81, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2177.76, \"learn_time_ms\": 57029.488}", "{\"n\": 1256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2173.53, \"learn_time_ms\": 56970.886}", "{\"n\": 1257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2179.93, \"learn_time_ms\": 56925.493}", "{\"n\": 1258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2187.56, \"learn_time_ms\": 56840.181}", "{\"n\": 1259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2187.58, \"learn_time_ms\": 56841.433}", "{\"n\": 1260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2189.84, \"learn_time_ms\": 56754.589}", "{\"n\": 1261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2188.62, \"learn_time_ms\": 56673.453}", "{\"n\": 1262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2191.93, \"learn_time_ms\": 56692.644}", "{\"n\": 1263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2195.41, \"learn_time_ms\": 56642.271}", "{\"n\": 1264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2195.34, \"learn_time_ms\": 56583.163}", "{\"n\": 1265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2202.94, \"learn_time_ms\": 56539.291}", "{\"n\": 1266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2217.78, \"learn_time_ms\": 56630.386}", "{\"n\": 1267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2215.09, \"learn_time_ms\": 56623.241}", "{\"n\": 1268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2223.2, \"learn_time_ms\": 56599.544}", "{\"n\": 1269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2236.06, \"learn_time_ms\": 56612.536}", "{\"n\": 1270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2237.14, \"learn_time_ms\": 56673.355}", "{\"n\": 1271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2248.5, \"learn_time_ms\": 56792.851}", "{\"n\": 1272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2250.27, \"learn_time_ms\": 56750.13}", "{\"n\": 1273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.46, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2249.52, \"learn_time_ms\": 56812.398}", "{\"n\": 1274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2257.1, \"learn_time_ms\": 56713.677}", "{\"n\": 1275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2253.52, \"learn_time_ms\": 56759.487}", "{\"n\": 1276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2250.21, \"learn_time_ms\": 56694.146}", "{\"n\": 1277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2247.76, \"learn_time_ms\": 56704.693}", "{\"n\": 1278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2240.75, \"learn_time_ms\": 56732.389}", "{\"n\": 1279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2240.75, \"learn_time_ms\": 56738.612}", "{\"n\": 1280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2246.43, \"learn_time_ms\": 56750.03}", "{\"n\": 1281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2246.76, \"learn_time_ms\": 56758.364}", "{\"n\": 1282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2245.16, \"learn_time_ms\": 56750.864}", "{\"n\": 1283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2235.32, \"learn_time_ms\": 56750.027}", "{\"n\": 1284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2236.22, \"learn_time_ms\": 56875.749}", "{\"n\": 1285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2232.46, \"learn_time_ms\": 56868.763}", "{\"n\": 1286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2243.32, \"learn_time_ms\": 56935.133}", "{\"n\": 1287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2239.37, \"learn_time_ms\": 56927.323}", "{\"n\": 1288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2235.84, \"learn_time_ms\": 56984.839}", "{\"n\": 1289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2237.34, \"learn_time_ms\": 56925.589}", "{\"n\": 1290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2237.21, \"learn_time_ms\": 56918.109}", "{\"n\": 1291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2237.21, \"learn_time_ms\": 56845.042}", "{\"n\": 1292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2240.46, \"learn_time_ms\": 56779.33}", "{\"n\": 1293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.91, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2225.05, \"learn_time_ms\": 56744.146}", "{\"n\": 1294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2226.91, \"learn_time_ms\": 56763.699}", "{\"n\": 1295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2230.13, \"learn_time_ms\": 56662.492}", "{\"n\": 1296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2233.85, \"learn_time_ms\": 56562.278}", "{\"n\": 1297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2224.6, \"learn_time_ms\": 56625.972}", "{\"n\": 1298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2226.86, \"learn_time_ms\": 56618.357}", "{\"n\": 1299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2229.55, \"learn_time_ms\": 56655.077}", "{\"n\": 1300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2228.94, \"learn_time_ms\": 56578.002}", "{\"n\": 1301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.72, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2234.4, \"learn_time_ms\": 56703.762}", "{\"n\": 1302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2229.89, \"learn_time_ms\": 56744.429}", "{\"n\": 1303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2228.6, \"learn_time_ms\": 56723.137}", "{\"n\": 1304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2224.99, \"learn_time_ms\": 56637.76}", "{\"n\": 1305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.67, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2231.6, \"learn_time_ms\": 56781.348}", "{\"n\": 1306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.67, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2231.73, \"learn_time_ms\": 56811.634}", "{\"n\": 1307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.67, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2226.14, \"learn_time_ms\": 56744.677}", "{\"n\": 1308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2229.35, \"learn_time_ms\": 56653.639}", "{\"n\": 1309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.72, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2226.25, \"learn_time_ms\": 56589.402}", "{\"n\": 1310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2229.83, \"learn_time_ms\": 56680.577}", "{\"n\": 1311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2231.34, \"learn_time_ms\": 56562.529}", "{\"n\": 1312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2209.39, \"learn_time_ms\": 56647.226}", "{\"n\": 1313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2212.93, \"learn_time_ms\": 56690.127}", "{\"n\": 1314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2204.75, \"learn_time_ms\": 56729.565}", "{\"n\": 1315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2186.85, \"learn_time_ms\": 56591.476}", "{\"n\": 1316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2186.57, \"learn_time_ms\": 56650.652}", "{\"n\": 1317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2192.29, \"learn_time_ms\": 56606.968}", "{\"n\": 1318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2191.47, \"learn_time_ms\": 56690.578}", "{\"n\": 1319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2189.33, \"learn_time_ms\": 56709.847}", "{\"n\": 1320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2182.95, \"learn_time_ms\": 56665.151}", "{\"n\": 1321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2190.58, \"learn_time_ms\": 56669.816}", "{\"n\": 1322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2192.51, \"learn_time_ms\": 56569.994}", "{\"n\": 1323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.8, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2197.93, \"learn_time_ms\": 56667.002}", "{\"n\": 1324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.77, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2207.15, \"learn_time_ms\": 56654.603}", "{\"n\": 1325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2201.99, \"learn_time_ms\": 56820.74}", "{\"n\": 1326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2201.99, \"learn_time_ms\": 56812.075}", "{\"n\": 1327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2204.58, \"learn_time_ms\": 56805.809}", "{\"n\": 1328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2204.32, \"learn_time_ms\": 56782.505}", "{\"n\": 1329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2206.17, \"learn_time_ms\": 56804.555}", "{\"n\": 1330, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2213.14, \"learn_time_ms\": 56817.446}", "{\"n\": 1331, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2210.77, \"learn_time_ms\": 56862.662}", "{\"n\": 1332, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2210.48, \"learn_time_ms\": 56880.819}", "{\"n\": 1333, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2210.48, \"learn_time_ms\": 56769.042}", "{\"n\": 1334, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2212.22, \"learn_time_ms\": 56679.014}", "{\"n\": 1335, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2208.91, \"learn_time_ms\": 56587.914}", "{\"n\": 1336, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2208.91, \"learn_time_ms\": 56599.755}", "{\"n\": 1337, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2208.91, \"learn_time_ms\": 56617.708}", "{\"n\": 1338, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.72, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2213.07, \"learn_time_ms\": 56522.077}", "{\"n\": 1339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2219.67, \"learn_time_ms\": 56561.828}", "{\"n\": 1340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2215.78, \"learn_time_ms\": 56555.943}", "{\"n\": 1341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2217.57, \"learn_time_ms\": 56522.794}", "{\"n\": 1342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.78, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2218.46, \"learn_time_ms\": 56554.864}", "{\"n\": 1343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.79, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2222.18, \"learn_time_ms\": 56639.121}", "{\"n\": 1344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2228.89, \"learn_time_ms\": 56703.27}", "{\"n\": 1345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2229.73, \"learn_time_ms\": 56661.226}", "{\"n\": 1346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2233.35, \"learn_time_ms\": 56706.832}", "{\"n\": 1347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2240.42, \"learn_time_ms\": 56688.255}", "{\"n\": 1348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2240.15, \"learn_time_ms\": 56765.636}", "{\"n\": 1349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2240.69, \"learn_time_ms\": 56726.969}", "{\"n\": 1350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2240.76, \"learn_time_ms\": 56743.109}", "{\"n\": 1351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.75, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2238.66, \"learn_time_ms\": 56728.572}", "{\"n\": 1352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.76, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2240.45, \"learn_time_ms\": 56740.064}", "{\"n\": 1353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2252.85, \"learn_time_ms\": 56675.032}", "{\"n\": 1354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.67, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2254.56, \"learn_time_ms\": 56641.121}", "{\"n\": 1355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2245.65, \"learn_time_ms\": 56703.38}", "{\"n\": 1356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2251.4, \"learn_time_ms\": 56631.24}", "{\"n\": 1357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.73, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2242.2, \"learn_time_ms\": 56724.884}", "{\"n\": 1358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.68, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2247.11, \"learn_time_ms\": 56701.79}", "{\"n\": 1359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2263.93, \"learn_time_ms\": 56577.582}", "{\"n\": 1360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2259.78, \"learn_time_ms\": 56627.128}", "{\"n\": 1361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2263.92, \"learn_time_ms\": 56649.91}", "{\"n\": 1362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2269.27, \"learn_time_ms\": 56609.609}", "{\"n\": 1363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.59, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2270.93, \"learn_time_ms\": 56563.067}", "{\"n\": 1364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2265.47, \"learn_time_ms\": 56487.793}", "{\"n\": 1365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2265.34, \"learn_time_ms\": 56488.141}", "{\"n\": 1366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.7, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2260.35, \"learn_time_ms\": 56475.967}", "{\"n\": 1367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2273.27, \"learn_time_ms\": 56418.248}", "{\"n\": 1368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.62, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2279.43, \"learn_time_ms\": 56427.744}", "{\"n\": 1369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.61, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2279.91, \"learn_time_ms\": 56535.014}", "{\"n\": 1370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.61, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2280.83, \"learn_time_ms\": 56411.879}", "{\"n\": 1371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2281.31, \"learn_time_ms\": 56338.202}", "{\"n\": 1372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.66, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2276.38, \"learn_time_ms\": 56438.443}", "{\"n\": 1373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.62, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2283.47, \"learn_time_ms\": 56426.332}", "{\"n\": 1374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2290.64, \"learn_time_ms\": 56573.504}", "{\"n\": 1375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2301.27, \"learn_time_ms\": 56548.606}", "{\"n\": 1376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.52, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2309.82, \"learn_time_ms\": 56621.51}", "{\"n\": 1377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2312.29, \"learn_time_ms\": 56605.167}", "{\"n\": 1378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.51, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2312.29, \"learn_time_ms\": 56568.326}", "{\"n\": 1379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2307.42, \"learn_time_ms\": 56549.092}", "{\"n\": 1380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2303.27, \"learn_time_ms\": 56571.339}", "{\"n\": 1381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2321.67, \"learn_time_ms\": 56674.065}", "{\"n\": 1382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2314.23, \"learn_time_ms\": 56620.157}", "{\"n\": 1383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.46, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2310.66, \"learn_time_ms\": 56643.24}", "{\"n\": 1384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.4, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2323.26, \"learn_time_ms\": 56534.468}", "{\"n\": 1385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2318.85, \"learn_time_ms\": 56532.381}", "{\"n\": 1386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2317.41, \"learn_time_ms\": 56577.182}", "{\"n\": 1387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2314.23, \"learn_time_ms\": 56608.095}", "{\"n\": 1388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2317.3, \"learn_time_ms\": 56673.099}", "{\"n\": 1389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2318.28, \"learn_time_ms\": 56702.033}", "{\"n\": 1390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2319.53, \"learn_time_ms\": 56734.657}", "{\"n\": 1391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2321.32, \"learn_time_ms\": 56719.637}", "{\"n\": 1392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2316.69, \"learn_time_ms\": 56671.406}", "{\"n\": 1393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2314.85, \"learn_time_ms\": 56671.846}", "{\"n\": 1394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2315.31, \"learn_time_ms\": 56780.17}", "{\"n\": 1395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2316.09, \"learn_time_ms\": 56754.986}", "{\"n\": 1396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2316.09, \"learn_time_ms\": 56737.216}", "{\"n\": 1397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2321.27, \"learn_time_ms\": 56720.525}", "{\"n\": 1398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2314.95, \"learn_time_ms\": 56761.687}", "{\"n\": 1399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2308.52, \"learn_time_ms\": 56745.248}", "{\"n\": 1400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2311.46, \"learn_time_ms\": 56742.713}", "{\"n\": 1401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2307.63, \"learn_time_ms\": 56711.839}", "{\"n\": 1402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2308.35, \"learn_time_ms\": 56777.125}", "{\"n\": 1403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2309.46, \"learn_time_ms\": 56847.692}", "{\"n\": 1404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2304.62, \"learn_time_ms\": 56865.44}", "{\"n\": 1405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2305.3, \"learn_time_ms\": 56862.583}", "{\"n\": 1406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2307.51, \"learn_time_ms\": 56862.765}", "{\"n\": 1407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2300.05, \"learn_time_ms\": 56813.99}", "{\"n\": 1408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2294.72, \"learn_time_ms\": 56814.072}", "{\"n\": 1409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2292.88, \"learn_time_ms\": 56804.76}", "{\"n\": 1410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2300.44, \"learn_time_ms\": 56752.118}", "{\"n\": 1411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2301.21, \"learn_time_ms\": 56768.532}", "{\"n\": 1412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2301.21, \"learn_time_ms\": 56705.554}", "{\"n\": 1413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2300.88, \"learn_time_ms\": 56721.569}", "{\"n\": 1414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2306.21, \"learn_time_ms\": 56655.908}", "{\"n\": 1415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2294.11, \"learn_time_ms\": 56727.677}", "{\"n\": 1416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2295.32, \"learn_time_ms\": 56613.07}", "{\"n\": 1417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2299.23, \"learn_time_ms\": 56666.664}", "{\"n\": 1418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2294.08, \"learn_time_ms\": 56555.558}", "{\"n\": 1419, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2309.57, \"learn_time_ms\": 56513.282}", "{\"n\": 1420, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2304.44, \"learn_time_ms\": 56620.511}", "{\"n\": 1421, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2287.32, \"learn_time_ms\": 56553.944}", "{\"n\": 1422, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2292.87, \"learn_time_ms\": 56589.563}", "{\"n\": 1423, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2290.77, \"learn_time_ms\": 56615.482}", "{\"n\": 1424, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2291.19, \"learn_time_ms\": 56636.534}", "{\"n\": 1425, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2286.19, \"learn_time_ms\": 56570.887}", "{\"n\": 1426, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2284.62, \"learn_time_ms\": 56661.941}", "{\"n\": 1427, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2286.72, \"learn_time_ms\": 56613.823}", "{\"n\": 1428, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2286.72, \"learn_time_ms\": 56688.505}", "{\"n\": 1429, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.19, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2293.37, \"learn_time_ms\": 56805.273}", "{\"n\": 1430, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2292.15, \"learn_time_ms\": 56736.511}", "{\"n\": 1431, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2297.9, \"learn_time_ms\": 56792.716}", "{\"n\": 1432, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2298.39, \"learn_time_ms\": 56776.38}", "{\"n\": 1433, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2302.53, \"learn_time_ms\": 56654.527}", "{\"n\": 1434, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2302.53, \"learn_time_ms\": 56570.269}", "{\"n\": 1435, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2318.89, \"learn_time_ms\": 56620.291}", "{\"n\": 1436, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2315.6, \"learn_time_ms\": 56484.946}", "{\"n\": 1437, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2306.8, \"learn_time_ms\": 56540.492}", "{\"n\": 1438, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2306.8, \"learn_time_ms\": 56509.569}", "{\"n\": 1439, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.01, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2312.32, \"learn_time_ms\": 56393.844}", "{\"n\": 1440, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.06, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2304.87, \"learn_time_ms\": 56458.772}", "{\"n\": 1441, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2316.84, \"learn_time_ms\": 56439.181}", "{\"n\": 1442, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.07, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2316.84, \"learn_time_ms\": 56511.692}", "{\"n\": 1443, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.04, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2314.04, \"learn_time_ms\": 56495.114}", "{\"n\": 1444, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2310.89, \"learn_time_ms\": 56534.666}", "{\"n\": 1445, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.99, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2316.31, \"learn_time_ms\": 56505.903}", "{\"n\": 1446, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2323.7, \"learn_time_ms\": 56564.739}", "{\"n\": 1447, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2326.39, \"learn_time_ms\": 56583.149}", "{\"n\": 1448, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2320.43, \"learn_time_ms\": 56650.289}", "{\"n\": 1449, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.8, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2324.46, \"learn_time_ms\": 56691.613}", "{\"n\": 1450, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2327.35, \"learn_time_ms\": 56565.956}", "{\"n\": 1451, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2326.33, \"learn_time_ms\": 56602.298}", "{\"n\": 1452, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.8, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2336.45, \"learn_time_ms\": 56475.245}", "{\"n\": 1453, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.8, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2338.85, \"learn_time_ms\": 56569.0}", "{\"n\": 1454, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.76, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2343.19, \"learn_time_ms\": 56619.211}", "{\"n\": 1455, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2336.16, \"learn_time_ms\": 56667.134}", "{\"n\": 1456, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2346.86, \"learn_time_ms\": 56725.5}", "{\"n\": 1457, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.71, \"learn_time_ms\": 56727.735}", "{\"n\": 1458, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2346.91, \"learn_time_ms\": 56629.609}", "{\"n\": 1459, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.68, \"learn_time_ms\": 56635.286}", "{\"n\": 1460, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2344.68, \"learn_time_ms\": 56680.29}", "{\"n\": 1461, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2345.98, \"learn_time_ms\": 56647.576}", "{\"n\": 1462, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2338.61, \"learn_time_ms\": 56690.484}", "{\"n\": 1463, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2343.9, \"learn_time_ms\": 56553.32}", "{\"n\": 1464, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2350.32, \"learn_time_ms\": 56542.238}", "{\"n\": 1465, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2350.93, \"learn_time_ms\": 56458.659}", "{\"n\": 1466, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.8, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2340.78, \"learn_time_ms\": 56457.702}", "{\"n\": 1467, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2345.34, \"learn_time_ms\": 56412.375}", "{\"n\": 1468, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.79, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2345.34, \"learn_time_ms\": 56416.927}", "{\"n\": 1469, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2343.76, \"learn_time_ms\": 56426.559}", "{\"n\": 1470, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2341.62, \"learn_time_ms\": 56433.887}", "{\"n\": 1471, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2334.42, \"learn_time_ms\": 56405.559}", "{\"n\": 1472, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2334.42, \"learn_time_ms\": 56376.149}", "{\"n\": 1473, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2340.92, \"learn_time_ms\": 56478.076}", "{\"n\": 1474, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.96, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2354.91, \"learn_time_ms\": 56437.686}", "{\"n\": 1475, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2339.14, \"learn_time_ms\": 56460.981}", "{\"n\": 1476, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2339.14, \"learn_time_ms\": 56334.621}", "{\"n\": 1477, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.12, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2337.62, \"learn_time_ms\": 56452.611}", "{\"n\": 1478, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2335.23, \"learn_time_ms\": 56436.015}", "{\"n\": 1479, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.13, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2331.88, \"learn_time_ms\": 56340.582}", "{\"n\": 1480, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2338.68, \"learn_time_ms\": 56385.224}", "{\"n\": 1481, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2337.51, \"learn_time_ms\": 56416.541}", "{\"n\": 1482, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.06, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2340.25, \"learn_time_ms\": 56382.505}", "{\"n\": 1483, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2335.6, \"learn_time_ms\": 56384.265}", "{\"n\": 1484, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2336.17, \"learn_time_ms\": 56369.11}", "{\"n\": 1485, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2338.29, \"learn_time_ms\": 56350.66}", "{\"n\": 1486, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.01, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2349.68, \"learn_time_ms\": 56465.946}", "{\"n\": 1487, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.04, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2350.41, \"learn_time_ms\": 56400.267}", "{\"n\": 1488, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.03, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2350.34, \"learn_time_ms\": 56407.53}", "{\"n\": 1489, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2363.06, \"learn_time_ms\": 56539.305}", "{\"n\": 1490, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.9, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2357.56, \"learn_time_ms\": 56557.372}", "{\"n\": 1491, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2364.56, \"learn_time_ms\": 56492.164}", "{\"n\": 1492, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2360.33, \"learn_time_ms\": 56510.352}", "{\"n\": 1493, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2361.76, \"learn_time_ms\": 56482.993}", "{\"n\": 1494, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2363.29, \"learn_time_ms\": 56563.993}", "{\"n\": 1495, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.84, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2365.79, \"learn_time_ms\": 56573.79}", "{\"n\": 1496, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2365.3, \"learn_time_ms\": 56486.776}", "{\"n\": 1497, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2371.91, \"learn_time_ms\": 56456.19}", "{\"n\": 1498, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2363.49, \"learn_time_ms\": 56557.604}", "{\"n\": 1499, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2367.26, \"learn_time_ms\": 56486.038}", "{\"n\": 1500, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.82, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2372.17, \"learn_time_ms\": 56471.434}", "{\"n\": 1501, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.83, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2361.45, \"learn_time_ms\": 56512.417}", "{\"n\": 1502, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2373.78, \"learn_time_ms\": 56637.991}", "{\"n\": 1503, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2378.92, \"learn_time_ms\": 56636.131}", "{\"n\": 1504, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.77, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2374.51, \"learn_time_ms\": 56605.1}", "{\"n\": 1505, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2363.62, \"learn_time_ms\": 56577.378}", "{\"n\": 1506, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2376.03, \"learn_time_ms\": 56622.549}", "{\"n\": 1507, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2376.91, \"learn_time_ms\": 56610.532}", "{\"n\": 1508, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.73, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2373.91, \"learn_time_ms\": 56637.614}", "{\"n\": 1509, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2374.62, \"learn_time_ms\": 56640.362}", "{\"n\": 1510, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2386.61, \"learn_time_ms\": 56623.225}", "{\"n\": 1511, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2386.45, \"learn_time_ms\": 56617.641}", "{\"n\": 1512, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.55, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2402.17, \"learn_time_ms\": 56592.847}", "{\"n\": 1513, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2386.15, \"learn_time_ms\": 56567.188}", "{\"n\": 1514, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.52, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2396.05, \"learn_time_ms\": 56570.222}", "{\"n\": 1515, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.52, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2396.05, \"learn_time_ms\": 56572.026}", "{\"n\": 1516, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2387.64, \"learn_time_ms\": 56609.489}", "{\"n\": 1517, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2389.49, \"learn_time_ms\": 56590.789}", "{\"n\": 1518, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2389.4, \"learn_time_ms\": 56517.636}", "{\"n\": 1519, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2392.17, \"learn_time_ms\": 56535.097}", "{\"n\": 1520, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2390.12, \"learn_time_ms\": 56532.874}", "{\"n\": 1521, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2390.12, \"learn_time_ms\": 56555.69}", "{\"n\": 1522, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2388.47, \"learn_time_ms\": 56499.678}", "{\"n\": 1523, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2371.92, \"learn_time_ms\": 56552.75}", "{\"n\": 1524, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2381.92, \"learn_time_ms\": 56505.467}", "{\"n\": 1525, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2373.99, \"learn_time_ms\": 56609.271}", "{\"n\": 1526, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2372.06, \"learn_time_ms\": 56570.577}", "{\"n\": 1527, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2365.68, \"learn_time_ms\": 56654.476}", "{\"n\": 1528, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2359.87, \"learn_time_ms\": 56628.0}", "{\"n\": 1529, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2369.14, \"learn_time_ms\": 56686.55}", "{\"n\": 1530, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2364.95, \"learn_time_ms\": 56630.213}", "{\"n\": 1531, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2359.69, \"learn_time_ms\": 56645.065}", "{\"n\": 1532, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2359.21, \"learn_time_ms\": 56713.903}", "{\"n\": 1533, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2356.08, \"learn_time_ms\": 56679.42}", "{\"n\": 1534, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2359.11, \"learn_time_ms\": 56665.002}", "{\"n\": 1535, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2346.3, \"learn_time_ms\": 56648.542}", "{\"n\": 1536, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2345.32, \"learn_time_ms\": 56620.943}", "{\"n\": 1537, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2347.38, \"learn_time_ms\": 56573.21}", "{\"n\": 1538, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2349.11, \"learn_time_ms\": 56622.481}", "{\"n\": 1539, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2343.43, \"learn_time_ms\": 56607.586}", "{\"n\": 1540, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2346.12, \"learn_time_ms\": 56615.52}", "{\"n\": 1541, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2339.84, \"learn_time_ms\": 56580.477}", "{\"n\": 1542, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2341.69, \"learn_time_ms\": 56601.708}", "{\"n\": 1543, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.52, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2335.29, \"learn_time_ms\": 56652.99}", "{\"n\": 1544, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2335.36, \"learn_time_ms\": 56706.562}", "{\"n\": 1545, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2341.85, \"learn_time_ms\": 56655.256}", "{\"n\": 1546, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2343.51, \"learn_time_ms\": 56641.607}", "{\"n\": 1547, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2348.95, \"learn_time_ms\": 56771.588}", "{\"n\": 1548, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2345.89, \"learn_time_ms\": 56778.266}", "{\"n\": 1549, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2342.03, \"learn_time_ms\": 56791.959}", "{\"n\": 1550, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2354.12, \"learn_time_ms\": 56812.082}", "{\"n\": 1551, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.47, \"learn_time_ms\": 56883.024}", "{\"n\": 1552, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2342.31, \"learn_time_ms\": 56751.5}", "{\"n\": 1553, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2352.18, \"learn_time_ms\": 56708.644}", "{\"n\": 1554, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.95, \"learn_time_ms\": 56703.016}", "{\"n\": 1555, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.95, \"learn_time_ms\": 56741.301}", "{\"n\": 1556, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2346.01, \"learn_time_ms\": 56765.791}", "{\"n\": 1557, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2353.92, \"learn_time_ms\": 56565.222}", "{\"n\": 1558, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2351.5, \"learn_time_ms\": 56575.507}", "{\"n\": 1559, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.49, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2348.4, \"learn_time_ms\": 56545.369}", "{\"n\": 1560, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2346.14, \"learn_time_ms\": 56592.664}", "{\"n\": 1561, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2344.22, \"learn_time_ms\": 56539.162}", "{\"n\": 1562, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2342.28, \"learn_time_ms\": 56645.886}", "{\"n\": 1563, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.61, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2341.4, \"learn_time_ms\": 56625.81}", "{\"n\": 1564, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.61, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2340.47, \"learn_time_ms\": 56518.249}", "{\"n\": 1565, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2343.84, \"learn_time_ms\": 56498.556}", "{\"n\": 1566, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.6, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2344.73, \"learn_time_ms\": 56478.677}", "{\"n\": 1567, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.57, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2348.86, \"learn_time_ms\": 56478.633}", "{\"n\": 1568, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2356.73, \"learn_time_ms\": 56445.851}", "{\"n\": 1569, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.59, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2358.08, \"learn_time_ms\": 56404.923}", "{\"n\": 1570, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.59, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2358.91, \"learn_time_ms\": 56440.396}", "{\"n\": 1571, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.58, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2358.29, \"learn_time_ms\": 56423.805}", "{\"n\": 1572, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2362.0, \"learn_time_ms\": 56295.798}", "{\"n\": 1573, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.56, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2364.77, \"learn_time_ms\": 56353.727}", "{\"n\": 1574, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.57, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2365.1, \"learn_time_ms\": 56452.224}", "{\"n\": 1575, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2380.38, \"learn_time_ms\": 56437.341}", "{\"n\": 1576, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2390.22, \"learn_time_ms\": 56533.876}", "{\"n\": 1577, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2396.71, \"learn_time_ms\": 56664.409}", "{\"n\": 1578, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2397.75, \"learn_time_ms\": 56574.699}", "{\"n\": 1579, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2384.46, \"learn_time_ms\": 56622.577}", "{\"n\": 1580, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2384.46, \"learn_time_ms\": 56547.881}", "{\"n\": 1581, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2386.94, \"learn_time_ms\": 56518.938}", "{\"n\": 1582, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2381.87, \"learn_time_ms\": 56657.095}", "{\"n\": 1583, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2392.93, \"learn_time_ms\": 56626.945}", "{\"n\": 1584, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2392.93, \"learn_time_ms\": 56643.925}", "{\"n\": 1585, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2399.62, \"learn_time_ms\": 56603.938}", "{\"n\": 1586, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2403.72, \"learn_time_ms\": 56521.711}", "{\"n\": 1587, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2403.72, \"learn_time_ms\": 56547.654}", "{\"n\": 1588, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2397.39, \"learn_time_ms\": 56605.136}", "{\"n\": 1589, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2393.1, \"learn_time_ms\": 56568.606}", "{\"n\": 1590, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2390.04, \"learn_time_ms\": 56610.242}", "{\"n\": 1591, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2398.14, \"learn_time_ms\": 56640.179}", "{\"n\": 1592, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2400.61, \"learn_time_ms\": 56539.95}", "{\"n\": 1593, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2402.43, \"learn_time_ms\": 56518.514}", "{\"n\": 1594, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2403.6, \"learn_time_ms\": 56438.859}", "{\"n\": 1595, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2403.4, \"learn_time_ms\": 56452.457}", "{\"n\": 1596, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2406.18, \"learn_time_ms\": 56432.499}", "{\"n\": 1597, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2393.84, \"learn_time_ms\": 56372.293}", "{\"n\": 1598, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2398.59, \"learn_time_ms\": 56383.072}", "{\"n\": 1599, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2403.32, \"learn_time_ms\": 56410.265}", "{\"n\": 1600, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2396.75, \"learn_time_ms\": 56455.853}", "{\"n\": 1601, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2394.11, \"learn_time_ms\": 56481.218}", "{\"n\": 1602, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2402.14, \"learn_time_ms\": 56581.045}", "{\"n\": 1603, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2399.97, \"learn_time_ms\": 56572.772}", "{\"n\": 1604, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2407.68, \"learn_time_ms\": 56671.679}", "{\"n\": 1605, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2418.39, \"learn_time_ms\": 56660.912}", "{\"n\": 1606, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2424.43, \"learn_time_ms\": 56693.627}", "{\"n\": 1607, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.26, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2423.79, \"learn_time_ms\": 56682.948}", "{\"n\": 1608, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2424.76, \"learn_time_ms\": 56696.367}", "{\"n\": 1609, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2421.49, \"learn_time_ms\": 56617.288}", "{\"n\": 1610, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2417.04, \"learn_time_ms\": 56544.075}", "{\"n\": 1611, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2421.22, \"learn_time_ms\": 56549.799}", "{\"n\": 1612, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2426.9, \"learn_time_ms\": 56522.215}", "{\"n\": 1613, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.19, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2424.6, \"learn_time_ms\": 56542.381}", "{\"n\": 1614, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2426.0, \"learn_time_ms\": 56486.878}", "{\"n\": 1615, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2429.1, \"learn_time_ms\": 56515.98}", "{\"n\": 1616, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2424.35, \"learn_time_ms\": 56494.136}", "{\"n\": 1617, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2421.56, \"learn_time_ms\": 56470.378}", "{\"n\": 1618, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2424.12, \"learn_time_ms\": 56492.157}", "{\"n\": 1619, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2421.76, \"learn_time_ms\": 56540.41}", "{\"n\": 1620, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2421.76, \"learn_time_ms\": 56519.48}", "{\"n\": 1621, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2425.4, \"learn_time_ms\": 56552.715}", "{\"n\": 1622, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2429.56, \"learn_time_ms\": 56464.061}", "{\"n\": 1623, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2426.24, \"learn_time_ms\": 56402.782}", "{\"n\": 1624, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2419.41, \"learn_time_ms\": 56469.879}", "{\"n\": 1625, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.48, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2407.99, \"learn_time_ms\": 56457.708}", "{\"n\": 1626, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.43, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2414.85, \"learn_time_ms\": 56470.733}", "{\"n\": 1627, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2419.63, \"learn_time_ms\": 56542.347}", "{\"n\": 1628, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2422.11, \"learn_time_ms\": 56504.287}", "{\"n\": 1629, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2425.57, \"learn_time_ms\": 56495.101}", "{\"n\": 1630, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2426.31, \"learn_time_ms\": 56537.375}", "{\"n\": 1631, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2432.19, \"learn_time_ms\": 56462.889}", "{\"n\": 1632, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2421.67, \"learn_time_ms\": 56457.437}", "{\"n\": 1633, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2411.86, \"learn_time_ms\": 56485.013}", "{\"n\": 1634, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2411.86, \"learn_time_ms\": 56506.736}", "{\"n\": 1635, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.55, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2400.56, \"learn_time_ms\": 56486.166}", "{\"n\": 1636, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.49, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2400.07, \"learn_time_ms\": 56601.216}", "{\"n\": 1637, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.48, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2402.29, \"learn_time_ms\": 56549.049}", "{\"n\": 1638, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.48, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2402.29, \"learn_time_ms\": 56616.553}", "{\"n\": 1639, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.46, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2397.04, \"learn_time_ms\": 56630.698}", "{\"n\": 1640, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.49, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2396.14, \"learn_time_ms\": 56551.947}", "{\"n\": 1641, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2397.27, \"learn_time_ms\": 56607.092}", "{\"n\": 1642, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2402.1, \"learn_time_ms\": 56722.224}", "{\"n\": 1643, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.45, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2397.97, \"learn_time_ms\": 56765.488}", "{\"n\": 1644, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2403.81, \"learn_time_ms\": 56750.134}", "{\"n\": 1645, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2405.23, \"learn_time_ms\": 56706.458}", "{\"n\": 1646, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2408.15, \"learn_time_ms\": 56676.588}", "{\"n\": 1647, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2411.84, \"learn_time_ms\": 56660.951}", "{\"n\": 1648, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2420.78, \"learn_time_ms\": 56525.37}", "{\"n\": 1649, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2419.93, \"learn_time_ms\": 56567.652}", "{\"n\": 1650, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2418.43, \"learn_time_ms\": 56577.095}", "{\"n\": 1651, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2418.43, \"learn_time_ms\": 56577.157}", "{\"n\": 1652, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2414.06, \"learn_time_ms\": 56488.206}", "{\"n\": 1653, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2411.25, \"learn_time_ms\": 56504.819}", "{\"n\": 1654, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2401.76, \"learn_time_ms\": 56453.631}", "{\"n\": 1655, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2401.76, \"learn_time_ms\": 56498.388}", "{\"n\": 1656, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2391.34, \"learn_time_ms\": 56482.836}", "{\"n\": 1657, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2386.76, \"learn_time_ms\": 56479.462}", "{\"n\": 1658, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2391.32, \"learn_time_ms\": 56614.523}", "{\"n\": 1659, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2394.32, \"learn_time_ms\": 56502.358}", "{\"n\": 1660, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2408.07, \"learn_time_ms\": 56553.197}", "{\"n\": 1661, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2404.95, \"learn_time_ms\": 56503.104}", "{\"n\": 1662, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2400.4, \"learn_time_ms\": 56563.742}", "{\"n\": 1663, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2392.23, \"learn_time_ms\": 56522.457}", "{\"n\": 1664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2396.45, \"learn_time_ms\": 56562.584}", "{\"n\": 1665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2396.03, \"learn_time_ms\": 56628.34}", "{\"n\": 1666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2399.66, \"learn_time_ms\": 56607.467}", "{\"n\": 1667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2411.14, \"learn_time_ms\": 56575.331}", "{\"n\": 1668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2420.21, \"learn_time_ms\": 56478.13}", "{\"n\": 1669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2429.59, \"learn_time_ms\": 56575.622}", "{\"n\": 1670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2430.15, \"learn_time_ms\": 56560.22}", "{\"n\": 1671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2433.94, \"learn_time_ms\": 56572.818}", "{\"n\": 1672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.2, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2432.86, \"learn_time_ms\": 56566.645}", "{\"n\": 1673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2424.25, \"learn_time_ms\": 56593.853}", "{\"n\": 1674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2424.37, \"learn_time_ms\": 56570.619}", "{\"n\": 1675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2424.21, \"learn_time_ms\": 56494.22}", "{\"n\": 1676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2419.71, \"learn_time_ms\": 56466.14}", "{\"n\": 1677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.19, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2421.01, \"learn_time_ms\": 56458.661}", "{\"n\": 1678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2414.15, \"learn_time_ms\": 56393.611}", "{\"n\": 1679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.2, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2417.69, \"learn_time_ms\": 56412.269}", "{\"n\": 1680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2420.19, \"learn_time_ms\": 56340.611}", "{\"n\": 1681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2426.2, \"learn_time_ms\": 56381.692}", "{\"n\": 1682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2435.75, \"learn_time_ms\": 56271.551}", "{\"n\": 1683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.17, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2434.56, \"learn_time_ms\": 56252.555}", "{\"n\": 1684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2445.72, \"learn_time_ms\": 56220.611}", "{\"n\": 1685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2448.5, \"learn_time_ms\": 56224.044}", "{\"n\": 1686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.13, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2444.14, \"learn_time_ms\": 56237.695}", "{\"n\": 1687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2432.0, \"learn_time_ms\": 56265.004}", "{\"n\": 1688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2437.15, \"learn_time_ms\": 56381.486}", "{\"n\": 1689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2440.0, \"learn_time_ms\": 56364.672}", "{\"n\": 1690, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2446.04, \"learn_time_ms\": 56372.963}", "{\"n\": 1691, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2455.83, \"learn_time_ms\": 56399.018}", "{\"n\": 1692, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2452.86, \"learn_time_ms\": 56476.157}", "{\"n\": 1693, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2454.19, \"learn_time_ms\": 56538.854}", "{\"n\": 1694, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2457.01, \"learn_time_ms\": 56522.386}", "{\"n\": 1695, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.18, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2445.8, \"learn_time_ms\": 56511.839}", "{\"n\": 1696, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2434.55, \"learn_time_ms\": 56586.497}", "{\"n\": 1697, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2438.87, \"learn_time_ms\": 56601.173}", "{\"n\": 1698, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2423.94, \"learn_time_ms\": 56529.777}", "{\"n\": 1699, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2424.26, \"learn_time_ms\": 56549.895}", "{\"n\": 1700, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2431.05, \"learn_time_ms\": 56612.496}", "{\"n\": 1701, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2423.98, \"learn_time_ms\": 56607.905}", "{\"n\": 1702, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2422.27, \"learn_time_ms\": 56568.182}", "{\"n\": 1703, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2423.19, \"learn_time_ms\": 56591.226}", "{\"n\": 1704, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2426.41, \"learn_time_ms\": 56603.721}", "{\"n\": 1705, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2419.61, \"learn_time_ms\": 56670.134}", "{\"n\": 1706, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2430.07, \"learn_time_ms\": 56661.811}", "{\"n\": 1707, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2438.48, \"learn_time_ms\": 56655.919}", "{\"n\": 1708, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2438.48, \"learn_time_ms\": 56770.706}", "{\"n\": 1709, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2437.2, \"learn_time_ms\": 56744.288}", "{\"n\": 1710, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2431.83, \"learn_time_ms\": 56834.477}", "{\"n\": 1711, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2425.6, \"learn_time_ms\": 56730.427}", "{\"n\": 1712, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2437.29, \"learn_time_ms\": 56872.38}", "{\"n\": 1713, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2441.16, \"learn_time_ms\": 56818.94}", "{\"n\": 1714, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2440.37, \"learn_time_ms\": 56912.533}", "{\"n\": 1715, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2442.25, \"learn_time_ms\": 56865.827}", "{\"n\": 1716, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2442.25, \"learn_time_ms\": 56745.651}", "{\"n\": 1717, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2416.59, \"learn_time_ms\": 56764.212}", "{\"n\": 1718, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2406.13, \"learn_time_ms\": 56638.894}", "{\"n\": 1719, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2396.98, \"learn_time_ms\": 56624.587}", "{\"n\": 1720, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2395.82, \"learn_time_ms\": 56472.736}", "{\"n\": 1721, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.34, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2395.15, \"learn_time_ms\": 56570.535}", "{\"n\": 1722, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2397.3, \"learn_time_ms\": 56552.247}", "{\"n\": 1723, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2399.78, \"learn_time_ms\": 56508.883}", "{\"n\": 1724, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2401.2, \"learn_time_ms\": 56498.484}", "{\"n\": 1725, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2408.67, \"learn_time_ms\": 56538.032}", "{\"n\": 1726, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2409.52, \"learn_time_ms\": 56613.055}", "{\"n\": 1727, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2409.36, \"learn_time_ms\": 56610.585}", "{\"n\": 1728, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2411.53, \"learn_time_ms\": 56725.357}", "{\"n\": 1729, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2411.64, \"learn_time_ms\": 56727.016}", "{\"n\": 1730, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2403.41, \"learn_time_ms\": 56851.986}", "{\"n\": 1731, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2404.67, \"learn_time_ms\": 56819.683}", "{\"n\": 1732, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2404.67, \"learn_time_ms\": 56827.802}", "{\"n\": 1733, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2400.8, \"learn_time_ms\": 56884.355}", "{\"n\": 1734, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2406.17, \"learn_time_ms\": 56884.22}", "{\"n\": 1735, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2413.0, \"learn_time_ms\": 56857.311}", "{\"n\": 1736, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.32, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2413.0, \"learn_time_ms\": 56899.448}", "{\"n\": 1737, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.28, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2414.07, \"learn_time_ms\": 56879.838}", "{\"n\": 1738, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2428.64, \"learn_time_ms\": 56844.323}", "{\"n\": 1739, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2423.73, \"learn_time_ms\": 56860.85}", "{\"n\": 1740, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.21, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2424.09, \"learn_time_ms\": 56852.371}", "{\"n\": 1741, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2424.26, \"learn_time_ms\": 56884.328}", "{\"n\": 1742, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.26, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2420.1, \"learn_time_ms\": 56801.035}", "{\"n\": 1743, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.19, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2431.62, \"learn_time_ms\": 56754.855}", "{\"n\": 1744, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2440.2, \"learn_time_ms\": 56700.939}", "{\"n\": 1745, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.13, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2433.54, \"learn_time_ms\": 56727.342}", "{\"n\": 1746, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.15, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2443.87, \"learn_time_ms\": 56706.919}", "{\"n\": 1747, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2443.99, \"learn_time_ms\": 56702.501}", "{\"n\": 1748, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.13, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2445.83, \"learn_time_ms\": 56634.343}", "{\"n\": 1749, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2450.05, \"learn_time_ms\": 56704.703}", "{\"n\": 1750, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2454.74, \"learn_time_ms\": 56640.133}", "{\"n\": 1751, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -15.01, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2451.17, \"learn_time_ms\": 56655.483}", "{\"n\": 1752, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2455.66, \"learn_time_ms\": 56667.783}", "{\"n\": 1753, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2459.27, \"learn_time_ms\": 56668.905}", "{\"n\": 1754, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2465.18, \"learn_time_ms\": 56612.265}", "{\"n\": 1755, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2469.38, \"learn_time_ms\": 56617.604}", "{\"n\": 1756, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2471.92, \"learn_time_ms\": 56515.997}", "{\"n\": 1757, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2471.92, \"learn_time_ms\": 56584.658}", "{\"n\": 1758, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2462.76, \"learn_time_ms\": 56655.791}", "{\"n\": 1759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2456.89, \"learn_time_ms\": 56593.811}", "{\"n\": 1760, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2459.77, \"learn_time_ms\": 56614.003}", "{\"n\": 1761, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2463.69, \"learn_time_ms\": 56536.395}", "{\"n\": 1762, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2463.63, \"learn_time_ms\": 56572.284}", "{\"n\": 1763, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2468.86, \"learn_time_ms\": 56622.173}", "{\"n\": 1764, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2468.41, \"learn_time_ms\": 56716.857}", "{\"n\": 1765, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2475.49, \"learn_time_ms\": 56702.133}", "{\"n\": 1766, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2482.33, \"learn_time_ms\": 56833.287}", "{\"n\": 1767, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2476.38, \"learn_time_ms\": 56750.148}", "{\"n\": 1768, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2490.86, \"learn_time_ms\": 56719.808}", "{\"n\": 1769, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2506.28, \"learn_time_ms\": 56720.463}", "{\"n\": 1770, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2521.55, \"learn_time_ms\": 56718.613}", "{\"n\": 1771, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2519.86, \"learn_time_ms\": 56746.857}", "{\"n\": 1772, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2519.86, \"learn_time_ms\": 56699.043}", "{\"n\": 1773, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2508.36, \"learn_time_ms\": 56685.061}", "{\"n\": 1774, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2508.85, \"learn_time_ms\": 56627.748}", "{\"n\": 1775, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2509.58, \"learn_time_ms\": 56718.11}", "{\"n\": 1776, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2508.46, \"learn_time_ms\": 56644.979}", "{\"n\": 1777, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2505.46, \"learn_time_ms\": 56706.136}", "{\"n\": 1778, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2506.96, \"learn_time_ms\": 56665.378}", "{\"n\": 1779, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2515.42, \"learn_time_ms\": 56679.924}", "{\"n\": 1780, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2513.04, \"learn_time_ms\": 56777.68}", "{\"n\": 1781, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2516.33, \"learn_time_ms\": 56751.422}", "{\"n\": 1782, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2516.02, \"learn_time_ms\": 56812.247}", "{\"n\": 1783, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2516.02, \"learn_time_ms\": 56804.712}", "{\"n\": 1784, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2509.34, \"learn_time_ms\": 56768.555}", "{\"n\": 1785, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2497.93, \"learn_time_ms\": 56736.548}", "{\"n\": 1786, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2492.84, \"learn_time_ms\": 56702.282}", "{\"n\": 1787, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2489.24, \"learn_time_ms\": 56703.646}", "{\"n\": 1788, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2489.35, \"learn_time_ms\": 56752.467}", "{\"n\": 1789, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2486.8, \"learn_time_ms\": 56684.657}", "{\"n\": 1790, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2489.12, \"learn_time_ms\": 56624.197}", "{\"n\": 1791, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2504.65, \"learn_time_ms\": 56694.973}", "{\"n\": 1792, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2509.1, \"learn_time_ms\": 56701.625}", "{\"n\": 1793, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2507.25, \"learn_time_ms\": 56685.775}", "{\"n\": 1794, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2500.19, \"learn_time_ms\": 56785.083}", "{\"n\": 1795, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2487.34, \"learn_time_ms\": 56744.828}", "{\"n\": 1796, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2482.67, \"learn_time_ms\": 56750.855}", "{\"n\": 1797, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2494.54, \"learn_time_ms\": 56799.105}", "{\"n\": 1798, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2497.59, \"learn_time_ms\": 56818.552}", "{\"n\": 1799, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2504.55, \"learn_time_ms\": 56907.324}", "{\"n\": 1800, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2505.91, \"learn_time_ms\": 56812.913}", "{\"n\": 1801, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2497.36, \"learn_time_ms\": 56778.9}", "{\"n\": 1802, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2494.63, \"learn_time_ms\": 56757.997}", "{\"n\": 1803, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2501.13, \"learn_time_ms\": 56775.036}", "{\"n\": 1804, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2505.48, \"learn_time_ms\": 56800.934}", "{\"n\": 1805, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2502.92, \"learn_time_ms\": 56808.002}", "{\"n\": 1806, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2505.59, \"learn_time_ms\": 56815.728}", "{\"n\": 1807, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2500.34, \"learn_time_ms\": 56739.208}", "{\"n\": 1808, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2502.28, \"learn_time_ms\": 56754.156}", "{\"n\": 1809, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2492.73, \"learn_time_ms\": 56686.264}", "{\"n\": 1810, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2494.46, \"learn_time_ms\": 56786.238}", "{\"n\": 1811, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2496.4, \"learn_time_ms\": 56786.38}", "{\"n\": 1812, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2489.29, \"learn_time_ms\": 56710.138}", "{\"n\": 1813, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2497.6, \"learn_time_ms\": 56735.191}", "{\"n\": 1814, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2486.92, \"learn_time_ms\": 56621.889}", "{\"n\": 1815, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2484.86, \"learn_time_ms\": 56650.558}", "{\"n\": 1816, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2483.28, \"learn_time_ms\": 56695.929}", "{\"n\": 1817, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2483.28, \"learn_time_ms\": 56771.81}", "{\"n\": 1818, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2474.08, \"learn_time_ms\": 56677.627}", "{\"n\": 1819, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2460.83, \"learn_time_ms\": 56711.11}", "{\"n\": 1820, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2453.76, \"learn_time_ms\": 56638.323}", "{\"n\": 1821, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2453.76, \"learn_time_ms\": 56620.607}", "{\"n\": 1822, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2446.72, \"learn_time_ms\": 56736.209}", "{\"n\": 1823, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2446.8, \"learn_time_ms\": 56729.64}", "{\"n\": 1824, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2448.24, \"learn_time_ms\": 56723.824}", "{\"n\": 1825, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2445.77, \"learn_time_ms\": 56756.769}", "{\"n\": 1826, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2453.87, \"learn_time_ms\": 56684.219}", "{\"n\": 1827, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2465.87, \"learn_time_ms\": 56660.409}", "{\"n\": 1828, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2469.54, \"learn_time_ms\": 56649.337}", "{\"n\": 1829, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2470.45, \"learn_time_ms\": 56717.412}", "{\"n\": 1830, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2451.62, \"learn_time_ms\": 56737.402}", "{\"n\": 1831, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2457.29, \"learn_time_ms\": 56718.92}", "{\"n\": 1832, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2460.68, \"learn_time_ms\": 56686.054}", "{\"n\": 1833, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2463.05, \"learn_time_ms\": 56625.409}", "{\"n\": 1834, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2464.69, \"learn_time_ms\": 56615.747}", "{\"n\": 1835, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2466.35, \"learn_time_ms\": 56594.823}", "{\"n\": 1836, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2465.39, \"learn_time_ms\": 56683.364}", "{\"n\": 1837, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2468.42, \"learn_time_ms\": 56610.194}", "{\"n\": 1838, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2479.53, \"learn_time_ms\": 56659.559}", "{\"n\": 1839, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.42, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2479.05, \"learn_time_ms\": 56608.96}", "{\"n\": 1840, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2474.59, \"learn_time_ms\": 56578.599}", "{\"n\": 1841, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2455.59, \"learn_time_ms\": 56640.659}", "{\"n\": 1842, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2446.68, \"learn_time_ms\": 56584.477}", "{\"n\": 1843, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2451.9, \"learn_time_ms\": 56602.37}", "{\"n\": 1844, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2458.97, \"learn_time_ms\": 56628.808}", "{\"n\": 1845, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2449.19, \"learn_time_ms\": 56640.381}", "{\"n\": 1846, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.51, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2449.33, \"learn_time_ms\": 56590.973}", "{\"n\": 1847, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.59, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2430.24, \"learn_time_ms\": 56605.338}", "{\"n\": 1848, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2432.87, \"learn_time_ms\": 56707.04}", "{\"n\": 1849, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2424.52, \"learn_time_ms\": 56654.078}", "{\"n\": 1850, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2427.66, \"learn_time_ms\": 56716.736}", "{\"n\": 1851, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2429.94, \"learn_time_ms\": 56740.381}", "{\"n\": 1852, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2420.33, \"learn_time_ms\": 56785.117}", "{\"n\": 1853, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2417.3, \"learn_time_ms\": 56780.333}", "{\"n\": 1854, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2407.7, \"learn_time_ms\": 56747.707}", "{\"n\": 1855, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2406.85, \"learn_time_ms\": 56704.006}", "{\"n\": 1856, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2406.85, \"learn_time_ms\": 56679.325}", "{\"n\": 1857, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2411.91, \"learn_time_ms\": 56761.517}", "{\"n\": 1858, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2412.14, \"learn_time_ms\": 56712.727}", "{\"n\": 1859, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2412.0, \"learn_time_ms\": 56737.217}", "{\"n\": 1860, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2416.6, \"learn_time_ms\": 56721.112}", "{\"n\": 1861, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2426.67, \"learn_time_ms\": 56691.501}", "{\"n\": 1862, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2427.38, \"learn_time_ms\": 56587.958}", "{\"n\": 1863, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2424.51, \"learn_time_ms\": 56662.136}", "{\"n\": 1864, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2417.61, \"learn_time_ms\": 56677.952}", "{\"n\": 1865, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2417.47, \"learn_time_ms\": 56608.369}", "{\"n\": 1866, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2414.2, \"learn_time_ms\": 56673.127}", "{\"n\": 1867, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2417.12, \"learn_time_ms\": 56614.459}", "{\"n\": 1868, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2424.19, \"learn_time_ms\": 56662.313}", "{\"n\": 1869, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2421.99, \"learn_time_ms\": 56681.085}", "{\"n\": 1870, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2421.98, \"learn_time_ms\": 56712.154}", "{\"n\": 1871, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2432.47, \"learn_time_ms\": 56711.188}", "{\"n\": 1872, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2427.93, \"learn_time_ms\": 56755.412}", "{\"n\": 1873, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2424.55, \"learn_time_ms\": 56600.587}", "{\"n\": 1874, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2423.48, \"learn_time_ms\": 56727.806}", "{\"n\": 1875, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2430.24, \"learn_time_ms\": 56787.404}", "{\"n\": 1876, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2432.23, \"learn_time_ms\": 56797.863}", "{\"n\": 1877, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2426.85, \"learn_time_ms\": 56825.513}", "{\"n\": 1878, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2423.43, \"learn_time_ms\": 56773.937}", "{\"n\": 1879, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2421.6, \"learn_time_ms\": 56760.128}", "{\"n\": 1880, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.03, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2424.35, \"learn_time_ms\": 56796.255}", "{\"n\": 1881, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2429.55, \"learn_time_ms\": 56713.903}", "{\"n\": 1882, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2422.6, \"learn_time_ms\": 56739.615}", "{\"n\": 1883, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2427.2, \"learn_time_ms\": 56900.076}", "{\"n\": 1884, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2427.2, \"learn_time_ms\": 56791.935}", "{\"n\": 1885, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2435.52, \"learn_time_ms\": 56731.737}", "{\"n\": 1886, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2421.61, \"learn_time_ms\": 56781.787}", "{\"n\": 1887, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2414.83, \"learn_time_ms\": 56709.699}", "{\"n\": 1888, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2412.34, \"learn_time_ms\": 56819.659}", "{\"n\": 1889, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2422.41, \"learn_time_ms\": 56765.248}", "{\"n\": 1890, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.16, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2415.81, \"learn_time_ms\": 56727.533}", "{\"n\": 1891, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2422.89, \"learn_time_ms\": 56797.713}", "{\"n\": 1892, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2422.89, \"learn_time_ms\": 56814.662}", "{\"n\": 1893, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2418.24, \"learn_time_ms\": 56770.673}", "{\"n\": 1894, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.29, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2408.8, \"learn_time_ms\": 56832.987}", "{\"n\": 1895, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2423.11, \"learn_time_ms\": 56848.7}", "{\"n\": 1896, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2422.92, \"learn_time_ms\": 56821.99}", "{\"n\": 1897, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.18, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2424.23, \"learn_time_ms\": 56880.977}", "{\"n\": 1898, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.19, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2424.88, \"learn_time_ms\": 56803.465}", "{\"n\": 1899, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2419.35, \"learn_time_ms\": 56825.808}", "{\"n\": 1900, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2427.74, \"learn_time_ms\": 56805.921}", "{\"n\": 1901, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2431.41, \"learn_time_ms\": 56837.039}", "{\"n\": 1902, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2431.41, \"learn_time_ms\": 56772.014}", "{\"n\": 1903, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2440.02, \"learn_time_ms\": 56780.958}", "{\"n\": 1904, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2452.03, \"learn_time_ms\": 56723.588}", "{\"n\": 1905, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2456.99, \"learn_time_ms\": 56738.247}", "{\"n\": 1906, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2456.99, \"learn_time_ms\": 56700.339}", "{\"n\": 1907, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2449.02, \"learn_time_ms\": 56712.921}", "{\"n\": 1908, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2450.24, \"learn_time_ms\": 56665.198}", "{\"n\": 1909, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2450.75, \"learn_time_ms\": 56693.886}", "{\"n\": 1910, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2458.04, \"learn_time_ms\": 56705.998}", "{\"n\": 1911, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2457.91, \"learn_time_ms\": 56647.127}", "{\"n\": 1912, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2456.73, \"learn_time_ms\": 56731.683}", "{\"n\": 1913, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2446.47, \"learn_time_ms\": 56660.102}", "{\"n\": 1914, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2448.17, \"learn_time_ms\": 56696.683}", "{\"n\": 1915, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2460.88, \"learn_time_ms\": 56653.596}", "{\"n\": 1916, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2471.39, \"learn_time_ms\": 56666.846}", "{\"n\": 1917, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2479.35, \"learn_time_ms\": 56583.394}", "{\"n\": 1918, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2485.21, \"learn_time_ms\": 56596.202}", "{\"n\": 1919, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2489.06, \"learn_time_ms\": 56605.607}", "{\"n\": 1920, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2493.95, \"learn_time_ms\": 56566.003}", "{\"n\": 1921, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2493.95, \"learn_time_ms\": 56598.712}", "{\"n\": 1922, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2497.36, \"learn_time_ms\": 56459.534}", "{\"n\": 1923, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2505.69, \"learn_time_ms\": 56550.258}", "{\"n\": 1924, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2504.6, \"learn_time_ms\": 56495.684}", "{\"n\": 1925, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2505.08, \"learn_time_ms\": 56570.088}", "{\"n\": 1926, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2514.34, \"learn_time_ms\": 56557.835}", "{\"n\": 1927, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2506.75, \"learn_time_ms\": 56604.067}", "{\"n\": 1928, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2506.75, \"learn_time_ms\": 56590.746}", "{\"n\": 1929, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2508.11, \"learn_time_ms\": 56630.954}", "{\"n\": 1930, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2508.11, \"learn_time_ms\": 56616.835}", "{\"n\": 1931, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2511.79, \"learn_time_ms\": 56623.879}", "{\"n\": 1932, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2510.9, \"learn_time_ms\": 56682.625}", "{\"n\": 1933, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2510.9, \"learn_time_ms\": 56757.829}", "{\"n\": 1934, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2499.31, \"learn_time_ms\": 56792.983}", "{\"n\": 1935, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2508.3, \"learn_time_ms\": 56780.468}", "{\"n\": 1936, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2511.07, \"learn_time_ms\": 56713.07}", "{\"n\": 1937, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2520.22, \"learn_time_ms\": 56644.23}", "{\"n\": 1938, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.5, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2512.49, \"learn_time_ms\": 56693.083}", "{\"n\": 1939, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2541.1, \"learn_time_ms\": 56627.912}", "{\"n\": 1940, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2541.1, \"learn_time_ms\": 56613.536}", "{\"n\": 1941, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2545.19, \"learn_time_ms\": 56632.1}", "{\"n\": 1942, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2550.4, \"learn_time_ms\": 56696.862}", "{\"n\": 1943, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2551.66, \"learn_time_ms\": 56608.019}", "{\"n\": 1944, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2562.97, \"learn_time_ms\": 56541.376}", "{\"n\": 1945, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2562.61, \"learn_time_ms\": 56591.857}", "{\"n\": 1946, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2560.81, \"learn_time_ms\": 56583.56}", "{\"n\": 1947, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.21, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2568.24, \"learn_time_ms\": 56651.167}", "{\"n\": 1948, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2571.42, \"learn_time_ms\": 56614.832}", "{\"n\": 1949, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2566.13, \"learn_time_ms\": 56599.779}", "{\"n\": 1950, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2566.13, \"learn_time_ms\": 56625.394}", "{\"n\": 1951, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2581.98, \"learn_time_ms\": 56589.517}", "{\"n\": 1952, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2577.19, \"learn_time_ms\": 56537.528}", "{\"n\": 1953, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.22, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2565.65, \"learn_time_ms\": 56534.427}", "{\"n\": 1954, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.19, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2565.72, \"learn_time_ms\": 56574.872}", "{\"n\": 1955, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2561.47, \"learn_time_ms\": 56559.719}", "{\"n\": 1956, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.31, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2557.18, \"learn_time_ms\": 56581.779}", "{\"n\": 1957, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.31, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2557.18, \"learn_time_ms\": 56648.402}", "{\"n\": 1958, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2562.24, \"learn_time_ms\": 56615.841}", "{\"n\": 1959, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2557.91, \"learn_time_ms\": 56562.393}", "{\"n\": 1960, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2562.62, \"learn_time_ms\": 56627.587}", "{\"n\": 1961, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2562.67, \"learn_time_ms\": 56589.847}", "{\"n\": 1962, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2564.17, \"learn_time_ms\": 56644.058}", "{\"n\": 1963, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.37, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2548.07, \"learn_time_ms\": 56602.182}", "{\"n\": 1964, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2551.3, \"learn_time_ms\": 56644.087}", "{\"n\": 1965, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2552.52, \"learn_time_ms\": 56586.146}", "{\"n\": 1966, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2550.88, \"learn_time_ms\": 56596.489}", "{\"n\": 1967, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2531.39, \"learn_time_ms\": 56479.643}", "{\"n\": 1968, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2531.39, \"learn_time_ms\": 56539.673}", "{\"n\": 1969, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.48, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2526.13, \"learn_time_ms\": 56628.61}", "{\"n\": 1970, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.48, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2526.13, \"learn_time_ms\": 56538.961}", "{\"n\": 1971, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2511.38, \"learn_time_ms\": 56610.361}", "{\"n\": 1972, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2519.32, \"learn_time_ms\": 56545.632}", "{\"n\": 1973, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2522.33, \"learn_time_ms\": 56525.729}", "{\"n\": 1974, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2519.17, \"learn_time_ms\": 56544.677}", "{\"n\": 1975, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2520.46, \"learn_time_ms\": 56587.951}", "{\"n\": 1976, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2524.47, \"learn_time_ms\": 56638.313}", "{\"n\": 1977, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2524.47, \"learn_time_ms\": 56675.491}", "{\"n\": 1978, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.48, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2530.13, \"learn_time_ms\": 56554.97}", "{\"n\": 1979, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2519.93, \"learn_time_ms\": 56568.863}", "{\"n\": 1980, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2527.35, \"learn_time_ms\": 56565.493}", "{\"n\": 1981, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2528.73, \"learn_time_ms\": 56553.874}", "{\"n\": 1982, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2528.73, \"learn_time_ms\": 56566.941}", "{\"n\": 1983, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2527.36, \"learn_time_ms\": 56606.854}", "{\"n\": 1984, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2527.32, \"learn_time_ms\": 56567.989}", "{\"n\": 1985, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2536.15, \"learn_time_ms\": 56574.454}", "{\"n\": 1986, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.54, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2536.15, \"learn_time_ms\": 56521.26}", "{\"n\": 1987, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.52, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2543.35, \"learn_time_ms\": 56551.023}", "{\"n\": 1988, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2534.83, \"learn_time_ms\": 56572.553}", "{\"n\": 1989, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.61, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2539.81, \"learn_time_ms\": 56568.693}", "{\"n\": 1990, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.56, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2544.13, \"learn_time_ms\": 56715.083}", "{\"n\": 1991, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2539.37, \"learn_time_ms\": 56665.979}", "{\"n\": 1992, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2526.35, \"learn_time_ms\": 56675.383}", "{\"n\": 1993, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2532.24, \"learn_time_ms\": 56731.535}", "{\"n\": 1994, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.62, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2525.47, \"learn_time_ms\": 56654.5}", "{\"n\": 1995, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2523.38, \"learn_time_ms\": 56736.437}", "{\"n\": 1996, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2509.76, \"learn_time_ms\": 56733.544}", "{\"n\": 1997, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2506.18, \"learn_time_ms\": 56739.55}", "{\"n\": 1998, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2503.78, \"learn_time_ms\": 56806.168}", "{\"n\": 1999, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2504.54, \"learn_time_ms\": 56694.911}", "{\"n\": 2000, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2498.94, \"learn_time_ms\": 56552.301}"]["{\"n\": 2001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 44704.214}", "{\"n\": 2002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43679.547}", "{\"n\": 2003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43295.716}", "{\"n\": 2004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43131.299}", "{\"n\": 2005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43129.448}", "{\"n\": 2006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43038.895}", "{\"n\": 2007, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -15.666666666666666, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2184.0, \"learn_time_ms\": 43032.67}", "{\"n\": 2008, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -15.4, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2215.0, \"learn_time_ms\": 42994.591}", "{\"n\": 2009, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -15.714285714285714, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2246.1428571428573, \"learn_time_ms\": 43036.906}", "{\"n\": 2010, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2365.25, \"learn_time_ms\": 43009.223}", "{\"n\": 2011, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -15.25, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2365.25, \"learn_time_ms\": 42752.753}", "{\"n\": 2012, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -15.333333333333334, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2310.1666666666665, \"learn_time_ms\": 42843.249}", "{\"n\": 2013, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -15.428571428571429, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2288.3571428571427, \"learn_time_ms\": 42881.787}", "{\"n\": 2014, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -15.1875, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2344.3125, \"learn_time_ms\": 42887.982}", "{\"n\": 2015, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -15.052631578947368, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2361.684210526316, \"learn_time_ms\": 42907.055}", "{\"n\": 2016, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2368.3809523809523, \"learn_time_ms\": 42944.416}", "{\"n\": 2017, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.954545454545455, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2399.7272727272725, \"learn_time_ms\": 42975.372}", "{\"n\": 2018, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.73913043478261, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2427.2608695652175, \"learn_time_ms\": 43108.117}", "{\"n\": 2019, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.884615384615385, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2396.3076923076924, \"learn_time_ms\": 43048.55}", "{\"n\": 2020, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.068965517241379, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2394.6206896551726, \"learn_time_ms\": 43088.204}", "{\"n\": 2021, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.966666666666667, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2397.4666666666667, \"learn_time_ms\": 43245.015}", "{\"n\": 2022, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.969696969696969, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2395.6060606060605, \"learn_time_ms\": 43115.23}", "{\"n\": 2023, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2390.5, \"learn_time_ms\": 43136.022}", "{\"n\": 2024, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.054054054054054, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2373.3513513513512, \"learn_time_ms\": 43168.556}", "{\"n\": 2025, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.973684210526315, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2389.342105263158, \"learn_time_ms\": 43113.012}", "{\"n\": 2026, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.048780487804878, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2384.9756097560976, \"learn_time_ms\": 43067.879}", "{\"n\": 2027, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.162790697674419, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2364.279069767442, \"learn_time_ms\": 43024.42}", "{\"n\": 2028, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.162790697674419, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2364.279069767442, \"learn_time_ms\": 42912.301}", "{\"n\": 2029, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.11111111111111, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2378.088888888889, \"learn_time_ms\": 42856.003}", "{\"n\": 2030, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.106382978723405, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2383.255319148936, \"learn_time_ms\": 42808.926}", "{\"n\": 2031, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.254901960784315, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2367.725490196078, \"learn_time_ms\": 42683.205}", "{\"n\": 2032, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.254901960784315, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2367.725490196078, \"learn_time_ms\": 42757.826}", "{\"n\": 2033, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.11320754716981, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2394.490566037736, \"learn_time_ms\": 42756.313}", "{\"n\": 2034, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.055555555555555, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2402.037037037037, \"learn_time_ms\": 42725.324}", "{\"n\": 2035, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.779661016949152, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2445.593220338983, \"learn_time_ms\": 42703.217}", "{\"n\": 2036, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.779661016949152, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2445.593220338983, \"learn_time_ms\": 42809.574}", "{\"n\": 2037, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.766666666666667, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2447.05, \"learn_time_ms\": 42729.84}", "{\"n\": 2038, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.80327868852459, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2446.311475409836, \"learn_time_ms\": 42761.593}", "{\"n\": 2039, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.825396825396826, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2441.777777777778, \"learn_time_ms\": 42754.077}", "{\"n\": 2040, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.727272727272727, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2444.242424242424, \"learn_time_ms\": 42713.189}", "{\"n\": 2041, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.661764705882353, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2458.676470588235, \"learn_time_ms\": 42763.045}", "{\"n\": 2042, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.666666666666666, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2455.5797101449275, \"learn_time_ms\": 42693.773}", "{\"n\": 2043, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.51388888888889, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2473.6944444444443, \"learn_time_ms\": 42727.208}", "{\"n\": 2044, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.472972972972974, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2480.2432432432433, \"learn_time_ms\": 42836.576}", "{\"n\": 2045, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.466666666666667, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2479.346666666667, \"learn_time_ms\": 42929.105}", "{\"n\": 2046, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.467532467532468, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2481.194805194805, \"learn_time_ms\": 42898.093}", "{\"n\": 2047, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.531645569620252, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2473.0, \"learn_time_ms\": 43010.494}", "{\"n\": 2048, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.512195121951219, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2479.743902439024, \"learn_time_ms\": 42992.016}", "{\"n\": 2049, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.464285714285714, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2485.5714285714284, \"learn_time_ms\": 43094.815}", "{\"n\": 2050, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.476744186046512, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2478.5348837209303, \"learn_time_ms\": 43179.98}", "{\"n\": 2051, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.459770114942529, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2482.5862068965516, \"learn_time_ms\": 43188.694}", "{\"n\": 2052, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.404494382022472, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2489.6853932584268, \"learn_time_ms\": 43178.763}", "{\"n\": 2053, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.45054945054945, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2482.6703296703295, \"learn_time_ms\": 43079.712}", "{\"n\": 2054, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.473118279569892, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2478.451612903226, \"learn_time_ms\": 42953.816}", "{\"n\": 2055, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.46808510638298, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2477.9893617021276, \"learn_time_ms\": 42946.425}", "{\"n\": 2056, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.458333333333334, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2481.53125, \"learn_time_ms\": 42878.565}", "{\"n\": 2057, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.434343434343434, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2487.050505050505, \"learn_time_ms\": 42884.18}", "{\"n\": 2058, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.434343434343434, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2487.050505050505, \"learn_time_ms\": 42793.236}", "{\"n\": 2059, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2493.32, \"learn_time_ms\": 42725.973}", "{\"n\": 2060, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2516.55, \"learn_time_ms\": 42615.967}", "{\"n\": 2061, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2516.18, \"learn_time_ms\": 42616.046}", "{\"n\": 2062, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.19, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2518.44, \"learn_time_ms\": 42721.24}", "{\"n\": 2063, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.2, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2513.5, \"learn_time_ms\": 42754.182}", "{\"n\": 2064, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2526.15, \"learn_time_ms\": 42772.355}", "{\"n\": 2065, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2526.15, \"learn_time_ms\": 42687.012}", "{\"n\": 2066, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2535.8, \"learn_time_ms\": 42792.64}", "{\"n\": 2067, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2528.12, \"learn_time_ms\": 42767.077}", "{\"n\": 2068, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2531.89, \"learn_time_ms\": 42778.011}", "{\"n\": 2069, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.03, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2534.62, \"learn_time_ms\": 42829.304}", "{\"n\": 2070, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.04, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2531.21, \"learn_time_ms\": 42901.16}", "{\"n\": 2071, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.11, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2527.49, \"learn_time_ms\": 42963.986}", "{\"n\": 2072, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.03, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2541.46, \"learn_time_ms\": 42916.573}", "{\"n\": 2073, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.03, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2541.33, \"learn_time_ms\": 42969.738}", "{\"n\": 2074, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.03, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2547.49, \"learn_time_ms\": 42999.031}", "{\"n\": 2075, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2550.7, \"learn_time_ms\": 43087.899}", "{\"n\": 2076, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2552.6, \"learn_time_ms\": 43031.583}", "{\"n\": 2077, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2554.48, \"learn_time_ms\": 43069.554}", "{\"n\": 2078, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.99, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2558.24, \"learn_time_ms\": 43116.411}", "{\"n\": 2079, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2567.04, \"learn_time_ms\": 43146.526}", "{\"n\": 2080, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2565.65, \"learn_time_ms\": 43146.309}", "{\"n\": 2081, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.82, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2585.75, \"learn_time_ms\": 43129.762}", "{\"n\": 2082, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.82, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2585.75, \"learn_time_ms\": 43111.137}", "{\"n\": 2083, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -13.77, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2592.97, \"learn_time_ms\": 43077.155}", "{\"n\": 2084, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.73, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2606.35, \"learn_time_ms\": 43059.878}", "{\"n\": 2085, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.74, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2597.26, \"learn_time_ms\": 43012.894}", "{\"n\": 2086, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.74, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2597.26, \"learn_time_ms\": 43015.131}", "{\"n\": 2087, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.74, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2597.26, \"learn_time_ms\": 42992.14}", "{\"n\": 2088, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.85, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2577.76, \"learn_time_ms\": 42973.866}", "{\"n\": 2089, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.99, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2565.98, \"learn_time_ms\": 43028.542}", "{\"n\": 2090, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.96, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2569.56, \"learn_time_ms\": 43138.097}", "{\"n\": 2091, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.96, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2569.56, \"learn_time_ms\": 43196.611}", "{\"n\": 2092, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.85, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2584.55, \"learn_time_ms\": 43269.664}", "{\"n\": 2093, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.85, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2596.93, \"learn_time_ms\": 43209.51}", "{\"n\": 2094, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.88, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2590.76, \"learn_time_ms\": 43308.244}", "{\"n\": 2095, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.88, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2590.76, \"learn_time_ms\": 43301.716}", "{\"n\": 2096, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.92, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2585.81, \"learn_time_ms\": 43315.144}", "{\"n\": 2097, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2580.82, \"learn_time_ms\": 43340.963}", "{\"n\": 2098, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.98, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2582.75, \"learn_time_ms\": 43339.651}", "{\"n\": 2099, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2579.56, \"learn_time_ms\": 43262.47}", "{\"n\": 2100, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2583.51, \"learn_time_ms\": 43154.815}", "{\"n\": 2101, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.85, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2599.26, \"learn_time_ms\": 43014.7}", "{\"n\": 2102, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2595.82, \"learn_time_ms\": 43011.986}", "{\"n\": 2103, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.9, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2592.09, \"learn_time_ms\": 43126.79}", "{\"n\": 2104, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2596.07, \"learn_time_ms\": 43075.699}", "{\"n\": 2105, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2593.26, \"learn_time_ms\": 43198.585}", "{\"n\": 2106, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2600.33, \"learn_time_ms\": 43113.513}", "{\"n\": 2107, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.91, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2607.06, \"learn_time_ms\": 43075.192}", "{\"n\": 2108, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2608.31, \"learn_time_ms\": 43115.242}", "{\"n\": 2109, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2607.29, \"learn_time_ms\": 43064.647}", "{\"n\": 2110, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2592.94, \"learn_time_ms\": 43106.92}", "{\"n\": 2111, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2592.94, \"learn_time_ms\": 43089.849}", "{\"n\": 2112, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2594.0, \"learn_time_ms\": 43067.379}", "{\"n\": 2113, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.16, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2580.7, \"learn_time_ms\": 43010.326}", "{\"n\": 2114, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2581.3, \"learn_time_ms\": 42997.733}", "{\"n\": 2115, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2581.43, \"learn_time_ms\": 42893.099}", "{\"n\": 2116, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2585.42, \"learn_time_ms\": 42919.462}", "{\"n\": 2117, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2580.08, \"learn_time_ms\": 42889.79}", "{\"n\": 2118, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2579.52, \"learn_time_ms\": 42877.028}", "{\"n\": 2119, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2588.25, \"learn_time_ms\": 43001.512}", "{\"n\": 2120, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.16, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2584.26, \"learn_time_ms\": 43023.522}", "{\"n\": 2121, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.16, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2584.26, \"learn_time_ms\": 43059.197}", "{\"n\": 2122, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2587.97, \"learn_time_ms\": 43004.343}", "{\"n\": 2123, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2587.46, \"learn_time_ms\": 43000.416}", "{\"n\": 2124, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.2, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2593.26, \"learn_time_ms\": 42966.01}", "{\"n\": 2125, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.2, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2593.26, \"learn_time_ms\": 42983.341}", "{\"n\": 2126, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.21, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2588.67, \"learn_time_ms\": 43021.666}", "{\"n\": 2127, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2583.06, \"learn_time_ms\": 43032.001}", "{\"n\": 2128, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2574.8, \"learn_time_ms\": 43024.454}", "{\"n\": 2129, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2576.38, \"learn_time_ms\": 42884.267}", "{\"n\": 2130, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.21, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2581.83, \"learn_time_ms\": 42858.954}", "{\"n\": 2131, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2576.48, \"learn_time_ms\": 42847.854}", "{\"n\": 2132, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2569.68, \"learn_time_ms\": 42860.023}", "{\"n\": 2133, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2565.63, \"learn_time_ms\": 42834.587}", "{\"n\": 2134, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2551.21, \"learn_time_ms\": 42782.618}", "{\"n\": 2135, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2551.21, \"learn_time_ms\": 42707.112}", "{\"n\": 2136, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2551.21, \"learn_time_ms\": 42790.712}", "{\"n\": 2137, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2550.45, \"learn_time_ms\": 42726.509}", "{\"n\": 2138, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.22, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2568.96, \"learn_time_ms\": 42754.047}", "{\"n\": 2139, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2571.32, \"learn_time_ms\": 42743.662}", "{\"n\": 2140, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2571.32, \"learn_time_ms\": 42675.36}", "{\"n\": 2141, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2571.32, \"learn_time_ms\": 42626.159}", "{\"n\": 2142, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2571.42, \"learn_time_ms\": 42676.008}", "{\"n\": 2143, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2578.5, \"learn_time_ms\": 42735.738}", "{\"n\": 2144, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2582.1, \"learn_time_ms\": 42774.058}", "{\"n\": 2145, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2582.1, \"learn_time_ms\": 42725.887}", "{\"n\": 2146, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2581.1, \"learn_time_ms\": 42595.111}", "{\"n\": 2147, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.16, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2579.31, \"learn_time_ms\": 42575.391}", "{\"n\": 2148, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2598.42, \"learn_time_ms\": 42588.448}", "{\"n\": 2149, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2592.7, \"learn_time_ms\": 42626.2}", "{\"n\": 2150, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2590.22, \"learn_time_ms\": 42711.286}", "{\"n\": 2151, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2589.23, \"learn_time_ms\": 42817.625}", "{\"n\": 2152, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.21, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2586.68, \"learn_time_ms\": 42799.53}", "{\"n\": 2153, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2576.16, \"learn_time_ms\": 42816.525}", "{\"n\": 2154, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2570.08, \"learn_time_ms\": 42841.542}", "{\"n\": 2155, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2561.85, \"learn_time_ms\": 42929.196}", "{\"n\": 2156, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2566.15, \"learn_time_ms\": 42875.887}", "{\"n\": 2157, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2558.58, \"learn_time_ms\": 42919.342}", "{\"n\": 2158, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2560.48, \"learn_time_ms\": 42873.709}", "{\"n\": 2159, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2567.56, \"learn_time_ms\": 42865.244}", "{\"n\": 2160, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2559.23, \"learn_time_ms\": 42880.728}", "{\"n\": 2161, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2561.67, \"learn_time_ms\": 42820.509}", "{\"n\": 2162, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2571.27, \"learn_time_ms\": 42842.377}", "{\"n\": 2163, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2573.38, \"learn_time_ms\": 42858.208}", "{\"n\": 2164, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2578.71, \"learn_time_ms\": 42732.288}", "{\"n\": 2165, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2592.46, \"learn_time_ms\": 42625.163}", "{\"n\": 2166, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2591.41, \"learn_time_ms\": 42721.385}", "{\"n\": 2167, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2588.5, \"learn_time_ms\": 42679.894}", "{\"n\": 2168, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2582.81, \"learn_time_ms\": 42794.127}", "{\"n\": 2169, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2587.5, \"learn_time_ms\": 42773.175}", "{\"n\": 2170, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2594.41, \"learn_time_ms\": 42653.931}", "{\"n\": 2171, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2591.54, \"learn_time_ms\": 42592.769}", "{\"n\": 2172, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2593.03, \"learn_time_ms\": 42612.958}", "{\"n\": 2173, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2582.54, \"learn_time_ms\": 42534.617}", "{\"n\": 2174, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2582.54, \"learn_time_ms\": 42720.268}", "{\"n\": 2175, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2596.36, \"learn_time_ms\": 42798.744}", "{\"n\": 2176, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.41, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2599.45, \"learn_time_ms\": 42775.583}", "{\"n\": 2177, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2590.71, \"learn_time_ms\": 42867.233}", "{\"n\": 2178, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.5, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2583.69, \"learn_time_ms\": 42754.225}", "{\"n\": 2179, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.52, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2579.44, \"learn_time_ms\": 42817.971}", "{\"n\": 2180, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.49, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2583.77, \"learn_time_ms\": 42861.404}", "{\"n\": 2181, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2576.11, \"learn_time_ms\": 42950.096}", "{\"n\": 2182, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2576.11, \"learn_time_ms\": 42887.145}", "{\"n\": 2183, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2579.21, \"learn_time_ms\": 42940.607}", "{\"n\": 2184, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.58, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2577.4, \"learn_time_ms\": 42851.875}", "{\"n\": 2185, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2578.84, \"learn_time_ms\": 42878.544}", "{\"n\": 2186, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2578.84, \"learn_time_ms\": 42870.13}", "{\"n\": 2187, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2570.19, \"learn_time_ms\": 42965.807}", "{\"n\": 2188, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2560.08, \"learn_time_ms\": 42980.433}", "{\"n\": 2189, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2546.77, \"learn_time_ms\": 42981.713}", "{\"n\": 2190, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2546.77, \"learn_time_ms\": 42950.762}", "{\"n\": 2191, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2554.43, \"learn_time_ms\": 42905.864}", "{\"n\": 2192, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2542.89, \"learn_time_ms\": 42866.201}", "{\"n\": 2193, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2541.65, \"learn_time_ms\": 42770.645}", "{\"n\": 2194, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2538.9, \"learn_time_ms\": 42825.742}", "{\"n\": 2195, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2531.05, \"learn_time_ms\": 42828.032}", "{\"n\": 2196, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2538.25, \"learn_time_ms\": 42933.923}", "{\"n\": 2197, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2534.1, \"learn_time_ms\": 42836.317}", "{\"n\": 2198, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2534.1, \"learn_time_ms\": 42733.189}", "{\"n\": 2199, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2536.62, \"learn_time_ms\": 42688.975}", "{\"n\": 2200, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2526.41, \"learn_time_ms\": 42759.418}", "{\"n\": 2201, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.01, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2506.85, \"learn_time_ms\": 42748.925}", "{\"n\": 2202, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2517.38, \"learn_time_ms\": 42825.488}", "{\"n\": 2203, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2512.17, \"learn_time_ms\": 42830.696}", "{\"n\": 2204, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2512.17, \"learn_time_ms\": 42781.642}", "{\"n\": 2205, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2518.18, \"learn_time_ms\": 42807.262}", "{\"n\": 2206, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2530.94, \"learn_time_ms\": 42629.773}", "{\"n\": 2207, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2540.54, \"learn_time_ms\": 42694.396}", "{\"n\": 2208, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2528.24, \"learn_time_ms\": 42772.581}", "{\"n\": 2209, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2527.35, \"learn_time_ms\": 42678.407}", "{\"n\": 2210, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2533.06, \"learn_time_ms\": 42661.936}", "{\"n\": 2211, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2533.39, \"learn_time_ms\": 42678.089}", "{\"n\": 2212, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2530.75, \"learn_time_ms\": 42759.807}", "{\"n\": 2213, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2525.04, \"learn_time_ms\": 42900.095}", "{\"n\": 2214, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2522.2, \"learn_time_ms\": 42894.682}", "{\"n\": 2215, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2508.61, \"learn_time_ms\": 42830.387}", "{\"n\": 2216, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2506.89, \"learn_time_ms\": 42985.071}", "{\"n\": 2217, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2493.98, \"learn_time_ms\": 42919.419}", "{\"n\": 2218, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2496.63, \"learn_time_ms\": 43015.909}", "{\"n\": 2219, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2510.65, \"learn_time_ms\": 43167.942}", "{\"n\": 2220, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2502.69, \"learn_time_ms\": 43136.568}", "{\"n\": 2221, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2505.12, \"learn_time_ms\": 43102.085}", "{\"n\": 2222, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2505.12, \"learn_time_ms\": 43035.533}", "{\"n\": 2223, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2507.08, \"learn_time_ms\": 42919.553}", "{\"n\": 2224, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2495.25, \"learn_time_ms\": 42907.363}", "{\"n\": 2225, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2483.88, \"learn_time_ms\": 42930.963}", "{\"n\": 2226, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2477.1, \"learn_time_ms\": 42890.41}", "{\"n\": 2227, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2465.36, \"learn_time_ms\": 42825.672}", "{\"n\": 2228, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2471.51, \"learn_time_ms\": 42746.052}", "{\"n\": 2229, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2479.61, \"learn_time_ms\": 42652.733}", "{\"n\": 2230, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2476.01, \"learn_time_ms\": 42620.639}", "{\"n\": 2231, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2473.11, \"learn_time_ms\": 42668.076}", "{\"n\": 2232, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2478.95, \"learn_time_ms\": 42546.679}", "{\"n\": 2233, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2483.75, \"learn_time_ms\": 42595.716}", "{\"n\": 2234, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2483.75, \"learn_time_ms\": 42602.729}", "{\"n\": 2235, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2480.48, \"learn_time_ms\": 42516.072}", "{\"n\": 2236, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2475.28, \"learn_time_ms\": 42565.114}", "{\"n\": 2237, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2486.91, \"learn_time_ms\": 42575.452}", "{\"n\": 2238, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2492.67, \"learn_time_ms\": 42648.173}", "{\"n\": 2239, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2505.25, \"learn_time_ms\": 42718.651}", "{\"n\": 2240, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2518.01, \"learn_time_ms\": 42791.073}", "{\"n\": 2241, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2532.42, \"learn_time_ms\": 42844.859}", "{\"n\": 2242, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2525.83, \"learn_time_ms\": 42997.178}", "{\"n\": 2243, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2524.41, \"learn_time_ms\": 42903.81}", "{\"n\": 2244, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2524.41, \"learn_time_ms\": 42899.142}", "{\"n\": 2245, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2521.95, \"learn_time_ms\": 43043.719}", "{\"n\": 2246, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.66, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2520.19, \"learn_time_ms\": 42996.246}", "{\"n\": 2247, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.64, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2520.5, \"learn_time_ms\": 42975.496}", "{\"n\": 2248, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2504.97, \"learn_time_ms\": 42990.465}", "{\"n\": 2249, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.8, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2506.53, \"learn_time_ms\": 42926.425}", "{\"n\": 2250, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2504.28, \"learn_time_ms\": 42825.145}", "{\"n\": 2251, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2503.72, \"learn_time_ms\": 42834.907}", "{\"n\": 2252, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.81, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2508.5, \"learn_time_ms\": 42766.152}", "{\"n\": 2253, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2510.55, \"learn_time_ms\": 42741.064}", "{\"n\": 2254, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.85, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2500.74, \"learn_time_ms\": 42767.833}", "{\"n\": 2255, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2511.0, \"learn_time_ms\": 42692.467}", "{\"n\": 2256, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.82, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2511.0, \"learn_time_ms\": 42721.604}", "{\"n\": 2257, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2502.46, \"learn_time_ms\": 42727.556}", "{\"n\": 2258, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2502.46, \"learn_time_ms\": 42598.625}", "{\"n\": 2259, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2495.34, \"learn_time_ms\": 42581.544}", "{\"n\": 2260, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2493.01, \"learn_time_ms\": 42634.052}", "{\"n\": 2261, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2517.93, \"learn_time_ms\": 42513.474}", "{\"n\": 2262, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2517.34, \"learn_time_ms\": 42466.594}", "{\"n\": 2263, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2514.59, \"learn_time_ms\": 42571.987}", "{\"n\": 2264, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2527.52, \"learn_time_ms\": 42558.924}", "{\"n\": 2265, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.75, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2532.05, \"learn_time_ms\": 42662.472}", "{\"n\": 2266, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2544.39, \"learn_time_ms\": 42650.599}", "{\"n\": 2267, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2544.39, \"learn_time_ms\": 42637.499}", "{\"n\": 2268, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2537.85, \"learn_time_ms\": 42689.888}", "{\"n\": 2269, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2549.38, \"learn_time_ms\": 42740.713}", "{\"n\": 2270, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2549.41, \"learn_time_ms\": 42719.508}", "{\"n\": 2271, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.73, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2547.17, \"learn_time_ms\": 42766.587}", "{\"n\": 2272, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.7, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2557.81, \"learn_time_ms\": 42789.214}", "{\"n\": 2273, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2559.55, \"learn_time_ms\": 42710.308}", "{\"n\": 2274, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.68, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2556.43, \"learn_time_ms\": 42705.457}", "{\"n\": 2275, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2565.16, \"learn_time_ms\": 42634.785}", "{\"n\": 2276, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2565.16, \"learn_time_ms\": 42608.682}", "{\"n\": 2277, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2556.54, \"learn_time_ms\": 42697.639}", "{\"n\": 2278, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2559.26, \"learn_time_ms\": 42715.354}", "{\"n\": 2279, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.65, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2564.86, \"learn_time_ms\": 42662.08}", "{\"n\": 2280, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2579.19, \"learn_time_ms\": 42806.261}", "{\"n\": 2281, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.6, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2579.19, \"learn_time_ms\": 42831.883}", "{\"n\": 2282, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2588.82, \"learn_time_ms\": 42919.258}", "{\"n\": 2283, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2596.35, \"learn_time_ms\": 42955.138}", "{\"n\": 2284, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2600.99, \"learn_time_ms\": 43022.646}", "{\"n\": 2285, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2599.04, \"learn_time_ms\": 43005.488}", "{\"n\": 2286, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.53, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2599.04, \"learn_time_ms\": 42992.421}", "{\"n\": 2287, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2622.08, \"learn_time_ms\": 42927.758}", "{\"n\": 2288, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2615.13, \"learn_time_ms\": 42926.633}", "{\"n\": 2289, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2634.52, \"learn_time_ms\": 42992.57}", "{\"n\": 2290, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.42, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2633.38, \"learn_time_ms\": 42907.953}", "{\"n\": 2291, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2628.92, \"learn_time_ms\": 42964.656}", "{\"n\": 2292, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2633.55, \"learn_time_ms\": 42907.328}", "{\"n\": 2293, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2634.6, \"learn_time_ms\": 42927.16}", "{\"n\": 2294, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.37, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2638.67, \"learn_time_ms\": 43013.329}", "{\"n\": 2295, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2630.99, \"learn_time_ms\": 43029.895}", "{\"n\": 2296, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2623.38, \"learn_time_ms\": 43078.207}", "{\"n\": 2297, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2622.81, \"learn_time_ms\": 43147.898}", "{\"n\": 2298, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2640.88, \"learn_time_ms\": 43200.152}", "{\"n\": 2299, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.29, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2654.09, \"learn_time_ms\": 43154.964}", "{\"n\": 2300, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2660.51, \"learn_time_ms\": 43148.023}", "{\"n\": 2301, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.21, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2668.06, \"learn_time_ms\": 43126.706}", "{\"n\": 2302, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.19, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2667.63, \"learn_time_ms\": 43222.0}", "{\"n\": 2303, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.08, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2688.59, \"learn_time_ms\": 43139.695}", "{\"n\": 2304, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.08, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2688.59, \"learn_time_ms\": 43020.772}", "{\"n\": 2305, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2691.86, \"learn_time_ms\": 43055.747}", "{\"n\": 2306, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.99, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2689.17, \"learn_time_ms\": 42971.797}", "{\"n\": 2307, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.99, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2690.85, \"learn_time_ms\": 42960.575}", "{\"n\": 2308, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.96, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2696.82, \"learn_time_ms\": 42842.22}", "{\"n\": 2309, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2702.49, \"learn_time_ms\": 42907.196}", "{\"n\": 2310, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2702.49, \"learn_time_ms\": 42871.953}", "{\"n\": 2311, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.98, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2699.52, \"learn_time_ms\": 42925.185}", "{\"n\": 2312, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2720.33, \"learn_time_ms\": 42791.851}", "{\"n\": 2313, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2720.33, \"learn_time_ms\": 42931.484}", "{\"n\": 2314, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.9, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2716.6, \"learn_time_ms\": 42981.339}", "{\"n\": 2315, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2709.31, \"learn_time_ms\": 42839.741}", "{\"n\": 2316, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2743.22, \"learn_time_ms\": 42842.749}", "{\"n\": 2317, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2743.22, \"learn_time_ms\": 42871.007}", "{\"n\": 2318, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.82, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2742.08, \"learn_time_ms\": 42880.093}", "{\"n\": 2319, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2740.46, \"learn_time_ms\": 42861.266}", "{\"n\": 2320, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.94, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2720.02, \"learn_time_ms\": 42867.44}", "{\"n\": 2321, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.83, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2736.52, \"learn_time_ms\": 42886.13}", "{\"n\": 2322, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.83, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2736.52, \"learn_time_ms\": 42851.881}", "{\"n\": 2323, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.82, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2733.44, \"learn_time_ms\": 42791.205}", "{\"n\": 2324, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.82, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2733.44, \"learn_time_ms\": 42634.504}", "{\"n\": 2325, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.85, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2729.64, \"learn_time_ms\": 42812.993}", "{\"n\": 2326, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2725.19, \"learn_time_ms\": 42842.302}", "{\"n\": 2327, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2725.19, \"learn_time_ms\": 42756.524}", "{\"n\": 2328, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2723.12, \"learn_time_ms\": 42802.377}", "{\"n\": 2329, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2719.01, \"learn_time_ms\": 42909.578}", "{\"n\": 2330, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2717.79, \"learn_time_ms\": 42917.549}", "{\"n\": 2331, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.83, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2726.41, \"learn_time_ms\": 42843.426}", "{\"n\": 2332, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.79, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2728.88, \"learn_time_ms\": 42889.874}", "{\"n\": 2333, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.75, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2734.85, \"learn_time_ms\": 42812.222}", "{\"n\": 2334, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2747.3, \"learn_time_ms\": 42841.065}", "{\"n\": 2335, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.61, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2763.99, \"learn_time_ms\": 42779.737}", "{\"n\": 2336, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2768.32, \"learn_time_ms\": 42755.487}", "{\"n\": 2337, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.63, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2761.62, \"learn_time_ms\": 42856.458}", "{\"n\": 2338, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.67, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2757.25, \"learn_time_ms\": 42786.509}", "{\"n\": 2339, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.68, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2752.25, \"learn_time_ms\": 42690.478}", "{\"n\": 2340, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.68, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2750.92, \"learn_time_ms\": 42727.17}", "{\"n\": 2341, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2744.49, \"learn_time_ms\": 42713.978}", "{\"n\": 2342, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2744.49, \"learn_time_ms\": 42648.584}", "{\"n\": 2343, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.79, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2724.95, \"learn_time_ms\": 42718.267}", "{\"n\": 2344, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.75, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2725.42, \"learn_time_ms\": 42797.289}", "{\"n\": 2345, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2730.24, \"learn_time_ms\": 42719.246}", "{\"n\": 2346, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.75, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2719.08, \"learn_time_ms\": 42803.917}", "{\"n\": 2347, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2724.09, \"learn_time_ms\": 42761.055}", "{\"n\": 2348, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.73, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2722.34, \"learn_time_ms\": 42801.106}", "{\"n\": 2349, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2717.16, \"learn_time_ms\": 42722.148}", "{\"n\": 2350, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.74, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2720.7, \"learn_time_ms\": 42711.298}", "{\"n\": 2351, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.74, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2720.7, \"learn_time_ms\": 42662.104}", "{\"n\": 2352, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.73, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2725.76, \"learn_time_ms\": 42691.897}", "{\"n\": 2353, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2724.44, \"learn_time_ms\": 42718.445}", "{\"n\": 2354, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2707.92, \"learn_time_ms\": 42852.4}", "{\"n\": 2355, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2707.92, \"learn_time_ms\": 42786.522}", "{\"n\": 2356, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.83, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2704.69, \"learn_time_ms\": 42832.028}", "{\"n\": 2357, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.84, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2703.25, \"learn_time_ms\": 42763.091}", "{\"n\": 2358, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.89, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2698.53, \"learn_time_ms\": 42787.405}", "{\"n\": 2359, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2694.23, \"learn_time_ms\": 42881.355}", "{\"n\": 2360, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2694.23, \"learn_time_ms\": 42940.554}", "{\"n\": 2361, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.98, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2678.01, \"learn_time_ms\": 43013.439}", "{\"n\": 2362, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.97, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2682.07, \"learn_time_ms\": 43105.8}", "{\"n\": 2363, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2674.86, \"learn_time_ms\": 43080.768}", "{\"n\": 2364, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.97, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2677.93, \"learn_time_ms\": 42972.309}", "{\"n\": 2365, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2673.61, \"learn_time_ms\": 43041.01}", "{\"n\": 2366, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.01, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2674.41, \"learn_time_ms\": 42939.047}", "{\"n\": 2367, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.08, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2664.14, \"learn_time_ms\": 42952.414}", "{\"n\": 2368, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.06, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2663.98, \"learn_time_ms\": 42916.209}", "{\"n\": 2369, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.08, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2650.93, \"learn_time_ms\": 42808.826}", "{\"n\": 2370, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2640.07, \"learn_time_ms\": 42774.192}", "{\"n\": 2371, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2640.07, \"learn_time_ms\": 42684.443}", "{\"n\": 2372, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.22, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2619.9, \"learn_time_ms\": 42638.697}", "{\"n\": 2373, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2608.29, \"learn_time_ms\": 42739.766}", "{\"n\": 2374, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.24, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2606.2, \"learn_time_ms\": 42642.404}", "{\"n\": 2375, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2604.29, \"learn_time_ms\": 42657.614}", "{\"n\": 2376, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2589.9, \"learn_time_ms\": 42602.021}", "{\"n\": 2377, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2598.72, \"learn_time_ms\": 42618.943}", "{\"n\": 2378, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.27, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2596.65, \"learn_time_ms\": 42622.898}", "{\"n\": 2379, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.26, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2598.83, \"learn_time_ms\": 42806.612}", "{\"n\": 2380, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2603.18, \"learn_time_ms\": 42723.246}", "{\"n\": 2381, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.2, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2605.25, \"learn_time_ms\": 42736.883}", "{\"n\": 2382, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.2, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2608.58, \"learn_time_ms\": 42839.117}", "{\"n\": 2383, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2615.79, \"learn_time_ms\": 42705.56}", "{\"n\": 2384, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2607.21, \"learn_time_ms\": 42684.814}", "{\"n\": 2385, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2596.56, \"learn_time_ms\": 42624.977}", "{\"n\": 2386, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2596.56, \"learn_time_ms\": 42597.362}", "{\"n\": 2387, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.35, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2581.8, \"learn_time_ms\": 42584.667}", "{\"n\": 2388, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2577.14, \"learn_time_ms\": 42613.048}", "{\"n\": 2389, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2570.66, \"learn_time_ms\": 42487.831}", "{\"n\": 2390, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2564.89, \"learn_time_ms\": 42584.843}", "{\"n\": 2391, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.42, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2566.84, \"learn_time_ms\": 42666.164}", "{\"n\": 2392, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.5, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2564.61, \"learn_time_ms\": 42501.943}", "{\"n\": 2393, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2561.89, \"learn_time_ms\": 42578.64}", "{\"n\": 2394, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2560.16, \"learn_time_ms\": 42700.71}", "{\"n\": 2395, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2565.01, \"learn_time_ms\": 42812.182}", "{\"n\": 2396, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2568.9, \"learn_time_ms\": 42822.6}", "{\"n\": 2397, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2573.15, \"learn_time_ms\": 42855.516}", "{\"n\": 2398, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2574.85, \"learn_time_ms\": 42868.745}", "{\"n\": 2399, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.42, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2570.08, \"learn_time_ms\": 42872.228}", "{\"n\": 2400, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.42, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2570.08, \"learn_time_ms\": 42826.771}", "{\"n\": 2401, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.43, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2573.11, \"learn_time_ms\": 42723.684}", "{\"n\": 2402, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.42, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2572.72, \"learn_time_ms\": 42726.314}", "{\"n\": 2403, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2566.2, \"learn_time_ms\": 42595.646}", "{\"n\": 2404, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2565.26, \"learn_time_ms\": 42579.878}", "{\"n\": 2405, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2565.26, \"learn_time_ms\": 42595.253}", "{\"n\": 2406, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2576.22, \"learn_time_ms\": 42645.826}", "{\"n\": 2407, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -14.36, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2571.71, \"learn_time_ms\": 42604.211}", "{\"n\": 2408, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2580.13, \"learn_time_ms\": 42545.088}", "{\"n\": 2409, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.28, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2584.06, \"learn_time_ms\": 42665.434}", "{\"n\": 2410, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2584.68, \"learn_time_ms\": 42685.276}", "{\"n\": 2411, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.3, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2584.68, \"learn_time_ms\": 42718.738}", "{\"n\": 2412, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2592.63, \"learn_time_ms\": 42768.735}", "{\"n\": 2413, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.25, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2592.21, \"learn_time_ms\": 42818.172}", "{\"n\": 2414, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.21, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2601.15, \"learn_time_ms\": 42861.544}", "{\"n\": 2415, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.21, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2601.15, \"learn_time_ms\": 42771.401}", "{\"n\": 2416, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2618.14, \"learn_time_ms\": 42796.122}", "{\"n\": 2417, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2625.46, \"learn_time_ms\": 42825.191}", "{\"n\": 2418, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2625.06, \"learn_time_ms\": 42862.278}", "{\"n\": 2419, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2625.06, \"learn_time_ms\": 42737.857}", "{\"n\": 2420, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2625.06, \"learn_time_ms\": 42666.158}", "{\"n\": 2421, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.99, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2638.78, \"learn_time_ms\": 42637.317}", "{\"n\": 2422, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2632.26, \"learn_time_ms\": 42677.867}", "{\"n\": 2423, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.01, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2637.9, \"learn_time_ms\": 42704.459}", "{\"n\": 2424, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.01, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2637.9, \"learn_time_ms\": 42713.467}", "{\"n\": 2425, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.93, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2659.28, \"learn_time_ms\": 42796.905}", "{\"n\": 2426, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.92, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2666.83, \"learn_time_ms\": 42693.099}", "{\"n\": 2427, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.85, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2675.14, \"learn_time_ms\": 42733.11}", "{\"n\": 2428, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.81, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2684.97, \"learn_time_ms\": 42831.185}", "{\"n\": 2429, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.81, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2689.71, \"learn_time_ms\": 42743.975}", "{\"n\": 2430, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.86, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2681.59, \"learn_time_ms\": 42912.155}", "{\"n\": 2431, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.86, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2683.89, \"learn_time_ms\": 42924.005}", "{\"n\": 2432, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.81, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2694.88, \"learn_time_ms\": 42854.769}", "{\"n\": 2433, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.76, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2702.63, \"learn_time_ms\": 42882.27}", "{\"n\": 2434, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.78, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2693.13, \"learn_time_ms\": 42796.226}", "{\"n\": 2435, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.78, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2693.13, \"learn_time_ms\": 42763.699}", "{\"n\": 2436, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.82, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2691.79, \"learn_time_ms\": 42827.735}", "{\"n\": 2437, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.78, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2705.46, \"learn_time_ms\": 42843.756}", "{\"n\": 2438, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.78, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2705.46, \"learn_time_ms\": 42730.355}", "{\"n\": 2439, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.75, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2701.08, \"learn_time_ms\": 42798.864}", "{\"n\": 2440, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.77, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2705.99, \"learn_time_ms\": 42643.008}", "{\"n\": 2441, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2703.84, \"learn_time_ms\": 42676.402}", "{\"n\": 2442, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2700.25, \"learn_time_ms\": 42635.828}", "{\"n\": 2443, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.72, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2700.25, \"learn_time_ms\": 42707.379}", "{\"n\": 2444, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.58, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2719.27, \"learn_time_ms\": 42746.673}", "{\"n\": 2445, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.55, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2724.76, \"learn_time_ms\": 42842.071}", "{\"n\": 2446, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.5, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2731.37, \"learn_time_ms\": 42833.36}", "{\"n\": 2447, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.45, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2738.85, \"learn_time_ms\": 42939.415}", "{\"n\": 2448, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.37, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2750.95, \"learn_time_ms\": 42989.199}", "{\"n\": 2449, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.32, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2759.08, \"learn_time_ms\": 43049.174}", "{\"n\": 2450, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2766.13, \"learn_time_ms\": 43064.141}", "{\"n\": 2451, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.26, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2760.52, \"learn_time_ms\": 43032.923}", "{\"n\": 2452, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.27, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2761.3, \"learn_time_ms\": 43077.617}", "{\"n\": 2453, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2773.76, \"learn_time_ms\": 42938.068}", "{\"n\": 2454, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2778.65, \"learn_time_ms\": 43006.477}", "{\"n\": 2455, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2792.69, \"learn_time_ms\": 42915.692}", "{\"n\": 2456, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2787.72, \"learn_time_ms\": 42981.584}", "{\"n\": 2457, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.08, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2801.94, \"learn_time_ms\": 42785.136}", "{\"n\": 2458, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2805.44, \"learn_time_ms\": 42740.281}", "{\"n\": 2459, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2803.55, \"learn_time_ms\": 42726.524}", "{\"n\": 2460, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2803.55, \"learn_time_ms\": 42800.571}", "{\"n\": 2461, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2810.71, \"learn_time_ms\": 42744.812}", "{\"n\": 2462, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2814.88, \"learn_time_ms\": 42724.626}", "{\"n\": 2463, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2819.88, \"learn_time_ms\": 42768.82}", "{\"n\": 2464, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2819.88, \"learn_time_ms\": 42665.773}", "{\"n\": 2465, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2819.88, \"learn_time_ms\": 42608.209}", "{\"n\": 2466, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2832.7, \"learn_time_ms\": 42632.203}", "{\"n\": 2467, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2823.77, \"learn_time_ms\": 42626.065}", "{\"n\": 2468, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2827.69, \"learn_time_ms\": 42705.102}", "{\"n\": 2469, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2827.69, \"learn_time_ms\": 42715.193}", "{\"n\": 2470, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2823.25, \"learn_time_ms\": 42588.694}", "{\"n\": 2471, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2842.85, \"learn_time_ms\": 42682.694}", "{\"n\": 2472, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2842.85, \"learn_time_ms\": 42702.83}", "{\"n\": 2473, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2842.85, \"learn_time_ms\": 42771.958}", "{\"n\": 2474, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.96, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2837.19, \"learn_time_ms\": 42857.223}", "{\"n\": 2475, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2829.24, \"learn_time_ms\": 42953.509}", "{\"n\": 2476, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2836.92, \"learn_time_ms\": 42819.49}", "{\"n\": 2477, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2836.92, \"learn_time_ms\": 42818.916}", "{\"n\": 2478, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2836.92, \"learn_time_ms\": 42784.847}", "{\"n\": 2479, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2841.68, \"learn_time_ms\": 42748.939}", "{\"n\": 2480, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.87, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2854.54, \"learn_time_ms\": 42811.317}", "{\"n\": 2481, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2857.66, \"learn_time_ms\": 42677.682}", "{\"n\": 2482, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2868.16, \"learn_time_ms\": 42751.103}", "{\"n\": 2483, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2860.98, \"learn_time_ms\": 42735.359}", "{\"n\": 2484, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2851.66, \"learn_time_ms\": 42609.428}", "{\"n\": 2485, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2848.38, \"learn_time_ms\": 42554.994}", "{\"n\": 2486, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2843.33, \"learn_time_ms\": 42691.896}", "{\"n\": 2487, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2840.53, \"learn_time_ms\": 42719.457}", "{\"n\": 2488, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2841.59, \"learn_time_ms\": 42669.558}", "{\"n\": 2489, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2841.59, \"learn_time_ms\": 42712.22}", "{\"n\": 2490, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2846.66, \"learn_time_ms\": 42773.995}", "{\"n\": 2491, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2854.47, \"learn_time_ms\": 42799.837}", "{\"n\": 2492, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2852.44, \"learn_time_ms\": 42811.752}", "{\"n\": 2493, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2851.18, \"learn_time_ms\": 42706.802}", "{\"n\": 2494, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2860.83, \"learn_time_ms\": 42738.076}", "{\"n\": 2495, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2844.52, \"learn_time_ms\": 42774.58}", "{\"n\": 2496, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.73, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2849.51, \"learn_time_ms\": 42706.637}", "{\"n\": 2497, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.77, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2846.59, \"learn_time_ms\": 42779.352}", "{\"n\": 2498, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2838.39, \"learn_time_ms\": 42801.32}", "{\"n\": 2499, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.81, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2835.02, \"learn_time_ms\": 42837.172}", "{\"n\": 2500, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2834.35, \"learn_time_ms\": 42654.933}", "{\"n\": 2501, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2837.48, \"learn_time_ms\": 42823.356}", "{\"n\": 2502, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2822.85, \"learn_time_ms\": 42696.94}", "{\"n\": 2503, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2822.45, \"learn_time_ms\": 42737.231}", "{\"n\": 2504, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2819.18, \"learn_time_ms\": 42763.72}", "{\"n\": 2505, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.06, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2812.31, \"learn_time_ms\": 42762.927}", "{\"n\": 2506, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2807.48, \"learn_time_ms\": 42687.427}", "{\"n\": 2507, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2798.05, \"learn_time_ms\": 42664.166}", "{\"n\": 2508, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2796.82, \"learn_time_ms\": 42622.384}", "{\"n\": 2509, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2799.09, \"learn_time_ms\": 42612.655}", "{\"n\": 2510, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2810.67, \"learn_time_ms\": 42808.69}", "{\"n\": 2511, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2796.15, \"learn_time_ms\": 42713.403}", "{\"n\": 2512, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2770.9, \"learn_time_ms\": 42810.749}", "{\"n\": 2513, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2770.9, \"learn_time_ms\": 42726.234}", "{\"n\": 2514, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2767.46, \"learn_time_ms\": 42690.876}", "{\"n\": 2515, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2782.43, \"learn_time_ms\": 42633.218}", "{\"n\": 2516, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2781.08, \"learn_time_ms\": 42697.972}", "{\"n\": 2517, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2790.54, \"learn_time_ms\": 42642.298}", "{\"n\": 2518, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2781.88, \"learn_time_ms\": 42614.733}", "{\"n\": 2519, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2790.69, \"learn_time_ms\": 42561.44}", "{\"n\": 2520, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2791.66, \"learn_time_ms\": 42513.553}", "{\"n\": 2521, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2794.82, \"learn_time_ms\": 42483.306}", "{\"n\": 2522, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2794.82, \"learn_time_ms\": 42531.199}", "{\"n\": 2523, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2790.91, \"learn_time_ms\": 42638.388}", "{\"n\": 2524, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2777.53, \"learn_time_ms\": 42614.963}", "{\"n\": 2525, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2789.96, \"learn_time_ms\": 42572.826}", "{\"n\": 2526, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2781.67, \"learn_time_ms\": 42616.777}", "{\"n\": 2527, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2783.64, \"learn_time_ms\": 42582.505}", "{\"n\": 2528, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2793.84, \"learn_time_ms\": 42595.952}", "{\"n\": 2529, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2783.57, \"learn_time_ms\": 42555.631}", "{\"n\": 2530, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2784.48, \"learn_time_ms\": 42568.738}", "{\"n\": 2531, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2790.87, \"learn_time_ms\": 42564.663}", "{\"n\": 2532, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.08, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2791.99, \"learn_time_ms\": 42495.651}", "{\"n\": 2533, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2798.92, \"learn_time_ms\": 42581.674}", "{\"n\": 2534, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2795.11, \"learn_time_ms\": 42629.723}", "{\"n\": 2535, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2795.11, \"learn_time_ms\": 42745.263}", "{\"n\": 2536, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2790.95, \"learn_time_ms\": 42689.135}", "{\"n\": 2537, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2789.01, \"learn_time_ms\": 42803.185}", "{\"n\": 2538, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2776.84, \"learn_time_ms\": 42871.925}", "{\"n\": 2539, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2776.84, \"learn_time_ms\": 42971.176}", "{\"n\": 2540, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2782.82, \"learn_time_ms\": 42917.563}", "{\"n\": 2541, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2780.38, \"learn_time_ms\": 43029.184}", "{\"n\": 2542, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2793.34, \"learn_time_ms\": 42973.572}", "{\"n\": 2543, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2792.15, \"learn_time_ms\": 42979.315}", "{\"n\": 2544, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2792.41, \"learn_time_ms\": 42972.911}", "{\"n\": 2545, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.16, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2805.33, \"learn_time_ms\": 42901.193}", "{\"n\": 2546, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2811.7, \"learn_time_ms\": 42977.757}", "{\"n\": 2547, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2820.32, \"learn_time_ms\": 42970.188}", "{\"n\": 2548, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2826.92, \"learn_time_ms\": 42868.965}", "{\"n\": 2549, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2826.92, \"learn_time_ms\": 42874.077}", "{\"n\": 2550, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.15, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2813.67, \"learn_time_ms\": 42841.413}", "{\"n\": 2551, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2817.41, \"learn_time_ms\": 42735.313}", "{\"n\": 2552, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2814.95, \"learn_time_ms\": 42849.219}", "{\"n\": 2553, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2823.31, \"learn_time_ms\": 42809.504}", "{\"n\": 2554, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2834.41, \"learn_time_ms\": 42781.107}", "{\"n\": 2555, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2829.87, \"learn_time_ms\": 42920.137}", "{\"n\": 2556, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2832.99, \"learn_time_ms\": 42898.883}", "{\"n\": 2557, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2829.05, \"learn_time_ms\": 42841.951}", "{\"n\": 2558, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2826.01, \"learn_time_ms\": 42922.813}", "{\"n\": 2559, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2837.07, \"learn_time_ms\": 42755.223}", "{\"n\": 2560, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2837.07, \"learn_time_ms\": 42737.753}", "{\"n\": 2561, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2836.3, \"learn_time_ms\": 42781.045}", "{\"n\": 2562, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2846.13, \"learn_time_ms\": 42662.665}", "{\"n\": 2563, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2844.11, \"learn_time_ms\": 42647.163}", "{\"n\": 2564, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2849.82, \"learn_time_ms\": 42721.5}", "{\"n\": 2565, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2868.4, \"learn_time_ms\": 42601.681}", "{\"n\": 2566, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2881.44, \"learn_time_ms\": 42610.005}", "{\"n\": 2567, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2881.44, \"learn_time_ms\": 42685.479}", "{\"n\": 2568, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2884.01, \"learn_time_ms\": 42661.988}", "{\"n\": 2569, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2887.5, \"learn_time_ms\": 42814.785}", "{\"n\": 2570, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2896.88, \"learn_time_ms\": 42885.787}", "{\"n\": 2571, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2897.52, \"learn_time_ms\": 42837.308}", "{\"n\": 2572, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2905.71, \"learn_time_ms\": 42975.109}", "{\"n\": 2573, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2905.71, \"learn_time_ms\": 42876.856}", "{\"n\": 2574, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2923.19, \"learn_time_ms\": 42844.825}", "{\"n\": 2575, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2915.46, \"learn_time_ms\": 42880.817}", "{\"n\": 2576, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2921.03, \"learn_time_ms\": 42825.644}", "{\"n\": 2577, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2921.03, \"learn_time_ms\": 42810.367}", "{\"n\": 2578, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2924.68, \"learn_time_ms\": 42848.167}", "{\"n\": 2579, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2906.29, \"learn_time_ms\": 42925.887}", "{\"n\": 2580, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2905.34, \"learn_time_ms\": 42963.7}", "{\"n\": 2581, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2908.56, \"learn_time_ms\": 43016.838}", "{\"n\": 2582, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2906.71, \"learn_time_ms\": 42947.952}", "{\"n\": 2583, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2896.37, \"learn_time_ms\": 43019.46}", "{\"n\": 2584, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2911.55, \"learn_time_ms\": 43006.374}", "{\"n\": 2585, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2910.24, \"learn_time_ms\": 43067.332}", "{\"n\": 2586, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2910.24, \"learn_time_ms\": 43086.939}", "{\"n\": 2587, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2908.08, \"learn_time_ms\": 43185.837}", "{\"n\": 2588, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2918.63, \"learn_time_ms\": 43137.233}", "{\"n\": 2589, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2909.97, \"learn_time_ms\": 43068.492}", "{\"n\": 2590, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2913.36, \"learn_time_ms\": 43058.715}", "{\"n\": 2591, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2921.08, \"learn_time_ms\": 43017.683}", "{\"n\": 2592, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2924.8, \"learn_time_ms\": 42976.482}", "{\"n\": 2593, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2919.65, \"learn_time_ms\": 42975.654}", "{\"n\": 2594, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2919.65, \"learn_time_ms\": 42924.124}", "{\"n\": 2595, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2911.19, \"learn_time_ms\": 42850.941}", "{\"n\": 2596, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2926.42, \"learn_time_ms\": 42853.317}", "{\"n\": 2597, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2924.6, \"learn_time_ms\": 42695.267}", "{\"n\": 2598, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2937.87, \"learn_time_ms\": 42763.42}", "{\"n\": 2599, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2937.87, \"learn_time_ms\": 42752.128}", "{\"n\": 2600, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2935.81, \"learn_time_ms\": 42735.217}", "{\"n\": 2601, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2943.29, \"learn_time_ms\": 42758.74}", "{\"n\": 2602, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2939.19, \"learn_time_ms\": 42793.575}", "{\"n\": 2603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2927.7, \"learn_time_ms\": 42838.265}", "{\"n\": 2604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2927.7, \"learn_time_ms\": 42854.561}", "{\"n\": 2605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2918.32, \"learn_time_ms\": 42861.644}", "{\"n\": 2606, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.42, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2918.32, \"learn_time_ms\": 42752.746}", "{\"n\": 2607, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2914.85, \"learn_time_ms\": 42702.738}", "{\"n\": 2608, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2921.88, \"learn_time_ms\": 42637.981}", "{\"n\": 2609, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.46, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2912.21, \"learn_time_ms\": 42593.655}", "{\"n\": 2610, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.38, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2927.5, \"learn_time_ms\": 42650.149}", "{\"n\": 2611, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.36, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2929.96, \"learn_time_ms\": 42718.508}", "{\"n\": 2612, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2932.64, \"learn_time_ms\": 42798.242}", "{\"n\": 2613, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2934.52, \"learn_time_ms\": 42703.148}", "{\"n\": 2614, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2946.77, \"learn_time_ms\": 42731.133}", "{\"n\": 2615, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2947.18, \"learn_time_ms\": 42765.77}", "{\"n\": 2616, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2946.95, \"learn_time_ms\": 42867.159}", "{\"n\": 2617, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2940.06, \"learn_time_ms\": 42940.201}", "{\"n\": 2618, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2952.6, \"learn_time_ms\": 43049.458}", "{\"n\": 2619, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.15, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2966.57, \"learn_time_ms\": 43004.746}", "{\"n\": 2620, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2962.55, \"learn_time_ms\": 43083.419}", "{\"n\": 2621, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2962.55, \"learn_time_ms\": 43054.446}", "{\"n\": 2622, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.21, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2963.35, \"learn_time_ms\": 42987.103}", "{\"n\": 2623, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2959.91, \"learn_time_ms\": 43040.082}", "{\"n\": 2624, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -12.24, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2955.24, \"learn_time_ms\": 43025.557}", "{\"n\": 2625, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2949.45, \"learn_time_ms\": 43041.41}", "{\"n\": 2626, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.41, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2934.96, \"learn_time_ms\": 43062.143}", "{\"n\": 2627, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.38, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2937.52, \"learn_time_ms\": 43041.985}", "{\"n\": 2628, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.38, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2937.52, \"learn_time_ms\": 42979.381}", "{\"n\": 2629, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2938.42, \"learn_time_ms\": 43104.759}", "{\"n\": 2630, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2924.86, \"learn_time_ms\": 43012.735}", "{\"n\": 2631, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.3, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2935.4, \"learn_time_ms\": 43043.453}", "{\"n\": 2632, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.28, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2943.37, \"learn_time_ms\": 43169.59}", "{\"n\": 2633, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.33, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2931.84, \"learn_time_ms\": 43187.877}", "{\"n\": 2634, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.31, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2939.2, \"learn_time_ms\": 43239.44}", "{\"n\": 2635, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.35, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2935.77, \"learn_time_ms\": 43205.016}", "{\"n\": 2636, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2930.13, \"learn_time_ms\": 43283.453}", "{\"n\": 2637, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.38, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2927.75, \"learn_time_ms\": 43270.198}", "{\"n\": 2638, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2925.35, \"learn_time_ms\": 43356.51}", "{\"n\": 2639, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.43, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2917.56, \"learn_time_ms\": 43284.794}", "{\"n\": 2640, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2911.27, \"learn_time_ms\": 43232.47}", "{\"n\": 2641, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.44, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2911.27, \"learn_time_ms\": 43148.813}", "{\"n\": 2642, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2905.44, \"learn_time_ms\": 43072.389}", "{\"n\": 2643, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2905.44, \"learn_time_ms\": 43052.634}", "{\"n\": 2644, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2905.44, \"learn_time_ms\": 43047.281}", "{\"n\": 2645, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2892.29, \"learn_time_ms\": 42990.944}", "{\"n\": 2646, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.45, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2905.76, \"learn_time_ms\": 42916.264}", "{\"n\": 2647, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2895.2, \"learn_time_ms\": 42965.319}", "{\"n\": 2648, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2895.2, \"learn_time_ms\": 42820.301}", "{\"n\": 2649, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2902.96, \"learn_time_ms\": 42917.932}", "{\"n\": 2650, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2902.08, \"learn_time_ms\": 42928.708}", "{\"n\": 2651, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.51, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2904.21, \"learn_time_ms\": 42984.765}", "{\"n\": 2652, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2894.31, \"learn_time_ms\": 43021.742}", "{\"n\": 2653, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2887.22, \"learn_time_ms\": 43061.386}", "{\"n\": 2654, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.58, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2888.4, \"learn_time_ms\": 43069.549}", "{\"n\": 2655, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.57, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2894.62, \"learn_time_ms\": 43128.92}", "{\"n\": 2656, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2891.11, \"learn_time_ms\": 43096.984}", "{\"n\": 2657, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2876.6, \"learn_time_ms\": 43034.615}", "{\"n\": 2658, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2876.6, \"learn_time_ms\": 43008.581}", "{\"n\": 2659, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.59, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2878.37, \"learn_time_ms\": 42868.592}", "{\"n\": 2660, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.66, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2864.05, \"learn_time_ms\": 42901.625}", "{\"n\": 2661, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2869.8, \"learn_time_ms\": 42951.014}", "{\"n\": 2662, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2869.8, \"learn_time_ms\": 42843.549}", "{\"n\": 2663, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2869.8, \"learn_time_ms\": 42711.585}", "{\"n\": 2664, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2868.5, \"learn_time_ms\": 42747.198}", "{\"n\": 2665, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.76, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2866.1, \"learn_time_ms\": 42749.775}", "{\"n\": 2666, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2853.35, \"learn_time_ms\": 42724.513}", "{\"n\": 2667, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2853.35, \"learn_time_ms\": 42805.664}", "{\"n\": 2668, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2842.48, \"learn_time_ms\": 42808.497}", "{\"n\": 2669, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.84, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2842.48, \"learn_time_ms\": 42869.535}", "{\"n\": 2670, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2830.75, \"learn_time_ms\": 42923.135}", "{\"n\": 2671, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2830.75, \"learn_time_ms\": 42874.909}", "{\"n\": 2672, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2824.58, \"learn_time_ms\": 42829.382}", "{\"n\": 2673, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2822.7, \"learn_time_ms\": 42946.272}", "{\"n\": 2674, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.86, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2819.02, \"learn_time_ms\": 42893.09}", "{\"n\": 2675, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2803.1, \"learn_time_ms\": 42752.669}", "{\"n\": 2676, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2788.23, \"learn_time_ms\": 42790.294}", "{\"n\": 2677, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2788.23, \"learn_time_ms\": 42764.747}", "{\"n\": 2678, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2789.41, \"learn_time_ms\": 42837.141}", "{\"n\": 2679, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2780.01, \"learn_time_ms\": 42849.185}", "{\"n\": 2680, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2780.01, \"learn_time_ms\": 42704.578}", "{\"n\": 2681, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2796.1, \"learn_time_ms\": 42662.013}", "{\"n\": 2682, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.81, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2801.97, \"learn_time_ms\": 42728.506}", "{\"n\": 2683, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2790.56, \"learn_time_ms\": 42685.428}", "{\"n\": 2684, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2790.56, \"learn_time_ms\": 42709.545}", "{\"n\": 2685, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2790.56, \"learn_time_ms\": 42824.818}", "{\"n\": 2686, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2795.68, \"learn_time_ms\": 42794.429}", "{\"n\": 2687, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.01, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2775.65, \"learn_time_ms\": 42766.533}", "{\"n\": 2688, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2769.22, \"learn_time_ms\": 42747.113}", "{\"n\": 2689, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2772.5, \"learn_time_ms\": 42752.112}", "{\"n\": 2690, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.1, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2764.65, \"learn_time_ms\": 42919.498}", "{\"n\": 2691, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2766.18, \"learn_time_ms\": 42981.734}", "{\"n\": 2692, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.04, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2778.57, \"learn_time_ms\": 43027.862}", "{\"n\": 2693, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2783.91, \"learn_time_ms\": 42977.372}", "{\"n\": 2694, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2782.11, \"learn_time_ms\": 42931.709}", "{\"n\": 2695, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2791.3, \"learn_time_ms\": 42919.326}", "{\"n\": 2696, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2794.84, \"learn_time_ms\": 42923.47}", "{\"n\": 2697, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2794.84, \"learn_time_ms\": 42836.754}", "{\"n\": 2698, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2815.32, \"learn_time_ms\": 42816.272}", "{\"n\": 2699, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2844.06, \"learn_time_ms\": 42872.026}", "{\"n\": 2700, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2844.06, \"learn_time_ms\": 42773.594}", "{\"n\": 2701, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2846.68, \"learn_time_ms\": 42747.547}", "{\"n\": 2702, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2846.68, \"learn_time_ms\": 42703.199}", "{\"n\": 2703, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2854.86, \"learn_time_ms\": 42806.596}", "{\"n\": 2704, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.63, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2840.21, \"learn_time_ms\": 42760.066}", "{\"n\": 2705, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2847.29, \"learn_time_ms\": 42733.118}", "{\"n\": 2706, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2847.29, \"learn_time_ms\": 42845.492}", "{\"n\": 2707, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.64, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2844.06, \"learn_time_ms\": 43011.544}", "{\"n\": 2708, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -12.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2838.14, \"learn_time_ms\": 43116.71}", "{\"n\": 2709, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2822.03, \"learn_time_ms\": 43014.964}", "{\"n\": 2710, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2822.03, \"learn_time_ms\": 42998.628}", "{\"n\": 2711, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2822.03, \"learn_time_ms\": 43005.821}", "{\"n\": 2712, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2825.81, \"learn_time_ms\": 42948.741}", "{\"n\": 2713, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2842.49, \"learn_time_ms\": 43037.3}", "{\"n\": 2714, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.74, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2840.93, \"learn_time_ms\": 43090.251}", "{\"n\": 2715, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2838.55, \"learn_time_ms\": 43140.167}", "{\"n\": 2716, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2838.55, \"learn_time_ms\": 43055.017}", "{\"n\": 2717, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.75, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2831.67, \"learn_time_ms\": 42962.131}", "{\"n\": 2718, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2841.76, \"learn_time_ms\": 43003.89}", "{\"n\": 2719, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2856.06, \"learn_time_ms\": 42955.74}", "{\"n\": 2720, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2867.97, \"learn_time_ms\": 43041.037}", "{\"n\": 2721, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2858.07, \"learn_time_ms\": 43151.616}", "{\"n\": 2722, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2859.61, \"learn_time_ms\": 43192.183}", "{\"n\": 2723, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2877.45, \"learn_time_ms\": 43056.221}", "{\"n\": 2724, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.4, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2877.45, \"learn_time_ms\": 43043.229}", "{\"n\": 2725, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2885.32, \"learn_time_ms\": 43002.076}", "{\"n\": 2726, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2881.74, \"learn_time_ms\": 42936.798}", "{\"n\": 2727, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2898.21, \"learn_time_ms\": 42932.138}", "{\"n\": 2728, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2896.17, \"learn_time_ms\": 42840.892}", "{\"n\": 2729, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2901.15, \"learn_time_ms\": 42837.014}", "{\"n\": 2730, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2908.4, \"learn_time_ms\": 42691.821}", "{\"n\": 2731, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2904.98, \"learn_time_ms\": 42657.205}", "{\"n\": 2732, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2905.63, \"learn_time_ms\": 42687.984}", "{\"n\": 2733, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2904.8, \"learn_time_ms\": 42685.042}", "{\"n\": 2734, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2895.37, \"learn_time_ms\": 42773.832}", "{\"n\": 2735, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2911.76, \"learn_time_ms\": 42810.818}", "{\"n\": 2736, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2918.39, \"learn_time_ms\": 42933.932}", "{\"n\": 2737, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2932.76, \"learn_time_ms\": 42957.345}", "{\"n\": 2738, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2944.56, \"learn_time_ms\": 43033.27}", "{\"n\": 2739, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2944.56, \"learn_time_ms\": 43040.177}", "{\"n\": 2740, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2946.83, \"learn_time_ms\": 43183.425}", "{\"n\": 2741, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2950.26, \"learn_time_ms\": 43048.675}", "{\"n\": 2742, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2945.6, \"learn_time_ms\": 43040.713}", "{\"n\": 2743, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2937.97, \"learn_time_ms\": 43061.996}", "{\"n\": 2744, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2930.89, \"learn_time_ms\": 43040.054}", "{\"n\": 2745, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2941.59, \"learn_time_ms\": 42925.876}", "{\"n\": 2746, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2945.03, \"learn_time_ms\": 42836.465}", "{\"n\": 2747, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2940.18, \"learn_time_ms\": 42913.913}", "{\"n\": 2748, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2940.18, \"learn_time_ms\": 42871.977}", "{\"n\": 2749, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2949.14, \"learn_time_ms\": 42914.774}", "{\"n\": 2750, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2974.0, \"learn_time_ms\": 42878.194}", "{\"n\": 2751, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2962.55, \"learn_time_ms\": 42940.95}", "{\"n\": 2752, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2962.55, \"learn_time_ms\": 42913.043}", "{\"n\": 2753, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2963.24, \"learn_time_ms\": 42845.727}", "{\"n\": 2754, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2956.84, \"learn_time_ms\": 42782.323}", "{\"n\": 2755, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2972.97, \"learn_time_ms\": 42814.742}", "{\"n\": 2756, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2960.91, \"learn_time_ms\": 42950.716}", "{\"n\": 2757, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2957.75, \"learn_time_ms\": 42914.114}", "{\"n\": 2758, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2931.77, \"learn_time_ms\": 42836.293}", "{\"n\": 2759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2938.18, \"learn_time_ms\": 42954.242}", "{\"n\": 2760, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2938.18, \"learn_time_ms\": 42914.999}", "{\"n\": 2761, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2935.91, \"learn_time_ms\": 42922.091}", "{\"n\": 2762, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2929.33, \"learn_time_ms\": 42846.307}", "{\"n\": 2763, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2930.03, \"learn_time_ms\": 42908.105}", "{\"n\": 2764, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2934.29, \"learn_time_ms\": 42943.276}", "{\"n\": 2765, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2934.29, \"learn_time_ms\": 42984.42}", "{\"n\": 2766, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2955.15, \"learn_time_ms\": 42942.808}", "{\"n\": 2767, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2947.61, \"learn_time_ms\": 42784.37}", "{\"n\": 2768, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2947.61, \"learn_time_ms\": 42855.965}", "{\"n\": 2769, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2956.01, \"learn_time_ms\": 42869.973}", "{\"n\": 2770, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2962.26, \"learn_time_ms\": 42910.58}", "{\"n\": 2771, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2962.26, \"learn_time_ms\": 42930.822}", "{\"n\": 2772, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2962.94, \"learn_time_ms\": 42938.896}", "{\"n\": 2773, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2973.75, \"learn_time_ms\": 43002.283}", "{\"n\": 2774, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2960.44, \"learn_time_ms\": 43041.012}", "{\"n\": 2775, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2960.44, \"learn_time_ms\": 43132.31}", "{\"n\": 2776, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2960.46, \"learn_time_ms\": 43070.61}", "{\"n\": 2777, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2955.52, \"learn_time_ms\": 43184.111}", "{\"n\": 2778, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2945.58, \"learn_time_ms\": 43085.466}", "{\"n\": 2779, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2932.31, \"learn_time_ms\": 42911.188}", "{\"n\": 2780, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2940.25, \"learn_time_ms\": 42902.937}", "{\"n\": 2781, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2925.28, \"learn_time_ms\": 42898.622}", "{\"n\": 2782, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2930.04, \"learn_time_ms\": 42969.642}", "{\"n\": 2783, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2935.22, \"learn_time_ms\": 42920.989}", "{\"n\": 2784, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.05, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2929.49, \"learn_time_ms\": 43014.194}", "{\"n\": 2785, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2941.86, \"learn_time_ms\": 43065.106}", "{\"n\": 2786, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2932.75, \"learn_time_ms\": 43145.082}", "{\"n\": 2787, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2933.43, \"learn_time_ms\": 43129.717}", "{\"n\": 2788, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2946.0, \"learn_time_ms\": 43193.961}", "{\"n\": 2789, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2943.39, \"learn_time_ms\": 43271.408}", "{\"n\": 2790, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2932.66, \"learn_time_ms\": 43319.581}", "{\"n\": 2791, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2934.11, \"learn_time_ms\": 43195.32}", "{\"n\": 2792, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2934.11, \"learn_time_ms\": 43135.878}", "{\"n\": 2793, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2927.65, \"learn_time_ms\": 43112.144}", "{\"n\": 2794, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2935.73, \"learn_time_ms\": 42987.862}", "{\"n\": 2795, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2951.57, \"learn_time_ms\": 42898.366}", "{\"n\": 2796, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2962.07, \"learn_time_ms\": 42883.592}", "{\"n\": 2797, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2962.26, \"learn_time_ms\": 42960.626}", "{\"n\": 2798, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2962.83, \"learn_time_ms\": 43025.236}", "{\"n\": 2799, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2967.39, \"learn_time_ms\": 43052.464}", "{\"n\": 2800, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2970.43, \"learn_time_ms\": 43012.404}", "{\"n\": 2801, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2970.43, \"learn_time_ms\": 43124.841}", "{\"n\": 2802, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2973.93, \"learn_time_ms\": 43158.285}", "{\"n\": 2803, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2972.21, \"learn_time_ms\": 43141.305}", "{\"n\": 2804, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2977.55, \"learn_time_ms\": 43140.18}", "{\"n\": 2805, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2986.58, \"learn_time_ms\": 43126.459}", "{\"n\": 2806, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2988.82, \"learn_time_ms\": 43080.291}", "{\"n\": 2807, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2988.82, \"learn_time_ms\": 43031.461}", "{\"n\": 2808, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2977.64, \"learn_time_ms\": 43001.968}", "{\"n\": 2809, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2989.17, \"learn_time_ms\": 42922.866}", "{\"n\": 2810, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2998.53, \"learn_time_ms\": 42940.677}", "{\"n\": 2811, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2998.53, \"learn_time_ms\": 42949.769}", "{\"n\": 2812, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2998.53, \"learn_time_ms\": 42924.996}", "{\"n\": 2813, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2991.65, \"learn_time_ms\": 42934.412}", "{\"n\": 2814, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2998.53, \"learn_time_ms\": 42878.825}", "{\"n\": 2815, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2998.53, \"learn_time_ms\": 42821.255}", "{\"n\": 2816, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3007.12, \"learn_time_ms\": 42751.099}", "{\"n\": 2817, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2991.52, \"learn_time_ms\": 42812.916}", "{\"n\": 2818, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2970.28, \"learn_time_ms\": 42758.431}", "{\"n\": 2819, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2987.93, \"learn_time_ms\": 42745.349}", "{\"n\": 2820, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2987.93, \"learn_time_ms\": 42894.74}", "{\"n\": 2821, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2993.78, \"learn_time_ms\": 42806.343}", "{\"n\": 2822, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2971.88, \"learn_time_ms\": 42832.034}", "{\"n\": 2823, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2988.32, \"learn_time_ms\": 42965.232}", "{\"n\": 2824, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2988.32, \"learn_time_ms\": 42944.236}", "{\"n\": 2825, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2984.25, \"learn_time_ms\": 42997.523}", "{\"n\": 2826, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2986.33, \"learn_time_ms\": 43067.365}", "{\"n\": 2827, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2973.34, \"learn_time_ms\": 42997.741}", "{\"n\": 2828, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2960.64, \"learn_time_ms\": 43008.68}", "{\"n\": 2829, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2966.78, \"learn_time_ms\": 43103.185}", "{\"n\": 2830, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2966.78, \"learn_time_ms\": 42898.092}", "{\"n\": 2831, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2968.79, \"learn_time_ms\": 42886.834}", "{\"n\": 2832, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2996.35, \"learn_time_ms\": 42937.373}", "{\"n\": 2833, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2996.35, \"learn_time_ms\": 42796.146}", "{\"n\": 2834, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2989.98, \"learn_time_ms\": 42771.857}", "{\"n\": 2835, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2985.35, \"learn_time_ms\": 42758.312}", "{\"n\": 2836, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2976.74, \"learn_time_ms\": 42682.736}", "{\"n\": 2837, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2987.06, \"learn_time_ms\": 42657.904}", "{\"n\": 2838, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2981.3, \"learn_time_ms\": 42770.531}", "{\"n\": 2839, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2988.08, \"learn_time_ms\": 42739.267}", "{\"n\": 2840, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2994.84, \"learn_time_ms\": 42755.224}", "{\"n\": 2841, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -12.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2994.32, \"learn_time_ms\": 42877.114}", "{\"n\": 2842, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3002.06, \"learn_time_ms\": 42918.747}", "{\"n\": 2843, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3002.06, \"learn_time_ms\": 42886.373}", "{\"n\": 2844, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3007.43, \"learn_time_ms\": 43003.453}", "{\"n\": 2845, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3003.91, \"learn_time_ms\": 43070.206}", "{\"n\": 2846, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 2997.33, \"learn_time_ms\": 43092.743}", "{\"n\": 2847, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2993.85, \"learn_time_ms\": 43199.231}", "{\"n\": 2848, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2993.85, \"learn_time_ms\": 43028.379}", "{\"n\": 2849, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2993.84, \"learn_time_ms\": 42946.97}", "{\"n\": 2850, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3001.91, \"learn_time_ms\": 42967.231}", "{\"n\": 2851, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3001.91, \"learn_time_ms\": 42888.1}", "{\"n\": 2852, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3009.56, \"learn_time_ms\": 42825.013}", "{\"n\": 2853, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3009.56, \"learn_time_ms\": 42803.46}", "{\"n\": 2854, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3014.29, \"learn_time_ms\": 42700.709}", "{\"n\": 2855, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3008.86, \"learn_time_ms\": 42643.924}", "{\"n\": 2856, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3007.07, \"learn_time_ms\": 42662.827}", "{\"n\": 2857, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3014.93, \"learn_time_ms\": 42586.508}", "{\"n\": 2858, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3007.48, \"learn_time_ms\": 42659.827}", "{\"n\": 2859, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3000.34, \"learn_time_ms\": 42686.295}", "{\"n\": 2860, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2980.27, \"learn_time_ms\": 42612.862}", "{\"n\": 2861, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2985.86, \"learn_time_ms\": 42580.134}", "{\"n\": 2862, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.91, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2984.21, \"learn_time_ms\": 42568.09}", "{\"n\": 2863, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2991.3, \"learn_time_ms\": 42632.131}", "{\"n\": 2864, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2996.27, \"learn_time_ms\": 42637.745}", "{\"n\": 2865, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2983.3, \"learn_time_ms\": 42617.202}", "{\"n\": 2866, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.85, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2990.35, \"learn_time_ms\": 42683.131}", "{\"n\": 2867, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2998.26, \"learn_time_ms\": 42621.08}", "{\"n\": 2868, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2994.32, \"learn_time_ms\": 42761.247}", "{\"n\": 2869, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2987.56, \"learn_time_ms\": 42748.807}", "{\"n\": 2870, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2989.77, \"learn_time_ms\": 42868.354}", "{\"n\": 2871, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2977.01, \"learn_time_ms\": 42880.026}", "{\"n\": 2872, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2998.68, \"learn_time_ms\": 42869.965}", "{\"n\": 2873, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2992.21, \"learn_time_ms\": 42920.025}", "{\"n\": 2874, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2992.21, \"learn_time_ms\": 42953.902}", "{\"n\": 2875, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2991.89, \"learn_time_ms\": 42958.351}", "{\"n\": 2876, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2990.59, \"learn_time_ms\": 42954.706}", "{\"n\": 2877, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -11.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2978.76, \"learn_time_ms\": 43059.108}", "{\"n\": 2878, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2993.32, \"learn_time_ms\": 42926.9}", "{\"n\": 2879, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2993.32, \"learn_time_ms\": 42980.278}", "{\"n\": 2880, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2993.32, \"learn_time_ms\": 43030.372}", "{\"n\": 2881, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2996.77, \"learn_time_ms\": 43057.597}", "{\"n\": 2882, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3003.36, \"learn_time_ms\": 43071.071}", "{\"n\": 2883, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3017.53, \"learn_time_ms\": 43040.699}", "{\"n\": 2884, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3001.69, \"learn_time_ms\": 42991.449}", "{\"n\": 2885, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3001.69, \"learn_time_ms\": 42956.458}", "{\"n\": 2886, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 2999.83, \"learn_time_ms\": 42989.95}", "{\"n\": 2887, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3006.11, \"learn_time_ms\": 42922.569}", "{\"n\": 2888, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3023.05, \"learn_time_ms\": 42901.809}", "{\"n\": 2889, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3032.79, \"learn_time_ms\": 42853.758}", "{\"n\": 2890, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3036.59, \"learn_time_ms\": 42709.997}", "{\"n\": 2891, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3036.59, \"learn_time_ms\": 42786.629}", "{\"n\": 2892, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3051.39, \"learn_time_ms\": 42890.309}", "{\"n\": 2893, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3055.04, \"learn_time_ms\": 43043.327}", "{\"n\": 2894, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3052.16, \"learn_time_ms\": 43239.814}", "{\"n\": 2895, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3044.04, \"learn_time_ms\": 43463.766}", "{\"n\": 2896, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3036.97, \"learn_time_ms\": 43612.736}", "{\"n\": 2897, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3040.51, \"learn_time_ms\": 43904.92}", "{\"n\": 2898, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3042.18, \"learn_time_ms\": 44242.197}", "{\"n\": 2899, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.31, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3045.47, \"learn_time_ms\": 44359.283}", "{\"n\": 2900, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3052.85, \"learn_time_ms\": 44537.739}", "{\"n\": 2901, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3052.85, \"learn_time_ms\": 44612.442}", "{\"n\": 2902, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3052.85, \"learn_time_ms\": 44610.526}", "{\"n\": 2903, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3038.39, \"learn_time_ms\": 44606.7}", "{\"n\": 2904, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3048.45, \"learn_time_ms\": 44756.853}", "{\"n\": 2905, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3050.68, \"learn_time_ms\": 44746.375}", "{\"n\": 2906, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3050.68, \"learn_time_ms\": 44816.525}", "{\"n\": 2907, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3043.88, \"learn_time_ms\": 44679.968}", "{\"n\": 2908, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3052.29, \"learn_time_ms\": 44506.167}", "{\"n\": 2909, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3061.93, \"learn_time_ms\": 44738.192}", "{\"n\": 2910, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3070.01, \"learn_time_ms\": 44847.881}", "{\"n\": 2911, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3070.01, \"learn_time_ms\": 44977.448}", "{\"n\": 2912, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3070.01, \"learn_time_ms\": 45137.997}", "{\"n\": 2913, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3068.19, \"learn_time_ms\": 45242.963}", "{\"n\": 2914, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3071.47, \"learn_time_ms\": 45225.225}", "{\"n\": 2915, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3074.02, \"learn_time_ms\": 45374.674}", "{\"n\": 2916, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3075.19, \"learn_time_ms\": 45380.454}", "{\"n\": 2917, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3079.74, \"learn_time_ms\": 45503.814}", "{\"n\": 2918, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3077.3, \"learn_time_ms\": 45614.387}", "{\"n\": 2919, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3077.3, \"learn_time_ms\": 45531.544}", "{\"n\": 2920, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3090.24, \"learn_time_ms\": 45466.124}", "{\"n\": 2921, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3081.02, \"learn_time_ms\": 45502.515}", "{\"n\": 2922, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3082.01, \"learn_time_ms\": 45552.781}", "{\"n\": 2923, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3082.01, \"learn_time_ms\": 45654.328}", "{\"n\": 2924, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3082.01, \"learn_time_ms\": 45613.407}", "{\"n\": 2925, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3087.14, \"learn_time_ms\": 45485.366}", "{\"n\": 2926, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3097.25, \"learn_time_ms\": 45472.192}", "{\"n\": 2927, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3090.82, \"learn_time_ms\": 45457.49}", "{\"n\": 2928, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3089.04, \"learn_time_ms\": 45416.753}", "{\"n\": 2929, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3088.36, \"learn_time_ms\": 45319.038}", "{\"n\": 2930, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3091.58, \"learn_time_ms\": 45319.579}", "{\"n\": 2931, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3093.5, \"learn_time_ms\": 45355.585}", "{\"n\": 2932, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3099.2, \"learn_time_ms\": 45226.505}", "{\"n\": 2933, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3099.2, \"learn_time_ms\": 45124.354}", "{\"n\": 2934, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3121.66, \"learn_time_ms\": 45110.524}", "{\"n\": 2935, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3109.0, \"learn_time_ms\": 45222.955}", "{\"n\": 2936, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3105.95, \"learn_time_ms\": 45202.043}", "{\"n\": 2937, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3118.22, \"learn_time_ms\": 45198.278}", "{\"n\": 2938, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3118.22, \"learn_time_ms\": 45304.448}", "{\"n\": 2939, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3125.57, \"learn_time_ms\": 45395.996}", "{\"n\": 2940, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3113.67, \"learn_time_ms\": 45383.322}", "{\"n\": 2941, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3112.02, \"learn_time_ms\": 45309.787}", "{\"n\": 2942, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3112.11, \"learn_time_ms\": 45385.275}", "{\"n\": 2943, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3101.42, \"learn_time_ms\": 45478.775}", "{\"n\": 2944, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3108.65, \"learn_time_ms\": 45522.623}", "{\"n\": 2945, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3093.55, \"learn_time_ms\": 45427.366}", "{\"n\": 2946, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3095.33, \"learn_time_ms\": 45505.511}", "{\"n\": 2947, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3095.33, \"learn_time_ms\": 45511.346}", "{\"n\": 2948, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3104.35, \"learn_time_ms\": 45415.871}", "{\"n\": 2949, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3092.36, \"learn_time_ms\": 45418.622}", "{\"n\": 2950, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3089.79, \"learn_time_ms\": 45441.016}", "{\"n\": 2951, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3073.69, \"learn_time_ms\": 45457.103}", "{\"n\": 2952, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3073.69, \"learn_time_ms\": 45532.788}", "{\"n\": 2953, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3070.15, \"learn_time_ms\": 45392.415}", "{\"n\": 2954, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3070.15, \"learn_time_ms\": 45319.992}", "{\"n\": 2955, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.42, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3062.93, \"learn_time_ms\": 45351.684}", "{\"n\": 2956, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3055.42, \"learn_time_ms\": 45140.69}", "{\"n\": 2957, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3045.07, \"learn_time_ms\": 45121.607}", "{\"n\": 2958, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3048.26, \"learn_time_ms\": 45133.154}", "{\"n\": 2959, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3042.13, \"learn_time_ms\": 45161.218}", "{\"n\": 2960, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3037.79, \"learn_time_ms\": 45218.07}", "{\"n\": 2961, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3037.79, \"learn_time_ms\": 45183.398}", "{\"n\": 2962, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3033.62, \"learn_time_ms\": 45039.979}", "{\"n\": 2963, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3036.95, \"learn_time_ms\": 45096.594}", "{\"n\": 2964, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.58, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3035.48, \"learn_time_ms\": 45043.742}", "{\"n\": 2965, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3032.94, \"learn_time_ms\": 45130.313}", "{\"n\": 2966, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3049.61, \"learn_time_ms\": 45307.166}", "{\"n\": 2967, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3042.4, \"learn_time_ms\": 45333.91}", "{\"n\": 2968, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3035.87, \"learn_time_ms\": 45305.184}", "{\"n\": 2969, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3035.87, \"learn_time_ms\": 45344.839}", "{\"n\": 2970, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3031.04, \"learn_time_ms\": 45366.64}", "{\"n\": 2971, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.59, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3021.72, \"learn_time_ms\": 45377.559}", "{\"n\": 2972, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3027.08, \"learn_time_ms\": 45495.537}", "{\"n\": 2973, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3034.3, \"learn_time_ms\": 45489.502}", "{\"n\": 2974, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3032.85, \"learn_time_ms\": 45662.337}", "{\"n\": 2975, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3035.07, \"learn_time_ms\": 45628.024}", "{\"n\": 2976, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.47, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3037.14, \"learn_time_ms\": 45426.231}", "{\"n\": 2977, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.45, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3037.12, \"learn_time_ms\": 45463.471}", "{\"n\": 2978, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3032.34, \"learn_time_ms\": 45465.222}", "{\"n\": 2979, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3022.69, \"learn_time_ms\": 45483.134}", "{\"n\": 2980, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3021.68, \"learn_time_ms\": 45366.316}", "{\"n\": 2981, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3021.68, \"learn_time_ms\": 45323.006}", "{\"n\": 2982, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3016.43, \"learn_time_ms\": 45251.494}", "{\"n\": 2983, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3026.1, \"learn_time_ms\": 45213.092}", "{\"n\": 2984, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3031.81, \"learn_time_ms\": 45192.157}", "{\"n\": 2985, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3031.81, \"learn_time_ms\": 45104.377}", "{\"n\": 2986, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.38, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3033.98, \"learn_time_ms\": 45277.898}", "{\"n\": 2987, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3034.7, \"learn_time_ms\": 45344.788}", "{\"n\": 2988, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3005.98, \"learn_time_ms\": 45399.41}", "{\"n\": 2989, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.52, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3002.65, \"learn_time_ms\": 45437.036}", "{\"n\": 2990, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3012.45, \"learn_time_ms\": 45457.964}", "{\"n\": 2991, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3009.94, \"learn_time_ms\": 45582.039}", "{\"n\": 2992, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3009.94, \"learn_time_ms\": 45588.949}", "{\"n\": 2993, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3007.11, \"learn_time_ms\": 45589.674}", "{\"n\": 2994, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3013.31, \"learn_time_ms\": 45520.828}", "{\"n\": 2995, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.49, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3013.31, \"learn_time_ms\": 45575.926}", "{\"n\": 2996, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3008.51, \"learn_time_ms\": 45466.214}", "{\"n\": 2997, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3004.67, \"learn_time_ms\": 45424.323}", "{\"n\": 2998, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3001.28, \"learn_time_ms\": 45419.34}", "{\"n\": 2999, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2993.27, \"learn_time_ms\": 45416.766}", "{\"n\": 3000, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2993.52, \"learn_time_ms\": 45415.753}"]["{\"n\": 3001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 45608.268}", "{\"n\": 3002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 44108.768}", "{\"n\": 3003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43576.645}", "{\"n\": 3004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43425.492}", "{\"n\": 3005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43382.328}", "{\"n\": 3006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43323.128}", "{\"n\": 3007, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2255.0, \"learn_time_ms\": 43344.45}", "{\"n\": 3008, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2255.0, \"learn_time_ms\": 43249.132}", "{\"n\": 3009, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2579.0, \"learn_time_ms\": 43251.325}", "{\"n\": 3010, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -13.5, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2649.5, \"learn_time_ms\": 43252.836}", "{\"n\": 3011, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -12.571428571428571, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2792.5714285714284, \"learn_time_ms\": 42973.05}", "{\"n\": 3012, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2690.125, \"learn_time_ms\": 42999.876}", "{\"n\": 3013, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.777777777777779, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2724.8888888888887, \"learn_time_ms\": 42965.154}", "{\"n\": 3014, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.777777777777779, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2724.8888888888887, \"learn_time_ms\": 42960.888}", "{\"n\": 3015, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.636363636363637, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2764.909090909091, \"learn_time_ms\": 43006.372}", "{\"n\": 3016, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -12.461538461538462, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2779.6153846153848, \"learn_time_ms\": 43014.249}", "{\"n\": 3017, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.733333333333333, \"episode_reward_max\": -5.0, \"episode_len_mean\": 2875.266666666667, \"learn_time_ms\": 42934.873}", "{\"n\": 3018, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.235294117647058, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2967.764705882353, \"learn_time_ms\": 43060.293}", "{\"n\": 3019, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.235294117647058, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2967.764705882353, \"learn_time_ms\": 43044.139}", "{\"n\": 3020, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.157894736842104, \"episode_reward_max\": -4.0, \"episode_len_mean\": 2982.157894736842, \"learn_time_ms\": 42993.309}", "{\"n\": 3021, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.047619047619047, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3042.904761904762, \"learn_time_ms\": 42989.916}", "{\"n\": 3022, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.916666666666666, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3084.2916666666665, \"learn_time_ms\": 43057.13}", "{\"n\": 3023, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.916666666666666, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3084.2916666666665, \"learn_time_ms\": 43130.925}", "{\"n\": 3024, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3094.08, \"learn_time_ms\": 43098.638}", "{\"n\": 3025, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76923076923077, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3087.1153846153848, \"learn_time_ms\": 43115.648}", "{\"n\": 3026, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.966666666666667, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3055.5666666666666, \"learn_time_ms\": 43084.535}", "{\"n\": 3027, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3052.40625, \"learn_time_ms\": 43125.278}", "{\"n\": 3028, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3052.40625, \"learn_time_ms\": 43014.072}", "{\"n\": 3029, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.06060606060606, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3049.181818181818, \"learn_time_ms\": 43054.922}", "{\"n\": 3030, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.942857142857143, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3081.1428571428573, \"learn_time_ms\": 43146.216}", "{\"n\": 3031, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3073.3513513513512, \"learn_time_ms\": 43184.673}", "{\"n\": 3032, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.973684210526315, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3077.1315789473683, \"learn_time_ms\": 43261.135}", "{\"n\": 3033, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3068.358974358974, \"learn_time_ms\": 43293.203}", "{\"n\": 3034, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.121951219512194, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3050.682926829268, \"learn_time_ms\": 43327.942}", "{\"n\": 3035, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.071428571428571, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3063.5, \"learn_time_ms\": 43210.321}", "{\"n\": 3036, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.071428571428571, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3063.5, \"learn_time_ms\": 43214.173}", "{\"n\": 3037, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3042.4666666666667, \"learn_time_ms\": 43109.592}", "{\"n\": 3038, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.170212765957446, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3056.1063829787236, \"learn_time_ms\": 43259.335}", "{\"n\": 3039, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.170212765957446, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3056.1063829787236, \"learn_time_ms\": 43171.784}", "{\"n\": 3040, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.204081632653061, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3051.9795918367345, \"learn_time_ms\": 43173.213}", "{\"n\": 3041, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3088.28, \"learn_time_ms\": 43238.412}", "{\"n\": 3042, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.87037037037037, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3111.296296296296, \"learn_time_ms\": 43094.225}", "{\"n\": 3043, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.87037037037037, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3111.296296296296, \"learn_time_ms\": 43011.899}", "{\"n\": 3044, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.690909090909091, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3138.490909090909, \"learn_time_ms\": 42992.279}", "{\"n\": 3045, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.68421052631579, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3136.245614035088, \"learn_time_ms\": 43001.174}", "{\"n\": 3046, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.59322033898305, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3158.830508474576, \"learn_time_ms\": 43044.541}", "{\"n\": 3047, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.59322033898305, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3158.830508474576, \"learn_time_ms\": 43232.653}", "{\"n\": 3048, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.714285714285714, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3140.031746031746, \"learn_time_ms\": 43072.634}", "{\"n\": 3049, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.734375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3136.328125, \"learn_time_ms\": 43138.532}", "{\"n\": 3050, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.723076923076922, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3138.1384615384613, \"learn_time_ms\": 43172.744}", "{\"n\": 3051, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.727272727272727, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3141.060606060606, \"learn_time_ms\": 43078.431}", "{\"n\": 3052, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.666666666666666, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3139.768115942029, \"learn_time_ms\": 43121.632}", "{\"n\": 3053, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76056338028169, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3125.2676056338028, \"learn_time_ms\": 43111.037}", "{\"n\": 3054, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76056338028169, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3125.2676056338028, \"learn_time_ms\": 43144.752}", "{\"n\": 3055, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.684931506849315, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3133.931506849315, \"learn_time_ms\": 43236.102}", "{\"n\": 3056, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.684931506849315, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3133.931506849315, \"learn_time_ms\": 43167.027}", "{\"n\": 3057, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.855263157894736, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3116.0131578947367, \"learn_time_ms\": 43147.649}", "{\"n\": 3058, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.844155844155845, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3113.064935064935, \"learn_time_ms\": 43129.161}", "{\"n\": 3059, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.873417721518987, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3102.8734177215188, \"learn_time_ms\": 43076.742}", "{\"n\": 3060, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.728395061728396, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3132.9876543209875, \"learn_time_ms\": 42913.02}", "{\"n\": 3061, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.728395061728396, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3132.9876543209875, \"learn_time_ms\": 42933.15}", "{\"n\": 3062, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.734939759036145, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3128.843373493976, \"learn_time_ms\": 42920.741}", "{\"n\": 3063, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.686046511627907, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3132.5116279069766, \"learn_time_ms\": 42952.705}", "{\"n\": 3064, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.655172413793103, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3135.7816091954023, \"learn_time_ms\": 42971.578}", "{\"n\": 3065, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.595505617977528, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3147.438202247191, \"learn_time_ms\": 42823.921}", "{\"n\": 3066, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.595505617977528, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3147.438202247191, \"learn_time_ms\": 42903.769}", "{\"n\": 3067, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.615384615384615, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3147.7582417582416, \"learn_time_ms\": 42839.927}", "{\"n\": 3068, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.698924731182796, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3132.8172043010754, \"learn_time_ms\": 42887.339}", "{\"n\": 3069, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3131.6770833333335, \"learn_time_ms\": 42903.383}", "{\"n\": 3070, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.6875, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3131.6770833333335, \"learn_time_ms\": 43041.354}", "{\"n\": 3071, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76530612244898, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3124.4897959183672, \"learn_time_ms\": 42977.461}", "{\"n\": 3072, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.757575757575758, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3126.989898989899, \"learn_time_ms\": 42897.716}", "{\"n\": 3073, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3134.44, \"learn_time_ms\": 42923.99}", "{\"n\": 3074, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3139.6, \"learn_time_ms\": 42986.027}", "{\"n\": 3075, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3148.6, \"learn_time_ms\": 43125.476}", "{\"n\": 3076, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3137.67, \"learn_time_ms\": 43083.409}", "{\"n\": 3077, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3143.32, \"learn_time_ms\": 43003.034}", "{\"n\": 3078, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3145.6, \"learn_time_ms\": 42993.612}", "{\"n\": 3079, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3144.86, \"learn_time_ms\": 42976.041}", "{\"n\": 3080, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3160.56, \"learn_time_ms\": 42930.305}", "{\"n\": 3081, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3160.56, \"learn_time_ms\": 43029.957}", "{\"n\": 3082, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3146.73, \"learn_time_ms\": 43124.659}", "{\"n\": 3083, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3129.63, \"learn_time_ms\": 43092.796}", "{\"n\": 3084, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3119.64, \"learn_time_ms\": 43067.899}", "{\"n\": 3085, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3119.64, \"learn_time_ms\": 43107.128}", "{\"n\": 3086, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3114.63, \"learn_time_ms\": 43120.288}", "{\"n\": 3087, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3114.63, \"learn_time_ms\": 43214.381}", "{\"n\": 3088, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3110.1, \"learn_time_ms\": 43144.439}", "{\"n\": 3089, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3110.84, \"learn_time_ms\": 43112.84}", "{\"n\": 3090, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3106.93, \"learn_time_ms\": 43078.233}", "{\"n\": 3091, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3093.89, \"learn_time_ms\": 43042.994}", "{\"n\": 3092, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3094.0, \"learn_time_ms\": 43005.275}", "{\"n\": 3093, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3073.44, \"learn_time_ms\": 43081.971}", "{\"n\": 3094, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3073.44, \"learn_time_ms\": 43017.681}", "{\"n\": 3095, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3082.68, \"learn_time_ms\": 42887.666}", "{\"n\": 3096, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3082.86, \"learn_time_ms\": 42932.247}", "{\"n\": 3097, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3082.32, \"learn_time_ms\": 42923.549}", "{\"n\": 3098, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3087.6, \"learn_time_ms\": 43002.627}", "{\"n\": 3099, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3082.31, \"learn_time_ms\": 43002.081}", "{\"n\": 3100, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3088.51, \"learn_time_ms\": 43030.03}", "{\"n\": 3101, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3076.6, \"learn_time_ms\": 43011.67}", "{\"n\": 3102, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3076.6, \"learn_time_ms\": 43034.624}", "{\"n\": 3103, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3080.0, \"learn_time_ms\": 43025.159}", "{\"n\": 3104, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3068.15, \"learn_time_ms\": 43039.063}", "{\"n\": 3105, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3061.76, \"learn_time_ms\": 43203.045}", "{\"n\": 3106, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3059.36, \"learn_time_ms\": 43206.699}", "{\"n\": 3107, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.66, \"learn_time_ms\": 43255.863}", "{\"n\": 3108, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.66, \"learn_time_ms\": 43430.435}", "{\"n\": 3109, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3033.35, \"learn_time_ms\": 43482.225}", "{\"n\": 3110, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.66, \"learn_time_ms\": 43477.952}", "{\"n\": 3111, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3043.72, \"learn_time_ms\": 43507.184}", "{\"n\": 3112, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3050.83, \"learn_time_ms\": 43509.252}", "{\"n\": 3113, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3064.96, \"learn_time_ms\": 43541.172}", "{\"n\": 3114, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3069.3, \"learn_time_ms\": 43577.725}", "{\"n\": 3115, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3069.3, \"learn_time_ms\": 43407.479}", "{\"n\": 3116, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3063.89, \"learn_time_ms\": 43399.598}", "{\"n\": 3117, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3069.98, \"learn_time_ms\": 43299.008}", "{\"n\": 3118, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3073.97, \"learn_time_ms\": 43054.872}", "{\"n\": 3119, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3073.97, \"learn_time_ms\": 43130.864}", "{\"n\": 3120, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3073.97, \"learn_time_ms\": 43171.663}", "{\"n\": 3121, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3082.81, \"learn_time_ms\": 43110.505}", "{\"n\": 3122, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3089.24, \"learn_time_ms\": 43094.993}", "{\"n\": 3123, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3066.24, \"learn_time_ms\": 43063.753}", "{\"n\": 3124, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3068.92, \"learn_time_ms\": 43045.114}", "{\"n\": 3125, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3074.25, \"learn_time_ms\": 43017.334}", "{\"n\": 3126, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3074.25, \"learn_time_ms\": 43028.044}", "{\"n\": 3127, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3064.62, \"learn_time_ms\": 43072.623}", "{\"n\": 3128, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3054.41, \"learn_time_ms\": 43185.058}", "{\"n\": 3129, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3045.59, \"learn_time_ms\": 43134.133}", "{\"n\": 3130, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3051.18, \"learn_time_ms\": 43082.485}", "{\"n\": 3131, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3050.56, \"learn_time_ms\": 43159.075}", "{\"n\": 3132, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3050.56, \"learn_time_ms\": 43120.264}", "{\"n\": 3133, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3050.13, \"learn_time_ms\": 43021.665}", "{\"n\": 3134, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3052.15, \"learn_time_ms\": 43047.466}", "{\"n\": 3135, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3033.04, \"learn_time_ms\": 43056.07}", "{\"n\": 3136, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3022.87, \"learn_time_ms\": 43056.114}", "{\"n\": 3137, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3006.98, \"learn_time_ms\": 43036.544}", "{\"n\": 3138, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3006.98, \"learn_time_ms\": 43116.896}", "{\"n\": 3139, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3017.62, \"learn_time_ms\": 43225.854}", "{\"n\": 3140, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3026.6, \"learn_time_ms\": 43218.578}", "{\"n\": 3141, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3022.82, \"learn_time_ms\": 43263.651}", "{\"n\": 3142, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3016.26, \"learn_time_ms\": 43327.031}", "{\"n\": 3143, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3016.26, \"learn_time_ms\": 43360.891}", "{\"n\": 3144, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3021.08, \"learn_time_ms\": 43301.726}", "{\"n\": 3145, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3019.85, \"learn_time_ms\": 43375.106}", "{\"n\": 3146, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3017.81, \"learn_time_ms\": 43342.191}", "{\"n\": 3147, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3017.81, \"learn_time_ms\": 43315.909}", "{\"n\": 3148, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3010.4, \"learn_time_ms\": 43235.892}", "{\"n\": 3149, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3015.48, \"learn_time_ms\": 43139.908}", "{\"n\": 3150, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3006.49, \"learn_time_ms\": 43136.15}", "{\"n\": 3151, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3013.26, \"learn_time_ms\": 43060.962}", "{\"n\": 3152, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3014.13, \"learn_time_ms\": 43105.417}", "{\"n\": 3153, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3014.13, \"learn_time_ms\": 43232.632}", "{\"n\": 3154, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3023.04, \"learn_time_ms\": 43272.682}", "{\"n\": 3155, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3022.77, \"learn_time_ms\": 43269.427}", "{\"n\": 3156, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.3, \"learn_time_ms\": 43269.634}", "{\"n\": 3157, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.07, \"learn_time_ms\": 43363.424}", "{\"n\": 3158, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.07, \"learn_time_ms\": 43295.817}", "{\"n\": 3159, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.79, \"learn_time_ms\": 43291.897}", "{\"n\": 3160, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.48, \"learn_time_ms\": 43257.728}", "{\"n\": 3161, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3039.9, \"learn_time_ms\": 43362.518}", "{\"n\": 3162, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.13, \"learn_time_ms\": 43376.612}", "{\"n\": 3163, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.13, \"learn_time_ms\": 43221.464}", "{\"n\": 3164, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3033.64, \"learn_time_ms\": 43189.643}", "{\"n\": 3165, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3046.7, \"learn_time_ms\": 43239.468}", "{\"n\": 3166, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3037.37, \"learn_time_ms\": 43184.961}", "{\"n\": 3167, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3031.96, \"learn_time_ms\": 43206.62}", "{\"n\": 3168, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3031.96, \"learn_time_ms\": 43270.875}", "{\"n\": 3169, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3032.42, \"learn_time_ms\": 43264.159}", "{\"n\": 3170, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3038.31, \"learn_time_ms\": 43239.548}", "{\"n\": 3171, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3032.73, \"learn_time_ms\": 43182.368}", "{\"n\": 3172, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3032.73, \"learn_time_ms\": 43125.049}", "{\"n\": 3173, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3029.72, \"learn_time_ms\": 43258.374}", "{\"n\": 3174, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3035.14, \"learn_time_ms\": 43259.398}", "{\"n\": 3175, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3018.29, \"learn_time_ms\": 43212.912}", "{\"n\": 3176, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3010.21, \"learn_time_ms\": 43251.718}", "{\"n\": 3177, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.24, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3004.75, \"learn_time_ms\": 43193.139}", "{\"n\": 3178, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3005.76, \"learn_time_ms\": 43177.471}", "{\"n\": 3179, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3011.97, \"learn_time_ms\": 43225.888}", "{\"n\": 3180, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3016.58, \"learn_time_ms\": 43339.507}", "{\"n\": 3181, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3028.63, \"learn_time_ms\": 43257.668}", "{\"n\": 3182, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3025.71, \"learn_time_ms\": 43240.345}", "{\"n\": 3183, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3025.71, \"learn_time_ms\": 43112.148}", "{\"n\": 3184, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3018.14, \"learn_time_ms\": 43132.89}", "{\"n\": 3185, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3034.31, \"learn_time_ms\": 43086.371}", "{\"n\": 3186, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3041.38, \"learn_time_ms\": 43073.749}", "{\"n\": 3187, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3027.02, \"learn_time_ms\": 43101.69}", "{\"n\": 3188, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.14, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3027.02, \"learn_time_ms\": 43119.564}", "{\"n\": 3189, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.15, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3036.27, \"learn_time_ms\": 42964.534}", "{\"n\": 3190, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3044.83, \"learn_time_ms\": 42960.628}", "{\"n\": 3191, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3038.49, \"learn_time_ms\": 42930.751}", "{\"n\": 3192, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3047.05, \"learn_time_ms\": 42868.86}", "{\"n\": 3193, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3047.05, \"learn_time_ms\": 42944.264}", "{\"n\": 3194, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3050.36, \"learn_time_ms\": 42961.38}", "{\"n\": 3195, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3047.57, \"learn_time_ms\": 43019.269}", "{\"n\": 3196, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3042.63, \"learn_time_ms\": 43074.815}", "{\"n\": 3197, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3062.91, \"learn_time_ms\": 43023.171}", "{\"n\": 3198, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3062.91, \"learn_time_ms\": 43016.314}", "{\"n\": 3199, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3063.49, \"learn_time_ms\": 43074.626}", "{\"n\": 3200, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3069.92, \"learn_time_ms\": 43037.154}", "{\"n\": 3201, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3101.31, \"learn_time_ms\": 43115.396}", "{\"n\": 3202, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3107.99, \"learn_time_ms\": 43172.89}", "{\"n\": 3203, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3116.07, \"learn_time_ms\": 43151.317}", "{\"n\": 3204, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3108.32, \"learn_time_ms\": 43116.24}", "{\"n\": 3205, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3099.98, \"learn_time_ms\": 43039.949}", "{\"n\": 3206, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3110.14, \"learn_time_ms\": 42988.861}", "{\"n\": 3207, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3112.24, \"learn_time_ms\": 43095.016}", "{\"n\": 3208, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3112.24, \"learn_time_ms\": 43032.512}", "{\"n\": 3209, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3119.36, \"learn_time_ms\": 42978.897}", "{\"n\": 3210, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3123.16, \"learn_time_ms\": 43017.804}", "{\"n\": 3211, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3129.19, \"learn_time_ms\": 42981.173}", "{\"n\": 3212, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3114.88, \"learn_time_ms\": 42900.076}", "{\"n\": 3213, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3115.46, \"learn_time_ms\": 42984.586}", "{\"n\": 3214, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3128.08, \"learn_time_ms\": 42998.161}", "{\"n\": 3215, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3128.08, \"learn_time_ms\": 43007.468}", "{\"n\": 3216, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3130.46, \"learn_time_ms\": 43078.103}", "{\"n\": 3217, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3135.69, \"learn_time_ms\": 43067.174}", "{\"n\": 3218, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3142.09, \"learn_time_ms\": 43120.693}", "{\"n\": 3219, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3144.95, \"learn_time_ms\": 43252.757}", "{\"n\": 3220, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3144.95, \"learn_time_ms\": 43166.368}", "{\"n\": 3221, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3159.82, \"learn_time_ms\": 43190.461}", "{\"n\": 3222, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.99, \"learn_time_ms\": 43263.552}", "{\"n\": 3223, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3172.96, \"learn_time_ms\": 43182.906}", "{\"n\": 3224, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3172.96, \"learn_time_ms\": 43089.95}", "{\"n\": 3225, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3175.16, \"learn_time_ms\": 43102.326}", "{\"n\": 3226, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3165.54, \"learn_time_ms\": 43029.025}", "{\"n\": 3227, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3176.76, \"learn_time_ms\": 42999.887}", "{\"n\": 3228, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3170.33, \"learn_time_ms\": 42967.234}", "{\"n\": 3229, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3171.97, \"learn_time_ms\": 42875.108}", "{\"n\": 3230, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3156.29, \"learn_time_ms\": 42924.099}", "{\"n\": 3231, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3156.29, \"learn_time_ms\": 42915.705}", "{\"n\": 3232, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3165.89, \"learn_time_ms\": 42933.473}", "{\"n\": 3233, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3174.14, \"learn_time_ms\": 43010.776}", "{\"n\": 3234, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3190.05, \"learn_time_ms\": 43048.089}", "{\"n\": 3235, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.26, \"learn_time_ms\": 43138.484}", "{\"n\": 3236, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3183.26, \"learn_time_ms\": 43116.919}", "{\"n\": 3237, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3175.92, \"learn_time_ms\": 43105.013}", "{\"n\": 3238, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3175.92, \"learn_time_ms\": 43115.483}", "{\"n\": 3239, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3162.71, \"learn_time_ms\": 43168.992}", "{\"n\": 3240, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3148.7, \"learn_time_ms\": 43184.939}", "{\"n\": 3241, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3153.93, \"learn_time_ms\": 43168.605}", "{\"n\": 3242, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3154.96, \"learn_time_ms\": 43136.3}", "{\"n\": 3243, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3155.05, \"learn_time_ms\": 43145.467}", "{\"n\": 3244, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3149.59, \"learn_time_ms\": 43317.571}", "{\"n\": 3245, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3157.53, \"learn_time_ms\": 43288.037}", "{\"n\": 3246, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3154.23, \"learn_time_ms\": 43283.136}", "{\"n\": 3247, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3147.4, \"learn_time_ms\": 43228.788}", "{\"n\": 3248, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3138.01, \"learn_time_ms\": 43307.682}", "{\"n\": 3249, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3128.56, \"learn_time_ms\": 43269.691}", "{\"n\": 3250, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3125.82, \"learn_time_ms\": 43264.726}", "{\"n\": 3251, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3132.56, \"learn_time_ms\": 43256.971}", "{\"n\": 3252, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3143.77, \"learn_time_ms\": 43289.879}", "{\"n\": 3253, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3147.4, \"learn_time_ms\": 43196.479}", "{\"n\": 3254, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3140.81, \"learn_time_ms\": 43042.414}", "{\"n\": 3255, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3135.49, \"learn_time_ms\": 43079.031}", "{\"n\": 3256, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3127.77, \"learn_time_ms\": 43174.55}", "{\"n\": 3257, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3123.76, \"learn_time_ms\": 43106.726}", "{\"n\": 3258, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3123.76, \"learn_time_ms\": 43031.459}", "{\"n\": 3259, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3126.12, \"learn_time_ms\": 43140.882}", "{\"n\": 3260, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3139.08, \"learn_time_ms\": 43185.739}", "{\"n\": 3261, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3146.17, \"learn_time_ms\": 43280.618}", "{\"n\": 3262, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3148.08, \"learn_time_ms\": 43226.819}", "{\"n\": 3263, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3148.08, \"learn_time_ms\": 43257.288}", "{\"n\": 3264, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3123.38, \"learn_time_ms\": 43295.571}", "{\"n\": 3265, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3136.06, \"learn_time_ms\": 43239.619}", "{\"n\": 3266, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3134.28, \"learn_time_ms\": 43211.171}", "{\"n\": 3267, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3134.28, \"learn_time_ms\": 43198.745}", "{\"n\": 3268, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3140.04, \"learn_time_ms\": 43230.107}", "{\"n\": 3269, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3125.05, \"learn_time_ms\": 43141.272}", "{\"n\": 3270, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3130.22, \"learn_time_ms\": 43060.333}", "{\"n\": 3271, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3132.02, \"learn_time_ms\": 42984.501}", "{\"n\": 3272, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3141.98, \"learn_time_ms\": 42948.382}", "{\"n\": 3273, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3141.98, \"learn_time_ms\": 42970.13}", "{\"n\": 3274, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3129.38, \"learn_time_ms\": 42927.017}", "{\"n\": 3275, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3122.59, \"learn_time_ms\": 42972.137}", "{\"n\": 3276, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3127.42, \"learn_time_ms\": 42962.437}", "{\"n\": 3277, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3136.26, \"learn_time_ms\": 43052.56}", "{\"n\": 3278, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3132.89, \"learn_time_ms\": 42975.091}", "{\"n\": 3279, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3122.41, \"learn_time_ms\": 42892.782}", "{\"n\": 3280, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3127.32, \"learn_time_ms\": 42843.684}", "{\"n\": 3281, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3127.29, \"learn_time_ms\": 42830.95}", "{\"n\": 3282, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3126.27, \"learn_time_ms\": 42864.643}", "{\"n\": 3283, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3123.16, \"learn_time_ms\": 42872.147}", "{\"n\": 3284, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3113.71, \"learn_time_ms\": 42870.101}", "{\"n\": 3285, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3113.71, \"learn_time_ms\": 42818.637}", "{\"n\": 3286, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3096.25, \"learn_time_ms\": 42801.359}", "{\"n\": 3287, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3096.25, \"learn_time_ms\": 42824.199}", "{\"n\": 3288, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3087.96, \"learn_time_ms\": 42831.285}", "{\"n\": 3289, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3091.45, \"learn_time_ms\": 42904.094}", "{\"n\": 3290, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3091.45, \"learn_time_ms\": 42972.54}", "{\"n\": 3291, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3084.94, \"learn_time_ms\": 42987.011}", "{\"n\": 3292, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3090.89, \"learn_time_ms\": 43021.475}", "{\"n\": 3293, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3087.97, \"learn_time_ms\": 43008.707}", "{\"n\": 3294, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3087.97, \"learn_time_ms\": 43102.925}", "{\"n\": 3295, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3097.07, \"learn_time_ms\": 43181.24}", "{\"n\": 3296, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3112.71, \"learn_time_ms\": 43134.5}", "{\"n\": 3297, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3121.33, \"learn_time_ms\": 43033.964}", "{\"n\": 3298, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3098.94, \"learn_time_ms\": 43090.26}", "{\"n\": 3299, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3091.32, \"learn_time_ms\": 43099.175}", "{\"n\": 3300, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3103.05, \"learn_time_ms\": 43143.149}", "{\"n\": 3301, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3114.38, \"learn_time_ms\": 43125.996}", "{\"n\": 3302, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3104.95, \"learn_time_ms\": 43164.584}", "{\"n\": 3303, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3109.61, \"learn_time_ms\": 43135.689}", "{\"n\": 3304, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3109.61, \"learn_time_ms\": 42971.077}", "{\"n\": 3305, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3135.79, \"learn_time_ms\": 42877.868}", "{\"n\": 3306, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3134.14, \"learn_time_ms\": 42934.469}", "{\"n\": 3307, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3134.65, \"learn_time_ms\": 42917.404}", "{\"n\": 3308, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3130.29, \"learn_time_ms\": 42927.263}", "{\"n\": 3309, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3131.93, \"learn_time_ms\": 42952.628}", "{\"n\": 3310, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3116.29, \"learn_time_ms\": 42879.402}", "{\"n\": 3311, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3110.23, \"learn_time_ms\": 42880.194}", "{\"n\": 3312, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3105.96, \"learn_time_ms\": 42794.665}", "{\"n\": 3313, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3113.04, \"learn_time_ms\": 42799.13}", "{\"n\": 3314, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3113.04, \"learn_time_ms\": 42976.168}", "{\"n\": 3315, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3108.97, \"learn_time_ms\": 42931.13}", "{\"n\": 3316, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3108.97, \"learn_time_ms\": 42925.936}", "{\"n\": 3317, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3100.51, \"learn_time_ms\": 43008.562}", "{\"n\": 3318, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3086.83, \"learn_time_ms\": 42969.387}", "{\"n\": 3319, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3102.67, \"learn_time_ms\": 42892.857}", "{\"n\": 3320, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3104.14, \"learn_time_ms\": 42886.866}", "{\"n\": 3321, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3109.3, \"learn_time_ms\": 42999.857}", "{\"n\": 3322, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3109.3, \"learn_time_ms\": 42995.49}", "{\"n\": 3323, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3125.34, \"learn_time_ms\": 43004.516}", "{\"n\": 3324, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3130.47, \"learn_time_ms\": 42937.525}", "{\"n\": 3325, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3135.89, \"learn_time_ms\": 42914.846}", "{\"n\": 3326, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.01, \"learn_time_ms\": 42868.558}", "{\"n\": 3327, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3135.26, \"learn_time_ms\": 42967.8}", "{\"n\": 3328, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3135.26, \"learn_time_ms\": 43025.08}", "{\"n\": 3329, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3128.58, \"learn_time_ms\": 43015.196}", "{\"n\": 3330, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.32, \"learn_time_ms\": 42931.239}", "{\"n\": 3331, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3133.77, \"learn_time_ms\": 42799.041}", "{\"n\": 3332, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3133.77, \"learn_time_ms\": 42847.904}", "{\"n\": 3333, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3145.56, \"learn_time_ms\": 42836.76}", "{\"n\": 3334, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3158.2, \"learn_time_ms\": 42830.662}", "{\"n\": 3335, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.51, \"learn_time_ms\": 42964.241}", "{\"n\": 3336, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3169.51, \"learn_time_ms\": 43084.144}", "{\"n\": 3337, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.07, \"learn_time_ms\": 42928.269}", "{\"n\": 3338, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.07, \"learn_time_ms\": 42851.191}", "{\"n\": 3339, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3153.45, \"learn_time_ms\": 42877.695}", "{\"n\": 3340, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3146.95, \"learn_time_ms\": 42913.317}", "{\"n\": 3341, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3146.95, \"learn_time_ms\": 42996.835}", "{\"n\": 3342, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3135.18, \"learn_time_ms\": 42994.784}", "{\"n\": 3343, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3144.53, \"learn_time_ms\": 42998.977}", "{\"n\": 3344, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.63, \"learn_time_ms\": 42926.485}", "{\"n\": 3345, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3147.95, \"learn_time_ms\": 42893.558}", "{\"n\": 3346, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3149.07, \"learn_time_ms\": 42868.64}", "{\"n\": 3347, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.02, \"learn_time_ms\": 42981.669}", "{\"n\": 3348, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3161.02, \"learn_time_ms\": 43024.044}", "{\"n\": 3349, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.7, \"learn_time_ms\": 43066.127}", "{\"n\": 3350, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.98, \"learn_time_ms\": 43234.333}", "{\"n\": 3351, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3178.98, \"learn_time_ms\": 43181.552}", "{\"n\": 3352, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.18, \"learn_time_ms\": 43223.942}", "{\"n\": 3353, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.8, \"learn_time_ms\": 43227.987}", "{\"n\": 3354, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.8, \"learn_time_ms\": 43277.409}", "{\"n\": 3355, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.37, \"learn_time_ms\": 43240.599}", "{\"n\": 3356, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.66, \"learn_time_ms\": 43079.335}", "{\"n\": 3357, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.0, \"learn_time_ms\": 42915.035}", "{\"n\": 3358, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.54, \"learn_time_ms\": 42969.446}", "{\"n\": 3359, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.14, \"learn_time_ms\": 42899.509}", "{\"n\": 3360, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3227.18, \"learn_time_ms\": 42764.397}", "{\"n\": 3361, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.47, \"learn_time_ms\": 42819.938}", "{\"n\": 3362, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.68, \"learn_time_ms\": 42836.616}", "{\"n\": 3363, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3207.68, \"learn_time_ms\": 42870.32}", "{\"n\": 3364, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3203.37, \"learn_time_ms\": 42870.754}", "{\"n\": 3365, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3210.6, \"learn_time_ms\": 42964.351}", "{\"n\": 3366, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3198.5, \"learn_time_ms\": 43035.781}", "{\"n\": 3367, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3198.68, \"learn_time_ms\": 43112.695}", "{\"n\": 3368, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3198.68, \"learn_time_ms\": 43068.695}", "{\"n\": 3369, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3202.17, \"learn_time_ms\": 43094.989}", "{\"n\": 3370, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3209.69, \"learn_time_ms\": 43115.307}", "{\"n\": 3371, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3206.62, \"learn_time_ms\": 43034.136}", "{\"n\": 3372, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3206.62, \"learn_time_ms\": 43027.31}", "{\"n\": 3373, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3209.4, \"learn_time_ms\": 42938.207}", "{\"n\": 3374, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3207.2, \"learn_time_ms\": 42943.303}", "{\"n\": 3375, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.72, \"learn_time_ms\": 42974.596}", "{\"n\": 3376, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.31, \"learn_time_ms\": 42910.703}", "{\"n\": 3377, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.56, \"learn_time_ms\": 42980.031}", "{\"n\": 3378, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.86, \"learn_time_ms\": 42951.232}", "{\"n\": 3379, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3263.95, \"learn_time_ms\": 42992.419}", "{\"n\": 3380, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.55, \"learn_time_ms\": 43023.701}", "{\"n\": 3381, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3280.35, \"learn_time_ms\": 43090.148}", "{\"n\": 3382, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.16, \"learn_time_ms\": 43013.338}", "{\"n\": 3383, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.16, \"learn_time_ms\": 43064.752}", "{\"n\": 3384, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.4, \"learn_time_ms\": 43059.172}", "{\"n\": 3385, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.31, \"learn_time_ms\": 42865.764}", "{\"n\": 3386, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.2, \"learn_time_ms\": 42995.135}", "{\"n\": 3387, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.2, \"learn_time_ms\": 42982.52}", "{\"n\": 3388, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.2, \"learn_time_ms\": 42925.667}", "{\"n\": 3389, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.05, \"learn_time_ms\": 42970.851}", "{\"n\": 3390, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.9, \"learn_time_ms\": 42917.401}", "{\"n\": 3391, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.72, \"learn_time_ms\": 42802.86}", "{\"n\": 3392, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3231.6, \"learn_time_ms\": 42843.532}", "{\"n\": 3393, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.28, \"learn_time_ms\": 42837.902}", "{\"n\": 3394, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.39, \"learn_time_ms\": 42843.1}", "{\"n\": 3395, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.81, \"learn_time_ms\": 42860.73}", "{\"n\": 3396, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.49, \"learn_time_ms\": 42797.76}", "{\"n\": 3397, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.97, \"learn_time_ms\": 42844.768}", "{\"n\": 3398, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.97, \"learn_time_ms\": 42925.946}", "{\"n\": 3399, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.18, \"learn_time_ms\": 42836.271}", "{\"n\": 3400, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.22, \"learn_time_ms\": 42877.163}", "{\"n\": 3401, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.22, \"learn_time_ms\": 43018.535}", "{\"n\": 3402, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.99, \"learn_time_ms\": 42962.397}", "{\"n\": 3403, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.99, \"learn_time_ms\": 42910.651}", "{\"n\": 3404, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.99, \"learn_time_ms\": 42775.076}", "{\"n\": 3405, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.48, \"learn_time_ms\": 42821.187}", "{\"n\": 3406, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3219.57, \"learn_time_ms\": 42820.802}", "{\"n\": 3407, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.36, \"learn_time_ms\": 42752.612}", "{\"n\": 3408, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.36, \"learn_time_ms\": 42765.202}", "{\"n\": 3409, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.08, \"learn_time_ms\": 42753.119}", "{\"n\": 3410, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3239.35, \"learn_time_ms\": 42663.475}", "{\"n\": 3411, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.11, \"learn_time_ms\": 42640.07}", "{\"n\": 3412, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3246.73, \"learn_time_ms\": 42784.138}", "{\"n\": 3413, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.84, \"learn_time_ms\": 42837.366}", "{\"n\": 3414, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.84, \"learn_time_ms\": 43079.398}", "{\"n\": 3415, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.84, \"learn_time_ms\": 43078.256}", "{\"n\": 3416, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.84, \"learn_time_ms\": 43141.662}", "{\"n\": 3417, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.7, \"learn_time_ms\": 43233.579}", "{\"n\": 3418, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.16, \"learn_time_ms\": 43150.915}", "{\"n\": 3419, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.57, \"learn_time_ms\": 43163.448}", "{\"n\": 3420, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.74, \"learn_time_ms\": 43240.301}", "{\"n\": 3421, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.82, \"learn_time_ms\": 43073.135}", "{\"n\": 3422, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.2, \"learn_time_ms\": 42939.646}", "{\"n\": 3423, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.48, \"learn_time_ms\": 42880.232}", "{\"n\": 3424, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.46, \"learn_time_ms\": 42799.819}", "{\"n\": 3425, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.17, \"learn_time_ms\": 42805.787}", "{\"n\": 3426, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.77, \"learn_time_ms\": 42644.214}", "{\"n\": 3427, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.77, \"learn_time_ms\": 42612.241}", "{\"n\": 3428, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3215.77, \"learn_time_ms\": 42594.748}", "{\"n\": 3429, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.78, \"learn_time_ms\": 42727.29}", "{\"n\": 3430, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.3, \"learn_time_ms\": 42724.539}", "{\"n\": 3431, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.38, \"learn_time_ms\": 42859.562}", "{\"n\": 3432, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.38, \"learn_time_ms\": 42991.204}", "{\"n\": 3433, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.56, \"learn_time_ms\": 43004.467}", "{\"n\": 3434, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.65, \"learn_time_ms\": 43030.723}", "{\"n\": 3435, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.03, \"learn_time_ms\": 43096.521}", "{\"n\": 3436, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3224.36, \"learn_time_ms\": 43193.354}", "{\"n\": 3437, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.15, \"learn_time_ms\": 43075.516}", "{\"n\": 3438, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.92, \"learn_time_ms\": 43114.234}", "{\"n\": 3439, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.92, \"learn_time_ms\": 42941.005}", "{\"n\": 3440, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.25, \"learn_time_ms\": 43000.882}", "{\"n\": 3441, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.63, \"learn_time_ms\": 42880.296}", "{\"n\": 3442, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.79, \"learn_time_ms\": 42726.031}", "{\"n\": 3443, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.03, \"learn_time_ms\": 42747.743}", "{\"n\": 3444, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.36, \"learn_time_ms\": 42666.511}", "{\"n\": 3445, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.99, \"learn_time_ms\": 42561.643}", "{\"n\": 3446, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.09, \"learn_time_ms\": 42534.152}", "{\"n\": 3447, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3155.94, \"learn_time_ms\": 42645.849}", "{\"n\": 3448, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3155.94, \"learn_time_ms\": 42670.519}", "{\"n\": 3449, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.62, \"learn_time_ms\": 42802.452}", "{\"n\": 3450, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.62, \"learn_time_ms\": 42734.526}", "{\"n\": 3451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.89, \"learn_time_ms\": 42795.025}", "{\"n\": 3452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.89, \"learn_time_ms\": 42783.832}", "{\"n\": 3453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.89, \"learn_time_ms\": 42811.75}", "{\"n\": 3454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.7, \"learn_time_ms\": 42751.681}", "{\"n\": 3455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3167.44, \"learn_time_ms\": 42762.51}", "{\"n\": 3456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.45, \"learn_time_ms\": 42838.935}", "{\"n\": 3457, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.28, \"learn_time_ms\": 42871.717}", "{\"n\": 3458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.01, \"learn_time_ms\": 42911.533}", "{\"n\": 3459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.89, \"learn_time_ms\": 42854.203}", "{\"n\": 3460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3151.85, \"learn_time_ms\": 42927.946}", "{\"n\": 3461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.02, \"learn_time_ms\": 43040.871}", "{\"n\": 3462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.44, \"learn_time_ms\": 43134.296}", "{\"n\": 3463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.44, \"learn_time_ms\": 43062.523}", "{\"n\": 3464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.61, \"learn_time_ms\": 43207.688}", "{\"n\": 3465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3160.59, \"learn_time_ms\": 43171.07}", "{\"n\": 3466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3158.02, \"learn_time_ms\": 43168.484}", "{\"n\": 3467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3158.02, \"learn_time_ms\": 43110.387}", "{\"n\": 3468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3150.07, \"learn_time_ms\": 42994.646}", "{\"n\": 3469, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.13, \"learn_time_ms\": 43049.459}", "{\"n\": 3470, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3149.53, \"learn_time_ms\": 43019.276}", "{\"n\": 3471, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3140.64, \"learn_time_ms\": 42997.11}", "{\"n\": 3472, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3136.52, \"learn_time_ms\": 43006.885}", "{\"n\": 3473, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3146.69, \"learn_time_ms\": 42996.85}", "{\"n\": 3474, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3146.69, \"learn_time_ms\": 42945.973}", "{\"n\": 3475, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3155.91, \"learn_time_ms\": 43070.522}", "{\"n\": 3476, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3155.91, \"learn_time_ms\": 42998.517}", "{\"n\": 3477, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.84, \"learn_time_ms\": 42991.921}", "{\"n\": 3478, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3174.01, \"learn_time_ms\": 43027.881}", "{\"n\": 3479, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.05, \"learn_time_ms\": 42987.183}", "{\"n\": 3480, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.59, \"learn_time_ms\": 42968.022}", "{\"n\": 3481, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.59, \"learn_time_ms\": 42903.211}", "{\"n\": 3482, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.3, \"learn_time_ms\": 42864.006}", "{\"n\": 3483, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.01, \"learn_time_ms\": 43001.319}", "{\"n\": 3484, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.25, \"learn_time_ms\": 43050.996}", "{\"n\": 3485, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.25, \"learn_time_ms\": 43003.009}", "{\"n\": 3486, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.02, \"learn_time_ms\": 42998.228}", "{\"n\": 3487, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3209.06, \"learn_time_ms\": 42979.708}", "{\"n\": 3488, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.3, \"learn_time_ms\": 43066.05}", "{\"n\": 3489, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.68, \"learn_time_ms\": 43032.272}", "{\"n\": 3490, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3213.26, \"learn_time_ms\": 43059.412}", "{\"n\": 3491, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3211.07, \"learn_time_ms\": 43164.976}", "{\"n\": 3492, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.59, \"learn_time_ms\": 43192.12}", "{\"n\": 3493, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3207.92, \"learn_time_ms\": 43104.632}", "{\"n\": 3494, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.26, \"learn_time_ms\": 43116.478}", "{\"n\": 3495, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3206.09, \"learn_time_ms\": 43071.683}", "{\"n\": 3496, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.73, \"learn_time_ms\": 43215.432}", "{\"n\": 3497, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.73, \"learn_time_ms\": 43295.78}", "{\"n\": 3498, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3220.3, \"learn_time_ms\": 43230.28}", "{\"n\": 3499, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.92, \"learn_time_ms\": 43203.523}", "{\"n\": 3500, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.53, \"learn_time_ms\": 43203.463}", "{\"n\": 3501, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3218.19, \"learn_time_ms\": 43136.3}", "{\"n\": 3502, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.78, \"learn_time_ms\": 43081.136}", "{\"n\": 3503, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.91, \"learn_time_ms\": 43055.74}", "{\"n\": 3504, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.05, \"learn_time_ms\": 42990.695}", "{\"n\": 3505, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.08, \"learn_time_ms\": 43116.697}", "{\"n\": 3506, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.14, \"learn_time_ms\": 42993.638}", "{\"n\": 3507, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.39, \"learn_time_ms\": 42904.124}", "{\"n\": 3508, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.46, \"learn_time_ms\": 42913.183}", "{\"n\": 3509, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.96, \"learn_time_ms\": 42853.309}", "{\"n\": 3510, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3220.39, \"learn_time_ms\": 42798.169}", "{\"n\": 3511, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3243.07, \"learn_time_ms\": 42819.226}", "{\"n\": 3512, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3251.54, \"learn_time_ms\": 42797.925}", "{\"n\": 3513, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3255.36, \"learn_time_ms\": 42771.155}", "{\"n\": 3514, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3262.42, \"learn_time_ms\": 42776.68}", "{\"n\": 3515, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3263.72, \"learn_time_ms\": 42652.136}", "{\"n\": 3516, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3265.1, \"learn_time_ms\": 42670.288}", "{\"n\": 3517, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.39, \"learn_time_ms\": 42652.512}", "{\"n\": 3518, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.39, \"learn_time_ms\": 42669.643}", "{\"n\": 3519, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3266.76, \"learn_time_ms\": 42814.016}", "{\"n\": 3520, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3280.38, \"learn_time_ms\": 42803.606}", "{\"n\": 3521, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3271.05, \"learn_time_ms\": 42803.208}", "{\"n\": 3522, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3266.42, \"learn_time_ms\": 42743.985}", "{\"n\": 3523, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3269.55, \"learn_time_ms\": 42833.168}", "{\"n\": 3524, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3269.55, \"learn_time_ms\": 42733.656}", "{\"n\": 3525, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3260.49, \"learn_time_ms\": 42722.901}", "{\"n\": 3526, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3267.99, \"learn_time_ms\": 42800.321}", "{\"n\": 3527, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.09, \"learn_time_ms\": 42844.615}", "{\"n\": 3528, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.82, \"learn_time_ms\": 42876.897}", "{\"n\": 3529, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3297.02, \"learn_time_ms\": 42857.768}", "{\"n\": 3530, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3297.02, \"learn_time_ms\": 42928.087}", "{\"n\": 3531, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3298.74, \"learn_time_ms\": 42845.907}", "{\"n\": 3532, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3298.91, \"learn_time_ms\": 43051.549}", "{\"n\": 3533, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3305.0, \"learn_time_ms\": 43102.313}", "{\"n\": 3534, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3316.15, \"learn_time_ms\": 43166.369}", "{\"n\": 3535, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3316.15, \"learn_time_ms\": 43247.018}", "{\"n\": 3536, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3325.8, \"learn_time_ms\": 43221.325}", "{\"n\": 3537, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3334.16, \"learn_time_ms\": 43192.541}", "{\"n\": 3538, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3334.47, \"learn_time_ms\": 43235.943}", "{\"n\": 3539, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3352.04, \"learn_time_ms\": 43217.711}", "{\"n\": 3540, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3352.04, \"learn_time_ms\": 43279.459}", "{\"n\": 3541, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3359.67, \"learn_time_ms\": 43318.069}", "{\"n\": 3542, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3331.39, \"learn_time_ms\": 43319.338}", "{\"n\": 3543, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3331.39, \"learn_time_ms\": 43238.527}", "{\"n\": 3544, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3334.12, \"learn_time_ms\": 43217.539}", "{\"n\": 3545, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3334.12, \"learn_time_ms\": 43220.808}", "{\"n\": 3546, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3338.7, \"learn_time_ms\": 43175.46}", "{\"n\": 3547, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3329.38, \"learn_time_ms\": 43200.54}", "{\"n\": 3548, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3330.91, \"learn_time_ms\": 43103.904}", "{\"n\": 3549, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3321.0, \"learn_time_ms\": 43189.987}", "{\"n\": 3550, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3335.12, \"learn_time_ms\": 43179.543}", "{\"n\": 3551, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.15, \"learn_time_ms\": 43167.171}", "{\"n\": 3552, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3341.15, \"learn_time_ms\": 42987.382}", "{\"n\": 3553, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3337.88, \"learn_time_ms\": 43078.13}", "{\"n\": 3554, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3336.08, \"learn_time_ms\": 43168.588}", "{\"n\": 3555, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.85, \"learn_time_ms\": 43152.463}", "{\"n\": 3556, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3327.22, \"learn_time_ms\": 43167.963}", "{\"n\": 3557, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3319.67, \"learn_time_ms\": 43078.799}", "{\"n\": 3558, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.68, \"learn_time_ms\": 43119.174}", "{\"n\": 3559, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3316.68, \"learn_time_ms\": 43114.964}", "{\"n\": 3560, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3313.48, \"learn_time_ms\": 43018.774}", "{\"n\": 3561, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3324.56, \"learn_time_ms\": 43093.388}", "{\"n\": 3562, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3343.4, \"learn_time_ms\": 43207.529}", "{\"n\": 3563, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3339.84, \"learn_time_ms\": 43097.151}", "{\"n\": 3564, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.34, \"learn_time_ms\": 42965.463}", "{\"n\": 3565, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.62, \"learn_time_ms\": 42939.279}", "{\"n\": 3566, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3350.62, \"learn_time_ms\": 42909.395}", "{\"n\": 3567, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.97, \"learn_time_ms\": 42945.935}", "{\"n\": 3568, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.97, \"learn_time_ms\": 42891.659}", "{\"n\": 3569, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.02, \"learn_time_ms\": 42845.244}", "{\"n\": 3570, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.15, \"learn_time_ms\": 42898.118}", "{\"n\": 3571, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.09, \"learn_time_ms\": 42833.252}", "{\"n\": 3572, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3384.6, \"learn_time_ms\": 42727.741}", "{\"n\": 3573, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.53, \"learn_time_ms\": 42763.309}", "{\"n\": 3574, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.53, \"learn_time_ms\": 42754.957}", "{\"n\": 3575, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3382.79, \"learn_time_ms\": 42735.968}", "{\"n\": 3576, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.96, \"learn_time_ms\": 42802.846}", "{\"n\": 3577, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.68, \"learn_time_ms\": 42850.38}", "{\"n\": 3578, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.68, \"learn_time_ms\": 42845.739}", "{\"n\": 3579, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.95, \"learn_time_ms\": 42812.631}", "{\"n\": 3580, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3421.95, \"learn_time_ms\": 42839.441}", "{\"n\": 3581, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.24, \"learn_time_ms\": 42833.436}", "{\"n\": 3582, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.97, \"learn_time_ms\": 42838.782}", "{\"n\": 3583, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.14, \"learn_time_ms\": 42961.605}", "{\"n\": 3584, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.14, \"learn_time_ms\": 43011.622}", "{\"n\": 3585, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.16, \"learn_time_ms\": 42989.294}", "{\"n\": 3586, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.82, \"learn_time_ms\": 42962.396}", "{\"n\": 3587, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3415.23, \"learn_time_ms\": 42815.74}", "{\"n\": 3588, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.27, \"learn_time_ms\": 42787.06}", "{\"n\": 3589, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.03, \"learn_time_ms\": 42702.208}", "{\"n\": 3590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.03, \"learn_time_ms\": 42622.323}", "{\"n\": 3591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.27, \"learn_time_ms\": 42654.369}", "{\"n\": 3592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3440.53, \"learn_time_ms\": 42778.086}", "{\"n\": 3593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3445.42, \"learn_time_ms\": 42711.138}", "{\"n\": 3594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.92, \"learn_time_ms\": 42719.121}", "{\"n\": 3595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3435.13, \"learn_time_ms\": 42758.934}", "{\"n\": 3596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.14, \"learn_time_ms\": 42713.015}", "{\"n\": 3597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3430.59, \"learn_time_ms\": 42825.202}", "{\"n\": 3598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3429.28, \"learn_time_ms\": 42938.861}", "{\"n\": 3599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3429.28, \"learn_time_ms\": 43059.556}", "{\"n\": 3600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3416.81, \"learn_time_ms\": 42976.12}", "{\"n\": 3601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.5, \"learn_time_ms\": 43035.169}", "{\"n\": 3602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.5, \"learn_time_ms\": 42916.672}", "{\"n\": 3603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3417.49, \"learn_time_ms\": 42874.731}", "{\"n\": 3604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.04, \"learn_time_ms\": 42928.381}", "{\"n\": 3605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3399.98, \"learn_time_ms\": 42837.444}", "{\"n\": 3606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3388.7, \"learn_time_ms\": 42802.729}", "{\"n\": 3607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3387.48, \"learn_time_ms\": 42817.625}", "{\"n\": 3608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3390.16, \"learn_time_ms\": 42716.084}", "{\"n\": 3609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3383.79, \"learn_time_ms\": 42669.69}", "{\"n\": 3610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3391.46, \"learn_time_ms\": 42764.108}", "{\"n\": 3611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3376.26, \"learn_time_ms\": 42728.614}", "{\"n\": 3612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.95, \"learn_time_ms\": 42831.241}", "{\"n\": 3613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.95, \"learn_time_ms\": 42810.74}", "{\"n\": 3614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3379.95, \"learn_time_ms\": 42810.773}", "{\"n\": 3615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3348.63, \"learn_time_ms\": 42882.091}", "{\"n\": 3616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3330.56, \"learn_time_ms\": 42983.47}", "{\"n\": 3617, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3326.92, \"learn_time_ms\": 42972.734}", "{\"n\": 3618, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.2, \"learn_time_ms\": 43098.493}", "{\"n\": 3619, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3331.2, \"learn_time_ms\": 43109.612}", "{\"n\": 3620, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.23, \"learn_time_ms\": 43211.996}", "{\"n\": 3621, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.39, \"learn_time_ms\": 43206.897}", "{\"n\": 3622, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.39, \"learn_time_ms\": 43201.531}", "{\"n\": 3623, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.28, \"learn_time_ms\": 43148.131}", "{\"n\": 3624, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3289.28, \"learn_time_ms\": 43143.323}", "{\"n\": 3625, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.49, \"learn_time_ms\": 43151.869}", "{\"n\": 3626, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3296.75, \"learn_time_ms\": 43059.222}", "{\"n\": 3627, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.39, \"learn_time_ms\": 43077.978}", "{\"n\": 3628, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.39, \"learn_time_ms\": 42961.562}", "{\"n\": 3629, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.58, \"learn_time_ms\": 42894.119}", "{\"n\": 3630, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.58, \"learn_time_ms\": 42781.814}", "{\"n\": 3631, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3263.0, \"learn_time_ms\": 42839.81}", "{\"n\": 3632, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.13, \"learn_time_ms\": 42733.861}", "{\"n\": 3633, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3264.27, \"learn_time_ms\": 42850.614}", "{\"n\": 3634, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.94, \"learn_time_ms\": 42887.008}", "{\"n\": 3635, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.94, \"learn_time_ms\": 42848.241}", "{\"n\": 3636, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3266.94, \"learn_time_ms\": 42921.371}", "{\"n\": 3637, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.65, \"learn_time_ms\": 42956.13}", "{\"n\": 3638, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3267.98, \"learn_time_ms\": 43046.83}", "{\"n\": 3639, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3260.1, \"learn_time_ms\": 43068.248}", "{\"n\": 3640, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.32, \"learn_time_ms\": 43078.189}", "{\"n\": 3641, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.32, \"learn_time_ms\": 43015.363}", "{\"n\": 3642, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.39, \"learn_time_ms\": 43078.547}", "{\"n\": 3643, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.5, \"learn_time_ms\": 43026.744}", "{\"n\": 3644, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.04, \"learn_time_ms\": 42940.558}", "{\"n\": 3645, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3247.04, \"learn_time_ms\": 42962.795}", "{\"n\": 3646, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.45, \"learn_time_ms\": 42985.521}", "{\"n\": 3647, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.45, \"learn_time_ms\": 42956.009}", "{\"n\": 3648, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.19, \"learn_time_ms\": 42876.832}", "{\"n\": 3649, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.19, \"learn_time_ms\": 42905.437}", "{\"n\": 3650, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.43, \"learn_time_ms\": 42859.382}", "{\"n\": 3651, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.08, \"learn_time_ms\": 42772.176}", "{\"n\": 3652, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3243.08, \"learn_time_ms\": 42712.958}", "{\"n\": 3653, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3242.07, \"learn_time_ms\": 42706.592}", "{\"n\": 3654, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.46, \"learn_time_ms\": 42667.863}", "{\"n\": 3655, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3237.51, \"learn_time_ms\": 42627.299}", "{\"n\": 3656, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.95, \"learn_time_ms\": 42599.887}", "{\"n\": 3657, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.86, \"learn_time_ms\": 42658.265}", "{\"n\": 3658, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.86, \"learn_time_ms\": 42638.167}", "{\"n\": 3659, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3253.09, \"learn_time_ms\": 42687.319}", "{\"n\": 3660, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.84, \"learn_time_ms\": 42654.629}", "{\"n\": 3661, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.96, \"learn_time_ms\": 42790.651}", "{\"n\": 3662, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.04, \"learn_time_ms\": 42875.845}", "{\"n\": 3663, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.04, \"learn_time_ms\": 42815.693}", "{\"n\": 3664, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.22, \"learn_time_ms\": 42915.217}", "{\"n\": 3665, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3249.84, \"learn_time_ms\": 43115.532}", "{\"n\": 3666, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3250.48, \"learn_time_ms\": 43039.323}", "{\"n\": 3667, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.19, \"learn_time_ms\": 42993.807}", "{\"n\": 3668, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3245.19, \"learn_time_ms\": 43114.0}", "{\"n\": 3669, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3242.16, \"learn_time_ms\": 43108.569}", "{\"n\": 3670, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3230.33, \"learn_time_ms\": 43074.67}", "{\"n\": 3671, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3240.22, \"learn_time_ms\": 42947.138}", "{\"n\": 3672, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3232.94, \"learn_time_ms\": 42859.835}", "{\"n\": 3673, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3232.94, \"learn_time_ms\": 42915.605}", "{\"n\": 3674, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3251.87, \"learn_time_ms\": 42924.097}", "{\"n\": 3675, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3244.38, \"learn_time_ms\": 42793.958}", "{\"n\": 3676, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3242.89, \"learn_time_ms\": 42892.254}", "{\"n\": 3677, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3245.0, \"learn_time_ms\": 42860.047}", "{\"n\": 3678, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3245.0, \"learn_time_ms\": 42823.103}", "{\"n\": 3679, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3253.63, \"learn_time_ms\": 42797.414}", "{\"n\": 3680, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3256.94, \"learn_time_ms\": 42900.868}", "{\"n\": 3681, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3253.77, \"learn_time_ms\": 42961.682}", "{\"n\": 3682, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3253.77, \"learn_time_ms\": 42933.14}", "{\"n\": 3683, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3251.05, \"learn_time_ms\": 42939.851}", "{\"n\": 3684, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3257.12, \"learn_time_ms\": 42933.71}", "{\"n\": 3685, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3265.99, \"learn_time_ms\": 42917.011}", "{\"n\": 3686, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3249.1, \"learn_time_ms\": 42847.681}", "{\"n\": 3687, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3255.54, \"learn_time_ms\": 42891.157}", "{\"n\": 3688, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3243.29, \"learn_time_ms\": 42924.112}", "{\"n\": 3689, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3243.29, \"learn_time_ms\": 42988.99}", "{\"n\": 3690, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3243.29, \"learn_time_ms\": 43066.934}", "{\"n\": 3691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3252.53, \"learn_time_ms\": 43215.025}", "{\"n\": 3692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3255.98, \"learn_time_ms\": 43292.395}", "{\"n\": 3693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3255.98, \"learn_time_ms\": 43309.87}", "{\"n\": 3694, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3255.98, \"learn_time_ms\": 43196.216}", "{\"n\": 3695, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3265.8, \"learn_time_ms\": 43241.755}", "{\"n\": 3696, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3271.65, \"learn_time_ms\": 43283.764}", "{\"n\": 3697, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3271.65, \"learn_time_ms\": 43181.54}", "{\"n\": 3698, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3291.83, \"learn_time_ms\": 43129.796}", "{\"n\": 3699, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3284.02, \"learn_time_ms\": 43036.367}", "{\"n\": 3700, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3284.02, \"learn_time_ms\": 42899.313}", "{\"n\": 3701, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3266.58, \"learn_time_ms\": 42746.14}", "{\"n\": 3702, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3238.25, \"learn_time_ms\": 42835.238}", "{\"n\": 3703, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3251.07, \"learn_time_ms\": 42876.928}", "{\"n\": 3704, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3251.07, \"learn_time_ms\": 42993.663}", "{\"n\": 3705, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3237.07, \"learn_time_ms\": 43019.358}", "{\"n\": 3706, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.47, \"learn_time_ms\": 43058.103}", "{\"n\": 3707, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3251.66, \"learn_time_ms\": 43046.411}", "{\"n\": 3708, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3264.1, \"learn_time_ms\": 43067.455}", "{\"n\": 3709, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3246.91, \"learn_time_ms\": 43104.296}", "{\"n\": 3710, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.29, \"learn_time_ms\": 43171.349}", "{\"n\": 3711, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.29, \"learn_time_ms\": 43100.159}", "{\"n\": 3712, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3242.48, \"learn_time_ms\": 43081.595}", "{\"n\": 3713, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.26, \"learn_time_ms\": 43057.865}", "{\"n\": 3714, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.8, \"learn_time_ms\": 42959.755}", "{\"n\": 3715, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.72, \"learn_time_ms\": 42915.245}", "{\"n\": 3716, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.53, \"learn_time_ms\": 42864.861}", "{\"n\": 3717, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.94, \"learn_time_ms\": 42918.057}", "{\"n\": 3718, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.35, \"learn_time_ms\": 42887.859}", "{\"n\": 3719, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.48, \"learn_time_ms\": 42881.099}", "{\"n\": 3720, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.48, \"learn_time_ms\": 42949.67}", "{\"n\": 3721, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.51, \"learn_time_ms\": 42958.691}", "{\"n\": 3722, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3209.77, \"learn_time_ms\": 42930.543}", "{\"n\": 3723, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.25, \"learn_time_ms\": 42871.959}", "{\"n\": 3724, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.55, \"learn_time_ms\": 42823.613}", "{\"n\": 3725, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.23, \"learn_time_ms\": 42768.331}", "{\"n\": 3726, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3180.62, \"learn_time_ms\": 42806.158}", "{\"n\": 3727, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.82, \"learn_time_ms\": 42888.38}", "{\"n\": 3728, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3190.86, \"learn_time_ms\": 42873.416}", "{\"n\": 3729, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.65, \"learn_time_ms\": 42936.411}", "{\"n\": 3730, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3195.48, \"learn_time_ms\": 42917.337}", "{\"n\": 3731, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.58, \"learn_time_ms\": 43000.5}", "{\"n\": 3732, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.25, \"learn_time_ms\": 42935.475}", "{\"n\": 3733, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.44, \"learn_time_ms\": 43004.695}", "{\"n\": 3734, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.2, \"learn_time_ms\": 43133.875}", "{\"n\": 3735, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.69, \"learn_time_ms\": 43209.555}", "{\"n\": 3736, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3218.29, \"learn_time_ms\": 43201.01}", "{\"n\": 3737, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.16, \"learn_time_ms\": 43212.604}", "{\"n\": 3738, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.62, \"learn_time_ms\": 43237.518}", "{\"n\": 3739, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.62, \"learn_time_ms\": 43150.007}", "{\"n\": 3740, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.98, \"learn_time_ms\": 43142.161}", "{\"n\": 3741, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.98, \"learn_time_ms\": 43185.607}", "{\"n\": 3742, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.4, \"learn_time_ms\": 43226.68}", "{\"n\": 3743, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.76, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3242.8, \"learn_time_ms\": 43136.537}", "{\"n\": 3744, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.37, \"learn_time_ms\": 43110.542}", "{\"n\": 3745, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.66, \"learn_time_ms\": 43103.525}", "{\"n\": 3746, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3245.66, \"learn_time_ms\": 43085.885}", "{\"n\": 3747, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.65, \"learn_time_ms\": 43110.255}", "{\"n\": 3748, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3262.43, \"learn_time_ms\": 43097.191}", "{\"n\": 3749, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.24, \"learn_time_ms\": 43064.202}", "{\"n\": 3750, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3273.41, \"learn_time_ms\": 43082.163}", "{\"n\": 3751, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3273.41, \"learn_time_ms\": 42890.388}", "{\"n\": 3752, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3276.09, \"learn_time_ms\": 42920.913}", "{\"n\": 3753, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3276.09, \"learn_time_ms\": 42984.711}", "{\"n\": 3754, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.9, \"learn_time_ms\": 42984.654}", "{\"n\": 3755, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3317.99, \"learn_time_ms\": 42856.346}", "{\"n\": 3756, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3343.32, \"learn_time_ms\": 42895.073}", "{\"n\": 3757, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3343.32, \"learn_time_ms\": 42812.723}", "{\"n\": 3758, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3343.32, \"learn_time_ms\": 42856.315}", "{\"n\": 3759, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3359.23, \"learn_time_ms\": 42882.481}", "{\"n\": 3760, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3374.91, \"learn_time_ms\": 42827.068}", "{\"n\": 3761, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3399.8, \"learn_time_ms\": 42900.825}", "{\"n\": 3762, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3399.8, \"learn_time_ms\": 42905.369}", "{\"n\": 3763, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3399.8, \"learn_time_ms\": 42927.236}", "{\"n\": 3764, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.4, \"learn_time_ms\": 42936.472}", "{\"n\": 3765, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3381.4, \"learn_time_ms\": 43079.727}", "{\"n\": 3766, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3350.53, \"learn_time_ms\": 42968.749}", "{\"n\": 3767, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3357.25, \"learn_time_ms\": 42902.456}", "{\"n\": 3768, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3360.55, \"learn_time_ms\": 42888.409}", "{\"n\": 3769, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3360.32, \"learn_time_ms\": 42923.549}", "{\"n\": 3770, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3370.12, \"learn_time_ms\": 42905.628}", "{\"n\": 3771, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3397.98, \"learn_time_ms\": 42901.668}", "{\"n\": 3772, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3408.24, \"learn_time_ms\": 42888.636}", "{\"n\": 3773, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3411.22, \"learn_time_ms\": 42793.462}", "{\"n\": 3774, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3417.35, \"learn_time_ms\": 42803.771}", "{\"n\": 3775, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3399.77, \"learn_time_ms\": 42810.697}", "{\"n\": 3776, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3403.38, \"learn_time_ms\": 42862.506}", "{\"n\": 3777, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3392.93, \"learn_time_ms\": 42926.284}", "{\"n\": 3778, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3394.57, \"learn_time_ms\": 42914.943}", "{\"n\": 3779, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3407.34, \"learn_time_ms\": 42967.472}", "{\"n\": 3780, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3407.34, \"learn_time_ms\": 42925.875}", "{\"n\": 3781, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3395.23, \"learn_time_ms\": 42954.18}", "{\"n\": 3782, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3405.38, \"learn_time_ms\": 42952.041}", "{\"n\": 3783, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3401.72, \"learn_time_ms\": 42976.528}", "{\"n\": 3784, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3395.93, \"learn_time_ms\": 42977.024}", "{\"n\": 3785, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3397.29, \"learn_time_ms\": 42923.775}", "{\"n\": 3786, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3392.73, \"learn_time_ms\": 42912.97}", "{\"n\": 3787, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3392.73, \"learn_time_ms\": 42948.937}", "{\"n\": 3788, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3402.27, \"learn_time_ms\": 42950.636}", "{\"n\": 3789, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3406.94, \"learn_time_ms\": 42892.707}", "{\"n\": 3790, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3403.56, \"learn_time_ms\": 42941.447}", "{\"n\": 3791, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3404.83, \"learn_time_ms\": 42923.367}", "{\"n\": 3792, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3404.83, \"learn_time_ms\": 42919.819}", "{\"n\": 3793, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3394.47, \"learn_time_ms\": 42946.16}", "{\"n\": 3794, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3387.34, \"learn_time_ms\": 42916.445}", "{\"n\": 3795, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3408.93, \"learn_time_ms\": 42982.516}", "{\"n\": 3796, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3408.93, \"learn_time_ms\": 42919.65}", "{\"n\": 3797, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3411.67, \"learn_time_ms\": 42894.546}", "{\"n\": 3798, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.79, \"learn_time_ms\": 42954.56}", "{\"n\": 3799, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.79, \"learn_time_ms\": 42919.394}", "{\"n\": 3800, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3437.74, \"learn_time_ms\": 42929.614}", "{\"n\": 3801, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3440.41, \"learn_time_ms\": 42868.948}", "{\"n\": 3802, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3440.41, \"learn_time_ms\": 42914.074}", "{\"n\": 3803, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3439.76, \"learn_time_ms\": 42918.57}", "{\"n\": 3804, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3440.04, \"learn_time_ms\": 42946.665}", "{\"n\": 3805, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3428.46, \"learn_time_ms\": 42839.52}", "{\"n\": 3806, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3428.46, \"learn_time_ms\": 42944.737}", "{\"n\": 3807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3428.46, \"learn_time_ms\": 42951.175}", "{\"n\": 3808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3418.96, \"learn_time_ms\": 42956.209}", "{\"n\": 3809, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3438.93, \"learn_time_ms\": 42969.545}", "{\"n\": 3810, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3407.79, \"learn_time_ms\": 43009.959}", "{\"n\": 3811, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3407.79, \"learn_time_ms\": 43144.659}", "{\"n\": 3812, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3407.79, \"learn_time_ms\": 43087.949}", "{\"n\": 3813, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3396.41, \"learn_time_ms\": 43076.729}", "{\"n\": 3814, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.84, \"learn_time_ms\": 43117.856}", "{\"n\": 3815, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.85, \"learn_time_ms\": 43081.426}", "{\"n\": 3816, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3396.58, \"learn_time_ms\": 42988.918}", "{\"n\": 3817, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3396.58, \"learn_time_ms\": 43001.636}", "{\"n\": 3818, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3382.36, \"learn_time_ms\": 42937.117}", "{\"n\": 3819, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.6, \"learn_time_ms\": 42957.125}", "{\"n\": 3820, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.6, \"learn_time_ms\": 42853.123}", "{\"n\": 3821, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.92, \"learn_time_ms\": 42832.961}", "{\"n\": 3822, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.92, \"learn_time_ms\": 42846.406}", "{\"n\": 3823, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.92, \"learn_time_ms\": 42953.152}", "{\"n\": 3824, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.49, \"learn_time_ms\": 42858.66}", "{\"n\": 3825, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3333.37, \"learn_time_ms\": 42911.589}", "{\"n\": 3826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.24, \"learn_time_ms\": 42985.809}", "{\"n\": 3827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.24, \"learn_time_ms\": 42945.3}", "{\"n\": 3828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.24, \"learn_time_ms\": 42959.577}", "{\"n\": 3829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.58, \"learn_time_ms\": 42972.897}", "{\"n\": 3830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.07, \"learn_time_ms\": 43053.648}", "{\"n\": 3831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.31, \"learn_time_ms\": 43057.23}", "{\"n\": 3832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.8, \"learn_time_ms\": 43054.037}", "{\"n\": 3833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.12, \"learn_time_ms\": 43013.283}", "{\"n\": 3834, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.96, \"learn_time_ms\": 43112.951}", "{\"n\": 3835, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.65, \"learn_time_ms\": 43160.677}", "{\"n\": 3836, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.65, \"learn_time_ms\": 43205.088}", "{\"n\": 3837, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.21, \"learn_time_ms\": 43201.859}", "{\"n\": 3838, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.58, \"learn_time_ms\": 43143.554}", "{\"n\": 3839, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.58, \"learn_time_ms\": 43235.52}", "{\"n\": 3840, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.45, \"learn_time_ms\": 43173.833}", "{\"n\": 3841, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.36, \"learn_time_ms\": 43076.607}", "{\"n\": 3842, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.1, \"learn_time_ms\": 43114.428}", "{\"n\": 3843, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.53, \"learn_time_ms\": 43078.433}", "{\"n\": 3844, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.92, \"learn_time_ms\": 43086.172}", "{\"n\": 3845, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3244.55, \"learn_time_ms\": 43107.909}", "{\"n\": 3846, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.82, \"learn_time_ms\": 43036.075}", "{\"n\": 3847, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.95, \"learn_time_ms\": 42975.152}", "{\"n\": 3848, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3236.95, \"learn_time_ms\": 42972.028}", "{\"n\": 3849, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3245.76, \"learn_time_ms\": 42866.689}", "{\"n\": 3850, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3241.66, \"learn_time_ms\": 42882.788}", "{\"n\": 3851, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.71, \"learn_time_ms\": 42939.651}", "{\"n\": 3852, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3235.71, \"learn_time_ms\": 42905.223}", "{\"n\": 3853, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3238.75, \"learn_time_ms\": 42827.88}", "{\"n\": 3854, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3230.07, \"learn_time_ms\": 42781.177}", "{\"n\": 3855, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3222.9, \"learn_time_ms\": 42752.394}", "{\"n\": 3856, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.33, \"learn_time_ms\": 42897.425}", "{\"n\": 3857, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3221.33, \"learn_time_ms\": 42919.138}", "{\"n\": 3858, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.37, \"learn_time_ms\": 42916.249}", "{\"n\": 3859, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.37, \"learn_time_ms\": 42892.076}", "{\"n\": 3860, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.14, \"learn_time_ms\": 42918.674}", "{\"n\": 3861, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.5, \"learn_time_ms\": 42981.155}", "{\"n\": 3862, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3190.5, \"learn_time_ms\": 42892.305}", "{\"n\": 3863, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3170.96, \"learn_time_ms\": 42920.762}", "{\"n\": 3864, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.8, \"learn_time_ms\": 42917.222}", "{\"n\": 3865, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.03, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3156.28, \"learn_time_ms\": 42956.802}", "{\"n\": 3866, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.04, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3152.35, \"learn_time_ms\": 42855.193}", "{\"n\": 3867, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.07, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3144.06, \"learn_time_ms\": 42901.412}", "{\"n\": 3868, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3135.73, \"learn_time_ms\": 43008.36}", "{\"n\": 3869, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.17, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3113.99, \"learn_time_ms\": 43114.725}", "{\"n\": 3870, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.22, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3110.71, \"learn_time_ms\": 43115.117}", "{\"n\": 3871, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3100.88, \"learn_time_ms\": 43021.974}", "{\"n\": 3872, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.26, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3100.88, \"learn_time_ms\": 43090.64}", "{\"n\": 3873, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.2, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3119.09, \"learn_time_ms\": 43072.542}", "{\"n\": 3874, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.12, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3133.02, \"learn_time_ms\": 43057.473}", "{\"n\": 3875, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.1, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3136.77, \"learn_time_ms\": 42954.94}", "{\"n\": 3876, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.51, \"learn_time_ms\": 42912.486}", "{\"n\": 3877, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.51, \"learn_time_ms\": 42905.299}", "{\"n\": 3878, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -11.06, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3141.51, \"learn_time_ms\": 42840.152}", "{\"n\": 3879, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3159.15, \"learn_time_ms\": 42673.605}", "{\"n\": 3880, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.16, \"learn_time_ms\": 42646.101}", "{\"n\": 3881, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.97, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3156.16, \"learn_time_ms\": 42743.557}", "{\"n\": 3882, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.67, \"learn_time_ms\": 42717.086}", "{\"n\": 3883, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3171.63, \"learn_time_ms\": 42725.834}", "{\"n\": 3884, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3171.5, \"learn_time_ms\": 42694.851}", "{\"n\": 3885, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.95, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3171.5, \"learn_time_ms\": 42721.482}", "{\"n\": 3886, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.03, \"learn_time_ms\": 42681.233}", "{\"n\": 3887, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.03, \"learn_time_ms\": 42667.764}", "{\"n\": 3888, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3192.48, \"learn_time_ms\": 42661.211}", "{\"n\": 3889, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.73, \"learn_time_ms\": 42795.04}", "{\"n\": 3890, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.89, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3188.28, \"learn_time_ms\": 42834.125}", "{\"n\": 3891, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3197.39, \"learn_time_ms\": 42811.462}", "{\"n\": 3892, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3184.22, \"learn_time_ms\": 42800.171}", "{\"n\": 3893, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.56, \"learn_time_ms\": 42817.238}", "{\"n\": 3894, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.78, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.56, \"learn_time_ms\": 42902.068}", "{\"n\": 3895, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.77, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3194.18, \"learn_time_ms\": 42936.211}", "{\"n\": 3896, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3191.99, \"learn_time_ms\": 42914.596}", "{\"n\": 3897, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.08, \"learn_time_ms\": 42904.678}", "{\"n\": 3898, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.08, \"learn_time_ms\": 42936.253}", "{\"n\": 3899, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3221.37, \"learn_time_ms\": 42861.574}", "{\"n\": 3900, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.56, \"learn_time_ms\": 42821.91}", "{\"n\": 3901, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.56, \"learn_time_ms\": 42748.909}", "{\"n\": 3902, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3224.1, \"learn_time_ms\": 42780.103}", "{\"n\": 3903, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.4, \"learn_time_ms\": 42763.893}", "{\"n\": 3904, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3223.42, \"learn_time_ms\": 42649.284}", "{\"n\": 3905, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3231.09, \"learn_time_ms\": 42692.66}", "{\"n\": 3906, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.35, \"learn_time_ms\": 42753.267}", "{\"n\": 3907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.52, \"learn_time_ms\": 42740.003}", "{\"n\": 3908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3222.51, \"learn_time_ms\": 42639.503}", "{\"n\": 3909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3232.01, \"learn_time_ms\": 42679.11}", "{\"n\": 3910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3228.43, \"learn_time_ms\": 42717.828}", "{\"n\": 3911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.47, \"learn_time_ms\": 42910.908}", "{\"n\": 3912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.59, \"learn_time_ms\": 42817.24}", "{\"n\": 3913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.72, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.33, \"learn_time_ms\": 42799.201}", "{\"n\": 3914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3201.62, \"learn_time_ms\": 42803.247}", "{\"n\": 3915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.7, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.9, \"learn_time_ms\": 42729.519}", "{\"n\": 3916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3200.41, \"learn_time_ms\": 42811.884}", "{\"n\": 3917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3204.5, \"learn_time_ms\": 42885.613}", "{\"n\": 3918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3208.15, \"learn_time_ms\": 42921.773}", "{\"n\": 3919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.31, \"learn_time_ms\": 42974.644}", "{\"n\": 3920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.16, \"learn_time_ms\": 43004.235}", "{\"n\": 3921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3202.16, \"learn_time_ms\": 42787.997}", "{\"n\": 3922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3205.6, \"learn_time_ms\": 42844.564}", "{\"n\": 3923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3199.79, \"learn_time_ms\": 42884.414}", "{\"n\": 3924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3211.59, \"learn_time_ms\": 43014.244}", "{\"n\": 3925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3214.62, \"learn_time_ms\": 43040.227}", "{\"n\": 3926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.64, \"learn_time_ms\": 43037.022}", "{\"n\": 3927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3233.54, \"learn_time_ms\": 42968.1}", "{\"n\": 3928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3240.67, \"learn_time_ms\": 42909.318}", "{\"n\": 3929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3244.01, \"learn_time_ms\": 42868.201}", "{\"n\": 3930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3242.82, \"learn_time_ms\": 42801.934}", "{\"n\": 3931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3252.2, \"learn_time_ms\": 42886.04}", "{\"n\": 3932, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3239.56, \"learn_time_ms\": 42977.549}", "{\"n\": 3933, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3251.25, \"learn_time_ms\": 42959.618}", "{\"n\": 3934, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3261.38, \"learn_time_ms\": 42844.682}", "{\"n\": 3935, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3270.02, \"learn_time_ms\": 42794.014}", "{\"n\": 3936, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.08, \"learn_time_ms\": 42763.642}", "{\"n\": 3937, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3294.81, \"learn_time_ms\": 42816.25}", "{\"n\": 3938, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3282.98, \"learn_time_ms\": 42909.085}", "{\"n\": 3939, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3274.34, \"learn_time_ms\": 42828.282}", "{\"n\": 3940, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3283.03, \"learn_time_ms\": 42779.966}", "{\"n\": 3941, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3271.23, \"learn_time_ms\": 42740.747}", "{\"n\": 3942, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3259.68, \"learn_time_ms\": 42653.929}", "{\"n\": 3943, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.4, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3259.25, \"learn_time_ms\": 42615.18}", "{\"n\": 3944, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.97, \"learn_time_ms\": 42609.634}", "{\"n\": 3945, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3248.97, \"learn_time_ms\": 42544.803}", "{\"n\": 3946, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.16, \"learn_time_ms\": 42463.567}", "{\"n\": 3947, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3249.16, \"learn_time_ms\": 42425.367}", "{\"n\": 3948, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.38, \"learn_time_ms\": 42403.837}", "{\"n\": 3949, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.97, \"learn_time_ms\": 42462.718}", "{\"n\": 3950, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3236.63, \"learn_time_ms\": 42500.539}", "{\"n\": 3951, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.1, \"learn_time_ms\": 42563.574}", "{\"n\": 3952, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3225.1, \"learn_time_ms\": 42550.744}", "{\"n\": 3953, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.71, \"learn_time_ms\": 42600.118}", "{\"n\": 3954, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3209.37, \"learn_time_ms\": 42626.696}", "{\"n\": 3955, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3206.83, \"learn_time_ms\": 42708.858}", "{\"n\": 3956, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3215.8, \"learn_time_ms\": 42739.976}", "{\"n\": 3957, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3215.8, \"learn_time_ms\": 42739.278}", "{\"n\": 3958, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3221.57, \"learn_time_ms\": 42775.581}", "{\"n\": 3959, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3201.68, \"learn_time_ms\": 42777.843}", "{\"n\": 3960, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3201.68, \"learn_time_ms\": 42755.065}", "{\"n\": 3961, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3210.17, \"learn_time_ms\": 42666.036}", "{\"n\": 3962, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3218.62, \"learn_time_ms\": 42752.315}", "{\"n\": 3963, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.73, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3206.81, \"learn_time_ms\": 42736.731}", "{\"n\": 3964, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3191.16, \"learn_time_ms\": 42683.928}", "{\"n\": 3965, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.84, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3191.52, \"learn_time_ms\": 42672.243}", "{\"n\": 3966, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3189.11, \"learn_time_ms\": 42637.709}", "{\"n\": 3967, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3198.31, \"learn_time_ms\": 42559.433}", "{\"n\": 3968, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3188.13, \"learn_time_ms\": 42538.727}", "{\"n\": 3969, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3190.56, \"learn_time_ms\": 42531.709}", "{\"n\": 3970, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3191.05, \"learn_time_ms\": 42546.69}", "{\"n\": 3971, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3184.5, \"learn_time_ms\": 42645.808}", "{\"n\": 3972, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3192.2, \"learn_time_ms\": 42601.42}", "{\"n\": 3973, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3192.2, \"learn_time_ms\": 42655.179}", "{\"n\": 3974, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.86, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3194.71, \"learn_time_ms\": 42692.647}", "{\"n\": 3975, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.92, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3183.66, \"learn_time_ms\": 42790.186}", "{\"n\": 3976, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3193.79, \"learn_time_ms\": 42830.664}", "{\"n\": 3977, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.93, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.57, \"learn_time_ms\": 42932.843}", "{\"n\": 3978, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.68, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3213.35, \"learn_time_ms\": 42927.894}", "{\"n\": 3979, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3222.91, \"learn_time_ms\": 42904.579}", "{\"n\": 3980, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3222.91, \"learn_time_ms\": 42912.205}", "{\"n\": 3981, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3232.08, \"learn_time_ms\": 42820.157}", "{\"n\": 3982, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3226.3, \"learn_time_ms\": 42845.27}", "{\"n\": 3983, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3232.15, \"learn_time_ms\": 42776.676}", "{\"n\": 3984, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3232.15, \"learn_time_ms\": 42864.182}", "{\"n\": 3985, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3235.22, \"learn_time_ms\": 42718.408}", "{\"n\": 3986, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3237.54, \"learn_time_ms\": 42686.822}", "{\"n\": 3987, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3237.23, \"learn_time_ms\": 42641.346}", "{\"n\": 3988, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3237.84, \"learn_time_ms\": 42558.992}", "{\"n\": 3989, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3240.57, \"learn_time_ms\": 42520.918}", "{\"n\": 3990, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3240.57, \"learn_time_ms\": 42473.948}", "{\"n\": 3991, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3228.73, \"learn_time_ms\": 42548.725}", "{\"n\": 3992, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3215.72, \"learn_time_ms\": 42497.663}", "{\"n\": 3993, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3215.72, \"learn_time_ms\": 42595.518}", "{\"n\": 3994, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3225.71, \"learn_time_ms\": 42561.727}", "{\"n\": 3995, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3222.81, \"learn_time_ms\": 42668.222}", "{\"n\": 3996, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3213.79, \"learn_time_ms\": 42670.022}", "{\"n\": 3997, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3216.36, \"learn_time_ms\": 42601.922}", "{\"n\": 3998, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3231.99, \"learn_time_ms\": 42720.935}", "{\"n\": 3999, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3231.93, \"learn_time_ms\": 42745.297}", "{\"n\": 4000, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3230.4, \"learn_time_ms\": 42735.234}"]["{\"n\": 4001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 44520.785}", "{\"n\": 4002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43296.3}", "{\"n\": 4003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42965.581}", "{\"n\": 4004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42767.214}", "{\"n\": 4005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42587.316}", "{\"n\": 4006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42511.951}", "{\"n\": 4007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42464.888}", "{\"n\": 4008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42401.207}", "{\"n\": 4009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42365.223}", "{\"n\": 4010, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -12.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2904.5, \"learn_time_ms\": 42379.469}", "{\"n\": 4011, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.166666666666666, \"episode_reward_max\": -9.0, \"episode_len_mean\": 3054.3333333333335, \"learn_time_ms\": 42170.826}", "{\"n\": 4012, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.142857142857142, \"episode_reward_max\": -9.0, \"episode_len_mean\": 3038.1428571428573, \"learn_time_ms\": 42263.405}", "{\"n\": 4013, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.625, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3168.875, \"learn_time_ms\": 42275.611}", "{\"n\": 4014, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.333333333333334, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3201.777777777778, \"learn_time_ms\": 42276.001}", "{\"n\": 4015, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.333333333333334, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3201.777777777778, \"learn_time_ms\": 42399.661}", "{\"n\": 4016, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.333333333333334, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3214.75, \"learn_time_ms\": 42460.278}", "{\"n\": 4017, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.714285714285714, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3160.4285714285716, \"learn_time_ms\": 42514.858}", "{\"n\": 4018, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.529411764705882, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3181.529411764706, \"learn_time_ms\": 42575.544}", "{\"n\": 4019, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.529411764705882, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3181.529411764706, \"learn_time_ms\": 42649.559}", "{\"n\": 4020, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.555555555555555, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3178.6111111111113, \"learn_time_ms\": 42638.951}", "{\"n\": 4021, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3160.15, \"learn_time_ms\": 42633.543}", "{\"n\": 4022, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.454545454545455, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3225.5, \"learn_time_ms\": 42631.894}", "{\"n\": 4023, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.454545454545455, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3225.5, \"learn_time_ms\": 42693.088}", "{\"n\": 4024, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.541666666666666, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3218.5416666666665, \"learn_time_ms\": 42734.514}", "{\"n\": 4025, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.653846153846153, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3210.423076923077, \"learn_time_ms\": 42679.909}", "{\"n\": 4026, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.642857142857142, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3175.785714285714, \"learn_time_ms\": 42717.035}", "{\"n\": 4027, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.642857142857142, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3175.785714285714, \"learn_time_ms\": 42634.116}", "{\"n\": 4028, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3154.4333333333334, \"learn_time_ms\": 42743.218}", "{\"n\": 4029, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.625, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3183.125, \"learn_time_ms\": 42874.842}", "{\"n\": 4030, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3152.4857142857145, \"learn_time_ms\": 42897.623}", "{\"n\": 4031, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3152.4857142857145, \"learn_time_ms\": 42964.818}", "{\"n\": 4032, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.64864864864865, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3180.4054054054054, \"learn_time_ms\": 42952.974}", "{\"n\": 4033, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.605263157894736, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3186.8684210526317, \"learn_time_ms\": 42869.87}", "{\"n\": 4034, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.625, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3188.425, \"learn_time_ms\": 42846.297}", "{\"n\": 4035, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.658536585365853, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3177.6341463414633, \"learn_time_ms\": 42823.626}", "{\"n\": 4036, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.69047619047619, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3174.904761904762, \"learn_time_ms\": 42834.453}", "{\"n\": 4037, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.818181818181818, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3149.2727272727275, \"learn_time_ms\": 42869.474}", "{\"n\": 4038, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.777777777777779, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3156.088888888889, \"learn_time_ms\": 42837.963}", "{\"n\": 4039, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.787234042553191, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3159.0, \"learn_time_ms\": 42664.754}", "{\"n\": 4040, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.787234042553191, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3159.0, \"learn_time_ms\": 42652.284}", "{\"n\": 4041, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.692307692307692, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3172.096153846154, \"learn_time_ms\": 42673.35}", "{\"n\": 4042, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.692307692307692, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3172.096153846154, \"learn_time_ms\": 42691.443}", "{\"n\": 4043, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.692307692307692, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3172.096153846154, \"learn_time_ms\": 42723.436}", "{\"n\": 4044, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.722222222222221, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3168.4444444444443, \"learn_time_ms\": 42755.313}", "{\"n\": 4045, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.714285714285714, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3165.839285714286, \"learn_time_ms\": 42805.837}", "{\"n\": 4046, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.758620689655173, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3168.293103448276, \"learn_time_ms\": 42728.758}", "{\"n\": 4047, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62295081967213, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3180.4590163934427, \"learn_time_ms\": 42832.043}", "{\"n\": 4048, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.596774193548388, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3187.9032258064517, \"learn_time_ms\": 42754.226}", "{\"n\": 4049, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.596774193548388, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3187.9032258064517, \"learn_time_ms\": 42782.268}", "{\"n\": 4050, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.609375, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3189.921875, \"learn_time_ms\": 42842.791}", "{\"n\": 4051, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63076923076923, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3180.4, \"learn_time_ms\": 42838.699}", "{\"n\": 4052, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.529411764705882, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3192.470588235294, \"learn_time_ms\": 42825.427}", "{\"n\": 4053, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.594202898550725, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3179.942028985507, \"learn_time_ms\": 42763.642}", "{\"n\": 4054, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.661971830985916, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3171.3521126760565, \"learn_time_ms\": 42927.726}", "{\"n\": 4055, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.661971830985916, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3171.3521126760565, \"learn_time_ms\": 42832.194}", "{\"n\": 4056, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.73972602739726, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3162.027397260274, \"learn_time_ms\": 42893.698}", "{\"n\": 4057, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.763157894736842, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3161.934210526316, \"learn_time_ms\": 42805.285}", "{\"n\": 4058, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.807692307692308, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3158.641025641026, \"learn_time_ms\": 42730.803}", "{\"n\": 4059, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79746835443038, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3163.1012658227846, \"learn_time_ms\": 42769.253}", "{\"n\": 4060, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79746835443038, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3163.1012658227846, \"learn_time_ms\": 42736.001}", "{\"n\": 4061, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.79746835443038, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3163.1012658227846, \"learn_time_ms\": 42707.099}", "{\"n\": 4062, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.74390243902439, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3159.4268292682927, \"learn_time_ms\": 42703.578}", "{\"n\": 4063, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.741176470588234, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3152.8705882352942, \"learn_time_ms\": 42875.524}", "{\"n\": 4064, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.720930232558139, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3155.639534883721, \"learn_time_ms\": 42706.628}", "{\"n\": 4065, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.735632183908047, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3161.448275862069, \"learn_time_ms\": 42875.467}", "{\"n\": 4066, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.727272727272727, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3157.8636363636365, \"learn_time_ms\": 42850.894}", "{\"n\": 4067, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.703296703296703, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3170.153846153846, \"learn_time_ms\": 42952.832}", "{\"n\": 4068, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.706521739130435, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3166.8695652173915, \"learn_time_ms\": 43045.14}", "{\"n\": 4069, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.698924731182796, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3162.935483870968, \"learn_time_ms\": 43014.799}", "{\"n\": 4070, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.648936170212766, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3168.2340425531916, \"learn_time_ms\": 43034.128}", "{\"n\": 4071, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.673684210526316, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3166.3684210526317, \"learn_time_ms\": 43001.635}", "{\"n\": 4072, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.721649484536082, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3152.907216494845, \"learn_time_ms\": 42918.673}", "{\"n\": 4073, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.787878787878787, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3143.7272727272725, \"learn_time_ms\": 42835.386}", "{\"n\": 4074, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3154.95, \"learn_time_ms\": 42876.542}", "{\"n\": 4075, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -5.0, \"episode_len_mean\": 3154.95, \"learn_time_ms\": 42765.483}", "{\"n\": 4076, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3173.67, \"learn_time_ms\": 42723.341}", "{\"n\": 4077, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3178.32, \"learn_time_ms\": 42645.675}", "{\"n\": 4078, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3180.43, \"learn_time_ms\": 42671.07}", "{\"n\": 4079, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3182.32, \"learn_time_ms\": 42699.724}", "{\"n\": 4080, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3186.87, \"learn_time_ms\": 42679.581}", "{\"n\": 4081, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3183.74, \"learn_time_ms\": 42726.053}", "{\"n\": 4082, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.45, \"learn_time_ms\": 42831.74}", "{\"n\": 4083, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3175.05, \"learn_time_ms\": 42793.175}", "{\"n\": 4084, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3166.18, \"learn_time_ms\": 42825.403}", "{\"n\": 4085, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3177.73, \"learn_time_ms\": 42946.773}", "{\"n\": 4086, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3185.62, \"learn_time_ms\": 42979.594}", "{\"n\": 4087, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3187.82, \"learn_time_ms\": 43059.11}", "{\"n\": 4088, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.14, \"learn_time_ms\": 43059.712}", "{\"n\": 4089, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3168.13, \"learn_time_ms\": 42976.188}", "{\"n\": 4090, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.16, \"learn_time_ms\": 42999.499}", "{\"n\": 4091, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.16, \"learn_time_ms\": 42942.04}", "{\"n\": 4092, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.16, \"learn_time_ms\": 42939.245}", "{\"n\": 4093, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3176.56, \"learn_time_ms\": 43073.499}", "{\"n\": 4094, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3164.38, \"learn_time_ms\": 43049.576}", "{\"n\": 4095, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.22, \"learn_time_ms\": 42961.347}", "{\"n\": 4096, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.22, \"learn_time_ms\": 43015.879}", "{\"n\": 4097, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.8, \"learn_time_ms\": 42950.391}", "{\"n\": 4098, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3158.19, \"learn_time_ms\": 42923.52}", "{\"n\": 4099, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3154.28, \"learn_time_ms\": 42989.475}", "{\"n\": 4100, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3171.83, \"learn_time_ms\": 42958.573}", "{\"n\": 4101, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.47, \"learn_time_ms\": 43009.845}", "{\"n\": 4102, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3172.47, \"learn_time_ms\": 42998.158}", "{\"n\": 4103, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.56, \"learn_time_ms\": 42926.054}", "{\"n\": 4104, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3165.55, \"learn_time_ms\": 42917.118}", "{\"n\": 4105, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3158.52, \"learn_time_ms\": 42916.207}", "{\"n\": 4106, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3148.75, \"learn_time_ms\": 42868.675}", "{\"n\": 4107, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3148.75, \"learn_time_ms\": 42897.461}", "{\"n\": 4108, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3146.77, \"learn_time_ms\": 42987.04}", "{\"n\": 4109, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3145.84, \"learn_time_ms\": 42976.984}", "{\"n\": 4110, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3157.47, \"learn_time_ms\": 42936.935}", "{\"n\": 4111, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3152.09, \"learn_time_ms\": 42841.502}", "{\"n\": 4112, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3169.75, \"learn_time_ms\": 42839.992}", "{\"n\": 4113, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3162.55, \"learn_time_ms\": 42844.305}", "{\"n\": 4114, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.72, \"learn_time_ms\": 42834.986}", "{\"n\": 4115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3163.37, \"learn_time_ms\": 42799.632}", "{\"n\": 4116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3156.86, \"learn_time_ms\": 42828.186}", "{\"n\": 4117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3159.95, \"learn_time_ms\": 42818.001}", "{\"n\": 4118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3143.12, \"learn_time_ms\": 42686.615}", "{\"n\": 4119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.68, \"learn_time_ms\": 42702.866}", "{\"n\": 4120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.68, \"learn_time_ms\": 42783.313}", "{\"n\": 4121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3170.68, \"learn_time_ms\": 42876.092}", "{\"n\": 4122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.04, \"learn_time_ms\": 42862.82}", "{\"n\": 4123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.04, \"learn_time_ms\": 42902.451}", "{\"n\": 4124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.35, \"learn_time_ms\": 42915.225}", "{\"n\": 4125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.03, \"learn_time_ms\": 42940.38}", "{\"n\": 4126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3204.03, \"learn_time_ms\": 42878.862}", "{\"n\": 4127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3205.19, \"learn_time_ms\": 42878.757}", "{\"n\": 4128, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3193.29, \"learn_time_ms\": 42950.272}", "{\"n\": 4129, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.76, \"learn_time_ms\": 42970.396}", "{\"n\": 4130, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.76, \"learn_time_ms\": 42988.785}", "{\"n\": 4131, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.55, \"learn_time_ms\": 42921.307}", "{\"n\": 4132, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3198.97, \"learn_time_ms\": 42916.067}", "{\"n\": 4133, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.86, \"learn_time_ms\": 42799.905}", "{\"n\": 4134, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3199.1, \"learn_time_ms\": 42791.694}", "{\"n\": 4135, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.6, \"learn_time_ms\": 42833.78}", "{\"n\": 4136, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.6, \"learn_time_ms\": 42876.229}", "{\"n\": 4137, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3202.24, \"learn_time_ms\": 42928.113}", "{\"n\": 4138, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3197.84, \"learn_time_ms\": 42919.06}", "{\"n\": 4139, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.31, \"learn_time_ms\": 42878.319}", "{\"n\": 4140, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.44, \"learn_time_ms\": 42847.908}", "{\"n\": 4141, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.19, \"learn_time_ms\": 42884.558}", "{\"n\": 4142, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3195.38, \"learn_time_ms\": 43006.501}", "{\"n\": 4143, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3187.61, \"learn_time_ms\": 43066.676}", "{\"n\": 4144, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.53, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3190.8, \"learn_time_ms\": 42977.708}", "{\"n\": 4145, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3186.38, \"learn_time_ms\": 42967.658}", "{\"n\": 4146, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3177.3, \"learn_time_ms\": 43034.691}", "{\"n\": 4147, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.42, \"learn_time_ms\": 42944.791}", "{\"n\": 4148, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.65, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3175.42, \"learn_time_ms\": 42919.971}", "{\"n\": 4149, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.61, \"learn_time_ms\": 42917.328}", "{\"n\": 4150, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.6, \"learn_time_ms\": 42900.48}", "{\"n\": 4151, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3210.12, \"learn_time_ms\": 42910.956}", "{\"n\": 4152, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.37, \"learn_time_ms\": 42811.81}", "{\"n\": 4153, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3194.37, \"learn_time_ms\": 42784.992}", "{\"n\": 4154, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3212.31, \"learn_time_ms\": 42899.156}", "{\"n\": 4155, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.21, \"learn_time_ms\": 42923.293}", "{\"n\": 4156, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3223.21, \"learn_time_ms\": 42880.385}", "{\"n\": 4157, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.95, \"learn_time_ms\": 42867.518}", "{\"n\": 4158, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3226.95, \"learn_time_ms\": 42867.049}", "{\"n\": 4159, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3225.92, \"learn_time_ms\": 42835.344}", "{\"n\": 4160, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3216.4, \"learn_time_ms\": 42834.95}", "{\"n\": 4161, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3217.47, \"learn_time_ms\": 42809.161}", "{\"n\": 4162, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.49, \"learn_time_ms\": 42863.254}", "{\"n\": 4163, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.49, \"learn_time_ms\": 42860.124}", "{\"n\": 4164, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3229.49, \"learn_time_ms\": 42905.087}", "{\"n\": 4165, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3237.85, \"learn_time_ms\": 42859.981}", "{\"n\": 4166, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.86, \"learn_time_ms\": 42822.936}", "{\"n\": 4167, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.19, \"learn_time_ms\": 42899.845}", "{\"n\": 4168, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.11, \"learn_time_ms\": 42849.037}", "{\"n\": 4169, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3254.11, \"learn_time_ms\": 42900.461}", "{\"n\": 4170, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.93, \"learn_time_ms\": 42915.893}", "{\"n\": 4171, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.31, \"learn_time_ms\": 42905.503}", "{\"n\": 4172, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.48, \"learn_time_ms\": 42855.223}", "{\"n\": 4173, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.59, \"learn_time_ms\": 42850.134}", "{\"n\": 4174, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.91, \"learn_time_ms\": 42681.972}", "{\"n\": 4175, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3313.98, \"learn_time_ms\": 42708.319}", "{\"n\": 4176, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.35, \"learn_time_ms\": 42684.766}", "{\"n\": 4177, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.71, \"learn_time_ms\": 42577.959}", "{\"n\": 4178, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.04, \"learn_time_ms\": 42654.764}", "{\"n\": 4179, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.04, \"learn_time_ms\": 42637.748}", "{\"n\": 4180, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.01, \"learn_time_ms\": 42655.273}", "{\"n\": 4181, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.27, \"learn_time_ms\": 42767.354}", "{\"n\": 4182, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.35, \"learn_time_ms\": 42704.777}", "{\"n\": 4183, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.1, \"learn_time_ms\": 42645.91}", "{\"n\": 4184, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.04, \"learn_time_ms\": 42736.587}", "{\"n\": 4185, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.52, \"learn_time_ms\": 42730.936}", "{\"n\": 4186, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.62, \"learn_time_ms\": 42809.578}", "{\"n\": 4187, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.06, \"learn_time_ms\": 42898.873}", "{\"n\": 4188, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.06, \"learn_time_ms\": 42933.51}", "{\"n\": 4189, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.15, \"learn_time_ms\": 42941.273}", "{\"n\": 4190, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.55, \"learn_time_ms\": 42961.269}", "{\"n\": 4191, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.26, \"learn_time_ms\": 42962.468}", "{\"n\": 4192, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3269.38, \"learn_time_ms\": 42996.156}", "{\"n\": 4193, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3265.19, \"learn_time_ms\": 43005.787}", "{\"n\": 4194, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.65, \"learn_time_ms\": 43078.783}", "{\"n\": 4195, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.37, \"learn_time_ms\": 43152.636}", "{\"n\": 4196, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3258.25, \"learn_time_ms\": 43117.043}", "{\"n\": 4197, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3260.26, \"learn_time_ms\": 43053.4}", "{\"n\": 4198, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3262.44, \"learn_time_ms\": 43119.894}", "{\"n\": 4199, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3257.61, \"learn_time_ms\": 43069.211}", "{\"n\": 4200, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3242.76, \"learn_time_ms\": 43040.724}", "{\"n\": 4201, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.62, \"learn_time_ms\": 42992.168}", "{\"n\": 4202, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3250.62, \"learn_time_ms\": 43029.613}", "{\"n\": 4203, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3253.76, \"learn_time_ms\": 43077.767}", "{\"n\": 4204, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3256.31, \"learn_time_ms\": 43060.67}", "{\"n\": 4205, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3273.13, \"learn_time_ms\": 43012.647}", "{\"n\": 4206, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.77, \"learn_time_ms\": 43011.834}", "{\"n\": 4207, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3266.05, \"learn_time_ms\": 43117.055}", "{\"n\": 4208, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.2, \"learn_time_ms\": 43021.451}", "{\"n\": 4209, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.68, \"learn_time_ms\": 43055.274}", "{\"n\": 4210, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.68, \"learn_time_ms\": 43041.687}", "{\"n\": 4211, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.68, \"learn_time_ms\": 43033.077}", "{\"n\": 4212, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3249.33, \"learn_time_ms\": 42954.457}", "{\"n\": 4213, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.16, \"learn_time_ms\": 42978.275}", "{\"n\": 4214, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3229.16, \"learn_time_ms\": 42917.225}", "{\"n\": 4215, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3219.35, \"learn_time_ms\": 42849.658}", "{\"n\": 4216, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.03, \"learn_time_ms\": 42833.35}", "{\"n\": 4217, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3215.03, \"learn_time_ms\": 42769.6}", "{\"n\": 4218, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3206.65, \"learn_time_ms\": 42674.308}", "{\"n\": 4219, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3189.34, \"learn_time_ms\": 42651.431}", "{\"n\": 4220, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.01, \"learn_time_ms\": 42599.717}", "{\"n\": 4221, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3168.57, \"learn_time_ms\": 42669.608}", "{\"n\": 4222, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.74, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.3, \"learn_time_ms\": 42730.539}", "{\"n\": 4223, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3173.74, \"learn_time_ms\": 42773.026}", "{\"n\": 4224, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3186.13, \"learn_time_ms\": 42785.301}", "{\"n\": 4225, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3187.52, \"learn_time_ms\": 42844.164}", "{\"n\": 4226, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.88, \"learn_time_ms\": 42829.101}", "{\"n\": 4227, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.58, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3183.88, \"learn_time_ms\": 42828.624}", "{\"n\": 4228, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3176.12, \"learn_time_ms\": 42852.539}", "{\"n\": 4229, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.38, \"learn_time_ms\": 42986.207}", "{\"n\": 4230, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3154.38, \"learn_time_ms\": 43010.655}", "{\"n\": 4231, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.47, \"learn_time_ms\": 42920.161}", "{\"n\": 4232, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.64, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3157.78, \"learn_time_ms\": 42954.767}", "{\"n\": 4233, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3160.62, \"learn_time_ms\": 42969.177}", "{\"n\": 4234, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.67, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3150.03, \"learn_time_ms\": 42914.754}", "{\"n\": 4235, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3148.21, \"learn_time_ms\": 42914.061}", "{\"n\": 4236, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.66, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3148.21, \"learn_time_ms\": 42927.006}", "{\"n\": 4237, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3166.83, \"learn_time_ms\": 42905.18}", "{\"n\": 4238, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.48, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3177.16, \"learn_time_ms\": 42915.876}", "{\"n\": 4239, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3182.97, \"learn_time_ms\": 42808.076}", "{\"n\": 4240, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3179.81, \"learn_time_ms\": 42799.458}", "{\"n\": 4241, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.41, \"learn_time_ms\": 42810.632}", "{\"n\": 4242, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3181.41, \"learn_time_ms\": 42788.947}", "{\"n\": 4243, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.19, \"learn_time_ms\": 42785.378}", "{\"n\": 4244, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.49, \"learn_time_ms\": 42858.947}", "{\"n\": 4245, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.49, \"learn_time_ms\": 42845.574}", "{\"n\": 4246, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3188.49, \"learn_time_ms\": 42816.331}", "{\"n\": 4247, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3179.4, \"learn_time_ms\": 42766.165}", "{\"n\": 4248, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.46, \"learn_time_ms\": 42834.737}", "{\"n\": 4249, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3184.46, \"learn_time_ms\": 42828.214}", "{\"n\": 4250, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3192.88, \"learn_time_ms\": 42866.669}", "{\"n\": 4251, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3196.77, \"learn_time_ms\": 43003.537}", "{\"n\": 4252, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.72, \"learn_time_ms\": 42960.655}", "{\"n\": 4253, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.13, \"learn_time_ms\": 42870.882}", "{\"n\": 4254, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3201.13, \"learn_time_ms\": 42869.691}", "{\"n\": 4255, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3203.23, \"learn_time_ms\": 42902.065}", "{\"n\": 4256, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3234.95, \"learn_time_ms\": 43019.96}", "{\"n\": 4257, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3248.58, \"learn_time_ms\": 43214.032}", "{\"n\": 4258, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3247.59, \"learn_time_ms\": 43236.719}", "{\"n\": 4259, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.33, \"learn_time_ms\": 43169.905}", "{\"n\": 4260, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.33, \"learn_time_ms\": 43144.854}", "{\"n\": 4261, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3261.33, \"learn_time_ms\": 42984.074}", "{\"n\": 4262, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.87, \"learn_time_ms\": 43087.816}", "{\"n\": 4263, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.07, \"learn_time_ms\": 43191.487}", "{\"n\": 4264, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.49, \"learn_time_ms\": 43177.232}", "{\"n\": 4265, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.49, \"learn_time_ms\": 43069.291}", "{\"n\": 4266, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.49, \"learn_time_ms\": 42993.819}", "{\"n\": 4267, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.2, \"learn_time_ms\": 42881.079}", "{\"n\": 4268, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3277.97, \"learn_time_ms\": 42863.079}", "{\"n\": 4269, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3290.96, \"learn_time_ms\": 43002.355}", "{\"n\": 4270, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.76, \"learn_time_ms\": 43079.949}", "{\"n\": 4271, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.19, \"learn_time_ms\": 43056.319}", "{\"n\": 4272, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.13, \"learn_time_ms\": 43084.388}", "{\"n\": 4273, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.13, \"learn_time_ms\": 42987.309}", "{\"n\": 4274, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.59, \"learn_time_ms\": 42960.156}", "{\"n\": 4275, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.23, \"learn_time_ms\": 42939.289}", "{\"n\": 4276, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.35, \"learn_time_ms\": 42942.863}", "{\"n\": 4277, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.91, \"learn_time_ms\": 42926.275}", "{\"n\": 4278, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.91, \"learn_time_ms\": 42811.301}", "{\"n\": 4279, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3320.91, \"learn_time_ms\": 42728.122}", "{\"n\": 4280, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3334.32, \"learn_time_ms\": 42638.663}", "{\"n\": 4281, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3345.62, \"learn_time_ms\": 42787.791}", "{\"n\": 4282, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 42683.676}", "{\"n\": 4283, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3356.99, \"learn_time_ms\": 42725.225}", "{\"n\": 4284, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.82, \"learn_time_ms\": 42873.086}", "{\"n\": 4285, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3383.89, \"learn_time_ms\": 42960.108}", "{\"n\": 4286, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3383.89, \"learn_time_ms\": 42994.627}", "{\"n\": 4287, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.12, \"learn_time_ms\": 43051.325}", "{\"n\": 4288, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3414.08, \"learn_time_ms\": 43143.883}", "{\"n\": 4289, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3414.08, \"learn_time_ms\": 43167.049}", "{\"n\": 4290, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3413.72, \"learn_time_ms\": 43284.988}", "{\"n\": 4291, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3404.62, \"learn_time_ms\": 43219.693}", "{\"n\": 4292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3421.98, \"learn_time_ms\": 43296.133}", "{\"n\": 4293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3421.83, \"learn_time_ms\": 43352.556}", "{\"n\": 4294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3421.83, \"learn_time_ms\": 43231.459}", "{\"n\": 4295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3400.61, \"learn_time_ms\": 43149.286}", "{\"n\": 4296, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.0, \"learn_time_ms\": 43108.898}", "{\"n\": 4297, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.55, \"learn_time_ms\": 43064.247}", "{\"n\": 4298, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3404.32, \"learn_time_ms\": 43083.626}", "{\"n\": 4299, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3409.35, \"learn_time_ms\": 43163.202}", "{\"n\": 4300, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3420.34, \"learn_time_ms\": 43073.972}", "{\"n\": 4301, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3418.18, \"learn_time_ms\": 43187.3}", "{\"n\": 4302, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.33, \"learn_time_ms\": 43069.179}", "{\"n\": 4303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3422.64, \"learn_time_ms\": 43058.255}", "{\"n\": 4304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.73, \"learn_time_ms\": 43036.972}", "{\"n\": 4305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.01, \"learn_time_ms\": 43050.792}", "{\"n\": 4306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.27, \"learn_time_ms\": 43058.779}", "{\"n\": 4307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.27, \"learn_time_ms\": 43064.068}", "{\"n\": 4308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3377.96, \"learn_time_ms\": 43092.182}", "{\"n\": 4309, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.25, \"learn_time_ms\": 43004.22}", "{\"n\": 4310, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3347.56, \"learn_time_ms\": 43079.442}", "{\"n\": 4311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.01, \"learn_time_ms\": 42981.635}", "{\"n\": 4312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.01, \"learn_time_ms\": 43033.18}", "{\"n\": 4313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3320.85, \"learn_time_ms\": 42948.689}", "{\"n\": 4314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3330.46, \"learn_time_ms\": 42977.364}", "{\"n\": 4315, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3337.1, \"learn_time_ms\": 42949.756}", "{\"n\": 4316, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3331.1, \"learn_time_ms\": 42964.524}", "{\"n\": 4317, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3320.06, \"learn_time_ms\": 42897.611}", "{\"n\": 4318, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3320.06, \"learn_time_ms\": 42804.196}", "{\"n\": 4319, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3318.63, \"learn_time_ms\": 42840.064}", "{\"n\": 4320, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3301.59, \"learn_time_ms\": 42747.119}", "{\"n\": 4321, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3296.76, \"learn_time_ms\": 42649.912}", "{\"n\": 4322, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.21, \"learn_time_ms\": 42614.926}", "{\"n\": 4323, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.21, \"learn_time_ms\": 42697.391}", "{\"n\": 4324, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3279.21, \"learn_time_ms\": 42718.021}", "{\"n\": 4325, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3275.4, \"learn_time_ms\": 42698.842}", "{\"n\": 4326, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3260.25, \"learn_time_ms\": 42749.483}", "{\"n\": 4327, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3247.19, \"learn_time_ms\": 42721.692}", "{\"n\": 4328, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.93, \"learn_time_ms\": 42804.763}", "{\"n\": 4329, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3238.93, \"learn_time_ms\": 42703.621}", "{\"n\": 4330, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3213.86, \"learn_time_ms\": 42669.992}", "{\"n\": 4331, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3217.22, \"learn_time_ms\": 42725.459}", "{\"n\": 4332, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3216.68, \"learn_time_ms\": 42699.951}", "{\"n\": 4333, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.51, \"learn_time_ms\": 42688.075}", "{\"n\": 4334, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.51, \"learn_time_ms\": 42671.511}", "{\"n\": 4335, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.96, \"learn_time_ms\": 42835.296}", "{\"n\": 4336, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3257.96, \"learn_time_ms\": 42709.232}", "{\"n\": 4337, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3256.92, \"learn_time_ms\": 42729.727}", "{\"n\": 4338, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.18, \"learn_time_ms\": 42724.331}", "{\"n\": 4339, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.18, \"learn_time_ms\": 42732.134}", "{\"n\": 4340, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.18, \"learn_time_ms\": 42770.409}", "{\"n\": 4341, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3259.18, \"learn_time_ms\": 42836.724}", "{\"n\": 4342, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3258.39, \"learn_time_ms\": 42850.975}", "{\"n\": 4343, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3254.28, \"learn_time_ms\": 42826.994}", "{\"n\": 4344, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.87, \"learn_time_ms\": 42875.798}", "{\"n\": 4345, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3251.87, \"learn_time_ms\": 42763.535}", "{\"n\": 4346, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3246.89, \"learn_time_ms\": 42813.08}", "{\"n\": 4347, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.76, \"learn_time_ms\": 42849.597}", "{\"n\": 4348, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3232.72, \"learn_time_ms\": 42824.409}", "{\"n\": 4349, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3231.74, \"learn_time_ms\": 42858.695}", "{\"n\": 4350, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3222.2, \"learn_time_ms\": 42859.582}", "{\"n\": 4351, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3248.9, \"learn_time_ms\": 42791.734}", "{\"n\": 4352, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3227.17, \"learn_time_ms\": 42919.168}", "{\"n\": 4353, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.1, \"learn_time_ms\": 42873.137}", "{\"n\": 4354, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.1, \"learn_time_ms\": 42756.363}", "{\"n\": 4355, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3217.1, \"learn_time_ms\": 42768.811}", "{\"n\": 4356, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3233.92, \"learn_time_ms\": 42716.95}", "{\"n\": 4357, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3228.0, \"learn_time_ms\": 42749.884}", "{\"n\": 4358, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3241.29, \"learn_time_ms\": 42732.257}", "{\"n\": 4359, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.13, \"learn_time_ms\": 42751.87}", "{\"n\": 4360, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3240.13, \"learn_time_ms\": 42793.059}", "{\"n\": 4361, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3244.01, \"learn_time_ms\": 42817.944}", "{\"n\": 4362, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3234.46, \"learn_time_ms\": 42623.859}", "{\"n\": 4363, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.22, \"learn_time_ms\": 42605.174}", "{\"n\": 4364, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.0, \"learn_time_ms\": 42652.384}", "{\"n\": 4365, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3285.12, \"learn_time_ms\": 42672.395}", "{\"n\": 4366, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.13, \"learn_time_ms\": 42674.64}", "{\"n\": 4367, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.54, \"learn_time_ms\": 42726.059}", "{\"n\": 4368, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.54, \"learn_time_ms\": 42684.808}", "{\"n\": 4369, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.65, \"learn_time_ms\": 42656.95}", "{\"n\": 4370, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.43, \"learn_time_ms\": 42562.427}", "{\"n\": 4371, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.43, \"learn_time_ms\": 42653.515}", "{\"n\": 4372, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.15, \"learn_time_ms\": 42649.947}", "{\"n\": 4373, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.15, \"learn_time_ms\": 42732.966}", "{\"n\": 4374, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.36, \"learn_time_ms\": 42735.159}", "{\"n\": 4375, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3295.49, \"learn_time_ms\": 42834.634}", "{\"n\": 4376, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.04, \"learn_time_ms\": 42908.845}", "{\"n\": 4377, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.15, \"learn_time_ms\": 42783.0}", "{\"n\": 4378, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.75, \"learn_time_ms\": 42829.0}", "{\"n\": 4379, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3298.6, \"learn_time_ms\": 42858.96}", "{\"n\": 4380, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.91, \"learn_time_ms\": 42897.662}", "{\"n\": 4381, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.97, \"learn_time_ms\": 42717.147}", "{\"n\": 4382, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3323.97, \"learn_time_ms\": 42783.337}", "{\"n\": 4383, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.01, \"learn_time_ms\": 42800.709}", "{\"n\": 4384, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.75, \"learn_time_ms\": 42787.639}", "{\"n\": 4385, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.75, \"learn_time_ms\": 42752.025}", "{\"n\": 4386, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.47, \"learn_time_ms\": 42765.881}", "{\"n\": 4387, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.47, \"learn_time_ms\": 42887.948}", "{\"n\": 4388, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.56, \"learn_time_ms\": 42889.45}", "{\"n\": 4389, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.56, \"learn_time_ms\": 42921.612}", "{\"n\": 4390, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.06, \"learn_time_ms\": 42918.421}", "{\"n\": 4391, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.82, \"learn_time_ms\": 42989.312}", "{\"n\": 4392, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.28, \"learn_time_ms\": 43034.219}", "{\"n\": 4393, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.07, \"learn_time_ms\": 43112.023}", "{\"n\": 4394, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.07, \"learn_time_ms\": 43140.61}", "{\"n\": 4395, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3337.92, \"learn_time_ms\": 43148.334}", "{\"n\": 4396, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.49, \"learn_time_ms\": 43109.69}", "{\"n\": 4397, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3363.49, \"learn_time_ms\": 43090.626}", "{\"n\": 4398, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3387.21, \"learn_time_ms\": 43105.969}", "{\"n\": 4399, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.78, \"learn_time_ms\": 43059.945}", "{\"n\": 4400, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.78, \"learn_time_ms\": 43059.037}", "{\"n\": 4401, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.21, \"learn_time_ms\": 43015.738}", "{\"n\": 4402, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.01, \"learn_time_ms\": 42994.981}", "{\"n\": 4403, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.57, \"learn_time_ms\": 42945.587}", "{\"n\": 4404, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.57, \"learn_time_ms\": 42911.382}", "{\"n\": 4405, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3383.93, \"learn_time_ms\": 42954.449}", "{\"n\": 4406, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3383.93, \"learn_time_ms\": 43029.929}", "{\"n\": 4407, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.6, \"learn_time_ms\": 43052.182}", "{\"n\": 4408, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.18, \"learn_time_ms\": 43032.89}", "{\"n\": 4409, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.22, \"learn_time_ms\": 43030.701}", "{\"n\": 4410, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3377.01, \"learn_time_ms\": 43092.077}", "{\"n\": 4411, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.2, \"learn_time_ms\": 43178.49}", "{\"n\": 4412, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.93, \"learn_time_ms\": 43160.331}", "{\"n\": 4413, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.43, \"learn_time_ms\": 43153.924}", "{\"n\": 4414, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.16, \"learn_time_ms\": 43185.445}", "{\"n\": 4415, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3369.5, \"learn_time_ms\": 43152.78}", "{\"n\": 4416, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.53, \"learn_time_ms\": 43139.249}", "{\"n\": 4417, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.54, \"learn_time_ms\": 42986.093}", "{\"n\": 4418, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.54, \"learn_time_ms\": 43045.092}", "{\"n\": 4419, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.14, \"learn_time_ms\": 43158.664}", "{\"n\": 4420, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.6, \"learn_time_ms\": 43077.082}", "{\"n\": 4421, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.84, \"learn_time_ms\": 43108.624}", "{\"n\": 4422, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3363.13, \"learn_time_ms\": 43147.596}", "{\"n\": 4423, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3399.06, \"learn_time_ms\": 43078.483}", "{\"n\": 4424, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.24, \"learn_time_ms\": 43090.019}", "{\"n\": 4425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3378.92, \"learn_time_ms\": 42961.393}", "{\"n\": 4426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.56, \"learn_time_ms\": 42865.03}", "{\"n\": 4427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.56, \"learn_time_ms\": 42884.017}", "{\"n\": 4428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.62, \"learn_time_ms\": 42898.209}", "{\"n\": 4429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3359.2, \"learn_time_ms\": 42828.5}", "{\"n\": 4430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.74, \"learn_time_ms\": 42892.791}", "{\"n\": 4431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.39, \"learn_time_ms\": 42885.983}", "{\"n\": 4432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.39, \"learn_time_ms\": 42891.643}", "{\"n\": 4433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3364.39, \"learn_time_ms\": 42913.16}", "{\"n\": 4434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3350.09, \"learn_time_ms\": 42845.847}", "{\"n\": 4435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3355.29, \"learn_time_ms\": 42947.97}", "{\"n\": 4436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.75, \"learn_time_ms\": 42998.28}", "{\"n\": 4437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.45, \"learn_time_ms\": 43113.339}", "{\"n\": 4438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3365.45, \"learn_time_ms\": 43028.813}", "{\"n\": 4439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3367.04, \"learn_time_ms\": 42988.942}", "{\"n\": 4440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.25, \"learn_time_ms\": 43034.946}", "{\"n\": 4441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3361.75, \"learn_time_ms\": 42971.698}", "{\"n\": 4442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3379.11, \"learn_time_ms\": 42949.709}", "{\"n\": 4443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3398.85, \"learn_time_ms\": 42866.898}", "{\"n\": 4444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3390.25, \"learn_time_ms\": 42833.308}", "{\"n\": 4445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3371.54, \"learn_time_ms\": 42797.495}", "{\"n\": 4446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3371.28, \"learn_time_ms\": 42905.494}", "{\"n\": 4447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.52, \"learn_time_ms\": 42869.763}", "{\"n\": 4448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3373.52, \"learn_time_ms\": 42839.071}", "{\"n\": 4449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.74, \"learn_time_ms\": 42923.358}", "{\"n\": 4450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3358.08, \"learn_time_ms\": 42888.397}", "{\"n\": 4451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.93, \"learn_time_ms\": 42936.966}", "{\"n\": 4452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3335.39, \"learn_time_ms\": 42937.919}", "{\"n\": 4453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.1, \"learn_time_ms\": 42994.638}", "{\"n\": 4454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.45, \"learn_time_ms\": 43055.613}", "{\"n\": 4455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.94, \"learn_time_ms\": 42995.554}", "{\"n\": 4456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.48, \"learn_time_ms\": 42885.447}", "{\"n\": 4457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.93, \"learn_time_ms\": 42825.108}", "{\"n\": 4458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3306.15, \"learn_time_ms\": 42868.687}", "{\"n\": 4459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.94, \"learn_time_ms\": 42816.019}", "{\"n\": 4460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.91, \"learn_time_ms\": 42752.397}", "{\"n\": 4461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3315.67, \"learn_time_ms\": 42689.697}", "{\"n\": 4462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.8, \"learn_time_ms\": 42644.595}", "{\"n\": 4463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.8, \"learn_time_ms\": 42720.13}", "{\"n\": 4464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.67, \"learn_time_ms\": 42701.2}", "{\"n\": 4465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.67, \"learn_time_ms\": 42812.144}", "{\"n\": 4466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.42, \"learn_time_ms\": 42851.108}", "{\"n\": 4467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.21, \"learn_time_ms\": 42922.507}", "{\"n\": 4468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3328.21, \"learn_time_ms\": 42897.77}", "{\"n\": 4469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.26, \"learn_time_ms\": 42861.777}", "{\"n\": 4470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.28, \"learn_time_ms\": 42869.11}", "{\"n\": 4471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3307.44, \"learn_time_ms\": 42809.531}", "{\"n\": 4472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.22, \"learn_time_ms\": 43053.416}", "{\"n\": 4473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.92, \"learn_time_ms\": 42964.985}", "{\"n\": 4474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.92, \"learn_time_ms\": 42978.314}", "{\"n\": 4475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.92, \"learn_time_ms\": 42810.634}", "{\"n\": 4476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3393.63, \"learn_time_ms\": 42863.378}", "{\"n\": 4477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.66, \"learn_time_ms\": 42794.801}", "{\"n\": 4478, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.02, \"learn_time_ms\": 42890.142}", "{\"n\": 4479, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.02, \"learn_time_ms\": 42893.673}", "{\"n\": 4480, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3370.35, \"learn_time_ms\": 42963.006}", "{\"n\": 4481, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.08, \"learn_time_ms\": 43070.897}", "{\"n\": 4482, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.64, \"learn_time_ms\": 42940.402}", "{\"n\": 4483, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3349.64, \"learn_time_ms\": 42924.882}", "{\"n\": 4484, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.18, \"learn_time_ms\": 42920.657}", "{\"n\": 4485, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3343.27, \"learn_time_ms\": 42943.76}", "{\"n\": 4486, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.87, \"learn_time_ms\": 42889.324}", "{\"n\": 4487, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.38, \"learn_time_ms\": 42937.371}", "{\"n\": 4488, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.01, \"learn_time_ms\": 42888.881}", "{\"n\": 4489, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.9, \"learn_time_ms\": 42900.195}", "{\"n\": 4490, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.9, \"learn_time_ms\": 42885.963}", "{\"n\": 4491, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3272.17, \"learn_time_ms\": 42838.681}", "{\"n\": 4492, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.27, \"learn_time_ms\": 42762.095}", "{\"n\": 4493, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.01, \"learn_time_ms\": 42825.792}", "{\"n\": 4494, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.31, \"learn_time_ms\": 42859.479}", "{\"n\": 4495, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.46, \"learn_time_ms\": 42987.975}", "{\"n\": 4496, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.9, \"learn_time_ms\": 42974.483}", "{\"n\": 4497, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3297.66, \"learn_time_ms\": 42978.241}", "{\"n\": 4498, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3276.98, \"learn_time_ms\": 43023.139}", "{\"n\": 4499, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.53, \"learn_time_ms\": 42956.346}", "{\"n\": 4500, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3282.73, \"learn_time_ms\": 42991.622}", "{\"n\": 4501, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.62, \"learn_time_ms\": 42941.543}", "{\"n\": 4502, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3283.74, \"learn_time_ms\": 42954.97}", "{\"n\": 4503, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.15, \"learn_time_ms\": 43014.575}", "{\"n\": 4504, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3278.15, \"learn_time_ms\": 43038.058}", "{\"n\": 4505, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.92, \"learn_time_ms\": 42913.839}", "{\"n\": 4506, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.68, \"learn_time_ms\": 42845.519}", "{\"n\": 4507, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.83, \"learn_time_ms\": 42854.388}", "{\"n\": 4508, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.86, \"learn_time_ms\": 42791.275}", "{\"n\": 4509, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.86, \"learn_time_ms\": 42960.718}", "{\"n\": 4510, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3286.19, \"learn_time_ms\": 42948.286}", "{\"n\": 4511, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.48, \"learn_time_ms\": 43003.664}", "{\"n\": 4512, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3277.72, \"learn_time_ms\": 42886.088}", "{\"n\": 4513, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.43, \"learn_time_ms\": 42837.939}", "{\"n\": 4514, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3280.43, \"learn_time_ms\": 42821.229}", "{\"n\": 4515, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3269.7, \"learn_time_ms\": 42927.446}", "{\"n\": 4516, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3275.33, \"learn_time_ms\": 42940.515}", "{\"n\": 4517, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.42, \"learn_time_ms\": 42896.044}", "{\"n\": 4518, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.94, \"learn_time_ms\": 42965.199}", "{\"n\": 4519, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.94, \"learn_time_ms\": 42943.073}", "{\"n\": 4520, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3288.94, \"learn_time_ms\": 42868.309}", "{\"n\": 4521, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3293.68, \"learn_time_ms\": 42827.737}", "{\"n\": 4522, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3292.97, \"learn_time_ms\": 43050.532}", "{\"n\": 4523, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.76, \"learn_time_ms\": 43018.057}", "{\"n\": 4524, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.15, \"learn_time_ms\": 42912.416}", "{\"n\": 4525, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.15, \"learn_time_ms\": 43049.397}", "{\"n\": 4526, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.15, \"learn_time_ms\": 43062.554}", "{\"n\": 4527, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.37, \"learn_time_ms\": 43189.164}", "{\"n\": 4528, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.05, \"learn_time_ms\": 43142.023}", "{\"n\": 4529, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.49, \"learn_time_ms\": 43072.164}", "{\"n\": 4530, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.49, \"learn_time_ms\": 43082.203}", "{\"n\": 4531, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3328.49, \"learn_time_ms\": 43209.897}", "{\"n\": 4532, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.96, \"learn_time_ms\": 43213.043}", "{\"n\": 4533, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.79, \"learn_time_ms\": 43167.644}", "{\"n\": 4534, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.0, \"learn_time_ms\": 43217.346}", "{\"n\": 4535, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3310.92, \"learn_time_ms\": 43077.925}", "{\"n\": 4536, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.23, \"learn_time_ms\": 43148.389}", "{\"n\": 4537, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.23, \"learn_time_ms\": 43082.812}", "{\"n\": 4538, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.79, \"learn_time_ms\": 43039.802}", "{\"n\": 4539, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.93, \"learn_time_ms\": 42989.317}", "{\"n\": 4540, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.98, \"learn_time_ms\": 42916.991}", "{\"n\": 4541, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3278.43, \"learn_time_ms\": 42801.883}", "{\"n\": 4542, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3278.43, \"learn_time_ms\": 42693.262}", "{\"n\": 4543, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3278.43, \"learn_time_ms\": 42765.778}", "{\"n\": 4544, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3235.65, \"learn_time_ms\": 42797.475}", "{\"n\": 4545, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3259.54, \"learn_time_ms\": 42736.618}", "{\"n\": 4546, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.52, \"learn_time_ms\": 42697.58}", "{\"n\": 4547, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.52, \"learn_time_ms\": 42635.523}", "{\"n\": 4548, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.52, \"learn_time_ms\": 42728.548}", "{\"n\": 4549, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3254.52, \"learn_time_ms\": 42736.621}", "{\"n\": 4550, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3267.6, \"learn_time_ms\": 42888.84}", "{\"n\": 4551, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3278.11, \"learn_time_ms\": 43040.022}", "{\"n\": 4552, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3278.11, \"learn_time_ms\": 43111.699}", "{\"n\": 4553, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3281.58, \"learn_time_ms\": 43078.68}", "{\"n\": 4554, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3281.58, \"learn_time_ms\": 43101.374}", "{\"n\": 4555, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3295.54, \"learn_time_ms\": 43139.299}", "{\"n\": 4556, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3289.69, \"learn_time_ms\": 43122.997}", "{\"n\": 4557, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3310.36, \"learn_time_ms\": 43150.538}", "{\"n\": 4558, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3341.56, \"learn_time_ms\": 43080.916}", "{\"n\": 4559, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3344.39, \"learn_time_ms\": 43167.567}", "{\"n\": 4560, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3331.63, \"learn_time_ms\": 43045.927}", "{\"n\": 4561, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3331.63, \"learn_time_ms\": 42800.599}", "{\"n\": 4562, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3314.32, \"learn_time_ms\": 42729.126}", "{\"n\": 4563, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3314.32, \"learn_time_ms\": 42682.608}", "{\"n\": 4564, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3318.18, \"learn_time_ms\": 42705.468}", "{\"n\": 4565, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3318.18, \"learn_time_ms\": 42691.893}", "{\"n\": 4566, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3326.51, \"learn_time_ms\": 42703.151}", "{\"n\": 4567, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3325.56, \"learn_time_ms\": 42753.213}", "{\"n\": 4568, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3326.38, \"learn_time_ms\": 42818.794}", "{\"n\": 4569, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3324.35, \"learn_time_ms\": 42785.516}", "{\"n\": 4570, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3315.87, \"learn_time_ms\": 42841.978}", "{\"n\": 4571, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3315.87, \"learn_time_ms\": 42976.798}", "{\"n\": 4572, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3308.01, \"learn_time_ms\": 43017.118}", "{\"n\": 4573, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3288.78, \"learn_time_ms\": 43053.654}", "{\"n\": 4574, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3262.42, \"learn_time_ms\": 42961.247}", "{\"n\": 4575, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3262.42, \"learn_time_ms\": 43165.026}", "{\"n\": 4576, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3267.62, \"learn_time_ms\": 43208.528}", "{\"n\": 4577, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3273.99, \"learn_time_ms\": 43134.18}", "{\"n\": 4578, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3260.37, \"learn_time_ms\": 42997.461}", "{\"n\": 4579, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3260.37, \"learn_time_ms\": 43044.361}", "{\"n\": 4580, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3263.45, \"learn_time_ms\": 43074.195}", "{\"n\": 4581, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3265.58, \"learn_time_ms\": 43043.067}", "{\"n\": 4582, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3275.03, \"learn_time_ms\": 42973.622}", "{\"n\": 4583, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3269.35, \"learn_time_ms\": 43008.895}", "{\"n\": 4584, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3266.28, \"learn_time_ms\": 43081.666}", "{\"n\": 4585, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3258.37, \"learn_time_ms\": 42889.973}", "{\"n\": 4586, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3267.61, \"learn_time_ms\": 42836.083}", "{\"n\": 4587, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3262.93, \"learn_time_ms\": 42805.249}", "{\"n\": 4588, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3262.93, \"learn_time_ms\": 42849.797}", "{\"n\": 4589, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3285.53, \"learn_time_ms\": 42809.125}", "{\"n\": 4590, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3267.48, \"learn_time_ms\": 42781.507}", "{\"n\": 4591, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3251.43, \"learn_time_ms\": 42747.706}", "{\"n\": 4592, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3243.15, \"learn_time_ms\": 42782.138}", "{\"n\": 4593, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3243.15, \"learn_time_ms\": 42765.728}", "{\"n\": 4594, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3222.47, \"learn_time_ms\": 42688.734}", "{\"n\": 4595, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3225.01, \"learn_time_ms\": 42652.246}", "{\"n\": 4596, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3236.99, \"learn_time_ms\": 42620.415}", "{\"n\": 4597, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3236.99, \"learn_time_ms\": 42576.209}", "{\"n\": 4598, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3236.99, \"learn_time_ms\": 42643.391}", "{\"n\": 4599, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3245.61, \"learn_time_ms\": 42598.21}", "{\"n\": 4600, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3218.51, \"learn_time_ms\": 42590.427}", "{\"n\": 4601, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.92, \"learn_time_ms\": 42583.981}", "{\"n\": 4602, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.69, \"learn_time_ms\": 42611.663}", "{\"n\": 4603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3211.69, \"learn_time_ms\": 42643.528}", "{\"n\": 4604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3230.69, \"learn_time_ms\": 42681.12}", "{\"n\": 4605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3232.45, \"learn_time_ms\": 42856.274}", "{\"n\": 4606, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3232.45, \"learn_time_ms\": 42944.288}", "{\"n\": 4607, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3234.8, \"learn_time_ms\": 43007.134}", "{\"n\": 4608, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3235.42, \"learn_time_ms\": 43003.429}", "{\"n\": 4609, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3235.42, \"learn_time_ms\": 43120.019}", "{\"n\": 4610, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3235.42, \"learn_time_ms\": 43158.446}", "{\"n\": 4611, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3233.15, \"learn_time_ms\": 43212.35}", "{\"n\": 4612, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3233.96, \"learn_time_ms\": 43159.851}", "{\"n\": 4613, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3217.85, \"learn_time_ms\": 43130.03}", "{\"n\": 4614, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3227.59, \"learn_time_ms\": 43164.864}", "{\"n\": 4615, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3227.59, \"learn_time_ms\": 43037.839}", "{\"n\": 4616, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3240.29, \"learn_time_ms\": 43010.815}", "{\"n\": 4617, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3251.74, \"learn_time_ms\": 43078.104}", "{\"n\": 4618, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3281.41, \"learn_time_ms\": 43018.411}", "{\"n\": 4619, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3279.74, \"learn_time_ms\": 42891.401}", "{\"n\": 4620, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3285.68, \"learn_time_ms\": 42911.848}", "{\"n\": 4621, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3285.27, \"learn_time_ms\": 42889.592}", "{\"n\": 4622, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.02, \"learn_time_ms\": 42905.583}", "{\"n\": 4623, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.02, \"learn_time_ms\": 42935.448}", "{\"n\": 4624, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3258.6, \"learn_time_ms\": 42911.974}", "{\"n\": 4625, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3258.6, \"learn_time_ms\": 42935.815}", "{\"n\": 4626, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3258.6, \"learn_time_ms\": 42939.606}", "{\"n\": 4627, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3220.09, \"learn_time_ms\": 42907.216}", "{\"n\": 4628, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3248.85, \"learn_time_ms\": 42863.493}", "{\"n\": 4629, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3247.6, \"learn_time_ms\": 42974.983}", "{\"n\": 4630, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3247.6, \"learn_time_ms\": 42872.371}", "{\"n\": 4631, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3247.6, \"learn_time_ms\": 42819.232}", "{\"n\": 4632, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3247.6, \"learn_time_ms\": 42913.631}", "{\"n\": 4633, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3277.84, \"learn_time_ms\": 42973.91}", "{\"n\": 4634, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3283.36, \"learn_time_ms\": 43028.332}", "{\"n\": 4635, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3282.47, \"learn_time_ms\": 42978.538}", "{\"n\": 4636, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3282.47, \"learn_time_ms\": 42947.345}", "{\"n\": 4637, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3282.47, \"learn_time_ms\": 42996.895}", "{\"n\": 4638, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3269.5, \"learn_time_ms\": 43016.274}", "{\"n\": 4639, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3259.27, \"learn_time_ms\": 42916.046}", "{\"n\": 4640, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.41, \"learn_time_ms\": 43083.863}", "{\"n\": 4641, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3273.41, \"learn_time_ms\": 43129.773}", "{\"n\": 4642, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3296.52, \"learn_time_ms\": 43077.996}", "{\"n\": 4643, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3302.27, \"learn_time_ms\": 42966.324}", "{\"n\": 4644, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3300.53, \"learn_time_ms\": 43054.05}", "{\"n\": 4645, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3305.38, \"learn_time_ms\": 43127.789}", "{\"n\": 4646, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3312.63, \"learn_time_ms\": 43197.512}", "{\"n\": 4647, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3329.58, \"learn_time_ms\": 43157.174}", "{\"n\": 4648, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.13, \"learn_time_ms\": 43341.928}", "{\"n\": 4649, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3325.04, \"learn_time_ms\": 43276.685}", "{\"n\": 4650, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3316.63, \"learn_time_ms\": 43180.785}", "{\"n\": 4651, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3317.86, \"learn_time_ms\": 43225.129}", "{\"n\": 4652, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.64, \"learn_time_ms\": 43255.879}", "{\"n\": 4653, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3335.82, \"learn_time_ms\": 43334.303}", "{\"n\": 4654, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3326.35, \"learn_time_ms\": 43168.239}", "{\"n\": 4655, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.62, \"learn_time_ms\": 43104.857}", "{\"n\": 4656, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.62, \"learn_time_ms\": 43111.132}", "{\"n\": 4657, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3331.54, \"learn_time_ms\": 43235.869}", "{\"n\": 4658, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3331.96, \"learn_time_ms\": 43286.042}", "{\"n\": 4659, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3343.47, \"learn_time_ms\": 43409.761}", "{\"n\": 4660, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.01, \"learn_time_ms\": 43386.286}", "{\"n\": 4661, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.96, \"learn_time_ms\": 43444.77}", "{\"n\": 4662, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.11, \"learn_time_ms\": 43371.549}", "{\"n\": 4663, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.11, \"learn_time_ms\": 43334.592}", "{\"n\": 4664, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3371.11, \"learn_time_ms\": 43341.951}", "{\"n\": 4665, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.57, \"learn_time_ms\": 43307.405}", "{\"n\": 4666, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3388.38, \"learn_time_ms\": 43278.638}", "{\"n\": 4667, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3350.66, \"learn_time_ms\": 43111.486}", "{\"n\": 4668, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.65, \"learn_time_ms\": 42999.356}", "{\"n\": 4669, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.86, \"learn_time_ms\": 43000.353}", "{\"n\": 4670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3388.6, \"learn_time_ms\": 43075.073}", "{\"n\": 4671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3388.6, \"learn_time_ms\": 42982.901}", "{\"n\": 4672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3383.26, \"learn_time_ms\": 42966.823}", "{\"n\": 4673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.74, \"learn_time_ms\": 43058.518}", "{\"n\": 4674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3377.15, \"learn_time_ms\": 43058.416}", "{\"n\": 4675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3377.15, \"learn_time_ms\": 43088.912}", "{\"n\": 4676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3360.0, \"learn_time_ms\": 43021.038}", "{\"n\": 4677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3355.51, \"learn_time_ms\": 43096.087}", "{\"n\": 4678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.65, \"learn_time_ms\": 43031.063}", "{\"n\": 4679, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3358.74, \"learn_time_ms\": 43050.873}", "{\"n\": 4680, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3363.11, \"learn_time_ms\": 42888.335}", "{\"n\": 4681, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.19, \"learn_time_ms\": 42887.285}", "{\"n\": 4682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3352.18, \"learn_time_ms\": 42965.445}", "{\"n\": 4683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.77, \"learn_time_ms\": 42915.158}", "{\"n\": 4684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.77, \"learn_time_ms\": 42881.384}", "{\"n\": 4685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3350.98, \"learn_time_ms\": 43004.419}", "{\"n\": 4686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3336.54, \"learn_time_ms\": 43030.739}", "{\"n\": 4687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3338.76, \"learn_time_ms\": 42962.242}", "{\"n\": 4688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3338.76, \"learn_time_ms\": 43035.666}", "{\"n\": 4689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.11, \"learn_time_ms\": 43014.49}", "{\"n\": 4690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.02, \"learn_time_ms\": 43129.981}", "{\"n\": 4691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.76, \"learn_time_ms\": 43065.814}", "{\"n\": 4692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.12, \"learn_time_ms\": 42999.477}", "{\"n\": 4693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3340.51, \"learn_time_ms\": 42910.485}", "{\"n\": 4694, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.01, \"learn_time_ms\": 42954.458}", "{\"n\": 4695, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.61, \"learn_time_ms\": 42860.495}", "{\"n\": 4696, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.9, \"learn_time_ms\": 42809.966}", "{\"n\": 4697, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.03, \"learn_time_ms\": 42953.196}", "{\"n\": 4698, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.2, \"learn_time_ms\": 42835.005}", "{\"n\": 4699, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.58, \"learn_time_ms\": 42765.158}", "{\"n\": 4700, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.58, \"learn_time_ms\": 42759.419}", "{\"n\": 4701, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.16, \"learn_time_ms\": 42784.523}", "{\"n\": 4702, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.16, \"learn_time_ms\": 42677.587}", "{\"n\": 4703, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.67, \"learn_time_ms\": 42699.074}", "{\"n\": 4704, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.74, \"learn_time_ms\": 42733.53}", "{\"n\": 4705, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.98, \"learn_time_ms\": 42775.331}", "{\"n\": 4706, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.98, \"learn_time_ms\": 42873.713}", "{\"n\": 4707, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.98, \"learn_time_ms\": 42778.8}", "{\"n\": 4708, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.65, \"learn_time_ms\": 42825.615}", "{\"n\": 4709, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3411.44, \"learn_time_ms\": 42865.537}", "{\"n\": 4710, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.4, \"learn_time_ms\": 42863.137}", "{\"n\": 4711, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.58, \"learn_time_ms\": 42909.359}", "{\"n\": 4712, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3412.21, \"learn_time_ms\": 43007.18}", "{\"n\": 4713, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3412.21, \"learn_time_ms\": 43025.512}", "{\"n\": 4714, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.34, \"learn_time_ms\": 43011.577}", "{\"n\": 4715, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.23, \"learn_time_ms\": 42883.732}", "{\"n\": 4716, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.16, \"learn_time_ms\": 42801.289}", "{\"n\": 4717, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.11, \"learn_time_ms\": 42766.175}", "{\"n\": 4718, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.11, \"learn_time_ms\": 42893.738}", "{\"n\": 4719, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.22, \"learn_time_ms\": 42819.786}", "{\"n\": 4720, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.22, \"learn_time_ms\": 42713.806}", "{\"n\": 4721, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3367.09, \"learn_time_ms\": 42722.649}", "{\"n\": 4722, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.11, \"learn_time_ms\": 42750.638}", "{\"n\": 4723, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.26, \"learn_time_ms\": 42734.248}", "{\"n\": 4724, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.38, \"learn_time_ms\": 42699.277}", "{\"n\": 4725, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.08, \"learn_time_ms\": 42763.507}", "{\"n\": 4726, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.29, \"learn_time_ms\": 42765.924}", "{\"n\": 4727, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.81, \"learn_time_ms\": 42784.985}", "{\"n\": 4728, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.38, \"learn_time_ms\": 42661.138}", "{\"n\": 4729, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.38, \"learn_time_ms\": 42770.699}", "{\"n\": 4730, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3394.21, \"learn_time_ms\": 42838.753}", "{\"n\": 4731, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3412.43, \"learn_time_ms\": 42871.182}", "{\"n\": 4732, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3411.2, \"learn_time_ms\": 42743.223}", "{\"n\": 4733, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3411.2, \"learn_time_ms\": 42702.219}", "{\"n\": 4734, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.71, \"learn_time_ms\": 42707.422}", "{\"n\": 4735, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.71, \"learn_time_ms\": 42726.162}", "{\"n\": 4736, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.44, \"learn_time_ms\": 42709.678}", "{\"n\": 4737, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.53, \"learn_time_ms\": 42746.181}", "{\"n\": 4738, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.53, \"learn_time_ms\": 42771.987}", "{\"n\": 4739, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.03, \"learn_time_ms\": 42889.062}", "{\"n\": 4740, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.03, \"learn_time_ms\": 42852.13}", "{\"n\": 4741, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.03, \"learn_time_ms\": 42761.305}", "{\"n\": 4742, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.03, \"learn_time_ms\": 42880.707}", "{\"n\": 4743, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3471.15, \"learn_time_ms\": 42893.221}", "{\"n\": 4744, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.8, \"learn_time_ms\": 42903.8}", "{\"n\": 4745, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.3, \"learn_time_ms\": 42897.137}", "{\"n\": 4746, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.91, \"learn_time_ms\": 42906.967}", "{\"n\": 4747, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3463.98, \"learn_time_ms\": 42845.734}", "{\"n\": 4748, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.98, \"learn_time_ms\": 42739.962}", "{\"n\": 4749, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.58, \"learn_time_ms\": 42670.253}", "{\"n\": 4750, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3478.13, \"learn_time_ms\": 42759.901}", "{\"n\": 4751, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3494.73, \"learn_time_ms\": 42754.417}", "{\"n\": 4752, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3500.01, \"learn_time_ms\": 42689.027}", "{\"n\": 4753, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3500.01, \"learn_time_ms\": 42671.638}", "{\"n\": 4754, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3501.0, \"learn_time_ms\": 42620.672}", "{\"n\": 4755, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3500.28, \"learn_time_ms\": 42571.272}", "{\"n\": 4756, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3504.8, \"learn_time_ms\": 42597.775}", "{\"n\": 4757, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3503.31, \"learn_time_ms\": 42612.173}", "{\"n\": 4758, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3503.59, \"learn_time_ms\": 42637.322}", "{\"n\": 4759, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3494.3, \"learn_time_ms\": 42565.33}", "{\"n\": 4760, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3497.23, \"learn_time_ms\": 42581.667}", "{\"n\": 4761, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3485.45, \"learn_time_ms\": 42608.835}", "{\"n\": 4762, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.09, \"learn_time_ms\": 42739.392}", "{\"n\": 4763, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3485.87, \"learn_time_ms\": 42746.439}", "{\"n\": 4764, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3482.87, \"learn_time_ms\": 42817.672}", "{\"n\": 4765, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3475.41, \"learn_time_ms\": 42863.002}", "{\"n\": 4766, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3460.18, \"learn_time_ms\": 42810.365}", "{\"n\": 4767, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.04, \"learn_time_ms\": 42862.437}", "{\"n\": 4768, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.45, \"learn_time_ms\": 42950.613}", "{\"n\": 4769, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.17, \"learn_time_ms\": 42921.344}", "{\"n\": 4770, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.17, \"learn_time_ms\": 42914.342}", "{\"n\": 4771, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.17, \"learn_time_ms\": 42965.522}", "{\"n\": 4772, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3444.38, \"learn_time_ms\": 42868.276}", "{\"n\": 4773, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3450.12, \"learn_time_ms\": 42860.033}", "{\"n\": 4774, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3450.12, \"learn_time_ms\": 42822.175}", "{\"n\": 4775, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.39, \"learn_time_ms\": 42975.0}", "{\"n\": 4776, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3461.28, \"learn_time_ms\": 42967.18}", "{\"n\": 4777, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.48, \"learn_time_ms\": 42949.937}", "{\"n\": 4778, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.79, \"learn_time_ms\": 42917.473}", "{\"n\": 4779, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3477.85, \"learn_time_ms\": 42928.035}", "{\"n\": 4780, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.33, \"learn_time_ms\": 42836.98}", "{\"n\": 4781, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3482.97, \"learn_time_ms\": 42771.573}", "{\"n\": 4782, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3475.88, \"learn_time_ms\": 42792.198}", "{\"n\": 4783, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.25, \"learn_time_ms\": 42869.231}", "{\"n\": 4784, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.25, \"learn_time_ms\": 42930.503}", "{\"n\": 4785, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3445.1, \"learn_time_ms\": 42708.89}", "{\"n\": 4786, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.32, \"learn_time_ms\": 42743.946}", "{\"n\": 4787, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3482.34, \"learn_time_ms\": 42744.785}", "{\"n\": 4788, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3482.34, \"learn_time_ms\": 42726.777}", "{\"n\": 4789, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3485.61, \"learn_time_ms\": 42790.178}", "{\"n\": 4790, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3496.82, \"learn_time_ms\": 42840.911}", "{\"n\": 4791, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3507.13, \"learn_time_ms\": 42864.959}", "{\"n\": 4792, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3497.6, \"learn_time_ms\": 42860.076}", "{\"n\": 4793, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3496.07, \"learn_time_ms\": 42766.456}", "{\"n\": 4794, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3496.07, \"learn_time_ms\": 42757.9}", "{\"n\": 4795, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3496.07, \"learn_time_ms\": 42866.628}", "{\"n\": 4796, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3474.24, \"learn_time_ms\": 42914.705}", "{\"n\": 4797, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3491.29, \"learn_time_ms\": 42880.518}", "{\"n\": 4798, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3491.29, \"learn_time_ms\": 42932.108}", "{\"n\": 4799, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3482.82, \"learn_time_ms\": 42911.641}", "{\"n\": 4800, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.59, \"learn_time_ms\": 42859.62}", "{\"n\": 4801, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3452.59, \"learn_time_ms\": 42865.791}", "{\"n\": 4802, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.47, \"learn_time_ms\": 42800.659}", "{\"n\": 4803, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3465.94, \"learn_time_ms\": 42845.883}", "{\"n\": 4804, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.49, \"learn_time_ms\": 42923.762}", "{\"n\": 4805, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.49, \"learn_time_ms\": 42902.04}", "{\"n\": 4806, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.8, \"learn_time_ms\": 42887.05}", "{\"n\": 4807, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.32, \"learn_time_ms\": 42940.66}", "{\"n\": 4808, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.87, \"learn_time_ms\": 42860.177}", "{\"n\": 4809, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3446.63, \"learn_time_ms\": 42872.863}", "{\"n\": 4810, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3446.63, \"learn_time_ms\": 42905.587}", "{\"n\": 4811, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3439.78, \"learn_time_ms\": 42983.188}", "{\"n\": 4812, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.13, \"learn_time_ms\": 43064.826}", "{\"n\": 4813, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.53, \"learn_time_ms\": 42989.877}", "{\"n\": 4814, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3427.84, \"learn_time_ms\": 42931.079}", "{\"n\": 4815, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.29, \"learn_time_ms\": 42982.518}", "{\"n\": 4816, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.09, \"learn_time_ms\": 42922.362}", "{\"n\": 4817, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.27, \"learn_time_ms\": 42856.891}", "{\"n\": 4818, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.3, \"learn_time_ms\": 42929.806}", "{\"n\": 4819, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3450.55, \"learn_time_ms\": 42900.138}", "{\"n\": 4820, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.79, \"learn_time_ms\": 42890.859}", "{\"n\": 4821, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.79, \"learn_time_ms\": 42818.649}", "{\"n\": 4822, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3429.75, \"learn_time_ms\": 42801.723}", "{\"n\": 4823, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.04, \"learn_time_ms\": 42860.116}", "{\"n\": 4824, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.51, \"learn_time_ms\": 42829.302}", "{\"n\": 4825, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.51, \"learn_time_ms\": 42875.125}", "{\"n\": 4826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.51, \"learn_time_ms\": 43029.914}", "{\"n\": 4827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.11, \"learn_time_ms\": 43022.738}", "{\"n\": 4828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.25, \"learn_time_ms\": 42970.002}", "{\"n\": 4829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.25, \"learn_time_ms\": 42994.829}", "{\"n\": 4830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3439.19, \"learn_time_ms\": 43040.271}", "{\"n\": 4831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3442.71, \"learn_time_ms\": 42993.512}", "{\"n\": 4832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3442.71, \"learn_time_ms\": 43004.294}", "{\"n\": 4833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3441.13, \"learn_time_ms\": 43087.338}", "{\"n\": 4834, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.68, \"learn_time_ms\": 43074.42}", "{\"n\": 4835, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.1, \"learn_time_ms\": 42929.399}", "{\"n\": 4836, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.1, \"learn_time_ms\": 42853.508}", "{\"n\": 4837, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.73, \"learn_time_ms\": 42891.387}", "{\"n\": 4838, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3444.94, \"learn_time_ms\": 42889.582}", "{\"n\": 4839, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3441.04, \"learn_time_ms\": 42789.251}", "{\"n\": 4840, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.67, \"learn_time_ms\": 42811.672}", "{\"n\": 4841, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.24, \"learn_time_ms\": 42813.327}", "{\"n\": 4842, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.0, \"learn_time_ms\": 42898.663}", "{\"n\": 4843, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.0, \"learn_time_ms\": 42772.332}", "{\"n\": 4844, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.59, \"learn_time_ms\": 42822.619}", "{\"n\": 4845, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3441.7, \"learn_time_ms\": 42850.012}", "{\"n\": 4846, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3441.7, \"learn_time_ms\": 42770.862}", "{\"n\": 4847, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.56, \"learn_time_ms\": 42739.134}", "{\"n\": 4848, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.23, \"learn_time_ms\": 42691.9}", "{\"n\": 4849, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3430.08, \"learn_time_ms\": 42749.554}", "{\"n\": 4850, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3428.06, \"learn_time_ms\": 42770.719}", "{\"n\": 4851, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.72, \"learn_time_ms\": 42768.645}", "{\"n\": 4852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.27, \"learn_time_ms\": 42712.325}", "{\"n\": 4853, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.27, \"learn_time_ms\": 42824.873}", "{\"n\": 4854, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3419.51, \"learn_time_ms\": 42784.751}", "{\"n\": 4855, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.3, \"learn_time_ms\": 42757.694}", "{\"n\": 4856, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3439.27, \"learn_time_ms\": 42715.593}", "{\"n\": 4857, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.74, \"learn_time_ms\": 42770.071}", "{\"n\": 4858, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.05, \"learn_time_ms\": 42835.186}", "{\"n\": 4859, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.05, \"learn_time_ms\": 42818.008}", "{\"n\": 4860, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3426.88, \"learn_time_ms\": 42698.27}", "{\"n\": 4861, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.2, \"learn_time_ms\": 42761.653}", "{\"n\": 4862, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.91, \"learn_time_ms\": 42813.847}", "{\"n\": 4863, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.72, \"learn_time_ms\": 42740.934}", "{\"n\": 4864, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.84, \"learn_time_ms\": 42791.895}", "{\"n\": 4865, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.84, \"learn_time_ms\": 42771.485}", "{\"n\": 4866, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.84, \"learn_time_ms\": 42836.097}", "{\"n\": 4867, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3446.07, \"learn_time_ms\": 42805.326}", "{\"n\": 4868, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3457.77, \"learn_time_ms\": 42789.768}", "{\"n\": 4869, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3463.36, \"learn_time_ms\": 42773.01}", "{\"n\": 4870, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3463.36, \"learn_time_ms\": 42820.234}", "{\"n\": 4871, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.1, \"learn_time_ms\": 42828.28}", "{\"n\": 4872, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.01, \"learn_time_ms\": 42687.002}", "{\"n\": 4873, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3498.57, \"learn_time_ms\": 42691.214}", "{\"n\": 4874, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3509.15, \"learn_time_ms\": 42618.076}", "{\"n\": 4875, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.24, \"learn_time_ms\": 42706.258}", "{\"n\": 4876, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.24, \"learn_time_ms\": 42716.986}", "{\"n\": 4877, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3509.23, \"learn_time_ms\": 42711.25}", "{\"n\": 4878, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3506.02, \"learn_time_ms\": 42816.784}", "{\"n\": 4879, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3496.67, \"learn_time_ms\": 42844.591}", "{\"n\": 4880, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.12, \"learn_time_ms\": 42877.93}", "{\"n\": 4881, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.19, \"learn_time_ms\": 42818.155}", "{\"n\": 4882, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.19, \"learn_time_ms\": 42991.744}", "{\"n\": 4883, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3487.75, \"learn_time_ms\": 42958.961}", "{\"n\": 4884, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3501.79, \"learn_time_ms\": 42923.374}", "{\"n\": 4885, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3515.3, \"learn_time_ms\": 43021.213}", "{\"n\": 4886, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3515.37, \"learn_time_ms\": 43063.864}", "{\"n\": 4887, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3515.37, \"learn_time_ms\": 43011.812}", "{\"n\": 4888, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3514.04, \"learn_time_ms\": 42910.242}", "{\"n\": 4889, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3494.85, \"learn_time_ms\": 42844.836}", "{\"n\": 4890, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3488.2, \"learn_time_ms\": 42720.099}", "{\"n\": 4891, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3487.53, \"learn_time_ms\": 42781.129}", "{\"n\": 4892, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3495.53, \"learn_time_ms\": 42688.757}", "{\"n\": 4893, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3495.53, \"learn_time_ms\": 42736.092}", "{\"n\": 4894, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3507.55, \"learn_time_ms\": 42816.342}", "{\"n\": 4895, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3498.92, \"learn_time_ms\": 42643.283}", "{\"n\": 4896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3498.92, \"learn_time_ms\": 42571.952}", "{\"n\": 4897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3493.41, \"learn_time_ms\": 42589.564}", "{\"n\": 4898, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3496.69, \"learn_time_ms\": 42575.167}", "{\"n\": 4899, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3523.79, \"learn_time_ms\": 42679.185}", "{\"n\": 4900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.54, \"learn_time_ms\": 42785.707}", "{\"n\": 4901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3517.36, \"learn_time_ms\": 42748.07}", "{\"n\": 4902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3509.39, \"learn_time_ms\": 42707.884}", "{\"n\": 4903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3521.13, \"learn_time_ms\": 42775.842}", "{\"n\": 4904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3532.8, \"learn_time_ms\": 42677.973}", "{\"n\": 4905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3532.8, \"learn_time_ms\": 42697.747}", "{\"n\": 4906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3553.02, \"learn_time_ms\": 42688.258}", "{\"n\": 4907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3554.0, \"learn_time_ms\": 42740.682}", "{\"n\": 4908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.21, \"learn_time_ms\": 42791.143}", "{\"n\": 4909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3560.32, \"learn_time_ms\": 42723.665}", "{\"n\": 4910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3560.32, \"learn_time_ms\": 42678.369}", "{\"n\": 4911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3560.32, \"learn_time_ms\": 42628.35}", "{\"n\": 4912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3547.37, \"learn_time_ms\": 42629.922}", "{\"n\": 4913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3571.77, \"learn_time_ms\": 42606.359}", "{\"n\": 4914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3571.77, \"learn_time_ms\": 42729.654}", "{\"n\": 4915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3572.55, \"learn_time_ms\": 42708.814}", "{\"n\": 4916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.06, \"learn_time_ms\": 42770.85}", "{\"n\": 4917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3550.01, \"learn_time_ms\": 42684.749}", "{\"n\": 4918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.58, \"learn_time_ms\": 42634.94}", "{\"n\": 4919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3566.47, \"learn_time_ms\": 42759.733}", "{\"n\": 4920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3582.6, \"learn_time_ms\": 42801.943}", "{\"n\": 4921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3580.75, \"learn_time_ms\": 42861.437}", "{\"n\": 4922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3580.75, \"learn_time_ms\": 42855.263}", "{\"n\": 4923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3571.49, \"learn_time_ms\": 42779.881}", "{\"n\": 4924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.98, \"learn_time_ms\": 42739.641}", "{\"n\": 4925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3598.12, \"learn_time_ms\": 42773.262}", "{\"n\": 4926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3591.95, \"learn_time_ms\": 42797.974}", "{\"n\": 4927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3591.95, \"learn_time_ms\": 42856.143}", "{\"n\": 4928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3591.95, \"learn_time_ms\": 42915.341}", "{\"n\": 4929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3593.49, \"learn_time_ms\": 42785.474}", "{\"n\": 4930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3593.04, \"learn_time_ms\": 42780.852}", "{\"n\": 4931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3588.33, \"learn_time_ms\": 42698.918}", "{\"n\": 4932, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3585.39, \"learn_time_ms\": 42767.121}", "{\"n\": 4933, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3582.16, \"learn_time_ms\": 42805.19}", "{\"n\": 4934, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3584.28, \"learn_time_ms\": 42773.943}", "{\"n\": 4935, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3577.73, \"learn_time_ms\": 42769.007}", "{\"n\": 4936, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3575.41, \"learn_time_ms\": 42780.135}", "{\"n\": 4937, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3570.77, \"learn_time_ms\": 42826.805}", "{\"n\": 4938, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3570.21, \"learn_time_ms\": 42767.792}", "{\"n\": 4939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3570.21, \"learn_time_ms\": 42897.447}", "{\"n\": 4940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3578.4, \"learn_time_ms\": 42900.735}", "{\"n\": 4941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3569.1, \"learn_time_ms\": 42930.205}", "{\"n\": 4942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3559.72, \"learn_time_ms\": 42999.565}", "{\"n\": 4943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3559.72, \"learn_time_ms\": 43075.212}", "{\"n\": 4944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3572.9, \"learn_time_ms\": 43166.578}", "{\"n\": 4945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3572.11, \"learn_time_ms\": 43156.102}", "{\"n\": 4946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3572.11, \"learn_time_ms\": 43180.443}", "{\"n\": 4947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3568.12, \"learn_time_ms\": 43238.518}", "{\"n\": 4948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3572.12, \"learn_time_ms\": 43173.562}", "{\"n\": 4949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3563.34, \"learn_time_ms\": 43094.769}", "{\"n\": 4950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3522.34, \"learn_time_ms\": 43093.388}", "{\"n\": 4951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3549.63, \"learn_time_ms\": 43149.025}", "{\"n\": 4952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.01, \"learn_time_ms\": 43028.464}", "{\"n\": 4953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.01, \"learn_time_ms\": 42995.152}", "{\"n\": 4954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.01, \"learn_time_ms\": 42931.536}", "{\"n\": 4955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3566.12, \"learn_time_ms\": 43020.967}", "{\"n\": 4956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3533.68, \"learn_time_ms\": 42932.269}", "{\"n\": 4957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3524.21, \"learn_time_ms\": 42974.815}", "{\"n\": 4958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3524.21, \"learn_time_ms\": 43050.797}", "{\"n\": 4959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3535.07, \"learn_time_ms\": 43024.959}", "{\"n\": 4960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3535.07, \"learn_time_ms\": 42969.668}", "{\"n\": 4961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.24, \"learn_time_ms\": 43032.339}", "{\"n\": 4962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3531.0, \"learn_time_ms\": 42963.016}", "{\"n\": 4963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3541.15, \"learn_time_ms\": 42971.177}", "{\"n\": 4964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3541.15, \"learn_time_ms\": 42933.103}", "{\"n\": 4965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3526.61, \"learn_time_ms\": 42927.046}", "{\"n\": 4966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3523.24, \"learn_time_ms\": 42978.889}", "{\"n\": 4967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3523.24, \"learn_time_ms\": 42897.499}", "{\"n\": 4968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3541.27, \"learn_time_ms\": 42806.614}", "{\"n\": 4969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3546.56, \"learn_time_ms\": 42762.526}", "{\"n\": 4970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3523.45, \"learn_time_ms\": 42913.768}", "{\"n\": 4971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3509.1, \"learn_time_ms\": 42790.668}", "{\"n\": 4972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.76, \"learn_time_ms\": 42962.378}", "{\"n\": 4973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3531.21, \"learn_time_ms\": 42911.048}", "{\"n\": 4974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3537.77, \"learn_time_ms\": 42954.181}", "{\"n\": 4975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3526.16, \"learn_time_ms\": 42950.474}", "{\"n\": 4976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3526.16, \"learn_time_ms\": 42885.398}", "{\"n\": 4977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3509.31, \"learn_time_ms\": 42833.984}", "{\"n\": 4978, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.78, \"learn_time_ms\": 42949.46}", "{\"n\": 4979, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.5, \"learn_time_ms\": 42976.689}", "{\"n\": 4980, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.16, \"learn_time_ms\": 42846.983}", "{\"n\": 4981, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.78, \"learn_time_ms\": 42948.053}", "{\"n\": 4982, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.78, \"learn_time_ms\": 42851.135}", "{\"n\": 4983, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3477.73, \"learn_time_ms\": 42883.398}", "{\"n\": 4984, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3460.3, \"learn_time_ms\": 42862.948}", "{\"n\": 4985, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.68, \"learn_time_ms\": 42758.508}", "{\"n\": 4986, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.68, \"learn_time_ms\": 42811.968}", "{\"n\": 4987, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3461.26, \"learn_time_ms\": 42888.402}", "{\"n\": 4988, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.69, \"learn_time_ms\": 42883.383}", "{\"n\": 4989, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3477.48, \"learn_time_ms\": 42935.556}", "{\"n\": 4990, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.69, \"learn_time_ms\": 43005.5}", "{\"n\": 4991, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.69, \"learn_time_ms\": 42929.004}", "{\"n\": 4992, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.9, \"learn_time_ms\": 42916.64}", "{\"n\": 4993, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.03, \"learn_time_ms\": 42858.565}", "{\"n\": 4994, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.03, \"learn_time_ms\": 42815.645}", "{\"n\": 4995, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3460.25, \"learn_time_ms\": 42901.243}", "{\"n\": 4996, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3457.83, \"learn_time_ms\": 42832.159}", "{\"n\": 4997, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.23, \"learn_time_ms\": 42846.976}", "{\"n\": 4998, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.87, \"learn_time_ms\": 42849.041}", "{\"n\": 4999, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3460.63, \"learn_time_ms\": 42758.97}", "{\"n\": 5000, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.94, \"learn_time_ms\": 42802.172}"]["{\"n\": 5001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 50070.811}", "{\"n\": 5002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 49063.702}", "{\"n\": 5003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 48623.589}", "{\"n\": 5004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 48404.097}", "{\"n\": 5005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 48116.747}", "{\"n\": 5006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 48002.949}", "{\"n\": 5007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47804.703}", "{\"n\": 5008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47685.085}", "{\"n\": 5009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47598.11}", "{\"n\": 5010, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -11.5, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2872.5, \"learn_time_ms\": 47526.044}", "{\"n\": 5011, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -10.5, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3133.0, \"learn_time_ms\": 47208.034}", "{\"n\": 5012, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -11.333333333333334, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3106.8333333333335, \"learn_time_ms\": 47023.763}", "{\"n\": 5013, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -11.333333333333334, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3106.8333333333335, \"learn_time_ms\": 46935.53}", "{\"n\": 5014, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -11.285714285714286, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3100.4285714285716, \"learn_time_ms\": 46825.978}", "{\"n\": 5015, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -10.875, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3153.875, \"learn_time_ms\": 46847.562}", "{\"n\": 5016, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -11.3, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3062.6, \"learn_time_ms\": 46785.849}", "{\"n\": 5017, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -10.23076923076923, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3203.076923076923, \"learn_time_ms\": 46806.881}", "{\"n\": 5018, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -10.428571428571429, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3180.714285714286, \"learn_time_ms\": 46772.016}", "{\"n\": 5019, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.933333333333334, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3287.8, \"learn_time_ms\": 46757.432}", "{\"n\": 5020, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.4375, \"learn_time_ms\": 46698.781}", "{\"n\": 5021, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3402.4375, \"learn_time_ms\": 46658.183}", "{\"n\": 5022, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.166666666666666, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3431.222222222222, \"learn_time_ms\": 46754.563}", "{\"n\": 5023, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.4, \"learn_time_ms\": 46768.908}", "{\"n\": 5024, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.047619047619047, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.3809523809523, \"learn_time_ms\": 46596.689}", "{\"n\": 5025, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.304347826086957, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.1304347826085, \"learn_time_ms\": 46503.319}", "{\"n\": 5026, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.304347826086957, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.1304347826085, \"learn_time_ms\": 46475.895}", "{\"n\": 5027, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.28, \"learn_time_ms\": 46447.889}", "{\"n\": 5028, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.26923076923077, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.9615384615386, \"learn_time_ms\": 46444.346}", "{\"n\": 5029, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.26923076923077, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.9615384615386, \"learn_time_ms\": 46361.89}", "{\"n\": 5030, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.75, \"learn_time_ms\": 46367.763}", "{\"n\": 5031, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.612903225806452, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3557.1612903225805, \"learn_time_ms\": 46246.58}", "{\"n\": 5032, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.612903225806452, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3557.1612903225805, \"learn_time_ms\": 46154.823}", "{\"n\": 5033, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.666666666666666, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.787878787879, \"learn_time_ms\": 46137.988}", "{\"n\": 5034, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.685714285714285, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3552.8285714285716, \"learn_time_ms\": 46374.609}", "{\"n\": 5035, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.567567567567568, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3573.4864864864867, \"learn_time_ms\": 46378.859}", "{\"n\": 5036, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.567567567567568, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3573.4864864864867, \"learn_time_ms\": 46375.948}", "{\"n\": 5037, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -8.567567567567568, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3573.4864864864867, \"learn_time_ms\": 46300.949}", "{\"n\": 5038, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.923076923076923, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3517.5641025641025, \"learn_time_ms\": 46290.862}", "{\"n\": 5039, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69767441860465, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3552.5581395348836, \"learn_time_ms\": 46278.919}", "{\"n\": 5040, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.795454545454545, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3538.75, \"learn_time_ms\": 46261.844}", "{\"n\": 5041, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.795454545454545, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3538.75, \"learn_time_ms\": 46372.219}", "{\"n\": 5042, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.911111111111111, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3517.266666666667, \"learn_time_ms\": 46425.773}", "{\"n\": 5043, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.911111111111111, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3517.266666666667, \"learn_time_ms\": 46302.842}", "{\"n\": 5044, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.92156862745098, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3514.3333333333335, \"learn_time_ms\": 46043.438}", "{\"n\": 5045, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.942307692307692, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3506.1923076923076, \"learn_time_ms\": 46091.659}", "{\"n\": 5046, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.942307692307692, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3506.1923076923076, \"learn_time_ms\": 46056.399}", "{\"n\": 5047, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.849056603773585, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.830188679245, \"learn_time_ms\": 46089.268}", "{\"n\": 5048, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.849056603773585, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.830188679245, \"learn_time_ms\": 46035.454}", "{\"n\": 5049, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.909090909090908, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3494.3818181818183, \"learn_time_ms\": 46087.547}", "{\"n\": 5050, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.964285714285714, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3489.0714285714284, \"learn_time_ms\": 46049.096}", "{\"n\": 5051, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.066666666666666, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3481.2833333333333, \"learn_time_ms\": 45998.104}", "{\"n\": 5052, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.049180327868852, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3481.5081967213114, \"learn_time_ms\": 45853.976}", "{\"n\": 5053, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.049180327868852, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3481.5081967213114, \"learn_time_ms\": 45920.394}", "{\"n\": 5054, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.047619047619047, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3479.4761904761904, \"learn_time_ms\": 46015.449}", "{\"n\": 5055, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.047619047619047, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3479.4761904761904, \"learn_time_ms\": 45957.972}", "{\"n\": 5056, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.015151515151516, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.469696969697, \"learn_time_ms\": 46024.781}", "{\"n\": 5057, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3488.507462686567, \"learn_time_ms\": 45985.674}", "{\"n\": 5058, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.942028985507246, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3494.855072463768, \"learn_time_ms\": 46066.498}", "{\"n\": 5059, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.028571428571428, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3479.342857142857, \"learn_time_ms\": 46002.88}", "{\"n\": 5060, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.028571428571428, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3479.342857142857, \"learn_time_ms\": 46075.597}", "{\"n\": 5061, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.027397260273972, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3478.4383561643835, \"learn_time_ms\": 46079.893}", "{\"n\": 5062, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.932432432432432, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3491.2972972972975, \"learn_time_ms\": 46114.837}", "{\"n\": 5063, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.986666666666666, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.0533333333333, \"learn_time_ms\": 46100.132}", "{\"n\": 5064, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.013157894736842, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3474.815789473684, \"learn_time_ms\": 46168.234}", "{\"n\": 5065, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.064935064935066, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3466.948051948052, \"learn_time_ms\": 46104.758}", "{\"n\": 5066, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.025316455696203, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3475.6075949367087, \"learn_time_ms\": 45980.456}", "{\"n\": 5067, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.975308641975309, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3478.061728395062, \"learn_time_ms\": 46006.661}", "{\"n\": 5068, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.012048192771084, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3474.9156626506024, \"learn_time_ms\": 45921.866}", "{\"n\": 5069, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.928571428571429, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3486.1071428571427, \"learn_time_ms\": 45848.7}", "{\"n\": 5070, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.929411764705883, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3485.0823529411764, \"learn_time_ms\": 45834.804}", "{\"n\": 5071, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.929411764705883, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3485.0823529411764, \"learn_time_ms\": 45852.708}", "{\"n\": 5072, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.920454545454545, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3492.0, \"learn_time_ms\": 45882.293}", "{\"n\": 5073, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.910112359550562, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.1011235955057, \"learn_time_ms\": 45899.248}", "{\"n\": 5074, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88888888888889, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3495.733333333333, \"learn_time_ms\": 45891.903}", "{\"n\": 5075, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91304347826087, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.282608695652, \"learn_time_ms\": 45918.275}", "{\"n\": 5076, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.872340425531915, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.255319148936, \"learn_time_ms\": 45988.197}", "{\"n\": 5077, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.894736842105264, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.8736842105263, \"learn_time_ms\": 46008.429}", "{\"n\": 5078, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.894736842105264, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.8736842105263, \"learn_time_ms\": 46039.073}", "{\"n\": 5079, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88659793814433, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.865979381443, \"learn_time_ms\": 46187.542}", "{\"n\": 5080, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89795918367347, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.0204081632655, \"learn_time_ms\": 46092.956}", "{\"n\": 5081, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3488.28, \"learn_time_ms\": 46090.283}", "{\"n\": 5082, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3488.02, \"learn_time_ms\": 46027.928}", "{\"n\": 5083, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3477.27, \"learn_time_ms\": 45918.289}", "{\"n\": 5084, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3494.4, \"learn_time_ms\": 45927.11}", "{\"n\": 5085, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.71, \"learn_time_ms\": 45949.058}", "{\"n\": 5086, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3513.25, \"learn_time_ms\": 45928.489}", "{\"n\": 5087, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.24, \"learn_time_ms\": 45916.301}", "{\"n\": 5088, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3515.23, \"learn_time_ms\": 45928.555}", "{\"n\": 5089, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3496.38, \"learn_time_ms\": 45924.773}", "{\"n\": 5090, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3492.57, \"learn_time_ms\": 45940.306}", "{\"n\": 5091, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3474.06, \"learn_time_ms\": 45863.32}", "{\"n\": 5092, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3471.22, \"learn_time_ms\": 45886.799}", "{\"n\": 5093, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.77, \"learn_time_ms\": 45985.446}", "{\"n\": 5094, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.99, \"learn_time_ms\": 45992.343}", "{\"n\": 5095, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.99, \"learn_time_ms\": 46010.273}", "{\"n\": 5096, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.67, \"learn_time_ms\": 46107.483}", "{\"n\": 5097, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3466.85, \"learn_time_ms\": 46033.929}", "{\"n\": 5098, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3461.87, \"learn_time_ms\": 46061.391}", "{\"n\": 5099, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.2, \"learn_time_ms\": 46032.002}", "{\"n\": 5100, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3443.2, \"learn_time_ms\": 46118.793}", "{\"n\": 5101, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.71, \"learn_time_ms\": 46083.211}", "{\"n\": 5102, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.71, \"learn_time_ms\": 46092.331}", "{\"n\": 5103, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.23, \"learn_time_ms\": 46065.258}", "{\"n\": 5104, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3423.6, \"learn_time_ms\": 46014.108}", "{\"n\": 5105, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.69, \"learn_time_ms\": 46072.01}", "{\"n\": 5106, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.69, \"learn_time_ms\": 45949.708}", "{\"n\": 5107, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.69, \"learn_time_ms\": 46060.198}", "{\"n\": 5108, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3399.87, \"learn_time_ms\": 46051.535}", "{\"n\": 5109, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.61, \"learn_time_ms\": 46075.204}", "{\"n\": 5110, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3413.17, \"learn_time_ms\": 46038.409}", "{\"n\": 5111, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3413.17, \"learn_time_ms\": 46163.293}", "{\"n\": 5112, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3413.17, \"learn_time_ms\": 46215.926}", "{\"n\": 5113, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3431.13, \"learn_time_ms\": 46225.252}", "{\"n\": 5114, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3426.32, \"learn_time_ms\": 46227.824}", "{\"n\": 5115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3417.46, \"learn_time_ms\": 46129.371}", "{\"n\": 5116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3405.27, \"learn_time_ms\": 46214.475}", "{\"n\": 5117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3417.73, \"learn_time_ms\": 46251.926}", "{\"n\": 5118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.11, \"learn_time_ms\": 46193.712}", "{\"n\": 5119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3417.62, \"learn_time_ms\": 46111.814}", "{\"n\": 5120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3417.62, \"learn_time_ms\": 46124.236}", "{\"n\": 5121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3419.75, \"learn_time_ms\": 46091.041}", "{\"n\": 5122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3419.75, \"learn_time_ms\": 46050.872}", "{\"n\": 5123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3414.74, \"learn_time_ms\": 46070.06}", "{\"n\": 5124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3410.06, \"learn_time_ms\": 46167.508}", "{\"n\": 5125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3419.77, \"learn_time_ms\": 46219.226}", "{\"n\": 5126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3413.83, \"learn_time_ms\": 46248.664}", "{\"n\": 5127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3402.54, \"learn_time_ms\": 46168.785}", "{\"n\": 5128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3389.42, \"learn_time_ms\": 46289.219}", "{\"n\": 5129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3389.42, \"learn_time_ms\": 46342.898}", "{\"n\": 5130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3397.49, \"learn_time_ms\": 46372.345}", "{\"n\": 5131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3389.17, \"learn_time_ms\": 46414.625}", "{\"n\": 5132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3385.46, \"learn_time_ms\": 46308.638}", "{\"n\": 5133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3382.85, \"learn_time_ms\": 46319.006}", "{\"n\": 5134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3382.85, \"learn_time_ms\": 46139.103}", "{\"n\": 5135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.36, \"learn_time_ms\": 46108.322}", "{\"n\": 5136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3374.78, \"learn_time_ms\": 45986.73}", "{\"n\": 5137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3377.02, \"learn_time_ms\": 45952.475}", "{\"n\": 5138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3366.62, \"learn_time_ms\": 45852.826}", "{\"n\": 5139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3342.5, \"learn_time_ms\": 45823.865}", "{\"n\": 5140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3339.93, \"learn_time_ms\": 45789.983}", "{\"n\": 5141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3336.57, \"learn_time_ms\": 45806.202}", "{\"n\": 5142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.85, \"learn_time_ms\": 46033.185}", "{\"n\": 5143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.85, \"learn_time_ms\": 46035.914}", "{\"n\": 5144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3325.38, \"learn_time_ms\": 46027.123}", "{\"n\": 5145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.26, \"learn_time_ms\": 46005.557}", "{\"n\": 5146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3324.26, \"learn_time_ms\": 46054.414}", "{\"n\": 5147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3329.04, \"learn_time_ms\": 46157.941}", "{\"n\": 5148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.93, \"learn_time_ms\": 46099.575}", "{\"n\": 5149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.33, \"learn_time_ms\": 46174.823}", "{\"n\": 5150, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.23, \"learn_time_ms\": 46103.311}", "{\"n\": 5151, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.88, \"learn_time_ms\": 46022.77}", "{\"n\": 5152, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.05, \"learn_time_ms\": 46010.986}", "{\"n\": 5153, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3302.47, \"learn_time_ms\": 45949.572}", "{\"n\": 5154, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3299.49, \"learn_time_ms\": 46098.847}", "{\"n\": 5155, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.27, \"learn_time_ms\": 46121.632}", "{\"n\": 5156, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.27, \"learn_time_ms\": 46114.993}", "{\"n\": 5157, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.26, \"learn_time_ms\": 46096.933}", "{\"n\": 5158, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3314.3, \"learn_time_ms\": 46215.348}", "{\"n\": 5159, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3314.3, \"learn_time_ms\": 46222.794}", "{\"n\": 5160, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3318.5, \"learn_time_ms\": 46385.96}", "{\"n\": 5161, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3346.11, \"learn_time_ms\": 46373.441}", "{\"n\": 5162, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3338.2, \"learn_time_ms\": 46236.611}", "{\"n\": 5163, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3338.2, \"learn_time_ms\": 46171.263}", "{\"n\": 5164, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3338.2, \"learn_time_ms\": 46043.427}", "{\"n\": 5165, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3351.73, \"learn_time_ms\": 46053.786}", "{\"n\": 5166, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3370.94, \"learn_time_ms\": 46054.472}", "{\"n\": 5167, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3366.74, \"learn_time_ms\": 45949.552}", "{\"n\": 5168, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3370.69, \"learn_time_ms\": 45967.059}", "{\"n\": 5169, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3377.38, \"learn_time_ms\": 45986.818}", "{\"n\": 5170, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3389.82, \"learn_time_ms\": 45942.213}", "{\"n\": 5171, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3389.82, \"learn_time_ms\": 46018.004}", "{\"n\": 5172, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3389.7, \"learn_time_ms\": 46064.546}", "{\"n\": 5173, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3378.66, \"learn_time_ms\": 46250.904}", "{\"n\": 5174, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3366.64, \"learn_time_ms\": 46372.641}", "{\"n\": 5175, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3372.97, \"learn_time_ms\": 46285.226}", "{\"n\": 5176, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3384.1, \"learn_time_ms\": 46274.034}", "{\"n\": 5177, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3384.1, \"learn_time_ms\": 46244.678}", "{\"n\": 5178, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3394.47, \"learn_time_ms\": 46169.567}", "{\"n\": 5179, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3416.08, \"learn_time_ms\": 46059.39}", "{\"n\": 5180, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3416.08, \"learn_time_ms\": 45917.606}", "{\"n\": 5181, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3429.65, \"learn_time_ms\": 45864.156}", "{\"n\": 5182, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3429.65, \"learn_time_ms\": 45917.422}", "{\"n\": 5183, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3428.96, \"learn_time_ms\": 45870.834}", "{\"n\": 5184, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3426.3, \"learn_time_ms\": 45772.715}", "{\"n\": 5185, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3432.81, \"learn_time_ms\": 45840.482}", "{\"n\": 5186, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3439.04, \"learn_time_ms\": 45783.42}", "{\"n\": 5187, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3439.04, \"learn_time_ms\": 45941.456}", "{\"n\": 5188, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3444.71, \"learn_time_ms\": 45949.817}", "{\"n\": 5189, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3444.71, \"learn_time_ms\": 45860.692}", "{\"n\": 5190, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3444.35, \"learn_time_ms\": 45966.303}", "{\"n\": 5191, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3457.24, \"learn_time_ms\": 46027.555}", "{\"n\": 5192, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3455.68, \"learn_time_ms\": 45958.727}", "{\"n\": 5193, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3438.11, \"learn_time_ms\": 45880.542}", "{\"n\": 5194, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3438.11, \"learn_time_ms\": 45904.468}", "{\"n\": 5195, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3456.44, \"learn_time_ms\": 45938.844}", "{\"n\": 5196, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3462.22, \"learn_time_ms\": 46020.587}", "{\"n\": 5197, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3462.22, \"learn_time_ms\": 45944.332}", "{\"n\": 5198, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3449.47, \"learn_time_ms\": 45960.548}", "{\"n\": 5199, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3449.47, \"learn_time_ms\": 46118.889}", "{\"n\": 5200, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3443.14, \"learn_time_ms\": 46078.69}", "{\"n\": 5201, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3436.77, \"learn_time_ms\": 46007.729}", "{\"n\": 5202, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3451.36, \"learn_time_ms\": 45956.678}", "{\"n\": 5203, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3460.25, \"learn_time_ms\": 45998.358}", "{\"n\": 5204, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3452.64, \"learn_time_ms\": 45983.779}", "{\"n\": 5205, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3453.75, \"learn_time_ms\": 45947.725}", "{\"n\": 5206, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3467.73, \"learn_time_ms\": 45947.759}", "{\"n\": 5207, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3464.37, \"learn_time_ms\": 45952.46}", "{\"n\": 5208, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3470.72, \"learn_time_ms\": 45963.264}", "{\"n\": 5209, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3482.11, \"learn_time_ms\": 45955.764}", "{\"n\": 5210, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3500.79, \"learn_time_ms\": 45880.266}", "{\"n\": 5211, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3500.79, \"learn_time_ms\": 45925.993}", "{\"n\": 5212, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3508.56, \"learn_time_ms\": 46049.809}", "{\"n\": 5213, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.09, \"learn_time_ms\": 46060.475}", "{\"n\": 5214, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.88, \"learn_time_ms\": 46148.092}", "{\"n\": 5215, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.88, \"learn_time_ms\": 46164.085}", "{\"n\": 5216, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.5, \"learn_time_ms\": 46091.188}", "{\"n\": 5217, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3512.27, \"learn_time_ms\": 46076.067}", "{\"n\": 5218, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3534.2, \"learn_time_ms\": 46049.899}", "{\"n\": 5219, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3533.14, \"learn_time_ms\": 46037.545}", "{\"n\": 5220, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3533.14, \"learn_time_ms\": 46151.851}", "{\"n\": 5221, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3540.0, \"learn_time_ms\": 46211.727}", "{\"n\": 5222, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3540.0, \"learn_time_ms\": 46242.794}", "{\"n\": 5223, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3553.5, \"learn_time_ms\": 46211.546}", "{\"n\": 5224, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3558.53, \"learn_time_ms\": 46187.367}", "{\"n\": 5225, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3564.12, \"learn_time_ms\": 46219.6}", "{\"n\": 5226, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3548.5, \"learn_time_ms\": 46277.135}", "{\"n\": 5227, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3548.5, \"learn_time_ms\": 46321.98}", "{\"n\": 5228, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3547.88, \"learn_time_ms\": 46299.095}", "{\"n\": 5229, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3534.39, \"learn_time_ms\": 46339.206}", "{\"n\": 5230, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3534.39, \"learn_time_ms\": 46271.194}", "{\"n\": 5231, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3523.56, \"learn_time_ms\": 46245.581}", "{\"n\": 5232, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3507.63, \"learn_time_ms\": 46142.071}", "{\"n\": 5233, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3509.13, \"learn_time_ms\": 46161.408}", "{\"n\": 5234, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3504.75, \"learn_time_ms\": 46149.678}", "{\"n\": 5235, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3500.81, \"learn_time_ms\": 46082.121}", "{\"n\": 5236, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3516.57, \"learn_time_ms\": 46052.495}", "{\"n\": 5237, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3514.44, \"learn_time_ms\": 45991.627}", "{\"n\": 5238, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3504.43, \"learn_time_ms\": 45983.727}", "{\"n\": 5239, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3474.46, \"learn_time_ms\": 45885.758}", "{\"n\": 5240, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3461.81, \"learn_time_ms\": 45929.661}", "{\"n\": 5241, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3461.81, \"learn_time_ms\": 45860.728}", "{\"n\": 5242, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3470.76, \"learn_time_ms\": 45818.035}", "{\"n\": 5243, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3492.89, \"learn_time_ms\": 45803.822}", "{\"n\": 5244, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3492.89, \"learn_time_ms\": 45851.739}", "{\"n\": 5245, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3500.88, \"learn_time_ms\": 45892.23}", "{\"n\": 5246, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3497.48, \"learn_time_ms\": 45931.816}", "{\"n\": 5247, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.52, \"learn_time_ms\": 45974.342}", "{\"n\": 5248, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.52, \"learn_time_ms\": 46082.453}", "{\"n\": 5249, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.96, \"learn_time_ms\": 46149.321}", "{\"n\": 5250, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3451.63, \"learn_time_ms\": 46092.009}", "{\"n\": 5251, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.55, \"learn_time_ms\": 46164.366}", "{\"n\": 5252, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.55, \"learn_time_ms\": 46137.127}", "{\"n\": 5253, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.72, \"learn_time_ms\": 46119.794}", "{\"n\": 5254, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3431.37, \"learn_time_ms\": 46059.43}", "{\"n\": 5255, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3431.37, \"learn_time_ms\": 46120.916}", "{\"n\": 5256, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3424.5, \"learn_time_ms\": 46143.335}", "{\"n\": 5257, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.42, \"learn_time_ms\": 46014.388}", "{\"n\": 5258, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3438.67, \"learn_time_ms\": 45916.8}", "{\"n\": 5259, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3445.54, \"learn_time_ms\": 45823.814}", "{\"n\": 5260, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.59, \"learn_time_ms\": 45843.832}", "{\"n\": 5261, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3460.29, \"learn_time_ms\": 45876.759}", "{\"n\": 5262, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3474.33, \"learn_time_ms\": 46022.053}", "{\"n\": 5263, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3474.33, \"learn_time_ms\": 46111.499}", "{\"n\": 5264, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.95, \"learn_time_ms\": 46123.404}", "{\"n\": 5265, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3492.24, \"learn_time_ms\": 46169.142}", "{\"n\": 5266, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.85, \"learn_time_ms\": 46124.896}", "{\"n\": 5267, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.85, \"learn_time_ms\": 46279.071}", "{\"n\": 5268, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3501.75, \"learn_time_ms\": 46255.975}", "{\"n\": 5269, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3518.02, \"learn_time_ms\": 46358.52}", "{\"n\": 5270, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.27, \"learn_time_ms\": 46407.962}", "{\"n\": 5271, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3509.75, \"learn_time_ms\": 46373.294}", "{\"n\": 5272, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.52, \"learn_time_ms\": 46304.368}", "{\"n\": 5273, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.52, \"learn_time_ms\": 46270.254}", "{\"n\": 5274, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3512.06, \"learn_time_ms\": 46216.656}", "{\"n\": 5275, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3499.35, \"learn_time_ms\": 46113.356}", "{\"n\": 5276, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3508.89, \"learn_time_ms\": 46156.774}", "{\"n\": 5277, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3508.93, \"learn_time_ms\": 46078.6}", "{\"n\": 5278, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3508.84, \"learn_time_ms\": 46078.049}", "{\"n\": 5279, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3510.23, \"learn_time_ms\": 46095.137}", "{\"n\": 5280, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3509.02, \"learn_time_ms\": 46113.966}", "{\"n\": 5281, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3508.11, \"learn_time_ms\": 46102.9}", "{\"n\": 5282, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3509.36, \"learn_time_ms\": 46088.493}", "{\"n\": 5283, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3497.59, \"learn_time_ms\": 46037.449}", "{\"n\": 5284, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3497.59, \"learn_time_ms\": 46077.294}", "{\"n\": 5285, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3497.33, \"learn_time_ms\": 46109.808}", "{\"n\": 5286, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3505.22, \"learn_time_ms\": 46050.484}", "{\"n\": 5287, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.44, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3474.06, \"learn_time_ms\": 46148.229}", "{\"n\": 5288, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3468.08, \"learn_time_ms\": 46197.804}", "{\"n\": 5289, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3480.42, \"learn_time_ms\": 46078.119}", "{\"n\": 5290, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3491.67, \"learn_time_ms\": 46078.366}", "{\"n\": 5291, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3490.39, \"learn_time_ms\": 46159.037}", "{\"n\": 5292, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3516.18, \"learn_time_ms\": 46233.415}", "{\"n\": 5293, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3516.18, \"learn_time_ms\": 46259.884}", "{\"n\": 5294, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3497.26, \"learn_time_ms\": 46229.455}", "{\"n\": 5295, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3510.39, \"learn_time_ms\": 46168.334}", "{\"n\": 5296, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3510.39, \"learn_time_ms\": 46094.856}", "{\"n\": 5297, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3510.39, \"learn_time_ms\": 46091.668}", "{\"n\": 5298, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3502.45, \"learn_time_ms\": 46048.599}", "{\"n\": 5299, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3502.45, \"learn_time_ms\": 46141.907}", "{\"n\": 5300, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3510.88, \"learn_time_ms\": 46019.969}", "{\"n\": 5301, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3536.39, \"learn_time_ms\": 45908.347}", "{\"n\": 5302, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3545.33, \"learn_time_ms\": 45864.857}", "{\"n\": 5303, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3564.23, \"learn_time_ms\": 45930.724}", "{\"n\": 5304, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3564.64, \"learn_time_ms\": 45968.78}", "{\"n\": 5305, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3564.64, \"learn_time_ms\": 45987.149}", "{\"n\": 5306, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3577.24, \"learn_time_ms\": 46037.477}", "{\"n\": 5307, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3597.63, \"learn_time_ms\": 45971.822}", "{\"n\": 5308, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3568.7, \"learn_time_ms\": 45952.951}", "{\"n\": 5309, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3568.7, \"learn_time_ms\": 45962.36}", "{\"n\": 5310, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3568.7, \"learn_time_ms\": 46049.831}", "{\"n\": 5311, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3574.8, \"learn_time_ms\": 46070.488}", "{\"n\": 5312, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3588.28, \"learn_time_ms\": 46067.253}", "{\"n\": 5313, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3588.26, \"learn_time_ms\": 46000.142}", "{\"n\": 5314, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3601.72, \"learn_time_ms\": 45941.139}", "{\"n\": 5315, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3601.72, \"learn_time_ms\": 46047.231}", "{\"n\": 5316, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3596.38, \"learn_time_ms\": 46085.478}", "{\"n\": 5317, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3585.93, \"learn_time_ms\": 46021.635}", "{\"n\": 5318, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3585.93, \"learn_time_ms\": 46110.086}", "{\"n\": 5319, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3546.41, \"learn_time_ms\": 46073.556}", "{\"n\": 5320, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3546.41, \"learn_time_ms\": 46084.426}", "{\"n\": 5321, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3557.79, \"learn_time_ms\": 46096.715}", "{\"n\": 5322, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3593.39, \"learn_time_ms\": 46092.19}", "{\"n\": 5323, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3593.39, \"learn_time_ms\": 46102.698}", "{\"n\": 5324, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3599.85, \"learn_time_ms\": 46171.081}", "{\"n\": 5325, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3608.07, \"learn_time_ms\": 46024.069}", "{\"n\": 5326, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3635.92, \"learn_time_ms\": 46141.716}", "{\"n\": 5327, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3630.5, \"learn_time_ms\": 46167.474}", "{\"n\": 5328, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3630.5, \"learn_time_ms\": 46153.505}", "{\"n\": 5329, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3637.94, \"learn_time_ms\": 46133.313}", "{\"n\": 5330, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3612.25, \"learn_time_ms\": 46170.517}", "{\"n\": 5331, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3612.45, \"learn_time_ms\": 46175.841}", "{\"n\": 5332, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3599.91, \"learn_time_ms\": 46130.251}", "{\"n\": 5333, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3599.91, \"learn_time_ms\": 46104.973}", "{\"n\": 5334, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3594.33, \"learn_time_ms\": 46101.095}", "{\"n\": 5335, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3558.74, \"learn_time_ms\": 46154.536}", "{\"n\": 5336, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3567.87, \"learn_time_ms\": 46034.632}", "{\"n\": 5337, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3576.74, \"learn_time_ms\": 46120.135}", "{\"n\": 5338, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3569.74, \"learn_time_ms\": 46061.984}", "{\"n\": 5339, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3569.74, \"learn_time_ms\": 46157.222}", "{\"n\": 5340, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3569.74, \"learn_time_ms\": 46123.575}", "{\"n\": 5341, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3549.33, \"learn_time_ms\": 46042.617}", "{\"n\": 5342, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3549.33, \"learn_time_ms\": 46118.111}", "{\"n\": 5343, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3512.74, \"learn_time_ms\": 46160.927}", "{\"n\": 5344, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3526.8, \"learn_time_ms\": 46196.13}", "{\"n\": 5345, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3526.8, \"learn_time_ms\": 46117.993}", "{\"n\": 5346, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3522.46, \"learn_time_ms\": 46099.044}", "{\"n\": 5347, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3546.39, \"learn_time_ms\": 46036.832}", "{\"n\": 5348, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3557.32, \"learn_time_ms\": 46046.43}", "{\"n\": 5349, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3551.13, \"learn_time_ms\": 45874.162}", "{\"n\": 5350, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3556.96, \"learn_time_ms\": 45907.88}", "{\"n\": 5351, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3552.83, \"learn_time_ms\": 45960.377}", "{\"n\": 5352, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3542.33, \"learn_time_ms\": 45917.141}", "{\"n\": 5353, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3531.07, \"learn_time_ms\": 45915.669}", "{\"n\": 5354, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3532.11, \"learn_time_ms\": 45896.894}", "{\"n\": 5355, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3524.22, \"learn_time_ms\": 45935.301}", "{\"n\": 5356, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3523.31, \"learn_time_ms\": 45997.899}", "{\"n\": 5357, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3516.69, \"learn_time_ms\": 46012.727}", "{\"n\": 5358, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3505.91, \"learn_time_ms\": 46121.461}", "{\"n\": 5359, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3521.46, \"learn_time_ms\": 46189.829}", "{\"n\": 5360, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3536.69, \"learn_time_ms\": 46186.451}", "{\"n\": 5361, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3558.32, \"learn_time_ms\": 46205.686}", "{\"n\": 5362, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3558.32, \"learn_time_ms\": 46278.653}", "{\"n\": 5363, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3558.32, \"learn_time_ms\": 46167.441}", "{\"n\": 5364, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3517.83, \"learn_time_ms\": 46186.475}", "{\"n\": 5365, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3500.78, \"learn_time_ms\": 46160.336}", "{\"n\": 5366, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3493.64, \"learn_time_ms\": 46162.688}", "{\"n\": 5367, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3493.64, \"learn_time_ms\": 46117.562}", "{\"n\": 5368, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3479.76, \"learn_time_ms\": 46035.127}", "{\"n\": 5369, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3480.71, \"learn_time_ms\": 46084.51}", "{\"n\": 5370, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3497.43, \"learn_time_ms\": 45999.365}", "{\"n\": 5371, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3498.98, \"learn_time_ms\": 45982.841}", "{\"n\": 5372, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.51, \"learn_time_ms\": 45932.572}", "{\"n\": 5373, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3494.62, \"learn_time_ms\": 45887.6}", "{\"n\": 5374, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3477.21, \"learn_time_ms\": 45883.008}", "{\"n\": 5375, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3477.21, \"learn_time_ms\": 45976.96}", "{\"n\": 5376, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3467.66, \"learn_time_ms\": 45828.785}", "{\"n\": 5377, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3474.74, \"learn_time_ms\": 45910.245}", "{\"n\": 5378, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3466.21, \"learn_time_ms\": 45810.088}", "{\"n\": 5379, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3466.21, \"learn_time_ms\": 45772.25}", "{\"n\": 5380, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3474.3, \"learn_time_ms\": 45747.052}", "{\"n\": 5381, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3470.92, \"learn_time_ms\": 45803.184}", "{\"n\": 5382, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3470.92, \"learn_time_ms\": 45816.71}", "{\"n\": 5383, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3454.09, \"learn_time_ms\": 45979.357}", "{\"n\": 5384, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3455.86, \"learn_time_ms\": 45917.209}", "{\"n\": 5385, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3458.48, \"learn_time_ms\": 45898.349}", "{\"n\": 5386, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3467.9, \"learn_time_ms\": 45986.943}", "{\"n\": 5387, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3467.9, \"learn_time_ms\": 45982.862}", "{\"n\": 5388, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3478.49, \"learn_time_ms\": 46089.653}", "{\"n\": 5389, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3478.49, \"learn_time_ms\": 46062.867}", "{\"n\": 5390, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3508.45, \"learn_time_ms\": 46130.057}", "{\"n\": 5391, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3503.72, \"learn_time_ms\": 46114.266}", "{\"n\": 5392, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3504.32, \"learn_time_ms\": 46030.447}", "{\"n\": 5393, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3486.23, \"learn_time_ms\": 45988.368}", "{\"n\": 5394, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3486.23, \"learn_time_ms\": 46004.155}", "{\"n\": 5395, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3486.23, \"learn_time_ms\": 45998.686}", "{\"n\": 5396, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3477.7, \"learn_time_ms\": 46001.85}", "{\"n\": 5397, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3459.63, \"learn_time_ms\": 46000.56}", "{\"n\": 5398, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3459.63, \"learn_time_ms\": 46035.735}", "{\"n\": 5399, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3418.79, \"learn_time_ms\": 46083.206}", "{\"n\": 5400, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.6, \"learn_time_ms\": 46117.579}", "{\"n\": 5401, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3441.47, \"learn_time_ms\": 46052.591}", "{\"n\": 5402, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3449.28, \"learn_time_ms\": 46065.944}", "{\"n\": 5403, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3444.32, \"learn_time_ms\": 46029.138}", "{\"n\": 5404, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3444.66, \"learn_time_ms\": 46011.052}", "{\"n\": 5405, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3449.77, \"learn_time_ms\": 45970.052}", "{\"n\": 5406, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3442.64, \"learn_time_ms\": 46006.717}", "{\"n\": 5407, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3442.64, \"learn_time_ms\": 46054.124}", "{\"n\": 5408, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3451.15, \"learn_time_ms\": 45991.955}", "{\"n\": 5409, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3437.02, \"learn_time_ms\": 45993.501}", "{\"n\": 5410, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.65, \"learn_time_ms\": 45955.694}", "{\"n\": 5411, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3431.4, \"learn_time_ms\": 46001.864}", "{\"n\": 5412, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3422.96, \"learn_time_ms\": 45996.161}", "{\"n\": 5413, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3439.74, \"learn_time_ms\": 46097.79}", "{\"n\": 5414, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3451.12, \"learn_time_ms\": 46162.235}", "{\"n\": 5415, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3451.61, \"learn_time_ms\": 46208.333}", "{\"n\": 5416, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3461.96, \"learn_time_ms\": 46153.151}", "{\"n\": 5417, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3461.96, \"learn_time_ms\": 46058.081}", "{\"n\": 5418, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3433.58, \"learn_time_ms\": 46125.293}", "{\"n\": 5419, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.76, \"learn_time_ms\": 46095.199}", "{\"n\": 5420, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3417.33, \"learn_time_ms\": 46129.199}", "{\"n\": 5421, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3411.35, \"learn_time_ms\": 46184.139}", "{\"n\": 5422, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3416.78, \"learn_time_ms\": 46247.023}", "{\"n\": 5423, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3429.04, \"learn_time_ms\": 46127.485}", "{\"n\": 5424, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.42, \"learn_time_ms\": 46092.451}", "{\"n\": 5425, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.42, \"learn_time_ms\": 46111.963}", "{\"n\": 5426, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.07, \"learn_time_ms\": 46145.773}", "{\"n\": 5427, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3436.67, \"learn_time_ms\": 46139.554}", "{\"n\": 5428, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3443.73, \"learn_time_ms\": 46124.911}", "{\"n\": 5429, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3439.6, \"learn_time_ms\": 46101.03}", "{\"n\": 5430, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3433.18, \"learn_time_ms\": 46109.354}", "{\"n\": 5431, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3413.89, \"learn_time_ms\": 46057.186}", "{\"n\": 5432, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3413.89, \"learn_time_ms\": 46118.594}", "{\"n\": 5433, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3392.42, \"learn_time_ms\": 46284.022}", "{\"n\": 5434, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3421.43, \"learn_time_ms\": 46318.237}", "{\"n\": 5435, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3416.35, \"learn_time_ms\": 46193.635}", "{\"n\": 5436, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3421.39, \"learn_time_ms\": 46163.347}", "{\"n\": 5437, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3415.5, \"learn_time_ms\": 46139.858}", "{\"n\": 5438, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3412.22, \"learn_time_ms\": 46100.112}", "{\"n\": 5439, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3410.85, \"learn_time_ms\": 46109.577}", "{\"n\": 5440, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3392.62, \"learn_time_ms\": 46043.43}", "{\"n\": 5441, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3393.8, \"learn_time_ms\": 45986.965}", "{\"n\": 5442, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.45, \"learn_time_ms\": 45930.566}", "{\"n\": 5443, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.19, \"learn_time_ms\": 45815.719}", "{\"n\": 5444, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.19, \"learn_time_ms\": 45809.903}", "{\"n\": 5445, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.19, \"learn_time_ms\": 45829.268}", "{\"n\": 5446, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.74, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3387.15, \"learn_time_ms\": 45855.257}", "{\"n\": 5447, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3384.4, \"learn_time_ms\": 45828.697}", "{\"n\": 5448, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3371.95, \"learn_time_ms\": 45808.409}", "{\"n\": 5449, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3351.0, \"learn_time_ms\": 45821.19}", "{\"n\": 5450, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.98, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3348.4, \"learn_time_ms\": 45796.246}", "{\"n\": 5451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3346.44, \"learn_time_ms\": 45794.054}", "{\"n\": 5452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.94, \"learn_time_ms\": 45760.425}", "{\"n\": 5453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.94, \"learn_time_ms\": 45699.468}", "{\"n\": 5454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3362.24, \"learn_time_ms\": 45730.92}", "{\"n\": 5455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3357.25, \"learn_time_ms\": 45809.876}", "{\"n\": 5456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3350.01, \"learn_time_ms\": 45750.445}", "{\"n\": 5457, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3340.29, \"learn_time_ms\": 45846.215}", "{\"n\": 5458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3337.02, \"learn_time_ms\": 45809.07}", "{\"n\": 5459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.26, \"learn_time_ms\": 45839.808}", "{\"n\": 5460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3330.26, \"learn_time_ms\": 45832.435}", "{\"n\": 5461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3314.38, \"learn_time_ms\": 45873.277}", "{\"n\": 5462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3310.95, \"learn_time_ms\": 45929.839}", "{\"n\": 5463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.0, \"learn_time_ms\": 46019.366}", "{\"n\": 5464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.47, \"learn_time_ms\": 45960.808}", "{\"n\": 5465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3326.47, \"learn_time_ms\": 45937.764}", "{\"n\": 5466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3312.54, \"learn_time_ms\": 45998.802}", "{\"n\": 5467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3311.3, \"learn_time_ms\": 46034.199}", "{\"n\": 5468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.69, \"learn_time_ms\": 46093.622}", "{\"n\": 5469, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.2, \"learn_time_ms\": 46018.762}", "{\"n\": 5470, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3318.2, \"learn_time_ms\": 46175.163}", "{\"n\": 5471, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3322.18, \"learn_time_ms\": 46153.903}", "{\"n\": 5472, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.47, \"learn_time_ms\": 46206.343}", "{\"n\": 5473, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3317.47, \"learn_time_ms\": 46205.774}", "{\"n\": 5474, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.88, \"learn_time_ms\": 46279.374}", "{\"n\": 5475, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3319.88, \"learn_time_ms\": 46366.861}", "{\"n\": 5476, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.17, \"learn_time_ms\": 46312.285}", "{\"n\": 5477, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.17, \"learn_time_ms\": 46267.234}", "{\"n\": 5478, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3296.07, \"learn_time_ms\": 46276.845}", "{\"n\": 5479, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.73, \"learn_time_ms\": 46412.611}", "{\"n\": 5480, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.73, \"learn_time_ms\": 46258.975}", "{\"n\": 5481, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.79, \"learn_time_ms\": 46302.207}", "{\"n\": 5482, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3297.41, \"learn_time_ms\": 46252.644}", "{\"n\": 5483, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3289.72, \"learn_time_ms\": 46222.025}", "{\"n\": 5484, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.35, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.88, \"learn_time_ms\": 46137.413}", "{\"n\": 5485, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3274.11, \"learn_time_ms\": 46145.925}", "{\"n\": 5486, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.45, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.68, \"learn_time_ms\": 46209.087}", "{\"n\": 5487, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.42, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3279.24, \"learn_time_ms\": 46246.475}", "{\"n\": 5488, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.43, \"learn_time_ms\": 46264.63}", "{\"n\": 5489, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.43, \"learn_time_ms\": 46155.237}", "{\"n\": 5490, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.43, \"learn_time_ms\": 46256.78}", "{\"n\": 5491, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.79, \"learn_time_ms\": 46251.483}", "{\"n\": 5492, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3288.58, \"learn_time_ms\": 46120.031}", "{\"n\": 5493, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3294.49, \"learn_time_ms\": 46192.088}", "{\"n\": 5494, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.29, \"learn_time_ms\": 46239.744}", "{\"n\": 5495, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3270.44, \"learn_time_ms\": 46156.62}", "{\"n\": 5496, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3272.83, \"learn_time_ms\": 46194.483}", "{\"n\": 5497, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3276.15, \"learn_time_ms\": 46087.949}", "{\"n\": 5498, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.94, \"learn_time_ms\": 46144.936}", "{\"n\": 5499, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.93, \"learn_time_ms\": 46194.148}", "{\"n\": 5500, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3292.63, \"learn_time_ms\": 46143.493}", "{\"n\": 5501, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3308.18, \"learn_time_ms\": 46129.577}", "{\"n\": 5502, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3285.66, \"learn_time_ms\": 46246.017}", "{\"n\": 5503, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3287.68, \"learn_time_ms\": 46134.814}", "{\"n\": 5504, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3282.74, \"learn_time_ms\": 46122.194}", "{\"n\": 5505, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.07, \"learn_time_ms\": 46089.875}", "{\"n\": 5506, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3301.07, \"learn_time_ms\": 46025.528}", "{\"n\": 5507, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3305.11, \"learn_time_ms\": 46078.076}", "{\"n\": 5508, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3321.61, \"learn_time_ms\": 45964.038}", "{\"n\": 5509, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.56, \"learn_time_ms\": 45918.501}", "{\"n\": 5510, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3300.56, \"learn_time_ms\": 45953.276}", "{\"n\": 5511, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3283.73, \"learn_time_ms\": 45854.77}", "{\"n\": 5512, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3278.02, \"learn_time_ms\": 45841.361}", "{\"n\": 5513, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3286.61, \"learn_time_ms\": 45854.172}", "{\"n\": 5514, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3281.99, \"learn_time_ms\": 45779.459}", "{\"n\": 5515, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.34, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3271.81, \"learn_time_ms\": 45850.975}", "{\"n\": 5516, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3291.63, \"learn_time_ms\": 45850.653}", "{\"n\": 5517, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.19, \"learn_time_ms\": 45953.324}", "{\"n\": 5518, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3303.96, \"learn_time_ms\": 45999.102}", "{\"n\": 5519, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.79, \"learn_time_ms\": 46084.051}", "{\"n\": 5520, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3304.82, \"learn_time_ms\": 46032.893}", "{\"n\": 5521, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3295.57, \"learn_time_ms\": 46035.079}", "{\"n\": 5522, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.45, \"learn_time_ms\": 45939.829}", "{\"n\": 5523, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3306.29, \"learn_time_ms\": 45967.615}", "{\"n\": 5524, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3309.33, \"learn_time_ms\": 46034.09}", "{\"n\": 5525, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.69, \"learn_time_ms\": 46060.563}", "{\"n\": 5526, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3308.31, \"learn_time_ms\": 46109.962}", "{\"n\": 5527, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.46, \"learn_time_ms\": 46127.963}", "{\"n\": 5528, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.92, \"learn_time_ms\": 46009.928}", "{\"n\": 5529, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.88, \"learn_time_ms\": 45953.711}", "{\"n\": 5530, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.02, \"learn_time_ms\": 46113.769}", "{\"n\": 5531, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.01, \"learn_time_ms\": 46200.726}", "{\"n\": 5532, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.01, \"learn_time_ms\": 46282.541}", "{\"n\": 5533, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.22, \"learn_time_ms\": 46349.251}", "{\"n\": 5534, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3307.22, \"learn_time_ms\": 46301.383}", "{\"n\": 5535, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3303.38, \"learn_time_ms\": 46186.512}", "{\"n\": 5536, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3320.96, \"learn_time_ms\": 46198.329}", "{\"n\": 5537, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3309.52, \"learn_time_ms\": 46046.419}", "{\"n\": 5538, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3297.43, \"learn_time_ms\": 46152.349}", "{\"n\": 5539, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3289.44, \"learn_time_ms\": 46244.7}", "{\"n\": 5540, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3298.6, \"learn_time_ms\": 46111.24}", "{\"n\": 5541, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3312.87, \"learn_time_ms\": 46159.943}", "{\"n\": 5542, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3323.54, \"learn_time_ms\": 46192.341}", "{\"n\": 5543, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3323.54, \"learn_time_ms\": 46165.193}", "{\"n\": 5544, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3330.86, \"learn_time_ms\": 46247.26}", "{\"n\": 5545, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3338.17, \"learn_time_ms\": 46260.589}", "{\"n\": 5546, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3338.17, \"learn_time_ms\": 46242.707}", "{\"n\": 5547, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3330.76, \"learn_time_ms\": 46238.373}", "{\"n\": 5548, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3337.18, \"learn_time_ms\": 46142.612}", "{\"n\": 5549, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3330.47, \"learn_time_ms\": 46011.647}", "{\"n\": 5550, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3313.99, \"learn_time_ms\": 46058.506}", "{\"n\": 5551, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3331.42, \"learn_time_ms\": 46010.607}", "{\"n\": 5552, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.15, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3324.45, \"learn_time_ms\": 46059.051}", "{\"n\": 5553, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.24, \"learn_time_ms\": 46007.737}", "{\"n\": 5554, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3332.24, \"learn_time_ms\": 45942.488}", "{\"n\": 5555, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3346.99, \"learn_time_ms\": 45967.562}", "{\"n\": 5556, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3357.1, \"learn_time_ms\": 45935.596}", "{\"n\": 5557, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3338.86, \"learn_time_ms\": 45889.438}", "{\"n\": 5558, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3325.49, \"learn_time_ms\": 45943.588}", "{\"n\": 5559, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3325.49, \"learn_time_ms\": 45959.822}", "{\"n\": 5560, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3320.91, \"learn_time_ms\": 45921.599}", "{\"n\": 5561, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3331.3, \"learn_time_ms\": 45855.456}", "{\"n\": 5562, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3337.46, \"learn_time_ms\": 45769.613}", "{\"n\": 5563, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3331.88, \"learn_time_ms\": 45765.304}", "{\"n\": 5564, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3331.88, \"learn_time_ms\": 45824.159}", "{\"n\": 5565, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3337.45, \"learn_time_ms\": 45831.621}", "{\"n\": 5566, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3336.72, \"learn_time_ms\": 45808.405}", "{\"n\": 5567, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3336.72, \"learn_time_ms\": 45951.849}", "{\"n\": 5568, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3334.94, \"learn_time_ms\": 45954.416}", "{\"n\": 5569, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3341.66, \"learn_time_ms\": 45939.351}", "{\"n\": 5570, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.8, \"learn_time_ms\": 45958.269}", "{\"n\": 5571, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.8, \"learn_time_ms\": 46057.325}", "{\"n\": 5572, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.8, \"learn_time_ms\": 46062.891}", "{\"n\": 5573, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3353.8, \"learn_time_ms\": 46135.098}", "{\"n\": 5574, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3363.48, \"learn_time_ms\": 46106.451}", "{\"n\": 5575, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3379.11, \"learn_time_ms\": 46110.539}", "{\"n\": 5576, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3377.3, \"learn_time_ms\": 46158.422}", "{\"n\": 5577, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3394.75, \"learn_time_ms\": 46146.48}", "{\"n\": 5578, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3394.75, \"learn_time_ms\": 46127.494}", "{\"n\": 5579, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.93, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3382.57, \"learn_time_ms\": 46243.101}", "{\"n\": 5580, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3426.78, \"learn_time_ms\": 46231.657}", "{\"n\": 5581, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3426.78, \"learn_time_ms\": 46253.357}", "{\"n\": 5582, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3426.78, \"learn_time_ms\": 46272.906}", "{\"n\": 5583, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3421.87, \"learn_time_ms\": 46205.163}", "{\"n\": 5584, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3404.44, \"learn_time_ms\": 46241.631}", "{\"n\": 5585, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3393.01, \"learn_time_ms\": 46213.839}", "{\"n\": 5586, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.94, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3386.35, \"learn_time_ms\": 46173.39}", "{\"n\": 5587, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3370.3, \"learn_time_ms\": 46118.637}", "{\"n\": 5588, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3369.43, \"learn_time_ms\": 46226.639}", "{\"n\": 5589, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3362.9, \"learn_time_ms\": 46162.872}", "{\"n\": 5590, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3340.0, \"learn_time_ms\": 46218.645}", "{\"n\": 5591, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3340.0, \"learn_time_ms\": 46167.227}", "{\"n\": 5592, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3352.8, \"learn_time_ms\": 46056.245}", "{\"n\": 5593, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3342.9, \"learn_time_ms\": 46095.348}", "{\"n\": 5594, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3345.94, \"learn_time_ms\": 46098.435}", "{\"n\": 5595, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3306.85, \"learn_time_ms\": 46190.916}", "{\"n\": 5596, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3304.55, \"learn_time_ms\": 46168.522}", "{\"n\": 5597, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3313.8, \"learn_time_ms\": 46173.355}", "{\"n\": 5598, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3318.31, \"learn_time_ms\": 46142.899}", "{\"n\": 5599, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3300.66, \"learn_time_ms\": 46030.693}", "{\"n\": 5600, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.31, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3295.36, \"learn_time_ms\": 45898.068}", "{\"n\": 5601, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.62, \"learn_time_ms\": 45920.663}", "{\"n\": 5602, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3317.62, \"learn_time_ms\": 46080.508}", "{\"n\": 5603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.19, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3313.18, \"learn_time_ms\": 46053.689}", "{\"n\": 5604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.18, \"learn_time_ms\": 45973.968}", "{\"n\": 5605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3304.18, \"learn_time_ms\": 45885.083}", "{\"n\": 5606, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.3, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3314.47, \"learn_time_ms\": 45947.074}", "{\"n\": 5607, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3322.79, \"learn_time_ms\": 45883.566}", "{\"n\": 5608, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3336.55, \"learn_time_ms\": 45874.238}", "{\"n\": 5609, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3325.66, \"learn_time_ms\": 45952.957}", "{\"n\": 5610, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3325.66, \"learn_time_ms\": 46006.276}", "{\"n\": 5611, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3325.66, \"learn_time_ms\": 45965.34}", "{\"n\": 5612, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3305.07, \"learn_time_ms\": 45985.567}", "{\"n\": 5613, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.55, \"learn_time_ms\": 45961.039}", "{\"n\": 5614, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.55, \"learn_time_ms\": 46021.823}", "{\"n\": 5615, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.31, \"learn_time_ms\": 46051.042}", "{\"n\": 5616, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3318.98, \"learn_time_ms\": 46015.281}", "{\"n\": 5617, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3354.06, \"learn_time_ms\": 46049.277}", "{\"n\": 5618, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.92, \"learn_time_ms\": 46076.88}", "{\"n\": 5619, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.92, \"learn_time_ms\": 46089.725}", "{\"n\": 5620, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.66, \"learn_time_ms\": 46092.516}", "{\"n\": 5621, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3347.96, \"learn_time_ms\": 46100.735}", "{\"n\": 5622, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.67, \"learn_time_ms\": 45995.126}", "{\"n\": 5623, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.57, \"learn_time_ms\": 45946.283}", "{\"n\": 5624, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.28, \"learn_time_ms\": 45937.929}", "{\"n\": 5625, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.28, \"learn_time_ms\": 45925.003}", "{\"n\": 5626, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3332.28, \"learn_time_ms\": 45886.82}", "{\"n\": 5627, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.76, \"learn_time_ms\": 45939.395}", "{\"n\": 5628, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.88, \"learn_time_ms\": 45895.229}", "{\"n\": 5629, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.88, \"learn_time_ms\": 45970.952}", "{\"n\": 5630, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3317.88, \"learn_time_ms\": 46017.781}", "{\"n\": 5631, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.21, \"learn_time_ms\": 45983.157}", "{\"n\": 5632, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.25, \"learn_time_ms\": 45914.091}", "{\"n\": 5633, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.83, \"learn_time_ms\": 45902.224}", "{\"n\": 5634, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.12, \"learn_time_ms\": 45848.103}", "{\"n\": 5635, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3311.38, \"learn_time_ms\": 45850.364}", "{\"n\": 5636, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.93, \"learn_time_ms\": 45879.763}", "{\"n\": 5637, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.93, \"learn_time_ms\": 45888.942}", "{\"n\": 5638, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.5, \"learn_time_ms\": 45966.403}", "{\"n\": 5639, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3294.25, \"learn_time_ms\": 45828.947}", "{\"n\": 5640, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.63, \"learn_time_ms\": 45806.859}", "{\"n\": 5641, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.63, \"learn_time_ms\": 45731.791}", "{\"n\": 5642, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3287.63, \"learn_time_ms\": 45774.72}", "{\"n\": 5643, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3279.97, \"learn_time_ms\": 45865.13}", "{\"n\": 5644, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3273.93, \"learn_time_ms\": 45807.008}", "{\"n\": 5645, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3281.48, \"learn_time_ms\": 45784.495}", "{\"n\": 5646, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3274.91, \"learn_time_ms\": 45771.482}", "{\"n\": 5647, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.17, \"learn_time_ms\": 45672.968}", "{\"n\": 5648, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3284.6, \"learn_time_ms\": 45653.226}", "{\"n\": 5649, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.21, \"learn_time_ms\": 45674.423}", "{\"n\": 5650, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3291.21, \"learn_time_ms\": 45719.615}", "{\"n\": 5651, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.06, \"learn_time_ms\": 45811.763}", "{\"n\": 5652, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3290.79, \"learn_time_ms\": 45849.009}", "{\"n\": 5653, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.77, \"learn_time_ms\": 45779.011}", "{\"n\": 5654, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3312.77, \"learn_time_ms\": 45965.116}", "{\"n\": 5655, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.15, \"learn_time_ms\": 45963.209}", "{\"n\": 5656, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.95, \"learn_time_ms\": 46050.319}", "{\"n\": 5657, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3366.78, \"learn_time_ms\": 46122.118}", "{\"n\": 5658, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.03, \"learn_time_ms\": 46154.947}", "{\"n\": 5659, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.03, \"learn_time_ms\": 46123.654}", "{\"n\": 5660, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3378.03, \"learn_time_ms\": 46012.121}", "{\"n\": 5661, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.05, \"learn_time_ms\": 45972.922}", "{\"n\": 5662, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.66, \"learn_time_ms\": 46039.922}", "{\"n\": 5663, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.24, \"learn_time_ms\": 46111.716}", "{\"n\": 5664, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.04, \"learn_time_ms\": 46003.923}", "{\"n\": 5665, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.04, \"learn_time_ms\": 45961.394}", "{\"n\": 5666, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.04, \"learn_time_ms\": 45903.543}", "{\"n\": 5667, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.04, \"learn_time_ms\": 45923.45}", "{\"n\": 5668, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3444.47, \"learn_time_ms\": 45783.861}", "{\"n\": 5669, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.02, \"learn_time_ms\": 45831.249}", "{\"n\": 5670, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.02, \"learn_time_ms\": 45878.725}", "{\"n\": 5671, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.02, \"learn_time_ms\": 45879.58}", "{\"n\": 5672, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.02, \"learn_time_ms\": 45760.623}", "{\"n\": 5673, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3471.97, \"learn_time_ms\": 45848.02}", "{\"n\": 5674, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.27, \"learn_time_ms\": 45881.783}", "{\"n\": 5675, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3475.65, \"learn_time_ms\": 45878.647}", "{\"n\": 5676, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3475.65, \"learn_time_ms\": 45966.93}", "{\"n\": 5677, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3475.65, \"learn_time_ms\": 45983.694}", "{\"n\": 5678, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3475.65, \"learn_time_ms\": 45933.681}", "{\"n\": 5679, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3475.13, \"learn_time_ms\": 45973.987}", "{\"n\": 5680, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3464.05, \"learn_time_ms\": 45963.805}", "{\"n\": 5681, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.3, \"learn_time_ms\": 45986.839}", "{\"n\": 5682, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.3, \"learn_time_ms\": 46007.558}", "{\"n\": 5683, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.3, \"learn_time_ms\": 45887.092}", "{\"n\": 5684, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.25, \"learn_time_ms\": 45887.549}", "{\"n\": 5685, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3476.25, \"learn_time_ms\": 46035.949}", "{\"n\": 5686, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3460.04, \"learn_time_ms\": 45922.259}", "{\"n\": 5687, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3469.17, \"learn_time_ms\": 45868.573}", "{\"n\": 5688, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.29, \"learn_time_ms\": 45967.029}", "{\"n\": 5689, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.29, \"learn_time_ms\": 45919.153}", "{\"n\": 5690, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.85, \"learn_time_ms\": 45981.555}", "{\"n\": 5691, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3453.85, \"learn_time_ms\": 45977.637}", "{\"n\": 5692, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3486.69, \"learn_time_ms\": 45994.874}", "{\"n\": 5693, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3494.67, \"learn_time_ms\": 46119.872}", "{\"n\": 5694, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3506.95, \"learn_time_ms\": 46118.851}", "{\"n\": 5695, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3505.34, \"learn_time_ms\": 45965.856}", "{\"n\": 5696, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3505.34, \"learn_time_ms\": 45964.833}", "{\"n\": 5697, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.41, \"learn_time_ms\": 45941.349}", "{\"n\": 5698, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3529.91, \"learn_time_ms\": 45942.966}", "{\"n\": 5699, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3507.37, \"learn_time_ms\": 46046.241}", "{\"n\": 5700, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3523.49, \"learn_time_ms\": 46060.147}", "{\"n\": 5701, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3530.43, \"learn_time_ms\": 46107.138}", "{\"n\": 5702, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3539.97, \"learn_time_ms\": 46213.431}", "{\"n\": 5703, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3539.97, \"learn_time_ms\": 46110.875}", "{\"n\": 5704, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3530.58, \"learn_time_ms\": 46097.791}", "{\"n\": 5705, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3539.73, \"learn_time_ms\": 46223.108}", "{\"n\": 5706, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3539.73, \"learn_time_ms\": 46333.901}", "{\"n\": 5707, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3539.73, \"learn_time_ms\": 46379.175}", "{\"n\": 5708, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3578.36, \"learn_time_ms\": 46341.383}", "{\"n\": 5709, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3577.75, \"learn_time_ms\": 46282.934}", "{\"n\": 5710, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.28, \"learn_time_ms\": 46151.336}", "{\"n\": 5711, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3576.6, \"learn_time_ms\": 46047.394}", "{\"n\": 5712, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3576.6, \"learn_time_ms\": 45909.035}", "{\"n\": 5713, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3579.03, \"learn_time_ms\": 45901.536}", "{\"n\": 5714, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.1, \"learn_time_ms\": 45862.915}", "{\"n\": 5715, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3594.81, \"learn_time_ms\": 45916.576}", "{\"n\": 5716, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3602.61, \"learn_time_ms\": 45877.93}", "{\"n\": 5717, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3606.39, \"learn_time_ms\": 45763.078}", "{\"n\": 5718, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3599.17, \"learn_time_ms\": 45818.962}", "{\"n\": 5719, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.75, \"learn_time_ms\": 45856.641}", "{\"n\": 5720, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3580.25, \"learn_time_ms\": 45946.075}", "{\"n\": 5721, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3582.37, \"learn_time_ms\": 46002.739}", "{\"n\": 5722, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3578.3, \"learn_time_ms\": 46144.245}", "{\"n\": 5723, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.87, \"learn_time_ms\": 46167.558}", "{\"n\": 5724, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.91, \"learn_time_ms\": 46238.56}", "{\"n\": 5725, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3549.44, \"learn_time_ms\": 46182.763}", "{\"n\": 5726, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3549.44, \"learn_time_ms\": 46122.445}", "{\"n\": 5727, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3543.0, \"learn_time_ms\": 46217.616}", "{\"n\": 5728, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3538.36, \"learn_time_ms\": 46230.746}", "{\"n\": 5729, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3521.98, \"learn_time_ms\": 46184.524}", "{\"n\": 5730, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3526.81, \"learn_time_ms\": 46126.366}", "{\"n\": 5731, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.36, \"learn_time_ms\": 46173.714}", "{\"n\": 5732, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.36, \"learn_time_ms\": 46024.108}", "{\"n\": 5733, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.91, \"learn_time_ms\": 45999.038}", "{\"n\": 5734, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3536.35, \"learn_time_ms\": 45844.215}", "{\"n\": 5735, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3536.35, \"learn_time_ms\": 45777.732}", "{\"n\": 5736, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3516.8, \"learn_time_ms\": 45779.484}", "{\"n\": 5737, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3526.39, \"learn_time_ms\": 45746.981}", "{\"n\": 5738, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3526.39, \"learn_time_ms\": 45680.606}", "{\"n\": 5739, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3507.16, \"learn_time_ms\": 45687.465}", "{\"n\": 5740, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3484.61, \"learn_time_ms\": 45675.3}", "{\"n\": 5741, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3493.43, \"learn_time_ms\": 45710.321}", "{\"n\": 5742, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3493.01, \"learn_time_ms\": 45759.888}", "{\"n\": 5743, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3484.53, \"learn_time_ms\": 45706.489}", "{\"n\": 5744, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3484.53, \"learn_time_ms\": 45863.779}", "{\"n\": 5745, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3513.77, \"learn_time_ms\": 45842.709}", "{\"n\": 5746, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3506.66, \"learn_time_ms\": 45886.294}", "{\"n\": 5747, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3491.14, \"learn_time_ms\": 45923.451}", "{\"n\": 5748, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3491.14, \"learn_time_ms\": 45913.193}", "{\"n\": 5749, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3491.98, \"learn_time_ms\": 45891.678}", "{\"n\": 5750, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3486.51, \"learn_time_ms\": 45953.609}", "{\"n\": 5751, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3488.42, \"learn_time_ms\": 45911.93}", "{\"n\": 5752, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3475.38, \"learn_time_ms\": 45903.301}", "{\"n\": 5753, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3470.68, \"learn_time_ms\": 46008.839}", "{\"n\": 5754, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3459.8, \"learn_time_ms\": 46006.839}", "{\"n\": 5755, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3447.39, \"learn_time_ms\": 46138.785}", "{\"n\": 5756, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3447.39, \"learn_time_ms\": 46128.461}", "{\"n\": 5757, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3455.15, \"learn_time_ms\": 46060.935}", "{\"n\": 5758, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3451.45, \"learn_time_ms\": 46053.686}", "{\"n\": 5759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3422.4, \"learn_time_ms\": 46077.918}", "{\"n\": 5760, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3422.4, \"learn_time_ms\": 46034.31}", "{\"n\": 5761, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3425.08, \"learn_time_ms\": 45956.662}", "{\"n\": 5762, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3422.22, \"learn_time_ms\": 46030.845}", "{\"n\": 5763, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3422.22, \"learn_time_ms\": 45962.594}", "{\"n\": 5764, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3413.98, \"learn_time_ms\": 45940.711}", "{\"n\": 5765, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3415.32, \"learn_time_ms\": 45831.807}", "{\"n\": 5766, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3433.44, \"learn_time_ms\": 45909.591}", "{\"n\": 5767, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3421.87, \"learn_time_ms\": 46063.26}", "{\"n\": 5768, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3401.31, \"learn_time_ms\": 46087.806}", "{\"n\": 5769, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3401.31, \"learn_time_ms\": 46067.133}", "{\"n\": 5770, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3417.35, \"learn_time_ms\": 46060.389}", "{\"n\": 5771, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3433.46, \"learn_time_ms\": 46217.566}", "{\"n\": 5772, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3429.2, \"learn_time_ms\": 46154.119}", "{\"n\": 5773, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3427.9, \"learn_time_ms\": 46216.922}", "{\"n\": 5774, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3428.49, \"learn_time_ms\": 46257.112}", "{\"n\": 5775, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3421.36, \"learn_time_ms\": 46316.925}", "{\"n\": 5776, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3380.9, \"learn_time_ms\": 46265.32}", "{\"n\": 5777, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3377.64, \"learn_time_ms\": 46224.197}", "{\"n\": 5778, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3375.2, \"learn_time_ms\": 46297.671}", "{\"n\": 5779, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3368.64, \"learn_time_ms\": 46354.192}", "{\"n\": 5780, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3363.43, \"learn_time_ms\": 46388.984}", "{\"n\": 5781, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3365.71, \"learn_time_ms\": 46282.836}", "{\"n\": 5782, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.97, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3377.42, \"learn_time_ms\": 46340.521}", "{\"n\": 5783, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.88, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3389.84, \"learn_time_ms\": 46398.63}", "{\"n\": 5784, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3382.41, \"learn_time_ms\": 46366.167}", "{\"n\": 5785, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3382.41, \"learn_time_ms\": 46303.226}", "{\"n\": 5786, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3373.76, \"learn_time_ms\": 46282.784}", "{\"n\": 5787, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3372.42, \"learn_time_ms\": 46282.424}", "{\"n\": 5788, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3372.42, \"learn_time_ms\": 46144.382}", "{\"n\": 5789, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.9, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3384.77, \"learn_time_ms\": 46060.157}", "{\"n\": 5790, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3392.17, \"learn_time_ms\": 46058.841}", "{\"n\": 5791, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3365.99, \"learn_time_ms\": 46012.181}", "{\"n\": 5792, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -10.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3365.99, \"learn_time_ms\": 46043.031}", "{\"n\": 5793, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3371.42, \"learn_time_ms\": 45930.155}", "{\"n\": 5794, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.96, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3371.42, \"learn_time_ms\": 45831.346}", "{\"n\": 5795, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3383.56, \"learn_time_ms\": 45950.29}", "{\"n\": 5796, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3410.12, \"learn_time_ms\": 45975.704}", "{\"n\": 5797, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3405.88, \"learn_time_ms\": 45974.002}", "{\"n\": 5798, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3408.59, \"learn_time_ms\": 46070.005}", "{\"n\": 5799, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3401.73, \"learn_time_ms\": 46091.719}", "{\"n\": 5800, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3420.85, \"learn_time_ms\": 46102.716}", "{\"n\": 5801, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3424.73, \"learn_time_ms\": 46209.526}", "{\"n\": 5802, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3441.86, \"learn_time_ms\": 46191.844}", "{\"n\": 5803, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3450.39, \"learn_time_ms\": 46213.314}", "{\"n\": 5804, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3438.87, \"learn_time_ms\": 46280.318}", "{\"n\": 5805, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3399.97, \"learn_time_ms\": 46213.769}", "{\"n\": 5806, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3399.97, \"learn_time_ms\": 46231.569}", "{\"n\": 5807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3399.97, \"learn_time_ms\": 46250.202}", "{\"n\": 5808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3409.41, \"learn_time_ms\": 46279.761}", "{\"n\": 5809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3414.44, \"learn_time_ms\": 46448.141}", "{\"n\": 5810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3414.44, \"learn_time_ms\": 46473.248}", "{\"n\": 5811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3423.24, \"learn_time_ms\": 46436.097}", "{\"n\": 5812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3420.11, \"learn_time_ms\": 46420.153}", "{\"n\": 5813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3421.79, \"learn_time_ms\": 46448.079}", "{\"n\": 5814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3422.15, \"learn_time_ms\": 46458.93}", "{\"n\": 5815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3387.34, \"learn_time_ms\": 46439.007}", "{\"n\": 5816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3369.56, \"learn_time_ms\": 46445.511}", "{\"n\": 5817, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3369.56, \"learn_time_ms\": 46426.549}", "{\"n\": 5818, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3375.82, \"learn_time_ms\": 46399.143}", "{\"n\": 5819, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.75, \"learn_time_ms\": 46247.633}", "{\"n\": 5820, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3378.75, \"learn_time_ms\": 46101.329}", "{\"n\": 5821, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3408.99, \"learn_time_ms\": 46130.371}", "{\"n\": 5822, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3419.76, \"learn_time_ms\": 46097.167}", "{\"n\": 5823, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3419.76, \"learn_time_ms\": 46039.913}", "{\"n\": 5824, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3429.76, \"learn_time_ms\": 46095.938}", "{\"n\": 5825, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.34, \"learn_time_ms\": 46227.388}", "{\"n\": 5826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3460.89, \"learn_time_ms\": 46180.24}", "{\"n\": 5827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3467.36, \"learn_time_ms\": 46149.958}", "{\"n\": 5828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3477.09, \"learn_time_ms\": 46085.961}", "{\"n\": 5829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.44, \"learn_time_ms\": 46064.671}", "{\"n\": 5830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.44, \"learn_time_ms\": 46190.023}", "{\"n\": 5831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3484.43, \"learn_time_ms\": 46175.141}", "{\"n\": 5832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3507.34, \"learn_time_ms\": 46189.34}", "{\"n\": 5833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3500.33, \"learn_time_ms\": 46133.049}", "{\"n\": 5834, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3506.71, \"learn_time_ms\": 46139.476}", "{\"n\": 5835, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3506.71, \"learn_time_ms\": 45964.75}", "{\"n\": 5836, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3506.4, \"learn_time_ms\": 46028.597}", "{\"n\": 5837, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3505.89, \"learn_time_ms\": 46064.884}", "{\"n\": 5838, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3496.59, \"learn_time_ms\": 46144.802}", "{\"n\": 5839, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3498.97, \"learn_time_ms\": 46146.552}", "{\"n\": 5840, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3498.97, \"learn_time_ms\": 46129.436}", "{\"n\": 5841, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3510.59, \"learn_time_ms\": 46124.57}", "{\"n\": 5842, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3500.24, \"learn_time_ms\": 46099.665}", "{\"n\": 5843, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3492.48, \"learn_time_ms\": 46100.703}", "{\"n\": 5844, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3487.09, \"learn_time_ms\": 46082.437}", "{\"n\": 5845, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3477.84, \"learn_time_ms\": 46154.81}", "{\"n\": 5846, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3468.96, \"learn_time_ms\": 46046.853}", "{\"n\": 5847, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3470.7, \"learn_time_ms\": 45965.363}", "{\"n\": 5848, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3471.35, \"learn_time_ms\": 46018.183}", "{\"n\": 5849, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3479.74, \"learn_time_ms\": 46119.358}", "{\"n\": 5850, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3469.82, \"learn_time_ms\": 46192.198}", "{\"n\": 5851, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3468.28, \"learn_time_ms\": 46201.79}", "{\"n\": 5852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3475.75, \"learn_time_ms\": 46235.627}", "{\"n\": 5853, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3454.44, \"learn_time_ms\": 46350.066}", "{\"n\": 5854, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3458.93, \"learn_time_ms\": 46247.606}", "{\"n\": 5855, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3458.93, \"learn_time_ms\": 46296.102}", "{\"n\": 5856, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3454.27, \"learn_time_ms\": 46328.592}", "{\"n\": 5857, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3456.2, \"learn_time_ms\": 46415.888}", "{\"n\": 5858, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3447.95, \"learn_time_ms\": 46354.793}", "{\"n\": 5859, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3431.54, \"learn_time_ms\": 46381.601}", "{\"n\": 5860, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.73, \"learn_time_ms\": 46352.711}", "{\"n\": 5861, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3426.73, \"learn_time_ms\": 46341.649}", "{\"n\": 5862, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.31, \"learn_time_ms\": 46308.915}", "{\"n\": 5863, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.31, \"learn_time_ms\": 46299.396}", "{\"n\": 5864, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3406.31, \"learn_time_ms\": 46330.881}", "{\"n\": 5865, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3387.78, \"learn_time_ms\": 46247.533}", "{\"n\": 5866, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.46, \"learn_time_ms\": 46213.039}", "{\"n\": 5867, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3400.46, \"learn_time_ms\": 46179.139}", "{\"n\": 5868, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3386.74, \"learn_time_ms\": 46132.596}", "{\"n\": 5869, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3384.99, \"learn_time_ms\": 46006.209}", "{\"n\": 5870, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3380.76, \"learn_time_ms\": 46010.404}", "{\"n\": 5871, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3364.44, \"learn_time_ms\": 45987.315}", "{\"n\": 5872, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.62, \"learn_time_ms\": 46070.942}", "{\"n\": 5873, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3374.35, \"learn_time_ms\": 46093.38}", "{\"n\": 5874, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.5, \"learn_time_ms\": 46064.555}", "{\"n\": 5875, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.82, \"learn_time_ms\": 46084.864}", "{\"n\": 5876, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.82, \"learn_time_ms\": 46074.678}", "{\"n\": 5877, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.8, \"learn_time_ms\": 46102.174}", "{\"n\": 5878, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3396.8, \"learn_time_ms\": 46121.724}", "{\"n\": 5879, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.28, \"learn_time_ms\": 46141.828}", "{\"n\": 5880, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.25, \"learn_time_ms\": 46077.782}", "{\"n\": 5881, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3385.7, \"learn_time_ms\": 46150.44}", "{\"n\": 5882, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.87, \"learn_time_ms\": 46043.433}", "{\"n\": 5883, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3368.87, \"learn_time_ms\": 45926.423}", "{\"n\": 5884, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3360.39, \"learn_time_ms\": 46003.307}", "{\"n\": 5885, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3379.44, \"learn_time_ms\": 45991.554}", "{\"n\": 5886, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.13, \"learn_time_ms\": 46014.554}", "{\"n\": 5887, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.7, \"learn_time_ms\": 45970.617}", "{\"n\": 5888, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.7, \"learn_time_ms\": 45905.894}", "{\"n\": 5889, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.7, \"learn_time_ms\": 45902.496}", "{\"n\": 5890, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3422.44, \"learn_time_ms\": 45911.664}", "{\"n\": 5891, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.76, \"learn_time_ms\": 45824.042}", "{\"n\": 5892, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.58, \"learn_time_ms\": 45814.074}", "{\"n\": 5893, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.35, \"learn_time_ms\": 45970.207}", "{\"n\": 5894, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.35, \"learn_time_ms\": 45924.356}", "{\"n\": 5895, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.35, \"learn_time_ms\": 45941.496}", "{\"n\": 5896, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3400.35, \"learn_time_ms\": 46028.501}", "{\"n\": 5897, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3392.88, \"learn_time_ms\": 46033.606}", "{\"n\": 5898, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.4, \"learn_time_ms\": 46156.291}", "{\"n\": 5899, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3391.4, \"learn_time_ms\": 46196.56}", "{\"n\": 5900, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3392.19, \"learn_time_ms\": 46216.988}", "{\"n\": 5901, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3392.19, \"learn_time_ms\": 46133.507}", "{\"n\": 5902, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.18, \"learn_time_ms\": 46164.618}", "{\"n\": 5903, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.18, \"learn_time_ms\": 46095.093}", "{\"n\": 5904, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3422.11, \"learn_time_ms\": 46074.283}", "{\"n\": 5905, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3412.98, \"learn_time_ms\": 46036.759}", "{\"n\": 5906, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.01, \"learn_time_ms\": 45889.466}", "{\"n\": 5907, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3413.21, \"learn_time_ms\": 45900.083}", "{\"n\": 5908, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3422.26, \"learn_time_ms\": 45803.148}", "{\"n\": 5909, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3409.59, \"learn_time_ms\": 45783.773}", "{\"n\": 5910, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.55, \"learn_time_ms\": 45789.95}", "{\"n\": 5911, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3403.32, \"learn_time_ms\": 45908.818}", "{\"n\": 5912, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3419.43, \"learn_time_ms\": 45926.592}", "{\"n\": 5913, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3419.94, \"learn_time_ms\": 45932.549}", "{\"n\": 5914, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.46, \"learn_time_ms\": 45933.362}", "{\"n\": 5915, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.77, \"learn_time_ms\": 45981.319}", "{\"n\": 5916, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.4, \"learn_time_ms\": 46033.265}", "{\"n\": 5917, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3421.4, \"learn_time_ms\": 45976.835}", "{\"n\": 5918, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3461.74, \"learn_time_ms\": 46085.203}", "{\"n\": 5919, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3461.74, \"learn_time_ms\": 46083.242}", "{\"n\": 5920, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3457.36, \"learn_time_ms\": 46026.937}", "{\"n\": 5921, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3450.46, \"learn_time_ms\": 46021.149}", "{\"n\": 5922, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3453.8, \"learn_time_ms\": 45914.413}", "{\"n\": 5923, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3444.47, \"learn_time_ms\": 45866.443}", "{\"n\": 5924, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3446.79, \"learn_time_ms\": 45973.222}", "{\"n\": 5925, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3447.19, \"learn_time_ms\": 45893.897}", "{\"n\": 5926, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3435.69, \"learn_time_ms\": 45957.225}", "{\"n\": 5927, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3448.77, \"learn_time_ms\": 46044.514}", "{\"n\": 5928, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3448.77, \"learn_time_ms\": 46076.538}", "{\"n\": 5929, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3442.68, \"learn_time_ms\": 46076.174}", "{\"n\": 5930, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3439.95, \"learn_time_ms\": 46187.131}", "{\"n\": 5931, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3447.06, \"learn_time_ms\": 46200.896}", "{\"n\": 5932, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3455.3, \"learn_time_ms\": 46262.37}", "{\"n\": 5933, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3464.08, \"learn_time_ms\": 46334.602}", "{\"n\": 5934, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3472.32, \"learn_time_ms\": 46264.445}", "{\"n\": 5935, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3472.32, \"learn_time_ms\": 46256.785}", "{\"n\": 5936, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3473.18, \"learn_time_ms\": 46216.397}", "{\"n\": 5937, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3472.16, \"learn_time_ms\": 46231.371}", "{\"n\": 5938, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3473.39, \"learn_time_ms\": 46188.932}", "{\"n\": 5939, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3478.34, \"learn_time_ms\": 46215.03}", "{\"n\": 5940, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3461.63, \"learn_time_ms\": 46134.191}", "{\"n\": 5941, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3457.19, \"learn_time_ms\": 46123.948}", "{\"n\": 5942, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3457.19, \"learn_time_ms\": 46189.127}", "{\"n\": 5943, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3440.25, \"learn_time_ms\": 46208.766}", "{\"n\": 5944, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3440.25, \"learn_time_ms\": 46229.88}", "{\"n\": 5945, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3427.8, \"learn_time_ms\": 46270.111}", "{\"n\": 5946, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3439.54, \"learn_time_ms\": 46280.141}", "{\"n\": 5947, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3411.05, \"learn_time_ms\": 46197.674}", "{\"n\": 5948, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.92, \"learn_time_ms\": 46055.197}", "{\"n\": 5949, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.33, \"learn_time_ms\": 45969.935}", "{\"n\": 5950, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.33, \"learn_time_ms\": 46021.974}", "{\"n\": 5951, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3437.23, \"learn_time_ms\": 46036.303}", "{\"n\": 5952, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3425.85, \"learn_time_ms\": 46005.505}", "{\"n\": 5953, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3460.34, \"learn_time_ms\": 45904.263}", "{\"n\": 5954, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3442.08, \"learn_time_ms\": 45936.221}", "{\"n\": 5955, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.49, \"learn_time_ms\": 45894.089}", "{\"n\": 5956, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3430.49, \"learn_time_ms\": 45878.652}", "{\"n\": 5957, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3428.05, \"learn_time_ms\": 45926.573}", "{\"n\": 5958, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.03, \"learn_time_ms\": 46066.375}", "{\"n\": 5959, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3410.03, \"learn_time_ms\": 46108.128}", "{\"n\": 5960, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.88, \"learn_time_ms\": 45985.759}", "{\"n\": 5961, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.88, \"learn_time_ms\": 45952.11}", "{\"n\": 5962, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.88, \"learn_time_ms\": 45955.006}", "{\"n\": 5963, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3405.76, \"learn_time_ms\": 45984.919}", "{\"n\": 5964, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.69, \"learn_time_ms\": 45911.389}", "{\"n\": 5965, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3407.69, \"learn_time_ms\": 45844.605}", "{\"n\": 5966, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3388.57, \"learn_time_ms\": 45835.733}", "{\"n\": 5967, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3389.3, \"learn_time_ms\": 45755.082}", "{\"n\": 5968, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3372.09, \"learn_time_ms\": 45785.915}", "{\"n\": 5969, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3372.39, \"learn_time_ms\": 45822.336}", "{\"n\": 5970, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3372.39, \"learn_time_ms\": 45839.198}", "{\"n\": 5971, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3357.63, \"learn_time_ms\": 45877.051}", "{\"n\": 5972, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3362.48, \"learn_time_ms\": 45842.91}", "{\"n\": 5973, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3356.95, \"learn_time_ms\": 45875.461}", "{\"n\": 5974, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.1, \"learn_time_ms\": 45803.565}", "{\"n\": 5975, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3332.1, \"learn_time_ms\": 45919.009}", "{\"n\": 5976, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3348.34, \"learn_time_ms\": 45917.598}", "{\"n\": 5977, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3368.1, \"learn_time_ms\": 45921.016}", "{\"n\": 5978, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3356.02, \"learn_time_ms\": 45824.746}", "{\"n\": 5979, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3356.02, \"learn_time_ms\": 45815.401}", "{\"n\": 5980, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3361.93, \"learn_time_ms\": 45936.447}", "{\"n\": 5981, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.45, \"learn_time_ms\": 45832.476}", "{\"n\": 5982, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3349.45, \"learn_time_ms\": 45848.472}", "{\"n\": 5983, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3337.61, \"learn_time_ms\": 45877.576}", "{\"n\": 5984, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3353.76, \"learn_time_ms\": 45966.569}", "{\"n\": 5985, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3354.14, \"learn_time_ms\": 45948.977}", "{\"n\": 5986, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.28, \"learn_time_ms\": 45988.645}", "{\"n\": 5987, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3371.28, \"learn_time_ms\": 46085.76}", "{\"n\": 5988, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3366.49, \"learn_time_ms\": 46182.291}", "{\"n\": 5989, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3368.69, \"learn_time_ms\": 46153.802}", "{\"n\": 5990, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3378.18, \"learn_time_ms\": 46154.484}", "{\"n\": 5991, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3403.02, \"learn_time_ms\": 46244.6}", "{\"n\": 5992, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3404.52, \"learn_time_ms\": 46304.52}", "{\"n\": 5993, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.21, \"learn_time_ms\": 46207.918}", "{\"n\": 5994, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.21, \"learn_time_ms\": 46259.388}", "{\"n\": 5995, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.21, \"learn_time_ms\": 46281.804}", "{\"n\": 5996, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.12, \"learn_time_ms\": 46377.321}", "{\"n\": 5997, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.51, \"learn_time_ms\": 46281.963}", "{\"n\": 5998, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.87, \"learn_time_ms\": 46263.219}", "{\"n\": 5999, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3425.08, \"learn_time_ms\": 46301.69}", "{\"n\": 6000, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3425.08, \"learn_time_ms\": 46255.767}"]["{\"n\": 6001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 49902.162}", "{\"n\": 6002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 49018.236}", "{\"n\": 6003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 48585.94}", "{\"n\": 6004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 48375.749}", "{\"n\": 6005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 48038.742}", "{\"n\": 6006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47945.723}", "{\"n\": 6007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47759.661}", "{\"n\": 6008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47650.88}", "{\"n\": 6009, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2314.0, \"learn_time_ms\": 47520.709}", "{\"n\": 6010, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2623.0, \"learn_time_ms\": 47474.719}", "{\"n\": 6011, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.666666666666666, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2901.0, \"learn_time_ms\": 47078.351}", "{\"n\": 6012, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.571428571428571, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2960.714285714286, \"learn_time_ms\": 46885.164}", "{\"n\": 6013, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.571428571428571, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2960.714285714286, \"learn_time_ms\": 46805.299}", "{\"n\": 6014, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.25, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3052.25, \"learn_time_ms\": 46718.035}", "{\"n\": 6015, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.444444444444445, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3045.777777777778, \"learn_time_ms\": 46724.769}", "{\"n\": 6016, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.75, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2975.5, \"learn_time_ms\": 46598.128}", "{\"n\": 6017, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3104.285714285714, \"learn_time_ms\": 46574.746}", "{\"n\": 6018, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -11.0, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3104.285714285714, \"learn_time_ms\": 46472.655}", "{\"n\": 6019, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.8, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3134.0, \"learn_time_ms\": 46401.742}", "{\"n\": 6020, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.875, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3145.625, \"learn_time_ms\": 46356.123}", "{\"n\": 6021, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.823529411764707, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3152.294117647059, \"learn_time_ms\": 46408.099}", "{\"n\": 6022, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.578947368421053, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3198.1052631578946, \"learn_time_ms\": 46443.432}", "{\"n\": 6023, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.090909090909092, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3299.909090909091, \"learn_time_ms\": 46443.569}", "{\"n\": 6024, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.043478260869565, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3292.8695652173915, \"learn_time_ms\": 46408.572}", "{\"n\": 6025, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.125, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3274.8333333333335, \"learn_time_ms\": 46343.877}", "{\"n\": 6026, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.125, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3274.8333333333335, \"learn_time_ms\": 46393.226}", "{\"n\": 6027, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.28, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3270.68, \"learn_time_ms\": 46299.257}", "{\"n\": 6028, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -10.074074074074074, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3346.185185185185, \"learn_time_ms\": 46419.206}", "{\"n\": 6029, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.793103448275861, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3412.206896551724, \"learn_time_ms\": 46481.553}", "{\"n\": 6030, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.870967741935484, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3396.6451612903224, \"learn_time_ms\": 46413.233}", "{\"n\": 6031, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.969696969696969, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.5151515151515, \"learn_time_ms\": 46431.539}", "{\"n\": 6032, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.911764705882353, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3378.4411764705883, \"learn_time_ms\": 46435.791}", "{\"n\": 6033, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.857142857142858, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3386.9714285714285, \"learn_time_ms\": 46327.348}", "{\"n\": 6034, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.805555555555555, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3401.222222222222, \"learn_time_ms\": 46332.817}", "{\"n\": 6035, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.736842105263158, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3424.1052631578946, \"learn_time_ms\": 46362.486}", "{\"n\": 6036, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.666666666666666, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3441.358974358974, \"learn_time_ms\": 46327.027}", "{\"n\": 6037, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.666666666666666, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3441.358974358974, \"learn_time_ms\": 46446.588}", "{\"n\": 6038, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.906976744186046, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3397.2093023255816, \"learn_time_ms\": 46382.085}", "{\"n\": 6039, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.906976744186046, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3397.2093023255816, \"learn_time_ms\": 46292.874}", "{\"n\": 6040, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88888888888889, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3391.2444444444445, \"learn_time_ms\": 46326.148}", "{\"n\": 6041, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.88888888888889, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3391.2444444444445, \"learn_time_ms\": 46274.518}", "{\"n\": 6042, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.680851063829786, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3436.404255319149, \"learn_time_ms\": 46215.217}", "{\"n\": 6043, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.693877551020408, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3429.6326530612246, \"learn_time_ms\": 46224.526}", "{\"n\": 6044, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3421.12, \"learn_time_ms\": 46115.95}", "{\"n\": 6045, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.72, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3421.12, \"learn_time_ms\": 46070.57}", "{\"n\": 6046, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.843137254901961, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3399.5882352941176, \"learn_time_ms\": 45965.916}", "{\"n\": 6047, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.927272727272728, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3368.418181818182, \"learn_time_ms\": 45874.843}", "{\"n\": 6048, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.807017543859649, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.0175438596493, \"learn_time_ms\": 45784.431}", "{\"n\": 6049, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.807017543859649, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3394.0175438596493, \"learn_time_ms\": 45889.66}", "{\"n\": 6050, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.559322033898304, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.491525423729, \"learn_time_ms\": 45911.331}", "{\"n\": 6051, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.559322033898304, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3434.491525423729, \"learn_time_ms\": 45902.74}", "{\"n\": 6052, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.491803278688524, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3448.0163934426228, \"learn_time_ms\": 45963.215}", "{\"n\": 6053, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.483870967741936, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.8548387096776, \"learn_time_ms\": 46037.702}", "{\"n\": 6054, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.484375, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3455.078125, \"learn_time_ms\": 46154.18}", "{\"n\": 6055, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.553846153846154, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3445.5384615384614, \"learn_time_ms\": 46251.507}", "{\"n\": 6056, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.530303030303031, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3445.621212121212, \"learn_time_ms\": 46230.637}", "{\"n\": 6057, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.617647058823529, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3426.323529411765, \"learn_time_ms\": 46213.939}", "{\"n\": 6058, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.652173913043478, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3419.5652173913045, \"learn_time_ms\": 46290.265}", "{\"n\": 6059, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67142857142857, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3416.442857142857, \"learn_time_ms\": 46202.017}", "{\"n\": 6060, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.732394366197184, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.3098591549297, \"learn_time_ms\": 45991.23}", "{\"n\": 6061, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.63013698630137, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3425.2328767123286, \"learn_time_ms\": 46096.494}", "{\"n\": 6062, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.666666666666666, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.653333333333, \"learn_time_ms\": 46010.521}", "{\"n\": 6063, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.666666666666666, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.653333333333, \"learn_time_ms\": 46028.538}", "{\"n\": 6064, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.636363636363637, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3433.1688311688313, \"learn_time_ms\": 45888.263}", "{\"n\": 6065, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.564102564102564, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.051282051282, \"learn_time_ms\": 45848.676}", "{\"n\": 6066, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.564102564102564, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.051282051282, \"learn_time_ms\": 45768.905}", "{\"n\": 6067, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.544303797468354, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.6708860759495, \"learn_time_ms\": 45841.073}", "{\"n\": 6068, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.469135802469136, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.962962962963, \"learn_time_ms\": 45857.655}", "{\"n\": 6069, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.535714285714286, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3460.8690476190477, \"learn_time_ms\": 45925.729}", "{\"n\": 6070, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.4302325581393, \"learn_time_ms\": 46082.114}", "{\"n\": 6071, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.4302325581393, \"learn_time_ms\": 45964.143}", "{\"n\": 6072, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.4302325581393, \"learn_time_ms\": 46041.45}", "{\"n\": 6073, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.4302325581393, \"learn_time_ms\": 45973.089}", "{\"n\": 6074, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.528735632183908, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.8390804597702, \"learn_time_ms\": 46124.202}", "{\"n\": 6075, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.38888888888889, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3483.9222222222224, \"learn_time_ms\": 46026.114}", "{\"n\": 6076, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.279569892473118, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3503.94623655914, \"learn_time_ms\": 46274.641}", "{\"n\": 6077, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.279569892473118, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3503.94623655914, \"learn_time_ms\": 46135.39}", "{\"n\": 6078, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.26595744680851, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3502.7978723404253, \"learn_time_ms\": 46158.957}", "{\"n\": 6079, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.294736842105262, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3496.242105263158, \"learn_time_ms\": 46186.878}", "{\"n\": 6080, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.208333333333334, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3508.0729166666665, \"learn_time_ms\": 46208.378}", "{\"n\": 6081, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.175257731958762, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3513.8453608247423, \"learn_time_ms\": 46264.2}", "{\"n\": 6082, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3529.14, \"learn_time_ms\": 46333.378}", "{\"n\": 6083, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3554.37, \"learn_time_ms\": 46295.43}", "{\"n\": 6084, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.25, \"learn_time_ms\": 46267.909}", "{\"n\": 6085, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.25, \"learn_time_ms\": 46292.74}", "{\"n\": 6086, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.25, \"learn_time_ms\": 46178.099}", "{\"n\": 6087, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3575.51, \"learn_time_ms\": 46168.792}", "{\"n\": 6088, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.32, \"learn_time_ms\": 46068.042}", "{\"n\": 6089, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3580.57, \"learn_time_ms\": 45993.079}", "{\"n\": 6090, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.05, \"learn_time_ms\": 45990.174}", "{\"n\": 6091, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.05, \"learn_time_ms\": 45992.435}", "{\"n\": 6092, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.05, \"learn_time_ms\": 45863.244}", "{\"n\": 6093, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.82, \"learn_time_ms\": 45778.667}", "{\"n\": 6094, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.78, \"learn_time_ms\": 45764.078}", "{\"n\": 6095, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.1, \"learn_time_ms\": 45808.719}", "{\"n\": 6096, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.38, \"learn_time_ms\": 45866.263}", "{\"n\": 6097, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.38, \"learn_time_ms\": 45977.727}", "{\"n\": 6098, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3571.1, \"learn_time_ms\": 46002.58}", "{\"n\": 6099, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.94, \"learn_time_ms\": 46081.335}", "{\"n\": 6100, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.94, \"learn_time_ms\": 46097.13}", "{\"n\": 6101, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.06, \"learn_time_ms\": 46030.093}", "{\"n\": 6102, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3553.91, \"learn_time_ms\": 46087.52}", "{\"n\": 6103, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3553.91, \"learn_time_ms\": 46134.506}", "{\"n\": 6104, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3553.91, \"learn_time_ms\": 46104.894}", "{\"n\": 6105, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3561.48, \"learn_time_ms\": 46021.989}", "{\"n\": 6106, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.86, \"learn_time_ms\": 45969.678}", "{\"n\": 6107, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.86, \"learn_time_ms\": 45917.736}", "{\"n\": 6108, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3573.72, \"learn_time_ms\": 45965.354}", "{\"n\": 6109, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3576.4, \"learn_time_ms\": 45923.578}", "{\"n\": 6110, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3576.4, \"learn_time_ms\": 45927.945}", "{\"n\": 6111, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3582.41, \"learn_time_ms\": 45892.752}", "{\"n\": 6112, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3575.22, \"learn_time_ms\": 45836.059}", "{\"n\": 6113, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.93, \"learn_time_ms\": 45902.06}", "{\"n\": 6114, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3591.93, \"learn_time_ms\": 45949.882}", "{\"n\": 6115, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.09, \"learn_time_ms\": 45949.423}", "{\"n\": 6116, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3597.1, \"learn_time_ms\": 46002.601}", "{\"n\": 6117, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3607.85, \"learn_time_ms\": 45940.702}", "{\"n\": 6118, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3606.12, \"learn_time_ms\": 45965.54}", "{\"n\": 6119, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3619.05, \"learn_time_ms\": 45879.886}", "{\"n\": 6120, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3626.81, \"learn_time_ms\": 45900.99}", "{\"n\": 6121, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3626.81, \"learn_time_ms\": 45979.89}", "{\"n\": 6122, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3641.04, \"learn_time_ms\": 46013.693}", "{\"n\": 6123, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3636.1, \"learn_time_ms\": 46029.246}", "{\"n\": 6124, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.17, \"learn_time_ms\": 45950.518}", "{\"n\": 6125, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3605.17, \"learn_time_ms\": 46030.521}", "{\"n\": 6126, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3569.69, \"learn_time_ms\": 46117.705}", "{\"n\": 6127, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.13, \"learn_time_ms\": 46207.038}", "{\"n\": 6128, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3576.43, \"learn_time_ms\": 46107.809}", "{\"n\": 6129, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3579.49, \"learn_time_ms\": 46056.127}", "{\"n\": 6130, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3584.96, \"learn_time_ms\": 45992.567}", "{\"n\": 6131, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3599.45, \"learn_time_ms\": 45913.243}", "{\"n\": 6132, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3599.45, \"learn_time_ms\": 45763.496}", "{\"n\": 6133, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3610.14, \"learn_time_ms\": 45714.285}", "{\"n\": 6134, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3613.57, \"learn_time_ms\": 45678.538}", "{\"n\": 6135, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3600.7, \"learn_time_ms\": 45602.083}", "{\"n\": 6136, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3596.95, \"learn_time_ms\": 45552.039}", "{\"n\": 6137, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3596.95, \"learn_time_ms\": 45531.432}", "{\"n\": 6138, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3585.16, \"learn_time_ms\": 45665.719}", "{\"n\": 6139, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3566.23, \"learn_time_ms\": 45782.994}", "{\"n\": 6140, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3557.36, \"learn_time_ms\": 45791.867}", "{\"n\": 6141, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.89, \"learn_time_ms\": 45807.443}", "{\"n\": 6142, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.89, \"learn_time_ms\": 45905.231}", "{\"n\": 6143, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3571.37, \"learn_time_ms\": 45996.784}", "{\"n\": 6144, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3564.99, \"learn_time_ms\": 46088.214}", "{\"n\": 6145, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3550.63, \"learn_time_ms\": 46156.328}", "{\"n\": 6146, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3555.31, \"learn_time_ms\": 46059.323}", "{\"n\": 6147, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3536.59, \"learn_time_ms\": 46003.837}", "{\"n\": 6148, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.86, \"learn_time_ms\": 45939.537}", "{\"n\": 6149, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.1, \"learn_time_ms\": 45900.348}", "{\"n\": 6150, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3512.42, \"learn_time_ms\": 45892.872}", "{\"n\": 6151, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3500.65, \"learn_time_ms\": 45983.578}", "{\"n\": 6152, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3508.29, \"learn_time_ms\": 45996.911}", "{\"n\": 6153, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3517.0, \"learn_time_ms\": 45911.303}", "{\"n\": 6154, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3502.5, \"learn_time_ms\": 45844.334}", "{\"n\": 6155, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3502.5, \"learn_time_ms\": 45767.002}", "{\"n\": 6156, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.88, \"learn_time_ms\": 45881.145}", "{\"n\": 6157, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.88, \"learn_time_ms\": 46056.509}", "{\"n\": 6158, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3482.91, \"learn_time_ms\": 45949.974}", "{\"n\": 6159, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3484.17, \"learn_time_ms\": 46097.799}", "{\"n\": 6160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.07, \"learn_time_ms\": 46133.703}", "{\"n\": 6161, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.27, \"learn_time_ms\": 46131.758}", "{\"n\": 6162, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.43, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3468.45, \"learn_time_ms\": 46122.363}", "{\"n\": 6163, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3471.71, \"learn_time_ms\": 46140.334}", "{\"n\": 6164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3454.33, \"learn_time_ms\": 46131.052}", "{\"n\": 6165, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.69, \"learn_time_ms\": 46140.471}", "{\"n\": 6166, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3450.21, \"learn_time_ms\": 46089.3}", "{\"n\": 6167, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.18, \"learn_time_ms\": 46075.274}", "{\"n\": 6168, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.18, \"learn_time_ms\": 46200.122}", "{\"n\": 6169, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3437.04, \"learn_time_ms\": 46156.614}", "{\"n\": 6170, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.54, \"learn_time_ms\": 46198.494}", "{\"n\": 6171, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3405.17, \"learn_time_ms\": 46180.626}", "{\"n\": 6172, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.37, \"learn_time_ms\": 46219.285}", "{\"n\": 6173, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3406.37, \"learn_time_ms\": 46187.429}", "{\"n\": 6174, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.35, \"learn_time_ms\": 46176.559}", "{\"n\": 6175, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.57, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3395.52, \"learn_time_ms\": 46281.495}", "{\"n\": 6176, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3384.98, \"learn_time_ms\": 46238.342}", "{\"n\": 6177, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.02, \"learn_time_ms\": 46218.087}", "{\"n\": 6178, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3389.32, \"learn_time_ms\": 46203.097}", "{\"n\": 6179, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3359.1, \"learn_time_ms\": 46047.231}", "{\"n\": 6180, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.33, \"learn_time_ms\": 46008.878}", "{\"n\": 6181, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.36, \"learn_time_ms\": 45914.595}", "{\"n\": 6182, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3364.32, \"learn_time_ms\": 45924.694}", "{\"n\": 6183, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.75, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3355.47, \"learn_time_ms\": 45996.99}", "{\"n\": 6184, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3348.73, \"learn_time_ms\": 45977.798}", "{\"n\": 6185, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.79, \"learn_time_ms\": 45920.334}", "{\"n\": 6186, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.79, \"learn_time_ms\": 45883.758}", "{\"n\": 6187, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3315.81, \"learn_time_ms\": 45807.549}", "{\"n\": 6188, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.31, \"learn_time_ms\": 45730.787}", "{\"n\": 6189, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.59, \"learn_time_ms\": 45756.401}", "{\"n\": 6190, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.59, \"learn_time_ms\": 45629.696}", "{\"n\": 6191, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.0, \"learn_time_ms\": 45712.599}", "{\"n\": 6192, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3301.0, \"learn_time_ms\": 45620.661}", "{\"n\": 6193, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3299.76, \"learn_time_ms\": 45555.259}", "{\"n\": 6194, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.31, \"learn_time_ms\": 45611.241}", "{\"n\": 6195, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.31, \"learn_time_ms\": 45582.044}", "{\"n\": 6196, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.63, \"learn_time_ms\": 45568.143}", "{\"n\": 6197, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.63, \"learn_time_ms\": 45523.167}", "{\"n\": 6198, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3319.63, \"learn_time_ms\": 45563.686}", "{\"n\": 6199, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.95, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.99, \"learn_time_ms\": 45668.969}", "{\"n\": 6200, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.62, \"learn_time_ms\": 45634.645}", "{\"n\": 6201, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.62, \"learn_time_ms\": 45523.106}", "{\"n\": 6202, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.32, \"learn_time_ms\": 45581.712}", "{\"n\": 6203, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.32, \"learn_time_ms\": 45517.355}", "{\"n\": 6204, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -10.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3313.32, \"learn_time_ms\": 45586.486}", "{\"n\": 6205, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.18, \"learn_time_ms\": 45611.735}", "{\"n\": 6206, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3357.05, \"learn_time_ms\": 45717.798}", "{\"n\": 6207, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.54, \"learn_time_ms\": 45789.45}", "{\"n\": 6208, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.96, \"learn_time_ms\": 45795.855}", "{\"n\": 6209, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.96, \"learn_time_ms\": 45783.568}", "{\"n\": 6210, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3376.96, \"learn_time_ms\": 45921.071}", "{\"n\": 6211, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3390.15, \"learn_time_ms\": 45863.196}", "{\"n\": 6212, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3392.82, \"learn_time_ms\": 45891.63}", "{\"n\": 6213, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.08, \"learn_time_ms\": 45928.393}", "{\"n\": 6214, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.73, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3398.88, \"learn_time_ms\": 45846.827}", "{\"n\": 6215, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.67, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.85, \"learn_time_ms\": 45800.013}", "{\"n\": 6216, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.69, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.92, \"learn_time_ms\": 45745.092}", "{\"n\": 6217, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.38, \"learn_time_ms\": 45732.167}", "{\"n\": 6218, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.7, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3401.38, \"learn_time_ms\": 45674.913}", "{\"n\": 6219, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3420.03, \"learn_time_ms\": 45556.236}", "{\"n\": 6220, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3439.74, \"learn_time_ms\": 45529.76}", "{\"n\": 6221, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3439.74, \"learn_time_ms\": 45734.019}", "{\"n\": 6222, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3437.37, \"learn_time_ms\": 45726.096}", "{\"n\": 6223, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3425.43, \"learn_time_ms\": 45772.86}", "{\"n\": 6224, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3425.43, \"learn_time_ms\": 45729.561}", "{\"n\": 6225, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.62, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3405.11, \"learn_time_ms\": 45806.201}", "{\"n\": 6226, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.61, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3411.24, \"learn_time_ms\": 45833.308}", "{\"n\": 6227, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.6, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3417.22, \"learn_time_ms\": 45812.151}", "{\"n\": 6228, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3427.8, \"learn_time_ms\": 45874.813}", "{\"n\": 6229, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3427.8, \"learn_time_ms\": 45908.803}", "{\"n\": 6230, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3424.98, \"learn_time_ms\": 45971.452}", "{\"n\": 6231, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3429.87, \"learn_time_ms\": 45854.78}", "{\"n\": 6232, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3455.21, \"learn_time_ms\": 45736.476}", "{\"n\": 6233, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3451.23, \"learn_time_ms\": 45728.943}", "{\"n\": 6234, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3451.23, \"learn_time_ms\": 45797.98}", "{\"n\": 6235, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3438.02, \"learn_time_ms\": 45893.567}", "{\"n\": 6236, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3438.02, \"learn_time_ms\": 45959.728}", "{\"n\": 6237, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3455.1, \"learn_time_ms\": 45888.642}", "{\"n\": 6238, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3461.6, \"learn_time_ms\": 45821.848}", "{\"n\": 6239, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.38, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3461.6, \"learn_time_ms\": 45819.542}", "{\"n\": 6240, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3482.95, \"learn_time_ms\": 45738.059}", "{\"n\": 6241, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3513.15, \"learn_time_ms\": 45781.08}", "{\"n\": 6242, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3503.57, \"learn_time_ms\": 45833.245}", "{\"n\": 6243, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3501.83, \"learn_time_ms\": 45781.639}", "{\"n\": 6244, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3512.16, \"learn_time_ms\": 45709.711}", "{\"n\": 6245, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3512.16, \"learn_time_ms\": 45596.368}", "{\"n\": 6246, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3508.19, \"learn_time_ms\": 45457.866}", "{\"n\": 6247, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3519.9, \"learn_time_ms\": 45527.035}", "{\"n\": 6248, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3518.17, \"learn_time_ms\": 45560.315}", "{\"n\": 6249, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3519.83, \"learn_time_ms\": 45665.914}", "{\"n\": 6250, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3513.52, \"learn_time_ms\": 45697.365}", "{\"n\": 6251, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3513.52, \"learn_time_ms\": 45688.892}", "{\"n\": 6252, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3504.01, \"learn_time_ms\": 45848.968}", "{\"n\": 6253, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3534.15, \"learn_time_ms\": 45847.885}", "{\"n\": 6254, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3535.56, \"learn_time_ms\": 45930.075}", "{\"n\": 6255, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3540.82, \"learn_time_ms\": 45884.384}", "{\"n\": 6256, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3540.82, \"learn_time_ms\": 45885.357}", "{\"n\": 6257, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3531.01, \"learn_time_ms\": 45875.163}", "{\"n\": 6258, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3523.76, \"learn_time_ms\": 45876.168}", "{\"n\": 6259, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3521.47, \"learn_time_ms\": 45849.214}", "{\"n\": 6260, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.49, \"learn_time_ms\": 45865.247}", "{\"n\": 6261, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3544.39, \"learn_time_ms\": 45939.798}", "{\"n\": 6262, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3567.45, \"learn_time_ms\": 45863.508}", "{\"n\": 6263, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3567.45, \"learn_time_ms\": 45901.947}", "{\"n\": 6264, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3577.92, \"learn_time_ms\": 45865.424}", "{\"n\": 6265, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3590.12, \"learn_time_ms\": 45927.316}", "{\"n\": 6266, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3597.66, \"learn_time_ms\": 46124.916}", "{\"n\": 6267, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3618.55, \"learn_time_ms\": 46191.486}", "{\"n\": 6268, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3634.44, \"learn_time_ms\": 46163.371}", "{\"n\": 6269, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3616.73, \"learn_time_ms\": 46111.543}", "{\"n\": 6270, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3616.73, \"learn_time_ms\": 46054.96}", "{\"n\": 6271, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3622.33, \"learn_time_ms\": 45974.244}", "{\"n\": 6272, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3622.33, \"learn_time_ms\": 45883.831}", "{\"n\": 6273, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3626.33, \"learn_time_ms\": 45842.842}", "{\"n\": 6274, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3616.12, \"learn_time_ms\": 45868.115}", "{\"n\": 6275, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3616.77, \"learn_time_ms\": 45775.275}", "{\"n\": 6276, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3628.25, \"learn_time_ms\": 45719.447}", "{\"n\": 6277, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3628.25, \"learn_time_ms\": 45755.872}", "{\"n\": 6278, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3615.48, \"learn_time_ms\": 45719.774}", "{\"n\": 6279, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3615.48, \"learn_time_ms\": 45748.915}", "{\"n\": 6280, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3620.45, \"learn_time_ms\": 45856.112}", "{\"n\": 6281, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3620.45, \"learn_time_ms\": 45903.677}", "{\"n\": 6282, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3614.73, \"learn_time_ms\": 45962.766}", "{\"n\": 6283, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3597.99, \"learn_time_ms\": 45997.404}", "{\"n\": 6284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3599.87, \"learn_time_ms\": 45942.058}", "{\"n\": 6285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3599.87, \"learn_time_ms\": 45999.69}", "{\"n\": 6286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3596.33, \"learn_time_ms\": 45917.089}", "{\"n\": 6287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3579.92, \"learn_time_ms\": 45824.732}", "{\"n\": 6288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3589.24, \"learn_time_ms\": 45818.41}", "{\"n\": 6289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.95, \"learn_time_ms\": 45866.312}", "{\"n\": 6290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3595.07, \"learn_time_ms\": 45767.947}", "{\"n\": 6291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.96, \"learn_time_ms\": 45683.6}", "{\"n\": 6292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3596.46, \"learn_time_ms\": 45674.595}", "{\"n\": 6293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3580.88, \"learn_time_ms\": 45674.751}", "{\"n\": 6294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3581.33, \"learn_time_ms\": 45677.097}", "{\"n\": 6295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3581.33, \"learn_time_ms\": 45701.278}", "{\"n\": 6296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3563.24, \"learn_time_ms\": 45619.975}", "{\"n\": 6297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3563.27, \"learn_time_ms\": 45643.875}", "{\"n\": 6298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3554.31, \"learn_time_ms\": 45668.377}", "{\"n\": 6299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3539.74, \"learn_time_ms\": 45636.109}", "{\"n\": 6300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3539.74, \"learn_time_ms\": 45666.966}", "{\"n\": 6301, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3539.74, \"learn_time_ms\": 45753.392}", "{\"n\": 6302, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3526.98, \"learn_time_ms\": 45741.611}", "{\"n\": 6303, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3516.97, \"learn_time_ms\": 45728.366}", "{\"n\": 6304, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3511.04, \"learn_time_ms\": 45815.767}", "{\"n\": 6305, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3513.85, \"learn_time_ms\": 45837.117}", "{\"n\": 6306, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3513.85, \"learn_time_ms\": 45890.863}", "{\"n\": 6307, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3523.56, \"learn_time_ms\": 46015.701}", "{\"n\": 6308, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3527.9, \"learn_time_ms\": 46113.364}", "{\"n\": 6309, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3527.9, \"learn_time_ms\": 46053.539}", "{\"n\": 6310, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3523.12, \"learn_time_ms\": 46060.145}", "{\"n\": 6311, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3523.12, \"learn_time_ms\": 45998.708}", "{\"n\": 6312, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3508.77, \"learn_time_ms\": 46010.96}", "{\"n\": 6313, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3491.54, \"learn_time_ms\": 46016.872}", "{\"n\": 6314, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3495.04, \"learn_time_ms\": 45999.26}", "{\"n\": 6315, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3495.04, \"learn_time_ms\": 45922.885}", "{\"n\": 6316, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3485.65, \"learn_time_ms\": 46057.494}", "{\"n\": 6317, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3494.55, \"learn_time_ms\": 45880.051}", "{\"n\": 6318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3494.55, \"learn_time_ms\": 45938.643}", "{\"n\": 6319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3497.81, \"learn_time_ms\": 45949.878}", "{\"n\": 6320, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3495.96, \"learn_time_ms\": 45938.591}", "{\"n\": 6321, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3494.36, \"learn_time_ms\": 45955.25}", "{\"n\": 6322, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3495.16, \"learn_time_ms\": 46022.132}", "{\"n\": 6323, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3514.12, \"learn_time_ms\": 46073.321}", "{\"n\": 6324, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3494.55, \"learn_time_ms\": 46125.823}", "{\"n\": 6325, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3495.86, \"learn_time_ms\": 46150.293}", "{\"n\": 6326, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3510.73, \"learn_time_ms\": 46150.558}", "{\"n\": 6327, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3518.05, \"learn_time_ms\": 46254.902}", "{\"n\": 6328, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3518.05, \"learn_time_ms\": 46204.456}", "{\"n\": 6329, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3525.99, \"learn_time_ms\": 46310.269}", "{\"n\": 6330, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3513.42, \"learn_time_ms\": 46312.842}", "{\"n\": 6331, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3525.25, \"learn_time_ms\": 46338.202}", "{\"n\": 6332, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.38, \"learn_time_ms\": 46229.64}", "{\"n\": 6333, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.38, \"learn_time_ms\": 46221.579}", "{\"n\": 6334, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.38, \"learn_time_ms\": 46237.103}", "{\"n\": 6335, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3516.38, \"learn_time_ms\": 46151.316}", "{\"n\": 6336, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3486.39, \"learn_time_ms\": 46125.023}", "{\"n\": 6337, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3485.76, \"learn_time_ms\": 46179.225}", "{\"n\": 6338, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3485.76, \"learn_time_ms\": 46133.483}", "{\"n\": 6339, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3480.75, \"learn_time_ms\": 45982.802}", "{\"n\": 6340, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3465.61, \"learn_time_ms\": 45987.748}", "{\"n\": 6341, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3465.61, \"learn_time_ms\": 45987.606}", "{\"n\": 6342, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.03, \"learn_time_ms\": 46067.128}", "{\"n\": 6343, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3473.03, \"learn_time_ms\": 46064.43}", "{\"n\": 6344, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3460.67, \"learn_time_ms\": 45951.458}", "{\"n\": 6345, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3495.95, \"learn_time_ms\": 46051.862}", "{\"n\": 6346, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3491.84, \"learn_time_ms\": 46036.158}", "{\"n\": 6347, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3485.49, \"learn_time_ms\": 45899.94}", "{\"n\": 6348, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3482.06, \"learn_time_ms\": 45967.783}", "{\"n\": 6349, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3482.06, \"learn_time_ms\": 46009.548}", "{\"n\": 6350, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3483.4, \"learn_time_ms\": 45959.1}", "{\"n\": 6351, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.23, \"learn_time_ms\": 45972.241}", "{\"n\": 6352, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.23, \"learn_time_ms\": 45968.33}", "{\"n\": 6353, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3490.23, \"learn_time_ms\": 45991.44}", "{\"n\": 6354, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.27, \"learn_time_ms\": 46056.896}", "{\"n\": 6355, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3462.56, \"learn_time_ms\": 46061.577}", "{\"n\": 6356, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3459.75, \"learn_time_ms\": 45993.471}", "{\"n\": 6357, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3440.28, \"learn_time_ms\": 46090.056}", "{\"n\": 6358, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3456.41, \"learn_time_ms\": 45992.037}", "{\"n\": 6359, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.35, \"learn_time_ms\": 46055.325}", "{\"n\": 6360, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3471.17, \"learn_time_ms\": 46142.018}", "{\"n\": 6361, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3475.82, \"learn_time_ms\": 46095.069}", "{\"n\": 6362, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3467.4, \"learn_time_ms\": 46215.439}", "{\"n\": 6363, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3481.65, \"learn_time_ms\": 46244.97}", "{\"n\": 6364, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3471.94, \"learn_time_ms\": 46172.735}", "{\"n\": 6365, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.93, \"learn_time_ms\": 46249.622}", "{\"n\": 6366, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3449.93, \"learn_time_ms\": 46247.261}", "{\"n\": 6367, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3458.86, \"learn_time_ms\": 46222.343}", "{\"n\": 6368, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3447.76, \"learn_time_ms\": 46305.716}", "{\"n\": 6369, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3457.75, \"learn_time_ms\": 46261.147}", "{\"n\": 6370, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3463.02, \"learn_time_ms\": 46212.535}", "{\"n\": 6371, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3470.98, \"learn_time_ms\": 46129.931}", "{\"n\": 6372, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3466.87, \"learn_time_ms\": 45916.352}", "{\"n\": 6373, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.29, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3466.87, \"learn_time_ms\": 45903.35}", "{\"n\": 6374, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3482.96, \"learn_time_ms\": 46027.46}", "{\"n\": 6375, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3496.94, \"learn_time_ms\": 45966.679}", "{\"n\": 6376, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3509.64, \"learn_time_ms\": 46014.267}", "{\"n\": 6377, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.45, \"learn_time_ms\": 46035.18}", "{\"n\": 6378, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3519.45, \"learn_time_ms\": 45950.931}", "{\"n\": 6379, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3529.38, \"learn_time_ms\": 45974.791}", "{\"n\": 6380, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3529.38, \"learn_time_ms\": 46103.03}", "{\"n\": 6381, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3529.38, \"learn_time_ms\": 46292.172}", "{\"n\": 6382, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3527.09, \"learn_time_ms\": 46424.141}", "{\"n\": 6383, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3537.07, \"learn_time_ms\": 46425.496}", "{\"n\": 6384, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3547.64, \"learn_time_ms\": 46412.581}", "{\"n\": 6385, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3551.26, \"learn_time_ms\": 46429.147}", "{\"n\": 6386, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3551.26, \"learn_time_ms\": 46307.881}", "{\"n\": 6387, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3556.27, \"learn_time_ms\": 46276.043}", "{\"n\": 6388, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3580.51, \"learn_time_ms\": 46238.752}", "{\"n\": 6389, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.38, \"learn_time_ms\": 46294.104}", "{\"n\": 6390, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.38, \"learn_time_ms\": 46265.203}", "{\"n\": 6391, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3579.2, \"learn_time_ms\": 46271.904}", "{\"n\": 6392, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3579.2, \"learn_time_ms\": 46279.786}", "{\"n\": 6393, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3558.96, \"learn_time_ms\": 46330.93}", "{\"n\": 6394, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.17, \"learn_time_ms\": 46310.933}", "{\"n\": 6395, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.59, \"learn_time_ms\": 46323.228}", "{\"n\": 6396, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.59, \"learn_time_ms\": 46371.555}", "{\"n\": 6397, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3558.3, \"learn_time_ms\": 46321.919}", "{\"n\": 6398, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3558.82, \"learn_time_ms\": 46394.41}", "{\"n\": 6399, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.19, \"learn_time_ms\": 46326.488}", "{\"n\": 6400, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3544.24, \"learn_time_ms\": 46247.518}", "{\"n\": 6401, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3536.59, \"learn_time_ms\": 46222.976}", "{\"n\": 6402, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3535.23, \"learn_time_ms\": 46131.774}", "{\"n\": 6403, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3535.23, \"learn_time_ms\": 46026.846}", "{\"n\": 6404, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3526.69, \"learn_time_ms\": 46029.484}", "{\"n\": 6405, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3546.94, \"learn_time_ms\": 46020.238}", "{\"n\": 6406, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3541.63, \"learn_time_ms\": 46099.142}", "{\"n\": 6407, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.23, \"learn_time_ms\": 46167.353}", "{\"n\": 6408, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.23, \"learn_time_ms\": 46196.356}", "{\"n\": 6409, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.23, \"learn_time_ms\": 46142.865}", "{\"n\": 6410, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.09, \"learn_time_ms\": 46089.374}", "{\"n\": 6411, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3533.31, \"learn_time_ms\": 45982.183}", "{\"n\": 6412, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3528.98, \"learn_time_ms\": 45995.211}", "{\"n\": 6413, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3521.54, \"learn_time_ms\": 45985.628}", "{\"n\": 6414, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3521.54, \"learn_time_ms\": 45927.127}", "{\"n\": 6415, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3509.28, \"learn_time_ms\": 45940.426}", "{\"n\": 6416, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3502.89, \"learn_time_ms\": 45873.079}", "{\"n\": 6417, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3502.89, \"learn_time_ms\": 45939.254}", "{\"n\": 6418, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3464.84, \"learn_time_ms\": 45870.7}", "{\"n\": 6419, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.51, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3468.06, \"learn_time_ms\": 45891.724}", "{\"n\": 6420, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3481.88, \"learn_time_ms\": 46015.976}", "{\"n\": 6421, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3481.88, \"learn_time_ms\": 46075.037}", "{\"n\": 6422, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.53, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3465.22, \"learn_time_ms\": 46014.91}", "{\"n\": 6423, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3463.77, \"learn_time_ms\": 46032.212}", "{\"n\": 6424, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3499.83, \"learn_time_ms\": 45979.243}", "{\"n\": 6425, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3499.83, \"learn_time_ms\": 45967.929}", "{\"n\": 6426, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.4, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3499.83, \"learn_time_ms\": 45963.662}", "{\"n\": 6427, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3504.71, \"learn_time_ms\": 45846.746}", "{\"n\": 6428, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3504.49, \"learn_time_ms\": 45732.886}", "{\"n\": 6429, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3502.61, \"learn_time_ms\": 45768.334}", "{\"n\": 6430, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3520.77, \"learn_time_ms\": 45751.689}", "{\"n\": 6431, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3504.93, \"learn_time_ms\": 45612.632}", "{\"n\": 6432, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3504.93, \"learn_time_ms\": 45755.382}", "{\"n\": 6433, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3489.37, \"learn_time_ms\": 45770.219}", "{\"n\": 6434, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3476.75, \"learn_time_ms\": 45797.315}", "{\"n\": 6435, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3476.75, \"learn_time_ms\": 45746.367}", "{\"n\": 6436, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3477.55, \"learn_time_ms\": 45848.045}", "{\"n\": 6437, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.46, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3476.62, \"learn_time_ms\": 45794.751}", "{\"n\": 6438, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3496.87, \"learn_time_ms\": 45983.952}", "{\"n\": 6439, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3505.57, \"learn_time_ms\": 46015.865}", "{\"n\": 6440, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3520.43, \"learn_time_ms\": 45988.453}", "{\"n\": 6441, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3520.43, \"learn_time_ms\": 46053.607}", "{\"n\": 6442, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3528.89, \"learn_time_ms\": 46074.643}", "{\"n\": 6443, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.61, \"learn_time_ms\": 46040.95}", "{\"n\": 6444, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.77, \"learn_time_ms\": 46118.018}", "{\"n\": 6445, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3526.17, \"learn_time_ms\": 46191.351}", "{\"n\": 6446, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3526.17, \"learn_time_ms\": 46166.117}", "{\"n\": 6447, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3526.17, \"learn_time_ms\": 46209.803}", "{\"n\": 6448, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3510.01, \"learn_time_ms\": 46327.152}", "{\"n\": 6449, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3491.34, \"learn_time_ms\": 46319.953}", "{\"n\": 6450, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3501.59, \"learn_time_ms\": 46382.78}", "{\"n\": 6451, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3501.59, \"learn_time_ms\": 46508.03}", "{\"n\": 6452, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3502.96, \"learn_time_ms\": 46392.914}", "{\"n\": 6453, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3500.68, \"learn_time_ms\": 46472.371}", "{\"n\": 6454, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3500.99, \"learn_time_ms\": 46416.516}", "{\"n\": 6455, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3500.99, \"learn_time_ms\": 46335.769}", "{\"n\": 6456, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3518.24, \"learn_time_ms\": 46377.151}", "{\"n\": 6457, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.7, \"learn_time_ms\": 46460.092}", "{\"n\": 6458, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.7, \"learn_time_ms\": 46407.435}", "{\"n\": 6459, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3532.02, \"learn_time_ms\": 46359.009}", "{\"n\": 6460, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3522.11, \"learn_time_ms\": 46215.737}", "{\"n\": 6461, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3527.67, \"learn_time_ms\": 46113.284}", "{\"n\": 6462, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.23, \"learn_time_ms\": 46088.982}", "{\"n\": 6463, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3545.05, \"learn_time_ms\": 46115.935}", "{\"n\": 6464, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3542.47, \"learn_time_ms\": 46137.032}", "{\"n\": 6465, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3539.19, \"learn_time_ms\": 46127.892}", "{\"n\": 6466, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3538.15, \"learn_time_ms\": 46049.51}", "{\"n\": 6467, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.19, \"learn_time_ms\": 46080.112}", "{\"n\": 6468, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3530.76, \"learn_time_ms\": 46004.687}", "{\"n\": 6469, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3514.05, \"learn_time_ms\": 46086.145}", "{\"n\": 6470, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3508.32, \"learn_time_ms\": 46229.699}", "{\"n\": 6471, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3509.89, \"learn_time_ms\": 46329.003}", "{\"n\": 6472, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3510.0, \"learn_time_ms\": 46384.266}", "{\"n\": 6473, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3502.48, \"learn_time_ms\": 46353.804}", "{\"n\": 6474, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3492.82, \"learn_time_ms\": 46342.733}", "{\"n\": 6475, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3480.77, \"learn_time_ms\": 46302.75}", "{\"n\": 6476, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3480.77, \"learn_time_ms\": 46321.942}", "{\"n\": 6477, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3480.77, \"learn_time_ms\": 46249.992}", "{\"n\": 6478, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3477.78, \"learn_time_ms\": 46306.495}", "{\"n\": 6479, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3485.69, \"learn_time_ms\": 46348.72}", "{\"n\": 6480, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3494.52, \"learn_time_ms\": 46275.736}", "{\"n\": 6481, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3495.44, \"learn_time_ms\": 46318.79}", "{\"n\": 6482, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3523.26, \"learn_time_ms\": 46374.493}", "{\"n\": 6483, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3520.55, \"learn_time_ms\": 46331.2}", "{\"n\": 6484, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3509.5, \"learn_time_ms\": 46306.407}", "{\"n\": 6485, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3527.49, \"learn_time_ms\": 46479.759}", "{\"n\": 6486, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3520.53, \"learn_time_ms\": 46464.003}", "{\"n\": 6487, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3520.53, \"learn_time_ms\": 46486.481}", "{\"n\": 6488, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3517.36, \"learn_time_ms\": 46478.754}", "{\"n\": 6489, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3545.01, \"learn_time_ms\": 46389.221}", "{\"n\": 6490, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.1, \"learn_time_ms\": 46335.732}", "{\"n\": 6491, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3550.77, \"learn_time_ms\": 46147.8}", "{\"n\": 6492, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3536.46, \"learn_time_ms\": 46167.757}", "{\"n\": 6493, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3536.46, \"learn_time_ms\": 46127.632}", "{\"n\": 6494, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3569.86, \"learn_time_ms\": 46140.273}", "{\"n\": 6495, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3569.86, \"learn_time_ms\": 46128.381}", "{\"n\": 6496, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3570.92, \"learn_time_ms\": 46104.208}", "{\"n\": 6497, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3571.51, \"learn_time_ms\": 46128.889}", "{\"n\": 6498, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3542.17, \"learn_time_ms\": 46014.618}", "{\"n\": 6499, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3542.17, \"learn_time_ms\": 46055.88}", "{\"n\": 6500, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3535.92, \"learn_time_ms\": 46051.311}", "{\"n\": 6501, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3501.01, \"learn_time_ms\": 46178.909}", "{\"n\": 6502, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3512.91, \"learn_time_ms\": 46196.537}", "{\"n\": 6503, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3515.6, \"learn_time_ms\": 46156.198}", "{\"n\": 6504, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3514.74, \"learn_time_ms\": 46189.184}", "{\"n\": 6505, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3535.81, \"learn_time_ms\": 46112.38}", "{\"n\": 6506, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3549.59, \"learn_time_ms\": 46176.132}", "{\"n\": 6507, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3549.59, \"learn_time_ms\": 46135.314}", "{\"n\": 6508, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3560.44, \"learn_time_ms\": 46172.957}", "{\"n\": 6509, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3545.63, \"learn_time_ms\": 46082.72}", "{\"n\": 6510, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3545.63, \"learn_time_ms\": 45938.067}", "{\"n\": 6511, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3551.04, \"learn_time_ms\": 45906.605}", "{\"n\": 6512, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.56, \"learn_time_ms\": 45889.561}", "{\"n\": 6513, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.56, \"learn_time_ms\": 46017.257}", "{\"n\": 6514, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.56, \"learn_time_ms\": 46059.004}", "{\"n\": 6515, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.1, \"learn_time_ms\": 46167.076}", "{\"n\": 6516, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3531.55, \"learn_time_ms\": 46098.773}", "{\"n\": 6517, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3532.92, \"learn_time_ms\": 45985.8}", "{\"n\": 6518, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3552.87, \"learn_time_ms\": 45976.511}", "{\"n\": 6519, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3552.87, \"learn_time_ms\": 46059.644}", "{\"n\": 6520, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3549.08, \"learn_time_ms\": 46205.098}", "{\"n\": 6521, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3542.36, \"learn_time_ms\": 46097.503}", "{\"n\": 6522, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3559.06, \"learn_time_ms\": 45969.693}", "{\"n\": 6523, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3532.75, \"learn_time_ms\": 45932.873}", "{\"n\": 6524, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3526.5, \"learn_time_ms\": 45911.939}", "{\"n\": 6525, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3530.71, \"learn_time_ms\": 45777.173}", "{\"n\": 6526, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3521.47, \"learn_time_ms\": 45708.593}", "{\"n\": 6527, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3516.32, \"learn_time_ms\": 45811.942}", "{\"n\": 6528, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3505.88, \"learn_time_ms\": 45837.452}", "{\"n\": 6529, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3501.5, \"learn_time_ms\": 45846.711}", "{\"n\": 6530, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3490.09, \"learn_time_ms\": 45891.979}", "{\"n\": 6531, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3497.71, \"learn_time_ms\": 46056.737}", "{\"n\": 6532, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3498.52, \"learn_time_ms\": 46088.015}", "{\"n\": 6533, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3495.23, \"learn_time_ms\": 46134.149}", "{\"n\": 6534, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3488.06, \"learn_time_ms\": 46025.761}", "{\"n\": 6535, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3471.0, \"learn_time_ms\": 45938.564}", "{\"n\": 6536, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3468.1, \"learn_time_ms\": 45976.948}", "{\"n\": 6537, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3470.24, \"learn_time_ms\": 45943.25}", "{\"n\": 6538, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3494.38, \"learn_time_ms\": 45923.658}", "{\"n\": 6539, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3494.38, \"learn_time_ms\": 45835.02}", "{\"n\": 6540, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3494.38, \"learn_time_ms\": 45809.923}", "{\"n\": 6541, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3494.38, \"learn_time_ms\": 45820.445}", "{\"n\": 6542, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3511.2, \"learn_time_ms\": 45851.698}", "{\"n\": 6543, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3518.64, \"learn_time_ms\": 45767.92}", "{\"n\": 6544, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3521.96, \"learn_time_ms\": 45766.764}", "{\"n\": 6545, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3521.96, \"learn_time_ms\": 45881.582}", "{\"n\": 6546, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3521.67, \"learn_time_ms\": 45896.729}", "{\"n\": 6547, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.85, \"learn_time_ms\": 45928.284}", "{\"n\": 6548, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3531.87, \"learn_time_ms\": 45983.99}", "{\"n\": 6549, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3534.47, \"learn_time_ms\": 46002.6}", "{\"n\": 6550, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3531.77, \"learn_time_ms\": 46085.588}", "{\"n\": 6551, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3531.77, \"learn_time_ms\": 46030.809}", "{\"n\": 6552, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3534.7, \"learn_time_ms\": 46046.784}", "{\"n\": 6553, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3523.02, \"learn_time_ms\": 46157.636}", "{\"n\": 6554, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3507.42, \"learn_time_ms\": 46199.777}", "{\"n\": 6555, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3508.57, \"learn_time_ms\": 46178.21}", "{\"n\": 6556, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3520.16, \"learn_time_ms\": 46139.893}", "{\"n\": 6557, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3526.37, \"learn_time_ms\": 46112.239}", "{\"n\": 6558, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.35, \"learn_time_ms\": 46137.959}", "{\"n\": 6559, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.35, \"learn_time_ms\": 46180.745}", "{\"n\": 6560, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3547.92, \"learn_time_ms\": 46131.998}", "{\"n\": 6561, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3548.08, \"learn_time_ms\": 46026.901}", "{\"n\": 6562, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3523.54, \"learn_time_ms\": 46081.124}", "{\"n\": 6563, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3517.76, \"learn_time_ms\": 45942.563}", "{\"n\": 6564, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3537.0, \"learn_time_ms\": 46003.725}", "{\"n\": 6565, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3531.73, \"learn_time_ms\": 45998.479}", "{\"n\": 6566, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3509.94, \"learn_time_ms\": 46017.4}", "{\"n\": 6567, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3502.76, \"learn_time_ms\": 46096.12}", "{\"n\": 6568, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3495.5, \"learn_time_ms\": 45973.356}", "{\"n\": 6569, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.19, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3495.5, \"learn_time_ms\": 46005.327}", "{\"n\": 6570, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3511.34, \"learn_time_ms\": 45989.273}", "{\"n\": 6571, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3511.34, \"learn_time_ms\": 46136.849}", "{\"n\": 6572, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3522.26, \"learn_time_ms\": 46075.199}", "{\"n\": 6573, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3534.16, \"learn_time_ms\": 46181.131}", "{\"n\": 6574, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3546.4, \"learn_time_ms\": 46206.359}", "{\"n\": 6575, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3539.17, \"learn_time_ms\": 46245.916}", "{\"n\": 6576, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3534.26, \"learn_time_ms\": 46331.207}", "{\"n\": 6577, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3525.7, \"learn_time_ms\": 46330.393}", "{\"n\": 6578, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3515.35, \"learn_time_ms\": 46415.387}", "{\"n\": 6579, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3515.35, \"learn_time_ms\": 46252.794}", "{\"n\": 6580, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3514.63, \"learn_time_ms\": 46338.424}", "{\"n\": 6581, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.21, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3514.63, \"learn_time_ms\": 46327.562}", "{\"n\": 6582, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3521.72, \"learn_time_ms\": 46293.144}", "{\"n\": 6583, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3521.72, \"learn_time_ms\": 46295.174}", "{\"n\": 6584, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.23, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3506.57, \"learn_time_ms\": 46249.151}", "{\"n\": 6585, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3499.28, \"learn_time_ms\": 46302.111}", "{\"n\": 6586, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3499.28, \"learn_time_ms\": 46343.942}", "{\"n\": 6587, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.3, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3499.28, \"learn_time_ms\": 46296.098}", "{\"n\": 6588, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.35, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.48, \"learn_time_ms\": 46280.641}", "{\"n\": 6589, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3491.65, \"learn_time_ms\": 46411.935}", "{\"n\": 6590, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3491.07, \"learn_time_ms\": 46339.765}", "{\"n\": 6591, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.41, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3484.45, \"learn_time_ms\": 46313.917}", "{\"n\": 6592, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.48, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3474.07, \"learn_time_ms\": 46369.176}", "{\"n\": 6593, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.42, \"learn_time_ms\": 46398.968}", "{\"n\": 6594, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3488.42, \"learn_time_ms\": 46458.482}", "{\"n\": 6595, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.36, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3486.87, \"learn_time_ms\": 46437.461}", "{\"n\": 6596, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.33, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3485.18, \"learn_time_ms\": 46387.96}", "{\"n\": 6597, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3507.43, \"learn_time_ms\": 46392.35}", "{\"n\": 6598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3526.12, \"learn_time_ms\": 46400.671}", "{\"n\": 6599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3526.12, \"learn_time_ms\": 46484.382}", "{\"n\": 6600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3523.27, \"learn_time_ms\": 46442.4}", "{\"n\": 6601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3523.27, \"learn_time_ms\": 46420.362}", "{\"n\": 6602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3523.27, \"learn_time_ms\": 46417.384}", "{\"n\": 6603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3527.14, \"learn_time_ms\": 46385.015}", "{\"n\": 6604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3540.19, \"learn_time_ms\": 46363.471}", "{\"n\": 6605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3522.18, \"learn_time_ms\": 46367.439}", "{\"n\": 6606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3522.18, \"learn_time_ms\": 46310.713}", "{\"n\": 6607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.17, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3522.18, \"learn_time_ms\": 46319.688}", "{\"n\": 6608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3533.91, \"learn_time_ms\": 46251.031}", "{\"n\": 6609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3543.85, \"learn_time_ms\": 46195.985}", "{\"n\": 6610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3547.13, \"learn_time_ms\": 46192.123}", "{\"n\": 6611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3537.45, \"learn_time_ms\": 46226.55}", "{\"n\": 6612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3537.45, \"learn_time_ms\": 46303.951}", "{\"n\": 6613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3537.45, \"learn_time_ms\": 46319.348}", "{\"n\": 6614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3522.9, \"learn_time_ms\": 46343.172}", "{\"n\": 6615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3512.56, \"learn_time_ms\": 46261.005}", "{\"n\": 6616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3519.23, \"learn_time_ms\": 46295.363}", "{\"n\": 6617, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3542.37, \"learn_time_ms\": 46304.252}", "{\"n\": 6618, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3542.37, \"learn_time_ms\": 46373.139}", "{\"n\": 6619, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3546.49, \"learn_time_ms\": 46298.401}", "{\"n\": 6620, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3545.98, \"learn_time_ms\": 46395.196}", "{\"n\": 6621, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3549.11, \"learn_time_ms\": 46302.069}", "{\"n\": 6622, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3543.43, \"learn_time_ms\": 46226.818}", "{\"n\": 6623, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3545.43, \"learn_time_ms\": 46127.8}", "{\"n\": 6624, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3521.84, \"learn_time_ms\": 46033.576}", "{\"n\": 6625, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3535.48, \"learn_time_ms\": 46095.748}", "{\"n\": 6626, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3527.79, \"learn_time_ms\": 46166.693}", "{\"n\": 6627, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3527.79, \"learn_time_ms\": 46152.494}", "{\"n\": 6628, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3517.21, \"learn_time_ms\": 46092.654}", "{\"n\": 6629, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3517.21, \"learn_time_ms\": 46107.111}", "{\"n\": 6630, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3491.6, \"learn_time_ms\": 46089.859}", "{\"n\": 6631, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3493.04, \"learn_time_ms\": 46196.78}", "{\"n\": 6632, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3482.55, \"learn_time_ms\": 46099.464}", "{\"n\": 6633, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3485.07, \"learn_time_ms\": 46184.865}", "{\"n\": 6634, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3487.09, \"learn_time_ms\": 46258.188}", "{\"n\": 6635, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3492.0, \"learn_time_ms\": 46179.549}", "{\"n\": 6636, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3498.02, \"learn_time_ms\": 46138.239}", "{\"n\": 6637, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3495.49, \"learn_time_ms\": 46255.38}", "{\"n\": 6638, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3510.7, \"learn_time_ms\": 46273.15}", "{\"n\": 6639, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3542.65, \"learn_time_ms\": 46325.705}", "{\"n\": 6640, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3560.39, \"learn_time_ms\": 46408.672}", "{\"n\": 6641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3560.39, \"learn_time_ms\": 46280.928}", "{\"n\": 6642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3557.97, \"learn_time_ms\": 46311.834}", "{\"n\": 6643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3555.85, \"learn_time_ms\": 46171.976}", "{\"n\": 6644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3544.59, \"learn_time_ms\": 46288.376}", "{\"n\": 6645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3544.59, \"learn_time_ms\": 46363.664}", "{\"n\": 6646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3569.72, \"learn_time_ms\": 46325.98}", "{\"n\": 6647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3581.5, \"learn_time_ms\": 46160.062}", "{\"n\": 6648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3585.06, \"learn_time_ms\": 46191.868}", "{\"n\": 6649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3585.06, \"learn_time_ms\": 46193.454}", "{\"n\": 6650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3593.51, \"learn_time_ms\": 46080.063}", "{\"n\": 6651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3593.51, \"learn_time_ms\": 46103.167}", "{\"n\": 6652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3585.63, \"learn_time_ms\": 46091.766}", "{\"n\": 6653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3570.12, \"learn_time_ms\": 46197.125}", "{\"n\": 6654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3571.96, \"learn_time_ms\": 45942.964}", "{\"n\": 6655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3576.01, \"learn_time_ms\": 45942.427}", "{\"n\": 6656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3585.66, \"learn_time_ms\": 45913.743}", "{\"n\": 6657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3584.98, \"learn_time_ms\": 46001.109}", "{\"n\": 6658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3592.82, \"learn_time_ms\": 46068.14}", "{\"n\": 6659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3592.82, \"learn_time_ms\": 46001.537}", "{\"n\": 6660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3612.42, \"learn_time_ms\": 45899.575}", "{\"n\": 6661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3594.48, \"learn_time_ms\": 45877.38}", "{\"n\": 6662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3595.47, \"learn_time_ms\": 45968.651}", "{\"n\": 6663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3595.47, \"learn_time_ms\": 45951.174}", "{\"n\": 6664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3590.03, \"learn_time_ms\": 46035.532}", "{\"n\": 6665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3591.88, \"learn_time_ms\": 45979.299}", "{\"n\": 6666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3591.88, \"learn_time_ms\": 45943.827}", "{\"n\": 6667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3603.89, \"learn_time_ms\": 45899.007}", "{\"n\": 6668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3592.24, \"learn_time_ms\": 45867.123}", "{\"n\": 6669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3592.24, \"learn_time_ms\": 45941.181}", "{\"n\": 6670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3583.35, \"learn_time_ms\": 46131.65}", "{\"n\": 6671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3583.35, \"learn_time_ms\": 46228.553}", "{\"n\": 6672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3574.88, \"learn_time_ms\": 46233.912}", "{\"n\": 6673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3577.11, \"learn_time_ms\": 46302.452}", "{\"n\": 6674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3581.96, \"learn_time_ms\": 46299.781}", "{\"n\": 6675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.55, \"learn_time_ms\": 46268.962}", "{\"n\": 6676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.55, \"learn_time_ms\": 46306.007}", "{\"n\": 6677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.55, \"learn_time_ms\": 46255.29}", "{\"n\": 6678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3579.04, \"learn_time_ms\": 46077.366}", "{\"n\": 6679, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3549.06, \"learn_time_ms\": 46000.611}", "{\"n\": 6680, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3546.46, \"learn_time_ms\": 45898.466}", "{\"n\": 6681, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3551.47, \"learn_time_ms\": 45884.724}", "{\"n\": 6682, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3551.47, \"learn_time_ms\": 45729.688}", "{\"n\": 6683, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3532.06, \"learn_time_ms\": 45745.551}", "{\"n\": 6684, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3532.06, \"learn_time_ms\": 45876.984}", "{\"n\": 6685, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3532.06, \"learn_time_ms\": 45916.198}", "{\"n\": 6686, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3537.32, \"learn_time_ms\": 45973.26}", "{\"n\": 6687, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3528.05, \"learn_time_ms\": 46044.949}", "{\"n\": 6688, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3545.29, \"learn_time_ms\": 46178.094}", "{\"n\": 6689, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3533.96, \"learn_time_ms\": 46193.126}", "{\"n\": 6690, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3533.96, \"learn_time_ms\": 46246.787}", "{\"n\": 6691, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3537.47, \"learn_time_ms\": 46289.213}", "{\"n\": 6692, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3534.26, \"learn_time_ms\": 46337.268}", "{\"n\": 6693, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3548.89, \"learn_time_ms\": 46160.975}", "{\"n\": 6694, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3548.89, \"learn_time_ms\": 46042.296}", "{\"n\": 6695, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3548.89, \"learn_time_ms\": 46113.124}", "{\"n\": 6696, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.73, \"learn_time_ms\": 46076.162}", "{\"n\": 6697, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.73, \"learn_time_ms\": 46066.962}", "{\"n\": 6698, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3569.7, \"learn_time_ms\": 46010.634}", "{\"n\": 6699, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3581.74, \"learn_time_ms\": 46046.182}", "{\"n\": 6700, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.98, \"learn_time_ms\": 46099.512}", "{\"n\": 6701, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.98, \"learn_time_ms\": 46068.831}", "{\"n\": 6702, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.98, \"learn_time_ms\": 46093.086}", "{\"n\": 6703, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3590.66, \"learn_time_ms\": 46241.413}", "{\"n\": 6704, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3618.41, \"learn_time_ms\": 46282.03}", "{\"n\": 6705, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3615.88, \"learn_time_ms\": 46257.436}", "{\"n\": 6706, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3604.76, \"learn_time_ms\": 46255.151}", "{\"n\": 6707, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3608.33, \"learn_time_ms\": 46312.031}", "{\"n\": 6708, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3611.37, \"learn_time_ms\": 46361.98}", "{\"n\": 6709, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3611.37, \"learn_time_ms\": 46358.363}", "{\"n\": 6710, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3609.65, \"learn_time_ms\": 46144.304}", "{\"n\": 6711, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3598.16, \"learn_time_ms\": 46107.334}", "{\"n\": 6712, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3582.08, \"learn_time_ms\": 46107.423}", "{\"n\": 6713, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3579.77, \"learn_time_ms\": 46056.313}", "{\"n\": 6714, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3575.12, \"learn_time_ms\": 46054.414}", "{\"n\": 6715, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3575.12, \"learn_time_ms\": 45968.405}", "{\"n\": 6716, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3575.12, \"learn_time_ms\": 46065.582}", "{\"n\": 6717, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3582.27, \"learn_time_ms\": 46047.503}", "{\"n\": 6718, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3583.1, \"learn_time_ms\": 46045.733}", "{\"n\": 6719, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3555.98, \"learn_time_ms\": 46020.996}", "{\"n\": 6720, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3537.89, \"learn_time_ms\": 46087.244}", "{\"n\": 6721, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3552.52, \"learn_time_ms\": 46138.802}", "{\"n\": 6722, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3543.37, \"learn_time_ms\": 46176.568}", "{\"n\": 6723, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3550.81, \"learn_time_ms\": 46192.95}", "{\"n\": 6724, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3556.07, \"learn_time_ms\": 46219.064}", "{\"n\": 6725, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3546.91, \"learn_time_ms\": 46221.82}", "{\"n\": 6726, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3562.71, \"learn_time_ms\": 46190.044}", "{\"n\": 6727, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3562.71, \"learn_time_ms\": 46109.533}", "{\"n\": 6728, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3562.42, \"learn_time_ms\": 46203.705}", "{\"n\": 6729, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3560.7, \"learn_time_ms\": 46227.653}", "{\"n\": 6730, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3552.24, \"learn_time_ms\": 46279.589}", "{\"n\": 6731, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3547.8, \"learn_time_ms\": 46259.188}", "{\"n\": 6732, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3547.8, \"learn_time_ms\": 46185.923}", "{\"n\": 6733, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3528.0, \"learn_time_ms\": 46131.581}", "{\"n\": 6734, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3539.24, \"learn_time_ms\": 46084.203}", "{\"n\": 6735, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3557.59, \"learn_time_ms\": 46140.007}", "{\"n\": 6736, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3557.59, \"learn_time_ms\": 46116.397}", "{\"n\": 6737, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3560.93, \"learn_time_ms\": 46249.982}", "{\"n\": 6738, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3543.32, \"learn_time_ms\": 46152.871}", "{\"n\": 6739, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3543.32, \"learn_time_ms\": 46147.168}", "{\"n\": 6740, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3534.51, \"learn_time_ms\": 46161.779}", "{\"n\": 6741, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3529.01, \"learn_time_ms\": 46231.567}", "{\"n\": 6742, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3538.69, \"learn_time_ms\": 46228.753}", "{\"n\": 6743, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3537.08, \"learn_time_ms\": 46180.628}", "{\"n\": 6744, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3537.08, \"learn_time_ms\": 46240.571}", "{\"n\": 6745, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3519.28, \"learn_time_ms\": 46223.157}", "{\"n\": 6746, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3509.44, \"learn_time_ms\": 46070.597}", "{\"n\": 6747, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3506.48, \"learn_time_ms\": 45915.018}", "{\"n\": 6748, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3507.04, \"learn_time_ms\": 45927.362}", "{\"n\": 6749, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3507.04, \"learn_time_ms\": 45840.116}", "{\"n\": 6750, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3507.04, \"learn_time_ms\": 45798.717}", "{\"n\": 6751, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3505.65, \"learn_time_ms\": 45764.502}", "{\"n\": 6752, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.34, \"learn_time_ms\": 45917.14}", "{\"n\": 6753, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3547.39, \"learn_time_ms\": 46017.47}", "{\"n\": 6754, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3550.08, \"learn_time_ms\": 45901.035}", "{\"n\": 6755, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3544.5, \"learn_time_ms\": 45855.171}", "{\"n\": 6756, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.97, \"learn_time_ms\": 45874.433}", "{\"n\": 6757, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3536.97, \"learn_time_ms\": 45884.903}", "{\"n\": 6758, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3558.99, \"learn_time_ms\": 45908.722}", "{\"n\": 6759, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3541.23, \"learn_time_ms\": 46015.309}", "{\"n\": 6760, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3546.8, \"learn_time_ms\": 46054.969}", "{\"n\": 6761, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3544.24, \"learn_time_ms\": 46081.643}", "{\"n\": 6762, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3553.71, \"learn_time_ms\": 46034.999}", "{\"n\": 6763, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3553.71, \"learn_time_ms\": 46110.992}", "{\"n\": 6764, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3553.71, \"learn_time_ms\": 46169.296}", "{\"n\": 6765, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3561.45, \"learn_time_ms\": 46286.787}", "{\"n\": 6766, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3577.66, \"learn_time_ms\": 46490.814}", "{\"n\": 6767, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3600.17, \"learn_time_ms\": 46584.491}", "{\"n\": 6768, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3600.17, \"learn_time_ms\": 46584.14}", "{\"n\": 6769, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3592.65, \"learn_time_ms\": 46558.698}", "{\"n\": 6770, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.57, \"learn_time_ms\": 46475.674}", "{\"n\": 6771, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.57, \"learn_time_ms\": 46300.207}", "{\"n\": 6772, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.85, \"learn_time_ms\": 46213.583}", "{\"n\": 6773, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.0, \"learn_time_ms\": 46194.01}", "{\"n\": 6774, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.0, \"learn_time_ms\": 46209.07}", "{\"n\": 6775, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3630.91, \"learn_time_ms\": 46116.727}", "{\"n\": 6776, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3640.04, \"learn_time_ms\": 46142.766}", "{\"n\": 6777, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.1, \"learn_time_ms\": 46053.208}", "{\"n\": 6778, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.1, \"learn_time_ms\": 46030.51}", "{\"n\": 6779, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3615.45, \"learn_time_ms\": 46114.156}", "{\"n\": 6780, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3626.8, \"learn_time_ms\": 46275.113}", "{\"n\": 6781, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3626.8, \"learn_time_ms\": 46241.116}", "{\"n\": 6782, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3624.05, \"learn_time_ms\": 46392.305}", "{\"n\": 6783, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.08, \"learn_time_ms\": 46343.126}", "{\"n\": 6784, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.08, \"learn_time_ms\": 46209.23}", "{\"n\": 6785, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3612.63, \"learn_time_ms\": 46371.158}", "{\"n\": 6786, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.4, \"learn_time_ms\": 46251.036}", "{\"n\": 6787, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3608.15, \"learn_time_ms\": 46363.528}", "{\"n\": 6788, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3608.15, \"learn_time_ms\": 46408.473}", "{\"n\": 6789, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3607.62, \"learn_time_ms\": 46332.172}", "{\"n\": 6790, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.98, \"learn_time_ms\": 46241.733}", "{\"n\": 6791, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3624.02, \"learn_time_ms\": 46448.062}", "{\"n\": 6792, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3607.33, \"learn_time_ms\": 46351.461}", "{\"n\": 6793, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3610.37, \"learn_time_ms\": 46293.943}", "{\"n\": 6794, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3625.37, \"learn_time_ms\": 46448.512}", "{\"n\": 6795, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3625.37, \"learn_time_ms\": 46309.843}", "{\"n\": 6796, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3625.98, \"learn_time_ms\": 46328.403}", "{\"n\": 6797, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.14, \"learn_time_ms\": 46218.452}", "{\"n\": 6798, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.14, \"learn_time_ms\": 46086.804}", "{\"n\": 6799, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.14, \"learn_time_ms\": 46141.575}", "{\"n\": 6800, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.88, \"learn_time_ms\": 46168.179}", "{\"n\": 6801, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.79, \"learn_time_ms\": 46102.937}", "{\"n\": 6802, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3612.33, \"learn_time_ms\": 46101.282}", "{\"n\": 6803, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.49, \"learn_time_ms\": 46185.958}", "{\"n\": 6804, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.49, \"learn_time_ms\": 46125.561}", "{\"n\": 6805, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3616.53, \"learn_time_ms\": 46089.071}", "{\"n\": 6806, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.73, \"learn_time_ms\": 46165.671}", "{\"n\": 6807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3642.46, \"learn_time_ms\": 46194.674}", "{\"n\": 6808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3642.46, \"learn_time_ms\": 46277.062}", "{\"n\": 6809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.48, \"learn_time_ms\": 46257.762}", "{\"n\": 6810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.95, \"learn_time_ms\": 46173.189}", "{\"n\": 6811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.39, \"learn_time_ms\": 46090.28}", "{\"n\": 6812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3613.65, \"learn_time_ms\": 46138.535}", "{\"n\": 6813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3644.01, \"learn_time_ms\": 46128.97}", "{\"n\": 6814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.82, \"learn_time_ms\": 46186.587}", "{\"n\": 6815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.82, \"learn_time_ms\": 46250.862}", "{\"n\": 6816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3639.98, \"learn_time_ms\": 46247.242}", "{\"n\": 6817, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.37, \"learn_time_ms\": 46214.619}", "{\"n\": 6818, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.96, \"learn_time_ms\": 46282.403}", "{\"n\": 6819, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.32, \"learn_time_ms\": 46347.228}", "{\"n\": 6820, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.01, \"learn_time_ms\": 46415.131}", "{\"n\": 6821, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.01, \"learn_time_ms\": 46563.982}", "{\"n\": 6822, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.01, \"learn_time_ms\": 46549.322}", "{\"n\": 6823, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3615.64, \"learn_time_ms\": 46403.26}", "{\"n\": 6824, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3635.53, \"learn_time_ms\": 46362.681}", "{\"n\": 6825, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3630.94, \"learn_time_ms\": 46398.838}", "{\"n\": 6826, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.63, \"learn_time_ms\": 46265.198}", "{\"n\": 6827, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.44, \"learn_time_ms\": 46289.033}", "{\"n\": 6828, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.75, \"learn_time_ms\": 46271.601}", "{\"n\": 6829, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3619.75, \"learn_time_ms\": 46163.337}", "{\"n\": 6830, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.89, \"learn_time_ms\": 46258.04}", "{\"n\": 6831, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.16, \"learn_time_ms\": 46229.59}", "{\"n\": 6832, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.67, \"learn_time_ms\": 46140.708}", "{\"n\": 6833, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3607.91, \"learn_time_ms\": 46305.621}", "{\"n\": 6834, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.2, \"learn_time_ms\": 46309.277}", "{\"n\": 6835, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.06, \"learn_time_ms\": 46315.851}", "{\"n\": 6836, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.27, \"learn_time_ms\": 46397.501}", "{\"n\": 6837, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3619.57, \"learn_time_ms\": 46452.909}", "{\"n\": 6838, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3619.1, \"learn_time_ms\": 46417.572}", "{\"n\": 6839, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3591.58, \"learn_time_ms\": 46366.73}", "{\"n\": 6840, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3589.91, \"learn_time_ms\": 46193.761}", "{\"n\": 6841, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3579.04, \"learn_time_ms\": 46165.201}", "{\"n\": 6842, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3568.15, \"learn_time_ms\": 46269.405}", "{\"n\": 6843, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3563.84, \"learn_time_ms\": 46293.715}", "{\"n\": 6844, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.93, \"learn_time_ms\": 46327.969}", "{\"n\": 6845, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3539.14, \"learn_time_ms\": 46317.39}", "{\"n\": 6846, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3539.14, \"learn_time_ms\": 46292.937}", "{\"n\": 6847, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3541.64, \"learn_time_ms\": 46329.149}", "{\"n\": 6848, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3541.64, \"learn_time_ms\": 46318.83}", "{\"n\": 6849, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3546.6, \"learn_time_ms\": 46383.006}", "{\"n\": 6850, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3536.59, \"learn_time_ms\": 46464.424}", "{\"n\": 6851, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3555.14, \"learn_time_ms\": 46380.365}", "{\"n\": 6852, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3549.79, \"learn_time_ms\": 46316.045}", "{\"n\": 6853, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.84, \"learn_time_ms\": 46289.488}", "{\"n\": 6854, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.84, \"learn_time_ms\": 46311.494}", "{\"n\": 6855, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3557.73, \"learn_time_ms\": 46234.507}", "{\"n\": 6856, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3557.73, \"learn_time_ms\": 46183.39}", "{\"n\": 6857, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3575.62, \"learn_time_ms\": 46178.574}", "{\"n\": 6858, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3586.69, \"learn_time_ms\": 46192.892}", "{\"n\": 6859, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3594.5, \"learn_time_ms\": 46227.994}", "{\"n\": 6860, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3594.5, \"learn_time_ms\": 46205.171}", "{\"n\": 6861, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3602.42, \"learn_time_ms\": 46257.166}", "{\"n\": 6862, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3602.42, \"learn_time_ms\": 46272.735}", "{\"n\": 6863, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3595.96, \"learn_time_ms\": 46201.472}", "{\"n\": 6864, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3582.86, \"learn_time_ms\": 46115.082}", "{\"n\": 6865, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3575.02, \"learn_time_ms\": 46185.234}", "{\"n\": 6866, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3574.11, \"learn_time_ms\": 46199.287}", "{\"n\": 6867, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3587.64, \"learn_time_ms\": 46156.865}", "{\"n\": 6868, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.49, \"learn_time_ms\": 46150.988}", "{\"n\": 6869, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3583.94, \"learn_time_ms\": 46075.537}", "{\"n\": 6870, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3585.58, \"learn_time_ms\": 46166.227}", "{\"n\": 6871, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3581.3, \"learn_time_ms\": 46193.441}", "{\"n\": 6872, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3577.45, \"learn_time_ms\": 46074.257}", "{\"n\": 6873, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3578.42, \"learn_time_ms\": 46033.881}", "{\"n\": 6874, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3578.42, \"learn_time_ms\": 46156.288}", "{\"n\": 6875, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3578.88, \"learn_time_ms\": 46163.927}", "{\"n\": 6876, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3578.88, \"learn_time_ms\": 46208.004}", "{\"n\": 6877, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3579.83, \"learn_time_ms\": 46241.158}", "{\"n\": 6878, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3572.65, \"learn_time_ms\": 46207.936}", "{\"n\": 6879, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3572.65, \"learn_time_ms\": 46251.724}", "{\"n\": 6880, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.31, \"learn_time_ms\": 46253.434}", "{\"n\": 6881, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3578.31, \"learn_time_ms\": 46317.317}", "{\"n\": 6882, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3576.27, \"learn_time_ms\": 46469.983}", "{\"n\": 6883, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3576.27, \"learn_time_ms\": 46535.271}", "{\"n\": 6884, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3584.85, \"learn_time_ms\": 46385.152}", "{\"n\": 6885, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3584.85, \"learn_time_ms\": 46330.223}", "{\"n\": 6886, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3595.67, \"learn_time_ms\": 46244.519}", "{\"n\": 6887, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3611.03, \"learn_time_ms\": 46257.164}", "{\"n\": 6888, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3616.28, \"learn_time_ms\": 46240.481}", "{\"n\": 6889, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3628.2, \"learn_time_ms\": 46130.265}", "{\"n\": 6890, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3621.11, \"learn_time_ms\": 45973.664}", "{\"n\": 6891, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3642.03, \"learn_time_ms\": 45910.588}", "{\"n\": 6892, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3656.24, \"learn_time_ms\": 45960.168}", "{\"n\": 6893, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3657.45, \"learn_time_ms\": 46021.182}", "{\"n\": 6894, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3677.43, \"learn_time_ms\": 46113.631}", "{\"n\": 6895, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3677.43, \"learn_time_ms\": 46153.812}", "{\"n\": 6896, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3705.08, \"learn_time_ms\": 46170.982}", "{\"n\": 6897, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3707.28, \"learn_time_ms\": 46154.62}", "{\"n\": 6898, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3701.0, \"learn_time_ms\": 46167.489}", "{\"n\": 6899, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3696.51, \"learn_time_ms\": 46222.937}", "{\"n\": 6900, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3696.51, \"learn_time_ms\": 46310.057}", "{\"n\": 6901, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3696.51, \"learn_time_ms\": 46358.951}", "{\"n\": 6902, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3672.36, \"learn_time_ms\": 46310.253}", "{\"n\": 6903, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3665.1, \"learn_time_ms\": 46261.047}", "{\"n\": 6904, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3665.1, \"learn_time_ms\": 46338.16}", "{\"n\": 6905, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3663.72, \"learn_time_ms\": 46370.418}", "{\"n\": 6906, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3671.33, \"learn_time_ms\": 46442.688}", "{\"n\": 6907, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3671.33, \"learn_time_ms\": 46424.54}", "{\"n\": 6908, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3682.75, \"learn_time_ms\": 46442.733}", "{\"n\": 6909, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3685.5, \"learn_time_ms\": 46509.947}", "{\"n\": 6910, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3718.9, \"learn_time_ms\": 46520.937}", "{\"n\": 6911, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3726.54, \"learn_time_ms\": 46503.792}", "{\"n\": 6912, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3765.61, \"learn_time_ms\": 46546.756}", "{\"n\": 6913, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3765.61, \"learn_time_ms\": 46540.127}", "{\"n\": 6914, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3762.55, \"learn_time_ms\": 46470.258}", "{\"n\": 6915, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3762.55, \"learn_time_ms\": 46399.367}", "{\"n\": 6916, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3762.55, \"learn_time_ms\": 46448.968}", "{\"n\": 6917, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3789.06, \"learn_time_ms\": 46430.558}", "{\"n\": 6918, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3791.27, \"learn_time_ms\": 46491.729}", "{\"n\": 6919, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3783.63, \"learn_time_ms\": 46526.652}", "{\"n\": 6920, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3772.2, \"learn_time_ms\": 46571.583}", "{\"n\": 6921, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3748.65, \"learn_time_ms\": 46588.776}", "{\"n\": 6922, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3748.65, \"learn_time_ms\": 46491.565}", "{\"n\": 6923, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3745.08, \"learn_time_ms\": 46368.296}", "{\"n\": 6924, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3725.23, \"learn_time_ms\": 46427.296}", "{\"n\": 6925, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3725.23, \"learn_time_ms\": 46462.17}", "{\"n\": 6926, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3719.95, \"learn_time_ms\": 46313.173}", "{\"n\": 6927, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3727.9, \"learn_time_ms\": 46328.187}", "{\"n\": 6928, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3705.22, \"learn_time_ms\": 46273.312}", "{\"n\": 6929, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3705.22, \"learn_time_ms\": 46216.214}", "{\"n\": 6930, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3705.22, \"learn_time_ms\": 46096.553}", "{\"n\": 6931, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3675.16, \"learn_time_ms\": 46031.151}", "{\"n\": 6932, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3678.63, \"learn_time_ms\": 45967.913}", "{\"n\": 6933, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3686.08, \"learn_time_ms\": 46145.522}", "{\"n\": 6934, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3686.08, \"learn_time_ms\": 45994.631}", "{\"n\": 6935, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3669.88, \"learn_time_ms\": 45930.869}", "{\"n\": 6936, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3673.42, \"learn_time_ms\": 46028.678}", "{\"n\": 6937, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3687.19, \"learn_time_ms\": 45955.285}", "{\"n\": 6938, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3687.19, \"learn_time_ms\": 45952.425}", "{\"n\": 6939, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3682.42, \"learn_time_ms\": 45887.992}", "{\"n\": 6940, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3673.59, \"learn_time_ms\": 45938.968}", "{\"n\": 6941, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3679.91, \"learn_time_ms\": 46011.552}", "{\"n\": 6942, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3661.38, \"learn_time_ms\": 46077.831}", "{\"n\": 6943, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3658.15, \"learn_time_ms\": 46003.39}", "{\"n\": 6944, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3648.34, \"learn_time_ms\": 46124.046}", "{\"n\": 6945, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3643.14, \"learn_time_ms\": 46137.177}", "{\"n\": 6946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3623.12, \"learn_time_ms\": 46146.23}", "{\"n\": 6947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3623.12, \"learn_time_ms\": 46245.102}", "{\"n\": 6948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3637.38, \"learn_time_ms\": 46139.486}", "{\"n\": 6949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3632.88, \"learn_time_ms\": 46279.617}", "{\"n\": 6950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3629.42, \"learn_time_ms\": 46282.082}", "{\"n\": 6951, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3616.85, \"learn_time_ms\": 46181.907}", "{\"n\": 6952, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3625.81, \"learn_time_ms\": 46185.382}", "{\"n\": 6953, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3625.81, \"learn_time_ms\": 46281.887}", "{\"n\": 6954, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3625.81, \"learn_time_ms\": 46281.453}", "{\"n\": 6955, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3639.8, \"learn_time_ms\": 46294.335}", "{\"n\": 6956, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3633.37, \"learn_time_ms\": 46288.568}", "{\"n\": 6957, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3635.78, \"learn_time_ms\": 46206.215}", "{\"n\": 6958, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3596.53, \"learn_time_ms\": 46320.178}", "{\"n\": 6959, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3606.39, \"learn_time_ms\": 46188.727}", "{\"n\": 6960, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3606.39, \"learn_time_ms\": 46212.348}", "{\"n\": 6961, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3606.65, \"learn_time_ms\": 46202.107}", "{\"n\": 6962, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3605.66, \"learn_time_ms\": 46188.087}", "{\"n\": 6963, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3596.58, \"learn_time_ms\": 46117.433}", "{\"n\": 6964, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3598.45, \"learn_time_ms\": 45983.198}", "{\"n\": 6965, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3588.0, \"learn_time_ms\": 46000.143}", "{\"n\": 6966, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3588.0, \"learn_time_ms\": 45976.06}", "{\"n\": 6967, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.28, \"learn_time_ms\": 46034.356}", "{\"n\": 6968, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3559.07, \"learn_time_ms\": 46031.869}", "{\"n\": 6969, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3549.07, \"learn_time_ms\": 46003.135}", "{\"n\": 6970, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3550.62, \"learn_time_ms\": 46000.932}", "{\"n\": 6971, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3552.39, \"learn_time_ms\": 46029.307}", "{\"n\": 6972, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.9, \"learn_time_ms\": 46022.699}", "{\"n\": 6973, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.9, \"learn_time_ms\": 45998.939}", "{\"n\": 6974, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.26, \"learn_time_ms\": 46082.193}", "{\"n\": 6975, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.26, \"learn_time_ms\": 46078.814}", "{\"n\": 6976, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3600.93, \"learn_time_ms\": 46150.604}", "{\"n\": 6977, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3595.29, \"learn_time_ms\": 46216.581}", "{\"n\": 6978, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3590.46, \"learn_time_ms\": 46194.967}", "{\"n\": 6979, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3583.59, \"learn_time_ms\": 46233.289}", "{\"n\": 6980, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3583.59, \"learn_time_ms\": 46219.138}", "{\"n\": 6981, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3570.79, \"learn_time_ms\": 46224.964}", "{\"n\": 6982, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3553.12, \"learn_time_ms\": 46307.161}", "{\"n\": 6983, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3504.96, \"learn_time_ms\": 46235.466}", "{\"n\": 6984, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3513.64, \"learn_time_ms\": 46264.65}", "{\"n\": 6985, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3503.14, \"learn_time_ms\": 46204.282}", "{\"n\": 6986, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3490.3, \"learn_time_ms\": 46055.708}", "{\"n\": 6987, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3463.34, \"learn_time_ms\": 45957.148}", "{\"n\": 6988, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.02, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3438.58, \"learn_time_ms\": 46022.003}", "{\"n\": 6989, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3424.63, \"learn_time_ms\": 46062.566}", "{\"n\": 6990, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3418.47, \"learn_time_ms\": 46009.388}", "{\"n\": 6991, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3427.45, \"learn_time_ms\": 46021.621}", "{\"n\": 6992, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3430.65, \"learn_time_ms\": 45956.682}", "{\"n\": 6993, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3443.04, \"learn_time_ms\": 45996.743}", "{\"n\": 6994, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.8, \"learn_time_ms\": 45905.971}", "{\"n\": 6995, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.14, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3429.92, \"learn_time_ms\": 46026.574}", "{\"n\": 6996, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.4, \"learn_time_ms\": 46126.959}", "{\"n\": 6997, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3432.4, \"learn_time_ms\": 46140.659}", "{\"n\": 6998, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3436.22, \"learn_time_ms\": 46192.833}", "{\"n\": 6999, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3453.45, \"learn_time_ms\": 46250.475}", "{\"n\": 7000, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3437.55, \"learn_time_ms\": 46319.88}"]["{\"n\": 7001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 45350.073}", "{\"n\": 7002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 44180.322}", "{\"n\": 7003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43572.516}", "{\"n\": 7004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43410.121}", "{\"n\": 7005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43439.315}", "{\"n\": 7006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43263.067}", "{\"n\": 7007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43141.264}", "{\"n\": 7008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43125.514}", "{\"n\": 7009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43094.938}", "{\"n\": 7010, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -16.0, \"episode_len_mean\": 3024.0, \"learn_time_ms\": 43105.444}", "{\"n\": 7011, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -15.5, \"episode_reward_max\": -15.0, \"episode_len_mean\": 2618.0, \"learn_time_ms\": 42872.343}", "{\"n\": 7012, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -14.0, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2902.3333333333335, \"learn_time_ms\": 42929.452}", "{\"n\": 7013, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -10.166666666666666, \"episode_reward_max\": -3.0, \"episode_len_mean\": 3379.5, \"learn_time_ms\": 42916.916}", "{\"n\": 7014, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.285714285714286, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3627.5714285714284, \"learn_time_ms\": 42939.305}", "{\"n\": 7015, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.125, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3692.125, \"learn_time_ms\": 42871.638}", "{\"n\": 7016, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.125, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3692.125, \"learn_time_ms\": 42890.203}", "{\"n\": 7017, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.363636363636363, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3640.6363636363635, \"learn_time_ms\": 42953.487}", "{\"n\": 7018, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.23076923076923, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3649.923076923077, \"learn_time_ms\": 42943.462}", "{\"n\": 7019, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.23076923076923, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3649.923076923077, \"learn_time_ms\": 42984.383}", "{\"n\": 7020, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.142857142857142, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3642.9285714285716, \"learn_time_ms\": 42949.269}", "{\"n\": 7021, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.125, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3636.25, \"learn_time_ms\": 42985.213}", "{\"n\": 7022, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3627.722222222222, \"learn_time_ms\": 42954.761}", "{\"n\": 7023, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.315789473684211, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3640.0526315789475, \"learn_time_ms\": 43065.516}", "{\"n\": 7024, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.380952380952381, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3618.714285714286, \"learn_time_ms\": 43068.794}", "{\"n\": 7025, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2272727272727275, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3643.1363636363635, \"learn_time_ms\": 43031.826}", "{\"n\": 7026, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.173913043478261, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3652.7391304347825, \"learn_time_ms\": 43048.225}", "{\"n\": 7027, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3630.56, \"learn_time_ms\": 43033.23}", "{\"n\": 7028, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.555555555555555, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3577.5185185185187, \"learn_time_ms\": 42998.082}", "{\"n\": 7029, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.620689655172414, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3574.655172413793, \"learn_time_ms\": 42926.146}", "{\"n\": 7030, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.620689655172414, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3574.655172413793, \"learn_time_ms\": 42959.05}", "{\"n\": 7031, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.766666666666667, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3546.6666666666665, \"learn_time_ms\": 42899.689}", "{\"n\": 7032, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.967741935483871, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3523.3548387096776, \"learn_time_ms\": 42896.991}", "{\"n\": 7033, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.90625, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3533.34375, \"learn_time_ms\": 42894.824}", "{\"n\": 7034, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.878787878787879, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3556.181818181818, \"learn_time_ms\": 42914.154}", "{\"n\": 7035, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.027777777777779, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3540.277777777778, \"learn_time_ms\": 42979.733}", "{\"n\": 7036, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.135135135135135, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3523.108108108108, \"learn_time_ms\": 42991.59}", "{\"n\": 7037, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.973684210526316, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3541.2105263157896, \"learn_time_ms\": 43041.786}", "{\"n\": 7038, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.025641025641026, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3529.923076923077, \"learn_time_ms\": 43080.341}", "{\"n\": 7039, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.119047619047619, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3532.6190476190477, \"learn_time_ms\": 43163.978}", "{\"n\": 7040, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.046511627906977, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3552.3720930232557, \"learn_time_ms\": 43087.245}", "{\"n\": 7041, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.227272727272727, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3533.2954545454545, \"learn_time_ms\": 43161.621}", "{\"n\": 7042, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.065217391304348, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3539.717391304348, \"learn_time_ms\": 43206.519}", "{\"n\": 7043, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.065217391304348, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3539.717391304348, \"learn_time_ms\": 43128.076}", "{\"n\": 7044, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.145833333333334, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3536.0833333333335, \"learn_time_ms\": 43090.978}", "{\"n\": 7045, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.224489795918368, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3517.5102040816328, \"learn_time_ms\": 43076.989}", "{\"n\": 7046, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3510.88, \"learn_time_ms\": 43079.495}", "{\"n\": 7047, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.377358490566039, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3496.6415094339623, \"learn_time_ms\": 43039.863}", "{\"n\": 7048, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.290909090909091, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3520.836363636364, \"learn_time_ms\": 43033.566}", "{\"n\": 7049, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.290909090909091, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3520.836363636364, \"learn_time_ms\": 42979.077}", "{\"n\": 7050, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.350877192982455, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3512.8947368421054, \"learn_time_ms\": 43076.039}", "{\"n\": 7051, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.350877192982455, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3512.8947368421054, \"learn_time_ms\": 43005.87}", "{\"n\": 7052, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3526.1666666666665, \"learn_time_ms\": 42949.107}", "{\"n\": 7053, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.983606557377049, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3546.0819672131147, \"learn_time_ms\": 42954.315}", "{\"n\": 7054, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.967741935483871, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3545.3225806451615, \"learn_time_ms\": 42916.988}", "{\"n\": 7055, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.063492063492063, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3533.5079365079364, \"learn_time_ms\": 42954.982}", "{\"n\": 7056, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09375, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3529.1875, \"learn_time_ms\": 42951.343}", "{\"n\": 7057, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.153846153846153, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3525.123076923077, \"learn_time_ms\": 42852.75}", "{\"n\": 7058, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.149253731343284, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3521.223880597015, \"learn_time_ms\": 42786.221}", "{\"n\": 7059, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.191176470588236, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3511.3382352941176, \"learn_time_ms\": 42793.217}", "{\"n\": 7060, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.228571428571428, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3504.0285714285715, \"learn_time_ms\": 42773.412}", "{\"n\": 7061, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.208333333333334, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3514.3611111111113, \"learn_time_ms\": 42713.806}", "{\"n\": 7062, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.208333333333334, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3514.3611111111113, \"learn_time_ms\": 42749.08}", "{\"n\": 7063, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.14864864864865, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3523.4594594594596, \"learn_time_ms\": 42820.079}", "{\"n\": 7064, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.026315789473685, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3548.1052631578946, \"learn_time_ms\": 42841.957}", "{\"n\": 7065, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.026315789473685, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3548.1052631578946, \"learn_time_ms\": 42772.079}", "{\"n\": 7066, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.128205128205128, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3529.602564102564, \"learn_time_ms\": 42758.602}", "{\"n\": 7067, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.113924050632912, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3533.6582278481014, \"learn_time_ms\": 42898.489}", "{\"n\": 7068, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.113924050632912, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3533.6582278481014, \"learn_time_ms\": 43006.727}", "{\"n\": 7069, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.121951219512194, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3541.670731707317, \"learn_time_ms\": 43038.342}", "{\"n\": 7070, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.180722891566266, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3532.3012048192772, \"learn_time_ms\": 43042.743}", "{\"n\": 7071, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3522.0833333333335, \"learn_time_ms\": 43064.126}", "{\"n\": 7072, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.282352941176471, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3517.0, \"learn_time_ms\": 43029.996}", "{\"n\": 7073, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.149425287356323, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3537.5172413793102, \"learn_time_ms\": 43096.237}", "{\"n\": 7074, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.149425287356323, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3537.5172413793102, \"learn_time_ms\": 43120.644}", "{\"n\": 7075, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.044444444444444, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3553.2444444444445, \"learn_time_ms\": 43063.518}", "{\"n\": 7076, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.054945054945055, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3553.153846153846, \"learn_time_ms\": 43105.222}", "{\"n\": 7077, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.978260869565218, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3559.228260869565, \"learn_time_ms\": 43048.434}", "{\"n\": 7078, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.924731182795699, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3566.94623655914, \"learn_time_ms\": 43073.835}", "{\"n\": 7079, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.927083333333333, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3565.6875, \"learn_time_ms\": 43065.69}", "{\"n\": 7080, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.907216494845361, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3570.1649484536083, \"learn_time_ms\": 43066.527}", "{\"n\": 7081, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.907216494845361, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3570.1649484536083, \"learn_time_ms\": 43111.117}", "{\"n\": 7082, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.928571428571429, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3567.1530612244896, \"learn_time_ms\": 43105.963}", "{\"n\": 7083, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3561.42, \"learn_time_ms\": 43011.731}", "{\"n\": 7084, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3565.99, \"learn_time_ms\": 42927.087}", "{\"n\": 7085, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3556.91, \"learn_time_ms\": 43076.646}", "{\"n\": 7086, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3556.91, \"learn_time_ms\": 43063.673}", "{\"n\": 7087, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3556.91, \"learn_time_ms\": 43055.141}", "{\"n\": 7088, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3534.33, \"learn_time_ms\": 43055.617}", "{\"n\": 7089, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3539.76, \"learn_time_ms\": 43105.79}", "{\"n\": 7090, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3541.4, \"learn_time_ms\": 43065.123}", "{\"n\": 7091, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3536.31, \"learn_time_ms\": 43073.685}", "{\"n\": 7092, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3526.66, \"learn_time_ms\": 43115.59}", "{\"n\": 7093, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3513.57, \"learn_time_ms\": 42974.637}", "{\"n\": 7094, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3510.51, \"learn_time_ms\": 42985.721}", "{\"n\": 7095, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3510.51, \"learn_time_ms\": 42958.291}", "{\"n\": 7096, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3503.67, \"learn_time_ms\": 42956.805}", "{\"n\": 7097, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3501.86, \"learn_time_ms\": 43014.426}", "{\"n\": 7098, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3501.86, \"learn_time_ms\": 42916.884}", "{\"n\": 7099, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3504.61, \"learn_time_ms\": 42837.97}", "{\"n\": 7100, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3499.57, \"learn_time_ms\": 42864.064}", "{\"n\": 7101, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3508.69, \"learn_time_ms\": 42811.187}", "{\"n\": 7102, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3508.69, \"learn_time_ms\": 42669.234}", "{\"n\": 7103, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3503.13, \"learn_time_ms\": 42765.18}", "{\"n\": 7104, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3503.2, \"learn_time_ms\": 42833.488}", "{\"n\": 7105, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3513.34, \"learn_time_ms\": 42802.088}", "{\"n\": 7106, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3504.9, \"learn_time_ms\": 42889.071}", "{\"n\": 7107, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3517.84, \"learn_time_ms\": 42838.326}", "{\"n\": 7108, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3519.64, \"learn_time_ms\": 42881.046}", "{\"n\": 7109, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3527.04, \"learn_time_ms\": 42893.728}", "{\"n\": 7110, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3526.58, \"learn_time_ms\": 42881.374}", "{\"n\": 7111, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3526.58, \"learn_time_ms\": 42930.939}", "{\"n\": 7112, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3522.52, \"learn_time_ms\": 42960.898}", "{\"n\": 7113, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3522.52, \"learn_time_ms\": 42985.766}", "{\"n\": 7114, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3523.9, \"learn_time_ms\": 43034.753}", "{\"n\": 7115, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3524.32, \"learn_time_ms\": 42997.094}", "{\"n\": 7116, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3524.32, \"learn_time_ms\": 42898.642}", "{\"n\": 7117, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3514.74, \"learn_time_ms\": 42927.713}", "{\"n\": 7118, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3520.2, \"learn_time_ms\": 42925.395}", "{\"n\": 7119, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3520.2, \"learn_time_ms\": 42977.046}", "{\"n\": 7120, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3519.84, \"learn_time_ms\": 42925.889}", "{\"n\": 7121, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3523.36, \"learn_time_ms\": 42897.215}", "{\"n\": 7122, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3523.36, \"learn_time_ms\": 42902.443}", "{\"n\": 7123, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3522.51, \"learn_time_ms\": 42908.085}", "{\"n\": 7124, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3532.23, \"learn_time_ms\": 42876.093}", "{\"n\": 7125, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3496.07, \"learn_time_ms\": 42801.68}", "{\"n\": 7126, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3497.54, \"learn_time_ms\": 42905.929}", "{\"n\": 7127, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3498.53, \"learn_time_ms\": 42879.752}", "{\"n\": 7128, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3498.53, \"learn_time_ms\": 42849.687}", "{\"n\": 7129, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3498.53, \"learn_time_ms\": 42810.55}", "{\"n\": 7130, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3495.75, \"learn_time_ms\": 42864.126}", "{\"n\": 7131, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3497.62, \"learn_time_ms\": 42863.942}", "{\"n\": 7132, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3504.99, \"learn_time_ms\": 42859.314}", "{\"n\": 7133, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3498.31, \"learn_time_ms\": 42853.488}", "{\"n\": 7134, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3494.53, \"learn_time_ms\": 42823.562}", "{\"n\": 7135, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3494.53, \"learn_time_ms\": 43006.568}", "{\"n\": 7136, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3472.66, \"learn_time_ms\": 42849.423}", "{\"n\": 7137, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3476.49, \"learn_time_ms\": 42876.741}", "{\"n\": 7138, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3482.82, \"learn_time_ms\": 42929.05}", "{\"n\": 7139, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3499.21, \"learn_time_ms\": 42938.63}", "{\"n\": 7140, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3499.21, \"learn_time_ms\": 42940.548}", "{\"n\": 7141, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3489.22, \"learn_time_ms\": 42944.182}", "{\"n\": 7142, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3488.23, \"learn_time_ms\": 42928.558}", "{\"n\": 7143, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3493.18, \"learn_time_ms\": 42940.811}", "{\"n\": 7144, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3493.18, \"learn_time_ms\": 43012.48}", "{\"n\": 7145, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3474.38, \"learn_time_ms\": 42992.672}", "{\"n\": 7146, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3474.38, \"learn_time_ms\": 43060.979}", "{\"n\": 7147, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3474.38, \"learn_time_ms\": 43093.082}", "{\"n\": 7148, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3468.05, \"learn_time_ms\": 43096.632}", "{\"n\": 7149, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3446.27, \"learn_time_ms\": 43070.798}", "{\"n\": 7150, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3443.13, \"learn_time_ms\": 43158.62}", "{\"n\": 7151, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3429.35, \"learn_time_ms\": 43201.043}", "{\"n\": 7152, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3443.03, \"learn_time_ms\": 43371.386}", "{\"n\": 7153, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3448.31, \"learn_time_ms\": 43343.685}", "{\"n\": 7154, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3448.31, \"learn_time_ms\": 43284.146}", "{\"n\": 7155, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3448.99, \"learn_time_ms\": 43165.733}", "{\"n\": 7156, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3444.46, \"learn_time_ms\": 43195.053}", "{\"n\": 7157, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3444.46, \"learn_time_ms\": 43124.738}", "{\"n\": 7158, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3450.43, \"learn_time_ms\": 43188.578}", "{\"n\": 7159, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3436.74, \"learn_time_ms\": 43207.239}", "{\"n\": 7160, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3438.46, \"learn_time_ms\": 43233.276}", "{\"n\": 7161, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3426.46, \"learn_time_ms\": 43304.153}", "{\"n\": 7162, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3438.44, \"learn_time_ms\": 43276.915}", "{\"n\": 7163, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3438.44, \"learn_time_ms\": 43341.732}", "{\"n\": 7164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3461.82, \"learn_time_ms\": 43407.948}", "{\"n\": 7165, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3461.82, \"learn_time_ms\": 43659.644}", "{\"n\": 7166, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3458.94, \"learn_time_ms\": 43609.759}", "{\"n\": 7167, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3490.19, \"learn_time_ms\": 43595.941}", "{\"n\": 7168, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3481.73, \"learn_time_ms\": 43454.203}", "{\"n\": 7169, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3490.42, \"learn_time_ms\": 43398.285}", "{\"n\": 7170, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3490.42, \"learn_time_ms\": 43320.503}", "{\"n\": 7171, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3479.53, \"learn_time_ms\": 43282.312}", "{\"n\": 7172, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3477.12, \"learn_time_ms\": 43232.62}", "{\"n\": 7173, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3498.82, \"learn_time_ms\": 43257.742}", "{\"n\": 7174, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3520.82, \"learn_time_ms\": 43267.726}", "{\"n\": 7175, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3514.84, \"learn_time_ms\": 43168.541}", "{\"n\": 7176, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3523.18, \"learn_time_ms\": 43185.433}", "{\"n\": 7177, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3510.05, \"learn_time_ms\": 43160.705}", "{\"n\": 7178, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3510.05, \"learn_time_ms\": 43269.315}", "{\"n\": 7179, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3505.86, \"learn_time_ms\": 43312.234}", "{\"n\": 7180, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3495.3, \"learn_time_ms\": 43302.438}", "{\"n\": 7181, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3492.25, \"learn_time_ms\": 43318.972}", "{\"n\": 7182, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3477.43, \"learn_time_ms\": 43326.503}", "{\"n\": 7183, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3477.43, \"learn_time_ms\": 43258.39}", "{\"n\": 7184, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3473.1, \"learn_time_ms\": 43191.753}", "{\"n\": 7185, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3474.89, \"learn_time_ms\": 43008.888}", "{\"n\": 7186, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3482.18, \"learn_time_ms\": 42982.045}", "{\"n\": 7187, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3486.82, \"learn_time_ms\": 43026.943}", "{\"n\": 7188, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3498.51, \"learn_time_ms\": 42988.465}", "{\"n\": 7189, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3482.64, \"learn_time_ms\": 42984.667}", "{\"n\": 7190, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3499.45, \"learn_time_ms\": 42983.35}", "{\"n\": 7191, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3486.68, \"learn_time_ms\": 42956.346}", "{\"n\": 7192, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3476.52, \"learn_time_ms\": 42956.452}", "{\"n\": 7193, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3478.36, \"learn_time_ms\": 42961.589}", "{\"n\": 7194, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3478.36, \"learn_time_ms\": 42948.613}", "{\"n\": 7195, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3481.42, \"learn_time_ms\": 43021.057}", "{\"n\": 7196, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3475.84, \"learn_time_ms\": 43000.51}", "{\"n\": 7197, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3466.72, \"learn_time_ms\": 43019.42}", "{\"n\": 7198, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3479.65, \"learn_time_ms\": 42897.198}", "{\"n\": 7199, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3495.67, \"learn_time_ms\": 42892.511}", "{\"n\": 7200, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3495.67, \"learn_time_ms\": 42911.485}", "{\"n\": 7201, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3495.67, \"learn_time_ms\": 42888.023}", "{\"n\": 7202, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3492.71, \"learn_time_ms\": 42921.318}", "{\"n\": 7203, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3505.05, \"learn_time_ms\": 42949.98}", "{\"n\": 7204, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3515.47, \"learn_time_ms\": 42960.31}", "{\"n\": 7205, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3520.54, \"learn_time_ms\": 42996.342}", "{\"n\": 7206, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3502.92, \"learn_time_ms\": 43028.175}", "{\"n\": 7207, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3490.34, \"learn_time_ms\": 43014.568}", "{\"n\": 7208, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3491.15, \"learn_time_ms\": 43204.855}", "{\"n\": 7209, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3456.96, \"learn_time_ms\": 43271.799}", "{\"n\": 7210, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3474.33, \"learn_time_ms\": 43112.403}", "{\"n\": 7211, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3469.53, \"learn_time_ms\": 43163.388}", "{\"n\": 7212, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3500.19, \"learn_time_ms\": 43096.336}", "{\"n\": 7213, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3490.91, \"learn_time_ms\": 43121.946}", "{\"n\": 7214, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3490.91, \"learn_time_ms\": 43100.241}", "{\"n\": 7215, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3490.91, \"learn_time_ms\": 43094.691}", "{\"n\": 7216, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3490.91, \"learn_time_ms\": 43142.98}", "{\"n\": 7217, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3455.45, \"learn_time_ms\": 43144.121}", "{\"n\": 7218, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3448.42, \"learn_time_ms\": 43082.518}", "{\"n\": 7219, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3446.22, \"learn_time_ms\": 43025.206}", "{\"n\": 7220, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3458.99, \"learn_time_ms\": 43237.154}", "{\"n\": 7221, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3458.99, \"learn_time_ms\": 43163.873}", "{\"n\": 7222, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3467.59, \"learn_time_ms\": 43215.335}", "{\"n\": 7223, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3474.89, \"learn_time_ms\": 43104.082}", "{\"n\": 7224, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3460.79, \"learn_time_ms\": 43214.642}", "{\"n\": 7225, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3460.51, \"learn_time_ms\": 43203.722}", "{\"n\": 7226, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3445.74, \"learn_time_ms\": 43153.882}", "{\"n\": 7227, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3450.38, \"learn_time_ms\": 43200.446}", "{\"n\": 7228, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3450.38, \"learn_time_ms\": 43135.872}", "{\"n\": 7229, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3453.55, \"learn_time_ms\": 43087.167}", "{\"n\": 7230, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3452.0, \"learn_time_ms\": 43030.361}", "{\"n\": 7231, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3464.59, \"learn_time_ms\": 42992.778}", "{\"n\": 7232, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3464.44, \"learn_time_ms\": 42951.653}", "{\"n\": 7233, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3456.66, \"learn_time_ms\": 43023.936}", "{\"n\": 7234, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3456.66, \"learn_time_ms\": 42873.057}", "{\"n\": 7235, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3452.72, \"learn_time_ms\": 43009.942}", "{\"n\": 7236, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3452.72, \"learn_time_ms\": 42947.139}", "{\"n\": 7237, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3454.4, \"learn_time_ms\": 42880.932}", "{\"n\": 7238, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3446.7, \"learn_time_ms\": 42900.781}", "{\"n\": 7239, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3439.71, \"learn_time_ms\": 43070.457}", "{\"n\": 7240, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3424.81, \"learn_time_ms\": 43009.194}", "{\"n\": 7241, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3421.16, \"learn_time_ms\": 43196.727}", "{\"n\": 7242, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3406.93, \"learn_time_ms\": 43254.556}", "{\"n\": 7243, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3403.64, \"learn_time_ms\": 43243.672}", "{\"n\": 7244, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3407.72, \"learn_time_ms\": 43305.634}", "{\"n\": 7245, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3393.07, \"learn_time_ms\": 43264.441}", "{\"n\": 7246, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3393.07, \"learn_time_ms\": 43316.534}", "{\"n\": 7247, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3388.83, \"learn_time_ms\": 43381.516}", "{\"n\": 7248, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3392.74, \"learn_time_ms\": 43416.64}", "{\"n\": 7249, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3419.7, \"learn_time_ms\": 43307.534}", "{\"n\": 7250, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3419.7, \"learn_time_ms\": 43291.188}", "{\"n\": 7251, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3419.02, \"learn_time_ms\": 43166.348}", "{\"n\": 7252, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3411.27, \"learn_time_ms\": 43093.631}", "{\"n\": 7253, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3427.73, \"learn_time_ms\": 43133.449}", "{\"n\": 7254, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3417.39, \"learn_time_ms\": 43069.988}", "{\"n\": 7255, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3409.53, \"learn_time_ms\": 43016.486}", "{\"n\": 7256, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3405.94, \"learn_time_ms\": 42947.626}", "{\"n\": 7257, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3400.96, \"learn_time_ms\": 42925.331}", "{\"n\": 7258, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3400.96, \"learn_time_ms\": 42923.479}", "{\"n\": 7259, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.94, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3387.84, \"learn_time_ms\": 42874.051}", "{\"n\": 7260, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3406.1, \"learn_time_ms\": 42925.894}", "{\"n\": 7261, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3406.1, \"learn_time_ms\": 42894.212}", "{\"n\": 7262, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3427.23, \"learn_time_ms\": 42891.579}", "{\"n\": 7263, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3428.82, \"learn_time_ms\": 42777.382}", "{\"n\": 7264, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3420.06, \"learn_time_ms\": 42784.248}", "{\"n\": 7265, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.1, \"learn_time_ms\": 42680.098}", "{\"n\": 7266, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.76, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3412.1, \"learn_time_ms\": 42820.337}", "{\"n\": 7267, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.51, \"learn_time_ms\": 42760.766}", "{\"n\": 7268, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3419.51, \"learn_time_ms\": 42700.108}", "{\"n\": 7269, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3411.97, \"learn_time_ms\": 42786.277}", "{\"n\": 7270, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3417.09, \"learn_time_ms\": 42856.637}", "{\"n\": 7271, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3421.83, \"learn_time_ms\": 42938.141}", "{\"n\": 7272, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3417.16, \"learn_time_ms\": 42937.568}", "{\"n\": 7273, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3417.16, \"learn_time_ms\": 42954.335}", "{\"n\": 7274, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3435.76, \"learn_time_ms\": 42896.689}", "{\"n\": 7275, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3432.79, \"learn_time_ms\": 42987.323}", "{\"n\": 7276, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3428.84, \"learn_time_ms\": 42962.213}", "{\"n\": 7277, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3458.47, \"learn_time_ms\": 42962.446}", "{\"n\": 7278, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3458.47, \"learn_time_ms\": 42945.597}", "{\"n\": 7279, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3458.47, \"learn_time_ms\": 42856.108}", "{\"n\": 7280, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3455.95, \"learn_time_ms\": 42839.248}", "{\"n\": 7281, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3461.23, \"learn_time_ms\": 42807.078}", "{\"n\": 7282, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3461.23, \"learn_time_ms\": 42933.701}", "{\"n\": 7283, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3459.09, \"learn_time_ms\": 42951.648}", "{\"n\": 7284, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3459.09, \"learn_time_ms\": 43097.877}", "{\"n\": 7285, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3449.22, \"learn_time_ms\": 43041.653}", "{\"n\": 7286, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3420.69, \"learn_time_ms\": 42911.837}", "{\"n\": 7287, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3430.2, \"learn_time_ms\": 43009.574}", "{\"n\": 7288, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3468.57, \"learn_time_ms\": 43113.014}", "{\"n\": 7289, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3468.57, \"learn_time_ms\": 43112.91}", "{\"n\": 7290, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3468.57, \"learn_time_ms\": 43035.37}", "{\"n\": 7291, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3468.57, \"learn_time_ms\": 43001.626}", "{\"n\": 7292, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3469.42, \"learn_time_ms\": 42801.107}", "{\"n\": 7293, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3494.83, \"learn_time_ms\": 42805.673}", "{\"n\": 7294, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3496.0, \"learn_time_ms\": 42744.912}", "{\"n\": 7295, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3492.36, \"learn_time_ms\": 42738.424}", "{\"n\": 7296, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3492.36, \"learn_time_ms\": 42808.273}", "{\"n\": 7297, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3488.75, \"learn_time_ms\": 42797.718}", "{\"n\": 7298, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3498.52, \"learn_time_ms\": 42706.292}", "{\"n\": 7299, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3516.07, \"learn_time_ms\": 42773.813}", "{\"n\": 7300, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3519.83, \"learn_time_ms\": 42793.226}", "{\"n\": 7301, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3519.83, \"learn_time_ms\": 42783.203}", "{\"n\": 7302, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3519.83, \"learn_time_ms\": 42880.34}", "{\"n\": 7303, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3531.14, \"learn_time_ms\": 42875.469}", "{\"n\": 7304, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3531.14, \"learn_time_ms\": 42914.641}", "{\"n\": 7305, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3520.29, \"learn_time_ms\": 42914.949}", "{\"n\": 7306, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3520.29, \"learn_time_ms\": 42991.809}", "{\"n\": 7307, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3520.29, \"learn_time_ms\": 42926.752}", "{\"n\": 7308, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3525.09, \"learn_time_ms\": 42892.095}", "{\"n\": 7309, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3525.21, \"learn_time_ms\": 42785.087}", "{\"n\": 7310, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3509.67, \"learn_time_ms\": 42714.378}", "{\"n\": 7311, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3538.66, \"learn_time_ms\": 42713.454}", "{\"n\": 7312, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3538.66, \"learn_time_ms\": 42703.43}", "{\"n\": 7313, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3539.67, \"learn_time_ms\": 42660.532}", "{\"n\": 7314, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3544.74, \"learn_time_ms\": 42736.781}", "{\"n\": 7315, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3539.32, \"learn_time_ms\": 42817.419}", "{\"n\": 7316, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3524.5, \"learn_time_ms\": 42721.24}", "{\"n\": 7317, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3529.99, \"learn_time_ms\": 42694.434}", "{\"n\": 7318, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3523.35, \"learn_time_ms\": 42835.702}", "{\"n\": 7319, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3523.35, \"learn_time_ms\": 42902.045}", "{\"n\": 7320, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3536.24, \"learn_time_ms\": 42850.043}", "{\"n\": 7321, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3541.05, \"learn_time_ms\": 42872.627}", "{\"n\": 7322, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3542.14, \"learn_time_ms\": 42958.499}", "{\"n\": 7323, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3527.66, \"learn_time_ms\": 43051.12}", "{\"n\": 7324, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3527.75, \"learn_time_ms\": 42921.423}", "{\"n\": 7325, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3527.75, \"learn_time_ms\": 42859.891}", "{\"n\": 7326, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3527.37, \"learn_time_ms\": 42946.008}", "{\"n\": 7327, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3534.12, \"learn_time_ms\": 42968.345}", "{\"n\": 7328, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3534.12, \"learn_time_ms\": 42831.919}", "{\"n\": 7329, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3534.12, \"learn_time_ms\": 42832.416}", "{\"n\": 7330, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3548.73, \"learn_time_ms\": 42835.469}", "{\"n\": 7331, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3551.26, \"learn_time_ms\": 42848.359}", "{\"n\": 7332, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3539.84, \"learn_time_ms\": 42774.295}", "{\"n\": 7333, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3539.84, \"learn_time_ms\": 42798.086}", "{\"n\": 7334, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3532.81, \"learn_time_ms\": 42822.533}", "{\"n\": 7335, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3530.16, \"learn_time_ms\": 42756.173}", "{\"n\": 7336, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3523.18, \"learn_time_ms\": 42750.799}", "{\"n\": 7337, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3521.43, \"learn_time_ms\": 42731.869}", "{\"n\": 7338, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3514.44, \"learn_time_ms\": 42745.601}", "{\"n\": 7339, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3546.43, \"learn_time_ms\": 42712.246}", "{\"n\": 7340, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3561.96, \"learn_time_ms\": 42881.463}", "{\"n\": 7341, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3561.96, \"learn_time_ms\": 42907.836}", "{\"n\": 7342, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3593.44, \"learn_time_ms\": 42933.993}", "{\"n\": 7343, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3593.44, \"learn_time_ms\": 42882.711}", "{\"n\": 7344, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3582.59, \"learn_time_ms\": 42941.244}", "{\"n\": 7345, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3569.66, \"learn_time_ms\": 43061.078}", "{\"n\": 7346, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3569.66, \"learn_time_ms\": 42919.404}", "{\"n\": 7347, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3558.63, \"learn_time_ms\": 42969.002}", "{\"n\": 7348, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3532.7, \"learn_time_ms\": 43058.773}", "{\"n\": 7349, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3536.13, \"learn_time_ms\": 43089.406}", "{\"n\": 7350, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3536.13, \"learn_time_ms\": 43008.077}", "{\"n\": 7351, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3525.97, \"learn_time_ms\": 42891.824}", "{\"n\": 7352, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3525.97, \"learn_time_ms\": 42887.681}", "{\"n\": 7353, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3551.56, \"learn_time_ms\": 42868.823}", "{\"n\": 7354, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3538.92, \"learn_time_ms\": 42746.519}", "{\"n\": 7355, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3549.85, \"learn_time_ms\": 42694.106}", "{\"n\": 7356, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3545.4, \"learn_time_ms\": 42808.476}", "{\"n\": 7357, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3542.41, \"learn_time_ms\": 42861.423}", "{\"n\": 7358, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3545.15, \"learn_time_ms\": 42740.889}", "{\"n\": 7359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3554.22, \"learn_time_ms\": 42802.313}", "{\"n\": 7360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3557.51, \"learn_time_ms\": 42916.125}", "{\"n\": 7361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.77, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3557.51, \"learn_time_ms\": 42999.504}", "{\"n\": 7362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3534.73, \"learn_time_ms\": 42925.922}", "{\"n\": 7363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3546.91, \"learn_time_ms\": 42978.638}", "{\"n\": 7364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3554.95, \"learn_time_ms\": 43034.35}", "{\"n\": 7365, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3555.76, \"learn_time_ms\": 43022.403}", "{\"n\": 7366, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3550.71, \"learn_time_ms\": 43034.553}", "{\"n\": 7367, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3530.89, \"learn_time_ms\": 42975.778}", "{\"n\": 7368, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3541.18, \"learn_time_ms\": 43114.709}", "{\"n\": 7369, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3541.18, \"learn_time_ms\": 43059.139}", "{\"n\": 7370, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3550.27, \"learn_time_ms\": 42956.482}", "{\"n\": 7371, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3535.61, \"learn_time_ms\": 42875.882}", "{\"n\": 7372, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3535.61, \"learn_time_ms\": 42858.734}", "{\"n\": 7373, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.18, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3541.81, \"learn_time_ms\": 42839.666}", "{\"n\": 7374, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3526.05, \"learn_time_ms\": 42744.799}", "{\"n\": 7375, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3515.04, \"learn_time_ms\": 42791.908}", "{\"n\": 7376, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3515.04, \"learn_time_ms\": 42786.174}", "{\"n\": 7377, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3522.52, \"learn_time_ms\": 42807.488}", "{\"n\": 7378, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3528.55, \"learn_time_ms\": 42770.854}", "{\"n\": 7379, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3543.27, \"learn_time_ms\": 42811.711}", "{\"n\": 7380, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3546.43, \"learn_time_ms\": 42808.356}", "{\"n\": 7381, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3546.43, \"learn_time_ms\": 42890.79}", "{\"n\": 7382, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3546.43, \"learn_time_ms\": 43003.617}", "{\"n\": 7383, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3547.29, \"learn_time_ms\": 43009.057}", "{\"n\": 7384, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3544.0, \"learn_time_ms\": 43118.92}", "{\"n\": 7385, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3538.45, \"learn_time_ms\": 43068.469}", "{\"n\": 7386, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3542.31, \"learn_time_ms\": 43054.558}", "{\"n\": 7387, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3561.51, \"learn_time_ms\": 43048.401}", "{\"n\": 7388, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3561.51, \"learn_time_ms\": 43074.935}", "{\"n\": 7389, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3573.86, \"learn_time_ms\": 42968.829}", "{\"n\": 7390, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3566.41, \"learn_time_ms\": 42829.243}", "{\"n\": 7391, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3570.75, \"learn_time_ms\": 42782.622}", "{\"n\": 7392, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3568.57, \"learn_time_ms\": 42667.56}", "{\"n\": 7393, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3568.57, \"learn_time_ms\": 42709.616}", "{\"n\": 7394, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3582.38, \"learn_time_ms\": 42627.959}", "{\"n\": 7395, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3563.8, \"learn_time_ms\": 42635.588}", "{\"n\": 7396, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3564.25, \"learn_time_ms\": 42617.574}", "{\"n\": 7397, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3557.64, \"learn_time_ms\": 42592.779}", "{\"n\": 7398, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3557.64, \"learn_time_ms\": 42576.81}", "{\"n\": 7399, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3570.14, \"learn_time_ms\": 42652.548}", "{\"n\": 7400, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3585.65, \"learn_time_ms\": 42822.233}", "{\"n\": 7401, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3559.55, \"learn_time_ms\": 42784.38}", "{\"n\": 7402, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3559.55, \"learn_time_ms\": 42920.842}", "{\"n\": 7403, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3567.45, \"learn_time_ms\": 42797.785}", "{\"n\": 7404, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3567.6, \"learn_time_ms\": 42821.205}", "{\"n\": 7405, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3564.45, \"learn_time_ms\": 42775.215}", "{\"n\": 7406, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.51, \"learn_time_ms\": 42786.915}", "{\"n\": 7407, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.51, \"learn_time_ms\": 42774.208}", "{\"n\": 7408, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3582.95, \"learn_time_ms\": 42700.29}", "{\"n\": 7409, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3590.99, \"learn_time_ms\": 42676.431}", "{\"n\": 7410, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.2, \"learn_time_ms\": 42629.431}", "{\"n\": 7411, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.2, \"learn_time_ms\": 42633.481}", "{\"n\": 7412, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.2, \"learn_time_ms\": 42585.37}", "{\"n\": 7413, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3603.39, \"learn_time_ms\": 42650.265}", "{\"n\": 7414, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3600.26, \"learn_time_ms\": 42636.639}", "{\"n\": 7415, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3598.77, \"learn_time_ms\": 42684.307}", "{\"n\": 7416, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3574.59, \"learn_time_ms\": 42636.487}", "{\"n\": 7417, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3580.91, \"learn_time_ms\": 42646.345}", "{\"n\": 7418, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3580.91, \"learn_time_ms\": 42763.467}", "{\"n\": 7419, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3580.91, \"learn_time_ms\": 42696.377}", "{\"n\": 7420, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3579.34, \"learn_time_ms\": 42716.069}", "{\"n\": 7421, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3582.98, \"learn_time_ms\": 42748.791}", "{\"n\": 7422, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3582.98, \"learn_time_ms\": 42762.718}", "{\"n\": 7423, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3602.17, \"learn_time_ms\": 42669.047}", "{\"n\": 7424, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3626.73, \"learn_time_ms\": 42815.026}", "{\"n\": 7425, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3626.73, \"learn_time_ms\": 42868.638}", "{\"n\": 7426, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3634.86, \"learn_time_ms\": 42888.529}", "{\"n\": 7427, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3644.59, \"learn_time_ms\": 42871.536}", "{\"n\": 7428, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3644.59, \"learn_time_ms\": 42769.231}", "{\"n\": 7429, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3644.59, \"learn_time_ms\": 42957.488}", "{\"n\": 7430, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3654.22, \"learn_time_ms\": 43042.472}", "{\"n\": 7431, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3638.31, \"learn_time_ms\": 43080.904}", "{\"n\": 7432, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3673.61, \"learn_time_ms\": 43122.078}", "{\"n\": 7433, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3673.61, \"learn_time_ms\": 43253.501}", "{\"n\": 7434, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3670.28, \"learn_time_ms\": 43138.917}", "{\"n\": 7435, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3674.37, \"learn_time_ms\": 43092.427}", "{\"n\": 7436, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3674.37, \"learn_time_ms\": 43193.04}", "{\"n\": 7437, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3681.25, \"learn_time_ms\": 43283.284}", "{\"n\": 7438, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3706.02, \"learn_time_ms\": 43249.828}", "{\"n\": 7439, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3706.11, \"learn_time_ms\": 43081.281}", "{\"n\": 7440, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3706.11, \"learn_time_ms\": 43045.233}", "{\"n\": 7441, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3721.24, \"learn_time_ms\": 43068.694}", "{\"n\": 7442, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3703.48, \"learn_time_ms\": 42957.338}", "{\"n\": 7443, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.96, \"learn_time_ms\": 42985.955}", "{\"n\": 7444, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3711.54, \"learn_time_ms\": 42963.714}", "{\"n\": 7445, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3707.3, \"learn_time_ms\": 43053.075}", "{\"n\": 7446, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.15, \"learn_time_ms\": 43069.57}", "{\"n\": 7447, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.15, \"learn_time_ms\": 42961.406}", "{\"n\": 7448, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.15, \"learn_time_ms\": 43040.093}", "{\"n\": 7449, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3710.81, \"learn_time_ms\": 43137.671}", "{\"n\": 7450, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3724.78, \"learn_time_ms\": 43062.969}", "{\"n\": 7451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3738.95, \"learn_time_ms\": 43050.281}", "{\"n\": 7452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3747.74, \"learn_time_ms\": 43062.025}", "{\"n\": 7453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3747.74, \"learn_time_ms\": 42976.009}", "{\"n\": 7454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3757.7, \"learn_time_ms\": 43049.34}", "{\"n\": 7455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3768.24, \"learn_time_ms\": 43000.849}", "{\"n\": 7456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3754.05, \"learn_time_ms\": 42994.424}", "{\"n\": 7457, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3760.15, \"learn_time_ms\": 43026.125}", "{\"n\": 7458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3755.09, \"learn_time_ms\": 42941.973}", "{\"n\": 7459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3741.65, \"learn_time_ms\": 42844.63}", "{\"n\": 7460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3741.65, \"learn_time_ms\": 42857.98}", "{\"n\": 7461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3741.65, \"learn_time_ms\": 42836.077}", "{\"n\": 7462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3747.18, \"learn_time_ms\": 42863.399}", "{\"n\": 7463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3745.35, \"learn_time_ms\": 42925.921}", "{\"n\": 7464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3739.88, \"learn_time_ms\": 42922.303}", "{\"n\": 7465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3730.2, \"learn_time_ms\": 42957.424}", "{\"n\": 7466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3717.24, \"learn_time_ms\": 42865.463}", "{\"n\": 7467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3715.51, \"learn_time_ms\": 42883.299}", "{\"n\": 7468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3715.17, \"learn_time_ms\": 42924.845}", "{\"n\": 7469, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3718.69, \"learn_time_ms\": 42975.915}", "{\"n\": 7470, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3723.17, \"learn_time_ms\": 43000.03}", "{\"n\": 7471, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3715.28, \"learn_time_ms\": 42897.248}", "{\"n\": 7472, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3735.16, \"learn_time_ms\": 42859.894}", "{\"n\": 7473, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3735.24, \"learn_time_ms\": 42819.922}", "{\"n\": 7474, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3728.43, \"learn_time_ms\": 42767.899}", "{\"n\": 7475, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3730.19, \"learn_time_ms\": 42624.337}", "{\"n\": 7476, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3734.86, \"learn_time_ms\": 42569.161}", "{\"n\": 7477, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3732.03, \"learn_time_ms\": 42528.797}", "{\"n\": 7478, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3724.84, \"learn_time_ms\": 42505.111}", "{\"n\": 7479, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3743.04, \"learn_time_ms\": 42492.96}", "{\"n\": 7480, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3732.68, \"learn_time_ms\": 42496.314}", "{\"n\": 7481, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3732.68, \"learn_time_ms\": 42661.334}", "{\"n\": 7482, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3738.79, \"learn_time_ms\": 42666.445}", "{\"n\": 7483, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3730.21, \"learn_time_ms\": 42661.626}", "{\"n\": 7484, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3743.15, \"learn_time_ms\": 42727.264}", "{\"n\": 7485, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3740.43, \"learn_time_ms\": 42756.092}", "{\"n\": 7486, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3744.58, \"learn_time_ms\": 42821.43}", "{\"n\": 7487, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3744.58, \"learn_time_ms\": 42802.561}", "{\"n\": 7488, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3730.01, \"learn_time_ms\": 42749.903}", "{\"n\": 7489, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3731.51, \"learn_time_ms\": 42734.067}", "{\"n\": 7490, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3721.81, \"learn_time_ms\": 42701.132}", "{\"n\": 7491, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3728.28, \"learn_time_ms\": 42676.697}", "{\"n\": 7492, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3722.0, \"learn_time_ms\": 42714.129}", "{\"n\": 7493, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3722.0, \"learn_time_ms\": 42723.426}", "{\"n\": 7494, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3710.08, \"learn_time_ms\": 42703.838}", "{\"n\": 7495, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3691.13, \"learn_time_ms\": 42838.715}", "{\"n\": 7496, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3695.03, \"learn_time_ms\": 42824.845}", "{\"n\": 7497, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3674.52, \"learn_time_ms\": 42917.115}", "{\"n\": 7498, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3670.51, \"learn_time_ms\": 43057.359}", "{\"n\": 7499, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3645.61, \"learn_time_ms\": 43044.143}", "{\"n\": 7500, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3640.86, \"learn_time_ms\": 43102.042}", "{\"n\": 7501, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3641.48, \"learn_time_ms\": 43087.111}", "{\"n\": 7502, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3641.48, \"learn_time_ms\": 43099.723}", "{\"n\": 7503, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3642.37, \"learn_time_ms\": 43164.306}", "{\"n\": 7504, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3635.85, \"learn_time_ms\": 43160.171}", "{\"n\": 7505, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3624.11, \"learn_time_ms\": 43050.481}", "{\"n\": 7506, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3624.11, \"learn_time_ms\": 43108.281}", "{\"n\": 7507, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3611.59, \"learn_time_ms\": 43038.01}", "{\"n\": 7508, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3611.59, \"learn_time_ms\": 43038.072}", "{\"n\": 7509, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3626.14, \"learn_time_ms\": 43003.918}", "{\"n\": 7510, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3614.33, \"learn_time_ms\": 42959.347}", "{\"n\": 7511, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3614.33, \"learn_time_ms\": 42941.205}", "{\"n\": 7512, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3595.95, \"learn_time_ms\": 42900.898}", "{\"n\": 7513, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3595.95, \"learn_time_ms\": 42851.264}", "{\"n\": 7514, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3588.43, \"learn_time_ms\": 42893.145}", "{\"n\": 7515, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3588.43, \"learn_time_ms\": 42941.454}", "{\"n\": 7516, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3571.89, \"learn_time_ms\": 42944.43}", "{\"n\": 7517, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3587.11, \"learn_time_ms\": 42986.558}", "{\"n\": 7518, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3586.65, \"learn_time_ms\": 42908.019}", "{\"n\": 7519, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3578.91, \"learn_time_ms\": 43003.113}", "{\"n\": 7520, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3593.03, \"learn_time_ms\": 42946.333}", "{\"n\": 7521, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3619.55, \"learn_time_ms\": 42979.521}", "{\"n\": 7522, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3602.75, \"learn_time_ms\": 43029.717}", "{\"n\": 7523, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3597.46, \"learn_time_ms\": 42976.593}", "{\"n\": 7524, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3597.46, \"learn_time_ms\": 43012.991}", "{\"n\": 7525, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3591.13, \"learn_time_ms\": 42907.534}", "{\"n\": 7526, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.07, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3581.14, \"learn_time_ms\": 42814.562}", "{\"n\": 7527, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3574.49, \"learn_time_ms\": 42851.474}", "{\"n\": 7528, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3574.49, \"learn_time_ms\": 42988.457}", "{\"n\": 7529, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3574.49, \"learn_time_ms\": 42891.456}", "{\"n\": 7530, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3574.18, \"learn_time_ms\": 42998.558}", "{\"n\": 7531, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3579.91, \"learn_time_ms\": 43040.121}", "{\"n\": 7532, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3579.91, \"learn_time_ms\": 43004.599}", "{\"n\": 7533, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.51, \"learn_time_ms\": 43143.944}", "{\"n\": 7534, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.51, \"learn_time_ms\": 43057.297}", "{\"n\": 7535, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3563.51, \"learn_time_ms\": 43099.925}", "{\"n\": 7536, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3561.13, \"learn_time_ms\": 43218.571}", "{\"n\": 7537, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3577.18, \"learn_time_ms\": 43179.439}", "{\"n\": 7538, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3581.8, \"learn_time_ms\": 43090.635}", "{\"n\": 7539, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3582.43, \"learn_time_ms\": 43164.897}", "{\"n\": 7540, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3602.79, \"learn_time_ms\": 43146.331}", "{\"n\": 7541, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3613.69, \"learn_time_ms\": 43007.044}", "{\"n\": 7542, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3623.66, \"learn_time_ms\": 42997.885}", "{\"n\": 7543, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3612.2, \"learn_time_ms\": 42898.15}", "{\"n\": 7544, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3626.84, \"learn_time_ms\": 42907.691}", "{\"n\": 7545, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3626.84, \"learn_time_ms\": 42941.397}", "{\"n\": 7546, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3621.86, \"learn_time_ms\": 42928.399}", "{\"n\": 7547, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3621.86, \"learn_time_ms\": 42944.146}", "{\"n\": 7548, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3612.78, \"learn_time_ms\": 42990.475}", "{\"n\": 7549, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3599.53, \"learn_time_ms\": 43004.373}", "{\"n\": 7550, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3602.35, \"learn_time_ms\": 43018.727}", "{\"n\": 7551, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3587.26, \"learn_time_ms\": 43108.237}", "{\"n\": 7552, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3588.24, \"learn_time_ms\": 43100.405}", "{\"n\": 7553, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3595.35, \"learn_time_ms\": 43136.133}", "{\"n\": 7554, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3601.71, \"learn_time_ms\": 43048.229}", "{\"n\": 7555, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3622.46, \"learn_time_ms\": 43034.681}", "{\"n\": 7556, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3616.24, \"learn_time_ms\": 42994.843}", "{\"n\": 7557, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3623.38, \"learn_time_ms\": 42967.26}", "{\"n\": 7558, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3600.51, \"learn_time_ms\": 42936.98}", "{\"n\": 7559, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3601.36, \"learn_time_ms\": 42945.281}", "{\"n\": 7560, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3591.92, \"learn_time_ms\": 42912.805}", "{\"n\": 7561, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3591.92, \"learn_time_ms\": 42849.013}", "{\"n\": 7562, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3597.09, \"learn_time_ms\": 42852.03}", "{\"n\": 7563, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3592.55, \"learn_time_ms\": 42828.96}", "{\"n\": 7564, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.43, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3592.55, \"learn_time_ms\": 42901.0}", "{\"n\": 7565, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3578.31, \"learn_time_ms\": 42863.0}", "{\"n\": 7566, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3570.24, \"learn_time_ms\": 42862.508}", "{\"n\": 7567, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3573.95, \"learn_time_ms\": 42879.603}", "{\"n\": 7568, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3584.94, \"learn_time_ms\": 42856.704}", "{\"n\": 7569, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3584.94, \"learn_time_ms\": 42961.208}", "{\"n\": 7570, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3597.58, \"learn_time_ms\": 42926.743}", "{\"n\": 7571, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3597.58, \"learn_time_ms\": 42907.196}", "{\"n\": 7572, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3597.58, \"learn_time_ms\": 42922.864}", "{\"n\": 7573, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3597.33, \"learn_time_ms\": 42895.23}", "{\"n\": 7574, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.35, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3601.18, \"learn_time_ms\": 42949.99}", "{\"n\": 7575, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3591.66, \"learn_time_ms\": 42987.828}", "{\"n\": 7576, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3589.45, \"learn_time_ms\": 42917.112}", "{\"n\": 7577, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3580.33, \"learn_time_ms\": 42822.478}", "{\"n\": 7578, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3575.26, \"learn_time_ms\": 42801.328}", "{\"n\": 7579, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3602.91, \"learn_time_ms\": 42679.012}", "{\"n\": 7580, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3602.91, \"learn_time_ms\": 42727.831}", "{\"n\": 7581, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3602.91, \"learn_time_ms\": 42815.521}", "{\"n\": 7582, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3608.42, \"learn_time_ms\": 42804.262}", "{\"n\": 7583, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3598.11, \"learn_time_ms\": 42744.867}", "{\"n\": 7584, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3604.91, \"learn_time_ms\": 42744.253}", "{\"n\": 7585, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3600.81, \"learn_time_ms\": 42782.184}", "{\"n\": 7586, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3600.81, \"learn_time_ms\": 42810.893}", "{\"n\": 7587, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.33, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3600.81, \"learn_time_ms\": 42923.446}", "{\"n\": 7588, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3610.31, \"learn_time_ms\": 42937.051}", "{\"n\": 7589, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3582.7, \"learn_time_ms\": 42960.963}", "{\"n\": 7590, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3582.7, \"learn_time_ms\": 42951.916}", "{\"n\": 7591, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3595.98, \"learn_time_ms\": 43023.207}", "{\"n\": 7592, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3595.98, \"learn_time_ms\": 43040.118}", "{\"n\": 7593, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3595.98, \"learn_time_ms\": 43076.666}", "{\"n\": 7594, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3586.3, \"learn_time_ms\": 43050.06}", "{\"n\": 7595, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3566.21, \"learn_time_ms\": 43011.619}", "{\"n\": 7596, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3566.21, \"learn_time_ms\": 43006.336}", "{\"n\": 7597, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.87, \"learn_time_ms\": 43017.15}", "{\"n\": 7598, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3559.87, \"learn_time_ms\": 42964.648}", "{\"n\": 7599, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3553.46, \"learn_time_ms\": 42907.61}", "{\"n\": 7600, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.45, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3553.46, \"learn_time_ms\": 42879.996}", "{\"n\": 7601, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3573.99, \"learn_time_ms\": 42731.637}", "{\"n\": 7602, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 42873.154}", "{\"n\": 7603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3566.75, \"learn_time_ms\": 42921.386}", "{\"n\": 7604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3566.75, \"learn_time_ms\": 42872.415}", "{\"n\": 7605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3570.8, \"learn_time_ms\": 42864.419}", "{\"n\": 7606, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3565.19, \"learn_time_ms\": 42899.712}", "{\"n\": 7607, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3573.76, \"learn_time_ms\": 42794.51}", "{\"n\": 7608, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3587.58, \"learn_time_ms\": 42829.045}", "{\"n\": 7609, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3587.58, \"learn_time_ms\": 42981.481}", "{\"n\": 7610, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3587.58, \"learn_time_ms\": 42958.103}", "{\"n\": 7611, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3566.08, \"learn_time_ms\": 43049.671}", "{\"n\": 7612, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3548.89, \"learn_time_ms\": 42826.125}", "{\"n\": 7613, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.31, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3549.49, \"learn_time_ms\": 42755.43}", "{\"n\": 7614, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3537.41, \"learn_time_ms\": 42828.762}", "{\"n\": 7615, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3537.41, \"learn_time_ms\": 42849.181}", "{\"n\": 7616, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3537.41, \"learn_time_ms\": 42820.799}", "{\"n\": 7617, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3537.41, \"learn_time_ms\": 42932.508}", "{\"n\": 7618, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3542.25, \"learn_time_ms\": 42881.391}", "{\"n\": 7619, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.32, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3525.83, \"learn_time_ms\": 42805.628}", "{\"n\": 7620, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3536.46, \"learn_time_ms\": 42837.963}", "{\"n\": 7621, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3538.09, \"learn_time_ms\": 42785.534}", "{\"n\": 7622, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3538.09, \"learn_time_ms\": 42798.896}", "{\"n\": 7623, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3549.28, \"learn_time_ms\": 42863.15}", "{\"n\": 7624, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3553.8, \"learn_time_ms\": 42814.097}", "{\"n\": 7625, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3568.29, \"learn_time_ms\": 42781.829}", "{\"n\": 7626, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3574.12, \"learn_time_ms\": 42794.677}", "{\"n\": 7627, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.33, \"learn_time_ms\": 42691.708}", "{\"n\": 7628, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3567.33, \"learn_time_ms\": 42759.296}", "{\"n\": 7629, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3532.75, \"learn_time_ms\": 42666.362}", "{\"n\": 7630, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3532.75, \"learn_time_ms\": 42716.255}", "{\"n\": 7631, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3528.92, \"learn_time_ms\": 42715.092}", "{\"n\": 7632, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3538.14, \"learn_time_ms\": 42713.634}", "{\"n\": 7633, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3538.14, \"learn_time_ms\": 42762.47}", "{\"n\": 7634, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3527.17, \"learn_time_ms\": 42755.206}", "{\"n\": 7635, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3529.74, \"learn_time_ms\": 42708.828}", "{\"n\": 7636, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.09, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3538.2, \"learn_time_ms\": 42697.312}", "{\"n\": 7637, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3545.22, \"learn_time_ms\": 42722.396}", "{\"n\": 7638, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3545.22, \"learn_time_ms\": 42749.357}", "{\"n\": 7639, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3547.32, \"learn_time_ms\": 42714.734}", "{\"n\": 7640, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3559.67, \"learn_time_ms\": 42696.546}", "{\"n\": 7641, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3575.92, \"learn_time_ms\": 42736.625}", "{\"n\": 7642, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3572.71, \"learn_time_ms\": 42692.324}", "{\"n\": 7643, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.46, \"learn_time_ms\": 42665.495}", "{\"n\": 7644, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3588.84, \"learn_time_ms\": 42638.676}", "{\"n\": 7645, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3581.05, \"learn_time_ms\": 42725.771}", "{\"n\": 7646, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3581.05, \"learn_time_ms\": 42792.263}", "{\"n\": 7647, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3588.97, \"learn_time_ms\": 42790.517}", "{\"n\": 7648, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3591.69, \"learn_time_ms\": 42719.674}", "{\"n\": 7649, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3607.6, \"learn_time_ms\": 42840.925}", "{\"n\": 7650, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.5, \"learn_time_ms\": 42767.05}", "{\"n\": 7651, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3583.71, \"learn_time_ms\": 42689.902}", "{\"n\": 7652, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3583.71, \"learn_time_ms\": 42788.632}", "{\"n\": 7653, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.2, \"learn_time_ms\": 42715.518}", "{\"n\": 7654, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3562.17, \"learn_time_ms\": 42696.49}", "{\"n\": 7655, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3554.91, \"learn_time_ms\": 42666.474}", "{\"n\": 7656, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3552.76, \"learn_time_ms\": 42596.838}", "{\"n\": 7657, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3553.66, \"learn_time_ms\": 42639.355}", "{\"n\": 7658, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3554.31, \"learn_time_ms\": 42713.092}", "{\"n\": 7659, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3554.31, \"learn_time_ms\": 42731.13}", "{\"n\": 7660, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3568.48, \"learn_time_ms\": 42877.234}", "{\"n\": 7661, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3568.01, \"learn_time_ms\": 42913.191}", "{\"n\": 7662, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3568.01, \"learn_time_ms\": 42900.413}", "{\"n\": 7663, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3562.64, \"learn_time_ms\": 42927.829}", "{\"n\": 7664, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3585.44, \"learn_time_ms\": 42959.071}", "{\"n\": 7665, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3552.62, \"learn_time_ms\": 42946.457}", "{\"n\": 7666, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3552.62, \"learn_time_ms\": 42915.863}", "{\"n\": 7667, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3576.42, \"learn_time_ms\": 43009.917}", "{\"n\": 7668, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3576.42, \"learn_time_ms\": 43100.432}", "{\"n\": 7669, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3576.42, \"learn_time_ms\": 43029.225}", "{\"n\": 7670, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.33, \"learn_time_ms\": 42942.659}", "{\"n\": 7671, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.81, \"learn_time_ms\": 42882.481}", "{\"n\": 7672, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.09, \"learn_time_ms\": 42855.909}", "{\"n\": 7673, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.09, \"learn_time_ms\": 42835.94}", "{\"n\": 7674, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.09, \"learn_time_ms\": 42866.747}", "{\"n\": 7675, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3582.3, \"learn_time_ms\": 42895.659}", "{\"n\": 7676, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.24, \"learn_time_ms\": 42965.873}", "{\"n\": 7677, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3596.86, \"learn_time_ms\": 42830.897}", "{\"n\": 7678, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3592.49, \"learn_time_ms\": 42679.608}", "{\"n\": 7679, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3584.79, \"learn_time_ms\": 42692.056}", "{\"n\": 7680, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3562.29, \"learn_time_ms\": 42581.359}", "{\"n\": 7681, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3542.83, \"learn_time_ms\": 42694.843}", "{\"n\": 7682, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3542.83, \"learn_time_ms\": 42704.528}", "{\"n\": 7683, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3539.7, \"learn_time_ms\": 42730.64}", "{\"n\": 7684, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3544.61, \"learn_time_ms\": 42773.555}", "{\"n\": 7685, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.39, \"learn_time_ms\": 42768.58}", "{\"n\": 7686, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3559.01, \"learn_time_ms\": 42759.26}", "{\"n\": 7687, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3555.46, \"learn_time_ms\": 42829.465}", "{\"n\": 7688, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3555.46, \"learn_time_ms\": 42878.729}", "{\"n\": 7689, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3550.46, \"learn_time_ms\": 42932.969}", "{\"n\": 7690, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3553.08, \"learn_time_ms\": 43101.798}", "{\"n\": 7691, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3551.73, \"learn_time_ms\": 42962.967}", "{\"n\": 7692, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3544.04, \"learn_time_ms\": 43004.707}", "{\"n\": 7693, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3535.54, \"learn_time_ms\": 43138.422}", "{\"n\": 7694, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3529.4, \"learn_time_ms\": 43093.012}", "{\"n\": 7695, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3525.07, \"learn_time_ms\": 43158.836}", "{\"n\": 7696, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3533.78, \"learn_time_ms\": 43174.956}", "{\"n\": 7697, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3507.37, \"learn_time_ms\": 43123.242}", "{\"n\": 7698, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3507.37, \"learn_time_ms\": 43043.021}", "{\"n\": 7699, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3493.76, \"learn_time_ms\": 43036.102}", "{\"n\": 7700, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3466.38, \"learn_time_ms\": 42921.425}", "{\"n\": 7701, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3466.38, \"learn_time_ms\": 42954.548}", "{\"n\": 7702, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3466.38, \"learn_time_ms\": 42866.773}", "{\"n\": 7703, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -8.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3485.72, \"learn_time_ms\": 42757.212}", "{\"n\": 7704, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3480.31, \"learn_time_ms\": 42748.849}", "{\"n\": 7705, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3480.97, \"learn_time_ms\": 42704.799}", "{\"n\": 7706, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3474.68, \"learn_time_ms\": 42672.527}", "{\"n\": 7707, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3453.14, \"learn_time_ms\": 42647.745}", "{\"n\": 7708, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3453.14, \"learn_time_ms\": 42819.959}", "{\"n\": 7709, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3453.17, \"learn_time_ms\": 42757.493}", "{\"n\": 7710, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3459.76, \"learn_time_ms\": 42821.728}", "{\"n\": 7711, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3428.63, \"learn_time_ms\": 42859.081}", "{\"n\": 7712, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3435.46, \"learn_time_ms\": 42926.806}", "{\"n\": 7713, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3446.44, \"learn_time_ms\": 42934.873}", "{\"n\": 7714, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3446.44, \"learn_time_ms\": 42883.398}", "{\"n\": 7715, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3446.44, \"learn_time_ms\": 42924.373}", "{\"n\": 7716, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3449.75, \"learn_time_ms\": 43084.952}", "{\"n\": 7717, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3449.75, \"learn_time_ms\": 43134.02}", "{\"n\": 7718, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3442.8, \"learn_time_ms\": 42978.907}", "{\"n\": 7719, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3442.8, \"learn_time_ms\": 43065.709}", "{\"n\": 7720, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3442.8, \"learn_time_ms\": 43092.476}", "{\"n\": 7721, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3439.89, \"learn_time_ms\": 43122.899}", "{\"n\": 7722, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3433.81, \"learn_time_ms\": 43161.348}", "{\"n\": 7723, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3462.67, \"learn_time_ms\": 43171.599}", "{\"n\": 7724, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3462.67, \"learn_time_ms\": 43266.115}", "{\"n\": 7725, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3462.67, \"learn_time_ms\": 43172.739}", "{\"n\": 7726, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3460.14, \"learn_time_ms\": 43062.872}", "{\"n\": 7727, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.36, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3467.84, \"learn_time_ms\": 42990.628}", "{\"n\": 7728, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3456.98, \"learn_time_ms\": 43028.566}", "{\"n\": 7729, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3451.76, \"learn_time_ms\": 42955.59}", "{\"n\": 7730, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3441.42, \"learn_time_ms\": 42936.976}", "{\"n\": 7731, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3427.5, \"learn_time_ms\": 42965.838}", "{\"n\": 7732, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3415.73, \"learn_time_ms\": 42885.226}", "{\"n\": 7733, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3398.77, \"learn_time_ms\": 42829.926}", "{\"n\": 7734, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3410.73, \"learn_time_ms\": 42783.392}", "{\"n\": 7735, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3407.43, \"learn_time_ms\": 42884.488}", "{\"n\": 7736, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3411.01, \"learn_time_ms\": 42888.409}", "{\"n\": 7737, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3396.23, \"learn_time_ms\": 42981.457}", "{\"n\": 7738, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3380.43, \"learn_time_ms\": 42943.722}", "{\"n\": 7739, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3362.25, \"learn_time_ms\": 42909.692}", "{\"n\": 7740, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3355.18, \"learn_time_ms\": 42859.852}", "{\"n\": 7741, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3355.18, \"learn_time_ms\": 42851.786}", "{\"n\": 7742, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -9.08, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.7, \"learn_time_ms\": 42865.196}", "{\"n\": 7743, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.05, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3344.82, \"learn_time_ms\": 42885.846}", "{\"n\": 7744, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.07, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3342.91, \"learn_time_ms\": 42940.463}", "{\"n\": 7745, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.04, \"learn_time_ms\": 42911.695}", "{\"n\": 7746, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.04, \"learn_time_ms\": 42885.122}", "{\"n\": 7747, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.15, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3329.31, \"learn_time_ms\": 42854.895}", "{\"n\": 7748, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.11, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3335.03, \"learn_time_ms\": 42848.015}", "{\"n\": 7749, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -9.09, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3341.7, \"learn_time_ms\": 42857.298}", "{\"n\": 7750, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.98, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3361.12, \"learn_time_ms\": 42860.488}", "{\"n\": 7751, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.48, \"learn_time_ms\": 42782.288}", "{\"n\": 7752, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.71, \"learn_time_ms\": 42804.7}", "{\"n\": 7753, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.89, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3373.71, \"learn_time_ms\": 42794.606}", "{\"n\": 7754, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3371.22, \"learn_time_ms\": 42721.549}", "{\"n\": 7755, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.96, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3365.05, \"learn_time_ms\": 42753.553}", "{\"n\": 7756, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.92, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3369.96, \"learn_time_ms\": 42841.785}", "{\"n\": 7757, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.2, \"learn_time_ms\": 42822.835}", "{\"n\": 7758, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.9, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3372.76, \"learn_time_ms\": 42907.396}", "{\"n\": 7759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3382.25, \"learn_time_ms\": 43013.435}", "{\"n\": 7760, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.23, \"learn_time_ms\": 42992.126}", "{\"n\": 7761, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3391.87, \"learn_time_ms\": 43007.606}", "{\"n\": 7762, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.83, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3397.2, \"learn_time_ms\": 43046.086}", "{\"n\": 7763, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.25, \"learn_time_ms\": 43059.892}", "{\"n\": 7764, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.25, \"learn_time_ms\": 43140.134}", "{\"n\": 7765, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.8, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3411.22, \"learn_time_ms\": 43121.42}", "{\"n\": 7766, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3415.98, \"learn_time_ms\": 42995.961}", "{\"n\": 7767, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.5, \"learn_time_ms\": 43044.888}", "{\"n\": 7768, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3404.9, \"learn_time_ms\": 43014.435}", "{\"n\": 7769, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3408.64, \"learn_time_ms\": 43040.381}", "{\"n\": 7770, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3410.28, \"learn_time_ms\": 43034.221}", "{\"n\": 7771, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.78, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3414.37, \"learn_time_ms\": 43061.705}", "{\"n\": 7772, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3421.58, \"learn_time_ms\": 43140.259}", "{\"n\": 7773, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3432.66, \"learn_time_ms\": 43117.54}", "{\"n\": 7774, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3418.54, \"learn_time_ms\": 42987.927}", "{\"n\": 7775, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.05, \"learn_time_ms\": 42912.492}", "{\"n\": 7776, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.05, \"learn_time_ms\": 42986.843}", "{\"n\": 7777, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.79, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3417.05, \"learn_time_ms\": 42967.299}", "{\"n\": 7778, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.84, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3407.37, \"learn_time_ms\": 43059.31}", "{\"n\": 7779, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3426.53, \"learn_time_ms\": 42995.84}", "{\"n\": 7780, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3426.53, \"learn_time_ms\": 42989.419}", "{\"n\": 7781, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3426.05, \"learn_time_ms\": 42974.631}", "{\"n\": 7782, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3418.18, \"learn_time_ms\": 42809.56}", "{\"n\": 7783, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3401.58, \"learn_time_ms\": 42748.885}", "{\"n\": 7784, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3397.77, \"learn_time_ms\": 42866.371}", "{\"n\": 7785, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3394.31, \"learn_time_ms\": 42827.393}", "{\"n\": 7786, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3394.1, \"learn_time_ms\": 42799.801}", "{\"n\": 7787, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3394.1, \"learn_time_ms\": 42826.076}", "{\"n\": 7788, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3394.1, \"learn_time_ms\": 42780.854}", "{\"n\": 7789, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3391.14, \"learn_time_ms\": 42793.987}", "{\"n\": 7790, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3369.16, \"learn_time_ms\": 42923.597}", "{\"n\": 7791, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3363.93, \"learn_time_ms\": 42943.562}", "{\"n\": 7792, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3377.23, \"learn_time_ms\": 43073.901}", "{\"n\": 7793, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3377.11, \"learn_time_ms\": 43216.227}", "{\"n\": 7794, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3384.72, \"learn_time_ms\": 43233.55}", "{\"n\": 7795, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3384.25, \"learn_time_ms\": 43240.517}", "{\"n\": 7796, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3387.48, \"learn_time_ms\": 43187.826}", "{\"n\": 7797, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3376.41, \"learn_time_ms\": 43287.421}", "{\"n\": 7798, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3376.41, \"learn_time_ms\": 43252.714}", "{\"n\": 7799, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3381.35, \"learn_time_ms\": 43254.203}", "{\"n\": 7800, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3381.35, \"learn_time_ms\": 43154.164}", "{\"n\": 7801, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3379.7, \"learn_time_ms\": 43134.53}", "{\"n\": 7802, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3404.99, \"learn_time_ms\": 43120.472}", "{\"n\": 7803, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3403.59, \"learn_time_ms\": 42961.301}", "{\"n\": 7804, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3403.59, \"learn_time_ms\": 42962.956}", "{\"n\": 7805, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3403.59, \"learn_time_ms\": 43050.673}", "{\"n\": 7806, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3412.59, \"learn_time_ms\": 43022.122}", "{\"n\": 7807, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3410.84, \"learn_time_ms\": 42923.578}", "{\"n\": 7808, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3421.07, \"learn_time_ms\": 43004.188}", "{\"n\": 7809, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3417.09, \"learn_time_ms\": 43039.501}", "{\"n\": 7810, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3417.09, \"learn_time_ms\": 43166.457}", "{\"n\": 7811, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3422.02, \"learn_time_ms\": 43209.906}", "{\"n\": 7812, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3428.18, \"learn_time_ms\": 43261.11}", "{\"n\": 7813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3454.75, \"learn_time_ms\": 43322.654}", "{\"n\": 7814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3444.97, \"learn_time_ms\": 43347.742}", "{\"n\": 7815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3444.97, \"learn_time_ms\": 43351.487}", "{\"n\": 7816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3444.97, \"learn_time_ms\": 43493.557}", "{\"n\": 7817, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3434.03, \"learn_time_ms\": 43445.183}", "{\"n\": 7818, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3426.77, \"learn_time_ms\": 43366.234}", "{\"n\": 7819, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3429.85, \"learn_time_ms\": 43303.69}", "{\"n\": 7820, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3420.99, \"learn_time_ms\": 43174.127}", "{\"n\": 7821, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3423.96, \"learn_time_ms\": 43078.563}", "{\"n\": 7822, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3431.96, \"learn_time_ms\": 43042.03}", "{\"n\": 7823, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3433.98, \"learn_time_ms\": 43128.517}", "{\"n\": 7824, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3444.6, \"learn_time_ms\": 43011.323}", "{\"n\": 7825, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3433.44, \"learn_time_ms\": 42985.083}", "{\"n\": 7826, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3429.42, \"learn_time_ms\": 42967.753}", "{\"n\": 7827, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3420.67, \"learn_time_ms\": 43054.551}", "{\"n\": 7828, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3407.12, \"learn_time_ms\": 43038.912}", "{\"n\": 7829, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3407.12, \"learn_time_ms\": 42991.307}", "{\"n\": 7830, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3385.05, \"learn_time_ms\": 43064.788}", "{\"n\": 7831, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3370.0, \"learn_time_ms\": 43146.642}", "{\"n\": 7832, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3392.79, \"learn_time_ms\": 43212.885}", "{\"n\": 7833, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3401.29, \"learn_time_ms\": 43200.839}", "{\"n\": 7834, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3401.29, \"learn_time_ms\": 43181.873}", "{\"n\": 7835, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3401.34, \"learn_time_ms\": 43177.804}", "{\"n\": 7836, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3403.23, \"learn_time_ms\": 43122.017}", "{\"n\": 7837, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3387.8, \"learn_time_ms\": 43038.757}", "{\"n\": 7838, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3385.63, \"learn_time_ms\": 43077.939}", "{\"n\": 7839, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -8.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3393.6, \"learn_time_ms\": 43117.285}", "{\"n\": 7840, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3411.76, \"learn_time_ms\": 43082.702}", "{\"n\": 7841, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3417.92, \"learn_time_ms\": 43010.449}", "{\"n\": 7842, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3417.92, \"learn_time_ms\": 42949.134}", "{\"n\": 7843, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3417.92, \"learn_time_ms\": 42968.194}", "{\"n\": 7844, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3419.42, \"learn_time_ms\": 43042.902}", "{\"n\": 7845, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3424.99, \"learn_time_ms\": 43158.962}", "{\"n\": 7846, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3412.63, \"learn_time_ms\": 43118.44}", "{\"n\": 7847, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3413.67, \"learn_time_ms\": 43173.403}", "{\"n\": 7848, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3422.9, \"learn_time_ms\": 43199.256}", "{\"n\": 7849, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3442.68, \"learn_time_ms\": 43147.785}", "{\"n\": 7850, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3438.09, \"learn_time_ms\": 43176.762}", "{\"n\": 7851, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3433.81, \"learn_time_ms\": 43255.185}", "{\"n\": 7852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3435.43, \"learn_time_ms\": 43187.481}", "{\"n\": 7853, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.95, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3445.86, \"learn_time_ms\": 43085.476}", "{\"n\": 7854, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3443.74, \"learn_time_ms\": 43066.427}", "{\"n\": 7855, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3443.74, \"learn_time_ms\": 42958.192}", "{\"n\": 7856, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.93, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3451.35, \"learn_time_ms\": 43064.704}", "{\"n\": 7857, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.87, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3455.79, \"learn_time_ms\": 42954.161}", "{\"n\": 7858, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3456.77, \"learn_time_ms\": 42934.913}", "{\"n\": 7859, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3456.77, \"learn_time_ms\": 43019.514}", "{\"n\": 7860, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.88, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3445.78, \"learn_time_ms\": 43014.076}", "{\"n\": 7861, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3445.11, \"learn_time_ms\": 43059.571}", "{\"n\": 7862, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3452.65, \"learn_time_ms\": 43015.111}", "{\"n\": 7863, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.7, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3465.4, \"learn_time_ms\": 43113.672}", "{\"n\": 7864, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3451.96, \"learn_time_ms\": 43091.59}", "{\"n\": 7865, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3454.59, \"learn_time_ms\": 43147.733}", "{\"n\": 7866, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3454.59, \"learn_time_ms\": 43071.23}", "{\"n\": 7867, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3441.26, \"learn_time_ms\": 43167.631}", "{\"n\": 7868, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3441.26, \"learn_time_ms\": 43178.652}", "{\"n\": 7869, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3458.95, \"learn_time_ms\": 43038.309}", "{\"n\": 7870, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3458.01, \"learn_time_ms\": 43048.766}", "{\"n\": 7871, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.81, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3455.58, \"learn_time_ms\": 43076.862}", "{\"n\": 7872, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3442.78, \"learn_time_ms\": 43094.849}", "{\"n\": 7873, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3434.41, \"learn_time_ms\": 43140.613}", "{\"n\": 7874, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.91, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3437.13, \"learn_time_ms\": 43106.382}", "{\"n\": 7875, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3434.19, \"learn_time_ms\": 42983.858}", "{\"n\": 7876, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3413.09, \"learn_time_ms\": 43057.601}", "{\"n\": 7877, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.01, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3413.09, \"learn_time_ms\": 43009.245}", "{\"n\": 7878, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3408.02, \"learn_time_ms\": 43014.0}", "{\"n\": 7879, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3397.62, \"learn_time_ms\": 43159.439}", "{\"n\": 7880, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3404.69, \"learn_time_ms\": 43161.796}", "{\"n\": 7881, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3392.12, \"learn_time_ms\": 43192.876}", "{\"n\": 7882, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3392.46, \"learn_time_ms\": 43230.908}", "{\"n\": 7883, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3374.28, \"learn_time_ms\": 43207.273}", "{\"n\": 7884, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.26, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3374.28, \"learn_time_ms\": 43297.108}", "{\"n\": 7885, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3382.75, \"learn_time_ms\": 43403.053}", "{\"n\": 7886, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3384.27, \"learn_time_ms\": 43352.347}", "{\"n\": 7887, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3379.18, \"learn_time_ms\": 43422.784}", "{\"n\": 7888, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.3, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3368.74, \"learn_time_ms\": 43482.276}", "{\"n\": 7889, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3358.81, \"learn_time_ms\": 43357.099}", "{\"n\": 7890, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3359.94, \"learn_time_ms\": 43388.813}", "{\"n\": 7891, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3362.41, \"learn_time_ms\": 43301.865}", "{\"n\": 7892, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.44, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3362.41, \"learn_time_ms\": 43291.032}", "{\"n\": 7893, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.47, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3358.74, \"learn_time_ms\": 43270.764}", "{\"n\": 7894, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3351.42, \"learn_time_ms\": 43207.561}", "{\"n\": 7895, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3338.71, \"learn_time_ms\": 43202.528}", "{\"n\": 7896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.65, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3331.68, \"learn_time_ms\": 43209.755}", "{\"n\": 7897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3330.33, \"learn_time_ms\": 43210.901}", "{\"n\": 7898, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.32, \"learn_time_ms\": 43094.257}", "{\"n\": 7899, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.48, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3346.32, \"learn_time_ms\": 43156.099}", "{\"n\": 7900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.93, \"learn_time_ms\": 43149.474}", "{\"n\": 7901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.46, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3356.93, \"learn_time_ms\": 43048.837}", "{\"n\": 7902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3333.63, \"learn_time_ms\": 43094.043}", "{\"n\": 7903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.38, \"learn_time_ms\": 43077.227}", "{\"n\": 7904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.64, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.38, \"learn_time_ms\": 43157.32}", "{\"n\": 7905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.4, \"learn_time_ms\": 43136.428}", "{\"n\": 7906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3326.4, \"learn_time_ms\": 43110.864}", "{\"n\": 7907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.6, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3325.63, \"learn_time_ms\": 43127.992}", "{\"n\": 7908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.52, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3339.18, \"learn_time_ms\": 43142.393}", "{\"n\": 7909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.46, \"learn_time_ms\": 43172.674}", "{\"n\": 7910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.04, \"learn_time_ms\": 43151.965}", "{\"n\": 7911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.63, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3316.04, \"learn_time_ms\": 43185.663}", "{\"n\": 7912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.53, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3327.75, \"learn_time_ms\": 43118.972}", "{\"n\": 7913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3322.09, \"learn_time_ms\": 43066.453}", "{\"n\": 7914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.62, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3314.51, \"learn_time_ms\": 43029.841}", "{\"n\": 7915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.53, \"learn_time_ms\": 42989.028}", "{\"n\": 7916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.53, \"learn_time_ms\": 42982.969}", "{\"n\": 7917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": -1.0, \"episode_len_mean\": 3320.53, \"learn_time_ms\": 42900.77}", "{\"n\": 7918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.59, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3304.94, \"learn_time_ms\": 42870.893}", "{\"n\": 7919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3297.22, \"learn_time_ms\": 42851.424}", "{\"n\": 7920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.61, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3297.22, \"learn_time_ms\": 42774.529}", "{\"n\": 7921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.58, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3302.52, \"learn_time_ms\": 42790.227}", "{\"n\": 7922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3314.86, \"learn_time_ms\": 42819.111}", "{\"n\": 7923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3303.86, \"learn_time_ms\": 42812.901}", "{\"n\": 7924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3278.46, \"learn_time_ms\": 42787.324}", "{\"n\": 7925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.69, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3285.4, \"learn_time_ms\": 42934.604}", "{\"n\": 7926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.74, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3281.6, \"learn_time_ms\": 42943.873}", "{\"n\": 7927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3295.83, \"learn_time_ms\": 43042.923}", "{\"n\": 7928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3295.83, \"learn_time_ms\": 43152.134}", "{\"n\": 7929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.66, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3308.57, \"learn_time_ms\": 43069.237}", "{\"n\": 7930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.56, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3325.74, \"learn_time_ms\": 43060.35}", "{\"n\": 7931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.68, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3318.95, \"learn_time_ms\": 43045.753}", "{\"n\": 7932, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3309.01, \"learn_time_ms\": 43091.485}", "{\"n\": 7933, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3309.01, \"learn_time_ms\": 43119.753}", "{\"n\": 7934, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3309.01, \"learn_time_ms\": 43340.772}", "{\"n\": 7935, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.82, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3288.24, \"learn_time_ms\": 43200.037}", "{\"n\": 7936, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.77, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3299.0, \"learn_time_ms\": 43204.204}", "{\"n\": 7937, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.72, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3306.6, \"learn_time_ms\": 43175.65}", "{\"n\": 7938, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.73, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3301.2, \"learn_time_ms\": 43119.693}", "{\"n\": 7939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.85, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3284.51, \"learn_time_ms\": 43201.601}", "{\"n\": 7940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3289.8, \"learn_time_ms\": 43328.982}", "{\"n\": 7941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.81, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3289.8, \"learn_time_ms\": 43385.691}", "{\"n\": 7942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.75, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3294.14, \"learn_time_ms\": 43424.784}", "{\"n\": 7943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3301.97, \"learn_time_ms\": 43447.946}", "{\"n\": 7944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.71, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3301.97, \"learn_time_ms\": 43286.193}", "{\"n\": 7945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.67, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3309.51, \"learn_time_ms\": 43304.441}", "{\"n\": 7946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3323.57, \"learn_time_ms\": 43293.145}", "{\"n\": 7947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3343.77, \"learn_time_ms\": 43266.543}", "{\"n\": 7948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3349.07, \"learn_time_ms\": 43212.61}", "{\"n\": 7949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3351.52, \"learn_time_ms\": 43229.2}", "{\"n\": 7950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3351.52, \"learn_time_ms\": 43207.46}", "{\"n\": 7951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3364.69, \"learn_time_ms\": 43153.486}", "{\"n\": 7952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3375.32, \"learn_time_ms\": 43127.396}", "{\"n\": 7953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3405.66, \"learn_time_ms\": 43128.197}", "{\"n\": 7954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3417.36, \"learn_time_ms\": 43061.918}", "{\"n\": 7955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3417.36, \"learn_time_ms\": 43051.892}", "{\"n\": 7956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3421.78, \"learn_time_ms\": 43084.257}", "{\"n\": 7957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3428.96, \"learn_time_ms\": 43118.863}", "{\"n\": 7958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3432.39, \"learn_time_ms\": 43222.317}", "{\"n\": 7959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3438.39, \"learn_time_ms\": 43188.032}", "{\"n\": 7960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3441.81, \"learn_time_ms\": 43193.774}", "{\"n\": 7961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3451.57, \"learn_time_ms\": 43162.433}", "{\"n\": 7962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3451.57, \"learn_time_ms\": 43048.216}", "{\"n\": 7963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3438.1, \"learn_time_ms\": 43086.61}", "{\"n\": 7964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3440.43, \"learn_time_ms\": 43087.314}", "{\"n\": 7965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3440.43, \"learn_time_ms\": 43082.116}", "{\"n\": 7966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3442.24, \"learn_time_ms\": 43089.643}", "{\"n\": 7967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3470.49, \"learn_time_ms\": 42946.237}", "{\"n\": 7968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3470.49, \"learn_time_ms\": 42781.075}", "{\"n\": 7969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3474.92, \"learn_time_ms\": 42735.735}", "{\"n\": 7970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3469.15, \"learn_time_ms\": 42682.184}", "{\"n\": 7971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3483.19, \"learn_time_ms\": 42801.019}", "{\"n\": 7972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3490.07, \"learn_time_ms\": 42934.962}", "{\"n\": 7973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3490.07, \"learn_time_ms\": 42760.742}", "{\"n\": 7974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3498.16, \"learn_time_ms\": 42733.177}", "{\"n\": 7975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3478.29, \"learn_time_ms\": 42734.288}", "{\"n\": 7976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3484.57, \"learn_time_ms\": 42622.603}", "{\"n\": 7977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3505.02, \"learn_time_ms\": 42733.341}", "{\"n\": 7978, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3505.37, \"learn_time_ms\": 42825.978}", "{\"n\": 7979, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3505.37, \"learn_time_ms\": 43031.074}", "{\"n\": 7980, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3479.05, \"learn_time_ms\": 43004.802}", "{\"n\": 7981, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3479.05, \"learn_time_ms\": 42942.607}", "{\"n\": 7982, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3492.06, \"learn_time_ms\": 42884.336}", "{\"n\": 7983, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3489.85, \"learn_time_ms\": 43102.803}", "{\"n\": 7984, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3489.85, \"learn_time_ms\": 43128.417}", "{\"n\": 7985, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3500.92, \"learn_time_ms\": 43053.144}", "{\"n\": 7986, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3496.08, \"learn_time_ms\": 43254.341}", "{\"n\": 7987, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3503.68, \"learn_time_ms\": 43307.952}", "{\"n\": 7988, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3499.48, \"learn_time_ms\": 43298.247}", "{\"n\": 7989, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3499.48, \"learn_time_ms\": 43235.768}", "{\"n\": 7990, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3483.89, \"learn_time_ms\": 43240.515}", "{\"n\": 7991, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3510.09, \"learn_time_ms\": 43339.533}", "{\"n\": 7992, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3510.09, \"learn_time_ms\": 43271.042}", "{\"n\": 7993, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3493.75, \"learn_time_ms\": 43116.623}", "{\"n\": 7994, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3493.75, \"learn_time_ms\": 43145.987}", "{\"n\": 7995, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3493.75, \"learn_time_ms\": 43267.863}", "{\"n\": 7996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3524.14, \"learn_time_ms\": 43117.689}", "{\"n\": 7997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3521.9, \"learn_time_ms\": 43057.98}", "{\"n\": 7998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3521.9, \"learn_time_ms\": 43157.527}", "{\"n\": 7999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3519.35, \"learn_time_ms\": 43106.467}", "{\"n\": 8000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3499.74, \"learn_time_ms\": 43084.185}"]["{\"n\": 8001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 44238.396}", "{\"n\": 8002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43222.912}", "{\"n\": 8003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42854.28}", "{\"n\": 8004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42786.397}", "{\"n\": 8005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42782.32}", "{\"n\": 8006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42842.107}", "{\"n\": 8007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42789.325}", "{\"n\": 8008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42768.142}", "{\"n\": 8009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42757.57}", "{\"n\": 8010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42762.241}", "{\"n\": 8011, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3510.5, \"learn_time_ms\": 42573.355}", "{\"n\": 8012, \"episode_reward_min\": -8.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": -7.0, \"episode_len_mean\": 3510.5, \"learn_time_ms\": 42616.347}", "{\"n\": 8013, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -7.8, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3352.6, \"learn_time_ms\": 42633.671}", "{\"n\": 8014, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3645.375, \"learn_time_ms\": 42636.343}", "{\"n\": 8015, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3645.375, \"learn_time_ms\": 42567.407}", "{\"n\": 8016, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3645.375, \"learn_time_ms\": 42490.936}", "{\"n\": 8017, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3645.375, \"learn_time_ms\": 42488.806}", "{\"n\": 8018, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.153846153846154, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3683.153846153846, \"learn_time_ms\": 42438.365}", "{\"n\": 8019, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.142857142857143, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3670.214285714286, \"learn_time_ms\": 42470.989}", "{\"n\": 8020, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.1875, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3654.875, \"learn_time_ms\": 42455.365}", "{\"n\": 8021, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.1875, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3654.875, \"learn_time_ms\": 42525.648}", "{\"n\": 8022, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.117647058823529, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3669.294117647059, \"learn_time_ms\": 42616.059}", "{\"n\": 8023, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.277777777777778, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3643.3333333333335, \"learn_time_ms\": 42666.348}", "{\"n\": 8024, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3656.1, \"learn_time_ms\": 42709.979}", "{\"n\": 8025, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3667.8636363636365, \"learn_time_ms\": 42709.554}", "{\"n\": 8026, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.869565217391305, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3620.3478260869565, \"learn_time_ms\": 42746.877}", "{\"n\": 8027, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.869565217391305, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3620.3478260869565, \"learn_time_ms\": 42835.002}", "{\"n\": 8028, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.04, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3590.28, \"learn_time_ms\": 42921.43}", "{\"n\": 8029, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.592592592592593, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3516.814814814815, \"learn_time_ms\": 42915.427}", "{\"n\": 8030, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.172413793103448, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3570.1724137931033, \"learn_time_ms\": 43045.883}", "{\"n\": 8031, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.032258064516129, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3585.1290322580644, \"learn_time_ms\": 43020.414}", "{\"n\": 8032, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.032258064516129, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3585.1290322580644, \"learn_time_ms\": 42948.11}", "{\"n\": 8033, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3590.7272727272725, \"learn_time_ms\": 43068.594}", "{\"n\": 8034, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.117647058823529, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3579.470588235294, \"learn_time_ms\": 43036.427}", "{\"n\": 8035, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.171428571428572, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3575.714285714286, \"learn_time_ms\": 43105.71}", "{\"n\": 8036, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1891891891891895, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3567.7297297297296, \"learn_time_ms\": 43112.292}", "{\"n\": 8037, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.1891891891891895, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3567.7297297297296, \"learn_time_ms\": 43161.528}", "{\"n\": 8038, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.230769230769231, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3580.846153846154, \"learn_time_ms\": 43192.092}", "{\"n\": 8039, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.365853658536586, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3546.1951219512193, \"learn_time_ms\": 43289.585}", "{\"n\": 8040, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.27906976744186, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3546.6279069767443, \"learn_time_ms\": 43100.205}", "{\"n\": 8041, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.2727272727272725, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3545.3636363636365, \"learn_time_ms\": 43058.415}", "{\"n\": 8042, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.2727272727272725, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3545.3636363636365, \"learn_time_ms\": 43103.335}", "{\"n\": 8043, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.177777777777778, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3562.688888888889, \"learn_time_ms\": 43003.471}", "{\"n\": 8044, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.041666666666667, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3590.6041666666665, \"learn_time_ms\": 43031.595}", "{\"n\": 8045, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.041666666666667, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3590.6041666666665, \"learn_time_ms\": 43116.078}", "{\"n\": 8046, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.163265306122449, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3580.4897959183672, \"learn_time_ms\": 43107.193}", "{\"n\": 8047, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3577.9, \"learn_time_ms\": 43003.321}", "{\"n\": 8048, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.235294117647059, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3565.098039215686, \"learn_time_ms\": 42911.757}", "{\"n\": 8049, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.333333333333333, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3552.6296296296296, \"learn_time_ms\": 42762.675}", "{\"n\": 8050, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.345454545454546, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3547.2, \"learn_time_ms\": 42891.731}", "{\"n\": 8051, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.345454545454546, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3547.2, \"learn_time_ms\": 42899.639}", "{\"n\": 8052, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.175438596491228, \"episode_reward_max\": 1.0, \"episode_len_mean\": 3564.40350877193, \"learn_time_ms\": 42975.825}", "{\"n\": 8053, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.932203389830509, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3605.593220338983, \"learn_time_ms\": 42912.966}", "{\"n\": 8054, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.016666666666667, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3592.2833333333333, \"learn_time_ms\": 42949.419}", "{\"n\": 8055, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.935483870967742, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3608.2419354838707, \"learn_time_ms\": 42877.074}", "{\"n\": 8056, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.935483870967742, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3608.2419354838707, \"learn_time_ms\": 42880.126}", "{\"n\": 8057, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.9523809523809526, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3608.15873015873, \"learn_time_ms\": 42903.483}", "{\"n\": 8058, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.892307692307693, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3612.0153846153844, \"learn_time_ms\": 42927.223}", "{\"n\": 8059, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -7.029850746268656, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3586.6417910447763, \"learn_time_ms\": 43014.015}", "{\"n\": 8060, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.828571428571428, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3626.8, \"learn_time_ms\": 42893.466}", "{\"n\": 8061, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.828571428571428, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3626.8, \"learn_time_ms\": 42931.251}", "{\"n\": 8062, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.859154929577465, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3618.1408450704225, \"learn_time_ms\": 42759.995}", "{\"n\": 8063, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.8493150684931505, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3623.931506849315, \"learn_time_ms\": 42862.099}", "{\"n\": 8064, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.918918918918919, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3616.162162162162, \"learn_time_ms\": 42803.337}", "{\"n\": 8065, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.935064935064935, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3622.7922077922076, \"learn_time_ms\": 42758.04}", "{\"n\": 8066, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.064102564102564, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3607.2948717948716, \"learn_time_ms\": 42784.191}", "{\"n\": 8067, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.113924050632911, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3598.253164556962, \"learn_time_ms\": 42822.573}", "{\"n\": 8068, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.160493827160494, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3589.41975308642, \"learn_time_ms\": 42825.012}", "{\"n\": 8069, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.160493827160494, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3589.41975308642, \"learn_time_ms\": 42786.688}", "{\"n\": 8070, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.160493827160494, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3589.41975308642, \"learn_time_ms\": 42924.259}", "{\"n\": 8071, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.289156626506024, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3566.6385542168673, \"learn_time_ms\": 42977.204}", "{\"n\": 8072, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.270588235294118, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3572.505882352941, \"learn_time_ms\": 43044.599}", "{\"n\": 8073, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.244186046511628, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3579.8720930232557, \"learn_time_ms\": 43025.66}", "{\"n\": 8074, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.363636363636363, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3561.1704545454545, \"learn_time_ms\": 43119.735}", "{\"n\": 8075, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.415730337078652, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3555.247191011236, \"learn_time_ms\": 43197.282}", "{\"n\": 8076, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.413043478260869, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3567.0108695652175, \"learn_time_ms\": 43150.215}", "{\"n\": 8077, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.413043478260869, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3567.0108695652175, \"learn_time_ms\": 43106.802}", "{\"n\": 8078, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.425531914893617, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3571.127659574468, \"learn_time_ms\": 43130.341}", "{\"n\": 8079, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.425531914893617, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3571.127659574468, \"learn_time_ms\": 43186.334}", "{\"n\": 8080, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.329896907216495, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3592.536082474227, \"learn_time_ms\": 43231.992}", "{\"n\": 8081, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.387755102040816, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3582.7551020408164, \"learn_time_ms\": 43260.208}", "{\"n\": 8082, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.387755102040816, \"episode_reward_max\": 2.0, \"episode_len_mean\": 3582.7551020408164, \"learn_time_ms\": 43209.553}", "{\"n\": 8083, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3583.36, \"learn_time_ms\": 43090.902}", "{\"n\": 8084, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3565.02, \"learn_time_ms\": 43054.603}", "{\"n\": 8085, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3569.76, \"learn_time_ms\": 43038.401}", "{\"n\": 8086, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3569.76, \"learn_time_ms\": 42979.599}", "{\"n\": 8087, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3569.76, \"learn_time_ms\": 42994.954}", "{\"n\": 8088, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3555.2, \"learn_time_ms\": 42958.478}", "{\"n\": 8089, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3555.2, \"learn_time_ms\": 42818.887}", "{\"n\": 8090, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3550.99, \"learn_time_ms\": 42769.51}", "{\"n\": 8091, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3567.92, \"learn_time_ms\": 42915.783}", "{\"n\": 8092, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3542.07, \"learn_time_ms\": 43044.58}", "{\"n\": 8093, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3542.07, \"learn_time_ms\": 43145.429}", "{\"n\": 8094, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3546.46, \"learn_time_ms\": 43128.762}", "{\"n\": 8095, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3560.14, \"learn_time_ms\": 43037.399}", "{\"n\": 8096, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.57, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3560.14, \"learn_time_ms\": 43010.053}", "{\"n\": 8097, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3577.83, \"learn_time_ms\": 42921.062}", "{\"n\": 8098, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3574.91, \"learn_time_ms\": 43047.125}", "{\"n\": 8099, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3575.6, \"learn_time_ms\": 43057.101}", "{\"n\": 8100, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3572.84, \"learn_time_ms\": 43010.793}", "{\"n\": 8101, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3578.96, \"learn_time_ms\": 42808.001}", "{\"n\": 8102, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3590.41, \"learn_time_ms\": 42743.206}", "{\"n\": 8103, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3600.53, \"learn_time_ms\": 42753.74}", "{\"n\": 8104, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3602.73, \"learn_time_ms\": 42746.281}", "{\"n\": 8105, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3587.37, \"learn_time_ms\": 42803.454}", "{\"n\": 8106, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.48, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3587.37, \"learn_time_ms\": 42988.43}", "{\"n\": 8107, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3594.3, \"learn_time_ms\": 43040.437}", "{\"n\": 8108, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3594.3, \"learn_time_ms\": 42996.894}", "{\"n\": 8109, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.32, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3600.78, \"learn_time_ms\": 43137.173}", "{\"n\": 8110, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3598.05, \"learn_time_ms\": 43094.843}", "{\"n\": 8111, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3577.95, \"learn_time_ms\": 43024.54}", "{\"n\": 8112, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3577.95, \"learn_time_ms\": 43053.696}", "{\"n\": 8113, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3594.08, \"learn_time_ms\": 42976.761}", "{\"n\": 8114, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3580.03, \"learn_time_ms\": 43041.498}", "{\"n\": 8115, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3580.03, \"learn_time_ms\": 43158.611}", "{\"n\": 8116, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3595.45, \"learn_time_ms\": 43146.314}", "{\"n\": 8117, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3572.76, \"learn_time_ms\": 43168.076}", "{\"n\": 8118, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3568.67, \"learn_time_ms\": 43105.894}", "{\"n\": 8119, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3568.7, \"learn_time_ms\": 43137.811}", "{\"n\": 8120, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3568.7, \"learn_time_ms\": 43282.008}", "{\"n\": 8121, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3583.08, \"learn_time_ms\": 43200.86}", "{\"n\": 8122, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3581.76, \"learn_time_ms\": 43123.137}", "{\"n\": 8123, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3589.95, \"learn_time_ms\": 43142.195}", "{\"n\": 8124, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3581.29, \"learn_time_ms\": 43014.911}", "{\"n\": 8125, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3559.36, \"learn_time_ms\": 42991.782}", "{\"n\": 8126, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3552.26, \"learn_time_ms\": 42915.284}", "{\"n\": 8127, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3552.26, \"learn_time_ms\": 42944.386}", "{\"n\": 8128, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3531.59, \"learn_time_ms\": 43108.152}", "{\"n\": 8129, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3531.59, \"learn_time_ms\": 42937.155}", "{\"n\": 8130, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3526.18, \"learn_time_ms\": 42807.954}", "{\"n\": 8131, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3544.87, \"learn_time_ms\": 42908.64}", "{\"n\": 8132, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3544.87, \"learn_time_ms\": 42943.291}", "{\"n\": 8133, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3536.81, \"learn_time_ms\": 42850.729}", "{\"n\": 8134, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3529.8, \"learn_time_ms\": 42858.723}", "{\"n\": 8135, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3529.8, \"learn_time_ms\": 42866.297}", "{\"n\": 8136, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3519.18, \"learn_time_ms\": 42858.665}", "{\"n\": 8137, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3519.18, \"learn_time_ms\": 42744.071}", "{\"n\": 8138, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3495.76, \"learn_time_ms\": 42603.807}", "{\"n\": 8139, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3499.74, \"learn_time_ms\": 42645.213}", "{\"n\": 8140, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3493.6, \"learn_time_ms\": 42634.809}", "{\"n\": 8141, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3524.53, \"learn_time_ms\": 42684.462}", "{\"n\": 8142, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3537.73, \"learn_time_ms\": 42665.326}", "{\"n\": 8143, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3537.73, \"learn_time_ms\": 42755.333}", "{\"n\": 8144, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3537.73, \"learn_time_ms\": 42756.88}", "{\"n\": 8145, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3551.42, \"learn_time_ms\": 42561.207}", "{\"n\": 8146, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3566.59, \"learn_time_ms\": 42635.843}", "{\"n\": 8147, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3566.59, \"learn_time_ms\": 42703.39}", "{\"n\": 8148, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3566.59, \"learn_time_ms\": 42716.591}", "{\"n\": 8149, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3563.38, \"learn_time_ms\": 42718.29}", "{\"n\": 8150, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3563.38, \"learn_time_ms\": 42851.698}", "{\"n\": 8151, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3552.81, \"learn_time_ms\": 42852.014}", "{\"n\": 8152, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3513.59, \"learn_time_ms\": 43055.882}", "{\"n\": 8153, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3518.28, \"learn_time_ms\": 43159.237}", "{\"n\": 8154, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3518.28, \"learn_time_ms\": 43141.082}", "{\"n\": 8155, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3532.36, \"learn_time_ms\": 43248.759}", "{\"n\": 8156, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3523.07, \"learn_time_ms\": 43258.672}", "{\"n\": 8157, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3529.52, \"learn_time_ms\": 43286.173}", "{\"n\": 8158, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3557.78, \"learn_time_ms\": 43301.587}", "{\"n\": 8159, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3554.8, \"learn_time_ms\": 43334.658}", "{\"n\": 8160, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3548.77, \"learn_time_ms\": 43377.047}", "{\"n\": 8161, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3551.89, \"learn_time_ms\": 43427.205}", "{\"n\": 8162, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3538.56, \"learn_time_ms\": 43214.425}", "{\"n\": 8163, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3528.98, \"learn_time_ms\": 43207.976}", "{\"n\": 8164, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3535.02, \"learn_time_ms\": 43176.56}", "{\"n\": 8165, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3540.11, \"learn_time_ms\": 43197.777}", "{\"n\": 8166, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3544.67, \"learn_time_ms\": 43146.937}", "{\"n\": 8167, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3544.67, \"learn_time_ms\": 43116.407}", "{\"n\": 8168, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3525.03, \"learn_time_ms\": 43071.794}", "{\"n\": 8169, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3513.21, \"learn_time_ms\": 42981.546}", "{\"n\": 8170, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3500.37, \"learn_time_ms\": 42837.715}", "{\"n\": 8171, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3498.31, \"learn_time_ms\": 42757.276}", "{\"n\": 8172, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3506.15, \"learn_time_ms\": 42849.481}", "{\"n\": 8173, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3506.15, \"learn_time_ms\": 42830.502}", "{\"n\": 8174, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3501.6, \"learn_time_ms\": 43009.883}", "{\"n\": 8175, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3504.47, \"learn_time_ms\": 42921.571}", "{\"n\": 8176, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3499.53, \"learn_time_ms\": 42955.542}", "{\"n\": 8177, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3491.2, \"learn_time_ms\": 43060.251}", "{\"n\": 8178, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3475.11, \"learn_time_ms\": 43039.681}", "{\"n\": 8179, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.59, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3475.11, \"learn_time_ms\": 43111.851}", "{\"n\": 8180, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.72, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3457.09, \"learn_time_ms\": 43094.508}", "{\"n\": 8181, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -7.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3447.21, \"learn_time_ms\": 43092.67}", "{\"n\": 8182, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3469.54, \"learn_time_ms\": 42963.52}", "{\"n\": 8183, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3481.59, \"learn_time_ms\": 42930.223}", "{\"n\": 8184, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3486.15, \"learn_time_ms\": 42819.41}", "{\"n\": 8185, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3477.23, \"learn_time_ms\": 42838.688}", "{\"n\": 8186, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3476.71, \"learn_time_ms\": 42846.123}", "{\"n\": 8187, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3476.71, \"learn_time_ms\": 42780.148}", "{\"n\": 8188, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3484.16, \"learn_time_ms\": 42778.559}", "{\"n\": 8189, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3475.63, \"learn_time_ms\": 42824.476}", "{\"n\": 8190, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3477.33, \"learn_time_ms\": 42844.614}", "{\"n\": 8191, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3477.33, \"learn_time_ms\": 42828.765}", "{\"n\": 8192, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3456.73, \"learn_time_ms\": 42915.764}", "{\"n\": 8193, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3456.73, \"learn_time_ms\": 42966.217}", "{\"n\": 8194, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3456.73, \"learn_time_ms\": 43000.564}", "{\"n\": 8195, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.92, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3464.65, \"learn_time_ms\": 42986.016}", "{\"n\": 8196, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3460.88, \"learn_time_ms\": 42838.364}", "{\"n\": 8197, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3458.19, \"learn_time_ms\": 42815.728}", "{\"n\": 8198, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.94, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3458.19, \"learn_time_ms\": 42959.242}", "{\"n\": 8199, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.89, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3469.86, \"learn_time_ms\": 43011.666}", "{\"n\": 8200, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3488.25, \"learn_time_ms\": 43007.942}", "{\"n\": 8201, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3498.38, \"learn_time_ms\": 43131.204}", "{\"n\": 8202, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3487.83, \"learn_time_ms\": 43150.249}", "{\"n\": 8203, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.75, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3487.83, \"learn_time_ms\": 43070.257}", "{\"n\": 8204, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3504.73, \"learn_time_ms\": 42992.637}", "{\"n\": 8205, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.69, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3504.73, \"learn_time_ms\": 43089.956}", "{\"n\": 8206, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3507.83, \"learn_time_ms\": 43156.017}", "{\"n\": 8207, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.71, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3506.32, \"learn_time_ms\": 43192.643}", "{\"n\": 8208, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.64, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3515.69, \"learn_time_ms\": 43103.3}", "{\"n\": 8209, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3528.77, \"learn_time_ms\": 42989.637}", "{\"n\": 8210, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.58, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3528.77, \"learn_time_ms\": 43031.422}", "{\"n\": 8211, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3538.37, \"learn_time_ms\": 42996.953}", "{\"n\": 8212, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3554.63, \"learn_time_ms\": 43088.424}", "{\"n\": 8213, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3548.36, \"learn_time_ms\": 43219.115}", "{\"n\": 8214, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.36, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3548.36, \"learn_time_ms\": 43294.013}", "{\"n\": 8215, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3535.98, \"learn_time_ms\": 43328.034}", "{\"n\": 8216, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.49, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3518.58, \"learn_time_ms\": 43420.071}", "{\"n\": 8217, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3522.48, \"learn_time_ms\": 43508.271}", "{\"n\": 8218, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3522.48, \"learn_time_ms\": 43680.0}", "{\"n\": 8219, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3534.52, \"learn_time_ms\": 43911.18}", "{\"n\": 8220, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.42, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3529.73, \"learn_time_ms\": 43836.546}", "{\"n\": 8221, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3547.76, \"learn_time_ms\": 43751.554}", "{\"n\": 8222, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.38, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3547.76, \"learn_time_ms\": 43700.96}", "{\"n\": 8223, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3544.13, \"learn_time_ms\": 43627.729}", "{\"n\": 8224, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3540.18, \"learn_time_ms\": 43591.071}", "{\"n\": 8225, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3537.64, \"learn_time_ms\": 43586.156}", "{\"n\": 8226, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3537.64, \"learn_time_ms\": 43556.056}", "{\"n\": 8227, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3538.35, \"learn_time_ms\": 43401.773}", "{\"n\": 8228, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3529.26, \"learn_time_ms\": 43380.954}", "{\"n\": 8229, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3529.31, \"learn_time_ms\": 43232.915}", "{\"n\": 8230, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.24, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3522.76, \"learn_time_ms\": 43193.297}", "{\"n\": 8231, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3511.76, \"learn_time_ms\": 43124.214}", "{\"n\": 8232, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3511.76, \"learn_time_ms\": 43054.259}", "{\"n\": 8233, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.34, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3514.43, \"learn_time_ms\": 43064.102}", "{\"n\": 8234, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3520.21, \"learn_time_ms\": 43037.729}", "{\"n\": 8235, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3530.21, \"learn_time_ms\": 42920.064}", "{\"n\": 8236, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3529.37, \"learn_time_ms\": 42873.487}", "{\"n\": 8237, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.1, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3531.19, \"learn_time_ms\": 43002.71}", "{\"n\": 8238, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3531.79, \"learn_time_ms\": 42843.902}", "{\"n\": 8239, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.07, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3531.79, \"learn_time_ms\": 42798.798}", "{\"n\": 8240, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3521.06, \"learn_time_ms\": 42902.82}", "{\"n\": 8241, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3503.69, \"learn_time_ms\": 43028.214}", "{\"n\": 8242, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3503.32, \"learn_time_ms\": 43147.552}", "{\"n\": 8243, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.39, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3489.84, \"learn_time_ms\": 43041.348}", "{\"n\": 8244, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3492.28, \"learn_time_ms\": 43221.201}", "{\"n\": 8245, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3492.28, \"learn_time_ms\": 43352.636}", "{\"n\": 8246, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.31, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3502.52, \"learn_time_ms\": 43501.404}", "{\"n\": 8247, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3498.39, \"learn_time_ms\": 43353.301}", "{\"n\": 8248, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.3, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3498.39, \"learn_time_ms\": 43297.619}", "{\"n\": 8249, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3515.44, \"learn_time_ms\": 43323.54}", "{\"n\": 8250, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.25, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3515.41, \"learn_time_ms\": 43327.329}", "{\"n\": 8251, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3531.16, \"learn_time_ms\": 43233.708}", "{\"n\": 8252, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3526.21, \"learn_time_ms\": 43053.141}", "{\"n\": 8253, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3541.6, \"learn_time_ms\": 43197.001}", "{\"n\": 8254, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3562.0, \"learn_time_ms\": 43003.255}", "{\"n\": 8255, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3562.0, \"learn_time_ms\": 43054.425}", "{\"n\": 8256, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3581.94, \"learn_time_ms\": 42969.987}", "{\"n\": 8257, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3591.73, \"learn_time_ms\": 43111.744}", "{\"n\": 8258, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3591.73, \"learn_time_ms\": 43342.716}", "{\"n\": 8259, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3571.13, \"learn_time_ms\": 43267.628}", "{\"n\": 8260, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3571.13, \"learn_time_ms\": 43412.401}", "{\"n\": 8261, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3586.55, \"learn_time_ms\": 43569.494}", "{\"n\": 8262, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3623.0, \"learn_time_ms\": 43623.019}", "{\"n\": 8263, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3623.0, \"learn_time_ms\": 43604.92}", "{\"n\": 8264, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3634.25, \"learn_time_ms\": 43625.297}", "{\"n\": 8265, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3634.25, \"learn_time_ms\": 43498.981}", "{\"n\": 8266, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3631.47, \"learn_time_ms\": 43518.768}", "{\"n\": 8267, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3642.79, \"learn_time_ms\": 43398.229}", "{\"n\": 8268, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3642.79, \"learn_time_ms\": 43190.18}", "{\"n\": 8269, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3621.72, \"learn_time_ms\": 43215.356}", "{\"n\": 8270, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3615.6, \"learn_time_ms\": 43002.725}", "{\"n\": 8271, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3622.5, \"learn_time_ms\": 42871.878}", "{\"n\": 8272, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3630.37, \"learn_time_ms\": 43023.449}", "{\"n\": 8273, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3613.35, \"learn_time_ms\": 42981.329}", "{\"n\": 8274, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3618.08, \"learn_time_ms\": 42996.169}", "{\"n\": 8275, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3621.48, \"learn_time_ms\": 43053.743}", "{\"n\": 8276, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3621.48, \"learn_time_ms\": 42961.407}", "{\"n\": 8277, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3626.83, \"learn_time_ms\": 42989.895}", "{\"n\": 8278, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3613.56, \"learn_time_ms\": 43087.729}", "{\"n\": 8279, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3607.44, \"learn_time_ms\": 43130.28}", "{\"n\": 8280, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3607.57, \"learn_time_ms\": 43164.464}", "{\"n\": 8281, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.79, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3594.84, \"learn_time_ms\": 43278.014}", "{\"n\": 8282, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3578.06, \"learn_time_ms\": 43214.723}", "{\"n\": 8283, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3590.32, \"learn_time_ms\": 43153.233}", "{\"n\": 8284, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3588.42, \"learn_time_ms\": 43230.602}", "{\"n\": 8285, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3565.28, \"learn_time_ms\": 43142.943}", "{\"n\": 8286, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3565.28, \"learn_time_ms\": 43256.253}", "{\"n\": 8287, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3563.27, \"learn_time_ms\": 43292.163}", "{\"n\": 8288, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3536.92, \"learn_time_ms\": 43226.596}", "{\"n\": 8289, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3546.2, \"learn_time_ms\": 43184.865}", "{\"n\": 8290, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3551.85, \"learn_time_ms\": 43292.759}", "{\"n\": 8291, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3551.85, \"learn_time_ms\": 43209.186}", "{\"n\": 8292, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3566.26, \"learn_time_ms\": 43128.305}", "{\"n\": 8293, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3559.02, \"learn_time_ms\": 43292.024}", "{\"n\": 8294, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3549.99, \"learn_time_ms\": 43203.345}", "{\"n\": 8295, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3534.12, \"learn_time_ms\": 43297.427}", "{\"n\": 8296, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3534.12, \"learn_time_ms\": 43246.503}", "{\"n\": 8297, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3535.84, \"learn_time_ms\": 43310.36}", "{\"n\": 8298, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3535.84, \"learn_time_ms\": 43355.783}", "{\"n\": 8299, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3542.72, \"learn_time_ms\": 43403.955}", "{\"n\": 8300, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3562.99, \"learn_time_ms\": 43327.819}", "{\"n\": 8301, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.88, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3581.64, \"learn_time_ms\": 43493.274}", "{\"n\": 8302, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3573.88, \"learn_time_ms\": 43515.667}", "{\"n\": 8303, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3573.88, \"learn_time_ms\": 43458.752}", "{\"n\": 8304, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.86, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3587.11, \"learn_time_ms\": 43408.122}", "{\"n\": 8305, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3597.61, \"learn_time_ms\": 43343.49}", "{\"n\": 8306, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3605.65, \"learn_time_ms\": 43386.805}", "{\"n\": 8307, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3630.97, \"learn_time_ms\": 43288.429}", "{\"n\": 8308, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3630.97, \"learn_time_ms\": 43195.586}", "{\"n\": 8309, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3634.58, \"learn_time_ms\": 43204.122}", "{\"n\": 8310, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3653.08, \"learn_time_ms\": 43260.49}", "{\"n\": 8311, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 3.0, \"episode_len_mean\": 3661.63, \"learn_time_ms\": 43207.788}", "{\"n\": 8312, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3660.85, \"learn_time_ms\": 43219.215}", "{\"n\": 8313, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3659.59, \"learn_time_ms\": 43171.299}", "{\"n\": 8314, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3656.94, \"learn_time_ms\": 43369.612}", "{\"n\": 8315, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3662.99, \"learn_time_ms\": 43396.23}", "{\"n\": 8316, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3682.1, \"learn_time_ms\": 43360.841}", "{\"n\": 8317, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3682.1, \"learn_time_ms\": 43344.24}", "{\"n\": 8318, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3682.1, \"learn_time_ms\": 43429.496}", "{\"n\": 8319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3686.15, \"learn_time_ms\": 43437.632}", "{\"n\": 8320, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3685.64, \"learn_time_ms\": 43398.331}", "{\"n\": 8321, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3678.28, \"learn_time_ms\": 43247.288}", "{\"n\": 8322, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3674.49, \"learn_time_ms\": 43107.861}", "{\"n\": 8323, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3674.49, \"learn_time_ms\": 43151.529}", "{\"n\": 8324, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3672.27, \"learn_time_ms\": 42955.395}", "{\"n\": 8325, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3676.81, \"learn_time_ms\": 42917.728}", "{\"n\": 8326, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3672.7, \"learn_time_ms\": 42860.349}", "{\"n\": 8327, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3685.32, \"learn_time_ms\": 42824.883}", "{\"n\": 8328, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3685.32, \"learn_time_ms\": 42807.216}", "{\"n\": 8329, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3685.32, \"learn_time_ms\": 42698.036}", "{\"n\": 8330, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3668.58, \"learn_time_ms\": 42620.674}", "{\"n\": 8331, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3662.19, \"learn_time_ms\": 42625.976}", "{\"n\": 8332, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3658.28, \"learn_time_ms\": 42803.026}", "{\"n\": 8333, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3655.18, \"learn_time_ms\": 42757.256}", "{\"n\": 8334, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3658.21, \"learn_time_ms\": 42934.559}", "{\"n\": 8335, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3658.21, \"learn_time_ms\": 42970.586}", "{\"n\": 8336, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3655.76, \"learn_time_ms\": 42994.981}", "{\"n\": 8337, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3645.03, \"learn_time_ms\": 42997.394}", "{\"n\": 8338, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3629.72, \"learn_time_ms\": 42987.147}", "{\"n\": 8339, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3631.78, \"learn_time_ms\": 43042.523}", "{\"n\": 8340, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.35, \"learn_time_ms\": 43131.618}", "{\"n\": 8341, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.66, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.35, \"learn_time_ms\": 43177.13}", "{\"n\": 8342, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3605.98, \"learn_time_ms\": 43106.67}", "{\"n\": 8343, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3605.02, \"learn_time_ms\": 43085.267}", "{\"n\": 8344, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3611.17, \"learn_time_ms\": 42971.585}", "{\"n\": 8345, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3616.76, \"learn_time_ms\": 43018.007}", "{\"n\": 8346, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3616.76, \"learn_time_ms\": 43036.924}", "{\"n\": 8347, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3616.76, \"learn_time_ms\": 43138.012}", "{\"n\": 8348, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3614.74, \"learn_time_ms\": 43122.074}", "{\"n\": 8349, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3640.67, \"learn_time_ms\": 43149.969}", "{\"n\": 8350, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3640.95, \"learn_time_ms\": 43110.046}", "{\"n\": 8351, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.85, \"learn_time_ms\": 43109.55}", "{\"n\": 8352, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.85, \"learn_time_ms\": 43141.882}", "{\"n\": 8353, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.73, \"learn_time_ms\": 43217.117}", "{\"n\": 8354, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.73, \"learn_time_ms\": 43181.852}", "{\"n\": 8355, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.73, \"learn_time_ms\": 43068.138}", "{\"n\": 8356, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.45, \"learn_time_ms\": 43095.844}", "{\"n\": 8357, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3655.06, \"learn_time_ms\": 43131.951}", "{\"n\": 8358, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3642.6, \"learn_time_ms\": 43054.832}", "{\"n\": 8359, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3642.6, \"learn_time_ms\": 43066.077}", "{\"n\": 8360, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3642.6, \"learn_time_ms\": 42985.058}", "{\"n\": 8361, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.46, \"learn_time_ms\": 42976.721}", "{\"n\": 8362, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.46, \"learn_time_ms\": 42992.522}", "{\"n\": 8363, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3671.32, \"learn_time_ms\": 42952.374}", "{\"n\": 8364, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.38, \"learn_time_ms\": 42968.846}", "{\"n\": 8365, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.38, \"learn_time_ms\": 43125.612}", "{\"n\": 8366, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.38, \"learn_time_ms\": 43111.467}", "{\"n\": 8367, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.38, \"learn_time_ms\": 43111.462}", "{\"n\": 8368, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3712.32, \"learn_time_ms\": 43127.714}", "{\"n\": 8369, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3703.33, \"learn_time_ms\": 43240.701}", "{\"n\": 8370, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3700.17, \"learn_time_ms\": 43301.876}", "{\"n\": 8371, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.51, \"learn_time_ms\": 43360.011}", "{\"n\": 8372, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.51, \"learn_time_ms\": 43261.539}", "{\"n\": 8373, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3718.73, \"learn_time_ms\": 43292.978}", "{\"n\": 8374, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3712.28, \"learn_time_ms\": 43341.573}", "{\"n\": 8375, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3711.66, \"learn_time_ms\": 43175.041}", "{\"n\": 8376, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3704.85, \"learn_time_ms\": 43082.835}", "{\"n\": 8377, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3704.85, \"learn_time_ms\": 43013.019}", "{\"n\": 8378, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3692.52, \"learn_time_ms\": 43090.829}", "{\"n\": 8379, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3671.38, \"learn_time_ms\": 43051.672}", "{\"n\": 8380, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.92, \"learn_time_ms\": 43046.494}", "{\"n\": 8381, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3652.92, \"learn_time_ms\": 42921.206}", "{\"n\": 8382, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3646.1, \"learn_time_ms\": 42877.341}", "{\"n\": 8383, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.29, \"learn_time_ms\": 42849.153}", "{\"n\": 8384, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.29, \"learn_time_ms\": 42867.675}", "{\"n\": 8385, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.88, \"learn_time_ms\": 42965.786}", "{\"n\": 8386, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.13, \"learn_time_ms\": 43073.555}", "{\"n\": 8387, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.13, \"learn_time_ms\": 43012.4}", "{\"n\": 8388, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.13, \"learn_time_ms\": 42956.871}", "{\"n\": 8389, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3593.49, \"learn_time_ms\": 42903.607}", "{\"n\": 8390, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3591.36, \"learn_time_ms\": 42955.439}", "{\"n\": 8391, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3575.16, \"learn_time_ms\": 42962.111}", "{\"n\": 8392, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3583.79, \"learn_time_ms\": 43006.719}", "{\"n\": 8393, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3579.67, \"learn_time_ms\": 43037.868}", "{\"n\": 8394, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3579.67, \"learn_time_ms\": 43045.719}", "{\"n\": 8395, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3582.9, \"learn_time_ms\": 43003.904}", "{\"n\": 8396, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.38, \"learn_time_ms\": 43000.055}", "{\"n\": 8397, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.49, \"learn_time_ms\": 43029.328}", "{\"n\": 8398, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3594.72, \"learn_time_ms\": 43009.492}", "{\"n\": 8399, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3594.72, \"learn_time_ms\": 42944.028}", "{\"n\": 8400, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3585.05, \"learn_time_ms\": 42756.163}", "{\"n\": 8401, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3585.05, \"learn_time_ms\": 42831.668}", "{\"n\": 8402, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3595.38, \"learn_time_ms\": 42873.063}", "{\"n\": 8403, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3595.38, \"learn_time_ms\": 42840.115}", "{\"n\": 8404, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3595.71, \"learn_time_ms\": 42765.187}", "{\"n\": 8405, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3595.71, \"learn_time_ms\": 42669.618}", "{\"n\": 8406, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.66, \"learn_time_ms\": 42652.415}", "{\"n\": 8407, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.66, \"learn_time_ms\": 42716.08}", "{\"n\": 8408, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3596.21, \"learn_time_ms\": 42805.841}", "{\"n\": 8409, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3610.01, \"learn_time_ms\": 42742.616}", "{\"n\": 8410, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3610.76, \"learn_time_ms\": 42773.303}", "{\"n\": 8411, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3610.76, \"learn_time_ms\": 42741.261}", "{\"n\": 8412, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3593.81, \"learn_time_ms\": 42744.634}", "{\"n\": 8413, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3593.81, \"learn_time_ms\": 42664.341}", "{\"n\": 8414, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.9, \"learn_time_ms\": 42628.692}", "{\"n\": 8415, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.4, \"learn_time_ms\": 42784.28}", "{\"n\": 8416, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.22, \"learn_time_ms\": 42693.13}", "{\"n\": 8417, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.22, \"learn_time_ms\": 42707.679}", "{\"n\": 8418, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3624.36, \"learn_time_ms\": 42858.272}", "{\"n\": 8419, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.1, \"learn_time_ms\": 42917.892}", "{\"n\": 8420, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.23, \"learn_time_ms\": 43032.496}", "{\"n\": 8421, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3626.48, \"learn_time_ms\": 43072.055}", "{\"n\": 8422, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.75, \"learn_time_ms\": 43010.505}", "{\"n\": 8423, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3617.75, \"learn_time_ms\": 43080.474}", "{\"n\": 8424, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3594.55, \"learn_time_ms\": 43102.448}", "{\"n\": 8425, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3589.75, \"learn_time_ms\": 43056.002}", "{\"n\": 8426, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3589.75, \"learn_time_ms\": 43230.878}", "{\"n\": 8427, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3595.67, \"learn_time_ms\": 43113.276}", "{\"n\": 8428, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.33, \"learn_time_ms\": 42904.388}", "{\"n\": 8429, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.33, \"learn_time_ms\": 42811.916}", "{\"n\": 8430, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.27, \"learn_time_ms\": 42723.316}", "{\"n\": 8431, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3580.42, \"learn_time_ms\": 42659.978}", "{\"n\": 8432, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3577.68, \"learn_time_ms\": 42783.094}", "{\"n\": 8433, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3604.92, \"learn_time_ms\": 42765.709}", "{\"n\": 8434, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3604.92, \"learn_time_ms\": 42763.98}", "{\"n\": 8435, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3610.25, \"learn_time_ms\": 42770.625}", "{\"n\": 8436, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3610.25, \"learn_time_ms\": 42671.52}", "{\"n\": 8437, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3619.83, \"learn_time_ms\": 42725.576}", "{\"n\": 8438, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3613.62, \"learn_time_ms\": 42741.31}", "{\"n\": 8439, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.0, \"learn_time_ms\": 42888.185}", "{\"n\": 8440, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3584.46, \"learn_time_ms\": 42916.371}", "{\"n\": 8441, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3575.65, \"learn_time_ms\": 42955.858}", "{\"n\": 8442, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3550.51, \"learn_time_ms\": 42967.905}", "{\"n\": 8443, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.25, \"learn_time_ms\": 42974.334}", "{\"n\": 8444, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.25, \"learn_time_ms\": 43124.415}", "{\"n\": 8445, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3529.64, \"learn_time_ms\": 43113.611}", "{\"n\": 8446, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3539.25, \"learn_time_ms\": 43094.445}", "{\"n\": 8447, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3525.96, \"learn_time_ms\": 43145.711}", "{\"n\": 8448, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3525.96, \"learn_time_ms\": 43115.894}", "{\"n\": 8449, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3526.49, \"learn_time_ms\": 43141.848}", "{\"n\": 8450, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3525.53, \"learn_time_ms\": 43137.725}", "{\"n\": 8451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3530.06, \"learn_time_ms\": 43187.105}", "{\"n\": 8452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3522.81, \"learn_time_ms\": 43201.737}", "{\"n\": 8453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3522.81, \"learn_time_ms\": 43119.763}", "{\"n\": 8454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3551.33, \"learn_time_ms\": 43029.048}", "{\"n\": 8455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3558.22, \"learn_time_ms\": 42975.816}", "{\"n\": 8456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3547.27, \"learn_time_ms\": 42950.086}", "{\"n\": 8457, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3539.16, \"learn_time_ms\": 42969.932}", "{\"n\": 8458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3539.16, \"learn_time_ms\": 42949.258}", "{\"n\": 8459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3539.16, \"learn_time_ms\": 42908.097}", "{\"n\": 8460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3535.21, \"learn_time_ms\": 42889.985}", "{\"n\": 8461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3555.58, \"learn_time_ms\": 42803.166}", "{\"n\": 8462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3552.3, \"learn_time_ms\": 42756.328}", "{\"n\": 8463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.6, \"learn_time_ms\": 42836.467}", "{\"n\": 8464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.6, \"learn_time_ms\": 42895.963}", "{\"n\": 8465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.6, \"learn_time_ms\": 42892.601}", "{\"n\": 8466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3568.03, \"learn_time_ms\": 42831.432}", "{\"n\": 8467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3568.03, \"learn_time_ms\": 42683.187}", "{\"n\": 8468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.59, \"learn_time_ms\": 42798.708}", "{\"n\": 8469, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.57, \"learn_time_ms\": 42746.009}", "{\"n\": 8470, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3584.9, \"learn_time_ms\": 42807.418}", "{\"n\": 8471, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3584.9, \"learn_time_ms\": 42833.448}", "{\"n\": 8472, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3584.9, \"learn_time_ms\": 42787.197}", "{\"n\": 8473, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3581.87, \"learn_time_ms\": 42721.924}", "{\"n\": 8474, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3599.15, \"learn_time_ms\": 42563.836}", "{\"n\": 8475, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3599.15, \"learn_time_ms\": 42757.816}", "{\"n\": 8476, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3604.17, \"learn_time_ms\": 42814.787}", "{\"n\": 8477, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3604.17, \"learn_time_ms\": 42878.164}", "{\"n\": 8478, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3610.57, \"learn_time_ms\": 42914.073}", "{\"n\": 8479, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3611.83, \"learn_time_ms\": 42878.203}", "{\"n\": 8480, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3611.83, \"learn_time_ms\": 42880.54}", "{\"n\": 8481, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3611.83, \"learn_time_ms\": 42839.175}", "{\"n\": 8482, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3588.11, \"learn_time_ms\": 42861.642}", "{\"n\": 8483, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3591.41, \"learn_time_ms\": 42945.367}", "{\"n\": 8484, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3586.55, \"learn_time_ms\": 43016.802}", "{\"n\": 8485, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3586.55, \"learn_time_ms\": 42957.734}", "{\"n\": 8486, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3599.67, \"learn_time_ms\": 42937.909}", "{\"n\": 8487, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3603.4, \"learn_time_ms\": 42921.856}", "{\"n\": 8488, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3606.07, \"learn_time_ms\": 42810.6}", "{\"n\": 8489, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3623.22, \"learn_time_ms\": 42828.673}", "{\"n\": 8490, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3616.11, \"learn_time_ms\": 42880.927}", "{\"n\": 8491, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3628.88, \"learn_time_ms\": 42992.182}", "{\"n\": 8492, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3607.59, \"learn_time_ms\": 42905.396}", "{\"n\": 8493, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3615.2, \"learn_time_ms\": 42874.284}", "{\"n\": 8494, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3620.51, \"learn_time_ms\": 42946.72}", "{\"n\": 8495, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3608.35, \"learn_time_ms\": 42893.427}", "{\"n\": 8496, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3605.85, \"learn_time_ms\": 42929.143}", "{\"n\": 8497, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3606.56, \"learn_time_ms\": 42966.024}", "{\"n\": 8498, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3610.87, \"learn_time_ms\": 42906.45}", "{\"n\": 8499, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3586.72, \"learn_time_ms\": 42928.721}", "{\"n\": 8500, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3586.72, \"learn_time_ms\": 42872.776}", "{\"n\": 8501, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3586.72, \"learn_time_ms\": 42812.535}", "{\"n\": 8502, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3577.31, \"learn_time_ms\": 42888.526}", "{\"n\": 8503, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3577.31, \"learn_time_ms\": 42797.036}", "{\"n\": 8504, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3576.2, \"learn_time_ms\": 42763.261}", "{\"n\": 8505, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3590.46, \"learn_time_ms\": 42688.183}", "{\"n\": 8506, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3580.68, \"learn_time_ms\": 42809.609}", "{\"n\": 8507, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3571.64, \"learn_time_ms\": 42939.181}", "{\"n\": 8508, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3560.76, \"learn_time_ms\": 42984.556}", "{\"n\": 8509, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3560.33, \"learn_time_ms\": 43068.896}", "{\"n\": 8510, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3554.81, \"learn_time_ms\": 43109.768}", "{\"n\": 8511, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3554.81, \"learn_time_ms\": 43231.735}", "{\"n\": 8512, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3554.81, \"learn_time_ms\": 43153.111}", "{\"n\": 8513, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3551.0, \"learn_time_ms\": 43280.265}", "{\"n\": 8514, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3565.72, \"learn_time_ms\": 43249.271}", "{\"n\": 8515, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3585.57, \"learn_time_ms\": 43247.08}", "{\"n\": 8516, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3585.57, \"learn_time_ms\": 43141.396}", "{\"n\": 8517, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3585.57, \"learn_time_ms\": 42943.754}", "{\"n\": 8518, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3597.3, \"learn_time_ms\": 42987.876}", "{\"n\": 8519, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3607.72, \"learn_time_ms\": 42917.462}", "{\"n\": 8520, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.77, \"learn_time_ms\": 42912.696}", "{\"n\": 8521, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3599.13, \"learn_time_ms\": 42834.187}", "{\"n\": 8522, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.94, \"learn_time_ms\": 42853.551}", "{\"n\": 8523, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.73, \"learn_time_ms\": 42849.985}", "{\"n\": 8524, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.87, \"learn_time_ms\": 42819.198}", "{\"n\": 8525, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.93, \"learn_time_ms\": 42926.606}", "{\"n\": 8526, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.93, \"learn_time_ms\": 43057.689}", "{\"n\": 8527, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3617.72, \"learn_time_ms\": 43179.398}", "{\"n\": 8528, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.9, \"learn_time_ms\": 43229.785}", "{\"n\": 8529, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.9, \"learn_time_ms\": 43373.482}", "{\"n\": 8530, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.97, \"learn_time_ms\": 43369.011}", "{\"n\": 8531, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3593.45, \"learn_time_ms\": 43557.872}", "{\"n\": 8532, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3594.56, \"learn_time_ms\": 43635.085}", "{\"n\": 8533, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3600.86, \"learn_time_ms\": 43620.681}", "{\"n\": 8534, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3578.25, \"learn_time_ms\": 43781.756}", "{\"n\": 8535, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3578.25, \"learn_time_ms\": 43665.646}", "{\"n\": 8536, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3590.97, \"learn_time_ms\": 43487.313}", "{\"n\": 8537, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.76, \"learn_time_ms\": 43430.599}", "{\"n\": 8538, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.76, \"learn_time_ms\": 43367.843}", "{\"n\": 8539, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.76, \"learn_time_ms\": 43274.567}", "{\"n\": 8540, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.04, \"learn_time_ms\": 43261.879}", "{\"n\": 8541, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3602.83, \"learn_time_ms\": 43059.533}", "{\"n\": 8542, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3578.35, \"learn_time_ms\": 43019.813}", "{\"n\": 8543, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3575.28, \"learn_time_ms\": 43071.196}", "{\"n\": 8544, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3567.2, \"learn_time_ms\": 42888.143}", "{\"n\": 8545, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3582.97, \"learn_time_ms\": 43016.97}", "{\"n\": 8546, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3582.97, \"learn_time_ms\": 43194.867}", "{\"n\": 8547, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3563.94, \"learn_time_ms\": 43235.732}", "{\"n\": 8548, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3575.12, \"learn_time_ms\": 43201.392}", "{\"n\": 8549, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3561.0, \"learn_time_ms\": 43140.116}", "{\"n\": 8550, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3555.21, \"learn_time_ms\": 43110.572}", "{\"n\": 8551, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3550.81, \"learn_time_ms\": 43045.731}", "{\"n\": 8552, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3541.79, \"learn_time_ms\": 43064.143}", "{\"n\": 8553, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3538.79, \"learn_time_ms\": 43045.067}", "{\"n\": 8554, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3529.55, \"learn_time_ms\": 43121.072}", "{\"n\": 8555, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3531.87, \"learn_time_ms\": 43129.74}", "{\"n\": 8556, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3525.02, \"learn_time_ms\": 42989.847}", "{\"n\": 8557, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3528.12, \"learn_time_ms\": 42929.957}", "{\"n\": 8558, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3532.77, \"learn_time_ms\": 42939.753}", "{\"n\": 8559, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3532.49, \"learn_time_ms\": 43023.987}", "{\"n\": 8560, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3526.33, \"learn_time_ms\": 43072.678}", "{\"n\": 8561, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3526.33, \"learn_time_ms\": 43139.54}", "{\"n\": 8562, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3515.95, \"learn_time_ms\": 43180.924}", "{\"n\": 8563, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3511.12, \"learn_time_ms\": 43060.504}", "{\"n\": 8564, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3511.12, \"learn_time_ms\": 43041.777}", "{\"n\": 8565, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3515.22, \"learn_time_ms\": 42924.398}", "{\"n\": 8566, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3519.71, \"learn_time_ms\": 43031.899}", "{\"n\": 8567, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3519.71, \"learn_time_ms\": 43008.259}", "{\"n\": 8568, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3517.75, \"learn_time_ms\": 43143.664}", "{\"n\": 8569, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3523.29, \"learn_time_ms\": 42992.848}", "{\"n\": 8570, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3546.55, \"learn_time_ms\": 42982.697}", "{\"n\": 8571, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3552.59, \"learn_time_ms\": 42992.673}", "{\"n\": 8572, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.59, \"learn_time_ms\": 43012.133}", "{\"n\": 8573, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.59, \"learn_time_ms\": 43139.403}", "{\"n\": 8574, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3559.16, \"learn_time_ms\": 43163.659}", "{\"n\": 8575, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3568.39, \"learn_time_ms\": 43147.625}", "{\"n\": 8576, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3570.82, \"learn_time_ms\": 43129.166}", "{\"n\": 8577, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3575.28, \"learn_time_ms\": 43209.903}", "{\"n\": 8578, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3593.98, \"learn_time_ms\": 43083.506}", "{\"n\": 8579, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3593.98, \"learn_time_ms\": 43077.257}", "{\"n\": 8580, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3590.61, \"learn_time_ms\": 43032.159}", "{\"n\": 8581, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.92, \"learn_time_ms\": 42942.368}", "{\"n\": 8582, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.92, \"learn_time_ms\": 42855.344}", "{\"n\": 8583, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.69, \"learn_time_ms\": 42828.769}", "{\"n\": 8584, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3613.69, \"learn_time_ms\": 42884.548}", "{\"n\": 8585, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3612.81, \"learn_time_ms\": 42967.904}", "{\"n\": 8586, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3612.81, \"learn_time_ms\": 42889.441}", "{\"n\": 8587, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3612.81, \"learn_time_ms\": 42967.96}", "{\"n\": 8588, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.52, \"learn_time_ms\": 43007.267}", "{\"n\": 8589, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.63, \"learn_time_ms\": 43061.32}", "{\"n\": 8590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3624.79, \"learn_time_ms\": 43162.264}", "{\"n\": 8591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.77, \"learn_time_ms\": 43232.502}", "{\"n\": 8592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.77, \"learn_time_ms\": 43276.87}", "{\"n\": 8593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3630.68, \"learn_time_ms\": 43340.51}", "{\"n\": 8594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3643.1, \"learn_time_ms\": 43189.356}", "{\"n\": 8595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3623.57, \"learn_time_ms\": 43123.396}", "{\"n\": 8596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3623.57, \"learn_time_ms\": 43211.279}", "{\"n\": 8597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3649.32, \"learn_time_ms\": 43042.723}", "{\"n\": 8598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3649.32, \"learn_time_ms\": 43031.565}", "{\"n\": 8599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3648.99, \"learn_time_ms\": 43009.449}", "{\"n\": 8600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3670.23, \"learn_time_ms\": 42968.077}", "{\"n\": 8601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3659.99, \"learn_time_ms\": 42885.699}", "{\"n\": 8602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3659.8, \"learn_time_ms\": 42878.82}", "{\"n\": 8603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3653.5, \"learn_time_ms\": 42868.37}", "{\"n\": 8604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3648.33, \"learn_time_ms\": 42956.31}", "{\"n\": 8605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3647.16, \"learn_time_ms\": 42919.119}", "{\"n\": 8606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3653.04, \"learn_time_ms\": 42860.849}", "{\"n\": 8607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3653.04, \"learn_time_ms\": 42901.083}", "{\"n\": 8608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3668.15, \"learn_time_ms\": 42879.357}", "{\"n\": 8609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3678.5, \"learn_time_ms\": 42928.255}", "{\"n\": 8610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3668.15, \"learn_time_ms\": 42985.096}", "{\"n\": 8611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.55, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3642.01, \"learn_time_ms\": 43044.562}", "{\"n\": 8612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3619.76, \"learn_time_ms\": 43118.727}", "{\"n\": 8613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3619.76, \"learn_time_ms\": 42975.027}", "{\"n\": 8614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.67, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3618.13, \"learn_time_ms\": 42968.931}", "{\"n\": 8615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3614.76, \"learn_time_ms\": 42987.579}", "{\"n\": 8616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.75, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3605.89, \"learn_time_ms\": 42984.332}", "{\"n\": 8617, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3617.11, \"learn_time_ms\": 43012.787}", "{\"n\": 8618, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3596.59, \"learn_time_ms\": 43008.109}", "{\"n\": 8619, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3596.9, \"learn_time_ms\": 43000.079}", "{\"n\": 8620, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3585.39, \"learn_time_ms\": 42903.822}", "{\"n\": 8621, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3585.39, \"learn_time_ms\": 42874.584}", "{\"n\": 8622, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3585.39, \"learn_time_ms\": 42867.012}", "{\"n\": 8623, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3574.82, \"learn_time_ms\": 43033.038}", "{\"n\": 8624, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.7, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3584.36, \"learn_time_ms\": 43001.11}", "{\"n\": 8625, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3596.83, \"learn_time_ms\": 43013.052}", "{\"n\": 8626, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3610.2, \"learn_time_ms\": 43086.225}", "{\"n\": 8627, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3610.2, \"learn_time_ms\": 43064.013}", "{\"n\": 8628, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.47, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3610.2, \"learn_time_ms\": 43117.245}", "{\"n\": 8629, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3621.83, \"learn_time_ms\": 43113.86}", "{\"n\": 8630, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3622.61, \"learn_time_ms\": 43137.722}", "{\"n\": 8631, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3621.59, \"learn_time_ms\": 43173.511}", "{\"n\": 8632, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3624.63, \"learn_time_ms\": 43146.651}", "{\"n\": 8633, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3624.63, \"learn_time_ms\": 43180.517}", "{\"n\": 8634, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3618.05, \"learn_time_ms\": 43274.79}", "{\"n\": 8635, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3621.38, \"learn_time_ms\": 43253.624}", "{\"n\": 8636, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3621.38, \"learn_time_ms\": 43177.041}", "{\"n\": 8637, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3638.91, \"learn_time_ms\": 43033.416}", "{\"n\": 8638, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3630.09, \"learn_time_ms\": 42919.944}", "{\"n\": 8639, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3630.09, \"learn_time_ms\": 42908.199}", "{\"n\": 8640, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.46, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3629.48, \"learn_time_ms\": 42774.809}", "{\"n\": 8641, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3619.89, \"learn_time_ms\": 42697.006}", "{\"n\": 8642, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3619.89, \"learn_time_ms\": 42702.177}", "{\"n\": 8643, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.51, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3619.85, \"learn_time_ms\": 42543.005}", "{\"n\": 8644, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.73, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3590.2, \"learn_time_ms\": 42494.357}", "{\"n\": 8645, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.71, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3591.09, \"learn_time_ms\": 42508.56}", "{\"n\": 8646, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3586.58, \"learn_time_ms\": 42541.079}", "{\"n\": 8647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3578.93, \"learn_time_ms\": 42662.947}", "{\"n\": 8648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.78, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3578.93, \"learn_time_ms\": 42696.014}", "{\"n\": 8649, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.02, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3549.45, \"learn_time_ms\": 42741.526}", "{\"n\": 8650, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.97, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3561.67, \"learn_time_ms\": 42830.862}", "{\"n\": 8651, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.05, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3544.94, \"learn_time_ms\": 42909.424}", "{\"n\": 8652, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3549.06, \"learn_time_ms\": 42823.058}", "{\"n\": 8653, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.11, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3549.06, \"learn_time_ms\": 42770.896}", "{\"n\": 8654, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3541.19, \"learn_time_ms\": 42678.298}", "{\"n\": 8655, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3541.19, \"learn_time_ms\": 42783.646}", "{\"n\": 8656, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3533.7, \"learn_time_ms\": 42777.24}", "{\"n\": 8657, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3530.94, \"learn_time_ms\": 42832.121}", "{\"n\": 8658, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3522.15, \"learn_time_ms\": 42902.94}", "{\"n\": 8659, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.28, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3522.15, \"learn_time_ms\": 42867.19}", "{\"n\": 8660, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3528.28, \"learn_time_ms\": 42891.888}", "{\"n\": 8661, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.35, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3524.71, \"learn_time_ms\": 42893.177}", "{\"n\": 8662, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.41, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3515.13, \"learn_time_ms\": 42975.097}", "{\"n\": 8663, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.51, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3500.19, \"learn_time_ms\": 43042.318}", "{\"n\": 8664, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3489.17, \"learn_time_ms\": 43108.493}", "{\"n\": 8665, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3494.77, \"learn_time_ms\": 43173.183}", "{\"n\": 8666, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3484.29, \"learn_time_ms\": 43186.941}", "{\"n\": 8667, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3482.91, \"learn_time_ms\": 43200.362}", "{\"n\": 8668, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.67, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3482.91, \"learn_time_ms\": 43205.177}", "{\"n\": 8669, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.62, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3488.86, \"learn_time_ms\": 43269.497}", "{\"n\": 8670, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.63, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3486.79, \"learn_time_ms\": 43299.848}", "{\"n\": 8671, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3496.01, \"learn_time_ms\": 43281.305}", "{\"n\": 8672, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.52, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3496.01, \"learn_time_ms\": 43213.248}", "{\"n\": 8673, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.6, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3482.99, \"learn_time_ms\": 43264.279}", "{\"n\": 8674, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.47, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3491.56, \"learn_time_ms\": 43171.968}", "{\"n\": 8675, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.45, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3487.73, \"learn_time_ms\": 43142.285}", "{\"n\": 8676, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3492.66, \"learn_time_ms\": 43107.719}", "{\"n\": 8677, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.43, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3497.49, \"learn_time_ms\": 43048.889}", "{\"n\": 8678, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3505.08, \"learn_time_ms\": 42982.475}", "{\"n\": 8679, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.37, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3505.08, \"learn_time_ms\": 42919.718}", "{\"n\": 8680, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.23, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3514.28, \"learn_time_ms\": 42884.658}", "{\"n\": 8681, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.26, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3505.03, \"learn_time_ms\": 42952.611}", "{\"n\": 8682, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.27, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3496.38, \"learn_time_ms\": 42923.173}", "{\"n\": 8683, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3502.33, \"learn_time_ms\": 42855.957}", "{\"n\": 8684, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.22, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3502.33, \"learn_time_ms\": 43064.916}", "{\"n\": 8685, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3531.03, \"learn_time_ms\": 43067.741}", "{\"n\": 8686, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -7.0, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3531.03, \"learn_time_ms\": 43029.722}", "{\"n\": 8687, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.98, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3539.26, \"learn_time_ms\": 43134.132}", "{\"n\": 8688, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3547.49, \"learn_time_ms\": 43179.27}", "{\"n\": 8689, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3566.48, \"learn_time_ms\": 43218.783}", "{\"n\": 8690, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.68, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3566.48, \"learn_time_ms\": 43224.863}", "{\"n\": 8691, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.87, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3544.33, \"learn_time_ms\": 43226.714}", "{\"n\": 8692, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3565.06, \"learn_time_ms\": 43258.093}", "{\"n\": 8693, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3565.06, \"learn_time_ms\": 43296.309}", "{\"n\": 8694, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3572.48, \"learn_time_ms\": 43219.221}", "{\"n\": 8695, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.65, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3572.48, \"learn_time_ms\": 43109.89}", "{\"n\": 8696, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3592.44, \"learn_time_ms\": 43183.429}", "{\"n\": 8697, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3594.15, \"learn_time_ms\": 43013.52}", "{\"n\": 8698, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3583.55, \"learn_time_ms\": 43167.638}", "{\"n\": 8699, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.38, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3583.55, \"learn_time_ms\": 43208.308}", "{\"n\": 8700, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.52, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3571.67, \"learn_time_ms\": 43128.378}", "{\"n\": 8701, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.39, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3574.83, \"learn_time_ms\": 43042.149}", "{\"n\": 8702, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.4, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3566.67, \"learn_time_ms\": 42985.027}", "{\"n\": 8703, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3556.3, \"learn_time_ms\": 42991.345}", "{\"n\": 8704, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3572.1, \"learn_time_ms\": 42993.777}", "{\"n\": 8705, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3579.8, \"learn_time_ms\": 43152.892}", "{\"n\": 8706, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3564.48, \"learn_time_ms\": 43035.91}", "{\"n\": 8707, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3581.31, \"learn_time_ms\": 43119.337}", "{\"n\": 8708, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3581.31, \"learn_time_ms\": 43026.007}", "{\"n\": 8709, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3571.25, \"learn_time_ms\": 42892.676}", "{\"n\": 8710, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3571.25, \"learn_time_ms\": 42981.554}", "{\"n\": 8711, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3571.25, \"learn_time_ms\": 42961.404}", "{\"n\": 8712, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3546.95, \"learn_time_ms\": 42994.6}", "{\"n\": 8713, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3538.51, \"learn_time_ms\": 43015.9}", "{\"n\": 8714, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3538.51, \"learn_time_ms\": 43020.025}", "{\"n\": 8715, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3540.45, \"learn_time_ms\": 42998.573}", "{\"n\": 8716, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3540.45, \"learn_time_ms\": 43061.465}", "{\"n\": 8717, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3562.82, \"learn_time_ms\": 43010.151}", "{\"n\": 8718, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3575.15, \"learn_time_ms\": 43067.415}", "{\"n\": 8719, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3574.37, \"learn_time_ms\": 43047.504}", "{\"n\": 8720, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3574.37, \"learn_time_ms\": 43044.588}", "{\"n\": 8721, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3579.53, \"learn_time_ms\": 43108.965}", "{\"n\": 8722, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3579.53, \"learn_time_ms\": 43177.619}", "{\"n\": 8723, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3581.46, \"learn_time_ms\": 43143.531}", "{\"n\": 8724, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3572.25, \"learn_time_ms\": 43209.881}", "{\"n\": 8725, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3592.95, \"learn_time_ms\": 43041.58}", "{\"n\": 8726, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3592.95, \"learn_time_ms\": 43030.644}", "{\"n\": 8727, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3603.43, \"learn_time_ms\": 43087.677}", "{\"n\": 8728, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3594.34, \"learn_time_ms\": 42929.749}", "{\"n\": 8729, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3589.57, \"learn_time_ms\": 42991.865}", "{\"n\": 8730, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3591.47, \"learn_time_ms\": 42899.293}", "{\"n\": 8731, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3602.06, \"learn_time_ms\": 42872.797}", "{\"n\": 8732, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3617.13, \"learn_time_ms\": 42833.654}", "{\"n\": 8733, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3617.13, \"learn_time_ms\": 42821.096}", "{\"n\": 8734, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3617.13, \"learn_time_ms\": 42701.026}", "{\"n\": 8735, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3615.79, \"learn_time_ms\": 42791.819}", "{\"n\": 8736, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3624.06, \"learn_time_ms\": 42723.408}", "{\"n\": 8737, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.28, \"learn_time_ms\": 42721.595}", "{\"n\": 8738, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3636.99, \"learn_time_ms\": 42654.66}", "{\"n\": 8739, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3636.99, \"learn_time_ms\": 42676.421}", "{\"n\": 8740, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3646.06, \"learn_time_ms\": 42670.899}", "{\"n\": 8741, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3646.06, \"learn_time_ms\": 42659.629}", "{\"n\": 8742, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3663.91, \"learn_time_ms\": 42509.97}", "{\"n\": 8743, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3670.94, \"learn_time_ms\": 42431.356}", "{\"n\": 8744, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3668.22, \"learn_time_ms\": 42405.485}", "{\"n\": 8745, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.46, \"learn_time_ms\": 42323.269}", "{\"n\": 8746, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.46, \"learn_time_ms\": 42271.393}", "{\"n\": 8747, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3660.09, \"learn_time_ms\": 42229.242}", "{\"n\": 8748, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3660.09, \"learn_time_ms\": 42345.19}", "{\"n\": 8749, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3663.59, \"learn_time_ms\": 42412.485}", "{\"n\": 8750, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3668.36, \"learn_time_ms\": 42459.092}", "{\"n\": 8751, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3668.36, \"learn_time_ms\": 42484.208}", "{\"n\": 8752, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3668.96, \"learn_time_ms\": 42664.896}", "{\"n\": 8753, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3656.6, \"learn_time_ms\": 42718.59}", "{\"n\": 8754, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.04, \"learn_time_ms\": 42866.525}", "{\"n\": 8755, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.86, \"learn_time_ms\": 42873.963}", "{\"n\": 8756, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.86, \"learn_time_ms\": 43020.707}", "{\"n\": 8757, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3641.86, \"learn_time_ms\": 43028.916}", "{\"n\": 8758, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3648.57, \"learn_time_ms\": 42971.619}", "{\"n\": 8759, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3648.57, \"learn_time_ms\": 42912.067}", "{\"n\": 8760, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3653.97, \"learn_time_ms\": 42913.181}", "{\"n\": 8761, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3657.98, \"learn_time_ms\": 42962.958}", "{\"n\": 8762, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3657.98, \"learn_time_ms\": 42952.874}", "{\"n\": 8763, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3657.98, \"learn_time_ms\": 42974.315}", "{\"n\": 8764, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3649.72, \"learn_time_ms\": 42812.654}", "{\"n\": 8765, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3643.27, \"learn_time_ms\": 42848.688}", "{\"n\": 8766, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.11, \"learn_time_ms\": 42879.301}", "{\"n\": 8767, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.11, \"learn_time_ms\": 42895.435}", "{\"n\": 8768, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.06, \"learn_time_ms\": 43004.277}", "{\"n\": 8769, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3660.3, \"learn_time_ms\": 42953.535}", "{\"n\": 8770, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.47, \"learn_time_ms\": 42972.642}", "{\"n\": 8771, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3644.41, \"learn_time_ms\": 42979.202}", "{\"n\": 8772, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3635.31, \"learn_time_ms\": 42963.197}", "{\"n\": 8773, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3635.31, \"learn_time_ms\": 42983.754}", "{\"n\": 8774, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.82, \"learn_time_ms\": 42912.335}", "{\"n\": 8775, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3650.82, \"learn_time_ms\": 42928.942}", "{\"n\": 8776, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3653.7, \"learn_time_ms\": 42853.637}", "{\"n\": 8777, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3648.75, \"learn_time_ms\": 42722.352}", "{\"n\": 8778, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3645.77, \"learn_time_ms\": 42735.835}", "{\"n\": 8779, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3645.77, \"learn_time_ms\": 42848.602}", "{\"n\": 8780, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.05, \"learn_time_ms\": 43024.391}", "{\"n\": 8781, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.05, \"learn_time_ms\": 42969.704}", "{\"n\": 8782, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.05, \"learn_time_ms\": 42950.476}", "{\"n\": 8783, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3630.69, \"learn_time_ms\": 42818.574}", "{\"n\": 8784, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.0, \"learn_time_ms\": 42970.254}", "{\"n\": 8785, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3636.66, \"learn_time_ms\": 42898.283}", "{\"n\": 8786, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3653.75, \"learn_time_ms\": 42974.087}", "{\"n\": 8787, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.8, \"learn_time_ms\": 43043.044}", "{\"n\": 8788, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3661.8, \"learn_time_ms\": 42974.78}", "{\"n\": 8789, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3668.16, \"learn_time_ms\": 42984.942}", "{\"n\": 8790, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3689.96, \"learn_time_ms\": 42843.217}", "{\"n\": 8791, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3689.96, \"learn_time_ms\": 42862.039}", "{\"n\": 8792, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3700.01, \"learn_time_ms\": 42997.418}", "{\"n\": 8793, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3700.01, \"learn_time_ms\": 43102.955}", "{\"n\": 8794, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3689.86, \"learn_time_ms\": 43106.999}", "{\"n\": 8795, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3682.62, \"learn_time_ms\": 43048.068}", "{\"n\": 8796, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3682.26, \"learn_time_ms\": 42963.635}", "{\"n\": 8797, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3678.51, \"learn_time_ms\": 43000.903}", "{\"n\": 8798, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3703.28, \"learn_time_ms\": 42976.471}", "{\"n\": 8799, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3703.28, \"learn_time_ms\": 42798.118}", "{\"n\": 8800, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3713.55, \"learn_time_ms\": 42925.485}", "{\"n\": 8801, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3701.36, \"learn_time_ms\": 42971.959}", "{\"n\": 8802, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3701.36, \"learn_time_ms\": 42883.893}", "{\"n\": 8803, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3700.54, \"learn_time_ms\": 42786.079}", "{\"n\": 8804, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3710.33, \"learn_time_ms\": 42718.928}", "{\"n\": 8805, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3691.4, \"learn_time_ms\": 42934.511}", "{\"n\": 8806, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3661.38, \"learn_time_ms\": 42983.24}", "{\"n\": 8807, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3661.38, \"learn_time_ms\": 43079.347}", "{\"n\": 8808, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3661.38, \"learn_time_ms\": 43179.228}", "{\"n\": 8809, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3653.3, \"learn_time_ms\": 43323.431}", "{\"n\": 8810, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.65, \"learn_time_ms\": 43105.447}", "{\"n\": 8811, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3659.02, \"learn_time_ms\": 42970.691}", "{\"n\": 8812, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3670.96, \"learn_time_ms\": 42942.915}", "{\"n\": 8813, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3662.93, \"learn_time_ms\": 43111.948}", "{\"n\": 8814, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3651.24, \"learn_time_ms\": 43271.89}", "{\"n\": 8815, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3653.77, \"learn_time_ms\": 43154.923}", "{\"n\": 8816, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.44, \"learn_time_ms\": 43160.267}", "{\"n\": 8817, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.44, \"learn_time_ms\": 43091.709}", "{\"n\": 8818, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.37, \"learn_time_ms\": 43121.706}", "{\"n\": 8819, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.27, \"learn_time_ms\": 43136.878}", "{\"n\": 8820, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3630.65, \"learn_time_ms\": 43218.444}", "{\"n\": 8821, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3630.65, \"learn_time_ms\": 43271.427}", "{\"n\": 8822, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3621.97, \"learn_time_ms\": 43314.426}", "{\"n\": 8823, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3632.08, \"learn_time_ms\": 43252.755}", "{\"n\": 8824, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3611.08, \"learn_time_ms\": 43092.432}", "{\"n\": 8825, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.33, \"learn_time_ms\": 43115.688}", "{\"n\": 8826, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.33, \"learn_time_ms\": 43060.892}", "{\"n\": 8827, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.33, \"learn_time_ms\": 43012.004}", "{\"n\": 8828, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3606.84, \"learn_time_ms\": 42914.433}", "{\"n\": 8829, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.99, \"learn_time_ms\": 42888.432}", "{\"n\": 8830, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3621.46, \"learn_time_ms\": 42983.981}", "{\"n\": 8831, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3622.43, \"learn_time_ms\": 43009.198}", "{\"n\": 8832, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3615.37, \"learn_time_ms\": 42999.093}", "{\"n\": 8833, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.3, \"learn_time_ms\": 43021.174}", "{\"n\": 8834, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3610.82, \"learn_time_ms\": 43130.167}", "{\"n\": 8835, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3611.69, \"learn_time_ms\": 43043.34}", "{\"n\": 8836, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3611.69, \"learn_time_ms\": 43251.536}", "{\"n\": 8837, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3612.57, \"learn_time_ms\": 43252.38}", "{\"n\": 8838, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3620.53, \"learn_time_ms\": 43263.525}", "{\"n\": 8839, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3620.53, \"learn_time_ms\": 43331.707}", "{\"n\": 8840, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3626.16, \"learn_time_ms\": 43231.106}", "{\"n\": 8841, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.73, \"learn_time_ms\": 43190.53}", "{\"n\": 8842, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3616.73, \"learn_time_ms\": 43134.096}", "{\"n\": 8843, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3635.6, \"learn_time_ms\": 43116.411}", "{\"n\": 8844, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3635.6, \"learn_time_ms\": 43084.076}", "{\"n\": 8845, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3635.6, \"learn_time_ms\": 43348.061}", "{\"n\": 8846, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3638.44, \"learn_time_ms\": 43202.016}", "{\"n\": 8847, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3645.58, \"learn_time_ms\": 43272.685}", "{\"n\": 8848, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3643.46, \"learn_time_ms\": 43175.666}", "{\"n\": 8849, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3639.79, \"learn_time_ms\": 43032.421}", "{\"n\": 8850, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3639.79, \"learn_time_ms\": 43241.446}", "{\"n\": 8851, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3639.79, \"learn_time_ms\": 43337.162}", "{\"n\": 8852, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3643.52, \"learn_time_ms\": 43273.097}", "{\"n\": 8853, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3652.64, \"learn_time_ms\": 43207.559}", "{\"n\": 8854, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3652.64, \"learn_time_ms\": 43229.551}", "{\"n\": 8855, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.06, \"learn_time_ms\": 42928.187}", "{\"n\": 8856, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.06, \"learn_time_ms\": 42930.654}", "{\"n\": 8857, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.06, \"learn_time_ms\": 42852.395}", "{\"n\": 8858, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3644.92, \"learn_time_ms\": 42927.748}", "{\"n\": 8859, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3618.72, \"learn_time_ms\": 43041.098}", "{\"n\": 8860, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3614.76, \"learn_time_ms\": 42900.973}", "{\"n\": 8861, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3618.84, \"learn_time_ms\": 42810.006}", "{\"n\": 8862, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3618.84, \"learn_time_ms\": 42902.352}", "{\"n\": 8863, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.8, \"learn_time_ms\": 43006.256}", "{\"n\": 8864, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.8, \"learn_time_ms\": 42952.064}", "{\"n\": 8865, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3576.5, \"learn_time_ms\": 43044.164}", "{\"n\": 8866, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3576.5, \"learn_time_ms\": 43061.585}", "{\"n\": 8867, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3578.41, \"learn_time_ms\": 43093.659}", "{\"n\": 8868, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3572.19, \"learn_time_ms\": 43133.259}", "{\"n\": 8869, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3570.93, \"learn_time_ms\": 43046.707}", "{\"n\": 8870, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3570.93, \"learn_time_ms\": 43018.461}", "{\"n\": 8871, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3584.72, \"learn_time_ms\": 42987.462}", "{\"n\": 8872, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3585.18, \"learn_time_ms\": 42967.072}", "{\"n\": 8873, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3594.12, \"learn_time_ms\": 42868.718}", "{\"n\": 8874, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3578.2, \"learn_time_ms\": 42795.863}", "{\"n\": 8875, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3578.2, \"learn_time_ms\": 42742.373}", "{\"n\": 8876, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3576.91, \"learn_time_ms\": 42680.48}", "{\"n\": 8877, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3577.78, \"learn_time_ms\": 42727.042}", "{\"n\": 8878, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3569.59, \"learn_time_ms\": 42564.693}", "{\"n\": 8879, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3588.53, \"learn_time_ms\": 42651.835}", "{\"n\": 8880, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3601.08, \"learn_time_ms\": 42614.97}", "{\"n\": 8881, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3606.02, \"learn_time_ms\": 42633.535}", "{\"n\": 8882, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3605.8, \"learn_time_ms\": 42586.643}", "{\"n\": 8883, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3602.77, \"learn_time_ms\": 42572.154}", "{\"n\": 8884, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3602.77, \"learn_time_ms\": 42728.841}", "{\"n\": 8885, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3606.36, \"learn_time_ms\": 42743.408}", "{\"n\": 8886, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3593.62, \"learn_time_ms\": 42733.212}", "{\"n\": 8887, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3593.62, \"learn_time_ms\": 42766.009}", "{\"n\": 8888, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3586.8, \"learn_time_ms\": 42863.389}", "{\"n\": 8889, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3591.78, \"learn_time_ms\": 42930.951}", "{\"n\": 8890, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3591.78, \"learn_time_ms\": 42852.133}", "{\"n\": 8891, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3601.85, \"learn_time_ms\": 42801.727}", "{\"n\": 8892, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3600.47, \"learn_time_ms\": 42830.883}", "{\"n\": 8893, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.71, \"learn_time_ms\": 42899.524}", "{\"n\": 8894, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.35, \"learn_time_ms\": 42825.314}", "{\"n\": 8895, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3597.92, \"learn_time_ms\": 42752.043}", "{\"n\": 8896, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3611.42, \"learn_time_ms\": 42789.211}", "{\"n\": 8897, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3611.42, \"learn_time_ms\": 42635.588}", "{\"n\": 8898, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3607.29, \"learn_time_ms\": 42614.782}", "{\"n\": 8899, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3621.84, \"learn_time_ms\": 42474.672}", "{\"n\": 8900, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.23, \"learn_time_ms\": 42492.39}", "{\"n\": 8901, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3640.05, \"learn_time_ms\": 42613.259}", "{\"n\": 8902, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.99, \"learn_time_ms\": 42611.321}", "{\"n\": 8903, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.99, \"learn_time_ms\": 42645.207}", "{\"n\": 8904, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3650.68, \"learn_time_ms\": 42597.339}", "{\"n\": 8905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.67, \"learn_time_ms\": 42647.134}", "{\"n\": 8906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3644.67, \"learn_time_ms\": 42635.26}", "{\"n\": 8907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3638.49, \"learn_time_ms\": 42718.151}", "{\"n\": 8908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3653.3, \"learn_time_ms\": 42811.323}", "{\"n\": 8909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3642.13, \"learn_time_ms\": 42758.983}", "{\"n\": 8910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3629.79, \"learn_time_ms\": 42814.639}", "{\"n\": 8911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3627.12, \"learn_time_ms\": 42926.05}", "{\"n\": 8912, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3627.63, \"learn_time_ms\": 42897.188}", "{\"n\": 8913, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3626.44, \"learn_time_ms\": 42747.966}", "{\"n\": 8914, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3625.99, \"learn_time_ms\": 42717.732}", "{\"n\": 8915, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3625.99, \"learn_time_ms\": 42697.713}", "{\"n\": 8916, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3632.33, \"learn_time_ms\": 42605.274}", "{\"n\": 8917, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3633.34, \"learn_time_ms\": 42559.176}", "{\"n\": 8918, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3625.37, \"learn_time_ms\": 42463.313}", "{\"n\": 8919, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3604.76, \"learn_time_ms\": 42555.671}", "{\"n\": 8920, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.34, \"learn_time_ms\": 42615.143}", "{\"n\": 8921, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3589.34, \"learn_time_ms\": 42442.759}", "{\"n\": 8922, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3589.76, \"learn_time_ms\": 42526.72}", "{\"n\": 8923, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3610.0, \"learn_time_ms\": 42603.329}", "{\"n\": 8924, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 5.0, \"episode_len_mean\": 3608.05, \"learn_time_ms\": 42632.244}", "{\"n\": 8925, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3589.8, \"learn_time_ms\": 42684.461}", "{\"n\": 8926, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3589.8, \"learn_time_ms\": 42942.585}", "{\"n\": 8927, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3607.7, \"learn_time_ms\": 42965.192}", "{\"n\": 8928, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3595.42, \"learn_time_ms\": 43040.777}", "{\"n\": 8929, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3583.82, \"learn_time_ms\": 43023.066}", "{\"n\": 8930, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3609.85, \"learn_time_ms\": 42937.997}", "{\"n\": 8931, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3608.71, \"learn_time_ms\": 42840.125}", "{\"n\": 8932, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3608.71, \"learn_time_ms\": 42803.544}", "{\"n\": 8933, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3612.97, \"learn_time_ms\": 42799.791}", "{\"n\": 8934, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3604.85, \"learn_time_ms\": 42867.979}", "{\"n\": 8935, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3603.15, \"learn_time_ms\": 42874.736}", "{\"n\": 8936, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3603.15, \"learn_time_ms\": 42676.737}", "{\"n\": 8937, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3604.91, \"learn_time_ms\": 42691.144}", "{\"n\": 8938, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3604.91, \"learn_time_ms\": 42622.871}", "{\"n\": 8939, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3604.91, \"learn_time_ms\": 42584.352}", "{\"n\": 8940, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3606.45, \"learn_time_ms\": 42684.31}", "{\"n\": 8941, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3606.45, \"learn_time_ms\": 42880.45}", "{\"n\": 8942, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3602.74, \"learn_time_ms\": 42902.821}", "{\"n\": 8943, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3608.04, \"learn_time_ms\": 42940.815}", "{\"n\": 8944, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3608.04, \"learn_time_ms\": 42996.02}", "{\"n\": 8945, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3605.31, \"learn_time_ms\": 43043.718}", "{\"n\": 8946, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3605.31, \"learn_time_ms\": 43066.465}", "{\"n\": 8947, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3605.42, \"learn_time_ms\": 43035.99}", "{\"n\": 8948, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3598.03, \"learn_time_ms\": 43067.762}", "{\"n\": 8949, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3630.95, \"learn_time_ms\": 43056.996}", "{\"n\": 8950, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3630.95, \"learn_time_ms\": 42934.6}", "{\"n\": 8951, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3630.95, \"learn_time_ms\": 42915.206}", "{\"n\": 8952, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3632.51, \"learn_time_ms\": 42896.887}", "{\"n\": 8953, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3628.29, \"learn_time_ms\": 42823.481}", "{\"n\": 8954, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3635.17, \"learn_time_ms\": 42740.392}", "{\"n\": 8955, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3623.64, \"learn_time_ms\": 42661.241}", "{\"n\": 8956, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3632.91, \"learn_time_ms\": 42757.575}", "{\"n\": 8957, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3631.01, \"learn_time_ms\": 42931.264}", "{\"n\": 8958, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3627.47, \"learn_time_ms\": 42960.369}", "{\"n\": 8959, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3627.47, \"learn_time_ms\": 42914.984}", "{\"n\": 8960, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 4.0, \"episode_len_mean\": 3624.21, \"learn_time_ms\": 43045.979}", "{\"n\": 8961, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.18, \"learn_time_ms\": 43023.975}", "{\"n\": 8962, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3637.46, \"learn_time_ms\": 42926.918}", "{\"n\": 8963, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3637.46, \"learn_time_ms\": 43114.702}", "{\"n\": 8964, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.93, \"learn_time_ms\": 43086.568}", "{\"n\": 8965, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.93, \"learn_time_ms\": 43161.932}", "{\"n\": 8966, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.33, \"learn_time_ms\": 43062.417}", "{\"n\": 8967, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3637.43, \"learn_time_ms\": 43049.076}", "{\"n\": 8968, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.61, \"learn_time_ms\": 42991.262}", "{\"n\": 8969, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.85, \"learn_time_ms\": 43046.23}", "{\"n\": 8970, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.85, \"learn_time_ms\": 42983.435}", "{\"n\": 8971, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.71, \"learn_time_ms\": 42916.605}", "{\"n\": 8972, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3633.48, \"learn_time_ms\": 42922.132}", "{\"n\": 8973, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3648.32, \"learn_time_ms\": 42759.815}", "{\"n\": 8974, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.55, \"learn_time_ms\": 42771.864}", "{\"n\": 8975, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.95, \"learn_time_ms\": 42854.691}", "{\"n\": 8976, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.82, \"learn_time_ms\": 42861.084}", "{\"n\": 8977, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.82, \"learn_time_ms\": 42779.617}", "{\"n\": 8978, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.34, \"learn_time_ms\": 42886.651}", "{\"n\": 8979, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.34, \"learn_time_ms\": 42884.231}", "{\"n\": 8980, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.65, \"learn_time_ms\": 42840.252}", "{\"n\": 8981, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.01, \"learn_time_ms\": 42789.848}", "{\"n\": 8982, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.3, \"learn_time_ms\": 42841.028}", "{\"n\": 8983, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.3, \"learn_time_ms\": 42931.861}", "{\"n\": 8984, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.3, \"learn_time_ms\": 42982.069}", "{\"n\": 8985, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.72, \"learn_time_ms\": 42884.008}", "{\"n\": 8986, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.43, \"learn_time_ms\": 42790.524}", "{\"n\": 8987, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.77, \"learn_time_ms\": 42708.303}", "{\"n\": 8988, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.77, \"learn_time_ms\": 42548.065}", "{\"n\": 8989, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3642.98, \"learn_time_ms\": 42518.787}", "{\"n\": 8990, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.33, \"learn_time_ms\": 42576.899}", "{\"n\": 8991, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3652.56, \"learn_time_ms\": 42645.748}", "{\"n\": 8992, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.92, \"learn_time_ms\": 42610.426}", "{\"n\": 8993, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.2, \"learn_time_ms\": 42544.39}", "{\"n\": 8994, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.74, \"learn_time_ms\": 42537.719}", "{\"n\": 8995, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.31, \"learn_time_ms\": 42563.064}", "{\"n\": 8996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.98, \"learn_time_ms\": 42700.9}", "{\"n\": 8997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.54, \"learn_time_ms\": 42719.179}", "{\"n\": 8998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.57, \"learn_time_ms\": 42694.745}", "{\"n\": 8999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.41, \"learn_time_ms\": 42733.695}", "{\"n\": 9000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3657.43, \"learn_time_ms\": 42705.394}"]["{\"n\": 9001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 49927.734}", "{\"n\": 9002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 48476.472}", "{\"n\": 9003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47822.896}", "{\"n\": 9004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47548.162}", "{\"n\": 9005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47353.589}", "{\"n\": 9006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47291.047}", "{\"n\": 9007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47233.706}", "{\"n\": 9008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47164.636}", "{\"n\": 9009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47127.222}", "{\"n\": 9010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 47018.864}", "{\"n\": 9011, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 3224.0, \"learn_time_ms\": 46758.183}", "{\"n\": 9012, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -8.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 3484.0, \"learn_time_ms\": 46675.971}", "{\"n\": 9013, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3588.5, \"learn_time_ms\": 46742.554}", "{\"n\": 9014, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.166666666666667, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3703.8333333333335, \"learn_time_ms\": 46767.525}", "{\"n\": 9015, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -2.625, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3791.625, \"learn_time_ms\": 46717.195}", "{\"n\": 9016, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -3.4444444444444446, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3712.8888888888887, \"learn_time_ms\": 46709.452}", "{\"n\": 9017, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -3.4444444444444446, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3712.8888888888887, \"learn_time_ms\": 46673.122}", "{\"n\": 9018, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3736.9, \"learn_time_ms\": 46676.197}", "{\"n\": 9019, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -3.4545454545454546, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3700.2727272727275, \"learn_time_ms\": 46617.922}", "{\"n\": 9020, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -2.7857142857142856, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3753.5, \"learn_time_ms\": 46680.149}", "{\"n\": 9021, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -2.533333333333333, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3802.4, \"learn_time_ms\": 46660.031}", "{\"n\": 9022, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -2.4375, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3871.9375, \"learn_time_ms\": 46701.225}", "{\"n\": 9023, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -2.6470588235294117, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3840.5882352941176, \"learn_time_ms\": 46682.753}", "{\"n\": 9024, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -2.6470588235294117, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3840.5882352941176, \"learn_time_ms\": 46667.741}", "{\"n\": 9025, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3806.2, \"learn_time_ms\": 46779.994}", "{\"n\": 9026, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -2.8636363636363638, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3843.090909090909, \"learn_time_ms\": 46709.583}", "{\"n\": 9027, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -2.8636363636363638, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3843.090909090909, \"learn_time_ms\": 46764.644}", "{\"n\": 9028, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.217391304347826, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3811.608695652174, \"learn_time_ms\": 46736.191}", "{\"n\": 9029, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.2916666666666665, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3828.25, \"learn_time_ms\": 46722.523}", "{\"n\": 9030, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3851.1923076923076, \"learn_time_ms\": 46771.808}", "{\"n\": 9031, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.111111111111111, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3831.740740740741, \"learn_time_ms\": 46784.357}", "{\"n\": 9032, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.3214285714285716, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3808.6071428571427, \"learn_time_ms\": 46744.458}", "{\"n\": 9033, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3785.5, \"learn_time_ms\": 46647.347}", "{\"n\": 9034, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.09375, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3819.375, \"learn_time_ms\": 46665.967}", "{\"n\": 9035, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.090909090909091, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3822.969696969697, \"learn_time_ms\": 46617.159}", "{\"n\": 9036, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.090909090909091, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3822.969696969697, \"learn_time_ms\": 46634.392}", "{\"n\": 9037, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.4285714285714284, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3785.342857142857, \"learn_time_ms\": 46575.008}", "{\"n\": 9038, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.4166666666666665, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3791.0, \"learn_time_ms\": 46552.662}", "{\"n\": 9039, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.3513513513513513, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3798.972972972973, \"learn_time_ms\": 46559.566}", "{\"n\": 9040, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.289473684210526, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3810.7105263157896, \"learn_time_ms\": 46495.765}", "{\"n\": 9041, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.2439024390243905, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3787.2926829268295, \"learn_time_ms\": 46459.493}", "{\"n\": 9042, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.0476190476190474, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3784.309523809524, \"learn_time_ms\": 46507.22}", "{\"n\": 9043, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.86046511627907, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3795.8837209302324, \"learn_time_ms\": 46565.622}", "{\"n\": 9044, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.86046511627907, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3795.8837209302324, \"learn_time_ms\": 46558.834}", "{\"n\": 9045, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.8444444444444446, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3800.0666666666666, \"learn_time_ms\": 46633.356}", "{\"n\": 9046, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.891304347826087, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3795.9347826086955, \"learn_time_ms\": 46572.032}", "{\"n\": 9047, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.7551020408163267, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3801.530612244898, \"learn_time_ms\": 46512.323}", "{\"n\": 9048, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3792.78, \"learn_time_ms\": 46505.153}", "{\"n\": 9049, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.9607843137254903, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3780.843137254902, \"learn_time_ms\": 46501.241}", "{\"n\": 9050, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -2.9423076923076925, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3789.980769230769, \"learn_time_ms\": 46507.422}", "{\"n\": 9051, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3795.377358490566, \"learn_time_ms\": 46462.77}", "{\"n\": 9052, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.1403508771929824, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3777.7017543859647, \"learn_time_ms\": 46435.806}", "{\"n\": 9053, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.1403508771929824, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3777.7017543859647, \"learn_time_ms\": 46398.208}", "{\"n\": 9054, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.189655172413793, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3773.2413793103447, \"learn_time_ms\": 46408.174}", "{\"n\": 9055, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.189655172413793, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3773.2413793103447, \"learn_time_ms\": 46318.993}", "{\"n\": 9056, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.2711864406779663, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3767.0338983050847, \"learn_time_ms\": 46408.476}", "{\"n\": 9057, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4444444444444446, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3750.031746031746, \"learn_time_ms\": 46552.453}", "{\"n\": 9058, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.4444444444444446, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3750.031746031746, \"learn_time_ms\": 46560.966}", "{\"n\": 9059, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.5846153846153848, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3736.476923076923, \"learn_time_ms\": 46517.667}", "{\"n\": 9060, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.621212121212121, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.469696969697, \"learn_time_ms\": 46500.594}", "{\"n\": 9061, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.621212121212121, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3731.469696969697, \"learn_time_ms\": 46559.562}", "{\"n\": 9062, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.742857142857143, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3726.6714285714284, \"learn_time_ms\": 46501.612}", "{\"n\": 9063, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.8028169014084505, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3723.9295774647885, \"learn_time_ms\": 46527.219}", "{\"n\": 9064, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7083333333333335, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3726.652777777778, \"learn_time_ms\": 46537.145}", "{\"n\": 9065, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.684931506849315, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3729.8630136986303, \"learn_time_ms\": 46437.472}", "{\"n\": 9066, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.684931506849315, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3729.8630136986303, \"learn_time_ms\": 46479.782}", "{\"n\": 9067, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7567567567567566, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3720.337837837838, \"learn_time_ms\": 46403.247}", "{\"n\": 9068, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.9358974358974357, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3709.730769230769, \"learn_time_ms\": 46483.796}", "{\"n\": 9069, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.0375, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3706.0125, \"learn_time_ms\": 46434.48}", "{\"n\": 9070, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.074074074074074, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3698.246913580247, \"learn_time_ms\": 46457.026}", "{\"n\": 9071, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.146341463414634, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3691.3658536585367, \"learn_time_ms\": 46423.434}", "{\"n\": 9072, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.144578313253012, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3692.397590361446, \"learn_time_ms\": 46465.235}", "{\"n\": 9073, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.144578313253012, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3692.397590361446, \"learn_time_ms\": 46427.574}", "{\"n\": 9074, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.178571428571429, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3692.9166666666665, \"learn_time_ms\": 46380.698}", "{\"n\": 9075, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.318181818181818, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3683.2954545454545, \"learn_time_ms\": 46505.263}", "{\"n\": 9076, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.348314606741573, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3683.752808988764, \"learn_time_ms\": 46422.301}", "{\"n\": 9077, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.455555555555556, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3668.266666666667, \"learn_time_ms\": 46342.419}", "{\"n\": 9078, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56043956043956, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3656.5384615384614, \"learn_time_ms\": 46284.601}", "{\"n\": 9079, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56043956043956, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3656.5384615384614, \"learn_time_ms\": 46384.506}", "{\"n\": 9080, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.585106382978723, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3654.723404255319, \"learn_time_ms\": 46327.817}", "{\"n\": 9081, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.552083333333333, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3666.59375, \"learn_time_ms\": 46313.275}", "{\"n\": 9082, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.552083333333333, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3666.59375, \"learn_time_ms\": 46243.764}", "{\"n\": 9083, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.618556701030927, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3661.6494845360826, \"learn_time_ms\": 46220.782}", "{\"n\": 9084, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3649.13, \"learn_time_ms\": 46142.672}", "{\"n\": 9085, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3653.87, \"learn_time_ms\": 45993.704}", "{\"n\": 9086, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3650.07, \"learn_time_ms\": 45881.635}", "{\"n\": 9087, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3644.71, \"learn_time_ms\": 45844.309}", "{\"n\": 9088, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3639.61, \"learn_time_ms\": 45754.709}", "{\"n\": 9089, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3641.79, \"learn_time_ms\": 45684.263}", "{\"n\": 9090, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3615.36, \"learn_time_ms\": 45626.857}", "{\"n\": 9091, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3626.25, \"learn_time_ms\": 45504.947}", "{\"n\": 9092, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3619.65, \"learn_time_ms\": 45410.308}", "{\"n\": 9093, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3627.42, \"learn_time_ms\": 45399.835}", "{\"n\": 9094, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3629.87, \"learn_time_ms\": 45448.551}", "{\"n\": 9095, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3629.87, \"learn_time_ms\": 45510.866}", "{\"n\": 9096, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3599.55, \"learn_time_ms\": 45487.745}", "{\"n\": 9097, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3604.52, \"learn_time_ms\": 45524.584}", "{\"n\": 9098, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3603.64, \"learn_time_ms\": 45504.263}", "{\"n\": 9099, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3604.61, \"learn_time_ms\": 45607.829}", "{\"n\": 9100, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3582.44, \"learn_time_ms\": 45712.53}", "{\"n\": 9101, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3582.44, \"learn_time_ms\": 45731.168}", "{\"n\": 9102, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3589.12, \"learn_time_ms\": 45880.412}", "{\"n\": 9103, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3584.49, \"learn_time_ms\": 45887.435}", "{\"n\": 9104, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3566.59, \"learn_time_ms\": 45844.248}", "{\"n\": 9105, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3566.59, \"learn_time_ms\": 45891.509}", "{\"n\": 9106, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3573.54, \"learn_time_ms\": 46038.014}", "{\"n\": 9107, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3573.54, \"learn_time_ms\": 46028.199}", "{\"n\": 9108, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3582.96, \"learn_time_ms\": 46086.691}", "{\"n\": 9109, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3571.37, \"learn_time_ms\": 46070.672}", "{\"n\": 9110, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3582.84, \"learn_time_ms\": 46051.394}", "{\"n\": 9111, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3578.88, \"learn_time_ms\": 46121.724}", "{\"n\": 9112, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3578.88, \"learn_time_ms\": 46119.222}", "{\"n\": 9113, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3560.32, \"learn_time_ms\": 46111.165}", "{\"n\": 9114, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3561.45, \"learn_time_ms\": 46061.644}", "{\"n\": 9115, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.66, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3570.67, \"learn_time_ms\": 45970.533}", "{\"n\": 9116, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3553.79, \"learn_time_ms\": 45981.315}", "{\"n\": 9117, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3553.79, \"learn_time_ms\": 45955.435}", "{\"n\": 9118, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3556.11, \"learn_time_ms\": 45941.375}", "{\"n\": 9119, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3551.95, \"learn_time_ms\": 45811.974}", "{\"n\": 9120, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3551.95, \"learn_time_ms\": 45853.74}", "{\"n\": 9121, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3539.73, \"learn_time_ms\": 45839.376}", "{\"n\": 9122, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3547.89, \"learn_time_ms\": 45813.043}", "{\"n\": 9123, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3547.89, \"learn_time_ms\": 45748.041}", "{\"n\": 9124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3547.89, \"learn_time_ms\": 45759.603}", "{\"n\": 9125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3547.49, \"learn_time_ms\": 45754.967}", "{\"n\": 9126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3554.98, \"learn_time_ms\": 45796.456}", "{\"n\": 9127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3559.23, \"learn_time_ms\": 45912.107}", "{\"n\": 9128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3559.23, \"learn_time_ms\": 45996.663}", "{\"n\": 9129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3556.52, \"learn_time_ms\": 46149.969}", "{\"n\": 9130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3552.27, \"learn_time_ms\": 46030.988}", "{\"n\": 9131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3539.53, \"learn_time_ms\": 46014.32}", "{\"n\": 9132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3539.53, \"learn_time_ms\": 46007.255}", "{\"n\": 9133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3551.45, \"learn_time_ms\": 46135.804}", "{\"n\": 9134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3549.14, \"learn_time_ms\": 46096.209}", "{\"n\": 9135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3551.57, \"learn_time_ms\": 46154.07}", "{\"n\": 9136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3560.2, \"learn_time_ms\": 46026.295}", "{\"n\": 9137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.39, \"learn_time_ms\": 45989.262}", "{\"n\": 9138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.39, \"learn_time_ms\": 45988.677}", "{\"n\": 9139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3572.31, \"learn_time_ms\": 45921.772}", "{\"n\": 9140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3586.76, \"learn_time_ms\": 45933.807}", "{\"n\": 9141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3586.76, \"learn_time_ms\": 45909.932}", "{\"n\": 9142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3593.28, \"learn_time_ms\": 46013.901}", "{\"n\": 9143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.73, \"learn_time_ms\": 45996.225}", "{\"n\": 9144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.44, \"learn_time_ms\": 46134.879}", "{\"n\": 9145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.46, \"learn_time_ms\": 46187.121}", "{\"n\": 9146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.45, \"learn_time_ms\": 46214.22}", "{\"n\": 9147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.88, \"learn_time_ms\": 46175.203}", "{\"n\": 9148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3608.77, \"learn_time_ms\": 46068.1}", "{\"n\": 9149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.87, \"learn_time_ms\": 46038.324}", "{\"n\": 9150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.34, \"learn_time_ms\": 46056.196}", "{\"n\": 9151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.34, \"learn_time_ms\": 46087.717}", "{\"n\": 9152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.43, \"learn_time_ms\": 46086.83}", "{\"n\": 9153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3625.94, \"learn_time_ms\": 46098.138}", "{\"n\": 9154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.62, \"learn_time_ms\": 45951.371}", "{\"n\": 9155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.82, \"learn_time_ms\": 45900.425}", "{\"n\": 9156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.82, \"learn_time_ms\": 45920.023}", "{\"n\": 9157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.82, \"learn_time_ms\": 45965.744}", "{\"n\": 9158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.68, \"learn_time_ms\": 46083.304}", "{\"n\": 9159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3633.0, \"learn_time_ms\": 45998.557}", "{\"n\": 9160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3624.37, \"learn_time_ms\": 45955.204}", "{\"n\": 9161, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3616.3, \"learn_time_ms\": 45940.693}", "{\"n\": 9162, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.57, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3616.3, \"learn_time_ms\": 45837.552}", "{\"n\": 9163, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3608.79, \"learn_time_ms\": 45827.802}", "{\"n\": 9164, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.97, \"learn_time_ms\": 45964.996}", "{\"n\": 9165, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3628.79, \"learn_time_ms\": 45918.068}", "{\"n\": 9166, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.55, \"learn_time_ms\": 45918.46}", "{\"n\": 9167, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.55, \"learn_time_ms\": 45848.587}", "{\"n\": 9168, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.55, \"learn_time_ms\": 45735.898}", "{\"n\": 9169, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.13, \"learn_time_ms\": 45869.553}", "{\"n\": 9170, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.13, \"learn_time_ms\": 45954.306}", "{\"n\": 9171, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.3, \"learn_time_ms\": 46015.598}", "{\"n\": 9172, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.16, \"learn_time_ms\": 46075.223}", "{\"n\": 9173, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.5, \"learn_time_ms\": 46046.772}", "{\"n\": 9174, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.5, \"learn_time_ms\": 45976.447}", "{\"n\": 9175, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.15, \"learn_time_ms\": 46013.809}", "{\"n\": 9176, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.45, \"learn_time_ms\": 45987.854}", "{\"n\": 9177, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3594.32, \"learn_time_ms\": 46027.73}", "{\"n\": 9178, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3594.32, \"learn_time_ms\": 46007.311}", "{\"n\": 9179, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3616.29, \"learn_time_ms\": 46010.099}", "{\"n\": 9180, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3616.29, \"learn_time_ms\": 46048.995}", "{\"n\": 9181, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3616.29, \"learn_time_ms\": 46003.967}", "{\"n\": 9182, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3597.35, \"learn_time_ms\": 46061.125}", "{\"n\": 9183, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3596.26, \"learn_time_ms\": 46039.529}", "{\"n\": 9184, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3596.26, \"learn_time_ms\": 46045.357}", "{\"n\": 9185, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.52, \"learn_time_ms\": 46039.774}", "{\"n\": 9186, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3599.04, \"learn_time_ms\": 46123.645}", "{\"n\": 9187, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.49, \"learn_time_ms\": 46092.263}", "{\"n\": 9188, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3616.16, \"learn_time_ms\": 46182.397}", "{\"n\": 9189, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.49, \"learn_time_ms\": 46232.377}", "{\"n\": 9190, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3607.56, \"learn_time_ms\": 46160.35}", "{\"n\": 9191, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3600.89, \"learn_time_ms\": 46190.569}", "{\"n\": 9192, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.05, \"learn_time_ms\": 46032.855}", "{\"n\": 9193, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.05, \"learn_time_ms\": 46089.52}", "{\"n\": 9194, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3642.29, \"learn_time_ms\": 46066.384}", "{\"n\": 9195, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3642.29, \"learn_time_ms\": 46101.17}", "{\"n\": 9196, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3644.1, \"learn_time_ms\": 46075.324}", "{\"n\": 9197, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.41, \"learn_time_ms\": 46101.836}", "{\"n\": 9198, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3630.55, \"learn_time_ms\": 46007.506}", "{\"n\": 9199, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.09, \"learn_time_ms\": 45967.704}", "{\"n\": 9200, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.89, \"learn_time_ms\": 45893.087}", "{\"n\": 9201, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.87, \"learn_time_ms\": 45853.83}", "{\"n\": 9202, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.1, \"learn_time_ms\": 46014.273}", "{\"n\": 9203, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.1, \"learn_time_ms\": 45989.394}", "{\"n\": 9204, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.68, \"learn_time_ms\": 46060.957}", "{\"n\": 9205, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3593.96, \"learn_time_ms\": 46078.418}", "{\"n\": 9206, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.88, \"learn_time_ms\": 46026.06}", "{\"n\": 9207, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3607.93, \"learn_time_ms\": 46104.258}", "{\"n\": 9208, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.82, \"learn_time_ms\": 46179.238}", "{\"n\": 9209, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.82, \"learn_time_ms\": 46167.147}", "{\"n\": 9210, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3599.95, \"learn_time_ms\": 46275.09}", "{\"n\": 9211, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3594.02, \"learn_time_ms\": 46288.089}", "{\"n\": 9212, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.69, \"learn_time_ms\": 46246.973}", "{\"n\": 9213, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3599.55, \"learn_time_ms\": 46274.253}", "{\"n\": 9214, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.45, \"learn_time_ms\": 46258.276}", "{\"n\": 9215, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3583.74, \"learn_time_ms\": 46212.128}", "{\"n\": 9216, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3583.74, \"learn_time_ms\": 46243.849}", "{\"n\": 9217, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3583.74, \"learn_time_ms\": 46070.144}", "{\"n\": 9218, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3582.49, \"learn_time_ms\": 45997.676}", "{\"n\": 9219, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3587.65, \"learn_time_ms\": 45944.941}", "{\"n\": 9220, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3602.68, \"learn_time_ms\": 45936.727}", "{\"n\": 9221, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3604.22, \"learn_time_ms\": 45931.708}", "{\"n\": 9222, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3608.73, \"learn_time_ms\": 45885.078}", "{\"n\": 9223, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3603.94, \"learn_time_ms\": 45835.256}", "{\"n\": 9224, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3603.94, \"learn_time_ms\": 45813.835}", "{\"n\": 9225, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.7, \"learn_time_ms\": 45834.353}", "{\"n\": 9226, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3600.89, \"learn_time_ms\": 45752.688}", "{\"n\": 9227, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3597.83, \"learn_time_ms\": 45835.066}", "{\"n\": 9228, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3597.83, \"learn_time_ms\": 45853.295}", "{\"n\": 9229, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3608.89, \"learn_time_ms\": 45789.5}", "{\"n\": 9230, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3608.89, \"learn_time_ms\": 45785.656}", "{\"n\": 9231, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.24, \"learn_time_ms\": 45795.03}", "{\"n\": 9232, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.93, \"learn_time_ms\": 45759.262}", "{\"n\": 9233, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3615.73, \"learn_time_ms\": 45822.143}", "{\"n\": 9234, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3615.73, \"learn_time_ms\": 45798.656}", "{\"n\": 9235, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.55, \"learn_time_ms\": 45892.71}", "{\"n\": 9236, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3623.55, \"learn_time_ms\": 45970.852}", "{\"n\": 9237, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3630.52, \"learn_time_ms\": 45968.902}", "{\"n\": 9238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3656.35, \"learn_time_ms\": 46063.599}", "{\"n\": 9239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3654.71, \"learn_time_ms\": 46172.609}", "{\"n\": 9240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3660.69, \"learn_time_ms\": 46157.919}", "{\"n\": 9241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.7, \"learn_time_ms\": 46092.904}", "{\"n\": 9242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3675.3, \"learn_time_ms\": 46147.938}", "{\"n\": 9243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3663.69, \"learn_time_ms\": 46130.695}", "{\"n\": 9244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3670.61, \"learn_time_ms\": 46082.194}", "{\"n\": 9245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3670.61, \"learn_time_ms\": 46004.146}", "{\"n\": 9246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3679.78, \"learn_time_ms\": 45914.148}", "{\"n\": 9247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3689.96, \"learn_time_ms\": 45940.447}", "{\"n\": 9248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.25, \"learn_time_ms\": 45908.484}", "{\"n\": 9249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3692.27, \"learn_time_ms\": 45848.294}", "{\"n\": 9250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3697.77, \"learn_time_ms\": 45835.183}", "{\"n\": 9251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.61, \"learn_time_ms\": 45876.532}", "{\"n\": 9252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.61, \"learn_time_ms\": 45742.672}", "{\"n\": 9253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.61, \"learn_time_ms\": 45747.554}", "{\"n\": 9254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3716.18, \"learn_time_ms\": 45857.93}", "{\"n\": 9255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3717.48, \"learn_time_ms\": 45795.326}", "{\"n\": 9256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3705.86, \"learn_time_ms\": 45869.342}", "{\"n\": 9257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3705.39, \"learn_time_ms\": 45934.079}", "{\"n\": 9258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3705.39, \"learn_time_ms\": 45929.23}", "{\"n\": 9259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3714.4, \"learn_time_ms\": 46056.933}", "{\"n\": 9260, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.01, \"learn_time_ms\": 46057.256}", "{\"n\": 9261, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3720.01, \"learn_time_ms\": 46117.759}", "{\"n\": 9262, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3725.62, \"learn_time_ms\": 46176.179}", "{\"n\": 9263, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3712.14, \"learn_time_ms\": 46144.54}", "{\"n\": 9264, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3707.31, \"learn_time_ms\": 46124.837}", "{\"n\": 9265, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3707.31, \"learn_time_ms\": 46134.277}", "{\"n\": 9266, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.78, \"learn_time_ms\": 46181.174}", "{\"n\": 9267, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3688.21, \"learn_time_ms\": 46039.08}", "{\"n\": 9268, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.71, \"learn_time_ms\": 46106.495}", "{\"n\": 9269, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3675.17, \"learn_time_ms\": 46032.002}", "{\"n\": 9270, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3679.87, \"learn_time_ms\": 45956.702}", "{\"n\": 9271, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.93, \"learn_time_ms\": 45831.639}", "{\"n\": 9272, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3691.3, \"learn_time_ms\": 45926.576}", "{\"n\": 9273, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.73, \"learn_time_ms\": 45947.095}", "{\"n\": 9274, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.73, \"learn_time_ms\": 45961.124}", "{\"n\": 9275, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3686.09, \"learn_time_ms\": 45967.38}", "{\"n\": 9276, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3689.51, \"learn_time_ms\": 45879.504}", "{\"n\": 9277, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3693.74, \"learn_time_ms\": 45875.951}", "{\"n\": 9278, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3694.73, \"learn_time_ms\": 45733.485}", "{\"n\": 9279, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3694.73, \"learn_time_ms\": 45688.88}", "{\"n\": 9280, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3704.54, \"learn_time_ms\": 45803.297}", "{\"n\": 9281, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3728.52, \"learn_time_ms\": 45903.362}", "{\"n\": 9282, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3732.32, \"learn_time_ms\": 45780.194}", "{\"n\": 9283, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3716.73, \"learn_time_ms\": 45777.324}", "{\"n\": 9284, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.28, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3716.73, \"learn_time_ms\": 45733.61}", "{\"n\": 9285, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3739.41, \"learn_time_ms\": 45850.472}", "{\"n\": 9286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3730.3, \"learn_time_ms\": 45783.275}", "{\"n\": 9287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3724.25, \"learn_time_ms\": 45877.998}", "{\"n\": 9288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3715.92, \"learn_time_ms\": 45912.008}", "{\"n\": 9289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3715.92, \"learn_time_ms\": 45817.106}", "{\"n\": 9290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3716.77, \"learn_time_ms\": 45724.341}", "{\"n\": 9291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.23, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3717.79, \"learn_time_ms\": 45703.186}", "{\"n\": 9292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3713.65, \"learn_time_ms\": 45799.841}", "{\"n\": 9293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3713.65, \"learn_time_ms\": 45857.957}", "{\"n\": 9294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3698.49, \"learn_time_ms\": 45943.281}", "{\"n\": 9295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3700.62, \"learn_time_ms\": 45768.988}", "{\"n\": 9296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3700.62, \"learn_time_ms\": 45917.943}", "{\"n\": 9297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3701.58, \"learn_time_ms\": 45940.312}", "{\"n\": 9298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3681.21, \"learn_time_ms\": 45907.603}", "{\"n\": 9299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3689.26, \"learn_time_ms\": 46119.057}", "{\"n\": 9300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3670.32, \"learn_time_ms\": 46191.944}", "{\"n\": 9301, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3677.49, \"learn_time_ms\": 46231.581}", "{\"n\": 9302, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3678.96, \"learn_time_ms\": 46192.315}", "{\"n\": 9303, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3685.7, \"learn_time_ms\": 46126.362}", "{\"n\": 9304, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3679.67, \"learn_time_ms\": 46072.458}", "{\"n\": 9305, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3679.67, \"learn_time_ms\": 45997.207}", "{\"n\": 9306, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3692.53, \"learn_time_ms\": 46011.094}", "{\"n\": 9307, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3692.7, \"learn_time_ms\": 46062.733}", "{\"n\": 9308, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3699.31, \"learn_time_ms\": 46141.657}", "{\"n\": 9309, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.07, \"learn_time_ms\": 45927.522}", "{\"n\": 9310, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.07, \"learn_time_ms\": 45950.715}", "{\"n\": 9311, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3687.07, \"learn_time_ms\": 45861.244}", "{\"n\": 9312, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3675.15, \"learn_time_ms\": 45798.384}", "{\"n\": 9313, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.15, \"learn_time_ms\": 45869.326}", "{\"n\": 9314, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3665.01, \"learn_time_ms\": 45810.987}", "{\"n\": 9315, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3666.99, \"learn_time_ms\": 45923.857}", "{\"n\": 9316, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3666.99, \"learn_time_ms\": 45900.317}", "{\"n\": 9317, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3659.57, \"learn_time_ms\": 45679.929}", "{\"n\": 9318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3668.37, \"learn_time_ms\": 45634.976}", "{\"n\": 9319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3684.41, \"learn_time_ms\": 45752.096}", "{\"n\": 9320, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3681.25, \"learn_time_ms\": 45677.926}", "{\"n\": 9321, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3681.25, \"learn_time_ms\": 45682.83}", "{\"n\": 9322, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3678.19, \"learn_time_ms\": 45755.916}", "{\"n\": 9323, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3658.83, \"learn_time_ms\": 45751.859}", "{\"n\": 9324, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3656.36, \"learn_time_ms\": 45843.844}", "{\"n\": 9325, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.13, \"learn_time_ms\": 45895.918}", "{\"n\": 9326, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3666.0, \"learn_time_ms\": 45876.834}", "{\"n\": 9327, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3666.6, \"learn_time_ms\": 45960.407}", "{\"n\": 9328, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3658.94, \"learn_time_ms\": 46039.93}", "{\"n\": 9329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.29, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3658.94, \"learn_time_ms\": 46023.992}", "{\"n\": 9330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3640.62, \"learn_time_ms\": 46076.111}", "{\"n\": 9331, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3630.5, \"learn_time_ms\": 46075.255}", "{\"n\": 9332, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3632.97, \"learn_time_ms\": 46053.718}", "{\"n\": 9333, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3632.97, \"learn_time_ms\": 45951.569}", "{\"n\": 9334, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3632.97, \"learn_time_ms\": 46024.925}", "{\"n\": 9335, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.95, \"learn_time_ms\": 45950.145}", "{\"n\": 9336, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.95, \"learn_time_ms\": 45911.579}", "{\"n\": 9337, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3643.4, \"learn_time_ms\": 45857.565}", "{\"n\": 9338, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.21, \"learn_time_ms\": 45778.266}", "{\"n\": 9339, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.21, \"learn_time_ms\": 45732.502}", "{\"n\": 9340, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3632.92, \"learn_time_ms\": 45718.432}", "{\"n\": 9341, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3636.7, \"learn_time_ms\": 45824.411}", "{\"n\": 9342, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3649.18, \"learn_time_ms\": 45859.125}", "{\"n\": 9343, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3645.78, \"learn_time_ms\": 45872.332}", "{\"n\": 9344, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3654.15, \"learn_time_ms\": 45812.36}", "{\"n\": 9345, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.14, \"learn_time_ms\": 45887.691}", "{\"n\": 9346, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.14, \"learn_time_ms\": 45957.391}", "{\"n\": 9347, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.14, \"learn_time_ms\": 45988.177}", "{\"n\": 9348, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3625.61, \"learn_time_ms\": 45916.644}", "{\"n\": 9349, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3626.72, \"learn_time_ms\": 46034.19}", "{\"n\": 9350, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3612.82, \"learn_time_ms\": 46054.071}", "{\"n\": 9351, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.76, \"learn_time_ms\": 45868.426}", "{\"n\": 9352, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.76, \"learn_time_ms\": 45794.549}", "{\"n\": 9353, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3616.83, \"learn_time_ms\": 45873.525}", "{\"n\": 9354, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3613.02, \"learn_time_ms\": 45688.034}", "{\"n\": 9355, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3603.06, \"learn_time_ms\": 45732.876}", "{\"n\": 9356, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3603.06, \"learn_time_ms\": 45735.51}", "{\"n\": 9357, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3599.62, \"learn_time_ms\": 45830.361}", "{\"n\": 9358, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.09, \"learn_time_ms\": 45928.07}", "{\"n\": 9359, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.81, \"learn_time_ms\": 45944.013}", "{\"n\": 9360, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.81, \"learn_time_ms\": 45858.3}", "{\"n\": 9361, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3604.16, \"learn_time_ms\": 45945.734}", "{\"n\": 9362, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.1, \"learn_time_ms\": 45917.093}", "{\"n\": 9363, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3598.1, \"learn_time_ms\": 45829.762}", "{\"n\": 9364, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3600.83, \"learn_time_ms\": 46021.925}", "{\"n\": 9365, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3600.83, \"learn_time_ms\": 45985.295}", "{\"n\": 9366, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3608.0, \"learn_time_ms\": 45856.481}", "{\"n\": 9367, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.11, \"learn_time_ms\": 45836.591}", "{\"n\": 9368, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.21, \"learn_time_ms\": 45887.414}", "{\"n\": 9369, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3635.16, \"learn_time_ms\": 45849.856}", "{\"n\": 9370, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3624.12, \"learn_time_ms\": 45936.338}", "{\"n\": 9371, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.24, \"learn_time_ms\": 45951.633}", "{\"n\": 9372, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.46, \"learn_time_ms\": 46028.498}", "{\"n\": 9373, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.46, \"learn_time_ms\": 46020.189}", "{\"n\": 9374, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3629.32, \"learn_time_ms\": 45920.767}", "{\"n\": 9375, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.61, \"learn_time_ms\": 45857.602}", "{\"n\": 9376, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.61, \"learn_time_ms\": 45928.172}", "{\"n\": 9377, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.22, \"learn_time_ms\": 45891.422}", "{\"n\": 9378, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3610.81, \"learn_time_ms\": 45764.124}", "{\"n\": 9379, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3596.85, \"learn_time_ms\": 45756.658}", "{\"n\": 9380, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3615.97, \"learn_time_ms\": 45751.713}", "{\"n\": 9381, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.66, \"learn_time_ms\": 45736.351}", "{\"n\": 9382, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3608.36, \"learn_time_ms\": 45725.553}", "{\"n\": 9383, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.72, \"learn_time_ms\": 45691.494}", "{\"n\": 9384, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.86, \"learn_time_ms\": 45651.347}", "{\"n\": 9385, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.86, \"learn_time_ms\": 45702.105}", "{\"n\": 9386, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3619.56, \"learn_time_ms\": 45698.66}", "{\"n\": 9387, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.04, \"learn_time_ms\": 45765.157}", "{\"n\": 9388, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3612.13, \"learn_time_ms\": 45751.909}", "{\"n\": 9389, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.54, \"learn_time_ms\": 45732.961}", "{\"n\": 9390, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3627.54, \"learn_time_ms\": 45804.427}", "{\"n\": 9391, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3625.22, \"learn_time_ms\": 45858.508}", "{\"n\": 9392, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3625.22, \"learn_time_ms\": 45812.894}", "{\"n\": 9393, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.72, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.91, \"learn_time_ms\": 45870.052}", "{\"n\": 9394, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3609.34, \"learn_time_ms\": 45902.087}", "{\"n\": 9395, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3605.23, \"learn_time_ms\": 45865.21}", "{\"n\": 9396, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3592.79, \"learn_time_ms\": 45922.658}", "{\"n\": 9397, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3592.79, \"learn_time_ms\": 45832.932}", "{\"n\": 9398, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3589.24, \"learn_time_ms\": 45952.225}", "{\"n\": 9399, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3613.38, \"learn_time_ms\": 45985.328}", "{\"n\": 9400, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3604.49, \"learn_time_ms\": 45890.664}", "{\"n\": 9401, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3604.49, \"learn_time_ms\": 45883.992}", "{\"n\": 9402, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3594.88, \"learn_time_ms\": 45944.092}", "{\"n\": 9403, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3594.88, \"learn_time_ms\": 45926.093}", "{\"n\": 9404, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3609.19, \"learn_time_ms\": 45948.481}", "{\"n\": 9405, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3603.76, \"learn_time_ms\": 45974.61}", "{\"n\": 9406, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.1, \"learn_time_ms\": 45923.334}", "{\"n\": 9407, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3621.25, \"learn_time_ms\": 45927.885}", "{\"n\": 9408, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.9, \"learn_time_ms\": 45894.354}", "{\"n\": 9409, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.9, \"learn_time_ms\": 45908.451}", "{\"n\": 9410, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3617.69, \"learn_time_ms\": 45940.884}", "{\"n\": 9411, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3617.69, \"learn_time_ms\": 45916.206}", "{\"n\": 9412, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3606.72, \"learn_time_ms\": 45885.693}", "{\"n\": 9413, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3606.69, \"learn_time_ms\": 45932.752}", "{\"n\": 9414, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.5, \"learn_time_ms\": 45964.382}", "{\"n\": 9415, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3640.5, \"learn_time_ms\": 45949.033}", "{\"n\": 9416, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.57, \"learn_time_ms\": 45974.575}", "{\"n\": 9417, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3629.57, \"learn_time_ms\": 45952.091}", "{\"n\": 9418, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.25, \"learn_time_ms\": 46026.85}", "{\"n\": 9419, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3644.14, \"learn_time_ms\": 46052.885}", "{\"n\": 9420, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.84, \"learn_time_ms\": 46102.187}", "{\"n\": 9421, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.67, \"learn_time_ms\": 46178.342}", "{\"n\": 9422, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3659.67, \"learn_time_ms\": 46194.107}", "{\"n\": 9423, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.65, \"learn_time_ms\": 46182.636}", "{\"n\": 9424, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3654.77, \"learn_time_ms\": 46133.284}", "{\"n\": 9425, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.44, \"learn_time_ms\": 46069.861}", "{\"n\": 9426, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3648.44, \"learn_time_ms\": 46002.461}", "{\"n\": 9427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.14, \"learn_time_ms\": 46046.132}", "{\"n\": 9428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3676.5, \"learn_time_ms\": 45895.756}", "{\"n\": 9429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3678.76, \"learn_time_ms\": 45923.491}", "{\"n\": 9430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.57, \"learn_time_ms\": 45867.41}", "{\"n\": 9431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.57, \"learn_time_ms\": 45803.24}", "{\"n\": 9432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.04, \"learn_time_ms\": 45835.848}", "{\"n\": 9433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.7, \"learn_time_ms\": 45792.528}", "{\"n\": 9434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.79, \"learn_time_ms\": 45881.313}", "{\"n\": 9435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.79, \"learn_time_ms\": 45973.263}", "{\"n\": 9436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3691.82, \"learn_time_ms\": 45973.468}", "{\"n\": 9437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.23, \"learn_time_ms\": 45995.449}", "{\"n\": 9438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3705.23, \"learn_time_ms\": 46052.152}", "{\"n\": 9439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3714.42, \"learn_time_ms\": 46094.408}", "{\"n\": 9440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3716.07, \"learn_time_ms\": 46115.483}", "{\"n\": 9441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3721.35, \"learn_time_ms\": 46091.624}", "{\"n\": 9442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3721.35, \"learn_time_ms\": 46085.948}", "{\"n\": 9443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3718.07, \"learn_time_ms\": 46141.245}", "{\"n\": 9444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3703.44, \"learn_time_ms\": 46050.1}", "{\"n\": 9445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.54, \"learn_time_ms\": 45978.935}", "{\"n\": 9446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.58, \"learn_time_ms\": 46048.648}", "{\"n\": 9447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3693.58, \"learn_time_ms\": 45985.002}", "{\"n\": 9448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.74, \"learn_time_ms\": 45956.547}", "{\"n\": 9449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.74, \"learn_time_ms\": 45863.141}", "{\"n\": 9450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3711.37, \"learn_time_ms\": 45813.883}", "{\"n\": 9451, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3711.37, \"learn_time_ms\": 45852.801}", "{\"n\": 9452, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.9, \"learn_time_ms\": 45881.665}", "{\"n\": 9453, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.95, \"learn_time_ms\": 45828.049}", "{\"n\": 9454, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.71, \"learn_time_ms\": 45835.373}", "{\"n\": 9455, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.57, \"learn_time_ms\": 45891.971}", "{\"n\": 9456, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3722.33, \"learn_time_ms\": 45853.49}", "{\"n\": 9457, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3718.14, \"learn_time_ms\": 45940.258}", "{\"n\": 9458, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3727.47, \"learn_time_ms\": 45909.604}", "{\"n\": 9459, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3734.19, \"learn_time_ms\": 45800.871}", "{\"n\": 9460, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3735.06, \"learn_time_ms\": 45760.578}", "{\"n\": 9461, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3735.06, \"learn_time_ms\": 45771.701}", "{\"n\": 9462, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3724.95, \"learn_time_ms\": 45726.639}", "{\"n\": 9463, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3710.63, \"learn_time_ms\": 45754.444}", "{\"n\": 9464, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3717.48, \"learn_time_ms\": 45846.797}", "{\"n\": 9465, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3708.92, \"learn_time_ms\": 45862.795}", "{\"n\": 9466, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3706.45, \"learn_time_ms\": 45986.045}", "{\"n\": 9467, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3698.22, \"learn_time_ms\": 45876.69}", "{\"n\": 9468, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.31, \"learn_time_ms\": 46019.92}", "{\"n\": 9469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.97, \"learn_time_ms\": 45990.379}", "{\"n\": 9470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3694.97, \"learn_time_ms\": 46062.271}", "{\"n\": 9471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.19, \"learn_time_ms\": 46088.425}", "{\"n\": 9472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3695.43, \"learn_time_ms\": 46122.433}", "{\"n\": 9473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.19, \"learn_time_ms\": 46108.672}", "{\"n\": 9474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.09, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.04, \"learn_time_ms\": 46057.285}", "{\"n\": 9475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.75, \"learn_time_ms\": 45988.098}", "{\"n\": 9476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.75, \"learn_time_ms\": 45931.851}", "{\"n\": 9477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3670.56, \"learn_time_ms\": 46101.055}", "{\"n\": 9478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.59, \"learn_time_ms\": 45970.013}", "{\"n\": 9479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.59, \"learn_time_ms\": 46047.833}", "{\"n\": 9480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.19, \"learn_time_ms\": 46038.978}", "{\"n\": 9481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.2, \"learn_time_ms\": 45958.853}", "{\"n\": 9482, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3673.2, \"learn_time_ms\": 45932.355}", "{\"n\": 9483, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3677.61, \"learn_time_ms\": 46019.502}", "{\"n\": 9484, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.87, \"learn_time_ms\": 46120.926}", "{\"n\": 9485, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3667.73, \"learn_time_ms\": 46161.997}", "{\"n\": 9486, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.25, \"learn_time_ms\": 46127.618}", "{\"n\": 9487, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.25, \"learn_time_ms\": 46032.517}", "{\"n\": 9488, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.25, \"learn_time_ms\": 46059.181}", "{\"n\": 9489, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3679.25, \"learn_time_ms\": 46139.41}", "{\"n\": 9490, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3670.14, \"learn_time_ms\": 46205.873}", "{\"n\": 9491, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3664.12, \"learn_time_ms\": 46246.743}", "{\"n\": 9492, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3667.24, \"learn_time_ms\": 46272.722}", "{\"n\": 9493, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3656.23, \"learn_time_ms\": 46212.722}", "{\"n\": 9494, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3656.23, \"learn_time_ms\": 46094.052}", "{\"n\": 9495, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3630.2, \"learn_time_ms\": 46068.523}", "{\"n\": 9496, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3637.34, \"learn_time_ms\": 46043.102}", "{\"n\": 9497, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3642.45, \"learn_time_ms\": 46077.996}", "{\"n\": 9498, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3653.02, \"learn_time_ms\": 46163.468}", "{\"n\": 9499, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3653.02, \"learn_time_ms\": 46073.344}", "{\"n\": 9500, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3653.02, \"learn_time_ms\": 45967.517}", "{\"n\": 9501, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3647.44, \"learn_time_ms\": 45933.309}", "{\"n\": 9502, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3638.09, \"learn_time_ms\": 45920.645}", "{\"n\": 9503, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.89, \"learn_time_ms\": 45890.603}", "{\"n\": 9504, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.59, \"learn_time_ms\": 45932.549}", "{\"n\": 9505, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.59, \"learn_time_ms\": 45966.741}", "{\"n\": 9506, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.59, \"learn_time_ms\": 46084.431}", "{\"n\": 9507, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.76, \"learn_time_ms\": 46082.046}", "{\"n\": 9508, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.02, \"learn_time_ms\": 46070.479}", "{\"n\": 9509, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3605.8, \"learn_time_ms\": 46147.26}", "{\"n\": 9510, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.17, \"learn_time_ms\": 46051.064}", "{\"n\": 9511, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.17, \"learn_time_ms\": 46056.376}", "{\"n\": 9512, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3578.48, \"learn_time_ms\": 46097.795}", "{\"n\": 9513, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3578.48, \"learn_time_ms\": 46122.521}", "{\"n\": 9514, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3563.15, \"learn_time_ms\": 46126.899}", "{\"n\": 9515, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3552.22, \"learn_time_ms\": 46224.515}", "{\"n\": 9516, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3557.31, \"learn_time_ms\": 46106.03}", "{\"n\": 9517, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3567.3, \"learn_time_ms\": 46131.715}", "{\"n\": 9518, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3546.38, \"learn_time_ms\": 46097.859}", "{\"n\": 9519, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3546.38, \"learn_time_ms\": 45969.686}", "{\"n\": 9520, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3543.69, \"learn_time_ms\": 46077.564}", "{\"n\": 9521, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3545.6, \"learn_time_ms\": 46193.733}", "{\"n\": 9522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3551.41, \"learn_time_ms\": 46135.999}", "{\"n\": 9523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3540.1, \"learn_time_ms\": 46093.0}", "{\"n\": 9524, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3536.88, \"learn_time_ms\": 46068.945}", "{\"n\": 9525, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3534.87, \"learn_time_ms\": 46034.351}", "{\"n\": 9526, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3534.87, \"learn_time_ms\": 46007.25}", "{\"n\": 9527, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3546.21, \"learn_time_ms\": 45984.947}", "{\"n\": 9528, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3554.28, \"learn_time_ms\": 45976.743}", "{\"n\": 9529, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3554.28, \"learn_time_ms\": 46145.772}", "{\"n\": 9530, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3548.47, \"learn_time_ms\": 46187.0}", "{\"n\": 9531, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3534.18, \"learn_time_ms\": 46084.47}", "{\"n\": 9532, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3535.81, \"learn_time_ms\": 46076.017}", "{\"n\": 9533, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3535.81, \"learn_time_ms\": 46065.34}", "{\"n\": 9534, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3511.09, \"learn_time_ms\": 46055.354}", "{\"n\": 9535, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3512.5, \"learn_time_ms\": 45943.492}", "{\"n\": 9536, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3529.53, \"learn_time_ms\": 45921.475}", "{\"n\": 9537, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3532.91, \"learn_time_ms\": 45931.352}", "{\"n\": 9538, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3522.78, \"learn_time_ms\": 45913.73}", "{\"n\": 9539, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.42, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3537.28, \"learn_time_ms\": 45804.98}", "{\"n\": 9540, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.45, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3539.28, \"learn_time_ms\": 45786.296}", "{\"n\": 9541, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3554.56, \"learn_time_ms\": 45833.891}", "{\"n\": 9542, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3554.56, \"learn_time_ms\": 45892.353}", "{\"n\": 9543, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3559.88, \"learn_time_ms\": 45848.896}", "{\"n\": 9544, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3537.69, \"learn_time_ms\": 45873.207}", "{\"n\": 9545, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3537.69, \"learn_time_ms\": 45989.075}", "{\"n\": 9546, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3542.6, \"learn_time_ms\": 46028.527}", "{\"n\": 9547, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3540.58, \"learn_time_ms\": 45940.69}", "{\"n\": 9548, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3540.58, \"learn_time_ms\": 46022.202}", "{\"n\": 9549, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3538.25, \"learn_time_ms\": 45975.76}", "{\"n\": 9550, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3536.95, \"learn_time_ms\": 45993.324}", "{\"n\": 9551, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3545.68, \"learn_time_ms\": 45937.562}", "{\"n\": 9552, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3538.4, \"learn_time_ms\": 45959.291}", "{\"n\": 9553, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3524.23, \"learn_time_ms\": 46018.189}", "{\"n\": 9554, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3524.23, \"learn_time_ms\": 46010.005}", "{\"n\": 9555, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3524.23, \"learn_time_ms\": 45996.769}", "{\"n\": 9556, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3525.81, \"learn_time_ms\": 46008.903}", "{\"n\": 9557, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3525.8, \"learn_time_ms\": 46067.128}", "{\"n\": 9558, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3524.54, \"learn_time_ms\": 45999.56}", "{\"n\": 9559, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3533.49, \"learn_time_ms\": 45917.85}", "{\"n\": 9560, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3532.29, \"learn_time_ms\": 45938.776}", "{\"n\": 9561, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3534.49, \"learn_time_ms\": 45883.638}", "{\"n\": 9562, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3534.49, \"learn_time_ms\": 45825.443}", "{\"n\": 9563, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3534.49, \"learn_time_ms\": 45838.833}", "{\"n\": 9564, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3540.9, \"learn_time_ms\": 45814.559}", "{\"n\": 9565, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3556.81, \"learn_time_ms\": 45827.971}", "{\"n\": 9566, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3548.57, \"learn_time_ms\": 45831.787}", "{\"n\": 9567, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3543.35, \"learn_time_ms\": 45732.686}", "{\"n\": 9568, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3544.75, \"learn_time_ms\": 45833.483}", "{\"n\": 9569, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3554.47, \"learn_time_ms\": 46031.259}", "{\"n\": 9570, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.15, \"learn_time_ms\": 45947.81}", "{\"n\": 9571, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.15, \"learn_time_ms\": 46027.048}", "{\"n\": 9572, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3561.15, \"learn_time_ms\": 46007.074}", "{\"n\": 9573, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3555.48, \"learn_time_ms\": 45905.79}", "{\"n\": 9574, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3568.08, \"learn_time_ms\": 45889.252}", "{\"n\": 9575, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3544.8, \"learn_time_ms\": 45805.08}", "{\"n\": 9576, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3540.32, \"learn_time_ms\": 45730.459}", "{\"n\": 9577, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3540.32, \"learn_time_ms\": 45783.503}", "{\"n\": 9578, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3529.44, \"learn_time_ms\": 45717.989}", "{\"n\": 9579, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3522.68, \"learn_time_ms\": 45672.02}", "{\"n\": 9580, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3515.01, \"learn_time_ms\": 45690.891}", "{\"n\": 9581, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3515.01, \"learn_time_ms\": 45699.369}", "{\"n\": 9582, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3518.45, \"learn_time_ms\": 45732.523}", "{\"n\": 9583, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3498.33, \"learn_time_ms\": 45883.038}", "{\"n\": 9584, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3502.14, \"learn_time_ms\": 45882.147}", "{\"n\": 9585, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3502.14, \"learn_time_ms\": 45860.781}", "{\"n\": 9586, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3499.52, \"learn_time_ms\": 45934.696}", "{\"n\": 9587, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3499.52, \"learn_time_ms\": 46029.555}", "{\"n\": 9588, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3499.52, \"learn_time_ms\": 46035.02}", "{\"n\": 9589, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3516.09, \"learn_time_ms\": 46134.894}", "{\"n\": 9590, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3516.94, \"learn_time_ms\": 46131.284}", "{\"n\": 9591, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3516.94, \"learn_time_ms\": 46113.088}", "{\"n\": 9592, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3524.54, \"learn_time_ms\": 46047.054}", "{\"n\": 9593, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.67, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3525.24, \"learn_time_ms\": 45984.486}", "{\"n\": 9594, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3517.83, \"learn_time_ms\": 45957.046}", "{\"n\": 9595, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3511.21, \"learn_time_ms\": 45929.864}", "{\"n\": 9596, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3520.89, \"learn_time_ms\": 45916.46}", "{\"n\": 9597, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3524.13, \"learn_time_ms\": 45932.09}", "{\"n\": 9598, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3510.54, \"learn_time_ms\": 45923.168}", "{\"n\": 9599, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3510.54, \"learn_time_ms\": 45698.381}", "{\"n\": 9600, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3511.12, \"learn_time_ms\": 45821.781}", "{\"n\": 9601, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3493.85, \"learn_time_ms\": 45838.315}", "{\"n\": 9602, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3504.07, \"learn_time_ms\": 45918.204}", "{\"n\": 9603, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3510.36, \"learn_time_ms\": 45938.137}", "{\"n\": 9604, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3493.99, \"learn_time_ms\": 45937.24}", "{\"n\": 9605, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3493.99, \"learn_time_ms\": 45961.362}", "{\"n\": 9606, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3500.59, \"learn_time_ms\": 45967.399}", "{\"n\": 9607, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3509.48, \"learn_time_ms\": 45892.602}", "{\"n\": 9608, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3514.14, \"learn_time_ms\": 45911.053}", "{\"n\": 9609, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3505.52, \"learn_time_ms\": 46060.215}", "{\"n\": 9610, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3511.89, \"learn_time_ms\": 46028.877}", "{\"n\": 9611, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3511.89, \"learn_time_ms\": 45948.949}", "{\"n\": 9612, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.18, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3508.01, \"learn_time_ms\": 45978.115}", "{\"n\": 9613, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3488.07, \"learn_time_ms\": 45962.91}", "{\"n\": 9614, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3494.23, \"learn_time_ms\": 45983.906}", "{\"n\": 9615, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3492.73, \"learn_time_ms\": 46084.849}", "{\"n\": 9616, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3490.17, \"learn_time_ms\": 46092.701}", "{\"n\": 9617, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3496.7, \"learn_time_ms\": 46122.91}", "{\"n\": 9618, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3509.82, \"learn_time_ms\": 46029.353}", "{\"n\": 9619, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3520.3, \"learn_time_ms\": 45934.703}", "{\"n\": 9620, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3520.3, \"learn_time_ms\": 45885.62}", "{\"n\": 9621, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3527.58, \"learn_time_ms\": 45914.25}", "{\"n\": 9622, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.19, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3527.58, \"learn_time_ms\": 45924.322}", "{\"n\": 9623, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3540.63, \"learn_time_ms\": 46019.525}", "{\"n\": 9624, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3540.63, \"learn_time_ms\": 46000.133}", "{\"n\": 9625, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.23, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3536.51, \"learn_time_ms\": 45958.009}", "{\"n\": 9626, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3543.09, \"learn_time_ms\": 45967.302}", "{\"n\": 9627, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3534.44, \"learn_time_ms\": 45985.473}", "{\"n\": 9628, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3538.47, \"learn_time_ms\": 46053.515}", "{\"n\": 9629, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3523.42, \"learn_time_ms\": 46133.7}", "{\"n\": 9630, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.25, \"learn_time_ms\": 46051.122}", "{\"n\": 9631, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.25, \"learn_time_ms\": 46110.88}", "{\"n\": 9632, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3521.16, \"learn_time_ms\": 46107.094}", "{\"n\": 9633, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3509.95, \"learn_time_ms\": 46081.024}", "{\"n\": 9634, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3514.95, \"learn_time_ms\": 46134.109}", "{\"n\": 9635, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.35, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3499.32, \"learn_time_ms\": 46138.934}", "{\"n\": 9636, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3490.89, \"learn_time_ms\": 46103.407}", "{\"n\": 9637, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3490.89, \"learn_time_ms\": 46157.97}", "{\"n\": 9638, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3490.89, \"learn_time_ms\": 46204.202}", "{\"n\": 9639, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3489.37, \"learn_time_ms\": 46205.993}", "{\"n\": 9640, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3475.83, \"learn_time_ms\": 46228.679}", "{\"n\": 9641, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3471.66, \"learn_time_ms\": 46224.352}", "{\"n\": 9642, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3474.15, \"learn_time_ms\": 46255.544}", "{\"n\": 9643, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3474.15, \"learn_time_ms\": 46212.47}", "{\"n\": 9644, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3474.15, \"learn_time_ms\": 46184.226}", "{\"n\": 9645, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3474.15, \"learn_time_ms\": 46189.271}", "{\"n\": 9646, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -6.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3444.4, \"learn_time_ms\": 46323.562}", "{\"n\": 9647, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3463.67, \"learn_time_ms\": 46291.994}", "{\"n\": 9648, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3477.48, \"learn_time_ms\": 46173.626}", "{\"n\": 9649, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3477.48, \"learn_time_ms\": 46243.556}", "{\"n\": 9650, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3503.22, \"learn_time_ms\": 46311.057}", "{\"n\": 9651, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3498.75, \"learn_time_ms\": 46303.716}", "{\"n\": 9652, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3531.9, \"learn_time_ms\": 46215.603}", "{\"n\": 9653, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.29, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3537.64, \"learn_time_ms\": 46183.259}", "{\"n\": 9654, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3531.24, \"learn_time_ms\": 46219.515}", "{\"n\": 9655, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3531.24, \"learn_time_ms\": 46222.044}", "{\"n\": 9656, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3524.8, \"learn_time_ms\": 46140.728}", "{\"n\": 9657, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3515.04, \"learn_time_ms\": 46152.825}", "{\"n\": 9658, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3513.93, \"learn_time_ms\": 46205.034}", "{\"n\": 9659, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.08, \"learn_time_ms\": 46125.513}", "{\"n\": 9660, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.08, \"learn_time_ms\": 46089.396}", "{\"n\": 9661, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.08, \"learn_time_ms\": 46021.241}", "{\"n\": 9662, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3516.86, \"learn_time_ms\": 46012.318}", "{\"n\": 9663, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3512.44, \"learn_time_ms\": 46058.268}", "{\"n\": 9664, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3530.68, \"learn_time_ms\": 46041.786}", "{\"n\": 9665, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3530.68, \"learn_time_ms\": 46025.201}", "{\"n\": 9666, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3524.06, \"learn_time_ms\": 46007.976}", "{\"n\": 9667, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3531.88, \"learn_time_ms\": 45976.378}", "{\"n\": 9668, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3540.38, \"learn_time_ms\": 45995.554}", "{\"n\": 9669, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3513.27, \"learn_time_ms\": 46014.197}", "{\"n\": 9670, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3506.23, \"learn_time_ms\": 46061.404}", "{\"n\": 9671, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3516.66, \"learn_time_ms\": 46143.613}", "{\"n\": 9672, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3516.66, \"learn_time_ms\": 46154.604}", "{\"n\": 9673, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.36, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3518.34, \"learn_time_ms\": 46073.112}", "{\"n\": 9674, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3527.22, \"learn_time_ms\": 46072.094}", "{\"n\": 9675, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3513.08, \"learn_time_ms\": 46120.925}", "{\"n\": 9676, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3513.08, \"learn_time_ms\": 46022.968}", "{\"n\": 9677, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3517.01, \"learn_time_ms\": 46034.452}", "{\"n\": 9678, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3535.47, \"learn_time_ms\": 46088.633}", "{\"n\": 9679, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3545.52, \"learn_time_ms\": 46111.401}", "{\"n\": 9680, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3522.35, \"learn_time_ms\": 46031.352}", "{\"n\": 9681, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3536.09, \"learn_time_ms\": 46017.73}", "{\"n\": 9682, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3536.09, \"learn_time_ms\": 46036.869}", "{\"n\": 9683, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3536.09, \"learn_time_ms\": 46019.741}", "{\"n\": 9684, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.4, \"learn_time_ms\": 46090.77}", "{\"n\": 9685, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3525.25, \"learn_time_ms\": 46042.548}", "{\"n\": 9686, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.9, \"learn_time_ms\": 46012.346}", "{\"n\": 9687, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3529.49, \"learn_time_ms\": 45890.035}", "{\"n\": 9688, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3529.49, \"learn_time_ms\": 45812.237}", "{\"n\": 9689, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3526.65, \"learn_time_ms\": 45813.373}", "{\"n\": 9690, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3518.36, \"learn_time_ms\": 45827.637}", "{\"n\": 9691, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3519.78, \"learn_time_ms\": 45860.873}", "{\"n\": 9692, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3514.29, \"learn_time_ms\": 45848.923}", "{\"n\": 9693, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3516.7, \"learn_time_ms\": 45816.778}", "{\"n\": 9694, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3503.06, \"learn_time_ms\": 45712.687}", "{\"n\": 9695, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3503.06, \"learn_time_ms\": 45749.195}", "{\"n\": 9696, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3503.74, \"learn_time_ms\": 45876.146}", "{\"n\": 9697, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3500.09, \"learn_time_ms\": 45974.805}", "{\"n\": 9698, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3519.14, \"learn_time_ms\": 45992.21}", "{\"n\": 9699, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3525.88, \"learn_time_ms\": 45949.737}", "{\"n\": 9700, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3525.88, \"learn_time_ms\": 46016.516}", "{\"n\": 9701, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3523.83, \"learn_time_ms\": 46058.474}", "{\"n\": 9702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3515.52, \"learn_time_ms\": 46018.56}", "{\"n\": 9703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3526.94, \"learn_time_ms\": 46146.708}", "{\"n\": 9704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3523.6, \"learn_time_ms\": 46206.083}", "{\"n\": 9705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3523.85, \"learn_time_ms\": 46161.844}", "{\"n\": 9706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3523.85, \"learn_time_ms\": 46130.968}", "{\"n\": 9707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3523.85, \"learn_time_ms\": 46084.297}", "{\"n\": 9708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3534.52, \"learn_time_ms\": 46128.601}", "{\"n\": 9709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3547.98, \"learn_time_ms\": 46108.941}", "{\"n\": 9710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3547.98, \"learn_time_ms\": 46047.15}", "{\"n\": 9711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3541.1, \"learn_time_ms\": 46014.635}", "{\"n\": 9712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3551.47, \"learn_time_ms\": 46081.592}", "{\"n\": 9713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3558.35, \"learn_time_ms\": 46156.099}", "{\"n\": 9714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3570.3, \"learn_time_ms\": 46150.676}", "{\"n\": 9715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3583.12, \"learn_time_ms\": 46100.262}", "{\"n\": 9716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.47, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3576.31, \"learn_time_ms\": 46121.554}", "{\"n\": 9717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3572.86, \"learn_time_ms\": 46100.403}", "{\"n\": 9718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3574.91, \"learn_time_ms\": 46001.306}", "{\"n\": 9719, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3581.58, \"learn_time_ms\": 46082.78}", "{\"n\": 9720, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.06, \"learn_time_ms\": 46106.449}", "{\"n\": 9721, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.4, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.06, \"learn_time_ms\": 46048.98}", "{\"n\": 9722, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.44, \"learn_time_ms\": 46087.539}", "{\"n\": 9723, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.74, \"learn_time_ms\": 45971.052}", "{\"n\": 9724, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3589.51, \"learn_time_ms\": 45930.495}", "{\"n\": 9725, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.76, \"learn_time_ms\": 45991.464}", "{\"n\": 9726, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.27, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3581.66, \"learn_time_ms\": 46081.371}", "{\"n\": 9727, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.36, \"learn_time_ms\": 46139.067}", "{\"n\": 9728, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3579.98, \"learn_time_ms\": 46240.085}", "{\"n\": 9729, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3583.85, \"learn_time_ms\": 46170.55}", "{\"n\": 9730, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3592.58, \"learn_time_ms\": 46164.378}", "{\"n\": 9731, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3623.23, \"learn_time_ms\": 46199.363}", "{\"n\": 9732, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3623.23, \"learn_time_ms\": 46107.462}", "{\"n\": 9733, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3623.23, \"learn_time_ms\": 46131.135}", "{\"n\": 9734, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3627.14, \"learn_time_ms\": 46112.938}", "{\"n\": 9735, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3611.92, \"learn_time_ms\": 46109.329}", "{\"n\": 9736, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3617.65, \"learn_time_ms\": 46051.741}", "{\"n\": 9737, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3611.01, \"learn_time_ms\": 45954.602}", "{\"n\": 9738, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3611.44, \"learn_time_ms\": 45887.001}", "{\"n\": 9739, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3607.48, \"learn_time_ms\": 45886.413}", "{\"n\": 9740, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.22, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3597.26, \"learn_time_ms\": 45896.373}", "{\"n\": 9741, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3588.87, \"learn_time_ms\": 45889.6}", "{\"n\": 9742, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3585.84, \"learn_time_ms\": 45934.832}", "{\"n\": 9743, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.88, \"learn_time_ms\": 45969.645}", "{\"n\": 9744, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3609.32, \"learn_time_ms\": 45901.485}", "{\"n\": 9745, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.01, \"learn_time_ms\": 45915.751}", "{\"n\": 9746, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3592.75, \"learn_time_ms\": 45913.43}", "{\"n\": 9747, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3580.99, \"learn_time_ms\": 46034.646}", "{\"n\": 9748, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3570.13, \"learn_time_ms\": 46059.269}", "{\"n\": 9749, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3579.39, \"learn_time_ms\": 46120.524}", "{\"n\": 9750, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3599.21, \"learn_time_ms\": 46065.741}", "{\"n\": 9751, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3601.25, \"learn_time_ms\": 46024.761}", "{\"n\": 9752, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.2, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3601.25, \"learn_time_ms\": 45953.96}", "{\"n\": 9753, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.43, \"learn_time_ms\": 45962.765}", "{\"n\": 9754, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3602.56, \"learn_time_ms\": 46029.353}", "{\"n\": 9755, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3604.7, \"learn_time_ms\": 46015.363}", "{\"n\": 9756, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3604.7, \"learn_time_ms\": 45963.436}", "{\"n\": 9757, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3587.16, \"learn_time_ms\": 45956.788}", "{\"n\": 9758, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3589.55, \"learn_time_ms\": 45898.787}", "{\"n\": 9759, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.28, \"learn_time_ms\": 45842.27}", "{\"n\": 9760, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.44, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3591.95, \"learn_time_ms\": 45832.384}", "{\"n\": 9761, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3600.79, \"learn_time_ms\": 45859.028}", "{\"n\": 9762, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.29, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3600.79, \"learn_time_ms\": 45934.688}", "{\"n\": 9763, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3593.28, \"learn_time_ms\": 45796.82}", "{\"n\": 9764, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3596.42, \"learn_time_ms\": 45840.49}", "{\"n\": 9765, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.06, \"learn_time_ms\": 45747.358}", "{\"n\": 9766, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3595.06, \"learn_time_ms\": 45855.997}", "{\"n\": 9767, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.97, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3600.5, \"learn_time_ms\": 45787.617}", "{\"n\": 9768, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3604.81, \"learn_time_ms\": 45881.043}", "{\"n\": 9769, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3594.62, \"learn_time_ms\": 45876.355}", "{\"n\": 9770, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3606.79, \"learn_time_ms\": 45882.927}", "{\"n\": 9771, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3604.61, \"learn_time_ms\": 45802.904}", "{\"n\": 9772, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3604.61, \"learn_time_ms\": 45794.891}", "{\"n\": 9773, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3606.63, \"learn_time_ms\": 45920.333}", "{\"n\": 9774, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3608.87, \"learn_time_ms\": 45927.749}", "{\"n\": 9775, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3632.09, \"learn_time_ms\": 46070.297}", "{\"n\": 9776, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3632.09, \"learn_time_ms\": 45986.471}", "{\"n\": 9777, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.5, \"learn_time_ms\": 45990.112}", "{\"n\": 9778, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3638.32, \"learn_time_ms\": 45967.432}", "{\"n\": 9779, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3629.84, \"learn_time_ms\": 46020.056}", "{\"n\": 9780, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3634.35, \"learn_time_ms\": 46009.687}", "{\"n\": 9781, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3615.16, \"learn_time_ms\": 46166.626}", "{\"n\": 9782, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.74, \"learn_time_ms\": 46111.819}", "{\"n\": 9783, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.74, \"learn_time_ms\": 45987.496}", "{\"n\": 9784, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3592.02, \"learn_time_ms\": 45959.694}", "{\"n\": 9785, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3601.5, \"learn_time_ms\": 45906.652}", "{\"n\": 9786, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.57, \"learn_time_ms\": 45946.239}", "{\"n\": 9787, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.73, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3581.72, \"learn_time_ms\": 46043.975}", "{\"n\": 9788, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3570.05, \"learn_time_ms\": 45976.275}", "{\"n\": 9789, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3557.78, \"learn_time_ms\": 45932.211}", "{\"n\": 9790, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3544.61, \"learn_time_ms\": 45984.36}", "{\"n\": 9791, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3537.6, \"learn_time_ms\": 45941.805}", "{\"n\": 9792, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3543.56, \"learn_time_ms\": 46002.093}", "{\"n\": 9793, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3542.2, \"learn_time_ms\": 46044.234}", "{\"n\": 9794, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3536.2, \"learn_time_ms\": 45964.593}", "{\"n\": 9795, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3536.2, \"learn_time_ms\": 45990.911}", "{\"n\": 9796, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3534.38, \"learn_time_ms\": 45969.157}", "{\"n\": 9797, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3534.38, \"learn_time_ms\": 45935.184}", "{\"n\": 9798, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3526.19, \"learn_time_ms\": 45923.563}", "{\"n\": 9799, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3509.84, \"learn_time_ms\": 45977.071}", "{\"n\": 9800, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3490.92, \"learn_time_ms\": 46053.436}", "{\"n\": 9801, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3482.61, \"learn_time_ms\": 45957.424}", "{\"n\": 9802, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3480.46, \"learn_time_ms\": 45908.831}", "{\"n\": 9803, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3480.28, \"learn_time_ms\": 45930.201}", "{\"n\": 9804, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3476.97, \"learn_time_ms\": 46019.342}", "{\"n\": 9805, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3484.0, \"learn_time_ms\": 45982.637}", "{\"n\": 9806, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3487.27, \"learn_time_ms\": 45853.495}", "{\"n\": 9807, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3497.03, \"learn_time_ms\": 45842.886}", "{\"n\": 9808, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3487.62, \"learn_time_ms\": 45940.209}", "{\"n\": 9809, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.98, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3493.43, \"learn_time_ms\": 45916.794}", "{\"n\": 9810, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3491.08, \"learn_time_ms\": 45842.106}", "{\"n\": 9811, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3491.08, \"learn_time_ms\": 45881.119}", "{\"n\": 9812, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3480.94, \"learn_time_ms\": 45867.744}", "{\"n\": 9813, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3486.92, \"learn_time_ms\": 45860.886}", "{\"n\": 9814, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3486.92, \"learn_time_ms\": 45816.025}", "{\"n\": 9815, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3483.5, \"learn_time_ms\": 45791.664}", "{\"n\": 9816, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3471.55, \"learn_time_ms\": 45894.959}", "{\"n\": 9817, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3476.35, \"learn_time_ms\": 45879.101}", "{\"n\": 9818, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3476.35, \"learn_time_ms\": 45772.678}", "{\"n\": 9819, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3494.41, \"learn_time_ms\": 45681.416}", "{\"n\": 9820, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3501.24, \"learn_time_ms\": 45719.502}", "{\"n\": 9821, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3503.32, \"learn_time_ms\": 45732.951}", "{\"n\": 9822, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3500.14, \"learn_time_ms\": 45824.552}", "{\"n\": 9823, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3500.14, \"learn_time_ms\": 45885.154}", "{\"n\": 9824, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3507.17, \"learn_time_ms\": 45904.329}", "{\"n\": 9825, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3501.51, \"learn_time_ms\": 46001.494}", "{\"n\": 9826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3503.81, \"learn_time_ms\": 45895.367}", "{\"n\": 9827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3505.46, \"learn_time_ms\": 45783.593}", "{\"n\": 9828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3516.48, \"learn_time_ms\": 45866.888}", "{\"n\": 9829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3511.26, \"learn_time_ms\": 45876.809}", "{\"n\": 9830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3508.88, \"learn_time_ms\": 45807.541}", "{\"n\": 9831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3508.88, \"learn_time_ms\": 45750.548}", "{\"n\": 9832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3490.08, \"learn_time_ms\": 45697.48}", "{\"n\": 9833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3489.63, \"learn_time_ms\": 45612.856}", "{\"n\": 9834, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3488.93, \"learn_time_ms\": 45562.237}", "{\"n\": 9835, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3488.74, \"learn_time_ms\": 45557.028}", "{\"n\": 9836, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3477.55, \"learn_time_ms\": 45663.915}", "{\"n\": 9837, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3471.69, \"learn_time_ms\": 45817.956}", "{\"n\": 9838, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3457.08, \"learn_time_ms\": 45753.983}", "{\"n\": 9839, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3457.08, \"learn_time_ms\": 45773.764}", "{\"n\": 9840, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3472.79, \"learn_time_ms\": 45848.841}", "{\"n\": 9841, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.39, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3471.61, \"learn_time_ms\": 45947.776}", "{\"n\": 9842, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3458.07, \"learn_time_ms\": 45873.891}", "{\"n\": 9843, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3456.35, \"learn_time_ms\": 45991.341}", "{\"n\": 9844, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3444.29, \"learn_time_ms\": 46145.015}", "{\"n\": 9845, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3444.29, \"learn_time_ms\": 46067.953}", "{\"n\": 9846, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3442.37, \"learn_time_ms\": 46168.39}", "{\"n\": 9847, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.51, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3449.05, \"learn_time_ms\": 46173.61}", "{\"n\": 9848, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3433.15, \"learn_time_ms\": 46176.989}", "{\"n\": 9849, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3433.97, \"learn_time_ms\": 46213.91}", "{\"n\": 9850, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3433.97, \"learn_time_ms\": 46104.559}", "{\"n\": 9851, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3432.62, \"learn_time_ms\": 46049.902}", "{\"n\": 9852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3432.62, \"learn_time_ms\": 46105.726}", "{\"n\": 9853, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3447.93, \"learn_time_ms\": 46041.457}", "{\"n\": 9854, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3467.58, \"learn_time_ms\": 45994.314}", "{\"n\": 9855, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3470.56, \"learn_time_ms\": 46055.901}", "{\"n\": 9856, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3470.56, \"learn_time_ms\": 46022.694}", "{\"n\": 9857, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.48, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3465.53, \"learn_time_ms\": 45964.795}", "{\"n\": 9858, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3461.24, \"learn_time_ms\": 46036.318}", "{\"n\": 9859, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3463.83, \"learn_time_ms\": 45994.407}", "{\"n\": 9860, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3463.83, \"learn_time_ms\": 46108.11}", "{\"n\": 9861, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3463.83, \"learn_time_ms\": 46170.822}", "{\"n\": 9862, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3487.02, \"learn_time_ms\": 46233.088}", "{\"n\": 9863, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3487.02, \"learn_time_ms\": 46231.374}", "{\"n\": 9864, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.53, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3480.99, \"learn_time_ms\": 46117.217}", "{\"n\": 9865, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3474.84, \"learn_time_ms\": 46063.258}", "{\"n\": 9866, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3462.07, \"learn_time_ms\": 46057.54}", "{\"n\": 9867, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3469.17, \"learn_time_ms\": 46044.851}", "{\"n\": 9868, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3474.35, \"learn_time_ms\": 46024.94}", "{\"n\": 9869, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3474.35, \"learn_time_ms\": 46071.526}", "{\"n\": 9870, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3474.35, \"learn_time_ms\": 45989.497}", "{\"n\": 9871, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.6, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3497.7, \"learn_time_ms\": 45990.222}", "{\"n\": 9872, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3497.65, \"learn_time_ms\": 45907.541}", "{\"n\": 9873, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3497.65, \"learn_time_ms\": 45988.537}", "{\"n\": 9874, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3511.67, \"learn_time_ms\": 46105.122}", "{\"n\": 9875, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3511.67, \"learn_time_ms\": 46084.495}", "{\"n\": 9876, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3511.67, \"learn_time_ms\": 45964.436}", "{\"n\": 9877, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3518.9, \"learn_time_ms\": 46032.75}", "{\"n\": 9878, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.62, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3497.34, \"learn_time_ms\": 46035.888}", "{\"n\": 9879, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3514.25, \"learn_time_ms\": 46094.875}", "{\"n\": 9880, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3514.25, \"learn_time_ms\": 46156.488}", "{\"n\": 9881, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3536.31, \"learn_time_ms\": 46105.509}", "{\"n\": 9882, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3536.31, \"learn_time_ms\": 46198.477}", "{\"n\": 9883, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3536.31, \"learn_time_ms\": 46146.82}", "{\"n\": 9884, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3550.43, \"learn_time_ms\": 46162.187}", "{\"n\": 9885, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3564.15, \"learn_time_ms\": 46237.164}", "{\"n\": 9886, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3577.25, \"learn_time_ms\": 46339.087}", "{\"n\": 9887, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.65, \"learn_time_ms\": 46277.799}", "{\"n\": 9888, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3590.65, \"learn_time_ms\": 46328.346}", "{\"n\": 9889, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3585.01, \"learn_time_ms\": 46326.788}", "{\"n\": 9890, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3608.9, \"learn_time_ms\": 46356.388}", "{\"n\": 9891, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3611.35, \"learn_time_ms\": 46332.224}", "{\"n\": 9892, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.58, \"learn_time_ms\": 46221.846}", "{\"n\": 9893, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.79, \"learn_time_ms\": 46226.322}", "{\"n\": 9894, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.79, \"learn_time_ms\": 46172.609}", "{\"n\": 9895, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.7, \"learn_time_ms\": 46082.857}", "{\"n\": 9896, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.17, \"learn_time_ms\": 46074.381}", "{\"n\": 9897, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.0, \"learn_time_ms\": 46040.728}", "{\"n\": 9898, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3574.09, \"learn_time_ms\": 45973.285}", "{\"n\": 9899, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.76, \"learn_time_ms\": 45974.606}", "{\"n\": 9900, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3580.02, \"learn_time_ms\": 45867.702}", "{\"n\": 9901, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.54, \"learn_time_ms\": 45925.657}", "{\"n\": 9902, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.54, \"learn_time_ms\": 45955.26}", "{\"n\": 9903, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3575.32, \"learn_time_ms\": 45907.186}", "{\"n\": 9904, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3595.12, \"learn_time_ms\": 45916.969}", "{\"n\": 9905, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3590.8, \"learn_time_ms\": 45945.072}", "{\"n\": 9906, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.84, \"learn_time_ms\": 45938.53}", "{\"n\": 9907, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3576.68, \"learn_time_ms\": 46002.064}", "{\"n\": 9908, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.57, \"learn_time_ms\": 45988.789}", "{\"n\": 9909, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3578.68, \"learn_time_ms\": 45935.917}", "{\"n\": 9910, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3572.29, \"learn_time_ms\": 45944.48}", "{\"n\": 9911, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.26, \"learn_time_ms\": 45837.414}", "{\"n\": 9912, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.59, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3587.26, \"learn_time_ms\": 45851.214}", "{\"n\": 9913, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.91, \"learn_time_ms\": 45936.098}", "{\"n\": 9914, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.35, \"learn_time_ms\": 45803.921}", "{\"n\": 9915, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.51, \"learn_time_ms\": 45771.485}", "{\"n\": 9916, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3591.31, \"learn_time_ms\": 45758.121}", "{\"n\": 9917, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3589.58, \"learn_time_ms\": 45740.14}", "{\"n\": 9918, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.82, \"learn_time_ms\": 45670.625}", "{\"n\": 9919, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3596.82, \"learn_time_ms\": 45689.704}", "{\"n\": 9920, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.07, \"learn_time_ms\": 45794.367}", "{\"n\": 9921, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.75, \"learn_time_ms\": 45759.895}", "{\"n\": 9922, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3592.68, \"learn_time_ms\": 45797.471}", "{\"n\": 9923, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.82, \"learn_time_ms\": 45797.399}", "{\"n\": 9924, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3579.46, \"learn_time_ms\": 45790.832}", "{\"n\": 9925, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.08, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.33, \"learn_time_ms\": 45924.72}", "{\"n\": 9926, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.52, \"learn_time_ms\": 45892.538}", "{\"n\": 9927, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.26, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3548.78, \"learn_time_ms\": 45813.987}", "{\"n\": 9928, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.76, \"learn_time_ms\": 45935.599}", "{\"n\": 9929, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3545.1, \"learn_time_ms\": 45966.24}", "{\"n\": 9930, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3545.1, \"learn_time_ms\": 45948.243}", "{\"n\": 9931, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3540.63, \"learn_time_ms\": 46026.09}", "{\"n\": 9932, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.95, \"learn_time_ms\": 45974.282}", "{\"n\": 9933, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.95, \"learn_time_ms\": 45942.91}", "{\"n\": 9934, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.14, \"learn_time_ms\": 46118.254}", "{\"n\": 9935, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.22, \"learn_time_ms\": 46085.421}", "{\"n\": 9936, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3547.89, \"learn_time_ms\": 46135.905}", "{\"n\": 9937, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3547.89, \"learn_time_ms\": 46216.513}", "{\"n\": 9938, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.53, \"learn_time_ms\": 46185.323}", "{\"n\": 9939, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.53, \"learn_time_ms\": 46189.004}", "{\"n\": 9940, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.57, \"learn_time_ms\": 46127.265}", "{\"n\": 9941, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.51, \"learn_time_ms\": 46160.729}", "{\"n\": 9942, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3583.62, \"learn_time_ms\": 46166.115}", "{\"n\": 9943, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.19, \"learn_time_ms\": 46180.41}", "{\"n\": 9944, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3586.19, \"learn_time_ms\": 46161.383}", "{\"n\": 9945, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3579.26, \"learn_time_ms\": 46074.01}", "{\"n\": 9946, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3579.26, \"learn_time_ms\": 46063.238}", "{\"n\": 9947, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.19, \"learn_time_ms\": 46089.191}", "{\"n\": 9948, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.02, \"learn_time_ms\": 46091.274}", "{\"n\": 9949, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.02, \"learn_time_ms\": 46063.931}", "{\"n\": 9950, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.17, \"learn_time_ms\": 46074.36}", "{\"n\": 9951, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.17, \"learn_time_ms\": 45981.629}", "{\"n\": 9952, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.53, \"learn_time_ms\": 45941.132}", "{\"n\": 9953, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.34, \"learn_time_ms\": 45930.673}", "{\"n\": 9954, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.34, \"learn_time_ms\": 45962.236}", "{\"n\": 9955, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3526.4, \"learn_time_ms\": 45999.329}", "{\"n\": 9956, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3524.4, \"learn_time_ms\": 45956.001}", "{\"n\": 9957, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3499.19, \"learn_time_ms\": 45933.083}", "{\"n\": 9958, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3490.08, \"learn_time_ms\": 45903.974}", "{\"n\": 9959, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3490.08, \"learn_time_ms\": 45806.751}", "{\"n\": 9960, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3485.71, \"learn_time_ms\": 45747.79}", "{\"n\": 9961, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3478.25, \"learn_time_ms\": 45855.575}", "{\"n\": 9962, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3477.73, \"learn_time_ms\": 45896.296}", "{\"n\": 9963, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3482.57, \"learn_time_ms\": 45923.133}", "{\"n\": 9964, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3475.3, \"learn_time_ms\": 45810.557}", "{\"n\": 9965, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3475.3, \"learn_time_ms\": 45684.117}", "{\"n\": 9966, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3475.3, \"learn_time_ms\": 45619.05}", "{\"n\": 9967, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3488.11, \"learn_time_ms\": 45653.719}", "{\"n\": 9968, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3462.76, \"learn_time_ms\": 45633.627}", "{\"n\": 9969, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3476.67, \"learn_time_ms\": 45643.573}", "{\"n\": 9970, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3460.26, \"learn_time_ms\": 45689.967}", "{\"n\": 9971, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -6.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3454.83, \"learn_time_ms\": 45634.489}", "{\"n\": 9972, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3448.29, \"learn_time_ms\": 45629.71}", "{\"n\": 9973, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3448.29, \"learn_time_ms\": 45614.96}", "{\"n\": 9974, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3440.2, \"learn_time_ms\": 45633.936}", "{\"n\": 9975, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3435.11, \"learn_time_ms\": 45771.297}", "{\"n\": 9976, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3435.4, \"learn_time_ms\": 45807.586}", "{\"n\": 9977, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3436.19, \"learn_time_ms\": 45779.834}", "{\"n\": 9978, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3444.78, \"learn_time_ms\": 45806.39}", "{\"n\": 9979, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3444.78, \"learn_time_ms\": 45850.006}", "{\"n\": 9980, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3451.81, \"learn_time_ms\": 45837.308}", "{\"n\": 9981, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3463.5, \"learn_time_ms\": 45857.6}", "{\"n\": 9982, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3455.7, \"learn_time_ms\": 45860.196}", "{\"n\": 9983, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3455.7, \"learn_time_ms\": 45806.658}", "{\"n\": 9984, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.36, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3455.7, \"learn_time_ms\": 45902.537}", "{\"n\": 9985, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.28, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3469.14, \"learn_time_ms\": 45977.711}", "{\"n\": 9986, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3464.65, \"learn_time_ms\": 45999.246}", "{\"n\": 9987, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3460.43, \"learn_time_ms\": 46074.747}", "{\"n\": 9988, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3470.86, \"learn_time_ms\": 46103.161}", "{\"n\": 9989, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3470.86, \"learn_time_ms\": 46039.631}", "{\"n\": 9990, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3470.86, \"learn_time_ms\": 45936.753}", "{\"n\": 9991, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3448.7, \"learn_time_ms\": 45867.12}", "{\"n\": 9992, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3457.29, \"learn_time_ms\": 45888.144}", "{\"n\": 9993, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3470.7, \"learn_time_ms\": 45858.487}", "{\"n\": 9994, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3482.4, \"learn_time_ms\": 45841.348}", "{\"n\": 9995, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3482.4, \"learn_time_ms\": 45710.331}", "{\"n\": 9996, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3482.4, \"learn_time_ms\": 45802.614}", "{\"n\": 9997, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3493.6, \"learn_time_ms\": 45706.01}", "{\"n\": 9998, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3505.21, \"learn_time_ms\": 45700.602}", "{\"n\": 9999, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3521.69, \"learn_time_ms\": 45770.184}", "{\"n\": 10000, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3521.79, \"learn_time_ms\": 46051.598}"]["{\"n\": 10001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 45062.763}", "{\"n\": 10002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43749.527}", "{\"n\": 10003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43574.554}", "{\"n\": 10004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43469.121}", "{\"n\": 10005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43362.789}", "{\"n\": 10006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43261.737}", "{\"n\": 10007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43158.685}", "{\"n\": 10008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43104.626}", "{\"n\": 10009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43054.644}", "{\"n\": 10010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43056.746}", "{\"n\": 10011, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -10.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2816.0, \"learn_time_ms\": 42873.364}", "{\"n\": 10012, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.0, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3480.25, \"learn_time_ms\": 42917.416}", "{\"n\": 10013, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -6.333333333333333, \"episode_reward_max\": -4.0, \"episode_len_mean\": 3413.8333333333335, \"learn_time_ms\": 42885.704}", "{\"n\": 10014, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3534.375, \"learn_time_ms\": 42840.714}", "{\"n\": 10015, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3534.375, \"learn_time_ms\": 42796.606}", "{\"n\": 10016, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -5.5, \"episode_reward_max\": -2.0, \"episode_len_mean\": 3534.375, \"learn_time_ms\": 42820.653}", "{\"n\": 10017, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3496.8, \"learn_time_ms\": 42875.612}", "{\"n\": 10018, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.454545454545454, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3515.0, \"learn_time_ms\": 42811.608}", "{\"n\": 10019, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3598.133333333333, \"learn_time_ms\": 42831.247}", "{\"n\": 10020, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3598.133333333333, \"learn_time_ms\": 42829.137}", "{\"n\": 10021, \"episode_reward_min\": -10.0, \"episode_reward_mean\": -4.625, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3643.0625, \"learn_time_ms\": 42784.181}", "{\"n\": 10022, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3590.0, \"learn_time_ms\": 42765.381}", "{\"n\": 10023, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3590.0, \"learn_time_ms\": 42726.103}", "{\"n\": 10024, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3588.35, \"learn_time_ms\": 42707.582}", "{\"n\": 10025, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -4.173913043478261, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.478260869565, \"learn_time_ms\": 42742.567}", "{\"n\": 10026, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.8333333333333335, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.7916666666665, \"learn_time_ms\": 42705.323}", "{\"n\": 10027, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.8333333333333335, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.7916666666665, \"learn_time_ms\": 42701.707}", "{\"n\": 10028, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.8333333333333335, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.7916666666665, \"learn_time_ms\": 42717.903}", "{\"n\": 10029, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.4615384615384617, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.1923076923076, \"learn_time_ms\": 42669.907}", "{\"n\": 10030, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.4074074074074074, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3592.037037037037, \"learn_time_ms\": 42617.439}", "{\"n\": 10031, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.5357142857142856, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.1071428571427, \"learn_time_ms\": 42693.897}", "{\"n\": 10032, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.806451612903226, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.516129032258, \"learn_time_ms\": 42718.128}", "{\"n\": 10033, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.8125, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3597.0625, \"learn_time_ms\": 42771.378}", "{\"n\": 10034, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.8125, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3597.0625, \"learn_time_ms\": 42771.755}", "{\"n\": 10035, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.8529411764705883, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3598.9117647058824, \"learn_time_ms\": 42808.857}", "{\"n\": 10036, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.7222222222222223, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.0833333333335, \"learn_time_ms\": 42871.37}", "{\"n\": 10037, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.7222222222222223, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.0833333333335, \"learn_time_ms\": 42840.115}", "{\"n\": 10038, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.6486486486486487, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.108108108108, \"learn_time_ms\": 42990.758}", "{\"n\": 10039, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.341463414634146, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.2195121951218, \"learn_time_ms\": 43022.844}", "{\"n\": 10040, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.341463414634146, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.2195121951218, \"learn_time_ms\": 43058.663}", "{\"n\": 10041, \"episode_reward_min\": -11.0, \"episode_reward_mean\": -3.3333333333333335, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.095238095238, \"learn_time_ms\": 43013.603}", "{\"n\": 10042, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.659090909090909, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3654.568181818182, \"learn_time_ms\": 43033.806}", "{\"n\": 10043, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.488888888889, \"learn_time_ms\": 42976.188}", "{\"n\": 10044, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.488888888889, \"learn_time_ms\": 43089.451}", "{\"n\": 10045, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.6595744680851063, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3662.936170212766, \"learn_time_ms\": 43128.036}", "{\"n\": 10046, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -3.4583333333333335, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3674.6875, \"learn_time_ms\": 43057.081}", "{\"n\": 10047, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.5, \"learn_time_ms\": 43245.3}", "{\"n\": 10048, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6153846153846154, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.5576923076924, \"learn_time_ms\": 43136.724}", "{\"n\": 10049, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6153846153846154, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.5576923076924, \"learn_time_ms\": 43230.399}", "{\"n\": 10050, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.7169811320754715, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3639.754716981132, \"learn_time_ms\": 43298.105}", "{\"n\": 10051, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6296296296296298, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.3703703703704, \"learn_time_ms\": 43247.864}", "{\"n\": 10052, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.625, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3660.5714285714284, \"learn_time_ms\": 43288.574}", "{\"n\": 10053, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.543859649122807, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3671.3684210526317, \"learn_time_ms\": 43317.059}", "{\"n\": 10054, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5254237288135593, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.8474576271187, \"learn_time_ms\": 43308.865}", "{\"n\": 10055, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3680.45, \"learn_time_ms\": 43174.516}", "{\"n\": 10056, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3680.45, \"learn_time_ms\": 43163.068}", "{\"n\": 10057, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.4761904761904763, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.5555555555557, \"learn_time_ms\": 43024.18}", "{\"n\": 10058, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.4375, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.140625, \"learn_time_ms\": 43037.719}", "{\"n\": 10059, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.4375, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3688.140625, \"learn_time_ms\": 42878.334}", "{\"n\": 10060, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.4615384615384617, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3684.769230769231, \"learn_time_ms\": 42798.087}", "{\"n\": 10061, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2794117647058822, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3692.8823529411766, \"learn_time_ms\": 42887.877}", "{\"n\": 10062, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2714285714285714, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.385714285714, \"learn_time_ms\": 42829.191}", "{\"n\": 10063, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2714285714285714, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.385714285714, \"learn_time_ms\": 42865.539}", "{\"n\": 10064, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.295774647887324, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.6619718309857, \"learn_time_ms\": 42815.332}", "{\"n\": 10065, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2222222222222223, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3695.1666666666665, \"learn_time_ms\": 42900.949}", "{\"n\": 10066, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.4933333333333, \"learn_time_ms\": 42938.411}", "{\"n\": 10067, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.986842105263158, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.434210526316, \"learn_time_ms\": 42899.077}", "{\"n\": 10068, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.986842105263158, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3712.434210526316, \"learn_time_ms\": 42918.924}", "{\"n\": 10069, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.1923076923076925, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.0128205128203, \"learn_time_ms\": 42983.953}", "{\"n\": 10070, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.1645569620253164, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.3924050632913, \"learn_time_ms\": 43115.36}", "{\"n\": 10071, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2222222222222223, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.6666666666665, \"learn_time_ms\": 43047.951}", "{\"n\": 10072, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2222222222222223, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.6666666666665, \"learn_time_ms\": 43212.457}", "{\"n\": 10073, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.369047619047619, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3695.3333333333335, \"learn_time_ms\": 43177.277}", "{\"n\": 10074, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3411764705882354, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.529411764706, \"learn_time_ms\": 43173.159}", "{\"n\": 10075, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2674418604651163, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.779069767442, \"learn_time_ms\": 43194.875}", "{\"n\": 10076, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2674418604651163, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.779069767442, \"learn_time_ms\": 43196.816}", "{\"n\": 10077, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.340909090909091, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3702.8636363636365, \"learn_time_ms\": 43183.107}", "{\"n\": 10078, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3777777777777778, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.1111111111113, \"learn_time_ms\": 43244.997}", "{\"n\": 10079, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2527472527472527, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.054945054945, \"learn_time_ms\": 43275.341}", "{\"n\": 10080, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2717391304347827, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3699.4891304347825, \"learn_time_ms\": 43213.801}", "{\"n\": 10081, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.234042553191489, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.6382978723404, \"learn_time_ms\": 43171.48}", "{\"n\": 10082, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.234042553191489, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.6382978723404, \"learn_time_ms\": 43103.677}", "{\"n\": 10083, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3333333333333335, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.3541666666665, \"learn_time_ms\": 43039.042}", "{\"n\": 10084, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.4285714285714284, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3683.0510204081634, \"learn_time_ms\": 43057.396}", "{\"n\": 10085, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.86, \"learn_time_ms\": 43065.968}", "{\"n\": 10086, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.71, \"learn_time_ms\": 43051.514}", "{\"n\": 10087, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.71, \"learn_time_ms\": 43163.83}", "{\"n\": 10088, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.71, \"learn_time_ms\": 43186.144}", "{\"n\": 10089, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3693.57, \"learn_time_ms\": 43210.063}", "{\"n\": 10090, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.91, \"learn_time_ms\": 43118.519}", "{\"n\": 10091, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.91, \"learn_time_ms\": 43136.904}", "{\"n\": 10092, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.16, \"learn_time_ms\": 43127.773}", "{\"n\": 10093, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.9, \"learn_time_ms\": 43207.667}", "{\"n\": 10094, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.9, \"learn_time_ms\": 43160.564}", "{\"n\": 10095, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3697.9, \"learn_time_ms\": 43242.012}", "{\"n\": 10096, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.1, \"learn_time_ms\": 43290.716}", "{\"n\": 10097, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.27, \"learn_time_ms\": 43252.255}", "{\"n\": 10098, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.27, \"learn_time_ms\": 43158.073}", "{\"n\": 10099, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.89, \"learn_time_ms\": 43181.612}", "{\"n\": 10100, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3703.89, \"learn_time_ms\": 43190.032}", "{\"n\": 10101, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.08, \"learn_time_ms\": 43156.876}", "{\"n\": 10102, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.42, \"learn_time_ms\": 43160.103}", "{\"n\": 10103, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3695.47, \"learn_time_ms\": 43177.303}", "{\"n\": 10104, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3708.61, \"learn_time_ms\": 43165.353}", "{\"n\": 10105, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3714.43, \"learn_time_ms\": 42977.029}", "{\"n\": 10106, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3714.21, \"learn_time_ms\": 42905.286}", "{\"n\": 10107, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3705.56, \"learn_time_ms\": 42865.784}", "{\"n\": 10108, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.95, \"learn_time_ms\": 42902.359}", "{\"n\": 10109, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.95, \"learn_time_ms\": 42858.618}", "{\"n\": 10110, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3702.57, \"learn_time_ms\": 42914.727}", "{\"n\": 10111, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3701.06, \"learn_time_ms\": 42944.613}", "{\"n\": 10112, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.18, \"learn_time_ms\": 42841.659}", "{\"n\": 10113, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.18, \"learn_time_ms\": 42808.483}", "{\"n\": 10114, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.17, \"learn_time_ms\": 42890.358}", "{\"n\": 10115, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.04, \"learn_time_ms\": 42875.357}", "{\"n\": 10116, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.72, \"learn_time_ms\": 42925.691}", "{\"n\": 10117, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.72, \"learn_time_ms\": 42917.641}", "{\"n\": 10118, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.01, \"learn_time_ms\": 42963.365}", "{\"n\": 10119, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3664.47, \"learn_time_ms\": 42955.707}", "{\"n\": 10120, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3646.77, \"learn_time_ms\": 42976.556}", "{\"n\": 10121, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.31, \"learn_time_ms\": 43032.288}", "{\"n\": 10122, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.31, \"learn_time_ms\": 43093.363}", "{\"n\": 10123, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3647.31, \"learn_time_ms\": 43136.883}", "{\"n\": 10124, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3627.08, \"learn_time_ms\": 43055.97}", "{\"n\": 10125, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.74, \"learn_time_ms\": 43265.476}", "{\"n\": 10126, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.27, \"learn_time_ms\": 43258.78}", "{\"n\": 10127, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.36, \"learn_time_ms\": 43295.421}", "{\"n\": 10128, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.75, \"learn_time_ms\": 43221.878}", "{\"n\": 10129, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3630.75, \"learn_time_ms\": 43166.467}", "{\"n\": 10130, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.54, \"learn_time_ms\": 43107.624}", "{\"n\": 10131, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.57, \"learn_time_ms\": 43169.752}", "{\"n\": 10132, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.82, \"learn_time_ms\": 43117.708}", "{\"n\": 10133, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.15, \"learn_time_ms\": 43106.312}", "{\"n\": 10134, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.15, \"learn_time_ms\": 43273.044}", "{\"n\": 10135, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.47, \"learn_time_ms\": 43118.565}", "{\"n\": 10136, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.82, \"learn_time_ms\": 43206.55}", "{\"n\": 10137, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.29, \"learn_time_ms\": 43294.724}", "{\"n\": 10138, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3619.29, \"learn_time_ms\": 43255.483}", "{\"n\": 10139, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.16, \"learn_time_ms\": 43265.821}", "{\"n\": 10140, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.16, \"learn_time_ms\": 43311.564}", "{\"n\": 10141, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3607.92, \"learn_time_ms\": 43208.392}", "{\"n\": 10142, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3604.98, \"learn_time_ms\": 43230.736}", "{\"n\": 10143, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3615.78, \"learn_time_ms\": 43261.067}", "{\"n\": 10144, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.28, \"learn_time_ms\": 43065.758}", "{\"n\": 10145, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.28, \"learn_time_ms\": 43114.96}", "{\"n\": 10146, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3596.28, \"learn_time_ms\": 42967.27}", "{\"n\": 10147, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.06, \"learn_time_ms\": 42849.545}", "{\"n\": 10148, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.44, \"learn_time_ms\": 42920.594}", "{\"n\": 10149, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.74, \"learn_time_ms\": 42962.793}", "{\"n\": 10150, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.74, \"learn_time_ms\": 42979.621}", "{\"n\": 10151, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.82, \"learn_time_ms\": 42977.95}", "{\"n\": 10152, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3576.71, \"learn_time_ms\": 42949.985}", "{\"n\": 10153, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3584.01, \"learn_time_ms\": 42896.138}", "{\"n\": 10154, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3575.4, \"learn_time_ms\": 42972.667}", "{\"n\": 10155, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3572.35, \"learn_time_ms\": 42983.291}", "{\"n\": 10156, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3572.35, \"learn_time_ms\": 43026.297}", "{\"n\": 10157, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3572.4, \"learn_time_ms\": 42966.407}", "{\"n\": 10158, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3571.84, \"learn_time_ms\": 42907.983}", "{\"n\": 10159, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3566.72, \"learn_time_ms\": 43034.306}", "{\"n\": 10160, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3566.72, \"learn_time_ms\": 42946.721}", "{\"n\": 10161, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3560.96, \"learn_time_ms\": 43063.306}", "{\"n\": 10162, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3585.5, \"learn_time_ms\": 43039.23}", "{\"n\": 10163, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.13, \"learn_time_ms\": 43002.753}", "{\"n\": 10164, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3585.43, \"learn_time_ms\": 43026.421}", "{\"n\": 10165, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3588.28, \"learn_time_ms\": 42967.553}", "{\"n\": 10166, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3578.55, \"learn_time_ms\": 42994.086}", "{\"n\": 10167, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3587.42, \"learn_time_ms\": 43021.138}", "{\"n\": 10168, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3579.4, \"learn_time_ms\": 43036.36}", "{\"n\": 10169, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3581.69, \"learn_time_ms\": 42939.5}", "{\"n\": 10170, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3582.29, \"learn_time_ms\": 42986.723}", "{\"n\": 10171, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3582.29, \"learn_time_ms\": 42895.114}", "{\"n\": 10172, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3572.26, \"learn_time_ms\": 42973.437}", "{\"n\": 10173, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3569.55, \"learn_time_ms\": 43012.847}", "{\"n\": 10174, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.3, \"learn_time_ms\": 43014.953}", "{\"n\": 10175, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3541.59, \"learn_time_ms\": 43057.27}", "{\"n\": 10176, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3548.37, \"learn_time_ms\": 43040.455}", "{\"n\": 10177, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3548.36, \"learn_time_ms\": 43055.859}", "{\"n\": 10178, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3548.36, \"learn_time_ms\": 43157.862}", "{\"n\": 10179, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3544.33, \"learn_time_ms\": 43121.006}", "{\"n\": 10180, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3543.85, \"learn_time_ms\": 43088.988}", "{\"n\": 10181, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3555.32, \"learn_time_ms\": 43055.96}", "{\"n\": 10182, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3588.02, \"learn_time_ms\": 42972.893}", "{\"n\": 10183, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3588.02, \"learn_time_ms\": 42934.558}", "{\"n\": 10184, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3588.02, \"learn_time_ms\": 42843.671}", "{\"n\": 10185, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3588.76, \"learn_time_ms\": 42736.481}", "{\"n\": 10186, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3588.76, \"learn_time_ms\": 42874.017}", "{\"n\": 10187, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.29, \"learn_time_ms\": 42950.041}", "{\"n\": 10188, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.99, \"learn_time_ms\": 42918.007}", "{\"n\": 10189, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.13, \"learn_time_ms\": 42964.812}", "{\"n\": 10190, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3610.13, \"learn_time_ms\": 42944.976}", "{\"n\": 10191, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3584.68, \"learn_time_ms\": 42995.104}", "{\"n\": 10192, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3599.1, \"learn_time_ms\": 43102.359}", "{\"n\": 10193, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3599.1, \"learn_time_ms\": 43117.576}", "{\"n\": 10194, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.25, \"learn_time_ms\": 43267.711}", "{\"n\": 10195, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3611.18, \"learn_time_ms\": 43318.755}", "{\"n\": 10196, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3617.28, \"learn_time_ms\": 43234.319}", "{\"n\": 10197, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.63, \"learn_time_ms\": 43165.608}", "{\"n\": 10198, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3636.94, \"learn_time_ms\": 43068.215}", "{\"n\": 10199, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.05, \"learn_time_ms\": 43112.538}", "{\"n\": 10200, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.54, \"learn_time_ms\": 43145.695}", "{\"n\": 10201, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3621.64, \"learn_time_ms\": 43138.702}", "{\"n\": 10202, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3621.64, \"learn_time_ms\": 43054.786}", "{\"n\": 10203, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3621.64, \"learn_time_ms\": 43100.798}", "{\"n\": 10204, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3629.87, \"learn_time_ms\": 43099.261}", "{\"n\": 10205, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.62, \"learn_time_ms\": 43113.087}", "{\"n\": 10206, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3623.34, \"learn_time_ms\": 43154.154}", "{\"n\": 10207, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.53, \"learn_time_ms\": 43067.513}", "{\"n\": 10208, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.92, \"learn_time_ms\": 43154.881}", "{\"n\": 10209, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3614.92, \"learn_time_ms\": 43066.409}", "{\"n\": 10210, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3621.94, \"learn_time_ms\": 43025.805}", "{\"n\": 10211, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3632.09, \"learn_time_ms\": 42970.263}", "{\"n\": 10212, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3626.7, \"learn_time_ms\": 42962.895}", "{\"n\": 10213, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.99, \"learn_time_ms\": 42934.657}", "{\"n\": 10214, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3629.91, \"learn_time_ms\": 42912.254}", "{\"n\": 10215, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3629.91, \"learn_time_ms\": 42923.668}", "{\"n\": 10216, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.94, \"learn_time_ms\": 42848.694}", "{\"n\": 10217, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.48, \"learn_time_ms\": 43062.156}", "{\"n\": 10218, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.48, \"learn_time_ms\": 43095.951}", "{\"n\": 10219, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.26, \"learn_time_ms\": 43119.32}", "{\"n\": 10220, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.86, \"learn_time_ms\": 43176.981}", "{\"n\": 10221, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.86, \"learn_time_ms\": 43185.142}", "{\"n\": 10222, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3644.86, \"learn_time_ms\": 43164.012}", "{\"n\": 10223, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.45, \"learn_time_ms\": 43254.608}", "{\"n\": 10224, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.7, \"learn_time_ms\": 43314.021}", "{\"n\": 10225, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3648.46, \"learn_time_ms\": 43347.882}", "{\"n\": 10226, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3655.24, \"learn_time_ms\": 43354.895}", "{\"n\": 10227, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.9, \"learn_time_ms\": 43175.95}", "{\"n\": 10228, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.9, \"learn_time_ms\": 43150.829}", "{\"n\": 10229, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3667.62, \"learn_time_ms\": 43132.057}", "{\"n\": 10230, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3687.15, \"learn_time_ms\": 43131.672}", "{\"n\": 10231, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3680.21, \"learn_time_ms\": 43238.558}", "{\"n\": 10232, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.26, \"learn_time_ms\": 43322.338}", "{\"n\": 10233, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3696.26, \"learn_time_ms\": 43171.86}", "{\"n\": 10234, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3694.96, \"learn_time_ms\": 43100.117}", "{\"n\": 10235, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3685.97, \"learn_time_ms\": 43102.69}", "{\"n\": 10236, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3681.19, \"learn_time_ms\": 43043.554}", "{\"n\": 10237, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.64, \"learn_time_ms\": 43092.735}", "{\"n\": 10238, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.78, \"learn_time_ms\": 43067.193}", "{\"n\": 10239, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.78, \"learn_time_ms\": 43023.576}", "{\"n\": 10240, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3677.79, \"learn_time_ms\": 42932.985}", "{\"n\": 10241, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3676.61, \"learn_time_ms\": 42908.454}", "{\"n\": 10242, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.71, \"learn_time_ms\": 42838.699}", "{\"n\": 10243, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3679.71, \"learn_time_ms\": 43043.352}", "{\"n\": 10244, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.98, \"learn_time_ms\": 42947.771}", "{\"n\": 10245, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3673.98, \"learn_time_ms\": 42878.628}", "{\"n\": 10246, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3671.92, \"learn_time_ms\": 42980.543}", "{\"n\": 10247, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3677.1, \"learn_time_ms\": 42940.793}", "{\"n\": 10248, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3682.07, \"learn_time_ms\": 42888.832}", "{\"n\": 10249, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3682.07, \"learn_time_ms\": 43091.755}", "{\"n\": 10250, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3687.2, \"learn_time_ms\": 43231.386}", "{\"n\": 10251, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3697.13, \"learn_time_ms\": 43241.186}", "{\"n\": 10252, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3714.42, \"learn_time_ms\": 43323.982}", "{\"n\": 10253, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3688.17, \"learn_time_ms\": 43184.977}", "{\"n\": 10254, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.62, \"learn_time_ms\": 43306.236}", "{\"n\": 10255, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3689.62, \"learn_time_ms\": 43369.557}", "{\"n\": 10256, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3684.5, \"learn_time_ms\": 43369.728}", "{\"n\": 10257, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3690.54, \"learn_time_ms\": 43510.769}", "{\"n\": 10258, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3680.07, \"learn_time_ms\": 43583.752}", "{\"n\": 10259, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.48, \"learn_time_ms\": 43395.369}", "{\"n\": 10260, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.23, \"learn_time_ms\": 43363.718}", "{\"n\": 10261, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.44, \"learn_time_ms\": 43347.958}", "{\"n\": 10262, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3656.44, \"learn_time_ms\": 43449.548}", "{\"n\": 10263, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.36, \"learn_time_ms\": 43502.134}", "{\"n\": 10264, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3668.56, \"learn_time_ms\": 43496.731}", "{\"n\": 10265, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3658.48, \"learn_time_ms\": 43548.177}", "{\"n\": 10266, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3672.67, \"learn_time_ms\": 43563.766}", "{\"n\": 10267, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.16, \"learn_time_ms\": 43483.674}", "{\"n\": 10268, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3666.16, \"learn_time_ms\": 43419.09}", "{\"n\": 10269, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3675.74, \"learn_time_ms\": 43578.588}", "{\"n\": 10270, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3685.58, \"learn_time_ms\": 43539.034}", "{\"n\": 10271, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3683.79, \"learn_time_ms\": 43467.289}", "{\"n\": 10272, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3669.41, \"learn_time_ms\": 43358.421}", "{\"n\": 10273, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3665.9, \"learn_time_ms\": 43310.765}", "{\"n\": 10274, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3657.46, \"learn_time_ms\": 43250.242}", "{\"n\": 10275, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.0, \"learn_time_ms\": 43210.241}", "{\"n\": 10276, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3651.29, \"learn_time_ms\": 43241.001}", "{\"n\": 10277, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3638.78, \"learn_time_ms\": 43247.842}", "{\"n\": 10278, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3639.77, \"learn_time_ms\": 43353.15}", "{\"n\": 10279, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3642.15, \"learn_time_ms\": 43253.179}", "{\"n\": 10280, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3649.96, \"learn_time_ms\": 43364.65}", "{\"n\": 10281, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3646.35, \"learn_time_ms\": 43493.122}", "{\"n\": 10282, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3650.84, \"learn_time_ms\": 43473.92}", "{\"n\": 10283, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.57, \"learn_time_ms\": 43483.62}", "{\"n\": 10284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.57, \"learn_time_ms\": 43504.797}", "{\"n\": 10285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3624.57, \"learn_time_ms\": 43564.8}", "{\"n\": 10286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3609.67, \"learn_time_ms\": 43439.678}", "{\"n\": 10287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.44, \"learn_time_ms\": 43440.041}", "{\"n\": 10288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3613.91, \"learn_time_ms\": 43360.261}", "{\"n\": 10289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.18, \"learn_time_ms\": 43294.915}", "{\"n\": 10290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.18, \"learn_time_ms\": 43238.928}", "{\"n\": 10291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3618.18, \"learn_time_ms\": 43146.647}", "{\"n\": 10292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3622.0, \"learn_time_ms\": 43193.068}", "{\"n\": 10293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3604.61, \"learn_time_ms\": 43210.015}", "{\"n\": 10294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3602.18, \"learn_time_ms\": 43138.963}", "{\"n\": 10295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3598.83, \"learn_time_ms\": 43154.403}", "{\"n\": 10296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3601.55, \"learn_time_ms\": 43238.948}", "{\"n\": 10297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3599.78, \"learn_time_ms\": 43180.031}", "{\"n\": 10298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3597.71, \"learn_time_ms\": 43312.844}", "{\"n\": 10299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.24, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3577.02, \"learn_time_ms\": 43390.529}", "{\"n\": 10300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 43394.081}", "{\"n\": 10301, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3569.17, \"learn_time_ms\": 43509.219}", "{\"n\": 10302, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.02, \"learn_time_ms\": 43440.95}", "{\"n\": 10303, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.02, \"learn_time_ms\": 43530.107}", "{\"n\": 10304, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3522.06, \"learn_time_ms\": 43574.397}", "{\"n\": 10305, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3514.48, \"learn_time_ms\": 43532.699}", "{\"n\": 10306, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3510.56, \"learn_time_ms\": 43485.984}", "{\"n\": 10307, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3510.56, \"learn_time_ms\": 43462.584}", "{\"n\": 10308, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3510.56, \"learn_time_ms\": 43301.096}", "{\"n\": 10309, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3534.96, \"learn_time_ms\": 43231.136}", "{\"n\": 10310, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.76, \"learn_time_ms\": 43273.823}", "{\"n\": 10311, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.76, \"learn_time_ms\": 43119.294}", "{\"n\": 10312, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.76, \"learn_time_ms\": 43149.357}", "{\"n\": 10313, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.76, \"learn_time_ms\": 43067.055}", "{\"n\": 10314, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3545.3, \"learn_time_ms\": 42984.115}", "{\"n\": 10315, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.71, \"learn_time_ms\": 42966.544}", "{\"n\": 10316, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.71, \"learn_time_ms\": 42906.947}", "{\"n\": 10317, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3531.99, \"learn_time_ms\": 42922.666}", "{\"n\": 10318, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3543.46, \"learn_time_ms\": 42850.848}", "{\"n\": 10319, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3543.46, \"learn_time_ms\": 42941.95}", "{\"n\": 10320, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.12, \"learn_time_ms\": 42919.559}", "{\"n\": 10321, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3524.31, \"learn_time_ms\": 43025.536}", "{\"n\": 10322, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3519.14, \"learn_time_ms\": 42964.904}", "{\"n\": 10323, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3523.95, \"learn_time_ms\": 42977.585}", "{\"n\": 10324, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3529.89, \"learn_time_ms\": 43064.738}", "{\"n\": 10325, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3531.65, \"learn_time_ms\": 42944.613}", "{\"n\": 10326, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3531.65, \"learn_time_ms\": 42996.798}", "{\"n\": 10327, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3534.42, \"learn_time_ms\": 43092.642}", "{\"n\": 10328, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.89, \"learn_time_ms\": 43133.729}", "{\"n\": 10329, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3529.54, \"learn_time_ms\": 43037.744}", "{\"n\": 10330, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3539.33, \"learn_time_ms\": 42934.287}", "{\"n\": 10331, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3513.05, \"learn_time_ms\": 42965.578}", "{\"n\": 10332, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3522.2, \"learn_time_ms\": 42970.923}", "{\"n\": 10333, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3515.41, \"learn_time_ms\": 42927.462}", "{\"n\": 10334, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3515.41, \"learn_time_ms\": 42936.852}", "{\"n\": 10335, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3517.47, \"learn_time_ms\": 42984.25}", "{\"n\": 10336, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3505.98, \"learn_time_ms\": 43012.778}", "{\"n\": 10337, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3497.0, \"learn_time_ms\": 42965.307}", "{\"n\": 10338, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3482.39, \"learn_time_ms\": 43076.145}", "{\"n\": 10339, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3482.39, \"learn_time_ms\": 43115.813}", "{\"n\": 10340, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3483.13, \"learn_time_ms\": 43133.808}", "{\"n\": 10341, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3483.13, \"learn_time_ms\": 43068.187}", "{\"n\": 10342, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3454.58, \"learn_time_ms\": 43229.584}", "{\"n\": 10343, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3458.5, \"learn_time_ms\": 43252.087}", "{\"n\": 10344, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3458.5, \"learn_time_ms\": 43374.74}", "{\"n\": 10345, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3453.38, \"learn_time_ms\": 43435.544}", "{\"n\": 10346, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3443.21, \"learn_time_ms\": 43366.762}", "{\"n\": 10347, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3434.88, \"learn_time_ms\": 43484.958}", "{\"n\": 10348, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3434.9, \"learn_time_ms\": 43461.687}", "{\"n\": 10349, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3426.25, \"learn_time_ms\": 43426.676}", "{\"n\": 10350, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3426.25, \"learn_time_ms\": 43428.299}", "{\"n\": 10351, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3416.06, \"learn_time_ms\": 43356.363}", "{\"n\": 10352, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3411.79, \"learn_time_ms\": 43157.136}", "{\"n\": 10353, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3411.79, \"learn_time_ms\": 43075.301}", "{\"n\": 10354, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3409.25, \"learn_time_ms\": 42888.341}", "{\"n\": 10355, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3408.47, \"learn_time_ms\": 42893.135}", "{\"n\": 10356, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3416.21, \"learn_time_ms\": 42940.316}", "{\"n\": 10357, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3412.45, \"learn_time_ms\": 42888.51}", "{\"n\": 10358, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3423.71, \"learn_time_ms\": 42833.591}", "{\"n\": 10359, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3413.69, \"learn_time_ms\": 42817.759}", "{\"n\": 10360, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3413.69, \"learn_time_ms\": 42805.081}", "{\"n\": 10361, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3404.37, \"learn_time_ms\": 42736.411}", "{\"n\": 10362, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.94, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3400.27, \"learn_time_ms\": 42788.602}", "{\"n\": 10363, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3397.52, \"learn_time_ms\": 42730.73}", "{\"n\": 10364, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3397.52, \"learn_time_ms\": 42751.752}", "{\"n\": 10365, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3406.22, \"learn_time_ms\": 42695.908}", "{\"n\": 10366, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.14, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3388.35, \"learn_time_ms\": 42697.658}", "{\"n\": 10367, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.33, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3395.35, \"learn_time_ms\": 42590.035}", "{\"n\": 10368, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3391.94, \"learn_time_ms\": 42571.265}", "{\"n\": 10369, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3376.55, \"learn_time_ms\": 42634.43}", "{\"n\": 10370, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3376.55, \"learn_time_ms\": 42598.35}", "{\"n\": 10371, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.41, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3387.67, \"learn_time_ms\": 42819.558}", "{\"n\": 10372, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3422.24, \"learn_time_ms\": 42866.393}", "{\"n\": 10373, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -5.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3418.14, \"learn_time_ms\": 42958.52}", "{\"n\": 10374, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3432.41, \"learn_time_ms\": 42950.355}", "{\"n\": 10375, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3432.41, \"learn_time_ms\": 43032.65}", "{\"n\": 10376, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.84, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3431.88, \"learn_time_ms\": 42952.463}", "{\"n\": 10377, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3435.49, \"learn_time_ms\": 43034.957}", "{\"n\": 10378, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3435.49, \"learn_time_ms\": 43121.698}", "{\"n\": 10379, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.13, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3394.02, \"learn_time_ms\": 43112.55}", "{\"n\": 10380, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3401.41, \"learn_time_ms\": 43123.075}", "{\"n\": 10381, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3387.84, \"learn_time_ms\": 43000.617}", "{\"n\": 10382, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.37, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3387.84, \"learn_time_ms\": 42954.359}", "{\"n\": 10383, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3377.05, \"learn_time_ms\": 42911.87}", "{\"n\": 10384, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.55, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3377.39, \"learn_time_ms\": 42979.36}", "{\"n\": 10385, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.54, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3374.98, \"learn_time_ms\": 42902.387}", "{\"n\": 10386, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.49, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3388.12, \"learn_time_ms\": 42865.773}", "{\"n\": 10387, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3399.02, \"learn_time_ms\": 42741.819}", "{\"n\": 10388, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3406.61, \"learn_time_ms\": 42595.926}", "{\"n\": 10389, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.61, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3406.61, \"learn_time_ms\": 42594.928}", "{\"n\": 10390, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.76, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3412.75, \"learn_time_ms\": 42619.327}", "{\"n\": 10391, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.71, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3419.11, \"learn_time_ms\": 42579.551}", "{\"n\": 10392, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3424.53, \"learn_time_ms\": 42605.254}", "{\"n\": 10393, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3424.53, \"learn_time_ms\": 42572.75}", "{\"n\": 10394, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3431.08, \"learn_time_ms\": 42507.118}", "{\"n\": 10395, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3427.62, \"learn_time_ms\": 42596.502}", "{\"n\": 10396, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3427.29, \"learn_time_ms\": 42723.126}", "{\"n\": 10397, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3433.97, \"learn_time_ms\": 42885.426}", "{\"n\": 10398, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3433.97, \"learn_time_ms\": 43002.332}", "{\"n\": 10399, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.74, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3441.21, \"learn_time_ms\": 42903.887}", "{\"n\": 10400, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3399.35, \"learn_time_ms\": 42925.779}", "{\"n\": 10401, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3411.43, \"learn_time_ms\": 42921.913}", "{\"n\": 10402, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3420.96, \"learn_time_ms\": 42889.748}", "{\"n\": 10403, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3415.36, \"learn_time_ms\": 42988.391}", "{\"n\": 10404, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3415.36, \"learn_time_ms\": 43020.307}", "{\"n\": 10405, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.01, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3408.17, \"learn_time_ms\": 42877.346}", "{\"n\": 10406, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.1, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3404.26, \"learn_time_ms\": 42873.304}", "{\"n\": 10407, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3410.96, \"learn_time_ms\": 42750.718}", "{\"n\": 10408, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3413.95, \"learn_time_ms\": 42668.141}", "{\"n\": 10409, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3431.5, \"learn_time_ms\": 42730.584}", "{\"n\": 10410, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3431.0, \"learn_time_ms\": 42636.407}", "{\"n\": 10411, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.86, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3431.0, \"learn_time_ms\": 42735.632}", "{\"n\": 10412, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3428.65, \"learn_time_ms\": 42684.417}", "{\"n\": 10413, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3428.65, \"learn_time_ms\": 42554.437}", "{\"n\": 10414, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3422.53, \"learn_time_ms\": 42527.704}", "{\"n\": 10415, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3428.21, \"learn_time_ms\": 42588.652}", "{\"n\": 10416, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3439.67, \"learn_time_ms\": 42628.966}", "{\"n\": 10417, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3442.41, \"learn_time_ms\": 42640.827}", "{\"n\": 10418, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3431.1, \"learn_time_ms\": 42694.299}", "{\"n\": 10419, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3431.1, \"learn_time_ms\": 42716.544}", "{\"n\": 10420, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.16, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3434.42, \"learn_time_ms\": 42863.965}", "{\"n\": 10421, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3435.42, \"learn_time_ms\": 42817.225}", "{\"n\": 10422, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.02, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3439.04, \"learn_time_ms\": 42945.525}", "{\"n\": 10423, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3440.7, \"learn_time_ms\": 43048.66}", "{\"n\": 10424, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.73, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3442.67, \"learn_time_ms\": 43002.286}", "{\"n\": 10425, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3432.88, \"learn_time_ms\": 42925.48}", "{\"n\": 10426, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3431.51, \"learn_time_ms\": 42912.487}", "{\"n\": 10427, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3420.03, \"learn_time_ms\": 42996.098}", "{\"n\": 10428, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.05, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3413.13, \"learn_time_ms\": 42983.094}", "{\"n\": 10429, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.97, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3422.64, \"learn_time_ms\": 42971.508}", "{\"n\": 10430, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3401.98, \"learn_time_ms\": 42923.725}", "{\"n\": 10431, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.08, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3401.98, \"learn_time_ms\": 42869.87}", "{\"n\": 10432, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.14, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3396.09, \"learn_time_ms\": 42787.533}", "{\"n\": 10433, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3400.62, \"learn_time_ms\": 42922.183}", "{\"n\": 10434, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3394.34, \"learn_time_ms\": 42934.226}", "{\"n\": 10435, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -6.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3386.67, \"learn_time_ms\": 43024.222}", "{\"n\": 10436, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3411.96, \"learn_time_ms\": 42972.151}", "{\"n\": 10437, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.92, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3411.96, \"learn_time_ms\": 42782.069}", "{\"n\": 10438, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.75, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3413.06, \"learn_time_ms\": 42812.481}", "{\"n\": 10439, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3408.01, \"learn_time_ms\": 42784.481}", "{\"n\": 10440, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3410.13, \"learn_time_ms\": 42741.455}", "{\"n\": 10441, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.56, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3427.14, \"learn_time_ms\": 42774.419}", "{\"n\": 10442, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3420.67, \"learn_time_ms\": 42804.202}", "{\"n\": 10443, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3420.67, \"learn_time_ms\": 42684.788}", "{\"n\": 10444, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3424.03, \"learn_time_ms\": 42670.659}", "{\"n\": 10445, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3418.64, \"learn_time_ms\": 42733.198}", "{\"n\": 10446, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3427.99, \"learn_time_ms\": 42737.642}", "{\"n\": 10447, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3431.02, \"learn_time_ms\": 42967.375}", "{\"n\": 10448, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3432.88, \"learn_time_ms\": 42943.121}", "{\"n\": 10449, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3473.96, \"learn_time_ms\": 43032.542}", "{\"n\": 10450, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3451.4, \"learn_time_ms\": 43108.505}", "{\"n\": 10451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3451.4, \"learn_time_ms\": 43118.126}", "{\"n\": 10452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3449.61, \"learn_time_ms\": 43060.832}", "{\"n\": 10453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.63, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3458.57, \"learn_time_ms\": 43185.727}", "{\"n\": 10454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.69, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3443.67, \"learn_time_ms\": 43301.784}", "{\"n\": 10455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3433.69, \"learn_time_ms\": 43260.913}", "{\"n\": 10456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.79, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3424.01, \"learn_time_ms\": 43323.366}", "{\"n\": 10457, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3415.22, \"learn_time_ms\": 43218.228}", "{\"n\": 10458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3408.74, \"learn_time_ms\": 43204.001}", "{\"n\": 10459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3408.74, \"learn_time_ms\": 43217.066}", "{\"n\": 10460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3406.23, \"learn_time_ms\": 43135.187}", "{\"n\": 10461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3401.27, \"learn_time_ms\": 43143.206}", "{\"n\": 10462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.89, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3378.74, \"learn_time_ms\": 43204.538}", "{\"n\": 10463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3361.67, \"learn_time_ms\": 43072.882}", "{\"n\": 10464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3359.07, \"learn_time_ms\": 43070.335}", "{\"n\": 10465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3362.34, \"learn_time_ms\": 43024.194}", "{\"n\": 10466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.64, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3378.43, \"learn_time_ms\": 42871.882}", "{\"n\": 10467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3357.25, \"learn_time_ms\": 43021.068}", "{\"n\": 10468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -5.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3338.06, \"learn_time_ms\": 43046.156}", "{\"n\": 10469, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.77, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3351.51, \"learn_time_ms\": 42986.273}", "{\"n\": 10470, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3343.63, \"learn_time_ms\": 42987.81}", "{\"n\": 10471, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.65, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3343.63, \"learn_time_ms\": 42996.48}", "{\"n\": 10472, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3349.53, \"learn_time_ms\": 42949.257}", "{\"n\": 10473, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3349.53, \"learn_time_ms\": 42985.126}", "{\"n\": 10474, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3354.2, \"learn_time_ms\": 42882.439}", "{\"n\": 10475, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3358.14, \"learn_time_ms\": 43000.593}", "{\"n\": 10476, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.34, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3358.14, \"learn_time_ms\": 43000.615}", "{\"n\": 10477, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3346.9, \"learn_time_ms\": 42806.133}", "{\"n\": 10478, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.31, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3346.9, \"learn_time_ms\": 42667.857}", "{\"n\": 10479, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.24, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3350.57, \"learn_time_ms\": 42659.758}", "{\"n\": 10480, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.25, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3347.87, \"learn_time_ms\": 42648.595}", "{\"n\": 10481, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -5.0, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3349.49, \"learn_time_ms\": 42694.541}", "{\"n\": 10482, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3352.84, \"learn_time_ms\": 42739.512}", "{\"n\": 10483, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3359.03, \"learn_time_ms\": 42625.239}", "{\"n\": 10484, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3358.73, \"learn_time_ms\": 42547.684}", "{\"n\": 10485, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.9, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3370.21, \"learn_time_ms\": 42421.864}", "{\"n\": 10486, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3387.0, \"learn_time_ms\": 42581.179}", "{\"n\": 10487, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3397.38, \"learn_time_ms\": 42520.09}", "{\"n\": 10488, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3416.25, \"learn_time_ms\": 42682.895}", "{\"n\": 10489, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3424.09, \"learn_time_ms\": 42651.726}", "{\"n\": 10490, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3424.09, \"learn_time_ms\": 42659.522}", "{\"n\": 10491, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3415.89, \"learn_time_ms\": 42696.585}", "{\"n\": 10492, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.51, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3413.48, \"learn_time_ms\": 42663.265}", "{\"n\": 10493, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3419.07, \"learn_time_ms\": 42678.25}", "{\"n\": 10494, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3411.56, \"learn_time_ms\": 42795.396}", "{\"n\": 10495, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.82, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3411.56, \"learn_time_ms\": 42809.635}", "{\"n\": 10496, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3418.35, \"learn_time_ms\": 42751.392}", "{\"n\": 10497, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3435.83, \"learn_time_ms\": 42763.824}", "{\"n\": 10498, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3433.75, \"learn_time_ms\": 42752.683}", "{\"n\": 10499, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3433.72, \"learn_time_ms\": 42778.516}", "{\"n\": 10500, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3432.89, \"learn_time_ms\": 42847.335}", "{\"n\": 10501, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3432.89, \"learn_time_ms\": 42739.056}", "{\"n\": 10502, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3449.48, \"learn_time_ms\": 42725.254}", "{\"n\": 10503, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3462.86, \"learn_time_ms\": 42762.405}", "{\"n\": 10504, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3442.43, \"learn_time_ms\": 42719.656}", "{\"n\": 10505, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3460.55, \"learn_time_ms\": 42813.997}", "{\"n\": 10506, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3460.55, \"learn_time_ms\": 43027.98}", "{\"n\": 10507, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3462.25, \"learn_time_ms\": 43151.239}", "{\"n\": 10508, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3454.89, \"learn_time_ms\": 43075.371}", "{\"n\": 10509, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3436.85, \"learn_time_ms\": 43136.878}", "{\"n\": 10510, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3440.18, \"learn_time_ms\": 43238.786}", "{\"n\": 10511, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3451.94, \"learn_time_ms\": 43253.191}", "{\"n\": 10512, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3447.82, \"learn_time_ms\": 43258.199}", "{\"n\": 10513, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3436.68, \"learn_time_ms\": 43230.109}", "{\"n\": 10514, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3429.34, \"learn_time_ms\": 43361.705}", "{\"n\": 10515, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3429.34, \"learn_time_ms\": 43182.608}", "{\"n\": 10516, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3433.69, \"learn_time_ms\": 42948.606}", "{\"n\": 10517, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3416.91, \"learn_time_ms\": 42936.364}", "{\"n\": 10518, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3419.84, \"learn_time_ms\": 42974.62}", "{\"n\": 10519, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3414.81, \"learn_time_ms\": 42840.21}", "{\"n\": 10520, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3406.76, \"learn_time_ms\": 42698.095}", "{\"n\": 10521, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3400.52, \"learn_time_ms\": 42632.808}", "{\"n\": 10522, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3416.21, \"learn_time_ms\": 42711.983}", "{\"n\": 10523, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.66, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3412.93, \"learn_time_ms\": 42759.137}", "{\"n\": 10524, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3418.78, \"learn_time_ms\": 42670.259}", "{\"n\": 10525, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3436.36, \"learn_time_ms\": 42643.679}", "{\"n\": 10526, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3443.0, \"learn_time_ms\": 42626.273}", "{\"n\": 10527, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3443.0, \"learn_time_ms\": 42574.505}", "{\"n\": 10528, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.45, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3441.61, \"learn_time_ms\": 42539.261}", "{\"n\": 10529, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3423.04, \"learn_time_ms\": 42541.463}", "{\"n\": 10530, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3425.93, \"learn_time_ms\": 42616.253}", "{\"n\": 10531, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3413.01, \"learn_time_ms\": 42570.219}", "{\"n\": 10532, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3417.91, \"learn_time_ms\": 42509.552}", "{\"n\": 10533, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3417.91, \"learn_time_ms\": 42562.261}", "{\"n\": 10534, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3417.91, \"learn_time_ms\": 42589.967}", "{\"n\": 10535, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3451.46, \"learn_time_ms\": 42705.529}", "{\"n\": 10536, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3466.37, \"learn_time_ms\": 42848.434}", "{\"n\": 10537, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3457.79, \"learn_time_ms\": 42833.564}", "{\"n\": 10538, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3454.63, \"learn_time_ms\": 42899.702}", "{\"n\": 10539, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3454.63, \"learn_time_ms\": 42965.752}", "{\"n\": 10540, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3474.48, \"learn_time_ms\": 42882.555}", "{\"n\": 10541, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3482.46, \"learn_time_ms\": 43016.92}", "{\"n\": 10542, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3482.46, \"learn_time_ms\": 43004.972}", "{\"n\": 10543, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3484.77, \"learn_time_ms\": 42957.826}", "{\"n\": 10544, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3496.7, \"learn_time_ms\": 42938.763}", "{\"n\": 10545, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3496.7, \"learn_time_ms\": 42905.792}", "{\"n\": 10546, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3466.02, \"learn_time_ms\": 42802.901}", "{\"n\": 10547, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3469.16, \"learn_time_ms\": 42809.734}", "{\"n\": 10548, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3468.71, \"learn_time_ms\": 42863.651}", "{\"n\": 10549, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3480.39, \"learn_time_ms\": 42841.737}", "{\"n\": 10550, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3480.39, \"learn_time_ms\": 42816.998}", "{\"n\": 10551, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3466.81, \"learn_time_ms\": 42717.123}", "{\"n\": 10552, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.47, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3466.81, \"learn_time_ms\": 42765.281}", "{\"n\": 10553, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3469.98, \"learn_time_ms\": 42749.225}", "{\"n\": 10554, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3465.63, \"learn_time_ms\": 42741.109}", "{\"n\": 10555, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3472.38, \"learn_time_ms\": 42791.583}", "{\"n\": 10556, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3472.38, \"learn_time_ms\": 42842.81}", "{\"n\": 10557, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.54, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3472.38, \"learn_time_ms\": 42856.449}", "{\"n\": 10558, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3472.07, \"learn_time_ms\": 42792.495}", "{\"n\": 10559, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3454.97, \"learn_time_ms\": 42867.682}", "{\"n\": 10560, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3455.96, \"learn_time_ms\": 42976.56}", "{\"n\": 10561, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3450.52, \"learn_time_ms\": 43006.721}", "{\"n\": 10562, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3450.52, \"learn_time_ms\": 42956.269}", "{\"n\": 10563, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3450.52, \"learn_time_ms\": 42955.096}", "{\"n\": 10564, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3462.64, \"learn_time_ms\": 42995.306}", "{\"n\": 10565, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3464.83, \"learn_time_ms\": 42937.336}", "{\"n\": 10566, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3471.75, \"learn_time_ms\": 42753.764}", "{\"n\": 10567, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3493.39, \"learn_time_ms\": 42870.32}", "{\"n\": 10568, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3493.39, \"learn_time_ms\": 42878.844}", "{\"n\": 10569, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3493.39, \"learn_time_ms\": 42861.185}", "{\"n\": 10570, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3498.7, \"learn_time_ms\": 42968.227}", "{\"n\": 10571, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3519.89, \"learn_time_ms\": 43081.641}", "{\"n\": 10572, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3520.75, \"learn_time_ms\": 43173.017}", "{\"n\": 10573, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3521.21, \"learn_time_ms\": 43228.61}", "{\"n\": 10574, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3528.63, \"learn_time_ms\": 43249.595}", "{\"n\": 10575, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3528.63, \"learn_time_ms\": 43273.871}", "{\"n\": 10576, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3504.74, \"learn_time_ms\": 43423.715}", "{\"n\": 10577, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3516.77, \"learn_time_ms\": 43430.194}", "{\"n\": 10578, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3508.87, \"learn_time_ms\": 43360.058}", "{\"n\": 10579, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3508.87, \"learn_time_ms\": 43440.295}", "{\"n\": 10580, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3508.87, \"learn_time_ms\": 43393.158}", "{\"n\": 10581, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3510.8, \"learn_time_ms\": 43264.675}", "{\"n\": 10582, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3519.98, \"learn_time_ms\": 43091.388}", "{\"n\": 10583, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3524.14, \"learn_time_ms\": 43190.026}", "{\"n\": 10584, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3528.11, \"learn_time_ms\": 43122.071}", "{\"n\": 10585, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3528.11, \"learn_time_ms\": 43173.249}", "{\"n\": 10586, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3528.11, \"learn_time_ms\": 43196.231}", "{\"n\": 10587, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3524.68, \"learn_time_ms\": 43110.71}", "{\"n\": 10588, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3512.04, \"learn_time_ms\": 43129.756}", "{\"n\": 10589, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3517.47, \"learn_time_ms\": 42996.222}", "{\"n\": 10590, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3517.47, \"learn_time_ms\": 42925.898}", "{\"n\": 10591, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3517.47, \"learn_time_ms\": 43051.231}", "{\"n\": 10592, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3517.47, \"learn_time_ms\": 43258.841}", "{\"n\": 10593, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3510.2, \"learn_time_ms\": 43135.401}", "{\"n\": 10594, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3500.32, \"learn_time_ms\": 43092.497}", "{\"n\": 10595, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3508.94, \"learn_time_ms\": 43048.263}", "{\"n\": 10596, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3504.81, \"learn_time_ms\": 42958.065}", "{\"n\": 10597, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3504.81, \"learn_time_ms\": 42873.594}", "{\"n\": 10598, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3482.08, \"learn_time_ms\": 42936.456}", "{\"n\": 10599, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3474.27, \"learn_time_ms\": 42969.97}", "{\"n\": 10600, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3474.64, \"learn_time_ms\": 42909.393}", "{\"n\": 10601, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3502.84, \"learn_time_ms\": 43002.195}", "{\"n\": 10602, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3502.84, \"learn_time_ms\": 42918.878}", "{\"n\": 10603, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3502.84, \"learn_time_ms\": 42976.343}", "{\"n\": 10604, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3500.89, \"learn_time_ms\": 43099.586}", "{\"n\": 10605, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3492.38, \"learn_time_ms\": 43077.364}", "{\"n\": 10606, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3497.91, \"learn_time_ms\": 43152.729}", "{\"n\": 10607, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3493.2, \"learn_time_ms\": 43206.454}", "{\"n\": 10608, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3493.2, \"learn_time_ms\": 43167.328}", "{\"n\": 10609, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3492.97, \"learn_time_ms\": 43266.594}", "{\"n\": 10610, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3483.68, \"learn_time_ms\": 43258.049}", "{\"n\": 10611, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3481.21, \"learn_time_ms\": 43195.316}", "{\"n\": 10612, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3473.8, \"learn_time_ms\": 43199.774}", "{\"n\": 10613, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3480.9, \"learn_time_ms\": 43125.826}", "{\"n\": 10614, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3471.4, \"learn_time_ms\": 43071.548}", "{\"n\": 10615, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3471.4, \"learn_time_ms\": 43160.002}", "{\"n\": 10616, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3470.86, \"learn_time_ms\": 43143.352}", "{\"n\": 10617, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3470.29, \"learn_time_ms\": 43317.235}", "{\"n\": 10618, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3482.41, \"learn_time_ms\": 43308.104}", "{\"n\": 10619, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.99, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3482.14, \"learn_time_ms\": 43225.262}", "{\"n\": 10620, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3478.42, \"learn_time_ms\": 43282.602}", "{\"n\": 10621, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3472.39, \"learn_time_ms\": 43105.413}", "{\"n\": 10622, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3467.98, \"learn_time_ms\": 43089.894}", "{\"n\": 10623, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3467.98, \"learn_time_ms\": 43054.819}", "{\"n\": 10624, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3481.61, \"learn_time_ms\": 43014.554}", "{\"n\": 10625, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3489.34, \"learn_time_ms\": 42998.396}", "{\"n\": 10626, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3490.2, \"learn_time_ms\": 42968.979}", "{\"n\": 10627, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3485.84, \"learn_time_ms\": 42868.358}", "{\"n\": 10628, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3484.99, \"learn_time_ms\": 42881.839}", "{\"n\": 10629, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3484.42, \"learn_time_ms\": 42862.136}", "{\"n\": 10630, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3484.42, \"learn_time_ms\": 42866.288}", "{\"n\": 10631, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3482.6, \"learn_time_ms\": 42955.433}", "{\"n\": 10632, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3498.67, \"learn_time_ms\": 42928.245}", "{\"n\": 10633, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3498.67, \"learn_time_ms\": 43072.237}", "{\"n\": 10634, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3505.58, \"learn_time_ms\": 43105.014}", "{\"n\": 10635, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3505.58, \"learn_time_ms\": 43129.37}", "{\"n\": 10636, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3504.46, \"learn_time_ms\": 43175.335}", "{\"n\": 10637, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3504.46, \"learn_time_ms\": 43154.16}", "{\"n\": 10638, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3514.36, \"learn_time_ms\": 43153.631}", "{\"n\": 10639, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3527.69, \"learn_time_ms\": 43254.905}", "{\"n\": 10640, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3514.76, \"learn_time_ms\": 43231.496}", "{\"n\": 10641, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3514.76, \"learn_time_ms\": 43249.535}", "{\"n\": 10642, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3514.76, \"learn_time_ms\": 43292.784}", "{\"n\": 10643, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3512.58, \"learn_time_ms\": 43228.145}", "{\"n\": 10644, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3527.2, \"learn_time_ms\": 43235.64}", "{\"n\": 10645, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3529.75, \"learn_time_ms\": 43313.023}", "{\"n\": 10646, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3511.89, \"learn_time_ms\": 43275.568}", "{\"n\": 10647, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3511.89, \"learn_time_ms\": 43260.268}", "{\"n\": 10648, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3511.89, \"learn_time_ms\": 43327.135}", "{\"n\": 10649, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3520.28, \"learn_time_ms\": 43263.364}", "{\"n\": 10650, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3525.63, \"learn_time_ms\": 43202.132}", "{\"n\": 10651, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3526.98, \"learn_time_ms\": 43212.433}", "{\"n\": 10652, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3547.67, \"learn_time_ms\": 43177.732}", "{\"n\": 10653, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3547.67, \"learn_time_ms\": 43185.814}", "{\"n\": 10654, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3547.67, \"learn_time_ms\": 43301.556}", "{\"n\": 10655, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3547.56, \"learn_time_ms\": 43145.993}", "{\"n\": 10656, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3541.82, \"learn_time_ms\": 43130.898}", "{\"n\": 10657, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3540.27, \"learn_time_ms\": 43158.698}", "{\"n\": 10658, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3548.59, \"learn_time_ms\": 43032.961}", "{\"n\": 10659, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3563.32, \"learn_time_ms\": 43159.954}", "{\"n\": 10660, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3563.32, \"learn_time_ms\": 43225.892}", "{\"n\": 10661, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3565.67, \"learn_time_ms\": 43168.129}", "{\"n\": 10662, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3563.67, \"learn_time_ms\": 43202.54}", "{\"n\": 10663, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3574.36, \"learn_time_ms\": 43176.273}", "{\"n\": 10664, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3595.8, \"learn_time_ms\": 43053.91}", "{\"n\": 10665, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3591.78, \"learn_time_ms\": 43055.261}", "{\"n\": 10666, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3597.59, \"learn_time_ms\": 43130.664}", "{\"n\": 10667, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3597.59, \"learn_time_ms\": 43102.464}", "{\"n\": 10668, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.17, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3597.59, \"learn_time_ms\": 43241.502}", "{\"n\": 10669, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3618.16, \"learn_time_ms\": 43100.361}", "{\"n\": 10670, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3620.64, \"learn_time_ms\": 43177.423}", "{\"n\": 10671, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3616.92, \"learn_time_ms\": 43193.944}", "{\"n\": 10672, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3626.81, \"learn_time_ms\": 43154.253}", "{\"n\": 10673, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3626.81, \"learn_time_ms\": 43153.098}", "{\"n\": 10674, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3631.48, \"learn_time_ms\": 43193.805}", "{\"n\": 10675, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.58, \"learn_time_ms\": 43194.028}", "{\"n\": 10676, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.76, \"learn_time_ms\": 43117.433}", "{\"n\": 10677, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3649.65, \"learn_time_ms\": 43174.943}", "{\"n\": 10678, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.47, \"learn_time_ms\": 43073.706}", "{\"n\": 10679, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3650.47, \"learn_time_ms\": 43145.216}", "{\"n\": 10680, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3651.48, \"learn_time_ms\": 43105.077}", "{\"n\": 10681, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3657.49, \"learn_time_ms\": 43230.966}", "{\"n\": 10682, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3657.49, \"learn_time_ms\": 43287.697}", "{\"n\": 10683, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3653.86, \"learn_time_ms\": 43269.284}", "{\"n\": 10684, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3653.86, \"learn_time_ms\": 43347.44}", "{\"n\": 10685, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3653.86, \"learn_time_ms\": 43380.645}", "{\"n\": 10686, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3670.35, \"learn_time_ms\": 43458.128}", "{\"n\": 10687, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3681.3, \"learn_time_ms\": 43294.546}", "{\"n\": 10688, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.51, \"learn_time_ms\": 43363.982}", "{\"n\": 10689, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.89, \"learn_time_ms\": 43284.547}", "{\"n\": 10690, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.33, \"learn_time_ms\": 43173.467}", "{\"n\": 10691, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.71, \"learn_time_ms\": 43023.212}", "{\"n\": 10692, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.98, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3689.37, \"learn_time_ms\": 42942.479}", "{\"n\": 10693, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3698.46, \"learn_time_ms\": 43007.598}", "{\"n\": 10694, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.24, \"learn_time_ms\": 42932.056}", "{\"n\": 10695, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3711.24, \"learn_time_ms\": 42863.364}", "{\"n\": 10696, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3699.44, \"learn_time_ms\": 42741.132}", "{\"n\": 10697, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3702.51, \"learn_time_ms\": 42788.469}", "{\"n\": 10698, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3685.19, \"learn_time_ms\": 42740.802}", "{\"n\": 10699, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3685.19, \"learn_time_ms\": 42648.659}", "{\"n\": 10700, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3684.97, \"learn_time_ms\": 42712.169}", "{\"n\": 10701, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3680.93, \"learn_time_ms\": 42713.034}", "{\"n\": 10702, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3672.57, \"learn_time_ms\": 42748.945}", "{\"n\": 10703, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.76, \"learn_time_ms\": 42678.877}", "{\"n\": 10704, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3683.76, \"learn_time_ms\": 42574.954}", "{\"n\": 10705, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.91, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3699.93, \"learn_time_ms\": 42599.016}", "{\"n\": 10706, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3690.5, \"learn_time_ms\": 42687.51}", "{\"n\": 10707, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3690.5, \"learn_time_ms\": 42741.37}", "{\"n\": 10708, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3671.27, \"learn_time_ms\": 42692.075}", "{\"n\": 10709, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3662.92, \"learn_time_ms\": 42747.343}", "{\"n\": 10710, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3657.29, \"learn_time_ms\": 42651.133}", "{\"n\": 10711, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3648.2, \"learn_time_ms\": 42642.278}", "{\"n\": 10712, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3637.47, \"learn_time_ms\": 42691.767}", "{\"n\": 10713, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.63, \"learn_time_ms\": 42737.442}", "{\"n\": 10714, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.63, \"learn_time_ms\": 42780.619}", "{\"n\": 10715, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.14, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3611.14, \"learn_time_ms\": 42813.497}", "{\"n\": 10716, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.04, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3621.21, \"learn_time_ms\": 42820.23}", "{\"n\": 10717, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.07, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.08, \"learn_time_ms\": 42844.202}", "{\"n\": 10718, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.18, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3612.79, \"learn_time_ms\": 42897.196}", "{\"n\": 10719, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3614.08, \"learn_time_ms\": 42947.324}", "{\"n\": 10720, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3604.43, \"learn_time_ms\": 43058.629}", "{\"n\": 10721, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3618.93, \"learn_time_ms\": 43186.636}", "{\"n\": 10722, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3630.73, \"learn_time_ms\": 43099.404}", "{\"n\": 10723, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.2, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3613.45, \"learn_time_ms\": 43059.323}", "{\"n\": 10724, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.62, \"learn_time_ms\": 43108.455}", "{\"n\": 10725, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3620.62, \"learn_time_ms\": 43053.09}", "{\"n\": 10726, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3622.1, \"learn_time_ms\": 42985.941}", "{\"n\": 10727, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3619.26, \"learn_time_ms\": 43038.497}", "{\"n\": 10728, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3619.26, \"learn_time_ms\": 42975.851}", "{\"n\": 10729, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.84, \"learn_time_ms\": 42991.832}", "{\"n\": 10730, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3606.84, \"learn_time_ms\": 42958.383}", "{\"n\": 10731, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3625.51, \"learn_time_ms\": 42852.32}", "{\"n\": 10732, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3619.31, \"learn_time_ms\": 42886.889}", "{\"n\": 10733, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3619.31, \"learn_time_ms\": 42769.151}", "{\"n\": 10734, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3625.43, \"learn_time_ms\": 42754.608}", "{\"n\": 10735, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.93, \"learn_time_ms\": 42838.973}", "{\"n\": 10736, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3631.93, \"learn_time_ms\": 42881.596}", "{\"n\": 10737, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3625.7, \"learn_time_ms\": 42789.182}", "{\"n\": 10738, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3622.84, \"learn_time_ms\": 42773.433}", "{\"n\": 10739, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3619.58, \"learn_time_ms\": 42756.169}", "{\"n\": 10740, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3619.58, \"learn_time_ms\": 42852.089}", "{\"n\": 10741, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3611.63, \"learn_time_ms\": 42806.906}", "{\"n\": 10742, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3605.68, \"learn_time_ms\": 42769.63}", "{\"n\": 10743, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3595.92, \"learn_time_ms\": 43015.606}", "{\"n\": 10744, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3600.43, \"learn_time_ms\": 42924.012}", "{\"n\": 10745, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.21, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3600.43, \"learn_time_ms\": 42945.536}", "{\"n\": 10746, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.19, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3605.81, \"learn_time_ms\": 42825.902}", "{\"n\": 10747, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3603.02, \"learn_time_ms\": 42892.583}", "{\"n\": 10748, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 8.0, \"episode_len_mean\": 3603.02, \"learn_time_ms\": 42958.894}", "{\"n\": 10749, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3605.56, \"learn_time_ms\": 42872.307}", "{\"n\": 10750, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3601.23, \"learn_time_ms\": 42833.341}", "{\"n\": 10751, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.09, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3602.63, \"learn_time_ms\": 42837.299}", "{\"n\": 10752, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3595.02, \"learn_time_ms\": 42855.782}", "{\"n\": 10753, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3593.47, \"learn_time_ms\": 42803.226}", "{\"n\": 10754, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3597.35, \"learn_time_ms\": 42789.414}", "{\"n\": 10755, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.15, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.92, \"learn_time_ms\": 42752.949}", "{\"n\": 10756, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3592.54, \"learn_time_ms\": 42857.769}", "{\"n\": 10757, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3592.54, \"learn_time_ms\": 42771.19}", "{\"n\": 10758, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.4, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3592.54, \"learn_time_ms\": 42883.731}", "{\"n\": 10759, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.3, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3589.92, \"learn_time_ms\": 42952.916}", "{\"n\": 10760, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.53, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3563.08, \"learn_time_ms\": 42905.94}", "{\"n\": 10761, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3584.09, \"learn_time_ms\": 43048.064}", "{\"n\": 10762, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3584.09, \"learn_time_ms\": 43022.25}", "{\"n\": 10763, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.32, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3584.09, \"learn_time_ms\": 42938.289}", "{\"n\": 10764, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.41, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3570.81, \"learn_time_ms\": 43014.567}", "{\"n\": 10765, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.58, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3566.25, \"learn_time_ms\": 42925.377}", "{\"n\": 10766, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.49, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3564.42, \"learn_time_ms\": 42936.154}", "{\"n\": 10767, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3558.33, \"learn_time_ms\": 42915.992}", "{\"n\": 10768, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3558.33, \"learn_time_ms\": 42737.576}", "{\"n\": 10769, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3556.92, \"learn_time_ms\": 42726.312}", "{\"n\": 10770, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.52, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3556.92, \"learn_time_ms\": 42787.207}", "{\"n\": 10771, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3554.31, \"learn_time_ms\": 42690.668}", "{\"n\": 10772, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3559.86, \"learn_time_ms\": 42722.417}", "{\"n\": 10773, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.61, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3559.86, \"learn_time_ms\": 42851.067}", "{\"n\": 10774, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3572.11, \"learn_time_ms\": 42870.82}", "{\"n\": 10775, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.6, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3572.11, \"learn_time_ms\": 42958.498}", "{\"n\": 10776, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.48, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3567.31, \"learn_time_ms\": 42902.502}", "{\"n\": 10777, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.27, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3559.94, \"learn_time_ms\": 43022.033}", "{\"n\": 10778, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3548.26, \"learn_time_ms\": 43183.473}", "{\"n\": 10779, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.37, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3548.26, \"learn_time_ms\": 43148.426}", "{\"n\": 10780, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3550.4, \"learn_time_ms\": 43180.291}", "{\"n\": 10781, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.26, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3550.4, \"learn_time_ms\": 43199.804}", "{\"n\": 10782, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -4.31, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3541.36, \"learn_time_ms\": 43241.029}", "{\"n\": 10783, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.92, \"learn_time_ms\": 43132.987}", "{\"n\": 10784, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3554.53, \"learn_time_ms\": 43117.552}", "{\"n\": 10785, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3554.53, \"learn_time_ms\": 43030.688}", "{\"n\": 10786, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3570.81, \"learn_time_ms\": 43124.824}", "{\"n\": 10787, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3582.41, \"learn_time_ms\": 43012.524}", "{\"n\": 10788, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.14, \"learn_time_ms\": 43011.982}", "{\"n\": 10789, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3571.14, \"learn_time_ms\": 43049.915}", "{\"n\": 10790, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3573.63, \"learn_time_ms\": 43000.216}", "{\"n\": 10791, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3588.41, \"learn_time_ms\": 43034.115}", "{\"n\": 10792, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3581.15, \"learn_time_ms\": 43044.197}", "{\"n\": 10793, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.55, \"learn_time_ms\": 43028.578}", "{\"n\": 10794, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.55, \"learn_time_ms\": 43104.45}", "{\"n\": 10795, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3555.42, \"learn_time_ms\": 43122.928}", "{\"n\": 10796, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3567.86, \"learn_time_ms\": 43171.146}", "{\"n\": 10797, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.56, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3561.53, \"learn_time_ms\": 43238.282}", "{\"n\": 10798, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3558.52, \"learn_time_ms\": 43129.115}", "{\"n\": 10799, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3558.52, \"learn_time_ms\": 43198.685}", "{\"n\": 10800, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3563.91, \"learn_time_ms\": 43166.637}", "{\"n\": 10801, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.53, \"learn_time_ms\": 43072.112}", "{\"n\": 10802, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3546.91, \"learn_time_ms\": 43041.991}", "{\"n\": 10803, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3546.91, \"learn_time_ms\": 43095.158}", "{\"n\": 10804, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3527.03, \"learn_time_ms\": 42985.488}", "{\"n\": 10805, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3519.24, \"learn_time_ms\": 43074.669}", "{\"n\": 10806, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3506.14, \"learn_time_ms\": 42955.762}", "{\"n\": 10807, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3506.14, \"learn_time_ms\": 42956.741}", "{\"n\": 10808, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3489.96, \"learn_time_ms\": 42974.411}", "{\"n\": 10809, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3496.97, \"learn_time_ms\": 42902.131}", "{\"n\": 10810, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3496.97, \"learn_time_ms\": 43019.13}", "{\"n\": 10811, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3485.79, \"learn_time_ms\": 43066.54}", "{\"n\": 10812, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3480.94, \"learn_time_ms\": 43057.803}", "{\"n\": 10813, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3480.94, \"learn_time_ms\": 43010.896}", "{\"n\": 10814, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3466.19, \"learn_time_ms\": 43043.674}", "{\"n\": 10815, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3466.19, \"learn_time_ms\": 43085.975}", "{\"n\": 10816, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3466.19, \"learn_time_ms\": 43130.297}", "{\"n\": 10817, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3443.46, \"learn_time_ms\": 43037.226}", "{\"n\": 10818, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3444.15, \"learn_time_ms\": 42967.719}", "{\"n\": 10819, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3444.15, \"learn_time_ms\": 43046.195}", "{\"n\": 10820, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3441.07, \"learn_time_ms\": 42904.944}", "{\"n\": 10821, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3439.77, \"learn_time_ms\": 42872.808}", "{\"n\": 10822, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3423.17, \"learn_time_ms\": 42898.289}", "{\"n\": 10823, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3423.17, \"learn_time_ms\": 42864.667}", "{\"n\": 10824, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3424.15, \"learn_time_ms\": 42834.277}", "{\"n\": 10825, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3424.15, \"learn_time_ms\": 42811.502}", "{\"n\": 10826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3429.96, \"learn_time_ms\": 42787.625}", "{\"n\": 10827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3430.7, \"learn_time_ms\": 42878.188}", "{\"n\": 10828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3424.65, \"learn_time_ms\": 42938.107}", "{\"n\": 10829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3420.67, \"learn_time_ms\": 42917.773}", "{\"n\": 10830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3420.67, \"learn_time_ms\": 42923.779}", "{\"n\": 10831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3435.91, \"learn_time_ms\": 42948.591}", "{\"n\": 10832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3435.91, \"learn_time_ms\": 42872.368}", "{\"n\": 10833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3428.5, \"learn_time_ms\": 42921.063}", "{\"n\": 10834, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3429.48, \"learn_time_ms\": 42910.066}", "{\"n\": 10835, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3432.37, \"learn_time_ms\": 42814.259}", "{\"n\": 10836, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3432.37, \"learn_time_ms\": 42766.776}", "{\"n\": 10837, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3423.51, \"learn_time_ms\": 42771.524}", "{\"n\": 10838, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3424.23, \"learn_time_ms\": 42728.078}", "{\"n\": 10839, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3432.66, \"learn_time_ms\": 42645.484}", "{\"n\": 10840, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3432.66, \"learn_time_ms\": 42596.38}", "{\"n\": 10841, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3452.58, \"learn_time_ms\": 42580.373}", "{\"n\": 10842, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3452.58, \"learn_time_ms\": 42560.756}", "{\"n\": 10843, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3454.2, \"learn_time_ms\": 42596.824}", "{\"n\": 10844, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3458.1, \"learn_time_ms\": 42670.145}", "{\"n\": 10845, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3458.1, \"learn_time_ms\": 42721.055}", "{\"n\": 10846, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3455.25, \"learn_time_ms\": 42760.384}", "{\"n\": 10847, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3455.79, \"learn_time_ms\": 42791.398}", "{\"n\": 10848, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.27, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3475.55, \"learn_time_ms\": 42861.794}", "{\"n\": 10849, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3480.98, \"learn_time_ms\": 42843.929}", "{\"n\": 10850, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3471.84, \"learn_time_ms\": 42941.378}", "{\"n\": 10851, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3477.79, \"learn_time_ms\": 42990.908}", "{\"n\": 10852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3477.79, \"learn_time_ms\": 43098.474}", "{\"n\": 10853, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3474.7, \"learn_time_ms\": 43041.865}", "{\"n\": 10854, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3500.75, \"learn_time_ms\": 42942.807}", "{\"n\": 10855, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3503.25, \"learn_time_ms\": 42843.362}", "{\"n\": 10856, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3502.44, \"learn_time_ms\": 42812.985}", "{\"n\": 10857, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3500.91, \"learn_time_ms\": 42656.262}", "{\"n\": 10858, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3500.91, \"learn_time_ms\": 42658.151}", "{\"n\": 10859, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3499.97, \"learn_time_ms\": 42569.79}", "{\"n\": 10860, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3499.87, \"learn_time_ms\": 42515.896}", "{\"n\": 10861, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3499.87, \"learn_time_ms\": 42600.085}", "{\"n\": 10862, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3493.07, \"learn_time_ms\": 42531.488}", "{\"n\": 10863, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3471.34, \"learn_time_ms\": 42568.88}", "{\"n\": 10864, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3473.48, \"learn_time_ms\": 42671.421}", "{\"n\": 10865, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3477.63, \"learn_time_ms\": 42728.469}", "{\"n\": 10866, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3477.63, \"learn_time_ms\": 42792.281}", "{\"n\": 10867, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3491.75, \"learn_time_ms\": 42823.866}", "{\"n\": 10868, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3485.54, \"learn_time_ms\": 42826.932}", "{\"n\": 10869, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3476.48, \"learn_time_ms\": 42882.253}", "{\"n\": 10870, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3467.79, \"learn_time_ms\": 42984.999}", "{\"n\": 10871, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3467.79, \"learn_time_ms\": 42860.614}", "{\"n\": 10872, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.71, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3460.54, \"learn_time_ms\": 42886.734}", "{\"n\": 10873, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3479.1, \"learn_time_ms\": 42847.733}", "{\"n\": 10874, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3482.66, \"learn_time_ms\": 42787.855}", "{\"n\": 10875, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3492.92, \"learn_time_ms\": 42795.599}", "{\"n\": 10876, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3505.09, \"learn_time_ms\": 42702.06}", "{\"n\": 10877, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3505.09, \"learn_time_ms\": 42731.244}", "{\"n\": 10878, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3510.25, \"learn_time_ms\": 42695.454}", "{\"n\": 10879, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3522.24, \"learn_time_ms\": 42850.709}", "{\"n\": 10880, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3533.62, \"learn_time_ms\": 42816.875}", "{\"n\": 10881, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3533.48, \"learn_time_ms\": 42831.501}", "{\"n\": 10882, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3540.35, \"learn_time_ms\": 42904.894}", "{\"n\": 10883, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3538.23, \"learn_time_ms\": 42913.482}", "{\"n\": 10884, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3546.72, \"learn_time_ms\": 43030.634}", "{\"n\": 10885, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3545.47, \"learn_time_ms\": 43148.322}", "{\"n\": 10886, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3531.1, \"learn_time_ms\": 43201.873}", "{\"n\": 10887, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3531.1, \"learn_time_ms\": 43181.904}", "{\"n\": 10888, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3544.57, \"learn_time_ms\": 43111.12}", "{\"n\": 10889, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3545.47, \"learn_time_ms\": 43000.721}", "{\"n\": 10890, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3545.47, \"learn_time_ms\": 42951.182}", "{\"n\": 10891, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3538.42, \"learn_time_ms\": 42964.831}", "{\"n\": 10892, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3552.31, \"learn_time_ms\": 42969.652}", "{\"n\": 10893, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3548.97, \"learn_time_ms\": 43025.112}", "{\"n\": 10894, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3564.36, \"learn_time_ms\": 42950.809}", "{\"n\": 10895, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3557.87, \"learn_time_ms\": 42832.367}", "{\"n\": 10896, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3562.08, \"learn_time_ms\": 42825.257}", "{\"n\": 10897, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3570.69, \"learn_time_ms\": 42901.609}", "{\"n\": 10898, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3589.74, \"learn_time_ms\": 42960.832}", "{\"n\": 10899, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3589.74, \"learn_time_ms\": 42982.735}", "{\"n\": 10900, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3584.68, \"learn_time_ms\": 43067.72}", "{\"n\": 10901, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3593.31, \"learn_time_ms\": 43014.277}", "{\"n\": 10902, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3589.47, \"learn_time_ms\": 42915.293}", "{\"n\": 10903, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3590.7, \"learn_time_ms\": 42875.653}", "{\"n\": 10904, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3590.7, \"learn_time_ms\": 42909.336}", "{\"n\": 10905, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3604.47, \"learn_time_ms\": 42985.423}", "{\"n\": 10906, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.08, \"learn_time_ms\": 42972.697}", "{\"n\": 10907, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3605.08, \"learn_time_ms\": 42892.695}", "{\"n\": 10908, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3597.36, \"learn_time_ms\": 42932.332}", "{\"n\": 10909, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3593.99, \"learn_time_ms\": 42932.588}", "{\"n\": 10910, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.56, \"learn_time_ms\": 42813.712}", "{\"n\": 10911, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -1.36, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.56, \"learn_time_ms\": 42952.426}", "{\"n\": 10912, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.4, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3601.89, \"learn_time_ms\": 43003.752}", "{\"n\": 10913, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3594.23, \"learn_time_ms\": 42893.789}", "{\"n\": 10914, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.71, \"learn_time_ms\": 42796.146}", "{\"n\": 10915, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.71, \"learn_time_ms\": 42686.594}", "{\"n\": 10916, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.71, \"learn_time_ms\": 42697.24}", "{\"n\": 10917, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.89, \"learn_time_ms\": 42741.681}", "{\"n\": 10918, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3600.89, \"learn_time_ms\": 42800.098}", "{\"n\": 10919, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3592.82, \"learn_time_ms\": 42765.359}", "{\"n\": 10920, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3592.82, \"learn_time_ms\": 42768.15}", "{\"n\": 10921, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3582.43, \"learn_time_ms\": 42681.665}", "{\"n\": 10922, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3572.38, \"learn_time_ms\": 42606.148}", "{\"n\": 10923, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3572.38, \"learn_time_ms\": 42636.626}", "{\"n\": 10924, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3570.36, \"learn_time_ms\": 42593.524}", "{\"n\": 10925, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3571.59, \"learn_time_ms\": 42687.323}", "{\"n\": 10926, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3574.7, \"learn_time_ms\": 42690.733}", "{\"n\": 10927, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3572.95, \"learn_time_ms\": 42718.859}", "{\"n\": 10928, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3567.04, \"learn_time_ms\": 42705.851}", "{\"n\": 10929, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3567.04, \"learn_time_ms\": 42707.332}", "{\"n\": 10930, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3579.84, \"learn_time_ms\": 42791.064}", "{\"n\": 10931, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3568.17, \"learn_time_ms\": 42822.132}", "{\"n\": 10932, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3567.21, \"learn_time_ms\": 42934.88}", "{\"n\": 10933, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3567.21, \"learn_time_ms\": 43002.12}", "{\"n\": 10934, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3569.78, \"learn_time_ms\": 43121.961}", "{\"n\": 10935, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3576.18, \"learn_time_ms\": 43061.185}", "{\"n\": 10936, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3574.91, \"learn_time_ms\": 43103.544}", "{\"n\": 10937, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3574.91, \"learn_time_ms\": 43110.665}", "{\"n\": 10938, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3574.91, \"learn_time_ms\": 43061.328}", "{\"n\": 10939, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3586.79, \"learn_time_ms\": 43007.262}", "{\"n\": 10940, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3586.79, \"learn_time_ms\": 42922.916}", "{\"n\": 10941, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3583.06, \"learn_time_ms\": 42794.277}", "{\"n\": 10942, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3580.24, \"learn_time_ms\": 42692.743}", "{\"n\": 10943, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3580.24, \"learn_time_ms\": 42758.869}", "{\"n\": 10944, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3597.86, \"learn_time_ms\": 42737.336}", "{\"n\": 10945, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3597.86, \"learn_time_ms\": 42770.446}", "{\"n\": 10946, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3613.16, \"learn_time_ms\": 42720.487}", "{\"n\": 10947, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.95, \"learn_time_ms\": 42730.026}", "{\"n\": 10948, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.84, \"learn_time_ms\": 42750.776}", "{\"n\": 10949, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3596.84, \"learn_time_ms\": 42889.023}", "{\"n\": 10950, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.77, \"learn_time_ms\": 42903.238}", "{\"n\": 10951, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.77, \"learn_time_ms\": 43005.428}", "{\"n\": 10952, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.77, \"learn_time_ms\": 42945.536}", "{\"n\": 10953, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3568.78, \"learn_time_ms\": 42838.084}", "{\"n\": 10954, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.45, \"learn_time_ms\": 42865.295}", "{\"n\": 10955, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.45, \"learn_time_ms\": 42801.688}", "{\"n\": 10956, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3561.45, \"learn_time_ms\": 42916.964}", "{\"n\": 10957, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.5, \"learn_time_ms\": 42873.523}", "{\"n\": 10958, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.5, \"learn_time_ms\": 42833.981}", "{\"n\": 10959, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3573.83, \"learn_time_ms\": 42837.151}", "{\"n\": 10960, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.46, \"learn_time_ms\": 42807.467}", "{\"n\": 10961, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.46, \"learn_time_ms\": 42776.409}", "{\"n\": 10962, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.88, \"learn_time_ms\": 42905.859}", "{\"n\": 10963, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.88, \"learn_time_ms\": 42887.136}", "{\"n\": 10964, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3587.22, \"learn_time_ms\": 42896.058}", "{\"n\": 10965, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.25, \"learn_time_ms\": 42917.151}", "{\"n\": 10966, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.35, \"learn_time_ms\": 42844.395}", "{\"n\": 10967, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3598.87, \"learn_time_ms\": 42831.747}", "{\"n\": 10968, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.73, \"learn_time_ms\": 42876.738}", "{\"n\": 10969, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.73, \"learn_time_ms\": 42874.81}", "{\"n\": 10970, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3594.05, \"learn_time_ms\": 42865.493}", "{\"n\": 10971, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.84, \"learn_time_ms\": 42937.815}", "{\"n\": 10972, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3588.09, \"learn_time_ms\": 42905.145}", "{\"n\": 10973, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3587.21, \"learn_time_ms\": 42914.698}", "{\"n\": 10974, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3587.21, \"learn_time_ms\": 42930.88}", "{\"n\": 10975, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3587.21, \"learn_time_ms\": 42965.149}", "{\"n\": 10976, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3587.21, \"learn_time_ms\": 42995.524}", "{\"n\": 10977, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.75, \"learn_time_ms\": 43076.083}", "{\"n\": 10978, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.2, \"learn_time_ms\": 43015.665}", "{\"n\": 10979, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.09, \"learn_time_ms\": 42918.252}", "{\"n\": 10980, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.09, \"learn_time_ms\": 43074.069}", "{\"n\": 10981, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3552.09, \"learn_time_ms\": 43042.367}", "{\"n\": 10982, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.51, \"learn_time_ms\": 42994.012}", "{\"n\": 10983, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.21, \"learn_time_ms\": 43117.973}", "{\"n\": 10984, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.64, \"learn_time_ms\": 43123.951}", "{\"n\": 10985, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.24, \"learn_time_ms\": 43078.81}", "{\"n\": 10986, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.24, \"learn_time_ms\": 43006.407}", "{\"n\": 10987, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3597.24, \"learn_time_ms\": 42999.894}", "{\"n\": 10988, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3579.78, \"learn_time_ms\": 43150.609}", "{\"n\": 10989, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3575.03, \"learn_time_ms\": 43235.668}", "{\"n\": 10990, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.39, \"learn_time_ms\": 43136.248}", "{\"n\": 10991, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.39, \"learn_time_ms\": 43104.292}", "{\"n\": 10992, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.39, \"learn_time_ms\": 43069.127}", "{\"n\": 10993, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3576.39, \"learn_time_ms\": 42945.374}", "{\"n\": 10994, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3569.88, \"learn_time_ms\": 42975.826}", "{\"n\": 10995, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3574.24, \"learn_time_ms\": 42878.763}", "{\"n\": 10996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.11, \"learn_time_ms\": 42980.054}", "{\"n\": 10997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.11, \"learn_time_ms\": 42984.845}", "{\"n\": 10998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3581.11, \"learn_time_ms\": 42931.632}", "{\"n\": 10999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3590.92, \"learn_time_ms\": 42860.925}", "{\"n\": 11000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.71, \"learn_time_ms\": 42856.346}"]["{\"n\": 11001, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 45383.112}", "{\"n\": 11002, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 44032.987}", "{\"n\": 11003, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43607.798}", "{\"n\": 11004, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43400.733}", "{\"n\": 11005, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43178.209}", "{\"n\": 11006, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43125.969}", "{\"n\": 11007, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43071.217}", "{\"n\": 11008, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43077.432}", "{\"n\": 11009, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43052.559}", "{\"n\": 11010, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 43009.538}", "{\"n\": 11011, \"episode_reward_min\": 6.0, \"episode_reward_mean\": 6.0, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3791.0, \"learn_time_ms\": 42736.044}", "{\"n\": 11012, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 0.0, \"episode_reward_max\": 6.0, \"episode_len_mean\": 3616.75, \"learn_time_ms\": 42769.064}", "{\"n\": 11013, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 1.1428571428571428, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3690.8571428571427, \"learn_time_ms\": 42777.431}", "{\"n\": 11014, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3769.5, \"learn_time_ms\": 42835.318}", "{\"n\": 11015, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3769.5, \"learn_time_ms\": 42847.144}", "{\"n\": 11016, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3769.5, \"learn_time_ms\": 42796.528}", "{\"n\": 11017, \"episode_reward_min\": -8.0, \"episode_reward_mean\": 0.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3769.5, \"learn_time_ms\": 42752.497}", "{\"n\": 11018, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3594.5833333333335, \"learn_time_ms\": 42712.398}", "{\"n\": 11019, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.3333333333333333, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3612.266666666667, \"learn_time_ms\": 42653.671}", "{\"n\": 11020, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.875, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3616.6875, \"learn_time_ms\": 42681.728}", "{\"n\": 11021, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.875, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3616.6875, \"learn_time_ms\": 42771.267}", "{\"n\": 11022, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.875, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3616.6875, \"learn_time_ms\": 42777.318}", "{\"n\": 11023, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.1111111111111112, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3638.8333333333335, \"learn_time_ms\": 42838.693}", "{\"n\": 11024, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 7.0, \"episode_len_mean\": 3680.85, \"learn_time_ms\": 42747.818}", "{\"n\": 11025, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.2727272727275, \"learn_time_ms\": 42714.153}", "{\"n\": 11026, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.782608695652174, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.1739130434785, \"learn_time_ms\": 42843.011}", "{\"n\": 11027, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.5416666666666666, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.3333333333335, \"learn_time_ms\": 42835.008}", "{\"n\": 11028, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.5416666666666666, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3634.3333333333335, \"learn_time_ms\": 42871.611}", "{\"n\": 11029, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3608.6, \"learn_time_ms\": 42952.294}", "{\"n\": 11030, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.8888888888888888, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3578.8888888888887, \"learn_time_ms\": 42900.214}", "{\"n\": 11031, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.0689655172413792, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3606.551724137931, \"learn_time_ms\": 42789.8}", "{\"n\": 11032, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.032258064516129, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3617.483870967742, \"learn_time_ms\": 42724.755}", "{\"n\": 11033, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -1.09375, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3628.5, \"learn_time_ms\": 42553.305}", "{\"n\": 11034, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.7575757575757576, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.848484848485, \"learn_time_ms\": 42548.036}", "{\"n\": 11035, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.7575757575757576, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3624.848484848485, \"learn_time_ms\": 42644.432}", "{\"n\": 11036, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.5142857142857142, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3640.6285714285714, \"learn_time_ms\": 42488.096}", "{\"n\": 11037, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.6388888888888888, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.1388888888887, \"learn_time_ms\": 42567.513}", "{\"n\": 11038, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.7692307692307693, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3675.897435897436, \"learn_time_ms\": 42582.396}", "{\"n\": 11039, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.575, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3678.775, \"learn_time_ms\": 42685.418}", "{\"n\": 11040, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.2926829268292683, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.0243902439024, \"learn_time_ms\": 42734.59}", "{\"n\": 11041, \"episode_reward_min\": -12.0, \"episode_reward_mean\": -0.2926829268292683, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3665.0243902439024, \"learn_time_ms\": 42718.738}", "{\"n\": 11042, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.6046511627906976, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3645.0, \"learn_time_ms\": 42729.681}", "{\"n\": 11043, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.9333333333333333, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3638.288888888889, \"learn_time_ms\": 42789.374}", "{\"n\": 11044, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.9148936170212766, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3669.276595744681, \"learn_time_ms\": 42936.342}", "{\"n\": 11045, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.0416666666666667, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.4166666666665, \"learn_time_ms\": 42954.996}", "{\"n\": 11046, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.0416666666666667, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.4166666666665, \"learn_time_ms\": 43029.276}", "{\"n\": 11047, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.1428571428571428, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3663.5102040816328, \"learn_time_ms\": 42977.121}", "{\"n\": 11048, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.2307692307692308, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3661.173076923077, \"learn_time_ms\": 42969.566}", "{\"n\": 11049, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.9056603773584906, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.1132075471696, \"learn_time_ms\": 42789.619}", "{\"n\": 11050, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.0727272727272728, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.2363636363634, \"learn_time_ms\": 42773.057}", "{\"n\": 11051, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.0727272727272728, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3635.2363636363634, \"learn_time_ms\": 42818.997}", "{\"n\": 11052, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.0517241379310345, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3654.896551724138, \"learn_time_ms\": 42863.629}", "{\"n\": 11053, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.0517241379310345, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3654.896551724138, \"learn_time_ms\": 42964.064}", "{\"n\": 11054, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.1864406779661016, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.322033898305, \"learn_time_ms\": 42839.508}", "{\"n\": 11055, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.467741935483871, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.0967741935483, \"learn_time_ms\": 42927.388}", "{\"n\": 11056, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.467741935483871, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.0967741935483, \"learn_time_ms\": 42936.534}", "{\"n\": 11057, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.515625, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.609375, \"learn_time_ms\": 42926.144}", "{\"n\": 11058, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.646153846153846, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.7076923076925, \"learn_time_ms\": 42905.173}", "{\"n\": 11059, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.8181818181818181, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.9848484848485, \"learn_time_ms\": 42944.873}", "{\"n\": 11060, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.8181818181818181, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3628.9848484848485, \"learn_time_ms\": 42951.057}", "{\"n\": 11061, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.7058823529411764, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.1323529411766, \"learn_time_ms\": 42937.816}", "{\"n\": 11062, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.6521739130434783, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3642.9565217391305, \"learn_time_ms\": 42984.661}", "{\"n\": 11063, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.7746478873239437, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3634.2957746478874, \"learn_time_ms\": 42890.589}", "{\"n\": 11064, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.7945205479452055, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3650.4794520547944, \"learn_time_ms\": 42946.123}", "{\"n\": 11065, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.7027027027027026, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.0810810810813, \"learn_time_ms\": 42852.57}", "{\"n\": 11066, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.7027027027027026, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3652.0810810810813, \"learn_time_ms\": 42932.287}", "{\"n\": 11067, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.6133333333333333, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3655.8533333333335, \"learn_time_ms\": 43009.86}", "{\"n\": 11068, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.3636363636363635, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3654.3896103896104, \"learn_time_ms\": 43003.818}", "{\"n\": 11069, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.1898734177215189, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3662.8860759493673, \"learn_time_ms\": 42967.801}", "{\"n\": 11070, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3660.6125, \"learn_time_ms\": 42967.556}", "{\"n\": 11071, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.2222222222222223, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3663.8395061728397, \"learn_time_ms\": 42952.291}", "{\"n\": 11072, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.216867469879518, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3664.3493975903616, \"learn_time_ms\": 42879.904}", "{\"n\": 11073, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.216867469879518, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3664.3493975903616, \"learn_time_ms\": 42936.789}", "{\"n\": 11074, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.2470588235294118, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3674.247058823529, \"learn_time_ms\": 42917.443}", "{\"n\": 11075, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.3068181818181819, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3678.0454545454545, \"learn_time_ms\": 42864.058}", "{\"n\": 11076, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.3932584269662922, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3673.8426966292136, \"learn_time_ms\": 42775.743}", "{\"n\": 11077, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.3932584269662922, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3673.8426966292136, \"learn_time_ms\": 42730.869}", "{\"n\": 11078, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.3932584269662922, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3673.8426966292136, \"learn_time_ms\": 42722.583}", "{\"n\": 11079, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.576086956521739, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3672.891304347826, \"learn_time_ms\": 42786.276}", "{\"n\": 11080, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.7708333333333333, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3658.9479166666665, \"learn_time_ms\": 42900.339}", "{\"n\": 11081, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.731958762886598, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3659.453608247423, \"learn_time_ms\": 43010.608}", "{\"n\": 11082, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.731958762886598, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3659.453608247423, \"learn_time_ms\": 43010.552}", "{\"n\": 11083, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.731958762886598, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3659.453608247423, \"learn_time_ms\": 42967.093}", "{\"n\": 11084, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.663265306122449, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3661.1632653061224, \"learn_time_ms\": 42962.419}", "{\"n\": 11085, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3666.78, \"learn_time_ms\": 43023.351}", "{\"n\": 11086, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3644.43, \"learn_time_ms\": 43062.025}", "{\"n\": 11087, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.58, \"learn_time_ms\": 43098.455}", "{\"n\": 11088, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3640.58, \"learn_time_ms\": 43095.437}", "{\"n\": 11089, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3629.48, \"learn_time_ms\": 43089.073}", "{\"n\": 11090, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3622.74, \"learn_time_ms\": 43065.432}", "{\"n\": 11091, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3622.74, \"learn_time_ms\": 42989.694}", "{\"n\": 11092, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3636.93, \"learn_time_ms\": 42995.482}", "{\"n\": 11093, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3633.99, \"learn_time_ms\": 43093.778}", "{\"n\": 11094, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3633.99, \"learn_time_ms\": 43095.364}", "{\"n\": 11095, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3614.94, \"learn_time_ms\": 43011.332}", "{\"n\": 11096, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3614.48, \"learn_time_ms\": 42883.94}", "{\"n\": 11097, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3599.96, \"learn_time_ms\": 42962.793}", "{\"n\": 11098, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.27, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3602.4, \"learn_time_ms\": 42924.918}", "{\"n\": 11099, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3600.74, \"learn_time_ms\": 42889.965}", "{\"n\": 11100, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3600.74, \"learn_time_ms\": 42804.417}", "{\"n\": 11101, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3608.58, \"learn_time_ms\": 42802.027}", "{\"n\": 11102, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.29, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3601.21, \"learn_time_ms\": 42826.919}", "{\"n\": 11103, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3610.31, \"learn_time_ms\": 42715.854}", "{\"n\": 11104, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3623.16, \"learn_time_ms\": 42691.103}", "{\"n\": 11105, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3613.12, \"learn_time_ms\": 42731.247}", "{\"n\": 11106, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3613.12, \"learn_time_ms\": 42858.756}", "{\"n\": 11107, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3611.17, \"learn_time_ms\": 42689.933}", "{\"n\": 11108, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3611.17, \"learn_time_ms\": 42736.268}", "{\"n\": 11109, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3613.21, \"learn_time_ms\": 42784.529}", "{\"n\": 11110, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3606.75, \"learn_time_ms\": 42838.34}", "{\"n\": 11111, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3609.12, \"learn_time_ms\": 42787.507}", "{\"n\": 11112, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3605.2, \"learn_time_ms\": 42789.218}", "{\"n\": 11113, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3605.2, \"learn_time_ms\": 42786.184}", "{\"n\": 11114, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3591.3, \"learn_time_ms\": 42725.443}", "{\"n\": 11115, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3615.18, \"learn_time_ms\": 42806.649}", "{\"n\": 11116, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3608.39, \"learn_time_ms\": 42730.024}", "{\"n\": 11117, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3604.13, \"learn_time_ms\": 42811.313}", "{\"n\": 11118, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3604.13, \"learn_time_ms\": 42812.766}", "{\"n\": 11119, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3604.13, \"learn_time_ms\": 42830.218}", "{\"n\": 11120, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.88, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3598.1, \"learn_time_ms\": 42827.534}", "{\"n\": 11121, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.85, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3597.36, \"learn_time_ms\": 42935.139}", "{\"n\": 11122, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3599.08, \"learn_time_ms\": 42891.209}", "{\"n\": 11123, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3599.08, \"learn_time_ms\": 42932.625}", "{\"n\": 11124, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3599.08, \"learn_time_ms\": 43006.844}", "{\"n\": 11125, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3593.55, \"learn_time_ms\": 42952.848}", "{\"n\": 11126, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3593.55, \"learn_time_ms\": 42981.68}", "{\"n\": 11127, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.19, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3579.04, \"learn_time_ms\": 43063.632}", "{\"n\": 11128, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3576.58, \"learn_time_ms\": 43060.293}", "{\"n\": 11129, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3574.12, \"learn_time_ms\": 43075.094}", "{\"n\": 11130, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3574.12, \"learn_time_ms\": 43007.508}", "{\"n\": 11131, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3568.76, \"learn_time_ms\": 42964.419}", "{\"n\": 11132, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3568.76, \"learn_time_ms\": 43058.666}", "{\"n\": 11133, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3569.81, \"learn_time_ms\": 43047.956}", "{\"n\": 11134, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.96, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3580.62, \"learn_time_ms\": 43011.271}", "{\"n\": 11135, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3582.37, \"learn_time_ms\": 42977.076}", "{\"n\": 11136, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3585.53, \"learn_time_ms\": 43005.997}", "{\"n\": 11137, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3585.53, \"learn_time_ms\": 42940.455}", "{\"n\": 11138, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3585.53, \"learn_time_ms\": 42958.555}", "{\"n\": 11139, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3583.69, \"learn_time_ms\": 42835.548}", "{\"n\": 11140, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.99, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3565.33, \"learn_time_ms\": 42901.927}", "{\"n\": 11141, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3562.22, \"learn_time_ms\": 42890.177}", "{\"n\": 11142, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3562.22, \"learn_time_ms\": 42856.512}", "{\"n\": 11143, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3552.99, \"learn_time_ms\": 42795.615}", "{\"n\": 11144, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3545.66, \"learn_time_ms\": 42901.362}", "{\"n\": 11145, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.06, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3545.66, \"learn_time_ms\": 42862.78}", "{\"n\": 11146, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.97, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3536.74, \"learn_time_ms\": 42846.948}", "{\"n\": 11147, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3534.66, \"learn_time_ms\": 42863.613}", "{\"n\": 11148, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3534.66, \"learn_time_ms\": 42795.287}", "{\"n\": 11149, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.9, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3523.89, \"learn_time_ms\": 42889.931}", "{\"n\": 11150, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3516.79, \"learn_time_ms\": 42923.953}", "{\"n\": 11151, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3518.47, \"learn_time_ms\": 42934.053}", "{\"n\": 11152, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3521.24, \"learn_time_ms\": 42850.902}", "{\"n\": 11153, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3516.17, \"learn_time_ms\": 42972.332}", "{\"n\": 11154, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3509.26, \"learn_time_ms\": 42805.374}", "{\"n\": 11155, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3511.48, \"learn_time_ms\": 42857.028}", "{\"n\": 11156, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3496.4, \"learn_time_ms\": 42849.612}", "{\"n\": 11157, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3494.67, \"learn_time_ms\": 42837.616}", "{\"n\": 11158, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.75, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3510.82, \"learn_time_ms\": 42920.426}", "{\"n\": 11159, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3514.28, \"learn_time_ms\": 42904.118}", "{\"n\": 11160, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3514.28, \"learn_time_ms\": 42740.113}", "{\"n\": 11161, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3513.51, \"learn_time_ms\": 42822.306}", "{\"n\": 11162, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3522.27, \"learn_time_ms\": 42929.489}", "{\"n\": 11163, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3511.47, \"learn_time_ms\": 42859.974}", "{\"n\": 11164, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3517.22, \"learn_time_ms\": 42967.411}", "{\"n\": 11165, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3502.42, \"learn_time_ms\": 42900.198}", "{\"n\": 11166, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3510.62, \"learn_time_ms\": 42847.73}", "{\"n\": 11167, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3510.18, \"learn_time_ms\": 42859.8}", "{\"n\": 11168, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3517.8, \"learn_time_ms\": 42881.408}", "{\"n\": 11169, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3517.8, \"learn_time_ms\": 42992.284}", "{\"n\": 11170, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.55, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3508.48, \"learn_time_ms\": 43042.354}", "{\"n\": 11171, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3506.66, \"learn_time_ms\": 42932.335}", "{\"n\": 11172, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3483.29, \"learn_time_ms\": 42866.215}", "{\"n\": 11173, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.1, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3478.58, \"learn_time_ms\": 43032.447}", "{\"n\": 11174, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3473.25, \"learn_time_ms\": 42991.656}", "{\"n\": 11175, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.31, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3459.12, \"learn_time_ms\": 43002.483}", "{\"n\": 11176, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3462.38, \"learn_time_ms\": 43044.225}", "{\"n\": 11177, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3461.13, \"learn_time_ms\": 42992.368}", "{\"n\": 11178, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.58, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3443.57, \"learn_time_ms\": 42892.895}", "{\"n\": 11179, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3443.22, \"learn_time_ms\": 42791.081}", "{\"n\": 11180, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3444.05, \"learn_time_ms\": 42870.244}", "{\"n\": 11181, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3434.25, \"learn_time_ms\": 42949.005}", "{\"n\": 11182, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3434.25, \"learn_time_ms\": 42867.418}", "{\"n\": 11183, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3429.68, \"learn_time_ms\": 42740.707}", "{\"n\": 11184, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.95, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3435.22, \"learn_time_ms\": 42882.361}", "{\"n\": 11185, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3430.3, \"learn_time_ms\": 42979.811}", "{\"n\": 11186, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3409.28, \"learn_time_ms\": 43013.091}", "{\"n\": 11187, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3404.46, \"learn_time_ms\": 43000.154}", "{\"n\": 11188, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3393.07, \"learn_time_ms\": 43095.182}", "{\"n\": 11189, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3393.07, \"learn_time_ms\": 43106.525}", "{\"n\": 11190, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3380.09, \"learn_time_ms\": 43168.94}", "{\"n\": 11191, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3380.09, \"learn_time_ms\": 43088.667}", "{\"n\": 11192, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3384.83, \"learn_time_ms\": 43144.29}", "{\"n\": 11193, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3374.13, \"learn_time_ms\": 43102.302}", "{\"n\": 11194, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3374.13, \"learn_time_ms\": 43056.316}", "{\"n\": 11195, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3376.16, \"learn_time_ms\": 43015.823}", "{\"n\": 11196, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3374.28, \"learn_time_ms\": 42976.941}", "{\"n\": 11197, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3355.2, \"learn_time_ms\": 43031.318}", "{\"n\": 11198, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3360.58, \"learn_time_ms\": 42946.394}", "{\"n\": 11199, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.35, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3370.43, \"learn_time_ms\": 43004.002}", "{\"n\": 11200, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3382.92, \"learn_time_ms\": 42974.37}", "{\"n\": 11201, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3382.92, \"learn_time_ms\": 43057.312}", "{\"n\": 11202, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3361.24, \"learn_time_ms\": 43014.768}", "{\"n\": 11203, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3358.75, \"learn_time_ms\": 42981.768}", "{\"n\": 11204, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3358.64, \"learn_time_ms\": 42902.524}", "{\"n\": 11205, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3354.09, \"learn_time_ms\": 42954.282}", "{\"n\": 11206, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3354.09, \"learn_time_ms\": 42979.58}", "{\"n\": 11207, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3346.03, \"learn_time_ms\": 43071.841}", "{\"n\": 11208, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3346.03, \"learn_time_ms\": 43129.426}", "{\"n\": 11209, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.28, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3358.38, \"learn_time_ms\": 43049.777}", "{\"n\": 11210, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.29, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3356.17, \"learn_time_ms\": 43037.067}", "{\"n\": 11211, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3328.51, \"learn_time_ms\": 43008.988}", "{\"n\": 11212, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3328.51, \"learn_time_ms\": 43039.743}", "{\"n\": 11213, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3343.34, \"learn_time_ms\": 43132.459}", "{\"n\": 11214, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3331.25, \"learn_time_ms\": 43119.85}", "{\"n\": 11215, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3340.29, \"learn_time_ms\": 43137.166}", "{\"n\": 11216, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3340.29, \"learn_time_ms\": 43074.834}", "{\"n\": 11217, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3340.63, \"learn_time_ms\": 42801.934}", "{\"n\": 11218, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3340.26, \"learn_time_ms\": 42831.727}", "{\"n\": 11219, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3358.11, \"learn_time_ms\": 42835.249}", "{\"n\": 11220, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3358.74, \"learn_time_ms\": 42740.63}", "{\"n\": 11221, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3364.75, \"learn_time_ms\": 42653.724}", "{\"n\": 11222, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3364.75, \"learn_time_ms\": 42781.153}", "{\"n\": 11223, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.17, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3365.87, \"learn_time_ms\": 42734.513}", "{\"n\": 11224, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3370.77, \"learn_time_ms\": 42836.62}", "{\"n\": 11225, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3369.01, \"learn_time_ms\": 42793.786}", "{\"n\": 11226, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3376.07, \"learn_time_ms\": 42963.064}", "{\"n\": 11227, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.03, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3376.07, \"learn_time_ms\": 43079.369}", "{\"n\": 11228, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3370.32, \"learn_time_ms\": 43090.934}", "{\"n\": 11229, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.06, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3370.32, \"learn_time_ms\": 43096.18}", "{\"n\": 11230, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3375.45, \"learn_time_ms\": 43146.075}", "{\"n\": 11231, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3399.86, \"learn_time_ms\": 43208.92}", "{\"n\": 11232, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3402.38, \"learn_time_ms\": 43074.033}", "{\"n\": 11233, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3402.38, \"learn_time_ms\": 43081.562}", "{\"n\": 11234, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3402.38, \"learn_time_ms\": 42901.689}", "{\"n\": 11235, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3394.16, \"learn_time_ms\": 42927.108}", "{\"n\": 11236, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3393.84, \"learn_time_ms\": 42752.308}", "{\"n\": 11237, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.96, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3396.89, \"learn_time_ms\": 42872.333}", "{\"n\": 11238, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3390.53, \"learn_time_ms\": 42834.269}", "{\"n\": 11239, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3390.53, \"learn_time_ms\": 42882.529}", "{\"n\": 11240, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.01, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3392.76, \"learn_time_ms\": 42827.706}", "{\"n\": 11241, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3376.41, \"learn_time_ms\": 42859.304}", "{\"n\": 11242, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3382.57, \"learn_time_ms\": 42871.404}", "{\"n\": 11243, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.92, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3412.73, \"learn_time_ms\": 42969.059}", "{\"n\": 11244, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3416.86, \"learn_time_ms\": 43116.343}", "{\"n\": 11245, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3415.71, \"learn_time_ms\": 43013.974}", "{\"n\": 11246, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3421.32, \"learn_time_ms\": 43063.442}", "{\"n\": 11247, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3421.32, \"learn_time_ms\": 43145.654}", "{\"n\": 11248, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3420.8, \"learn_time_ms\": 43228.052}", "{\"n\": 11249, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.97, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3417.87, \"learn_time_ms\": 43234.905}", "{\"n\": 11250, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3432.72, \"learn_time_ms\": 43263.308}", "{\"n\": 11251, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3413.71, \"learn_time_ms\": 43203.726}", "{\"n\": 11252, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -4.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3413.71, \"learn_time_ms\": 43203.556}", "{\"n\": 11253, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3419.36, \"learn_time_ms\": 43064.428}", "{\"n\": 11254, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.8, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3423.97, \"learn_time_ms\": 42953.737}", "{\"n\": 11255, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.73, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3428.98, \"learn_time_ms\": 43004.567}", "{\"n\": 11256, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3439.78, \"learn_time_ms\": 43032.045}", "{\"n\": 11257, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3457.39, \"learn_time_ms\": 42891.127}", "{\"n\": 11258, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3457.39, \"learn_time_ms\": 42864.518}", "{\"n\": 11259, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3467.37, \"learn_time_ms\": 42733.582}", "{\"n\": 11260, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3465.4, \"learn_time_ms\": 42911.042}", "{\"n\": 11261, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3468.82, \"learn_time_ms\": 42941.767}", "{\"n\": 11262, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3491.15, \"learn_time_ms\": 43029.794}", "{\"n\": 11263, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3506.41, \"learn_time_ms\": 43090.768}", "{\"n\": 11264, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3506.41, \"learn_time_ms\": 43153.81}", "{\"n\": 11265, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3507.81, \"learn_time_ms\": 43179.366}", "{\"n\": 11266, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3507.81, \"learn_time_ms\": 43221.422}", "{\"n\": 11267, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.65, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3516.26, \"learn_time_ms\": 43166.943}", "{\"n\": 11268, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.66, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3521.49, \"learn_time_ms\": 43055.82}", "{\"n\": 11269, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3533.85, \"learn_time_ms\": 43162.301}", "{\"n\": 11270, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3533.85, \"learn_time_ms\": 42940.108}", "{\"n\": 11271, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.57, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3533.98, \"learn_time_ms\": 42820.747}", "{\"n\": 11272, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.62, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3538.93, \"learn_time_ms\": 42791.175}", "{\"n\": 11273, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3542.12, \"learn_time_ms\": 42893.782}", "{\"n\": 11274, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3527.51, \"learn_time_ms\": 42878.529}", "{\"n\": 11275, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3542.0, \"learn_time_ms\": 42842.777}", "{\"n\": 11276, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3542.0, \"learn_time_ms\": 42847.783}", "{\"n\": 11277, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.2, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3542.0, \"learn_time_ms\": 42914.728}", "{\"n\": 11278, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3543.43, \"learn_time_ms\": 42888.607}", "{\"n\": 11279, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.02, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3535.64, \"learn_time_ms\": 42878.507}", "{\"n\": 11280, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3541.77, \"learn_time_ms\": 42977.353}", "{\"n\": 11281, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3545.64, \"learn_time_ms\": 43182.466}", "{\"n\": 11282, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3545.64, \"learn_time_ms\": 43170.064}", "{\"n\": 11283, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3545.64, \"learn_time_ms\": 43039.145}", "{\"n\": 11284, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3560.79, \"learn_time_ms\": 43016.831}", "{\"n\": 11285, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3559.84, \"learn_time_ms\": 43029.143}", "{\"n\": 11286, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.16, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3553.89, \"learn_time_ms\": 42887.407}", "{\"n\": 11287, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3557.85, \"learn_time_ms\": 42872.712}", "{\"n\": 11288, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3557.85, \"learn_time_ms\": 42903.908}", "{\"n\": 11289, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3557.85, \"learn_time_ms\": 42803.96}", "{\"n\": 11290, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3549.34, \"learn_time_ms\": 42823.134}", "{\"n\": 11291, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3562.76, \"learn_time_ms\": 42651.542}", "{\"n\": 11292, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3557.45, \"learn_time_ms\": 42613.684}", "{\"n\": 11293, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3557.45, \"learn_time_ms\": 42706.453}", "{\"n\": 11294, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3557.45, \"learn_time_ms\": 42816.568}", "{\"n\": 11295, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3560.86, \"learn_time_ms\": 42834.786}", "{\"n\": 11296, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3555.11, \"learn_time_ms\": 42860.738}", "{\"n\": 11297, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3564.49, \"learn_time_ms\": 42839.069}", "{\"n\": 11298, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3558.14, \"learn_time_ms\": 42845.746}", "{\"n\": 11299, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3558.14, \"learn_time_ms\": 42957.445}", "{\"n\": 11300, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3558.14, \"learn_time_ms\": 42885.51}", "{\"n\": 11301, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 11.0, \"episode_len_mean\": 3556.53, \"learn_time_ms\": 42931.72}", "{\"n\": 11302, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3535.03, \"learn_time_ms\": 42874.978}", "{\"n\": 11303, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3539.81, \"learn_time_ms\": 42814.205}", "{\"n\": 11304, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3524.02, \"learn_time_ms\": 42782.479}", "{\"n\": 11305, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3517.04, \"learn_time_ms\": 42802.702}", "{\"n\": 11306, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3513.2, \"learn_time_ms\": 42960.751}", "{\"n\": 11307, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3507.22, \"learn_time_ms\": 43000.37}", "{\"n\": 11308, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3522.77, \"learn_time_ms\": 42975.525}", "{\"n\": 11309, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3522.77, \"learn_time_ms\": 42903.159}", "{\"n\": 11310, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.43, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.55, \"learn_time_ms\": 42855.465}", "{\"n\": 11311, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.91, \"learn_time_ms\": 42938.629}", "{\"n\": 11312, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3546.31, \"learn_time_ms\": 43058.62}", "{\"n\": 11313, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.04, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.27, \"learn_time_ms\": 43106.287}", "{\"n\": 11314, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.94, \"learn_time_ms\": 43046.961}", "{\"n\": 11315, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.26, \"learn_time_ms\": 43013.303}", "{\"n\": 11316, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3558.26, \"learn_time_ms\": 42909.353}", "{\"n\": 11317, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3566.47, \"learn_time_ms\": 42816.123}", "{\"n\": 11318, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3573.75, \"learn_time_ms\": 42851.065}", "{\"n\": 11319, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.66, \"learn_time_ms\": 42991.986}", "{\"n\": 11320, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.22, \"learn_time_ms\": 43079.208}", "{\"n\": 11321, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.22, \"learn_time_ms\": 42967.876}", "{\"n\": 11322, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3578.22, \"learn_time_ms\": 42922.339}", "{\"n\": 11323, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.19, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.0, \"learn_time_ms\": 42829.077}", "{\"n\": 11324, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.24, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3589.44, \"learn_time_ms\": 42750.421}", "{\"n\": 11325, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.1, \"learn_time_ms\": 42699.323}", "{\"n\": 11326, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.1, \"learn_time_ms\": 42704.558}", "{\"n\": 11327, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.1, \"learn_time_ms\": 42684.804}", "{\"n\": 11328, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3595.1, \"learn_time_ms\": 42734.66}", "{\"n\": 11329, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3584.64, \"learn_time_ms\": 42695.219}", "{\"n\": 11330, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3564.71, \"learn_time_ms\": 42645.265}", "{\"n\": 11331, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.98, \"learn_time_ms\": 42742.761}", "{\"n\": 11332, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.71, \"learn_time_ms\": 42804.187}", "{\"n\": 11333, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.71, \"learn_time_ms\": 42972.19}", "{\"n\": 11334, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.6, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3563.71, \"learn_time_ms\": 43257.649}", "{\"n\": 11335, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3539.47, \"learn_time_ms\": 43341.387}", "{\"n\": 11336, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.07, \"learn_time_ms\": 43399.591}", "{\"n\": 11337, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.63, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.13, \"learn_time_ms\": 43449.513}", "{\"n\": 11338, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.46, \"learn_time_ms\": 43415.2}", "{\"n\": 11339, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.46, \"learn_time_ms\": 43439.083}", "{\"n\": 11340, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.79, \"learn_time_ms\": 43503.268}", "{\"n\": 11341, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.56, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3548.68, \"learn_time_ms\": 43424.685}", "{\"n\": 11342, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.54, \"learn_time_ms\": 43499.173}", "{\"n\": 11343, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.4, \"learn_time_ms\": 43325.387}", "{\"n\": 11344, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.4, \"learn_time_ms\": 43181.707}", "{\"n\": 11345, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.4, \"learn_time_ms\": 43107.113}", "{\"n\": 11346, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.24, \"learn_time_ms\": 43113.221}", "{\"n\": 11347, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.67, \"learn_time_ms\": 43081.416}", "{\"n\": 11348, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.74, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.7, \"learn_time_ms\": 43099.134}", "{\"n\": 11349, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.61, \"learn_time_ms\": 42996.453}", "{\"n\": 11350, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.11, \"learn_time_ms\": 42900.233}", "{\"n\": 11351, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.99, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.11, \"learn_time_ms\": 42943.556}", "{\"n\": 11352, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3540.47, \"learn_time_ms\": 42828.694}", "{\"n\": 11353, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.27, \"learn_time_ms\": 42842.619}", "{\"n\": 11354, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.96, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.59, \"learn_time_ms\": 42782.168}", "{\"n\": 11355, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.39, \"learn_time_ms\": 42873.727}", "{\"n\": 11356, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.39, \"learn_time_ms\": 42789.683}", "{\"n\": 11357, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.21, \"learn_time_ms\": 42897.158}", "{\"n\": 11358, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3554.21, \"learn_time_ms\": 42937.37}", "{\"n\": 11359, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3550.43, \"learn_time_ms\": 42929.679}", "{\"n\": 11360, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.99, \"learn_time_ms\": 42966.442}", "{\"n\": 11361, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.99, \"learn_time_ms\": 43004.921}", "{\"n\": 11362, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.99, \"learn_time_ms\": 43070.153}", "{\"n\": 11363, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3559.35, \"learn_time_ms\": 43071.22}", "{\"n\": 11364, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.62, \"learn_time_ms\": 43161.293}", "{\"n\": 11365, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.21, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3532.71, \"learn_time_ms\": 43215.986}", "{\"n\": 11366, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3529.94, \"learn_time_ms\": 43211.125}", "{\"n\": 11367, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3530.57, \"learn_time_ms\": 43151.713}", "{\"n\": 11368, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3527.53, \"learn_time_ms\": 43190.144}", "{\"n\": 11369, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3522.62, \"learn_time_ms\": 43260.56}", "{\"n\": 11370, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3518.06, \"learn_time_ms\": 43377.498}", "{\"n\": 11371, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3524.11, \"learn_time_ms\": 43242.442}", "{\"n\": 11372, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3528.98, \"learn_time_ms\": 43176.148}", "{\"n\": 11373, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3538.37, \"learn_time_ms\": 43134.527}", "{\"n\": 11374, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3545.44, \"learn_time_ms\": 43140.967}", "{\"n\": 11375, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3542.86, \"learn_time_ms\": 42982.992}", "{\"n\": 11376, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3533.46, \"learn_time_ms\": 43078.367}", "{\"n\": 11377, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3533.46, \"learn_time_ms\": 43172.036}", "{\"n\": 11378, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3553.38, \"learn_time_ms\": 43025.613}", "{\"n\": 11379, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.51, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3553.38, \"learn_time_ms\": 43005.052}", "{\"n\": 11380, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.4, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3556.26, \"learn_time_ms\": 42916.277}", "{\"n\": 11381, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.38, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3547.87, \"learn_time_ms\": 43064.652}", "{\"n\": 11382, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.3, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3544.95, \"learn_time_ms\": 43032.906}", "{\"n\": 11383, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3536.16, \"learn_time_ms\": 43002.63}", "{\"n\": 11384, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.23, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3536.3, \"learn_time_ms\": 42849.772}", "{\"n\": 11385, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.76, \"learn_time_ms\": 42973.477}", "{\"n\": 11386, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3532.76, \"learn_time_ms\": 42926.684}", "{\"n\": 11387, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3538.8, \"learn_time_ms\": 42913.569}", "{\"n\": 11388, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3537.32, \"learn_time_ms\": 43013.589}", "{\"n\": 11389, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3537.32, \"learn_time_ms\": 42972.634}", "{\"n\": 11390, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3540.25, \"learn_time_ms\": 42938.437}", "{\"n\": 11391, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3528.72, \"learn_time_ms\": 43053.116}", "{\"n\": 11392, \"episode_reward_min\": -13.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3520.25, \"learn_time_ms\": 43078.62}", "{\"n\": 11393, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3494.86, \"learn_time_ms\": 43204.6}", "{\"n\": 11394, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3494.86, \"learn_time_ms\": 43367.369}", "{\"n\": 11395, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 12.0, \"episode_len_mean\": 3496.04, \"learn_time_ms\": 43253.376}", "{\"n\": 11396, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3496.01, \"learn_time_ms\": 43249.896}", "{\"n\": 11397, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3493.87, \"learn_time_ms\": 43210.971}", "{\"n\": 11398, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3492.51, \"learn_time_ms\": 43251.585}", "{\"n\": 11399, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3476.37, \"learn_time_ms\": 43332.808}", "{\"n\": 11400, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3494.98, \"learn_time_ms\": 43330.872}", "{\"n\": 11401, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3494.98, \"learn_time_ms\": 43196.605}", "{\"n\": 11402, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3494.98, \"learn_time_ms\": 43180.904}", "{\"n\": 11403, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3486.74, \"learn_time_ms\": 43162.725}", "{\"n\": 11404, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.35, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3486.74, \"learn_time_ms\": 43240.929}", "{\"n\": 11405, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.57, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3470.31, \"learn_time_ms\": 43274.481}", "{\"n\": 11406, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3472.24, \"learn_time_ms\": 43231.893}", "{\"n\": 11407, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3472.24, \"learn_time_ms\": 43209.676}", "{\"n\": 11408, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3472.24, \"learn_time_ms\": 43139.337}", "{\"n\": 11409, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3473.79, \"learn_time_ms\": 43023.815}", "{\"n\": 11410, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3449.34, \"learn_time_ms\": 43116.909}", "{\"n\": 11411, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.54, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3457.31, \"learn_time_ms\": 43061.04}", "{\"n\": 11412, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3460.37, \"learn_time_ms\": 43080.923}", "{\"n\": 11413, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3460.37, \"learn_time_ms\": 43078.95}", "{\"n\": 11414, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.64, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3458.96, \"learn_time_ms\": 42962.927}", "{\"n\": 11415, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.69, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3449.68, \"learn_time_ms\": 43011.237}", "{\"n\": 11416, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3442.34, \"learn_time_ms\": 43159.548}", "{\"n\": 11417, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3432.47, \"learn_time_ms\": 43198.939}", "{\"n\": 11418, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3432.47, \"learn_time_ms\": 43096.289}", "{\"n\": 11419, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3432.47, \"learn_time_ms\": 43165.264}", "{\"n\": 11420, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3429.44, \"learn_time_ms\": 43133.859}", "{\"n\": 11421, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3431.2, \"learn_time_ms\": 43094.717}", "{\"n\": 11422, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3410.49, \"learn_time_ms\": 43153.92}", "{\"n\": 11423, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3409.26, \"learn_time_ms\": 43259.782}", "{\"n\": 11424, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3409.26, \"learn_time_ms\": 43309.892}", "{\"n\": 11425, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3401.75, \"learn_time_ms\": 43327.246}", "{\"n\": 11426, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3401.75, \"learn_time_ms\": 43331.718}", "{\"n\": 11427, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3405.26, \"learn_time_ms\": 43321.005}", "{\"n\": 11428, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3406.69, \"learn_time_ms\": 43410.592}", "{\"n\": 11429, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3412.49, \"learn_time_ms\": 43340.69}", "{\"n\": 11430, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.73, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3412.49, \"learn_time_ms\": 43319.411}", "{\"n\": 11431, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3409.92, \"learn_time_ms\": 43436.148}", "{\"n\": 11432, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3414.68, \"learn_time_ms\": 43428.989}", "{\"n\": 11433, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3416.3, \"learn_time_ms\": 43307.509}", "{\"n\": 11434, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3428.25, \"learn_time_ms\": 43155.798}", "{\"n\": 11435, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3429.59, \"learn_time_ms\": 43102.161}", "{\"n\": 11436, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3441.66, \"learn_time_ms\": 42977.245}", "{\"n\": 11437, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3444.51, \"learn_time_ms\": 42862.521}", "{\"n\": 11438, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3443.01, \"learn_time_ms\": 42914.113}", "{\"n\": 11439, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3442.91, \"learn_time_ms\": 43000.61}", "{\"n\": 11440, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3454.63, \"learn_time_ms\": 43102.131}", "{\"n\": 11441, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3454.63, \"learn_time_ms\": 43126.152}", "{\"n\": 11442, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3452.32, \"learn_time_ms\": 43048.697}", "{\"n\": 11443, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.82, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3440.44, \"learn_time_ms\": 43085.835}", "{\"n\": 11444, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3434.32, \"learn_time_ms\": 43150.468}", "{\"n\": 11445, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.83, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3445.55, \"learn_time_ms\": 43155.234}", "{\"n\": 11446, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3442.79, \"learn_time_ms\": 43194.886}", "{\"n\": 11447, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3442.79, \"learn_time_ms\": 43452.674}", "{\"n\": 11448, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3427.1, \"learn_time_ms\": 43425.394}", "{\"n\": 11449, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3413.76, \"learn_time_ms\": 43360.763}", "{\"n\": 11450, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.18, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3404.92, \"learn_time_ms\": 43242.424}", "{\"n\": 11451, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3396.54, \"learn_time_ms\": 43154.688}", "{\"n\": 11452, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.4, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3396.54, \"learn_time_ms\": 43142.433}", "{\"n\": 11453, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3398.59, \"learn_time_ms\": 43168.28}", "{\"n\": 11454, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3387.74, \"learn_time_ms\": 43185.787}", "{\"n\": 11455, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3383.42, \"learn_time_ms\": 43184.128}", "{\"n\": 11456, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3383.42, \"learn_time_ms\": 43143.54}", "{\"n\": 11457, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3355.79, \"learn_time_ms\": 42944.689}", "{\"n\": 11458, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3355.79, \"learn_time_ms\": 42928.523}", "{\"n\": 11459, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3355.79, \"learn_time_ms\": 42972.145}", "{\"n\": 11460, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3358.34, \"learn_time_ms\": 42960.905}", "{\"n\": 11461, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3363.69, \"learn_time_ms\": 43090.082}", "{\"n\": 11462, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3363.98, \"learn_time_ms\": 43145.042}", "{\"n\": 11463, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3369.39, \"learn_time_ms\": 43065.857}", "{\"n\": 11464, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3378.6, \"learn_time_ms\": 43147.129}", "{\"n\": 11465, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3374.94, \"learn_time_ms\": 43231.352}", "{\"n\": 11466, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.49, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3376.06, \"learn_time_ms\": 43304.188}", "{\"n\": 11467, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3373.73, \"learn_time_ms\": 43326.023}", "{\"n\": 11468, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3373.73, \"learn_time_ms\": 43330.836}", "{\"n\": 11469, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3373.73, \"learn_time_ms\": 43334.759}", "{\"n\": 11470, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3379.15, \"learn_time_ms\": 43375.006}", "{\"n\": 11471, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3373.66, \"learn_time_ms\": 43262.214}", "{\"n\": 11472, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3369.51, \"learn_time_ms\": 43215.896}", "{\"n\": 11473, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3369.51, \"learn_time_ms\": 43258.425}", "{\"n\": 11474, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3382.69, \"learn_time_ms\": 43103.232}", "{\"n\": 11475, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.47, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3398.59, \"learn_time_ms\": 43085.871}", "{\"n\": 11476, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3404.24, \"learn_time_ms\": 43113.351}", "{\"n\": 11477, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3404.24, \"learn_time_ms\": 43088.397}", "{\"n\": 11478, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3399.25, \"learn_time_ms\": 43115.953}", "{\"n\": 11479, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.3, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3405.73, \"learn_time_ms\": 43142.259}", "{\"n\": 11480, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3410.26, \"learn_time_ms\": 43104.431}", "{\"n\": 11481, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3410.26, \"learn_time_ms\": 43110.826}", "{\"n\": 11482, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3419.53, \"learn_time_ms\": 43176.613}", "{\"n\": 11483, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3419.53, \"learn_time_ms\": 43211.916}", "{\"n\": 11484, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.55, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3411.81, \"learn_time_ms\": 43288.048}", "{\"n\": 11485, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3405.82, \"learn_time_ms\": 43181.569}", "{\"n\": 11486, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3400.64, \"learn_time_ms\": 43196.596}", "{\"n\": 11487, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.64, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3410.8, \"learn_time_ms\": 43165.099}", "{\"n\": 11488, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3416.63, \"learn_time_ms\": 43156.485}", "{\"n\": 11489, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.43, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3429.75, \"learn_time_ms\": 43228.814}", "{\"n\": 11490, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.19, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3441.53, \"learn_time_ms\": 43147.019}", "{\"n\": 11491, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.45, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3437.69, \"learn_time_ms\": 43192.029}", "{\"n\": 11492, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3438.03, \"learn_time_ms\": 43204.196}", "{\"n\": 11493, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3438.03, \"learn_time_ms\": 43185.69}", "{\"n\": 11494, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 9.0, \"episode_len_mean\": 3426.4, \"learn_time_ms\": 43264.328}", "{\"n\": 11495, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.57, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3428.86, \"learn_time_ms\": 43459.309}", "{\"n\": 11496, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3418.61, \"learn_time_ms\": 43305.968}", "{\"n\": 11497, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3417.97, \"learn_time_ms\": 43502.675}", "{\"n\": 11498, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3417.97, \"learn_time_ms\": 43572.704}", "{\"n\": 11499, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3417.97, \"learn_time_ms\": 43438.449}", "{\"n\": 11500, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3408.97, \"learn_time_ms\": 43490.826}", "{\"n\": 11501, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3403.67, \"learn_time_ms\": 43494.697}", "{\"n\": 11502, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3389.47, \"learn_time_ms\": 43441.877}", "{\"n\": 11503, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3389.47, \"learn_time_ms\": 43447.708}", "{\"n\": 11504, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3389.47, \"learn_time_ms\": 43277.456}", "{\"n\": 11505, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3379.34, \"learn_time_ms\": 43153.389}", "{\"n\": 11506, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.88, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3379.34, \"learn_time_ms\": 43274.851}", "{\"n\": 11507, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3379.69, \"learn_time_ms\": 43068.967}", "{\"n\": 11508, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3387.68, \"learn_time_ms\": 42949.682}", "{\"n\": 11509, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3385.07, \"learn_time_ms\": 42879.926}", "{\"n\": 11510, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3383.31, \"learn_time_ms\": 42884.898}", "{\"n\": 11511, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3376.63, \"learn_time_ms\": 42864.267}", "{\"n\": 11512, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3380.63, \"learn_time_ms\": 42934.696}", "{\"n\": 11513, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3376.41, \"learn_time_ms\": 43026.751}", "{\"n\": 11514, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3375.59, \"learn_time_ms\": 43109.835}", "{\"n\": 11515, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3371.32, \"learn_time_ms\": 43114.239}", "{\"n\": 11516, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3372.91, \"learn_time_ms\": 43127.125}", "{\"n\": 11517, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3377.4, \"learn_time_ms\": 43185.275}", "{\"n\": 11518, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3383.08, \"learn_time_ms\": 43262.985}", "{\"n\": 11519, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3383.08, \"learn_time_ms\": 43356.929}", "{\"n\": 11520, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3393.72, \"learn_time_ms\": 43566.485}", "{\"n\": 11521, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.33, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3403.5, \"learn_time_ms\": 43421.763}", "{\"n\": 11522, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.23, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3411.71, \"learn_time_ms\": 43352.946}", "{\"n\": 11523, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3412.26, \"learn_time_ms\": 43271.617}", "{\"n\": 11524, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3418.73, \"learn_time_ms\": 43281.061}", "{\"n\": 11525, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -3.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3418.73, \"learn_time_ms\": 43299.941}", "{\"n\": 11526, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3427.72, \"learn_time_ms\": 43223.708}", "{\"n\": 11527, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3429.78, \"learn_time_ms\": 43180.974}", "{\"n\": 11528, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3447.65, \"learn_time_ms\": 43129.509}", "{\"n\": 11529, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3454.32, \"learn_time_ms\": 43208.562}", "{\"n\": 11530, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3464.82, \"learn_time_ms\": 43056.128}", "{\"n\": 11531, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3464.82, \"learn_time_ms\": 43248.344}", "{\"n\": 11532, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -2.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3474.41, \"learn_time_ms\": 43330.123}", "{\"n\": 11533, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -1.98, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3474.72, \"learn_time_ms\": 43214.267}", "{\"n\": 11534, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -1.67, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3493.15, \"learn_time_ms\": 43197.951}", "{\"n\": 11535, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3502.25, \"learn_time_ms\": 43152.76}", "{\"n\": 11536, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3502.25, \"learn_time_ms\": 43176.324}", "{\"n\": 11537, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3502.25, \"learn_time_ms\": 43383.672}", "{\"n\": 11538, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -1.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3504.66, \"learn_time_ms\": 43410.77}", "{\"n\": 11539, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3524.94, \"learn_time_ms\": 43395.121}", "{\"n\": 11540, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -1.5, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3526.79, \"learn_time_ms\": 43483.921}", "{\"n\": 11541, \"episode_reward_min\": -18.0, \"episode_reward_mean\": -1.34, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3516.41, \"learn_time_ms\": 43406.395}", "{\"n\": 11542, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3535.97, \"learn_time_ms\": 43247.726}", "{\"n\": 11543, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.17, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3535.97, \"learn_time_ms\": 43356.944}", "{\"n\": 11544, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3533.88, \"learn_time_ms\": 43407.686}", "{\"n\": 11545, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.53, \"learn_time_ms\": 43408.054}", "{\"n\": 11546, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.71, \"learn_time_ms\": 43396.729}", "{\"n\": 11547, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3546.7, \"learn_time_ms\": 43265.512}", "{\"n\": 11548, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.89, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.91, \"learn_time_ms\": 43224.217}", "{\"n\": 11549, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.01, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3526.28, \"learn_time_ms\": 43145.654}", "{\"n\": 11550, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3522.72, \"learn_time_ms\": 43021.727}", "{\"n\": 11551, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3525.69, \"learn_time_ms\": 43127.93}", "{\"n\": 11552, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3525.69, \"learn_time_ms\": 43154.339}", "{\"n\": 11553, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3510.31, \"learn_time_ms\": 43046.859}", "{\"n\": 11554, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3503.84, \"learn_time_ms\": 42930.309}", "{\"n\": 11555, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3503.84, \"learn_time_ms\": 42857.881}", "{\"n\": 11556, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3489.64, \"learn_time_ms\": 42829.921}", "{\"n\": 11557, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3487.55, \"learn_time_ms\": 42826.735}", "{\"n\": 11558, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3485.09, \"learn_time_ms\": 42891.07}", "{\"n\": 11559, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3485.09, \"learn_time_ms\": 42847.543}", "{\"n\": 11560, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3504.18, \"learn_time_ms\": 42966.432}", "{\"n\": 11561, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.75, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3504.18, \"learn_time_ms\": 42892.359}", "{\"n\": 11562, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3505.86, \"learn_time_ms\": 43114.569}", "{\"n\": 11563, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.83, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3505.86, \"learn_time_ms\": 43191.652}", "{\"n\": 11564, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.0, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3506.22, \"learn_time_ms\": 43261.153}", "{\"n\": 11565, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3526.54, \"learn_time_ms\": 43272.222}", "{\"n\": 11566, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3550.4, \"learn_time_ms\": 43256.764}", "{\"n\": 11567, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3550.4, \"learn_time_ms\": 43249.744}", "{\"n\": 11568, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.97, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3549.9, \"learn_time_ms\": 43234.291}", "{\"n\": 11569, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.02, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3544.87, \"learn_time_ms\": 43269.254}", "{\"n\": 11570, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.13, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3547.9, \"learn_time_ms\": 43161.086}", "{\"n\": 11571, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.92, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.96, \"learn_time_ms\": 43117.797}", "{\"n\": 11572, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.19, \"learn_time_ms\": 42968.664}", "{\"n\": 11573, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3542.19, \"learn_time_ms\": 42981.346}", "{\"n\": 11574, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.26, \"learn_time_ms\": 42976.887}", "{\"n\": 11575, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3541.26, \"learn_time_ms\": 43024.879}", "{\"n\": 11576, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.07, \"learn_time_ms\": 43013.089}", "{\"n\": 11577, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.36, \"learn_time_ms\": 42974.861}", "{\"n\": 11578, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.36, \"learn_time_ms\": 42927.202}", "{\"n\": 11579, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.72, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3551.36, \"learn_time_ms\": 42920.337}", "{\"n\": 11580, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.25, \"learn_time_ms\": 42948.405}", "{\"n\": 11581, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.71, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3556.25, \"learn_time_ms\": 43029.012}", "{\"n\": 11582, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.69, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3562.14, \"learn_time_ms\": 42959.245}", "{\"n\": 11583, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.2, \"learn_time_ms\": 42898.795}", "{\"n\": 11584, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.51, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3553.2, \"learn_time_ms\": 42968.448}", "{\"n\": 11585, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.64, \"learn_time_ms\": 42977.068}", "{\"n\": 11586, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3557.64, \"learn_time_ms\": 43041.635}", "{\"n\": 11587, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3560.86, \"learn_time_ms\": 43032.563}", "{\"n\": 11588, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3567.45, \"learn_time_ms\": 43045.854}", "{\"n\": 11589, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.12, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.58, \"learn_time_ms\": 43051.268}", "{\"n\": 11590, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3570.4, \"learn_time_ms\": 42982.019}", "{\"n\": 11591, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3571.53, \"learn_time_ms\": 42894.006}", "{\"n\": 11592, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3571.53, \"learn_time_ms\": 42995.578}", "{\"n\": 11593, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3553.48, \"learn_time_ms\": 42975.194}", "{\"n\": 11594, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3547.51, \"learn_time_ms\": 42868.665}", "{\"n\": 11595, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.09, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3553.76, \"learn_time_ms\": 43020.272}", "{\"n\": 11596, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3562.26, \"learn_time_ms\": 43010.898}", "{\"n\": 11597, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.22, \"learn_time_ms\": 43092.025}", "{\"n\": 11598, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3565.22, \"learn_time_ms\": 43146.906}", "{\"n\": 11599, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3561.25, \"learn_time_ms\": 43084.36}", "{\"n\": 11600, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.37, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.02, \"learn_time_ms\": 43174.84}", "{\"n\": 11601, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.6, \"learn_time_ms\": 43162.688}", "{\"n\": 11602, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3558.6, \"learn_time_ms\": 43124.291}", "{\"n\": 11603, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3559.05, \"learn_time_ms\": 43156.275}", "{\"n\": 11604, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3557.21, \"learn_time_ms\": 43102.891}", "{\"n\": 11605, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3557.21, \"learn_time_ms\": 42955.025}", "{\"n\": 11606, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.37, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3552.6, \"learn_time_ms\": 42956.414}", "{\"n\": 11607, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.38, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3529.9, \"learn_time_ms\": 42820.662}", "{\"n\": 11608, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.29, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3531.71, \"learn_time_ms\": 42814.898}", "{\"n\": 11609, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3531.01, \"learn_time_ms\": 42876.826}", "{\"n\": 11610, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3524.85, \"learn_time_ms\": 42830.189}", "{\"n\": 11611, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3524.85, \"learn_time_ms\": 42920.335}", "{\"n\": 11612, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.44, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3516.42, \"learn_time_ms\": 42943.405}", "{\"n\": 11613, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3514.85, \"learn_time_ms\": 43050.177}", "{\"n\": 11614, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.55, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3523.66, \"learn_time_ms\": 43073.124}", "{\"n\": 11615, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.52, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3528.7, \"learn_time_ms\": 43061.526}", "{\"n\": 11616, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3504.3, \"learn_time_ms\": 43029.775}", "{\"n\": 11617, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.78, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3505.2, \"learn_time_ms\": 43076.84}", "{\"n\": 11618, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3506.79, \"learn_time_ms\": 42940.96}", "{\"n\": 11619, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3503.9, \"learn_time_ms\": 42982.218}", "{\"n\": 11620, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.85, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3503.9, \"learn_time_ms\": 43070.72}", "{\"n\": 11621, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3523.63, \"learn_time_ms\": 43011.399}", "{\"n\": 11622, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.11, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3511.08, \"learn_time_ms\": 42965.409}", "{\"n\": 11623, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.03, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3507.37, \"learn_time_ms\": 42903.057}", "{\"n\": 11624, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3490.4, \"learn_time_ms\": 42962.854}", "{\"n\": 11625, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3487.01, \"learn_time_ms\": 42880.326}", "{\"n\": 11626, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3491.06, \"learn_time_ms\": 42927.765}", "{\"n\": 11627, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3494.7, \"learn_time_ms\": 42987.864}", "{\"n\": 11628, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.16, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3517.01, \"learn_time_ms\": 43143.512}", "{\"n\": 11629, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.99, \"learn_time_ms\": 43042.065}", "{\"n\": 11630, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3526.34, \"learn_time_ms\": 42943.308}", "{\"n\": 11631, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3526.34, \"learn_time_ms\": 42936.919}", "{\"n\": 11632, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3529.67, \"learn_time_ms\": 42889.29}", "{\"n\": 11633, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3514.39, \"learn_time_ms\": 42819.962}", "{\"n\": 11634, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3514.39, \"learn_time_ms\": 42801.514}", "{\"n\": 11635, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.1, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3514.39, \"learn_time_ms\": 42927.542}", "{\"n\": 11636, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3508.56, \"learn_time_ms\": 42912.129}", "{\"n\": 11637, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3506.61, \"learn_time_ms\": 42904.816}", "{\"n\": 11638, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.12, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3500.0, \"learn_time_ms\": 42768.83}", "{\"n\": 11639, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3493.95, \"learn_time_ms\": 42858.623}", "{\"n\": 11640, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.84, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3493.95, \"learn_time_ms\": 42833.595}", "{\"n\": 11641, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3502.62, \"learn_time_ms\": 42784.223}", "{\"n\": 11642, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.9, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3490.5, \"learn_time_ms\": 42867.155}", "{\"n\": 11643, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.86, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3498.1, \"learn_time_ms\": 42852.254}", "{\"n\": 11644, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.8, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3503.54, \"learn_time_ms\": 42918.13}", "{\"n\": 11645, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.61, \"learn_time_ms\": 42797.709}", "{\"n\": 11646, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.67, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3520.61, \"learn_time_ms\": 42888.621}", "{\"n\": 11647, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3513.52, \"learn_time_ms\": 42834.754}", "{\"n\": 11648, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3513.52, \"learn_time_ms\": 42906.895}", "{\"n\": 11649, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3506.59, \"learn_time_ms\": 42906.569}", "{\"n\": 11650, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.88, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3501.85, \"learn_time_ms\": 42905.025}", "{\"n\": 11651, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3511.03, \"learn_time_ms\": 42896.109}", "{\"n\": 11652, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.81, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3511.03, \"learn_time_ms\": 42866.432}", "{\"n\": 11653, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.93, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3502.71, \"learn_time_ms\": 42858.225}", "{\"n\": 11654, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.94, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3503.44, \"learn_time_ms\": 42850.012}", "{\"n\": 11655, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -0.95, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3515.93, \"learn_time_ms\": 42906.949}", "{\"n\": 11656, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3506.99, \"learn_time_ms\": 42739.323}", "{\"n\": 11657, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.24, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3505.2, \"learn_time_ms\": 42763.94}", "{\"n\": 11658, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3491.07, \"learn_time_ms\": 42775.213}", "{\"n\": 11659, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3488.77, \"learn_time_ms\": 42709.744}", "{\"n\": 11660, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3480.68, \"learn_time_ms\": 42788.652}", "{\"n\": 11661, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -1.89, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3490.63, \"learn_time_ms\": 42826.968}", "{\"n\": 11662, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.13, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3484.68, \"learn_time_ms\": 42841.862}", "{\"n\": 11663, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3495.93, \"learn_time_ms\": 43005.236}", "{\"n\": 11664, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.07, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3495.93, \"learn_time_ms\": 42942.822}", "{\"n\": 11665, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.12, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3513.23, \"learn_time_ms\": 43030.451}", "{\"n\": 11666, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3515.77, \"learn_time_ms\": 43037.978}", "{\"n\": 11667, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.15, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3508.89, \"learn_time_ms\": 43013.878}", "{\"n\": 11668, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.34, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3479.9, \"learn_time_ms\": 43024.001}", "{\"n\": 11669, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3483.51, \"learn_time_ms\": 43058.494}", "{\"n\": 11670, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.08, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3483.25, \"learn_time_ms\": 43031.983}", "{\"n\": 11671, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3480.56, \"learn_time_ms\": 43017.351}", "{\"n\": 11672, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.14, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3480.56, \"learn_time_ms\": 43053.463}", "{\"n\": 11673, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3479.36, \"learn_time_ms\": 42952.536}", "{\"n\": 11674, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3462.46, \"learn_time_ms\": 42986.608}", "{\"n\": 11675, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3458.49, \"learn_time_ms\": 42902.901}", "{\"n\": 11676, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3467.06, \"learn_time_ms\": 42916.558}", "{\"n\": 11677, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3464.11, \"learn_time_ms\": 43077.434}", "{\"n\": 11678, \"episode_reward_min\": -14.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3453.5, \"learn_time_ms\": 43034.439}", "{\"n\": 11679, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3444.53, \"learn_time_ms\": 43087.696}", "{\"n\": 11680, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.25, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3441.77, \"learn_time_ms\": 43057.667}", "{\"n\": 11681, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3452.39, \"learn_time_ms\": 43048.623}", "{\"n\": 11682, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3452.39, \"learn_time_ms\": 43026.08}", "{\"n\": 11683, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3456.22, \"learn_time_ms\": 43006.021}", "{\"n\": 11684, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3456.22, \"learn_time_ms\": 42972.672}", "{\"n\": 11685, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3437.79, \"learn_time_ms\": 42948.632}", "{\"n\": 11686, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3421.17, \"learn_time_ms\": 43044.667}", "{\"n\": 11687, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.11, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3434.75, \"learn_time_ms\": 42875.987}", "{\"n\": 11688, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3446.95, \"learn_time_ms\": 42901.548}", "{\"n\": 11689, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.94, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3446.95, \"learn_time_ms\": 42890.077}", "{\"n\": 11690, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3447.75, \"learn_time_ms\": 42856.184}", "{\"n\": 11691, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3455.98, \"learn_time_ms\": 42841.6}", "{\"n\": 11692, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.02, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3456.63, \"learn_time_ms\": 42927.164}", "{\"n\": 11693, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 15.0, \"episode_len_mean\": 3460.95, \"learn_time_ms\": 42877.615}", "{\"n\": 11694, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3467.75, \"learn_time_ms\": 43008.89}", "{\"n\": 11695, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3467.75, \"learn_time_ms\": 43124.34}", "{\"n\": 11696, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.03, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3467.75, \"learn_time_ms\": 42967.358}", "{\"n\": 11697, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.89, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3488.99, \"learn_time_ms\": 43048.502}", "{\"n\": 11698, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.93, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3480.73, \"learn_time_ms\": 43091.251}", "{\"n\": 11699, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.0, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3480.51, \"learn_time_ms\": 43025.715}", "{\"n\": 11700, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3467.49, \"learn_time_ms\": 43068.949}", "{\"n\": 11701, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.18, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3467.49, \"learn_time_ms\": 43112.965}", "{\"n\": 11702, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3474.59, \"learn_time_ms\": 43004.979}", "{\"n\": 11703, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3469.85, \"learn_time_ms\": 43147.064}", "{\"n\": 11704, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.53, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3450.57, \"learn_time_ms\": 43011.187}", "{\"n\": 11705, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3471.4, \"learn_time_ms\": 42918.15}", "{\"n\": 11706, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.59, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3471.4, \"learn_time_ms\": 43052.161}", "{\"n\": 11707, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3459.64, \"learn_time_ms\": 43058.208}", "{\"n\": 11708, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.84, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3440.79, \"learn_time_ms\": 42984.892}", "{\"n\": 11709, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3457.25, \"learn_time_ms\": 43017.122}", "{\"n\": 11710, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3445.74, \"learn_time_ms\": 43032.595}", "{\"n\": 11711, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3445.74, \"learn_time_ms\": 43064.096}", "{\"n\": 11712, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.83, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3444.46, \"learn_time_ms\": 43003.325}", "{\"n\": 11713, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3449.14, \"learn_time_ms\": 42939.223}", "{\"n\": 11714, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3425.47, \"learn_time_ms\": 42986.674}", "{\"n\": 11715, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3407.41, \"learn_time_ms\": 42976.083}", "{\"n\": 11716, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3407.41, \"learn_time_ms\": 42993.137}", "{\"n\": 11717, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3407.41, \"learn_time_ms\": 42966.29}", "{\"n\": 11718, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3416.28, \"learn_time_ms\": 42993.427}", "{\"n\": 11719, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3425.52, \"learn_time_ms\": 43027.151}", "{\"n\": 11720, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.0, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3422.01, \"learn_time_ms\": 43057.719}", "{\"n\": 11721, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3410.96, \"learn_time_ms\": 43025.832}", "{\"n\": 11722, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3410.96, \"learn_time_ms\": 43112.258}", "{\"n\": 11723, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3411.78, \"learn_time_ms\": 43062.329}", "{\"n\": 11724, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3411.78, \"learn_time_ms\": 43049.122}", "{\"n\": 11725, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3411.78, \"learn_time_ms\": 43008.783}", "{\"n\": 11726, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3420.09, \"learn_time_ms\": 42988.983}", "{\"n\": 11727, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3431.15, \"learn_time_ms\": 43067.111}", "{\"n\": 11728, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.31, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3434.55, \"learn_time_ms\": 43179.841}", "{\"n\": 11729, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3443.41, \"learn_time_ms\": 43128.44}", "{\"n\": 11730, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3443.41, \"learn_time_ms\": 43143.0}", "{\"n\": 11731, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.14, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3445.1, \"learn_time_ms\": 43180.389}", "{\"n\": 11732, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.97, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3457.27, \"learn_time_ms\": 43203.672}", "{\"n\": 11733, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.76, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3452.79, \"learn_time_ms\": 43213.214}", "{\"n\": 11734, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3453.18, \"learn_time_ms\": 43113.386}", "{\"n\": 11735, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3453.18, \"learn_time_ms\": 43206.629}", "{\"n\": 11736, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3445.5, \"learn_time_ms\": 43059.745}", "{\"n\": 11737, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.6, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3444.71, \"learn_time_ms\": 43012.348}", "{\"n\": 11738, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3444.92, \"learn_time_ms\": 42926.685}", "{\"n\": 11739, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3459.61, \"learn_time_ms\": 43045.079}", "{\"n\": 11740, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3468.75, \"learn_time_ms\": 43025.945}", "{\"n\": 11741, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.3, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3468.75, \"learn_time_ms\": 42974.258}", "{\"n\": 11742, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3487.1, \"learn_time_ms\": 42943.174}", "{\"n\": 11743, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3484.4, \"learn_time_ms\": 42968.53}", "{\"n\": 11744, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.39, \"episode_reward_max\": 16.0, \"episode_len_mean\": 3477.5, \"learn_time_ms\": 43082.532}", "{\"n\": 11745, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3489.19, \"learn_time_ms\": 43103.444}", "{\"n\": 11746, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.05, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3489.19, \"learn_time_ms\": 43206.311}", "{\"n\": 11747, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.17, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3487.92, \"learn_time_ms\": 43250.538}", "{\"n\": 11748, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3450.83, \"learn_time_ms\": 43203.305}", "{\"n\": 11749, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3452.23, \"learn_time_ms\": 43179.987}", "{\"n\": 11750, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3452.23, \"learn_time_ms\": 43230.403}", "{\"n\": 11751, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3474.02, \"learn_time_ms\": 43307.075}", "{\"n\": 11752, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3474.02, \"learn_time_ms\": 43314.126}", "{\"n\": 11753, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.23, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3451.41, \"learn_time_ms\": 43288.694}", "{\"n\": 11754, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3457.85, \"learn_time_ms\": 43298.616}", "{\"n\": 11755, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3457.85, \"learn_time_ms\": 43191.522}", "{\"n\": 11756, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3457.85, \"learn_time_ms\": 43192.995}", "{\"n\": 11757, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3476.31, \"learn_time_ms\": 43149.945}", "{\"n\": 11758, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.56, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3472.77, \"learn_time_ms\": 43267.156}", "{\"n\": 11759, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3449.88, \"learn_time_ms\": 43179.779}", "{\"n\": 11760, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3446.22, \"learn_time_ms\": 43078.749}", "{\"n\": 11761, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3446.22, \"learn_time_ms\": 43022.285}", "{\"n\": 11762, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3446.22, \"learn_time_ms\": 43053.631}", "{\"n\": 11763, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.96, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3431.47, \"learn_time_ms\": 43190.846}", "{\"n\": 11764, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3416.0, \"learn_time_ms\": 43184.271}", "{\"n\": 11765, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.1, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3416.0, \"learn_time_ms\": 43324.028}", "{\"n\": 11766, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3431.21, \"learn_time_ms\": 43252.691}", "{\"n\": 11767, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.74, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3431.21, \"learn_time_ms\": 43319.294}", "{\"n\": 11768, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3429.78, \"learn_time_ms\": 43150.712}", "{\"n\": 11769, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.63, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3428.53, \"learn_time_ms\": 43160.621}", "{\"n\": 11770, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.64, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3423.57, \"learn_time_ms\": 43193.226}", "{\"n\": 11771, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.35, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3439.05, \"learn_time_ms\": 43273.109}", "{\"n\": 11772, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.42, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3430.25, \"learn_time_ms\": 43241.976}", "{\"n\": 11773, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3411.9, \"learn_time_ms\": 43130.437}", "{\"n\": 11774, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3410.87, \"learn_time_ms\": 43034.964}", "{\"n\": 11775, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3419.79, \"learn_time_ms\": 43050.244}", "{\"n\": 11776, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.53, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3409.77, \"learn_time_ms\": 43132.334}", "{\"n\": 11777, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.54, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3412.15, \"learn_time_ms\": 43028.433}", "{\"n\": 11778, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.36, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3430.75, \"learn_time_ms\": 43150.627}", "{\"n\": 11779, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3419.96, \"learn_time_ms\": 43182.17}", "{\"n\": 11780, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3412.56, \"learn_time_ms\": 43202.957}", "{\"n\": 11781, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3415.38, \"learn_time_ms\": 43162.507}", "{\"n\": 11782, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3421.55, \"learn_time_ms\": 43176.978}", "{\"n\": 11783, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.61, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3413.36, \"learn_time_ms\": 43257.641}", "{\"n\": 11784, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.8, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3411.4, \"learn_time_ms\": 43367.439}", "{\"n\": 11785, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.77, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3416.14, \"learn_time_ms\": 43299.938}", "{\"n\": 11786, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3429.07, \"learn_time_ms\": 43278.369}", "{\"n\": 11787, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.9, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3429.07, \"learn_time_ms\": 43333.408}", "{\"n\": 11788, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.75, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3447.39, \"learn_time_ms\": 43413.046}", "{\"n\": 11789, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.81, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3432.18, \"learn_time_ms\": 43479.891}", "{\"n\": 11790, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.69, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3445.37, \"learn_time_ms\": 43498.155}", "{\"n\": 11791, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -2.82, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3446.05, \"learn_time_ms\": 43556.48}", "{\"n\": 11792, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3453.85, \"learn_time_ms\": 43546.247}", "{\"n\": 11793, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.01, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3453.85, \"learn_time_ms\": 43469.43}", "{\"n\": 11794, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.13, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3454.32, \"learn_time_ms\": 43459.786}", "{\"n\": 11795, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.07, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3451.08, \"learn_time_ms\": 43458.873}", "{\"n\": 11796, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3439.53, \"learn_time_ms\": 43515.939}", "{\"n\": 11797, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3440.8, \"learn_time_ms\": 43476.953}", "{\"n\": 11798, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3421.96, \"learn_time_ms\": 43416.051}", "{\"n\": 11799, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3416.1, \"learn_time_ms\": 43304.161}", "{\"n\": 11800, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3420.03, \"learn_time_ms\": 43298.869}", "{\"n\": 11801, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.36, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3413.42, \"learn_time_ms\": 43292.513}", "{\"n\": 11802, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3410.51, \"learn_time_ms\": 43248.306}", "{\"n\": 11803, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.4, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3408.24, \"learn_time_ms\": 43255.762}", "{\"n\": 11804, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.42, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3405.73, \"learn_time_ms\": 43150.756}", "{\"n\": 11805, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3405.71, \"learn_time_ms\": 43169.41}", "{\"n\": 11806, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3401.9, \"learn_time_ms\": 43147.731}", "{\"n\": 11807, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3401.9, \"learn_time_ms\": 43179.076}", "{\"n\": 11808, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.51, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3399.15, \"learn_time_ms\": 43075.558}", "{\"n\": 11809, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3400.51, \"learn_time_ms\": 43108.879}", "{\"n\": 11810, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3383.83, \"learn_time_ms\": 43169.181}", "{\"n\": 11811, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3384.37, \"learn_time_ms\": 43150.354}", "{\"n\": 11812, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3384.37, \"learn_time_ms\": 43110.557}", "{\"n\": 11813, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3382.79, \"learn_time_ms\": 43159.865}", "{\"n\": 11814, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -3.7, \"episode_reward_max\": 18.0, \"episode_len_mean\": 3374.11, \"learn_time_ms\": 43271.173}", "{\"n\": 11815, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.11, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3370.13, \"learn_time_ms\": 43290.353}", "{\"n\": 11816, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3370.22, \"learn_time_ms\": 43326.995}", "{\"n\": 11817, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3370.22, \"learn_time_ms\": 43308.443}", "{\"n\": 11818, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3415.95, \"learn_time_ms\": 43374.043}", "{\"n\": 11819, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3415.95, \"learn_time_ms\": 43469.784}", "{\"n\": 11820, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3415.95, \"learn_time_ms\": 43385.949}", "{\"n\": 11821, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3400.37, \"learn_time_ms\": 43433.089}", "{\"n\": 11822, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3400.37, \"learn_time_ms\": 43511.248}", "{\"n\": 11823, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.12, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3400.37, \"learn_time_ms\": 43482.107}", "{\"n\": 11824, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3398.62, \"learn_time_ms\": 43552.427}", "{\"n\": 11825, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3401.17, \"learn_time_ms\": 43577.902}", "{\"n\": 11826, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3404.88, \"learn_time_ms\": 43531.191}", "{\"n\": 11827, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3404.88, \"learn_time_ms\": 43515.428}", "{\"n\": 11828, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3410.93, \"learn_time_ms\": 43461.194}", "{\"n\": 11829, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3415.23, \"learn_time_ms\": 43439.791}", "{\"n\": 11830, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3415.23, \"learn_time_ms\": 43340.3}", "{\"n\": 11831, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.54, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3424.02, \"learn_time_ms\": 43304.307}", "{\"n\": 11832, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3412.12, \"learn_time_ms\": 43344.356}", "{\"n\": 11833, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3399.93, \"learn_time_ms\": 43384.702}", "{\"n\": 11834, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.78, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3405.04, \"learn_time_ms\": 43340.441}", "{\"n\": 11835, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3417.52, \"learn_time_ms\": 43260.014}", "{\"n\": 11836, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3417.52, \"learn_time_ms\": 43228.339}", "{\"n\": 11837, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.89, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3418.22, \"learn_time_ms\": 43268.078}", "{\"n\": 11838, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.9, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3410.66, \"learn_time_ms\": 43288.123}", "{\"n\": 11839, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3419.85, \"learn_time_ms\": 43183.162}", "{\"n\": 11840, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3399.32, \"learn_time_ms\": 43354.812}", "{\"n\": 11841, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3399.32, \"learn_time_ms\": 43252.61}", "{\"n\": 11842, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.94, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3399.32, \"learn_time_ms\": 43216.786}", "{\"n\": 11843, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3394.77, \"learn_time_ms\": 43239.782}", "{\"n\": 11844, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.91, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3403.06, \"learn_time_ms\": 43213.585}", "{\"n\": 11845, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.82, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3414.25, \"learn_time_ms\": 43169.459}", "{\"n\": 11846, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.62, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3434.44, \"learn_time_ms\": 43202.781}", "{\"n\": 11847, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.68, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3430.96, \"learn_time_ms\": 43142.326}", "{\"n\": 11848, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3430.84, \"learn_time_ms\": 43204.765}", "{\"n\": 11849, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.44, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3440.79, \"learn_time_ms\": 43215.224}", "{\"n\": 11850, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3447.44, \"learn_time_ms\": 43170.609}", "{\"n\": 11851, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3451.55, \"learn_time_ms\": 43227.599}", "{\"n\": 11852, \"episode_reward_min\": -16.0, \"episode_reward_mean\": -3.37, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3450.86, \"learn_time_ms\": 43302.818}", "{\"n\": 11853, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.48, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3433.05, \"learn_time_ms\": 43298.316}", "{\"n\": 11854, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3433.12, \"learn_time_ms\": 43290.682}", "{\"n\": 11855, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3428.89, \"learn_time_ms\": 43375.342}", "{\"n\": 11856, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3420.16, \"learn_time_ms\": 43427.971}", "{\"n\": 11857, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.5, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3420.16, \"learn_time_ms\": 43494.409}", "{\"n\": 11858, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.61, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3397.77, \"learn_time_ms\": 43492.366}", "{\"n\": 11859, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3396.97, \"learn_time_ms\": 43498.638}", "{\"n\": 11860, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.76, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3389.08, \"learn_time_ms\": 43545.787}", "{\"n\": 11861, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3379.31, \"learn_time_ms\": 43543.115}", "{\"n\": 11862, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3388.56, \"learn_time_ms\": 43352.942}", "{\"n\": 11863, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3388.56, \"learn_time_ms\": 43374.443}", "{\"n\": 11864, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.81, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3388.56, \"learn_time_ms\": 43420.199}", "{\"n\": 11865, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3374.79, \"learn_time_ms\": 43362.816}", "{\"n\": 11866, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3365.37, \"learn_time_ms\": 43240.404}", "{\"n\": 11867, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.75, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3372.21, \"learn_time_ms\": 43234.354}", "{\"n\": 11868, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3374.14, \"learn_time_ms\": 43172.639}", "{\"n\": 11869, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3374.14, \"learn_time_ms\": 43229.016}", "{\"n\": 11870, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.63, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3374.14, \"learn_time_ms\": 43128.391}", "{\"n\": 11871, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.66, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3374.93, \"learn_time_ms\": 43168.627}", "{\"n\": 11872, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3392.13, \"learn_time_ms\": 43314.917}", "{\"n\": 11873, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3390.98, \"learn_time_ms\": 43180.467}", "{\"n\": 11874, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.86, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3390.98, \"learn_time_ms\": 43110.547}", "{\"n\": 11875, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.65, \"episode_reward_max\": 14.0, \"episode_len_mean\": 3402.45, \"learn_time_ms\": 43044.852}", "{\"n\": 11876, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.85, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3403.47, \"learn_time_ms\": 43116.739}", "{\"n\": 11877, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3394.48, \"learn_time_ms\": 43134.704}", "{\"n\": 11878, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.98, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3387.32, \"learn_time_ms\": 43106.173}", "{\"n\": 11879, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -4.02, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3394.67, \"learn_time_ms\": 42970.6}", "{\"n\": 11880, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3413.12, \"learn_time_ms\": 43059.994}", "{\"n\": 11881, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.93, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3405.07, \"learn_time_ms\": 42994.071}", "{\"n\": 11882, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.95, \"episode_reward_max\": 10.0, \"episode_len_mean\": 3402.16, \"learn_time_ms\": 42973.29}", "{\"n\": 11883, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.77, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3388.24, \"learn_time_ms\": 43066.97}", "{\"n\": 11884, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.79, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3385.98, \"learn_time_ms\": 43077.955}", "{\"n\": 11885, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.69, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3389.17, \"learn_time_ms\": 43204.457}", "{\"n\": 11886, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3393.63, \"learn_time_ms\": 43183.539}", "{\"n\": 11887, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3393.63, \"learn_time_ms\": 43133.004}", "{\"n\": 11888, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.34, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3398.94, \"learn_time_ms\": 43094.156}", "{\"n\": 11889, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.21, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3394.31, \"learn_time_ms\": 43265.254}", "{\"n\": 11890, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.15, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3406.09, \"learn_time_ms\": 43200.804}", "{\"n\": 11891, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.08, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3416.4, \"learn_time_ms\": 43222.462}", "{\"n\": 11892, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.26, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3419.64, \"learn_time_ms\": 43150.49}", "{\"n\": 11893, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.52, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3409.93, \"learn_time_ms\": 43115.575}", "{\"n\": 11894, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.46, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3416.51, \"learn_time_ms\": 43098.361}", "{\"n\": 11895, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3416.18, \"learn_time_ms\": 43052.388}", "{\"n\": 11896, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.38, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3416.18, \"learn_time_ms\": 43109.716}", "{\"n\": 11897, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.32, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3417.28, \"learn_time_ms\": 43001.791}", "{\"n\": 11898, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.41, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3415.17, \"learn_time_ms\": 43012.314}", "{\"n\": 11899, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3406.68, \"learn_time_ms\": 42880.067}", "{\"n\": 11900, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.74, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3384.06, \"learn_time_ms\": 42891.376}", "{\"n\": 11901, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3384.73, \"learn_time_ms\": 42838.843}", "{\"n\": 11902, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.71, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3384.73, \"learn_time_ms\": 42872.627}", "{\"n\": 11903, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.58, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3389.75, \"learn_time_ms\": 42751.299}", "{\"n\": 11904, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3417.51, \"learn_time_ms\": 42909.386}", "{\"n\": 11905, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.2, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3418.28, \"learn_time_ms\": 42912.103}", "{\"n\": 11906, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3422.97, \"learn_time_ms\": 42904.11}", "{\"n\": 11907, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3422.97, \"learn_time_ms\": 42989.011}", "{\"n\": 11908, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -3.05, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3422.97, \"learn_time_ms\": 43155.972}", "{\"n\": 11909, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.99, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3419.79, \"learn_time_ms\": 43119.415}", "{\"n\": 11910, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3431.02, \"learn_time_ms\": 42981.847}", "{\"n\": 11911, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.79, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3431.02, \"learn_time_ms\": 43086.407}", "{\"n\": 11912, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.55, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3439.82, \"learn_time_ms\": 43156.971}", "{\"n\": 11913, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3444.0, \"learn_time_ms\": 43303.118}", "{\"n\": 11914, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.5, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3444.0, \"learn_time_ms\": 43277.973}", "{\"n\": 11915, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.59, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3429.99, \"learn_time_ms\": 43339.352}", "{\"n\": 11916, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.47, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3434.69, \"learn_time_ms\": 43264.627}", "{\"n\": 11917, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.46, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3418.9, \"learn_time_ms\": 43269.065}", "{\"n\": 11918, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.43, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3418.84, \"learn_time_ms\": 43169.591}", "{\"n\": 11919, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3428.23, \"learn_time_ms\": 43341.091}", "{\"n\": 11920, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.24, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3428.23, \"learn_time_ms\": 43403.113}", "{\"n\": 11921, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3429.08, \"learn_time_ms\": 43397.9}", "{\"n\": 11922, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.11, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3429.08, \"learn_time_ms\": 43350.796}", "{\"n\": 11923, \"episode_reward_min\": -17.0, \"episode_reward_mean\": -2.22, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3428.0, \"learn_time_ms\": 43367.214}", "{\"n\": 11924, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.09, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3430.42, \"learn_time_ms\": 43215.688}", "{\"n\": 11925, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -2.01, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3433.58, \"learn_time_ms\": 43122.018}", "{\"n\": 11926, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3440.13, \"learn_time_ms\": 43242.557}", "{\"n\": 11927, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3440.13, \"learn_time_ms\": 43250.255}", "{\"n\": 11928, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3440.13, \"learn_time_ms\": 43272.865}", "{\"n\": 11929, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.87, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3440.52, \"learn_time_ms\": 43257.938}", "{\"n\": 11930, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.33, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3488.64, \"learn_time_ms\": 43348.216}", "{\"n\": 11931, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.42, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3477.27, \"learn_time_ms\": 43321.034}", "{\"n\": 11932, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3472.23, \"learn_time_ms\": 43359.036}", "{\"n\": 11933, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.44, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3472.23, \"learn_time_ms\": 43369.848}", "{\"n\": 11934, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.43, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3475.82, \"learn_time_ms\": 43439.36}", "{\"n\": 11935, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3458.31, \"learn_time_ms\": 43383.11}", "{\"n\": 11936, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3464.29, \"learn_time_ms\": 43316.395}", "{\"n\": 11937, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.4, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3475.74, \"learn_time_ms\": 43305.723}", "{\"n\": 11938, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3477.95, \"learn_time_ms\": 43332.917}", "{\"n\": 11939, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.59, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3484.23, \"learn_time_ms\": 43264.279}", "{\"n\": 11940, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.66, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3475.73, \"learn_time_ms\": 43294.85}", "{\"n\": 11941, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3473.69, \"learn_time_ms\": 43251.051}", "{\"n\": 11942, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.93, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3472.62, \"learn_time_ms\": 43186.963}", "{\"n\": 11943, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.77, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3472.71, \"learn_time_ms\": 43169.332}", "{\"n\": 11944, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.63, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3469.52, \"learn_time_ms\": 43169.249}", "{\"n\": 11945, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3469.75, \"learn_time_ms\": 43187.513}", "{\"n\": 11946, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.52, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3469.75, \"learn_time_ms\": 43280.895}", "{\"n\": 11947, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.56, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3471.0, \"learn_time_ms\": 43240.429}", "{\"n\": 11948, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.36, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3469.34, \"learn_time_ms\": 43184.592}", "{\"n\": 11949, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.28, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3480.94, \"learn_time_ms\": 43184.418}", "{\"n\": 11950, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.28, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3480.94, \"learn_time_ms\": 43047.402}", "{\"n\": 11951, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -0.87, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3475.76, \"learn_time_ms\": 43114.065}", "{\"n\": 11952, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3476.42, \"learn_time_ms\": 43187.236}", "{\"n\": 11953, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3476.42, \"learn_time_ms\": 43192.116}", "{\"n\": 11954, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3476.42, \"learn_time_ms\": 43195.349}", "{\"n\": 11955, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.22, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3466.56, \"learn_time_ms\": 43259.332}", "{\"n\": 11956, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3478.39, \"learn_time_ms\": 43169.671}", "{\"n\": 11957, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.43, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3462.32, \"learn_time_ms\": 43230.133}", "{\"n\": 11958, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3440.12, \"learn_time_ms\": 43193.316}", "{\"n\": 11959, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.81, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3440.12, \"learn_time_ms\": 43191.211}", "{\"n\": 11960, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.91, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3423.39, \"learn_time_ms\": 43262.875}", "{\"n\": 11961, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.84, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3413.92, \"learn_time_ms\": 43256.193}", "{\"n\": 11962, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.86, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3411.19, \"learn_time_ms\": 43173.853}", "{\"n\": 11963, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.74, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3413.55, \"learn_time_ms\": 43122.873}", "{\"n\": 11964, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3411.9, \"learn_time_ms\": 43089.047}", "{\"n\": 11965, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.34, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3415.16, \"learn_time_ms\": 43134.133}", "{\"n\": 11966, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.34, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3415.16, \"learn_time_ms\": 43152.296}", "{\"n\": 11967, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.48, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3405.32, \"learn_time_ms\": 43150.479}", "{\"n\": 11968, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.46, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3406.99, \"learn_time_ms\": 43197.38}", "{\"n\": 11969, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.58, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3408.69, \"learn_time_ms\": 43229.462}", "{\"n\": 11970, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3426.37, \"learn_time_ms\": 43174.891}", "{\"n\": 11971, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3426.37, \"learn_time_ms\": 43053.737}", "{\"n\": 11972, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3426.37, \"learn_time_ms\": 43113.305}", "{\"n\": 11973, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.37, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3426.37, \"learn_time_ms\": 43061.96}", "{\"n\": 11974, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.18, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3444.98, \"learn_time_ms\": 43157.559}", "{\"n\": 11975, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.34, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3435.83, \"learn_time_ms\": 43212.851}", "{\"n\": 11976, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.19, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3425.08, \"learn_time_ms\": 43113.005}", "{\"n\": 11977, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.26, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3430.36, \"learn_time_ms\": 43023.795}", "{\"n\": 11978, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.26, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3430.36, \"learn_time_ms\": 43042.432}", "{\"n\": 11979, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.26, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3430.36, \"learn_time_ms\": 43017.139}", "{\"n\": 11980, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.15, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3419.94, \"learn_time_ms\": 43035.779}", "{\"n\": 11981, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.01, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3435.14, \"learn_time_ms\": 43066.684}", "{\"n\": 11982, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.05, \"episode_reward_max\": 17.0, \"episode_len_mean\": 3438.51, \"learn_time_ms\": 43002.467}", "{\"n\": 11983, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3447.3, \"learn_time_ms\": 43001.284}", "{\"n\": 11984, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3447.3, \"learn_time_ms\": 42851.723}", "{\"n\": 11985, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.25, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3447.3, \"learn_time_ms\": 42766.059}", "{\"n\": 11986, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.06, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3453.28, \"learn_time_ms\": 42855.532}", "{\"n\": 11987, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.2, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3461.29, \"learn_time_ms\": 43012.579}", "{\"n\": 11988, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.31, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3464.3, \"learn_time_ms\": 42881.757}", "{\"n\": 11989, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.39, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3469.47, \"learn_time_ms\": 42945.408}", "{\"n\": 11990, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3474.09, \"learn_time_ms\": 42941.157}", "{\"n\": 11991, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.32, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3474.09, \"learn_time_ms\": 42950.636}", "{\"n\": 11992, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.7, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3460.28, \"learn_time_ms\": 42973.456}", "{\"n\": 11993, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.79, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3459.21, \"learn_time_ms\": 43077.049}", "{\"n\": 11994, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.68, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3460.04, \"learn_time_ms\": 43145.579}", "{\"n\": 11995, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.41, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3478.54, \"learn_time_ms\": 43151.102}", "{\"n\": 11996, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.53, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3473.79, \"learn_time_ms\": 43172.518}", "{\"n\": 11997, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.65, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3473.05, \"learn_time_ms\": 43218.572}", "{\"n\": 11998, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.61, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3473.89, \"learn_time_ms\": 43226.254}", "{\"n\": 11999, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.62, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3472.3, \"learn_time_ms\": 43167.344}", "{\"n\": 12000, \"episode_reward_min\": -15.0, \"episode_reward_mean\": -1.49, \"episode_reward_max\": 13.0, \"episode_len_mean\": 3482.46, \"learn_time_ms\": 43134.252}"]