["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 607018.776, \"total_train_time_s\": 619.7044131755829}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 606789.841, \"total_train_time_s\": 613.1661493778229}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 606567.692, \"total_train_time_s\": 612.7468078136444}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1039.625, \"learn_time_ms\": 606372.956, \"total_train_time_s\": 612.2929651737213}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1035.7, \"learn_time_ms\": 606327.592, \"total_train_time_s\": 612.8314430713654}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.4375, \"learn_time_ms\": 606156.657, \"total_train_time_s\": 611.7671096324921}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1029.2173913043478, \"learn_time_ms\": 606130.528, \"total_train_time_s\": 612.5033481121063}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.958333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.2083333333333, \"learn_time_ms\": 606110.756, \"total_train_time_s\": 612.4614391326904}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.84375, \"learn_time_ms\": 606133.395, \"total_train_time_s\": 612.6735184192657}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1041.84375, \"learn_time_ms\": 606133.492, \"total_train_time_s\": 612.3967435359955}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1052.3, \"learn_time_ms\": 606027.448, \"total_train_time_s\": 612.3348152637482}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.952380952380953, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1054.6190476190477, \"learn_time_ms\": 605988.137, \"total_train_time_s\": 612.4623808860779}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.958333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1056.3541666666667, \"learn_time_ms\": 606001.751, \"total_train_time_s\": 612.4798386096954}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.942307692307693, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1058.5, \"learn_time_ms\": 606066.403, \"total_train_time_s\": 612.7295339107513}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.928571428571427, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1061.6607142857142, \"learn_time_ms\": 606087.32, \"total_train_time_s\": 612.6814143657684}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.936507936507937, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1066.920634920635, \"learn_time_ms\": 606246.038, \"total_train_time_s\": 613.3011951446533}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1068.34375, \"learn_time_ms\": 606369.076, \"total_train_time_s\": 613.5013959407806}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.930555555555557, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1072.0, \"learn_time_ms\": 606486.124, \"total_train_time_s\": 613.6702690124512}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.930555555555557, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1072.0, \"learn_time_ms\": 606524.034, \"total_train_time_s\": 612.9530982971191}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.925, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1081.675, \"learn_time_ms\": 606622.617, \"total_train_time_s\": 613.6214852333069}"]