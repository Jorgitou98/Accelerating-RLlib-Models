["{\"n\": 1, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.0, \"learn_time_ms\": 506142.172}", "{\"n\": 2, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.6, \"learn_time_ms\": 505272.666}", "{\"n\": 3, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1022.4444444444445, \"learn_time_ms\": 505113.119}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.75, \"learn_time_ms\": 504979.757}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.9375, \"learn_time_ms\": 505004.699}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1021.95, \"learn_time_ms\": 504972.797}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.3333333333334, \"learn_time_ms\": 504946.588}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.0357142857143, \"learn_time_ms\": 504959.307}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1018.75, \"learn_time_ms\": 504934.074}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 504930.645}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1023.375, \"learn_time_ms\": 504793.128}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.0, \"learn_time_ms\": 504853.868}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.9791666666667, \"learn_time_ms\": 504860.118}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1026.2884615384614, \"learn_time_ms\": 504913.688}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.964285714285715, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.642857142857, \"learn_time_ms\": 504906.239}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1035.4333333333334, \"learn_time_ms\": 504911.487}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.28125, \"learn_time_ms\": 504936.968}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.925373134328357, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1039.8358208955224, \"learn_time_ms\": 504923.541}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.887323943661972, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1044.0281690140846, \"learn_time_ms\": 504936.02}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87837837837838, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1047.337837837838, \"learn_time_ms\": 504977.528}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.846153846153847, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1051.1538461538462, \"learn_time_ms\": 504979.823}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.841463414634145, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1053.378048780488, \"learn_time_ms\": 504953.155}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.823529411764707, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1055.1411764705883, \"learn_time_ms\": 504950.207}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.808988764044944, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1056.2359550561798, \"learn_time_ms\": 504898.039}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.795698924731184, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1058.752688172043, \"learn_time_ms\": 504851.208}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.79381443298969, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1059.8762886597938, \"learn_time_ms\": 504811.219}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1061.07, \"learn_time_ms\": 504775.267}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.77, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1064.47, \"learn_time_ms\": 504751.859}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1067.14, \"learn_time_ms\": 504720.512}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1071.45, \"learn_time_ms\": 504645.171}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.68, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1074.74, \"learn_time_ms\": 504635.82}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1077.0, \"learn_time_ms\": 504649.789}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1081.14, \"learn_time_ms\": 504633.278}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1085.9, \"learn_time_ms\": 504642.932}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.58, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1089.3, \"learn_time_ms\": 504679.6}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1092.46, \"learn_time_ms\": 504704.419}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.54, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1095.41, \"learn_time_ms\": 504726.446}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.53, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1095.45, \"learn_time_ms\": 504729.037}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.51, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1097.16, \"learn_time_ms\": 504713.777}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1099.88, \"learn_time_ms\": 504700.588}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1103.24, \"learn_time_ms\": 504663.765}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1105.92, \"learn_time_ms\": 504610.774}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1104.18, \"learn_time_ms\": 504584.376}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1107.41, \"learn_time_ms\": 504576.984}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1107.13, \"learn_time_ms\": 504546.202}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.47, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1107.59, \"learn_time_ms\": 504533.716}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1107.25, \"learn_time_ms\": 504469.83}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.49, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1106.99, \"learn_time_ms\": 504460.921}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1107.84, \"learn_time_ms\": 504485.949}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.46, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1111.03, \"learn_time_ms\": 504486.241}"]