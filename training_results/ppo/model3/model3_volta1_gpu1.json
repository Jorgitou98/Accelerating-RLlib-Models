["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 17381.415}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 17148.988}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 17041.87}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.625, \"learn_time_ms\": 17013.239}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1014.3846153846154, \"learn_time_ms\": 16983.362}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1015.4375, \"learn_time_ms\": 16971.399}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.5, \"learn_time_ms\": 16939.374}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.5, \"learn_time_ms\": 16928.867}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.84375, \"learn_time_ms\": 16905.638}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.2162162162163, \"learn_time_ms\": 16898.786}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1017.175, \"learn_time_ms\": 16853.421}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.2978723404256, \"learn_time_ms\": 16845.597}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1019.25, \"learn_time_ms\": 16850.134}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.982142857142858, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.0357142857142, \"learn_time_ms\": 16831.791}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.982142857142858, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1026.0357142857142, \"learn_time_ms\": 16827.279}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96875, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1031.828125, \"learn_time_ms\": 16809.616}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96969696969697, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1033.2575757575758, \"learn_time_ms\": 16827.391}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.958333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1045.9583333333333, \"learn_time_ms\": 16822.476}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.96, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1047.28, \"learn_time_ms\": 16829.071}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9125, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1055.675, \"learn_time_ms\": 16816.957}", "{\"n\": 21, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.905882352941177, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1056.4352941176471, \"learn_time_ms\": 16799.736}", "{\"n\": 22, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.886363636363637, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1059.625, \"learn_time_ms\": 16805.373}", "{\"n\": 23, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.893617021276597, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1060.8085106382978, \"learn_time_ms\": 16805.946}", "{\"n\": 24, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.885416666666668, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1062.3333333333333, \"learn_time_ms\": 16799.86}", "{\"n\": 25, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1069.26, \"learn_time_ms\": 16802.401}", "{\"n\": 26, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.89, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1072.16, \"learn_time_ms\": 16802.032}", "{\"n\": 27, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.88, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1078.57, \"learn_time_ms\": 16802.016}", "{\"n\": 28, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1081.53, \"learn_time_ms\": 16806.584}", "{\"n\": 29, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1083.59, \"learn_time_ms\": 16821.56}", "{\"n\": 30, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.87, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1086.92, \"learn_time_ms\": 16840.279}", "{\"n\": 31, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1098.31, \"learn_time_ms\": 16858.243}", "{\"n\": 32, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.84, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1104.61, \"learn_time_ms\": 16873.095}", "{\"n\": 33, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1113.56, \"learn_time_ms\": 16868.232}", "{\"n\": 34, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.83, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1118.03, \"learn_time_ms\": 16907.023}", "{\"n\": 35, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1127.57, \"learn_time_ms\": 16907.865}", "{\"n\": 36, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.78, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1132.28, \"learn_time_ms\": 16921.668}", "{\"n\": 37, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1139.09, \"learn_time_ms\": 16927.766}", "{\"n\": 38, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.75, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1143.49, \"learn_time_ms\": 16942.302}", "{\"n\": 39, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.71, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1152.84, \"learn_time_ms\": 16934.115}", "{\"n\": 40, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.7, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1157.42, \"learn_time_ms\": 16924.755}", "{\"n\": 41, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1167.18, \"learn_time_ms\": 16909.08}", "{\"n\": 42, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.67, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1165.28, \"learn_time_ms\": 16883.519}", "{\"n\": 43, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1169.7, \"learn_time_ms\": 16894.857}", "{\"n\": 44, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1176.59, \"learn_time_ms\": 16881.918}", "{\"n\": 45, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.66, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1185.67, \"learn_time_ms\": 16910.346}", "{\"n\": 46, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.65, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1189.52, \"learn_time_ms\": 16912.49}", "{\"n\": 47, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1196.18, \"learn_time_ms\": 16891.802}", "{\"n\": 48, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.63, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1200.94, \"learn_time_ms\": 16865.011}", "{\"n\": 49, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1213.13, \"learn_time_ms\": 16869.809}", "{\"n\": 50, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.6, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1212.76, \"learn_time_ms\": 16873.476}", "{\"n\": 51, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.57, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1221.99, \"learn_time_ms\": 16870.134}", "{\"n\": 52, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1225.8, \"learn_time_ms\": 16876.433}", "{\"n\": 53, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1232.39, \"learn_time_ms\": 16856.465}", "{\"n\": 54, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.56, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1235.12, \"learn_time_ms\": 16852.336}", "{\"n\": 55, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.55, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1241.44, \"learn_time_ms\": 16837.974}", "{\"n\": 56, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.52, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1247.98, \"learn_time_ms\": 16848.665}", "{\"n\": 57, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1252.78, \"learn_time_ms\": 16879.334}", "{\"n\": 58, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.48, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1256.93, \"learn_time_ms\": 16910.915}", "{\"n\": 59, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1267.09, \"learn_time_ms\": 16910.172}", "{\"n\": 60, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1272.3, \"learn_time_ms\": 16929.303}", "{\"n\": 61, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1275.62, \"learn_time_ms\": 16936.377}", "{\"n\": 62, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1278.25, \"learn_time_ms\": 16949.844}", "{\"n\": 63, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1282.82, \"learn_time_ms\": 16959.066}", "{\"n\": 64, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1284.55, \"learn_time_ms\": 16968.653}", "{\"n\": 65, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1289.57, \"learn_time_ms\": 16974.886}", "{\"n\": 66, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1292.0, \"learn_time_ms\": 16992.917}", "{\"n\": 67, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1293.8, \"learn_time_ms\": 17005.086}", "{\"n\": 68, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1294.97, \"learn_time_ms\": 17024.582}", "{\"n\": 69, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1299.95, \"learn_time_ms\": 17033.246}", "{\"n\": 70, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1302.79, \"learn_time_ms\": 17014.016}", "{\"n\": 71, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1308.1, \"learn_time_ms\": 17010.491}", "{\"n\": 72, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1303.1, \"learn_time_ms\": 17005.754}", "{\"n\": 73, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1303.54, \"learn_time_ms\": 17007.18}", "{\"n\": 74, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1305.76, \"learn_time_ms\": 16985.961}", "{\"n\": 75, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1309.2, \"learn_time_ms\": 16961.085}", "{\"n\": 76, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1308.01, \"learn_time_ms\": 16922.205}", "{\"n\": 77, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1313.16, \"learn_time_ms\": 16888.067}", "{\"n\": 78, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.38, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1312.81, \"learn_time_ms\": 16848.534}", "{\"n\": 79, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1315.3, \"learn_time_ms\": 16822.851}", "{\"n\": 80, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1321.67, \"learn_time_ms\": 16823.558}", "{\"n\": 81, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.38, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1318.94, \"learn_time_ms\": 16824.718}", "{\"n\": 82, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.38, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1327.54, \"learn_time_ms\": 16804.842}", "{\"n\": 83, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.39, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1326.84, \"learn_time_ms\": 16800.522}", "{\"n\": 84, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1324.96, \"learn_time_ms\": 16810.072}", "{\"n\": 85, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.44, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1328.03, \"learn_time_ms\": 16810.205}", "{\"n\": 86, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.42, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1323.87, \"learn_time_ms\": 16809.39}", "{\"n\": 87, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.43, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1322.74, \"learn_time_ms\": 16796.626}", "{\"n\": 88, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.41, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1325.66, \"learn_time_ms\": 16806.179}", "{\"n\": 89, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.38, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1333.36, \"learn_time_ms\": 16822.029}", "{\"n\": 90, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.37, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1335.3, \"learn_time_ms\": 16817.362}", "{\"n\": 91, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.35, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1342.47, \"learn_time_ms\": 16810.699}", "{\"n\": 92, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.36, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1340.82, \"learn_time_ms\": 16810.789}", "{\"n\": 93, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.35, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1341.07, \"learn_time_ms\": 16815.349}", "{\"n\": 94, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.32, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1348.85, \"learn_time_ms\": 16838.308}", "{\"n\": 95, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.3, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1350.32, \"learn_time_ms\": 16868.752}", "{\"n\": 96, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.28, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1350.93, \"learn_time_ms\": 16921.325}", "{\"n\": 97, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1353.3, \"learn_time_ms\": 16969.545}", "{\"n\": 98, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.25, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1357.89, \"learn_time_ms\": 16999.833}", "{\"n\": 99, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.26, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1357.86, \"learn_time_ms\": 17033.179}", "{\"n\": 100, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1356.7, \"learn_time_ms\": 17065.838}", "{\"n\": 101, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.27, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1360.89, \"learn_time_ms\": 17090.205}", "{\"n\": 102, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.24, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1371.43, \"learn_time_ms\": 17133.914}", "{\"n\": 103, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.22, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1383.49, \"learn_time_ms\": 17162.609}", "{\"n\": 104, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.21, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1386.88, \"learn_time_ms\": 17164.973}", "{\"n\": 105, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.2, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1388.01, \"learn_time_ms\": 17137.406}", "{\"n\": 106, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.19, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1388.7, \"learn_time_ms\": 17104.08}", "{\"n\": 107, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.17, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1392.18, \"learn_time_ms\": 17059.154}", "{\"n\": 108, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1395.44, \"learn_time_ms\": 17010.811}", "{\"n\": 109, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.16, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1397.25, \"learn_time_ms\": 16974.209}", "{\"n\": 110, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.13, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1405.02, \"learn_time_ms\": 16941.547}", "{\"n\": 111, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.12, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1401.56, \"learn_time_ms\": 16940.104}", "{\"n\": 112, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.09, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1407.27, \"learn_time_ms\": 16910.403}", "{\"n\": 113, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.08, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1414.6, \"learn_time_ms\": 16880.498}", "{\"n\": 114, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.08, \"episode_reward_max\": -18.0, \"episode_len_mean\": 1414.6, \"learn_time_ms\": 16878.703}", "{\"n\": 115, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.02, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1419.41, \"learn_time_ms\": 16889.184}", "{\"n\": 116, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.03, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1427.31, \"learn_time_ms\": 16880.34}", "{\"n\": 117, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.01, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1430.88, \"learn_time_ms\": 16879.616}", "{\"n\": 118, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1432.49, \"learn_time_ms\": 16877.953}", "{\"n\": 119, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.0, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1438.42, \"learn_time_ms\": 16873.732}", "{\"n\": 120, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.99, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1438.94, \"learn_time_ms\": 16880.508}", "{\"n\": 121, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.98, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1445.03, \"learn_time_ms\": 16873.009}", "{\"n\": 122, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.92, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1458.37, \"learn_time_ms\": 16892.817}", "{\"n\": 123, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.92, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1457.61, \"learn_time_ms\": 16911.404}", "{\"n\": 124, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1473.58, \"learn_time_ms\": 16894.494}", "{\"n\": 125, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.84, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1473.58, \"learn_time_ms\": 16887.153}", "{\"n\": 126, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.82, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1479.44, \"learn_time_ms\": 16892.405}", "{\"n\": 127, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.82, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1487.14, \"learn_time_ms\": 16886.262}", "{\"n\": 128, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.8, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1491.4, \"learn_time_ms\": 16893.653}", "{\"n\": 129, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.75, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1490.09, \"learn_time_ms\": 16900.8}", "{\"n\": 130, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.73, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1493.39, \"learn_time_ms\": 16917.114}", "{\"n\": 131, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.66, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1497.04, \"learn_time_ms\": 16921.566}", "{\"n\": 132, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.66, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1499.22, \"learn_time_ms\": 16912.772}", "{\"n\": 133, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.64, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1502.88, \"learn_time_ms\": 16913.677}", "{\"n\": 134, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1496.29, \"learn_time_ms\": 16930.073}", "{\"n\": 135, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.68, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1502.43, \"learn_time_ms\": 16941.307}", "{\"n\": 136, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.66, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1506.49, \"learn_time_ms\": 16930.81}", "{\"n\": 137, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.63, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1512.66, \"learn_time_ms\": 16949.998}", "{\"n\": 138, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.61, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1518.09, \"learn_time_ms\": 16946.599}", "{\"n\": 139, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.56, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1527.27, \"learn_time_ms\": 16958.368}", "{\"n\": 140, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.52, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1538.5, \"learn_time_ms\": 16955.925}", "{\"n\": 141, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.5, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1539.05, \"learn_time_ms\": 16964.649}", "{\"n\": 142, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.52, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1543.74, \"learn_time_ms\": 16964.73}", "{\"n\": 143, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1551.37, \"learn_time_ms\": 16945.176}", "{\"n\": 144, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.49, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1552.34, \"learn_time_ms\": 16924.169}", "{\"n\": 145, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.46, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1557.36, \"learn_time_ms\": 16917.786}", "{\"n\": 146, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.42, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1562.35, \"learn_time_ms\": 16932.432}", "{\"n\": 147, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.43, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1564.46, \"learn_time_ms\": 16950.902}", "{\"n\": 148, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.41, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1556.72, \"learn_time_ms\": 16993.293}", "{\"n\": 149, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.42, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1561.86, \"learn_time_ms\": 17003.808}", "{\"n\": 150, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.41, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1568.73, \"learn_time_ms\": 17014.947}", "{\"n\": 151, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.41, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1565.23, \"learn_time_ms\": 17002.637}", "{\"n\": 152, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.37, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1572.42, \"learn_time_ms\": 16972.713}", "{\"n\": 153, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.34, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1575.65, \"learn_time_ms\": 16973.839}", "{\"n\": 154, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.35, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1576.18, \"learn_time_ms\": 16965.14}", "{\"n\": 155, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.37, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1578.3, \"learn_time_ms\": 16965.042}", "{\"n\": 156, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.37, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1584.07, \"learn_time_ms\": 16960.755}", "{\"n\": 157, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1583.31, \"learn_time_ms\": 16944.131}", "{\"n\": 158, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.42, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1579.62, \"learn_time_ms\": 16921.412}", "{\"n\": 159, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.41, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1586.35, \"learn_time_ms\": 16924.413}", "{\"n\": 160, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.39, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1598.57, \"learn_time_ms\": 16922.765}", "{\"n\": 161, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.41, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1605.15, \"learn_time_ms\": 16960.819}", "{\"n\": 162, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1607.84, \"learn_time_ms\": 16997.345}", "{\"n\": 163, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.42, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1610.57, \"learn_time_ms\": 17012.466}", "{\"n\": 164, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1612.0, \"learn_time_ms\": 17030.87}", "{\"n\": 165, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.44, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1619.27, \"learn_time_ms\": 17029.14}", "{\"n\": 166, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1625.49, \"learn_time_ms\": 17023.668}", "{\"n\": 167, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.45, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1632.78, \"learn_time_ms\": 17026.159}", "{\"n\": 168, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.43, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1640.3, \"learn_time_ms\": 17019.037}", "{\"n\": 169, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1642.73, \"learn_time_ms\": 16993.13}", "{\"n\": 170, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.38, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1647.11, \"learn_time_ms\": 16974.763}", "{\"n\": 171, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.38, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1656.11, \"learn_time_ms\": 16951.643}", "{\"n\": 172, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.35, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1662.53, \"learn_time_ms\": 16946.39}", "{\"n\": 173, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.36, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1664.11, \"learn_time_ms\": 16927.787}", "{\"n\": 174, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1667.08, \"learn_time_ms\": 16918.13}", "{\"n\": 175, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.39, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1675.35, \"learn_time_ms\": 16920.794}", "{\"n\": 176, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1680.32, \"learn_time_ms\": 16923.735}", "{\"n\": 177, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.4, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1682.98, \"learn_time_ms\": 16918.195}", "{\"n\": 178, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.37, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1695.39, \"learn_time_ms\": 16917.283}", "{\"n\": 179, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.35, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1701.39, \"learn_time_ms\": 16918.091}", "{\"n\": 180, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.32, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1706.97, \"learn_time_ms\": 16906.755}", "{\"n\": 181, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.33, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1715.33, \"learn_time_ms\": 16898.948}", "{\"n\": 182, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.33, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1718.75, \"learn_time_ms\": 16886.765}", "{\"n\": 183, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.31, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1725.98, \"learn_time_ms\": 16894.125}", "{\"n\": 184, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -17.0, \"episode_len_mean\": 1725.51, \"learn_time_ms\": 16906.42}", "{\"n\": 185, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.24, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1733.3, \"learn_time_ms\": 16913.237}", "{\"n\": 186, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1736.57, \"learn_time_ms\": 16920.442}", "{\"n\": 187, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1738.25, \"learn_time_ms\": 16938.988}", "{\"n\": 188, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1741.87, \"learn_time_ms\": 16958.155}", "{\"n\": 189, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1748.13, \"learn_time_ms\": 16983.511}", "{\"n\": 190, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1758.16, \"learn_time_ms\": 17011.224}", "{\"n\": 191, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1757.92, \"learn_time_ms\": 17007.601}", "{\"n\": 192, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.24, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1756.48, \"learn_time_ms\": 17011.626}", "{\"n\": 193, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1755.2, \"learn_time_ms\": 17012.559}", "{\"n\": 194, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.26, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1759.85, \"learn_time_ms\": 17013.728}", "{\"n\": 195, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.29, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1762.4, \"learn_time_ms\": 17012.07}", "{\"n\": 196, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.28, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1764.0, \"learn_time_ms\": 17038.303}", "{\"n\": 197, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1758.28, \"learn_time_ms\": 17050.713}", "{\"n\": 198, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1765.82, \"learn_time_ms\": 17047.671}", "{\"n\": 199, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1767.58, \"learn_time_ms\": 17042.517}", "{\"n\": 200, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1776.68, \"learn_time_ms\": 17024.907}", "{\"n\": 201, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1782.23, \"learn_time_ms\": 17028.89}", "{\"n\": 202, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1782.23, \"learn_time_ms\": 17036.002}", "{\"n\": 203, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1775.23, \"learn_time_ms\": 17032.239}", "{\"n\": 204, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1779.31, \"learn_time_ms\": 17018.93}", "{\"n\": 205, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1782.95, \"learn_time_ms\": 17020.71}", "{\"n\": 206, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.24, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1772.52, \"learn_time_ms\": 16998.452}", "{\"n\": 207, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.24, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1774.53, \"learn_time_ms\": 16969.185}", "{\"n\": 208, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1766.93, \"learn_time_ms\": 16950.574}", "{\"n\": 209, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1771.83, \"learn_time_ms\": 16931.237}", "{\"n\": 210, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1766.51, \"learn_time_ms\": 16939.009}", "{\"n\": 211, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1766.73, \"learn_time_ms\": 16941.996}", "{\"n\": 212, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.22, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1764.32, \"learn_time_ms\": 16951.685}", "{\"n\": 213, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1771.36, \"learn_time_ms\": 16949.099}", "{\"n\": 214, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1763.91, \"learn_time_ms\": 16955.488}", "{\"n\": 215, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1766.34, \"learn_time_ms\": 16960.634}", "{\"n\": 216, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.15, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1758.0, \"learn_time_ms\": 16947.283}", "{\"n\": 217, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1756.25, \"learn_time_ms\": 16946.663}", "{\"n\": 218, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.17, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1755.24, \"learn_time_ms\": 16949.797}", "{\"n\": 219, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1754.64, \"learn_time_ms\": 16959.185}", "{\"n\": 220, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1756.34, \"learn_time_ms\": 16941.195}", "{\"n\": 221, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1757.96, \"learn_time_ms\": 16929.755}", "{\"n\": 222, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.23, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1755.79, \"learn_time_ms\": 16930.487}", "{\"n\": 223, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1756.71, \"learn_time_ms\": 16947.704}", "{\"n\": 224, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.26, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1755.31, \"learn_time_ms\": 16972.049}", "{\"n\": 225, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1752.93, \"learn_time_ms\": 16996.342}", "{\"n\": 226, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.3, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1751.81, \"learn_time_ms\": 17009.314}", "{\"n\": 227, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.27, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1752.92, \"learn_time_ms\": 17023.07}", "{\"n\": 228, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.25, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1749.72, \"learn_time_ms\": 17028.617}", "{\"n\": 229, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.19, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1754.36, \"learn_time_ms\": 17021.206}", "{\"n\": 230, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.21, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1754.56, \"learn_time_ms\": 17028.317}", "{\"n\": 231, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1763.92, \"learn_time_ms\": 17035.019}", "{\"n\": 232, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.12, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1764.31, \"learn_time_ms\": 17013.765}", "{\"n\": 233, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.1, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1764.37, \"learn_time_ms\": 17002.532}", "{\"n\": 234, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1755.15, \"learn_time_ms\": 16981.451}", "{\"n\": 235, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.16, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1757.47, \"learn_time_ms\": 16957.483}", "{\"n\": 236, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.18, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1760.46, \"learn_time_ms\": 16948.65}", "{\"n\": 237, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.15, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1757.3, \"learn_time_ms\": 16934.622}", "{\"n\": 238, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.14, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1757.28, \"learn_time_ms\": 16929.445}", "{\"n\": 239, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.13, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1761.25, \"learn_time_ms\": 16932.24}", "{\"n\": 240, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.06, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1763.1, \"learn_time_ms\": 16939.742}", "{\"n\": 241, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.04, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1763.61, \"learn_time_ms\": 16938.429}", "{\"n\": 242, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -19.03, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1759.67, \"learn_time_ms\": 16940.455}", "{\"n\": 243, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.98, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1768.1, \"learn_time_ms\": 16963.182}", "{\"n\": 244, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.93, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1777.34, \"learn_time_ms\": 16992.12}", "{\"n\": 245, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.83, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1788.6, \"learn_time_ms\": 17034.537}", "{\"n\": 246, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1786.1, \"learn_time_ms\": 17058.958}", "{\"n\": 247, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1788.07, \"learn_time_ms\": 17111.435}", "{\"n\": 248, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1782.28, \"learn_time_ms\": 17133.942}", "{\"n\": 249, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1778.65, \"learn_time_ms\": 17129.722}", "{\"n\": 250, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1782.12, \"learn_time_ms\": 17123.223}", "{\"n\": 251, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1782.86, \"learn_time_ms\": 17146.943}", "{\"n\": 252, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.88, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1784.17, \"learn_time_ms\": 17164.715}", "{\"n\": 253, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.94, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1792.05, \"learn_time_ms\": 17173.79}", "{\"n\": 254, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.91, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1792.93, \"learn_time_ms\": 17166.124}", "{\"n\": 255, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.91, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1792.89, \"learn_time_ms\": 17132.079}", "{\"n\": 256, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1795.0, \"learn_time_ms\": 17122.083}", "{\"n\": 257, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1800.29, \"learn_time_ms\": 17095.981}", "{\"n\": 258, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.9, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1793.27, \"learn_time_ms\": 17089.427}", "{\"n\": 259, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.89, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1798.42, \"learn_time_ms\": 17092.793}", "{\"n\": 260, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.83, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1803.72, \"learn_time_ms\": 17105.183}", "{\"n\": 261, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1802.46, \"learn_time_ms\": 17093.796}", "{\"n\": 262, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.84, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1804.15, \"learn_time_ms\": 17082.819}", "{\"n\": 263, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.82, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1807.25, \"learn_time_ms\": 17066.284}", "{\"n\": 264, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1810.91, \"learn_time_ms\": 17055.144}", "{\"n\": 265, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1810.61, \"learn_time_ms\": 17051.319}", "{\"n\": 266, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1804.96, \"learn_time_ms\": 17062.743}", "{\"n\": 267, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1812.17, \"learn_time_ms\": 17051.019}", "{\"n\": 268, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1809.74, \"learn_time_ms\": 17036.969}", "{\"n\": 269, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1807.97, \"learn_time_ms\": 17031.686}", "{\"n\": 270, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1811.19, \"learn_time_ms\": 17025.1}", "{\"n\": 271, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1812.38, \"learn_time_ms\": 17036.371}", "{\"n\": 272, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1814.93, \"learn_time_ms\": 17078.136}", "{\"n\": 273, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1813.19, \"learn_time_ms\": 17111.99}", "{\"n\": 274, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1811.94, \"learn_time_ms\": 17127.976}", "{\"n\": 275, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1813.17, \"learn_time_ms\": 17127.73}", "{\"n\": 276, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1820.01, \"learn_time_ms\": 17096.597}", "{\"n\": 277, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1820.63, \"learn_time_ms\": 17089.913}", "{\"n\": 278, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1823.27, \"learn_time_ms\": 17101.6}", "{\"n\": 279, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1815.1, \"learn_time_ms\": 17125.276}", "{\"n\": 280, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1820.67, \"learn_time_ms\": 17161.174}", "{\"n\": 281, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1817.32, \"learn_time_ms\": 17166.254}", "{\"n\": 282, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1816.62, \"learn_time_ms\": 17166.439}", "{\"n\": 283, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.86, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1817.96, \"learn_time_ms\": 17147.291}", "{\"n\": 284, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.87, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1815.71, \"learn_time_ms\": 17140.589}", "{\"n\": 285, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1826.08, \"learn_time_ms\": 17119.963}", "{\"n\": 286, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.78, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1830.89, \"learn_time_ms\": 17130.272}", "{\"n\": 287, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.79, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1827.51, \"learn_time_ms\": 17165.012}", "{\"n\": 288, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.8, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1827.48, \"learn_time_ms\": 17192.018}", "{\"n\": 289, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.79, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1824.25, \"learn_time_ms\": 17193.678}", "{\"n\": 290, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1830.02, \"learn_time_ms\": 17169.902}", "{\"n\": 291, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1829.1, \"learn_time_ms\": 17159.446}", "{\"n\": 292, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1828.98, \"learn_time_ms\": 17147.734}", "{\"n\": 293, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1833.05, \"learn_time_ms\": 17134.636}", "{\"n\": 294, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.77, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1834.63, \"learn_time_ms\": 17123.59}", "{\"n\": 295, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1834.19, \"learn_time_ms\": 17121.897}", "{\"n\": 296, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.75, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1841.99, \"learn_time_ms\": 17116.582}", "{\"n\": 297, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1846.96, \"learn_time_ms\": 17091.811}", "{\"n\": 298, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1854.15, \"learn_time_ms\": 17059.011}", "{\"n\": 299, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1851.87, \"learn_time_ms\": 17036.954}", "{\"n\": 300, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1847.76, \"learn_time_ms\": 17023.793}", "{\"n\": 301, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1843.73, \"learn_time_ms\": 17012.024}", "{\"n\": 302, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1838.48, \"learn_time_ms\": 16975.319}", "{\"n\": 303, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1844.53, \"learn_time_ms\": 16965.918}", "{\"n\": 304, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1852.02, \"learn_time_ms\": 16954.179}", "{\"n\": 305, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1853.56, \"learn_time_ms\": 16956.644}", "{\"n\": 306, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1847.15, \"learn_time_ms\": 16978.446}", "{\"n\": 307, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.72, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1847.79, \"learn_time_ms\": 16964.84}", "{\"n\": 308, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.73, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1847.09, \"learn_time_ms\": 16991.529}", "{\"n\": 309, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.7, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1851.04, \"learn_time_ms\": 17016.365}", "{\"n\": 310, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1856.1, \"learn_time_ms\": 17023.009}", "{\"n\": 311, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1859.42, \"learn_time_ms\": 17025.059}", "{\"n\": 312, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.69, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1862.23, \"learn_time_ms\": 17028.187}", "{\"n\": 313, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.63, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1861.29, \"learn_time_ms\": 17021.445}", "{\"n\": 314, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.63, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1861.55, \"learn_time_ms\": 17024.891}", "{\"n\": 315, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1864.87, \"learn_time_ms\": 17034.284}", "{\"n\": 316, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1867.85, \"learn_time_ms\": 17030.901}", "{\"n\": 317, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1863.69, \"learn_time_ms\": 17033.704}", "{\"n\": 318, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1870.77, \"learn_time_ms\": 17003.723}", "{\"n\": 319, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1869.52, \"learn_time_ms\": 16979.586}", "{\"n\": 320, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1874.55, \"learn_time_ms\": 16988.603}", "{\"n\": 321, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1879.61, \"learn_time_ms\": 17002.51}", "{\"n\": 322, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.53, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1884.67, \"learn_time_ms\": 17027.25}", "{\"n\": 323, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1886.49, \"learn_time_ms\": 17054.353}", "{\"n\": 324, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1876.29, \"learn_time_ms\": 17076.052}", "{\"n\": 325, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1888.55, \"learn_time_ms\": 17088.754}", "{\"n\": 326, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1884.86, \"learn_time_ms\": 17069.743}", "{\"n\": 327, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1886.44, \"learn_time_ms\": 17065.408}", "{\"n\": 328, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1894.04, \"learn_time_ms\": 17061.516}", "{\"n\": 329, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1884.79, \"learn_time_ms\": 17066.235}", "{\"n\": 330, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1887.16, \"learn_time_ms\": 17049.693}", "{\"n\": 331, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1885.14, \"learn_time_ms\": 17032.003}", "{\"n\": 332, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1878.8, \"learn_time_ms\": 16991.24}", "{\"n\": 333, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1882.93, \"learn_time_ms\": 16970.341}", "{\"n\": 334, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.54, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1885.53, \"learn_time_ms\": 16948.217}", "{\"n\": 335, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1882.59, \"learn_time_ms\": 16937.616}", "{\"n\": 336, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1879.61, \"learn_time_ms\": 16940.041}", "{\"n\": 337, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.61, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1874.38, \"learn_time_ms\": 16947.048}", "{\"n\": 338, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.61, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1878.12, \"learn_time_ms\": 16976.866}", "{\"n\": 339, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.54, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1892.62, \"learn_time_ms\": 16979.876}", "{\"n\": 340, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.53, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1897.99, \"learn_time_ms\": 16980.303}", "{\"n\": 341, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.52, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1903.38, \"learn_time_ms\": 16983.621}", "{\"n\": 342, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1908.34, \"learn_time_ms\": 16993.746}", "{\"n\": 343, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1905.72, \"learn_time_ms\": 16990.543}", "{\"n\": 344, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1909.3, \"learn_time_ms\": 16984.899}", "{\"n\": 345, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1915.88, \"learn_time_ms\": 16975.704}", "{\"n\": 346, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.52, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1917.59, \"learn_time_ms\": 16977.079}", "{\"n\": 347, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1920.58, \"learn_time_ms\": 16970.971}", "{\"n\": 348, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.52, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1915.63, \"learn_time_ms\": 16928.119}", "{\"n\": 349, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1920.85, \"learn_time_ms\": 16917.972}", "{\"n\": 350, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.52, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1911.68, \"learn_time_ms\": 16919.17}", "{\"n\": 351, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1912.19, \"learn_time_ms\": 16908.326}", "{\"n\": 352, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1913.92, \"learn_time_ms\": 16908.789}", "{\"n\": 353, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.47, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1918.67, \"learn_time_ms\": 16922.512}", "{\"n\": 354, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1909.46, \"learn_time_ms\": 16925.253}", "{\"n\": 355, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1910.54, \"learn_time_ms\": 16921.405}", "{\"n\": 356, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.62, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1908.45, \"learn_time_ms\": 16918.877}", "{\"n\": 357, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.63, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1907.12, \"learn_time_ms\": 16915.959}", "{\"n\": 358, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.64, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1902.76, \"learn_time_ms\": 16942.245}", "{\"n\": 359, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.63, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1895.41, \"learn_time_ms\": 16946.107}", "{\"n\": 360, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1890.46, \"learn_time_ms\": 16964.127}", "{\"n\": 361, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1884.6, \"learn_time_ms\": 16964.04}", "{\"n\": 362, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1880.15, \"learn_time_ms\": 16988.177}", "{\"n\": 363, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1883.08, \"learn_time_ms\": 16978.605}", "{\"n\": 364, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.61, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1883.82, \"learn_time_ms\": 16969.133}", "{\"n\": 365, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1888.54, \"learn_time_ms\": 16963.784}", "{\"n\": 366, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1891.07, \"learn_time_ms\": 16973.315}", "{\"n\": 367, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1893.05, \"learn_time_ms\": 16968.938}", "{\"n\": 368, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1898.52, \"learn_time_ms\": 16957.056}", "{\"n\": 369, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1899.35, \"learn_time_ms\": 16960.129}", "{\"n\": 370, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.56, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1901.52, \"learn_time_ms\": 16948.795}", "{\"n\": 371, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1902.96, \"learn_time_ms\": 16965.353}", "{\"n\": 372, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1899.62, \"learn_time_ms\": 16955.281}", "{\"n\": 373, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.59, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1897.4, \"learn_time_ms\": 16937.003}", "{\"n\": 374, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1888.19, \"learn_time_ms\": 16943.094}", "{\"n\": 375, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1889.06, \"learn_time_ms\": 16970.32}", "{\"n\": 376, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1889.68, \"learn_time_ms\": 16959.527}", "{\"n\": 377, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1897.39, \"learn_time_ms\": 16977.196}", "{\"n\": 378, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1880.6, \"learn_time_ms\": 16989.172}", "{\"n\": 379, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -15.0, \"episode_len_mean\": 1880.6, \"learn_time_ms\": 16983.076}", "{\"n\": 380, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1885.66, \"learn_time_ms\": 16978.688}", "{\"n\": 381, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1888.28, \"learn_time_ms\": 16970.012}", "{\"n\": 382, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1886.92, \"learn_time_ms\": 16951.856}", "{\"n\": 383, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.68, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1880.26, \"learn_time_ms\": 16972.649}", "{\"n\": 384, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.79, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1881.52, \"learn_time_ms\": 16991.162}", "{\"n\": 385, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.8, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1884.3, \"learn_time_ms\": 16970.118}", "{\"n\": 386, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.81, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1884.4, \"learn_time_ms\": 16995.269}", "{\"n\": 387, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.75, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1899.08, \"learn_time_ms\": 17006.777}", "{\"n\": 388, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1902.37, \"learn_time_ms\": 17003.947}", "{\"n\": 389, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1902.37, \"learn_time_ms\": 17028.463}", "{\"n\": 390, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.74, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1904.58, \"learn_time_ms\": 17044.204}", "{\"n\": 391, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1905.62, \"learn_time_ms\": 17060.683}", "{\"n\": 392, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.76, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1905.62, \"learn_time_ms\": 17082.118}", "{\"n\": 393, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.79, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1897.83, \"learn_time_ms\": 17101.932}", "{\"n\": 394, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.71, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1906.55, \"learn_time_ms\": 17112.016}", "{\"n\": 395, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.66, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1913.73, \"learn_time_ms\": 17149.517}", "{\"n\": 396, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.63, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1923.91, \"learn_time_ms\": 17182.761}", "{\"n\": 397, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1928.04, \"learn_time_ms\": 17198.862}", "{\"n\": 398, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.55, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1932.05, \"learn_time_ms\": 17214.077}", "{\"n\": 399, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.53, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1948.85, \"learn_time_ms\": 17220.767}", "{\"n\": 400, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.53, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1948.94, \"learn_time_ms\": 17219.833}", "{\"n\": 401, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.52, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1951.45, \"learn_time_ms\": 17234.384}", "{\"n\": 402, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.53, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1957.95, \"learn_time_ms\": 17238.932}", "{\"n\": 403, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.57, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1962.01, \"learn_time_ms\": 17226.666}", "{\"n\": 404, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.61, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1964.07, \"learn_time_ms\": 17224.803}", "{\"n\": 405, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1966.81, \"learn_time_ms\": 17229.024}", "{\"n\": 406, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.64, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1959.19, \"learn_time_ms\": 17163.8}", "{\"n\": 407, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1958.44, \"learn_time_ms\": 17127.046}", "{\"n\": 408, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.65, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1960.44, \"learn_time_ms\": 17099.239}", "{\"n\": 409, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.64, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1963.27, \"learn_time_ms\": 17107.612}", "{\"n\": 410, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.67, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1962.02, \"learn_time_ms\": 17109.178}", "{\"n\": 411, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.64, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1968.04, \"learn_time_ms\": 17103.265}", "{\"n\": 412, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.62, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1967.89, \"learn_time_ms\": 17104.075}", "{\"n\": 413, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.6, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1969.58, \"learn_time_ms\": 17091.576}", "{\"n\": 414, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.61, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1967.75, \"learn_time_ms\": 17050.639}", "{\"n\": 415, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.58, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1978.49, \"learn_time_ms\": 17015.788}", "{\"n\": 416, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1988.64, \"learn_time_ms\": 17048.927}", "{\"n\": 417, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.5, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1990.72, \"learn_time_ms\": 17061.648}", "{\"n\": 418, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1986.13, \"learn_time_ms\": 17084.18}", "{\"n\": 419, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.51, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1990.11, \"learn_time_ms\": 17058.846}", "{\"n\": 420, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.46, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2003.4, \"learn_time_ms\": 17028.661}", "{\"n\": 421, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.49, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2000.28, \"learn_time_ms\": 17016.896}", "{\"n\": 422, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.44, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1999.72, \"learn_time_ms\": 17009.764}", "{\"n\": 423, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1999.74, \"learn_time_ms\": 17005.259}", "{\"n\": 424, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2005.68, \"learn_time_ms\": 17021.977}", "{\"n\": 425, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.37, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1998.65, \"learn_time_ms\": 17016.44}", "{\"n\": 426, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.35, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1996.03, \"learn_time_ms\": 17002.862}", "{\"n\": 427, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.35, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1996.03, \"learn_time_ms\": 16986.272}", "{\"n\": 428, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.34, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1997.76, \"learn_time_ms\": 16967.756}", "{\"n\": 429, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.39, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1994.46, \"learn_time_ms\": 16969.028}", "{\"n\": 430, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.43, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1989.62, \"learn_time_ms\": 16995.931}", "{\"n\": 431, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.42, \"episode_reward_max\": -14.0, \"episode_len_mean\": 1991.81, \"learn_time_ms\": 17028.395}", "{\"n\": 432, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.31, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2002.13, \"learn_time_ms\": 17063.63}", "{\"n\": 433, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2005.11, \"learn_time_ms\": 17096.649}", "{\"n\": 434, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2005.93, \"learn_time_ms\": 17096.5}", "{\"n\": 435, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2018.28, \"learn_time_ms\": 17108.491}", "{\"n\": 436, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2019.08, \"learn_time_ms\": 17104.938}", "{\"n\": 437, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.3, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2016.34, \"learn_time_ms\": 17112.521}", "{\"n\": 438, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2014.71, \"learn_time_ms\": 17120.911}", "{\"n\": 439, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2025.34, \"learn_time_ms\": 17091.588}", "{\"n\": 440, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.33, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2022.98, \"learn_time_ms\": 17072.756}", "{\"n\": 441, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.32, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2018.42, \"learn_time_ms\": 17012.068}", "{\"n\": 442, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2023.21, \"learn_time_ms\": 16967.677}", "{\"n\": 443, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2030.25, \"learn_time_ms\": 16934.576}", "{\"n\": 444, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2031.9, \"learn_time_ms\": 16939.773}", "{\"n\": 445, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2034.38, \"learn_time_ms\": 16941.982}", "{\"n\": 446, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2028.79, \"learn_time_ms\": 16940.112}", "{\"n\": 447, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2031.68, \"learn_time_ms\": 16934.612}", "{\"n\": 448, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2038.04, \"learn_time_ms\": 16929.644}", "{\"n\": 449, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.12, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2039.15, \"learn_time_ms\": 16960.932}", "{\"n\": 450, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2042.67, \"learn_time_ms\": 16965.079}", "{\"n\": 451, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2040.57, \"learn_time_ms\": 16978.712}", "{\"n\": 452, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2041.51, \"learn_time_ms\": 16991.532}", "{\"n\": 453, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2039.42, \"learn_time_ms\": 16997.715}", "{\"n\": 454, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2045.23, \"learn_time_ms\": 16986.981}", "{\"n\": 455, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2051.45, \"learn_time_ms\": 16980.985}", "{\"n\": 456, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.08, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2062.31, \"learn_time_ms\": 16966.555}", "{\"n\": 457, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.09, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2057.52, \"learn_time_ms\": 16970.825}", "{\"n\": 458, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2051.8, \"learn_time_ms\": 17003.131}", "{\"n\": 459, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.14, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2047.88, \"learn_time_ms\": 17007.489}", "{\"n\": 460, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2050.7, \"learn_time_ms\": 17018.072}", "{\"n\": 461, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2059.33, \"learn_time_ms\": 17043.889}", "{\"n\": 462, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2051.54, \"learn_time_ms\": 17049.224}", "{\"n\": 463, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2051.54, \"learn_time_ms\": 17073.685}", "{\"n\": 464, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2054.35, \"learn_time_ms\": 17090.494}", "{\"n\": 465, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2059.53, \"learn_time_ms\": 17106.302}", "{\"n\": 466, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2057.44, \"learn_time_ms\": 17123.388}", "{\"n\": 467, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2067.16, \"learn_time_ms\": 17144.633}", "{\"n\": 468, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2074.81, \"learn_time_ms\": 17125.92}", "{\"n\": 469, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2079.56, \"learn_time_ms\": 17122.753}", "{\"n\": 470, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2079.56, \"learn_time_ms\": 17096.934}", "{\"n\": 471, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2084.19, \"learn_time_ms\": 17064.916}", "{\"n\": 472, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2078.21, \"learn_time_ms\": 17041.713}", "{\"n\": 473, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.08, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2088.39, \"learn_time_ms\": 17015.779}", "{\"n\": 474, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2086.4, \"learn_time_ms\": 17008.955}", "{\"n\": 475, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.15, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2088.41, \"learn_time_ms\": 17017.319}", "{\"n\": 476, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2089.52, \"learn_time_ms\": 17017.955}", "{\"n\": 477, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2085.53, \"learn_time_ms\": 17015.318}", "{\"n\": 478, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2086.99, \"learn_time_ms\": 17037.798}", "{\"n\": 479, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.26, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2092.67, \"learn_time_ms\": 17039.337}", "{\"n\": 480, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.23, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2095.08, \"learn_time_ms\": 17070.189}", "{\"n\": 481, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2097.94, \"learn_time_ms\": 17092.926}", "{\"n\": 482, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.27, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2088.04, \"learn_time_ms\": 17126.421}", "{\"n\": 483, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.24, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2090.01, \"learn_time_ms\": 17159.843}", "{\"n\": 484, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.22, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2097.23, \"learn_time_ms\": 17176.811}", "{\"n\": 485, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2102.64, \"learn_time_ms\": 17196.715}", "{\"n\": 486, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.16, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2106.23, \"learn_time_ms\": 17209.837}", "{\"n\": 487, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2106.83, \"learn_time_ms\": 17243.288}", "{\"n\": 488, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.19, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2111.77, \"learn_time_ms\": 17246.245}", "{\"n\": 489, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2117.81, \"learn_time_ms\": 17272.959}", "{\"n\": 490, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.13, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2117.95, \"learn_time_ms\": 17297.836}", "{\"n\": 491, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.14, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2117.84, \"learn_time_ms\": 17308.44}", "{\"n\": 492, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.18, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2114.91, \"learn_time_ms\": 17294.491}", "{\"n\": 493, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.21, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2110.44, \"learn_time_ms\": 17301.027}", "{\"n\": 494, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.17, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2103.89, \"learn_time_ms\": 17314.063}", "{\"n\": 495, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.2, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2104.74, \"learn_time_ms\": 17269.502}", "{\"n\": 496, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.11, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2114.28, \"learn_time_ms\": 17257.47}", "{\"n\": 497, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.04, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2126.31, \"learn_time_ms\": 17226.158}", "{\"n\": 498, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.04, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2116.31, \"learn_time_ms\": 17188.948}", "{\"n\": 499, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2116.8, \"learn_time_ms\": 17162.06}", "{\"n\": 500, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2117.36, \"learn_time_ms\": 17135.288}", "{\"n\": 501, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2126.81, \"learn_time_ms\": 17102.715}", "{\"n\": 502, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.96, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2128.36, \"learn_time_ms\": 17085.177}", "{\"n\": 503, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2127.78, \"learn_time_ms\": 17043.623}", "{\"n\": 504, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2124.38, \"learn_time_ms\": 17011.398}", "{\"n\": 505, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2120.84, \"learn_time_ms\": 17013.316}", "{\"n\": 506, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2129.64, \"learn_time_ms\": 17030.507}", "{\"n\": 507, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2125.6, \"learn_time_ms\": 17035.488}", "{\"n\": 508, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2130.19, \"learn_time_ms\": 17057.424}", "{\"n\": 509, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2130.55, \"learn_time_ms\": 17066.87}", "{\"n\": 510, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2133.92, \"learn_time_ms\": 17071.465}", "{\"n\": 511, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2129.04, \"learn_time_ms\": 17082.986}", "{\"n\": 512, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.04, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2126.41, \"learn_time_ms\": 17095.559}", "{\"n\": 513, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.07, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2116.61, \"learn_time_ms\": 17101.653}", "{\"n\": 514, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.03, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2120.29, \"learn_time_ms\": 17106.476}", "{\"n\": 515, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2120.23, \"learn_time_ms\": 17118.153}", "{\"n\": 516, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2120.23, \"learn_time_ms\": 17095.139}", "{\"n\": 517, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.07, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2127.39, \"learn_time_ms\": 17073.58}", "{\"n\": 518, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2127.61, \"learn_time_ms\": 17047.56}", "{\"n\": 519, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2127.61, \"learn_time_ms\": 17020.281}", "{\"n\": 520, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2131.14, \"learn_time_ms\": 16993.721}", "{\"n\": 521, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2126.66, \"learn_time_ms\": 16986.526}", "{\"n\": 522, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2128.45, \"learn_time_ms\": 16974.712}", "{\"n\": 523, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.99, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2128.45, \"learn_time_ms\": 16984.696}", "{\"n\": 524, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2122.82, \"learn_time_ms\": 16981.918}", "{\"n\": 525, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.02, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2136.85, \"learn_time_ms\": 16987.205}", "{\"n\": 526, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2137.89, \"learn_time_ms\": 16995.786}", "{\"n\": 527, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2137.89, \"learn_time_ms\": 16981.209}", "{\"n\": 528, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.01, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2130.17, \"learn_time_ms\": 16973.863}", "{\"n\": 529, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2132.81, \"learn_time_ms\": 16980.959}", "{\"n\": 530, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2132.81, \"learn_time_ms\": 16983.748}", "{\"n\": 531, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.06, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2129.76, \"learn_time_ms\": 16979.667}", "{\"n\": 532, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.05, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2126.72, \"learn_time_ms\": 16985.511}", "{\"n\": 533, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.03, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2122.79, \"learn_time_ms\": 16992.955}", "{\"n\": 534, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.06, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2124.66, \"learn_time_ms\": 17007.529}", "{\"n\": 535, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.07, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2129.58, \"learn_time_ms\": 17012.843}", "{\"n\": 536, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.04, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2139.29, \"learn_time_ms\": 17019.516}", "{\"n\": 537, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.98, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2160.3, \"learn_time_ms\": 17026.158}", "{\"n\": 538, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.93, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2169.56, \"learn_time_ms\": 17031.012}", "{\"n\": 539, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2170.65, \"learn_time_ms\": 17021.653}", "{\"n\": 540, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.97, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2185.31, \"learn_time_ms\": 17017.978}", "{\"n\": 541, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.95, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2189.14, \"learn_time_ms\": 17021.388}", "{\"n\": 542, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.94, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2194.02, \"learn_time_ms\": 16998.74}", "{\"n\": 543, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.9, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2197.89, \"learn_time_ms\": 16972.95}", "{\"n\": 544, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.92, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2199.86, \"learn_time_ms\": 16955.298}", "{\"n\": 545, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.92, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2199.41, \"learn_time_ms\": 16930.153}", "{\"n\": 546, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2187.47, \"learn_time_ms\": 16919.805}", "{\"n\": 547, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -18.0, \"episode_reward_max\": -14.0, \"episode_len_mean\": 2188.99, \"learn_time_ms\": 16916.606}", "{\"n\": 548, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.92, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2199.35, \"learn_time_ms\": 16907.917}", "{\"n\": 549, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.92, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2197.09, \"learn_time_ms\": 16906.526}", "{\"n\": 550, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.89, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2202.87, \"learn_time_ms\": 16912.776}", "{\"n\": 551, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.89, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2204.4, \"learn_time_ms\": 16928.676}", "{\"n\": 552, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.84, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2209.47, \"learn_time_ms\": 16957.706}", "{\"n\": 553, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.78, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2215.84, \"learn_time_ms\": 16981.703}", "{\"n\": 554, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2221.69, \"learn_time_ms\": 17000.033}", "{\"n\": 555, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2221.69, \"learn_time_ms\": 17012.674}", "{\"n\": 556, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.73, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2222.63, \"learn_time_ms\": 17034.559}", "{\"n\": 557, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2229.69, \"learn_time_ms\": 17066.992}", "{\"n\": 558, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2233.26, \"learn_time_ms\": 17087.356}", "{\"n\": 559, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.74, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2233.26, \"learn_time_ms\": 17097.432}", "{\"n\": 560, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2260.02, \"learn_time_ms\": 17101.03}", "{\"n\": 561, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2262.64, \"learn_time_ms\": 17103.315}", "{\"n\": 562, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2262.64, \"learn_time_ms\": 17105.779}", "{\"n\": 563, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2262.64, \"learn_time_ms\": 17118.998}", "{\"n\": 564, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2263.92, \"learn_time_ms\": 17091.133}", "{\"n\": 565, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2272.82, \"learn_time_ms\": 17078.506}", "{\"n\": 566, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2272.82, \"learn_time_ms\": 17054.511}", "{\"n\": 567, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2272.14, \"learn_time_ms\": 17058.159}", "{\"n\": 568, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2281.54, \"learn_time_ms\": 17069.683}", "{\"n\": 569, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2277.24, \"learn_time_ms\": 17074.119}", "{\"n\": 570, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2272.94, \"learn_time_ms\": 17076.838}", "{\"n\": 571, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2276.11, \"learn_time_ms\": 17049.794}", "{\"n\": 572, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.59, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2270.3, \"learn_time_ms\": 17045.322}", "{\"n\": 573, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.58, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2276.93, \"learn_time_ms\": 17011.021}", "{\"n\": 574, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.61, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2273.47, \"learn_time_ms\": 17015.636}", "{\"n\": 575, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.6, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2273.34, \"learn_time_ms\": 17011.595}", "{\"n\": 576, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.57, \"episode_reward_max\": -13.0, \"episode_len_mean\": 2278.26, \"learn_time_ms\": 17020.177}", "{\"n\": 577, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.42, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2291.77, \"learn_time_ms\": 16993.455}", "{\"n\": 578, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.46, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2292.58, \"learn_time_ms\": 16973.597}", "{\"n\": 579, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.47, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2293.28, \"learn_time_ms\": 16980.591}", "{\"n\": 580, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.46, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2300.17, \"learn_time_ms\": 16977.576}", "{\"n\": 581, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.46, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2295.4, \"learn_time_ms\": 16986.778}", "{\"n\": 582, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2297.24, \"learn_time_ms\": 16975.551}", "{\"n\": 583, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2295.94, \"learn_time_ms\": 16973.608}", "{\"n\": 584, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2281.98, \"learn_time_ms\": 16973.889}", "{\"n\": 585, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.44, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2277.96, \"learn_time_ms\": 16972.7}", "{\"n\": 586, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.43, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2283.5, \"learn_time_ms\": 16977.006}", "{\"n\": 587, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.38, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2284.67, \"learn_time_ms\": 16962.064}", "{\"n\": 588, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.38, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2280.73, \"learn_time_ms\": 16954.076}", "{\"n\": 589, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.38, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2279.58, \"learn_time_ms\": 16938.152}", "{\"n\": 590, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.33, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2283.36, \"learn_time_ms\": 16946.163}", "{\"n\": 591, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.36, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2280.47, \"learn_time_ms\": 16949.097}", "{\"n\": 592, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.36, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2279.75, \"learn_time_ms\": 16960.722}", "{\"n\": 593, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.33, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2288.42, \"learn_time_ms\": 16972.39}", "{\"n\": 594, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.32, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2292.55, \"learn_time_ms\": 16985.307}", "{\"n\": 595, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2302.67, \"learn_time_ms\": 17015.755}", "{\"n\": 596, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.26, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2295.1, \"learn_time_ms\": 17018.918}", "{\"n\": 597, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.23, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2299.85, \"learn_time_ms\": 17057.297}", "{\"n\": 598, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.24, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2303.52, \"learn_time_ms\": 17076.366}", "{\"n\": 599, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.15, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2305.87, \"learn_time_ms\": 17085.668}", "{\"n\": 600, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2317.21, \"learn_time_ms\": 17076.417}", "{\"n\": 601, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2318.71, \"learn_time_ms\": 17105.674}", "{\"n\": 602, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.17, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2312.86, \"learn_time_ms\": 17115.449}", "{\"n\": 603, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2312.45, \"learn_time_ms\": 17110.267}", "{\"n\": 604, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.16, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2312.68, \"learn_time_ms\": 17114.512}", "{\"n\": 605, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.16, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2311.05, \"learn_time_ms\": 17081.89}", "{\"n\": 606, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.13, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2308.91, \"learn_time_ms\": 17053.623}", "{\"n\": 607, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.2, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2296.14, \"learn_time_ms\": 17034.734}", "{\"n\": 608, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.14, \"episode_reward_max\": -12.0, \"episode_len_mean\": 2300.75, \"learn_time_ms\": 17050.943}", "{\"n\": 609, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2302.26, \"learn_time_ms\": 17074.883}", "{\"n\": 610, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2301.44, \"learn_time_ms\": 17095.264}", "{\"n\": 611, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.11, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2293.97, \"learn_time_ms\": 17108.073}", "{\"n\": 612, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.1, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2293.5, \"learn_time_ms\": 17131.046}", "{\"n\": 613, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.09, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2293.85, \"learn_time_ms\": 17167.225}", "{\"n\": 614, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2291.24, \"learn_time_ms\": 17202.526}", "{\"n\": 615, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.05, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2286.77, \"learn_time_ms\": 17270.216}", "{\"n\": 616, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2285.37, \"learn_time_ms\": 17336.245}", "{\"n\": 617, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.08, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2285.37, \"learn_time_ms\": 17378.008}", "{\"n\": 618, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -17.04, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2290.2, \"learn_time_ms\": 17402.649}", "{\"n\": 619, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.89, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2309.31, \"learn_time_ms\": 17428.262}", "{\"n\": 620, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2306.62, \"learn_time_ms\": 17469.954}", "{\"n\": 621, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.88, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2306.62, \"learn_time_ms\": 17486.01}", "{\"n\": 622, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.85, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2316.62, \"learn_time_ms\": 17503.904}", "{\"n\": 623, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2330.11, \"learn_time_ms\": 17521.397}", "{\"n\": 624, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2328.65, \"learn_time_ms\": 17523.708}", "{\"n\": 625, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.74, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2327.81, \"learn_time_ms\": 17525.978}", "{\"n\": 626, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.71, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2328.72, \"learn_time_ms\": 17512.012}", "{\"n\": 627, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2332.14, \"learn_time_ms\": 17503.491}", "{\"n\": 628, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.67, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2328.84, \"learn_time_ms\": 17496.101}", "{\"n\": 629, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.65, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2325.33, \"learn_time_ms\": 17496.3}", "{\"n\": 630, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.69, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2319.89, \"learn_time_ms\": 17494.065}", "{\"n\": 631, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.63, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2320.04, \"learn_time_ms\": 17493.357}", "{\"n\": 632, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.64, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2320.65, \"learn_time_ms\": 17485.783}", "{\"n\": 633, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.58, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2326.28, \"learn_time_ms\": 17489.788}", "{\"n\": 634, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.62, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2321.52, \"learn_time_ms\": 17471.778}", "{\"n\": 635, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.59, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2325.75, \"learn_time_ms\": 17407.153}", "{\"n\": 636, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2324.74, \"learn_time_ms\": 17354.387}", "{\"n\": 637, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2324.57, \"learn_time_ms\": 17307.721}", "{\"n\": 638, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.56, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2324.57, \"learn_time_ms\": 17264.916}", "{\"n\": 639, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2335.58, \"learn_time_ms\": 17211.925}", "{\"n\": 640, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2335.58, \"learn_time_ms\": 17145.054}", "{\"n\": 641, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2324.29, \"learn_time_ms\": 17093.387}", "{\"n\": 642, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2320.79, \"learn_time_ms\": 17036.865}", "{\"n\": 643, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2326.58, \"learn_time_ms\": 16955.631}", "{\"n\": 644, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -11.0, \"episode_len_mean\": 2326.58, \"learn_time_ms\": 16911.974}", "{\"n\": 645, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.02, \"learn_time_ms\": 16893.211}", "{\"n\": 646, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2330.65, \"learn_time_ms\": 16884.368}", "{\"n\": 647, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2335.74, \"learn_time_ms\": 16873.987}", "{\"n\": 648, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2329.43, \"learn_time_ms\": 16868.189}", "{\"n\": 649, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.4, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2332.8, \"learn_time_ms\": 16874.925}", "{\"n\": 650, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2328.88, \"learn_time_ms\": 16893.79}", "{\"n\": 651, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2331.91, \"learn_time_ms\": 16884.342}", "{\"n\": 652, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2324.23, \"learn_time_ms\": 16882.943}", "{\"n\": 653, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2315.71, \"learn_time_ms\": 16891.463}", "{\"n\": 654, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2322.94, \"learn_time_ms\": 16884.2}", "{\"n\": 655, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2320.94, \"learn_time_ms\": 16887.171}", "{\"n\": 656, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2323.11, \"learn_time_ms\": 16894.056}", "{\"n\": 657, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2315.47, \"learn_time_ms\": 16912.058}", "{\"n\": 658, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2321.46, \"learn_time_ms\": 16913.867}", "{\"n\": 659, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2326.4, \"learn_time_ms\": 16898.207}", "{\"n\": 660, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2327.62, \"learn_time_ms\": 16887.862}", "{\"n\": 661, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2329.18, \"learn_time_ms\": 16919.165}", "{\"n\": 662, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2324.87, \"learn_time_ms\": 16941.666}", "{\"n\": 663, \"episode_reward_min\": -20.0, \"episode_reward_mean\": -16.26, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2324.89, \"learn_time_ms\": 16956.27}", "{\"n\": 664, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2327.99, \"learn_time_ms\": 16969.686}", "{\"n\": 665, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2329.31, \"learn_time_ms\": 16995.806}", "{\"n\": 666, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2333.17, \"learn_time_ms\": 17013.761}", "{\"n\": 667, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.23, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2334.34, \"learn_time_ms\": 16998.47}", "{\"n\": 668, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2311.08, \"learn_time_ms\": 16990.631}", "{\"n\": 669, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2308.35, \"learn_time_ms\": 16984.196}", "{\"n\": 670, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2311.29, \"learn_time_ms\": 16978.532}", "{\"n\": 671, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2308.83, \"learn_time_ms\": 16945.384}", "{\"n\": 672, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2306.85, \"learn_time_ms\": 16931.877}", "{\"n\": 673, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2309.82, \"learn_time_ms\": 16910.785}", "{\"n\": 674, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.47, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2309.62, \"learn_time_ms\": 16911.456}", "{\"n\": 675, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.53, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2304.73, \"learn_time_ms\": 16918.056}", "{\"n\": 676, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.55, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2303.24, \"learn_time_ms\": 16932.031}", "{\"n\": 677, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2305.31, \"learn_time_ms\": 16949.435}", "{\"n\": 678, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2326.34, \"learn_time_ms\": 16966.622}", "{\"n\": 679, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2336.07, \"learn_time_ms\": 16986.415}", "{\"n\": 680, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2345.97, \"learn_time_ms\": 17007.591}", "{\"n\": 681, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2347.67, \"learn_time_ms\": 17028.766}", "{\"n\": 682, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2347.23, \"learn_time_ms\": 17048.89}", "{\"n\": 683, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.34, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2354.14, \"learn_time_ms\": 17095.303}", "{\"n\": 684, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2362.98, \"learn_time_ms\": 17090.556}", "{\"n\": 685, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.25, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2366.24, \"learn_time_ms\": 17083.072}", "{\"n\": 686, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.29, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2365.74, \"learn_time_ms\": 17082.695}", "{\"n\": 687, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.3, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2371.39, \"learn_time_ms\": 17106.532}", "{\"n\": 688, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.33, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2373.03, \"learn_time_ms\": 17134.802}", "{\"n\": 689, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.32, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2377.88, \"learn_time_ms\": 17165.427}", "{\"n\": 690, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.37, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2368.68, \"learn_time_ms\": 17184.748}", "{\"n\": 691, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2371.46, \"learn_time_ms\": 17191.483}", "{\"n\": 692, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2365.01, \"learn_time_ms\": 17205.768}", "{\"n\": 693, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.57, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2358.27, \"learn_time_ms\": 17197.364}", "{\"n\": 694, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2354.96, \"learn_time_ms\": 17215.608}", "{\"n\": 695, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.61, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2355.55, \"learn_time_ms\": 17215.734}", "{\"n\": 696, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2359.76, \"learn_time_ms\": 17207.333}", "{\"n\": 697, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.62, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2351.66, \"learn_time_ms\": 17193.248}", "{\"n\": 698, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2361.02, \"learn_time_ms\": 17156.11}", "{\"n\": 699, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2361.02, \"learn_time_ms\": 17112.788}", "{\"n\": 700, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.6, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2361.02, \"learn_time_ms\": 17097.268}", "{\"n\": 701, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2374.57, \"learn_time_ms\": 17109.936}", "{\"n\": 702, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2378.63, \"learn_time_ms\": 17102.936}", "{\"n\": 703, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.49, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2380.42, \"learn_time_ms\": 17093.753}", "{\"n\": 704, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.54, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2372.49, \"learn_time_ms\": 17095.018}", "{\"n\": 705, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.52, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2378.99, \"learn_time_ms\": 17105.618}", "{\"n\": 706, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2380.36, \"learn_time_ms\": 17118.193}", "{\"n\": 707, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.4, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2392.05, \"learn_time_ms\": 17115.542}", "{\"n\": 708, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.43, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2388.68, \"learn_time_ms\": 17154.653}", "{\"n\": 709, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2392.71, \"learn_time_ms\": 17189.848}", "{\"n\": 710, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.48, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2392.09, \"learn_time_ms\": 17203.884}", "{\"n\": 711, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.42, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2396.99, \"learn_time_ms\": 17182.713}", "{\"n\": 712, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2401.51, \"learn_time_ms\": 17177.072}", "{\"n\": 713, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.41, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2404.28, \"learn_time_ms\": 17184.155}", "{\"n\": 714, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.44, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2404.53, \"learn_time_ms\": 17184.56}", "{\"n\": 715, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.28, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2417.14, \"learn_time_ms\": 17176.481}", "{\"n\": 716, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2415.04, \"learn_time_ms\": 17155.198}", "{\"n\": 717, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.27, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2420.43, \"learn_time_ms\": 17145.706}", "{\"n\": 718, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.21, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2423.43, \"learn_time_ms\": 17114.965}", "{\"n\": 719, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2440.14, \"learn_time_ms\": 17072.316}", "{\"n\": 720, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2441.17, \"learn_time_ms\": 17032.881}", "{\"n\": 721, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2433.2, \"learn_time_ms\": 17007.916}", "{\"n\": 722, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2433.2, \"learn_time_ms\": 16979.927}", "{\"n\": 723, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2436.34, \"learn_time_ms\": 16951.921}", "{\"n\": 724, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -16.0, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2451.44, \"learn_time_ms\": 16942.357}", "{\"n\": 725, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.97, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2451.71, \"learn_time_ms\": 16934.652}", "{\"n\": 726, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2453.1, \"learn_time_ms\": 16918.043}", "{\"n\": 727, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.93, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2452.03, \"learn_time_ms\": 16925.116}", "{\"n\": 728, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2439.08, \"learn_time_ms\": 16930.858}", "{\"n\": 729, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2440.27, \"learn_time_ms\": 16955.203}", "{\"n\": 730, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2434.02, \"learn_time_ms\": 16948.18}", "{\"n\": 731, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2432.48, \"learn_time_ms\": 16953.858}", "{\"n\": 732, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.89, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2429.06, \"learn_time_ms\": 16947.843}", "{\"n\": 733, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.95, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2420.17, \"learn_time_ms\": 16955.498}", "{\"n\": 734, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.91, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2422.6, \"learn_time_ms\": 16966.429}", "{\"n\": 735, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.98, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2417.07, \"learn_time_ms\": 16987.136}", "{\"n\": 736, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.86, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2421.73, \"learn_time_ms\": 17008.212}", "{\"n\": 737, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.83, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2427.6, \"learn_time_ms\": 17027.703}", "{\"n\": 738, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.88, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2424.62, \"learn_time_ms\": 17038.093}", "{\"n\": 739, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.85, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2429.6, \"learn_time_ms\": 17060.916}", "{\"n\": 740, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.78, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2438.22, \"learn_time_ms\": 17121.063}", "{\"n\": 741, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.75, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2442.83, \"learn_time_ms\": 17164.481}", "{\"n\": 742, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.72, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2441.7, \"learn_time_ms\": 17208.173}", "{\"n\": 743, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.52, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2458.97, \"learn_time_ms\": 17252.492}", "{\"n\": 744, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2463.66, \"learn_time_ms\": 17269.074}", "{\"n\": 745, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.39, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2467.4, \"learn_time_ms\": 17288.217}", "{\"n\": 746, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2471.61, \"learn_time_ms\": 17312.244}", "{\"n\": 747, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2467.29, \"learn_time_ms\": 17326.572}", "{\"n\": 748, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.36, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2467.29, \"learn_time_ms\": 17342.827}", "{\"n\": 749, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.38, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2468.49, \"learn_time_ms\": 17340.406}", "{\"n\": 750, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.37, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2465.1, \"learn_time_ms\": 17341.214}", "{\"n\": 751, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.41, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2457.95, \"learn_time_ms\": 17361.903}", "{\"n\": 752, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.33, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2461.45, \"learn_time_ms\": 17376.923}", "{\"n\": 753, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.35, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2461.16, \"learn_time_ms\": 17370.711}", "{\"n\": 754, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.42, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2464.08, \"learn_time_ms\": 17365.603}", "{\"n\": 755, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.31, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2476.92, \"learn_time_ms\": 17367.228}", "{\"n\": 756, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2480.8, \"learn_time_ms\": 17368.465}", "{\"n\": 757, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.3, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2480.8, \"learn_time_ms\": 17375.533}", "{\"n\": 758, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.27, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2484.13, \"learn_time_ms\": 17370.106}", "{\"n\": 759, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.24, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2488.47, \"learn_time_ms\": 17375.473}", "{\"n\": 760, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2503.52, \"learn_time_ms\": 17360.846}", "{\"n\": 761, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2503.52, \"learn_time_ms\": 17342.067}", "{\"n\": 762, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2510.38, \"learn_time_ms\": 17336.788}", "{\"n\": 763, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2510.38, \"learn_time_ms\": 17348.625}", "{\"n\": 764, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2500.05, \"learn_time_ms\": 17366.712}", "{\"n\": 765, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -10.0, \"episode_len_mean\": 2500.05, \"learn_time_ms\": 17356.92}", "{\"n\": 766, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2523.71, \"learn_time_ms\": 17360.706}", "{\"n\": 767, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2523.9, \"learn_time_ms\": 17348.283}", "{\"n\": 768, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2525.41, \"learn_time_ms\": 17357.202}", "{\"n\": 769, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2522.49, \"learn_time_ms\": 17350.448}", "{\"n\": 770, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2504.83, \"learn_time_ms\": 17373.682}", "{\"n\": 771, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.98, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2504.83, \"learn_time_ms\": 17369.248}", "{\"n\": 772, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2503.69, \"learn_time_ms\": 17366.501}", "{\"n\": 773, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2515.09, \"learn_time_ms\": 17363.103}", "{\"n\": 774, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2520.81, \"learn_time_ms\": 17369.913}", "{\"n\": 775, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.0, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2511.33, \"learn_time_ms\": 17387.088}", "{\"n\": 776, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2513.76, \"learn_time_ms\": 17390.268}", "{\"n\": 777, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2503.01, \"learn_time_ms\": 17389.923}", "{\"n\": 778, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2504.25, \"learn_time_ms\": 17402.623}", "{\"n\": 779, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2507.37, \"learn_time_ms\": 17422.071}", "{\"n\": 780, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2507.37, \"learn_time_ms\": 17413.406}", "{\"n\": 781, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2515.83, \"learn_time_ms\": 17422.206}", "{\"n\": 782, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2530.11, \"learn_time_ms\": 17431.834}", "{\"n\": 783, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2524.6, \"learn_time_ms\": 17431.72}", "{\"n\": 784, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2524.6, \"learn_time_ms\": 17440.914}", "{\"n\": 785, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.88, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2532.66, \"learn_time_ms\": 17426.267}", "{\"n\": 786, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2531.64, \"learn_time_ms\": 17429.481}", "{\"n\": 787, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2530.94, \"learn_time_ms\": 17430.854}", "{\"n\": 788, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2530.94, \"learn_time_ms\": 17408.811}", "{\"n\": 789, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.95, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2524.75, \"learn_time_ms\": 17403.796}", "{\"n\": 790, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2522.48, \"learn_time_ms\": 17397.878}", "{\"n\": 791, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2532.2, \"learn_time_ms\": 17386.903}", "{\"n\": 792, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2531.58, \"learn_time_ms\": 17363.98}", "{\"n\": 793, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2524.81, \"learn_time_ms\": 17357.263}", "{\"n\": 794, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2535.04, \"learn_time_ms\": 17346.283}", "{\"n\": 795, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2543.53, \"learn_time_ms\": 17350.609}", "{\"n\": 796, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2545.43, \"learn_time_ms\": 17326.258}", "{\"n\": 797, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.91, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2545.43, \"learn_time_ms\": 17321.883}", "{\"n\": 798, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2540.27, \"learn_time_ms\": 17336.517}", "{\"n\": 799, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.93, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2535.88, \"learn_time_ms\": 17340.081}", "{\"n\": 800, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2545.92, \"learn_time_ms\": 17339.741}", "{\"n\": 801, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2545.92, \"learn_time_ms\": 17348.684}", "{\"n\": 802, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2551.27, \"learn_time_ms\": 17362.972}", "{\"n\": 803, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2559.06, \"learn_time_ms\": 17359.576}", "{\"n\": 804, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2563.81, \"learn_time_ms\": 17342.297}", "{\"n\": 805, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.78, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2563.81, \"learn_time_ms\": 17332.88}", "{\"n\": 806, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.77, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2567.32, \"learn_time_ms\": 17347.609}", "{\"n\": 807, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2568.2, \"learn_time_ms\": 17365.921}", "{\"n\": 808, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.72, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2569.63, \"learn_time_ms\": 17357.943}", "{\"n\": 809, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2571.05, \"learn_time_ms\": 17348.786}", "{\"n\": 810, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.71, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2569.98, \"learn_time_ms\": 17349.102}", "{\"n\": 811, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2567.34, \"learn_time_ms\": 17348.633}", "{\"n\": 812, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.76, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2564.77, \"learn_time_ms\": 17361.49}", "{\"n\": 813, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2558.97, \"learn_time_ms\": 17381.972}", "{\"n\": 814, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2558.97, \"learn_time_ms\": 17394.324}", "{\"n\": 815, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2553.21, \"learn_time_ms\": 17392.074}", "{\"n\": 816, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.97, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2550.45, \"learn_time_ms\": 17394.089}", "{\"n\": 817, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2569.4, \"learn_time_ms\": 17393.012}", "{\"n\": 818, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.86, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2569.4, \"learn_time_ms\": 17389.557}", "{\"n\": 819, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.83, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2567.18, \"learn_time_ms\": 17385.917}", "{\"n\": 820, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2558.98, \"learn_time_ms\": 17389.338}", "{\"n\": 821, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.94, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2563.73, \"learn_time_ms\": 17386.021}", "{\"n\": 822, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.96, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2563.59, \"learn_time_ms\": 17375.484}", "{\"n\": 823, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2564.82, \"learn_time_ms\": 17363.579}", "{\"n\": 824, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2570.33, \"learn_time_ms\": 17376.151}", "{\"n\": 825, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.9, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2569.84, \"learn_time_ms\": 17400.953}", "{\"n\": 826, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.87, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2572.39, \"learn_time_ms\": 17398.695}", "{\"n\": 827, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.89, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2574.63, \"learn_time_ms\": 17392.146}", "{\"n\": 828, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2562.48, \"learn_time_ms\": 17398.868}", "{\"n\": 829, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2562.48, \"learn_time_ms\": 17409.762}", "{\"n\": 830, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.01, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2554.8, \"learn_time_ms\": 17411.655}", "{\"n\": 831, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2556.75, \"learn_time_ms\": 17412.376}", "{\"n\": 832, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2548.83, \"learn_time_ms\": 17399.527}", "{\"n\": 833, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2552.32, \"learn_time_ms\": 17380.669}", "{\"n\": 834, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2552.32, \"learn_time_ms\": 17362.298}", "{\"n\": 835, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2551.35, \"learn_time_ms\": 17340.172}", "{\"n\": 836, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2559.13, \"learn_time_ms\": 17332.233}", "{\"n\": 837, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.03, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2560.98, \"learn_time_ms\": 17313.548}", "{\"n\": 838, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2554.14, \"learn_time_ms\": 17295.357}", "{\"n\": 839, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2561.18, \"learn_time_ms\": 17282.382}", "{\"n\": 840, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2561.0, \"learn_time_ms\": 17261.1}", "{\"n\": 841, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2571.54, \"learn_time_ms\": 17238.686}", "{\"n\": 842, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.01, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2566.67, \"learn_time_ms\": 17231.867}", "{\"n\": 843, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.03, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2556.21, \"learn_time_ms\": 17236.624}", "{\"n\": 844, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2555.3, \"learn_time_ms\": 17238.863}", "{\"n\": 845, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2555.3, \"learn_time_ms\": 17238.873}", "{\"n\": 846, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2555.3, \"learn_time_ms\": 17238.911}", "{\"n\": 847, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2548.24, \"learn_time_ms\": 17248.533}", "{\"n\": 848, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2526.83, \"learn_time_ms\": 17265.242}", "{\"n\": 849, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2529.28, \"learn_time_ms\": 17279.58}", "{\"n\": 850, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2531.61, \"learn_time_ms\": 17298.537}", "{\"n\": 851, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2540.84, \"learn_time_ms\": 17332.911}", "{\"n\": 852, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2546.13, \"learn_time_ms\": 17366.025}", "{\"n\": 853, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2545.36, \"learn_time_ms\": 17396.149}", "{\"n\": 854, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2536.46, \"learn_time_ms\": 17418.578}", "{\"n\": 855, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2529.85, \"learn_time_ms\": 17447.573}", "{\"n\": 856, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2529.85, \"learn_time_ms\": 17468.719}", "{\"n\": 857, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2531.31, \"learn_time_ms\": 17474.595}", "{\"n\": 858, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2533.52, \"learn_time_ms\": 17478.91}", "{\"n\": 859, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2531.72, \"learn_time_ms\": 17463.652}", "{\"n\": 860, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2524.06, \"learn_time_ms\": 17443.99}", "{\"n\": 861, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2521.86, \"learn_time_ms\": 17403.88}", "{\"n\": 862, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2517.54, \"learn_time_ms\": 17379.002}", "{\"n\": 863, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2522.69, \"learn_time_ms\": 17369.491}", "{\"n\": 864, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2521.53, \"learn_time_ms\": 17335.988}", "{\"n\": 865, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2521.14, \"learn_time_ms\": 17301.336}", "{\"n\": 866, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2510.37, \"learn_time_ms\": 17287.345}", "{\"n\": 867, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2507.39, \"learn_time_ms\": 17272.816}", "{\"n\": 868, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2509.04, \"learn_time_ms\": 17259.741}", "{\"n\": 869, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2510.27, \"learn_time_ms\": 17271.825}", "{\"n\": 870, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -15.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2510.27, \"learn_time_ms\": 17304.252}", "{\"n\": 871, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.99, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2513.78, \"learn_time_ms\": 17339.327}", "{\"n\": 872, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2519.27, \"learn_time_ms\": 17375.87}", "{\"n\": 873, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.84, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2522.15, \"learn_time_ms\": 17372.123}", "{\"n\": 874, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2522.74, \"learn_time_ms\": 17397.597}", "{\"n\": 875, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.79, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2522.74, \"learn_time_ms\": 17409.61}", "{\"n\": 876, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.67, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2535.85, \"learn_time_ms\": 17429.938}", "{\"n\": 877, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2529.82, \"learn_time_ms\": 17466.985}", "{\"n\": 878, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.69, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2527.75, \"learn_time_ms\": 17486.484}", "{\"n\": 879, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.74, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2517.08, \"learn_time_ms\": 17502.308}", "{\"n\": 880, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.63, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2520.04, \"learn_time_ms\": 17513.263}", "{\"n\": 881, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2538.9, \"learn_time_ms\": 17519.178}", "{\"n\": 882, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2546.03, \"learn_time_ms\": 17508.478}", "{\"n\": 883, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.46, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2546.06, \"learn_time_ms\": 17516.703}", "{\"n\": 884, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.38, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2552.15, \"learn_time_ms\": 17524.688}", "{\"n\": 885, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2556.05, \"learn_time_ms\": 17537.726}", "{\"n\": 886, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.33, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2557.65, \"learn_time_ms\": 17536.789}", "{\"n\": 887, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2550.03, \"learn_time_ms\": 17506.228}", "{\"n\": 888, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2548.35, \"learn_time_ms\": 17486.813}", "{\"n\": 889, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -14.39, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2547.26, \"learn_time_ms\": 17472.235}", "{\"n\": 890, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2542.93, \"learn_time_ms\": 17443.058}", "{\"n\": 891, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.4, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2539.33, \"learn_time_ms\": 17416.474}", "{\"n\": 892, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2526.28, \"learn_time_ms\": 17393.689}", "{\"n\": 893, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.5, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2523.31, \"learn_time_ms\": 17374.68}", "{\"n\": 894, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2523.85, \"learn_time_ms\": 17357.386}", "{\"n\": 895, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2527.99, \"learn_time_ms\": 17333.741}", "{\"n\": 896, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2525.22, \"learn_time_ms\": 17315.664}", "{\"n\": 897, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.45, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2525.22, \"learn_time_ms\": 17331.212}", "{\"n\": 898, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.44, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2526.15, \"learn_time_ms\": 17333.028}", "{\"n\": 899, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.47, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2520.07, \"learn_time_ms\": 17327.025}", "{\"n\": 900, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.37, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2530.26, \"learn_time_ms\": 17330.039}", "{\"n\": 901, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.34, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2531.11, \"learn_time_ms\": 17337.07}", "{\"n\": 902, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.32, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2534.64, \"learn_time_ms\": 17334.518}", "{\"n\": 903, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.19, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2543.14, \"learn_time_ms\": 17342.253}", "{\"n\": 904, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2543.86, \"learn_time_ms\": 17329.024}", "{\"n\": 905, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2547.18, \"learn_time_ms\": 17337.048}", "{\"n\": 906, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2534.35, \"learn_time_ms\": 17335.91}", "{\"n\": 907, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.23, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2534.35, \"learn_time_ms\": 17321.811}", "{\"n\": 908, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.2, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2549.64, \"learn_time_ms\": 17329.761}", "{\"n\": 909, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.22, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2546.48, \"learn_time_ms\": 17325.383}", "{\"n\": 910, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2548.12, \"learn_time_ms\": 17322.24}", "{\"n\": 911, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.18, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2546.57, \"learn_time_ms\": 17316.714}", "{\"n\": 912, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2551.45, \"learn_time_ms\": 17315.353}", "{\"n\": 913, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2557.35, \"learn_time_ms\": 17307.685}", "{\"n\": 914, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2563.55, \"learn_time_ms\": 17318.599}", "{\"n\": 915, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2568.46, \"learn_time_ms\": 17329.171}", "{\"n\": 916, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2562.92, \"learn_time_ms\": 17340.02}", "{\"n\": 917, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.17, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2562.92, \"learn_time_ms\": 17345.801}", "{\"n\": 918, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2573.93, \"learn_time_ms\": 17341.073}", "{\"n\": 919, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.15, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2569.83, \"learn_time_ms\": 17342.994}", "{\"n\": 920, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2578.36, \"learn_time_ms\": 17308.828}", "{\"n\": 921, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2583.29, \"learn_time_ms\": 17313.653}", "{\"n\": 922, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.09, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2580.3, \"learn_time_ms\": 17310.047}", "{\"n\": 923, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2577.89, \"learn_time_ms\": 17300.14}", "{\"n\": 924, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2579.49, \"learn_time_ms\": 17293.075}", "{\"n\": 925, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.04, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2578.48, \"learn_time_ms\": 17278.312}", "{\"n\": 926, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2581.79, \"learn_time_ms\": 17266.033}", "{\"n\": 927, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.02, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2581.32, \"learn_time_ms\": 17239.027}", "{\"n\": 928, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2579.27, \"learn_time_ms\": 17225.417}", "{\"n\": 929, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.07, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2576.37, \"learn_time_ms\": 17190.291}", "{\"n\": 930, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.19, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2570.09, \"learn_time_ms\": 17204.929}", "{\"n\": 931, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2579.62, \"learn_time_ms\": 17204.066}", "{\"n\": 932, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.11, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2588.93, \"learn_time_ms\": 17215.108}", "{\"n\": 933, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2595.14, \"learn_time_ms\": 17227.906}", "{\"n\": 934, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.13, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2582.19, \"learn_time_ms\": 17222.056}", "{\"n\": 935, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.1, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2583.0, \"learn_time_ms\": 17210.105}", "{\"n\": 936, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2580.02, \"learn_time_ms\": 17193.311}", "{\"n\": 937, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.08, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2580.02, \"learn_time_ms\": 17204.001}", "{\"n\": 938, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.05, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2582.23, \"learn_time_ms\": 17190.259}", "{\"n\": 939, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.14, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2562.45, \"learn_time_ms\": 17205.142}", "{\"n\": 940, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.19, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2559.89, \"learn_time_ms\": 17203.022}", "{\"n\": 941, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.12, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2570.38, \"learn_time_ms\": 17189.997}", "{\"n\": 942, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.06, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2568.58, \"learn_time_ms\": 17181.312}", "{\"n\": 943, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -14.01, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2574.95, \"learn_time_ms\": 17166.55}", "{\"n\": 944, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.92, \"episode_reward_max\": -9.0, \"episode_len_mean\": 2581.14, \"learn_time_ms\": 17148.354}", "{\"n\": 945, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.84, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2583.68, \"learn_time_ms\": 17144.001}", "{\"n\": 946, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.77, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2592.86, \"learn_time_ms\": 17151.738}", "{\"n\": 947, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.8, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2585.31, \"learn_time_ms\": 17152.156}", "{\"n\": 948, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.83, \"episode_reward_max\": -8.0, \"episode_len_mean\": 2582.45, \"learn_time_ms\": 17170.634}", "{\"n\": 949, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.75, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2595.1, \"learn_time_ms\": 17179.734}", "{\"n\": 950, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.71, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2600.93, \"learn_time_ms\": 17193.039}", "{\"n\": 951, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.69, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2600.38, \"learn_time_ms\": 17198.261}", "{\"n\": 952, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.69, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2600.38, \"learn_time_ms\": 17184.71}", "{\"n\": 953, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.63, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2611.81, \"learn_time_ms\": 17181.895}", "{\"n\": 954, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.66, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2607.59, \"learn_time_ms\": 17201.319}", "{\"n\": 955, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.75, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2594.57, \"learn_time_ms\": 17204.861}", "{\"n\": 956, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.75, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2594.57, \"learn_time_ms\": 17204.282}", "{\"n\": 957, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.82, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2581.22, \"learn_time_ms\": 17218.161}", "{\"n\": 958, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.81, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2587.58, \"learn_time_ms\": 17239.684}", "{\"n\": 959, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.76, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2589.15, \"learn_time_ms\": 17229.474}", "{\"n\": 960, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2597.23, \"learn_time_ms\": 17217.616}", "{\"n\": 961, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2597.23, \"learn_time_ms\": 17212.809}", "{\"n\": 962, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.74, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2580.37, \"learn_time_ms\": 17224.325}", "{\"n\": 963, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.7, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2585.09, \"learn_time_ms\": 17233.411}", "{\"n\": 964, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.62, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2598.73, \"learn_time_ms\": 17236.632}", "{\"n\": 965, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.62, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2598.73, \"learn_time_ms\": 17252.254}", "{\"n\": 966, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.55, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2605.82, \"learn_time_ms\": 17256.285}", "{\"n\": 967, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.49, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2609.97, \"learn_time_ms\": 17238.713}", "{\"n\": 968, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.46, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2607.29, \"learn_time_ms\": 17203.873}", "{\"n\": 969, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.31, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2625.04, \"learn_time_ms\": 17198.283}", "{\"n\": 970, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.29, \"episode_reward_max\": -7.0, \"episode_len_mean\": 2624.49, \"learn_time_ms\": 17201.566}", "{\"n\": 971, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.22, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2633.96, \"learn_time_ms\": 17205.431}", "{\"n\": 972, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.25, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2628.71, \"learn_time_ms\": 17204.111}", "{\"n\": 973, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2638.26, \"learn_time_ms\": 17186.359}", "{\"n\": 974, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2644.33, \"learn_time_ms\": 17167.895}", "{\"n\": 975, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2643.86, \"learn_time_ms\": 17152.547}", "{\"n\": 976, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.14, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2643.73, \"learn_time_ms\": 17127.637}", "{\"n\": 977, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.13, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2642.64, \"learn_time_ms\": 17118.743}", "{\"n\": 978, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.12, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2648.78, \"learn_time_ms\": 17125.167}", "{\"n\": 979, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.17, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2645.1, \"learn_time_ms\": 17127.022}", "{\"n\": 980, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2635.45, \"learn_time_ms\": 17132.728}", "{\"n\": 981, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.19, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2638.85, \"learn_time_ms\": 17127.587}", "{\"n\": 982, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2629.87, \"learn_time_ms\": 17123.239}", "{\"n\": 983, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2629.87, \"learn_time_ms\": 17131.423}", "{\"n\": 984, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.19, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2625.92, \"learn_time_ms\": 17148.169}", "{\"n\": 985, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.23, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2623.92, \"learn_time_ms\": 17153.97}", "{\"n\": 986, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2628.96, \"learn_time_ms\": 17174.392}", "{\"n\": 987, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.2, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2628.96, \"learn_time_ms\": 17194.075}", "{\"n\": 988, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2637.79, \"learn_time_ms\": 17193.297}", "{\"n\": 989, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.04, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2639.15, \"learn_time_ms\": 17198.55}", "{\"n\": 990, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.0, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2644.77, \"learn_time_ms\": 17182.648}", "{\"n\": 991, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.99, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2643.65, \"learn_time_ms\": 17191.5}", "{\"n\": 992, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.03, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2641.73, \"learn_time_ms\": 17199.353}", "{\"n\": 993, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -13.02, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2643.73, \"learn_time_ms\": 17192.311}", "{\"n\": 994, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.97, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2651.7, \"learn_time_ms\": 17195.121}", "{\"n\": 995, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2653.79, \"learn_time_ms\": 17216.836}", "{\"n\": 996, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.92, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2653.79, \"learn_time_ms\": 17237.81}", "{\"n\": 997, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2657.27, \"learn_time_ms\": 17238.178}", "{\"n\": 998, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.89, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2663.53, \"learn_time_ms\": 17228.024}", "{\"n\": 999, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2662.0, \"learn_time_ms\": 17229.697}", "{\"n\": 1000, \"episode_reward_min\": -19.0, \"episode_reward_mean\": -12.93, \"episode_reward_max\": -6.0, \"episode_len_mean\": 2662.0, \"learn_time_ms\": 17223.691}"]