["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 18739.282, \"total_train_time_s\": 34.73544096946716}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 18453.638, \"total_train_time_s\": 28.462379932403564}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 18377.015, \"total_train_time_s\": 27.97715139389038}", "{\"n\": 4, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1027.25, \"learn_time_ms\": 18328.952, \"total_train_time_s\": 29.057929039001465}", "{\"n\": 5, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1025.3333333333333, \"learn_time_ms\": 18294.448, \"total_train_time_s\": 27.909475803375244}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -21.0, \"episode_reward_max\": -21.0, \"episode_len_mean\": 1033.8125, \"learn_time_ms\": 18265.883, \"total_train_time_s\": 27.97449803352356}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.954545454545453, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1049.3181818181818, \"learn_time_ms\": 18281.135, \"total_train_time_s\": 28.22639560699463}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.958333333333332, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1053.125, \"learn_time_ms\": 18259.507, \"total_train_time_s\": 28.370115518569946}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1059.4375, \"learn_time_ms\": 18242.797, \"total_train_time_s\": 27.87177538871765}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1059.4375, \"learn_time_ms\": 18228.923, \"total_train_time_s\": 27.95421075820923}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94871794871795, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1068.7948717948718, \"learn_time_ms\": 18165.191, \"total_train_time_s\": 28.04395890235901}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.95, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1069.3, \"learn_time_ms\": 18158.872, \"total_train_time_s\": 28.17221474647522}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.9375, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1085.6666666666667, \"learn_time_ms\": 18146.631, \"total_train_time_s\": 27.89406657218933}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1085.1, \"learn_time_ms\": 18139.372, \"total_train_time_s\": 27.789790153503418}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.946428571428573, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1090.25, \"learn_time_ms\": 18137.919, \"total_train_time_s\": 28.45678687095642}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.948275862068964, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1090.4137931034484, \"learn_time_ms\": 18135.691, \"total_train_time_s\": 27.838083505630493}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.953125, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1091.015625, \"learn_time_ms\": 18109.098, \"total_train_time_s\": 28.72482419013977}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.940298507462686, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1091.7164179104477, \"learn_time_ms\": 18110.627, \"total_train_time_s\": 28.18268585205078}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.944444444444443, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1095.0277777777778, \"learn_time_ms\": 18110.684, \"total_train_time_s\": 27.774044275283813}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.94871794871795, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1094.7307692307693, \"learn_time_ms\": 18112.041, \"total_train_time_s\": 27.94825768470764}"]