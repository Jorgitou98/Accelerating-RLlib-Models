["{\"n\": 1, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 71951.783, \"total_train_time_s\": 105.94537711143494}", "{\"n\": 2, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 52223.447, \"total_train_time_s\": 58.346800804138184}", "{\"n\": 3, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 45880.069, \"total_train_time_s\": 47.435630798339844}", "{\"n\": 4, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 42687.369, \"total_train_time_s\": 42.184171199798584}", "{\"n\": 5, \"episode_reward_min\": NaN, \"episode_reward_mean\": NaN, \"episode_reward_max\": NaN, \"episode_len_mean\": NaN, \"learn_time_ms\": 40754.342, \"total_train_time_s\": 42.10661792755127}", "{\"n\": 6, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.8, \"episode_reward_max\": -20.0, \"episode_len_mean\": 1096.2, \"learn_time_ms\": 39376.159, \"total_train_time_s\": 40.964009523391724}", "{\"n\": 7, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1187.6875, \"learn_time_ms\": 38283.146, \"total_train_time_s\": 40.107078552246094}", "{\"n\": 8, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1173.4444444444443, \"learn_time_ms\": 37554.799, \"total_train_time_s\": 40.860079526901245}", "{\"n\": 9, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.5, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1172.1666666666667, \"learn_time_ms\": 37056.219, \"total_train_time_s\": 41.50190305709839}", "{\"n\": 10, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.448275862068964, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1181.6896551724137, \"learn_time_ms\": 36586.389, \"total_train_time_s\": 40.85899877548218}", "{\"n\": 11, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.4375, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1180.96875, \"learn_time_ms\": 32648.519, \"total_train_time_s\": 41.26750349998474}", "{\"n\": 12, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.45945945945946, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1173.8108108108108, \"learn_time_ms\": 32642.048, \"total_train_time_s\": 41.17120671272278}", "{\"n\": 13, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.452380952380953, \"episode_reward_max\": -19.0, \"episode_len_mean\": 1175.3095238095239, \"learn_time_ms\": 32634.241, \"total_train_time_s\": 41.711151123046875}", "{\"n\": 14, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.291666666666668, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1211.2708333333333, \"learn_time_ms\": 32566.505, \"total_train_time_s\": 40.886436223983765}", "{\"n\": 15, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.254901960784313, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1215.9019607843138, \"learn_time_ms\": 32347.338, \"total_train_time_s\": 39.28413367271423}", "{\"n\": 16, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.196428571428573, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1235.9285714285713, \"learn_time_ms\": 32243.736, \"total_train_time_s\": 39.926037073135376}", "{\"n\": 17, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.129032258064516, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1256.758064516129, \"learn_time_ms\": 32390.498, \"total_train_time_s\": 41.6065092086792}", "{\"n\": 18, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.106060606060606, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1266.3939393939395, \"learn_time_ms\": 32406.197, \"total_train_time_s\": 41.42310881614685}", "{\"n\": 19, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.071428571428573, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1271.8857142857144, \"learn_time_ms\": 32423.972, \"total_train_time_s\": 41.633224964141846}", "{\"n\": 20, \"episode_reward_min\": -21.0, \"episode_reward_mean\": -20.054054054054053, \"episode_reward_max\": -16.0, \"episode_len_mean\": 1275.4864864864865, \"learn_time_ms\": 32410.4, \"total_train_time_s\": 40.64681577682495}"]